<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v3.0 20080202//EN" "archivearticle3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
  <?DTDIdentifier.IdentifierType public?>
  <?SourceDTD.DTDName A++V2.4.dtd?>
  <?SourceDTD.Version 2.4?>
  <?ConverterInfo.XSLTName springer2nlmx2.xsl?>
  <?ConverterInfo.Version 2?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Scientometrics</journal-id>
      <journal-title-group>
        <journal-title>Scientometrics</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0138-9130</issn>
      <issn pub-type="epub">1588-2861</issn>
      <publisher>
        <publisher-name>Springer Netherlands</publisher-name>
        <publisher-loc>Dordrecht</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3081055</article-id>
      <article-id pub-id-type="pmid">21654898</article-id>
      <article-id pub-id-type="publisher-id">354</article-id>
      <article-id pub-id-type="doi">10.1007/s11192-011-0354-5</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Towards a new crown indicator: an empirical analysis</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Waltman</surname>
            <given-names>Ludo</given-names>
          </name>
          <address>
            <email>waltmanlr@cwts.leidenuniv.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>van Eck</surname>
            <given-names>Nees Jan</given-names>
          </name>
          <address>
            <email>ecknjpvan@cwts.leidenuniv.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>van Leeuwen</surname>
            <given-names>Thed N.</given-names>
          </name>
          <address>
            <email>leeuwen@cwts.leidenuniv.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Visser</surname>
            <given-names>Martijn S.</given-names>
          </name>
          <address>
            <email>visser@cwts.leidenuniv.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>van Raan</surname>
            <given-names>Anthony F. J.</given-names>
          </name>
          <address>
            <email>vanraan@cwts.leidenuniv.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <aff id="Aff1">Centre for Science and Technology Studies, Leiden University, Leiden, The Netherlands </aff>
      </contrib-group>
      <pub-date pub-type="epub">
        <day>24</day>
        <month>2</month>
        <year>2011</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>24</day>
        <month>2</month>
        <year>2011</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>6</month>
        <year>2011</year>
      </pub-date>
      <volume>87</volume>
      <issue>3</issue>
      <fpage>467</fpage>
      <lpage>481</lpage>
      <history>
        <date date-type="received">
          <day>7</day>
          <month>9</month>
          <year>2010</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; The Author(s) 2011</copyright-statement>
      </permissions>
      <abstract id="Abs1">
        <p>We present an empirical comparison between two normalization mechanisms for citation-based indicators of research performance. These mechanisms aim to normalize citation counts for the field and the year in which a publication was published. One mechanism is applied in the current so-called crown indicator of our institute. The other mechanism is applied in the new crown indicator that our institute is currently exploring. We find that at high aggregation levels, such as at the level of large research institutions or at the level of countries, the differences between the two mechanisms are very small. At lower aggregation levels, such as at the level of research groups or at the level of journals, the differences between the two mechanisms are somewhat larger. We pay special attention to the way in which recent publications are handled. These publications typically have very low citation counts and should therefore be handled with special care.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Bibliometric indicator</kwd>
        <kwd>Citation</kwd>
        <kwd>Crown indicator</kwd>
        <kwd>Field</kwd>
        <kwd>Normalization</kwd>
      </kwd-group>
      <custom-meta-group>
        <custom-meta>
          <meta-name>issue-copyright-statement</meta-name>
          <meta-value>&#xA9; Akad&#xE9;miai Kiad&#xF3;, Budapest, Hungary 2011</meta-value>
        </custom-meta>
      </custom-meta-group>
    </article-meta>
  </front>
  <body>
    <sec id="Sec1">
      <title>Introduction</title>
      <p>It is well known that the average number of citations per publication varies significantly across scientific fields. Of course, the average number of citations per publication also varies across publications of different ages. That is, older publications on average have more citations than newer ones. Due to these effects, citation counts of publications published in different fields or in different years cannot be directly compared with each other.</p>
      <p>It is generally agreed that in citation-based research performance evaluations one needs to control for the field and the year in which a publication was published. In performance evaluation studies, our institute, the Centre for Science and Technology Studies (CWTS) of Leiden University, uses a standard set of bibliometric indicators (Van Raan <xref ref-type="bibr" rid="CR24">2005</xref>). Our best-known indicator, which we often refer to as the crown indicator, relies on a normalization mechanism that aims to correct for the field and the year in which a publication was published.<xref ref-type="fn" rid="Fn1">1</xref> An indicator similar to the crown indicator is used by the Centre for R&amp;D Monitoring (ECOOM) in Leuven, Belgium. ECOOM calls its indicator the normalized mean citation rate (e.g., Gl&#xE4;nzel et al. <xref ref-type="bibr" rid="CR11">2009</xref>).</p>
      <p>The normalization mechanism of the crown indicator basically works as follows. Given a set of publications, we count for each publication the number of citations it has received. We also determine for each publication its expected number of citations. The expected number of citations of a publication equals the average number of citations of all publications of the same document type (i.e., article, letter, or review) published in the same field and in the same year. To obtain the crown indicator, we divide the sum of the actual number of citations of all publications by the sum of the expected number of citations of all publications.</p>
      <p>As an alternative to the above normalization mechanism, one could take the following approach. One first calculates for each publication the ratio of its actual number of citations and its expected number of citations, and one then takes the average of the ratios that one has obtained. An indicator that corrects for field differences using this alternative normalization mechanism was introduced by Lundberg (<xref ref-type="bibr" rid="CR14">2007</xref>). He called his indicator the item-oriented field-normalized citation score average. More recently, Opthof and Leydesdorff (<xref ref-type="bibr" rid="CR17">2010</xref>) argued in favor of the alternative normalization mechanism. Their paper has been the starting point of a debate in the literature. A reply to Opthof and Leydesdorff was given by CWTS (Van Raan et al. <xref ref-type="bibr" rid="CR25">2010</xref>). Other contributions to the discussion were made by Bornmann (<xref ref-type="bibr" rid="CR1">2010</xref>), Bornmann and Mutz (<xref ref-type="bibr" rid="CR2">2011</xref>), Gingras and Larivi&#xE8;re (<xref ref-type="bibr" rid="CR10">2011</xref>), Leydesdorff and Opthof (<xref ref-type="bibr" rid="CR12">2010</xref>, <xref ref-type="bibr" rid="CR13">2011</xref>), Moed (<xref ref-type="bibr" rid="CR15">2010</xref>), and Spaan (<xref ref-type="bibr" rid="CR22">2010</xref>). Indicators that rely on the alternative normalization mechanism are being used by various institutes, among which Karolinska Institute in Sweden (Rehn and Kronman <xref ref-type="bibr" rid="CR18">2008</xref>), Science-Metrix in the US and Canada (e.g., Campbell et al. <xref ref-type="bibr" rid="CR4">2008</xref>, p. 12), the SCImago research group in Spain (SCImago Research Group <xref ref-type="bibr" rid="CR21">2009</xref>), and Wageningen University in the Netherlands (Van Veller et al. <xref ref-type="bibr" rid="CR26">2009</xref>). The alternative mechanism is also employed in studies by Colliander and Ahlgren (<xref ref-type="bibr" rid="CR5">2011</xref>) and Sandstr&#xF6;m (<xref ref-type="bibr" rid="CR19">2009</xref>, pp. 33&#x2013;34).</p>
      <p>In a recent paper (Waltman et al. <xref ref-type="bibr" rid="CR30">2011</xref>), we have presented a theoretical comparison between the normalization mechanism of the crown indicator and the alternative normalization mechanism advocated by Lundberg (<xref ref-type="bibr" rid="CR14">2007</xref>) and Opthof and Leydesdorff (<xref ref-type="bibr" rid="CR17">2010</xref>). The main conclusion that we have reached is that, at least for the purpose of correcting for the field in which a publication was published, the alternative mechanism has more satisfactory properties than the mechanism of the crown indicator. In particular, the alternative mechanism weighs all publications equally while the mechanism of the crown indicator gives more weight to publications from fields with a high expected number of citations. The alternative mechanism also has a so-called consistency property. Basically, this property ensures that the ranking of two units relative to each other does not change when both units make the same progress in terms of publications and citations. The normalization mechanism of the crown indicator does not have this important property.</p>
      <p>At CWTS, we are currently exploring a new crown indicator, in which we use the alternative normalization mechanism. In this paper, we perform an empirical comparison between on the one hand the normalization mechanism of our current crown indicator and on the other hand the alternative normalization mechanism of the new crown indicator that we are exploring. The comparison that we perform provides a detailed empirical illustration of various issues discussed in the indicator debate initiated by Opthof and Leydesdorff (<xref ref-type="bibr" rid="CR17">2010</xref>). Our focus in this paper is on the problem of correcting for the field and the year in which a publication was published. We do not consider the problem of correcting for a publication&#x2019;s document type. We study four aggregation levels at which bibliometric indicators can be calculated, namely the level of research groups, the level of research institutions, the level of countries, and the level of journals. We pay special attention to the way in which recent publications are handled when the alternative normalization mechanism is used. Finally, we want to emphasize that this is an empirical paper. It is not our aim to argue on theoretical grounds in favor of one of the two normalization mechanisms. For a theoretical discussion of the two normalization mechanisms, we refer to our earlier work (Waltman et al. <xref ref-type="bibr" rid="CR30">2011</xref>).</p>
    </sec>
    <sec id="Sec2">
      <title>Definitions of indicators</title>
      <p>In this section, we formally define the CPP/FCSm indicator and the MNCS indicator. The CPP/FCSm indicator, where CPP and FCSm are acronyms for, respectively, citations per publication and mean field citation score, has been used as the so-called crown indicator of CWTS for more than a decade. The MNCS indicator, where MNCS is an acronym for mean normalized citation score, is the new crown indicator that CWTS is currently exploring.</p>
      <p>Consider a set of <italic>n</italic> publications, denoted by 1 &#x2026;, <italic>n</italic>. Let <italic>c</italic><sub><italic>i</italic></sub> denote the number of citations of publication <italic>i</italic>, and let <italic>e</italic><sub><italic>i</italic></sub> denote the expected number of citations of publication <italic>i</italic> given the field and the year in which publication <italic>i</italic> was published. In other words, <italic>e</italic><sub><italic>i</italic></sub> equals the average number of citations of all publications published in the same field and in the same year as publication <italic>i</italic>. The field in which a publication was published can be defined in many different ways. At CWTS, we normally define fields based on subject categories in the Web of Science database. The CPP/FCSm indicator is defined as<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\text{CPP/FCSm}} = {\frac{{{{\sum\nolimits_{i = 1}^{n} {c_{i} } } \mathord{\left/ {\vphantom {{\sum\nolimits_{i = 1}^{n} {c_{i} } } n}} \right. \kern-\nulldelimiterspace} n}}}{{{{\sum\nolimits_{i = 1}^{n} {e_{i} } } \mathord{\left/ {\vphantom {{\sum\nolimits_{i = 1}^{n} {e_{i} } } n}} \right. \kern-\nulldelimiterspace} n}}}} = {\frac{{\sum\nolimits_{i = 1}^{n} {c_{i} } }}{{\sum\nolimits_{i = 1}^{n} {e_{i} } }}} .$$\end{document}</tex-math><graphic xlink:href="11192_2011_354_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>The CPP/FCSm indicator was introduced by De Bruin et al. (<xref ref-type="bibr" rid="CR6">1993</xref>) and Moed et al. (<xref ref-type="bibr" rid="CR16">1995</xref>). A similar indicator, the normalized mean citation rate, was introduced somewhat earlier by Braun and Gl&#xE4;nzel (<xref ref-type="bibr" rid="CR3">1990</xref>).<xref ref-type="fn" rid="Fn2">2</xref> The normalization mechanism of the CPP/FCSm indicator goes back to Schubert and Braun (<xref ref-type="bibr" rid="CR20">1986</xref>) and Vinkler (<xref ref-type="bibr" rid="CR27">1986</xref>). Schubert and Braun employed the mechanism for normalization at the level of journals, while Vinkler employed it for normalization at the level of fields. For a discussion of the conceptual foundation of the CPP/FCSm indicator, we refer to Moed (<xref ref-type="bibr" rid="CR15">2010</xref>).</p>
      <p>We now turn to the MNCS indicator (Waltman et al. <xref ref-type="bibr" rid="CR30">2011</xref>). This indicator is defined as<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M2">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\text{MNCS}} = \frac{1}{n}\sum\limits_{i = 1}^{n} {{\frac{{c_{i} }}{{e_{i} }}}} .$$\end{document}</tex-math><graphic xlink:href="11192_2011_354_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>The MNCS indicator is similar to the item-oriented field-normalized citation score average indicator introduced by Lundberg (<xref ref-type="bibr" rid="CR14">2007</xref>). The normalization mechanism of the MNCS indicator is also applied in the relative paper citation rate indicator discussed by Vinkler (<xref ref-type="bibr" rid="CR28">1996</xref>). The difference between the indicators of Lundberg and Vinkler is that Lundberg&#x2019;s indicator normalizes at the level of fields while Vinkler&#x2019;s indicator normalizes at the level of journals.<xref ref-type="fn" rid="Fn3">3</xref> Comparing Eqs.&#xA0;<xref rid="Equ1" ref-type="">1</xref> and <xref rid="Equ2" ref-type="">2</xref>, it can be seen that the CPP/FCSm indicator normalizes by calculating a ratio of averages while the MNCS indicator normalizes by calculating an average of ratios.<xref ref-type="fn" rid="Fn4">4</xref></p>
      <p>There is an interesting relation between the CPP/FCSm indicator and the MNCS indicator. It turns out that the CPP/FCSm indicator is a kind of weighted version of the MNCS indicator (Waltman et al. <xref ref-type="bibr" rid="CR30">2011</xref>). This can be seen by rewriting Eq.&#xA0;<xref rid="Equ1" ref-type="">1</xref> as<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\text{CPP/FCSm}} = \frac{1}{n}\sum\limits_{i = 1}^{n} {w_{i} {\frac{{c_{i} }}{{e_{i} }}}} $$\end{document}</tex-math><graphic xlink:href="11192_2011_354_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <italic>w</italic><sub><italic>i</italic></sub> is given by<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M4">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ w_{i} = {\frac{{e_{i} }}{{{{\sum\nolimits_{j = 1}^{n} {e_{j} } } \mathord{\left/ {\vphantom {{\sum\nolimits_{j = 1}^{n} {e_{j} } } n}} \right. \kern-\nulldelimiterspace} n}}}} .$$\end{document}</tex-math><graphic xlink:href="11192_2011_354_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>It follows from Eqs.&#xA0;<xref rid="Equ3" ref-type="">3</xref> and <xref rid="Equ4" ref-type="">4</xref> that, like the MNCS indicator, the CPP/FCSm indicator can be written as an average of ratios. However, unlike the MNCS indicator, the CPP/FCSm indicator does not weigh all ratios equally. Instead, it gives more weight to ratios corresponding with publications that have a higher expected number of citations. In other words, publications from fields with a high average number of citations per publication have more weight in the calculation of the CPP/FCSm indicator than publications from fields with a low average number of citations per publication. Similarly, older publications have more weight in the calculation of the CPP/FCSm indicator than more recent publications.</p>
    </sec>
    <sec id="Sec3">
      <title>How to handle recent publications?</title>
      <p>We now consider in more detail the way in which recent publications are handled in our indicators of interest. As indicated by Eqs.&#xA0;<xref rid="Equ3" ref-type="">3</xref> and <xref rid="Equ4" ref-type="">4</xref>, the CPP/FCSm indicator weighs publications proportionally to their expected number of citations. Recent publications tend to have a low expected number of citations, and their effect in the calculation of the CPP/FCSm indicator therefore tends to be small. This is different in the case of the MNCS indicator. Unlike the CPP/FCSm indicator, the MNCS indicator weighs all publications equally. Because of this, recent publications have an equally strong effect in the calculation of the MNCS indicator as older publications.</p>
      <p>Weighing all publications equally seems very natural and has theoretical advantages (Waltman et al. <xref ref-type="bibr" rid="CR30">2011</xref>). However, it also has a disadvantage. Recent publications have not had much time to earn citations, and their current number of citations therefore need not be a very accurate indicator of their long-run impact. To illustrate this issue, we look at some empirical data.</p>
      <p>Our analysis is based on the Web of Science database. We selected seven subject categories in this database. We interpret these subject categories as scientific fields. The selected subject categories are listed in the first column of Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref>. For each of the selected subject categories, we identified all publications of the document types article and review published in 1999 in journals belonging to the subject category. For each of the identified publications, we counted the number of times the publication had been cited by the end of each year between 1999 and 2008. Author self-citations are not included in our citation counts. For each subject category, the number of identified publications is listed in the second column of Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref>. Average citation counts of the identified publications are reported in the remaining columns of the table.<table-wrap id="Tab1"><label>Table&#xA0;1</label><caption><p>Average citation counts of publications published in 1999 in seven subject categories</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"/><th align="left" rowspan="2">No of pub.</th><th align="left" colspan="10">Average number of citations per publication by the end of</th></tr><tr><th align="left">1999</th><th align="left">2000</th><th align="left">2001</th><th align="left">2002</th><th align="left">2003</th><th align="left">2004</th><th align="left">2005</th><th align="left">2006</th><th align="left">2007</th><th align="left">2008</th></tr></thead><tbody><tr><td align="left"><italic>Biochemistry &amp; molecular biology</italic></td><td align="left">45,721</td><td char="." align="char">0.5</td><td char="." align="char">3.4</td><td char="." align="char">7.3</td><td char="." align="char">11.0</td><td char="." align="char">14.5</td><td char="." align="char">17.9</td><td char="." align="char">20.9</td><td char="." align="char">23.8</td><td char="." align="char">26.4</td><td char="." align="char">28.9</td></tr><tr><td align="left"><italic>Cardiac &amp; cardiovascular systems</italic></td><td align="left">11,332</td><td char="." align="char">0.3</td><td char="." align="char">2.0</td><td char="." align="char">4.7</td><td char="." align="char">7.4</td><td char="." align="char">10.0</td><td char="." align="char">12.6</td><td char="." align="char">14.9</td><td char="." align="char">17.0</td><td char="." align="char">19.1</td><td char="." align="char">20.9</td></tr><tr><td align="left"><italic>Chemistry, analytical</italic></td><td align="left">13,887</td><td char="." align="char">0.1</td><td char="." align="char">1.1</td><td char="." align="char">2.5</td><td char="." align="char">4.0</td><td char="." align="char">5.5</td><td char="." align="char">7.0</td><td char="." align="char">8.5</td><td char="." align="char">10.0</td><td char="." align="char">11.4</td><td char="." align="char">12.7</td></tr><tr><td align="left"><italic>Economics</italic></td><td align="left">7,346</td><td char="." align="char">0.1</td><td char="." align="char">0.5</td><td char="." align="char">1.2</td><td char="." align="char">2.0</td><td char="." align="char">3.0</td><td char="." align="char">4.1</td><td char="." align="char">5.3</td><td char="." align="char">6.5</td><td char="." align="char">7.9</td><td char="." align="char">9.4</td></tr><tr><td align="left"><italic>Mathematics</italic></td><td align="left">12,450</td><td char="." align="char">0.0</td><td char="." align="char">0.2</td><td char="." align="char">0.5</td><td char="." align="char">0.8</td><td char="." align="char">1.2</td><td char="." align="char">1.6</td><td char="." align="char">2.1</td><td char="." align="char">2.5</td><td char="." align="char">2.9</td><td char="." align="char">3.4</td></tr><tr><td align="left"><italic>Physics, applied</italic></td><td align="left">24,675</td><td char="." align="char">0.1</td><td char="." align="char">0.7</td><td char="." align="char">1.7</td><td char="." align="char">2.8</td><td char="." align="char">3.9</td><td char="." align="char">4.9</td><td char="." align="char">6.0</td><td char="." align="char">7.0</td><td char="." align="char">8.0</td><td char="." align="char">8.8</td></tr><tr><td align="left"><italic>Surgery</italic></td><td align="left">22,230</td><td char="." align="char">0.1</td><td char="." align="char">0.9</td><td char="." align="char">2.4</td><td char="." align="char">3.9</td><td char="." align="char">5.4</td><td char="." align="char">6.9</td><td char="." align="char">8.3</td><td char="." align="char">9.6</td><td char="." align="char">11.0</td><td char="." align="char">12.3</td></tr></tbody></table></table-wrap></p>
      <p>The citation counts in Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref> show large differences among fields. <italic>Biochemistry &amp; molecular biology</italic> has the highest citation counts, and <italic>Mathematics</italic> has the lowest. The difference is roughly one order of magnitude. This difference clearly indicates the importance of correcting for the field in which a publication was published. It can further be seen in Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref> that during the first 10&#xA0;years after a publication was published citation counts on average increase approximately linearly with time.</p>
      <p>As shown in the third column of Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref>, publications receive almost no citations in the year in which they were published. This is not surprising. Citing publications need to be written, reviewed, revised, and copyedited, which even under the most favorable conditions takes at least several months. In addition, some journals have a substantial backlog of manuscripts waiting to be published. This also delays the citation process. For these reasons, it is unlikely that publications receive more than a few citations in the year in which they were published.<xref ref-type="fn" rid="Fn5">5</xref> This is especially true for publications published towards the end of the year. Notice in Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref> that in some fields, in particular in <italic>Mathematics</italic>, publications are unlikely to be cited not only in the year in which they were published but also in the next year.</p>
      <p>How well does the number of citations of a publication 1 or 2&#xA0;years after the publication appeared predict the number of citations of the publication in the medium or long-run, say, after 5 or 10&#xA0;years? In Table&#xA0;<xref rid="Tab2" ref-type="table">2</xref>, we report for any 2&#xA0;years <italic>y</italic><sub>1</sub> and <italic>y</italic><sub>2</sub>, with <italic>y</italic><sub>1</sub> and <italic>y</italic><sub>2</sub> between 1999 and 2008, the Pearson correlation between the number of citations a publication has received by the end of year <italic>y</italic><sub>1</sub> and the number of citations a publication has received by the end of year <italic>y</italic><sub>2</sub>. The correlations in the upper right part of the table were calculated for publications published in 1999 in the subject category <italic>Biochemistry &amp; molecular biology</italic>. The correlations in the lower left part of the table were calculated for publications published in 1999 in the subject category <italic>Mathematics</italic>.<table-wrap id="Tab2"><label>Table&#xA0;2</label><caption><p>Pearson correlations between the number of citations a publication has received by the end of one&#xA0;year and the number of citations a publication has received by the end of another year</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">1999</th><th align="left">2000</th><th align="left">2001</th><th align="left">2002</th><th align="left">2003</th><th align="left">2004</th><th align="left">2005</th><th align="left">2006</th><th align="left">2007</th><th align="left">2008</th></tr></thead><tbody><tr><td align="left">1999</td><td align="left"/><td char="." align="char">0.83</td><td char="." align="char">0.74</td><td char="." align="char">0.68</td><td char="." align="char">0.65</td><td char="." align="char">0.62</td><td char="." align="char">0.60</td><td char="." align="char">0.58</td><td char="." align="char">0.56</td><td char="." align="char">0.55</td></tr><tr><td align="left">2000</td><td char="." align="char">0.56</td><td align="left"/><td char="." align="char">0.96</td><td char="." align="char">0.93</td><td char="." align="char">0.90</td><td char="." align="char">0.87</td><td char="." align="char">0.85</td><td char="." align="char">0.83</td><td char="." align="char">0.81</td><td char="." align="char">0.79</td></tr><tr><td align="left">2001</td><td char="." align="char">0.43</td><td char="." align="char">0.82</td><td align="left"/><td char="." align="char">0.99</td><td char="." align="char">0.97</td><td char="." align="char">0.95</td><td char="." align="char">0.93</td><td char="." align="char">0.92</td><td char="." align="char">0.90</td><td char="." align="char">0.88</td></tr><tr><td align="left">2002</td><td char="." align="char">0.37</td><td char="." align="char">0.74</td><td char="." align="char">0.92</td><td align="left"/><td char="." align="char">0.99</td><td char="." align="char">0.98</td><td char="." align="char">0.97</td><td char="." align="char">0.96</td><td char="." align="char">0.94</td><td char="." align="char">0.93</td></tr><tr><td align="left">2003</td><td char="." align="char">0.33</td><td char="." align="char">0.70</td><td char="." align="char">0.87</td><td char="." align="char">0.96</td><td align="left"/><td char="." align="char">1.00</td><td char="." align="char">0.99</td><td char="." align="char">0.98</td><td char="." align="char">0.97</td><td char="." align="char">0.95</td></tr><tr><td align="left">2004</td><td char="." align="char">0.31</td><td char="." align="char">0.67</td><td char="." align="char">0.83</td><td char="." align="char">0.92</td><td char="." align="char">0.97</td><td align="left"/><td char="." align="char">1.00</td><td char="." align="char">0.99</td><td char="." align="char">0.98</td><td char="." align="char">0.97</td></tr><tr><td align="left">2005</td><td char="." align="char">0.29</td><td char="." align="char">0.64</td><td char="." align="char">0.80</td><td char="." align="char">0.89</td><td char="." align="char">0.95</td><td char="." align="char">0.98</td><td align="left"/><td char="." align="char">1.00</td><td char="." align="char">0.99</td><td char="." align="char">0.99</td></tr><tr><td align="left">2006</td><td char="." align="char">0.28</td><td char="." align="char">0.62</td><td char="." align="char">0.78</td><td char="." align="char">0.87</td><td char="." align="char">0.93</td><td char="." align="char">0.97</td><td char="." align="char">0.99</td><td align="left"/><td char="." align="char">1.00</td><td char="." align="char">0.99</td></tr><tr><td align="left">2007</td><td char="." align="char">0.26</td><td char="." align="char">0.60</td><td char="." align="char">0.75</td><td char="." align="char">0.85</td><td char="." align="char">0.91</td><td char="." align="char">0.95</td><td char="." align="char">0.98</td><td char="." align="char">0.99</td><td align="left"/><td char="." align="char">1.00</td></tr><tr><td align="left">2008</td><td char="." align="char">0.25</td><td char="." align="char">0.59</td><td char="." align="char">0.74</td><td char="." align="char">0.83</td><td char="." align="char">0.89</td><td char="." align="char">0.93</td><td char="." align="char">0.96</td><td char="." align="char">0.98</td><td char="." align="char">0.99</td><td align="left"/></tr></tbody></table><table-wrap-foot><p>The upper right part and the lower left part of the table relate to publications published in 1999 in, respectively, the subject category <italic>Biochemistry &amp; molecular biology</italic> and the subject category <italic>Mathematics</italic></p></table-wrap-foot></table-wrap></p>
      <p>As can be seen in Table&#xA0;<xref rid="Tab2" ref-type="table">2</xref>, correlations between short-run citation counts and long-run citation counts can be quite weak. In the case of publications in <italic>Mathematics</italic> published in 1999, the correlation between the number of citations received by the end of 1999 and the number of citations received by the end of 2008 equals just 0.25. The correlation between the number of citations received by the end of 2000 and the number of citations received by the end of 2008 equals 0.59, which is still only a very moderate correlation. Of the seven subject categories that we have selected, <italic>Biochemistry &amp; molecular biology</italic> has the strongest correlations between short-run citation counts and long-run citation counts. This is to be expected, since <italic>Biochemistry &amp; molecular biology</italic> also has the highest citation counts. However, even in the case of publications in <italic>Biochemistry &amp; molecular biology</italic>, the correlation between the number of citations received by the end of 1999 and the number of citations received by the end of 2008 is rather moderate, with a value of 0.55.</p>
      <p>Based on Tables&#xA0;<xref rid="Tab1" ref-type="table">1</xref> and <xref rid="Tab2" ref-type="table">2</xref>, we conclude that in the calculation of the MNCS indicator recent publications need special attention. These publications have low citation counts (Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref>), and because of this their long-run impact cannot be predicted very well (Table&#xA0;<xref rid="Tab2" ref-type="table">2</xref>). This is not a big problem in the case of the CPP/FCSm indicator, since this indicator gives less weight to recent publications than to older ones. The MNCS indicator, however, weighs all publications equally, and recent publications may then introduce a quite significant amount of noise in the indicator. Especially when the MNCS indicator is calculated at lower aggregation levels (e.g., at the level of research groups or individual researchers), where only a limited number of publications are available, this can be a serious problem. To alleviate this problem, one may consider leaving out the most recent publications in the calculation of the MNCS indicator. For example, all publications that have had less than 1&#xA0;year to earn citations could be left out. In this way, one loses some relevant information, but one also gets rid of a lot of noise.</p>
    </sec>
    <sec id="Sec4">
      <title>Empirical comparison</title>
      <p>In this section, we present an empirical comparison between the CPP/FCSm indicator and the MNCS indicator. We distinguish between two variants of the MNCS indicator. In one variant, referred to as the MNCS1 indicator, all publications are taken into consideration. In the other variant, referred to as the MNCS2 indicator, publications that have had less than 1&#xA0;year to earn citations are left out.</p>
      <p>We study four aggregation levels at which bibliometric indicators can be calculated, namely the level of research groups, the level of research institutions, the level of countries, and the level of journals. We do not consider the level of individual researchers. An analysis at this level can be found elsewhere (Van Raan et al. <xref ref-type="bibr" rid="CR25">2010</xref>). We use the following four data sets:<list list-type="bullet"><list-item><p><italic>Research groups</italic>. Chemistry and chemical engineering research groups in the Netherlands. This data set has been employed in a performance evaluation study for the Association of Universities in the Netherlands (VSNU <xref ref-type="bibr" rid="CR29">2002</xref>).</p></list-item><list-item><p><italic>Research institutions</italic>. The 365 universities with the largest number of publications in the Web of Science database.</p></list-item><list-item><p><italic>Countries</italic>. The 58 countries with the largest number of publications in the Web of Science database.</p></list-item><list-item><p><italic>Journals</italic>. All journals in the Web of Science database except arts and humanities journals.</p></list-item></list>
The main characteristics of the data sets are listed in Table&#xA0;<xref rid="Tab3" ref-type="table">3</xref>.<table-wrap id="Tab3"><label>Table&#xA0;3</label><caption><p>Characteristics of the data sets used to compare the CPP/FCSm indicator and the MNCS indicator</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Research groups</th><th align="left">Research institutions</th><th align="left">Countries</th><th align="left">Journals</th></tr></thead><tbody><tr><td align="left"><italic>N</italic></td><td align="left">158</td><td align="left">365</td><td align="left">58</td><td align="left">8,423</td></tr><tr><td align="left">Time period</td><td align="left">1991&#x2013;2000</td><td align="left">2001&#x2013;2008</td><td align="left">2001&#x2013;2008</td><td align="left">2005&#x2013;2008</td></tr><tr><td align="left">Average no. of pub.</td><td align="left">131</td><td align="left">15,069</td><td align="left">154,512</td><td align="left">475</td></tr><tr><td align="left">Median no. of pub.</td><td align="left">103</td><td align="left">12,409</td><td align="left">47,506</td><td align="left">233</td></tr><tr><td align="left">St. dev. no. of pub.</td><td align="left">103</td><td align="left">9,149</td><td align="left">325,787</td><td align="left">1,027</td></tr></tbody></table></table-wrap></p>
      <p>The comparison between the CPP/FCSm indicator and the MNCS indicator was performed as follows. For each research group, research institution, country, or journal, we retrieved from the Web of Science database all publications of the document types article, note, and review published in the relevant time period specified in Table&#xA0;<xref rid="Tab3" ref-type="table">3</xref>.<xref ref-type="fn" rid="Fn6">6</xref> Publications in the arts and humanities were left out of the analysis. This was done because these publications tend to have very low citation counts, which makes the use of citation-based performance indicators problematic. We counted citations until the end of the relevant time period.<xref ref-type="fn" rid="Fn7">7</xref> Author self-citations were ignored. In the calculation of the indicators, we normalized for the field and the year in which a publication was published. We did not normalize for a publication&#x2019;s document type. Fields were defined by Web of Science subject categories. As mentioned earlier, in the MNCS2 indicator, publications that have had less than 1&#xA0;year to earn citations are left out. In the other two indicators, all publications are taken into consideration.</p>
      <p>For each of the four data sets that we use, Pearson and Spearman correlations between the CPP/FCSm indicator, the MNCS1 indicator, and the MNCS2 indicator are reported in Table&#xA0;<xref rid="Tab4" ref-type="table">4</xref>. The Pearson correlation measures to what degree two indicators are linearly related. The Spearman correlation, on the other hand, measures to what degree two indicators are monotonically related (i.e., to what degree two indicators yield the same ranking of items). Scatter plots of the relations between the indicators are shown in Figs.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>, <xref rid="Fig2" ref-type="fig">2</xref>, <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="Fig4" ref-type="fig">4</xref> and <xref rid="Fig5" ref-type="fig">5</xref>. Items with no more than 50 publications (excluding publications that have had less than 1&#xA0;year to earn citations) are indicated by red squares in the scatter plots. Items with more than 50 publications are indicated by blue circles. In each scatter plot, a 45&#xB0; line through the origin has been drawn. The closer items are located to this line, the stronger the relation between two indicators.<table-wrap id="Tab4"><label>Table&#xA0;4</label><caption><p>Pearson and Spearman correlations between the CPP/FCSm indicator, the MNCS1 indicator, and the MNCS2 indicator</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Research groups</th><th align="left">Research institutions</th><th align="left">Countries</th><th align="left">Journals</th></tr></thead><tbody><tr><td align="left">CPP/FCSm vs. MNCS1 (Pearson)</td><td char="." align="char">0.85</td><td char="." align="char">0.98</td><td char="." align="char">0.99</td><td char="." align="char">0.94</td></tr><tr><td align="left">CPP/FCSm vs. MNCS1 (Spearman)</td><td char="." align="char">0.89</td><td char="." align="char">0.98</td><td char="." align="char">0.99</td><td char="." align="char">0.95</td></tr><tr><td align="left">CPP/FCSm vs. MNCS2 (Pearson)</td><td char="." align="char">0.91</td><td char="." align="char">0.99</td><td char="." align="char">0.99</td><td char="." align="char">0.96</td></tr><tr><td align="left">CPP/FCSm vs. MNCS2 (Spearman)</td><td char="." align="char">0.95</td><td char="." align="char">0.99</td><td char="." align="char">0.99</td><td char="." align="char">0.98</td></tr><tr><td align="left">MNCS1 vs. MNCS2 (Pearson)</td><td char="." align="char">0.95</td><td char="." align="char">0.99</td><td char="." align="char">1.00</td><td char="." align="char">0.91</td></tr><tr><td align="left">MNCS1 vs. MNCS2 (Spearman)</td><td char="." align="char">0.95</td><td char="." align="char">0.99</td><td char="." align="char">1.00</td><td char="." align="char">0.96</td></tr></tbody></table></table-wrap><fig id="Fig1"><label>Fig.&#xA0;1</label><caption><p>Relation between the CPP/FCSm indicator and the MNCS1 and MNCS2 indicators for the research groups data set</p></caption><graphic xlink:href="11192_2011_354_Fig1_HTML" id="MO5"/></fig><fig id="Fig2"><label>Fig.&#xA0;2</label><caption><p>Relation between the CPP/FCSm indicator and the MNCS1 and MNCS2 indicators for the research institutions data set</p></caption><graphic xlink:href="11192_2011_354_Fig2_HTML" id="MO6"/></fig><fig id="Fig3"><label>Fig.&#xA0;3</label><caption><p>Relation between the CPP/FCSm indicator and the MNCS1 and MNCS2 indicators for the countries data set</p></caption><graphic xlink:href="11192_2011_354_Fig3_HTML" id="MO7"/></fig><fig id="Fig4"><label>Fig.&#xA0;4</label><caption><p>Relation between the CPP/FCSm indicator and the MNCS1 and MNCS2 indicators for the journals data set</p></caption><graphic xlink:href="11192_2011_354_Fig4_HTML" id="MO8"/></fig><fig id="Fig5"><label>Fig.&#xA0;5</label><caption><p>Relation between the CPP/FCSm indicator and the MNCS1 and MNCS2 indicators for the journals data set. Only journals with a CPP/FCSm score and an MNCS1 or MNCS2 score below 2.5 are shown</p></caption><graphic xlink:href="11192_2011_354_Fig5_HTML" id="MO9"/></fig></p>
      <p>We first consider the research groups data set. For this data set, we observe a moderately strong relation between the CPP/FCSm indicator and the MNCS1 indicator (see Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>, left panel). For most research groups, the difference between the CPP/FCSm score and the MNCS1 score is not very large. However, there are a number of research groups for which the MNCS1 score is much higher or much lower than the CPP/FCSm score. The relation between the CPP/FCSm indicator and the MNCS2 indicator is considerably stronger (see Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>, right panel). There are only a small number of research groups for which the CPP/FCSm score and the MNCS2 score really differ significantly from each other.</p>
      <p>The three research groups for which the difference between the CPP/FCSm score and the MNCS2 score is largest have been marked with the letters A, B, and C in the right panel of Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>. Let us consider these research groups in more detail. Research group A has only 15 publications. For each of these publications, we report in Table&#xA0;<xref rid="Tab5" ref-type="table">5</xref> the publication year, the number of citations, the expected number of citations,<xref ref-type="fn" rid="Fn8">8</xref> and the normalized citation score. The normalized citation score of a publication is defined as the ratio of the actual and the expected number of citations of the publication. Why is the CPP/FCSm score of research group A so much lower than the MNCS2 score of this research group? As can be seen in Table&#xA0;<xref rid="Tab5" ref-type="table">5</xref>, the three publications of research group A with the highest normalized citation score were all published in 1999, which is second-last year of the analysis. These publications have a large effect on the MNCS2 score of research group A.<xref ref-type="fn" rid="Fn9">9</xref> Their effect on the CPP/FCSm score of research group A is much smaller. This is because, as discussed earlier, recent publications have less weight in the CPP/FCSm indicator than in the MNCS2 indicator. This explains why the CPP/FCSm score of research group A is much lower than the MNCS2 score. Research groups B and C have more publications than research group A (respectively 42 and 165), but the explanation for the difference between the CPP/FCSm score and the MNCS2 score is similar. Like research group A, research group B has a number of recent publications with a high normalized citation score. Because of this, the MNCS2 score of research group B is much higher than the CPP/FCSm score. Research group C has two very highly cited publications in 1991, the first year of the analysis. These publications have more weight in the CPP/FCSm indicator than in the MNCS2 indicator, which explains the difference between the CPP/FCSm score and the MNCS2 score of research group C.<table-wrap id="Tab5"><label>Table&#xA0;5</label><caption><p>Publication year, number of citations, expected number of citations, and normalized citation score of the publications of research group A</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Pub. year</th><th align="left">No of cit.</th><th align="left">Exp. no of cit.</th><th align="left">Norm. cit. score</th></tr></thead><tbody><tr><td align="left">1994</td><td char="." align="char">6</td><td char="." align="char">6.97</td><td char="." align="char">0.86</td></tr><tr><td align="left">1994</td><td char="." align="char">3</td><td char="." align="char">6.97</td><td char="." align="char">0.43</td></tr><tr><td align="left">1995</td><td char="." align="char">0</td><td char="." align="char">7.39</td><td char="." align="char">0.00</td></tr><tr><td align="left">1995</td><td char="." align="char">2</td><td char="." align="char">2.54</td><td char="." align="char">0.79</td></tr><tr><td align="left">1995</td><td char="." align="char">5</td><td char="." align="char">7.39</td><td char="." align="char">0.68</td></tr><tr><td align="left">1997</td><td char="." align="char">21</td><td char="." align="char">3.57</td><td char="." align="char">5.89</td></tr><tr><td align="left">1997</td><td char="." align="char">1</td><td char="." align="char">4.42</td><td char="." align="char">0.23</td></tr><tr><td align="left">1998</td><td char="." align="char">6</td><td char="." align="char">2.48</td><td char="." align="char">2.42</td></tr><tr><td align="left">1998</td><td char="." align="char">6</td><td char="." align="char">2.48</td><td char="." align="char">2.42</td></tr><tr><td align="left">1998</td><td char="." align="char">3</td><td char="." align="char">2.17</td><td char="." align="char">1.38</td></tr><tr><td align="left">1999</td><td char="." align="char">16</td><td char="." align="char">1.52</td><td char="." align="char">10.55</td></tr><tr><td align="left">1999</td><td char="." align="char">13</td><td char="." align="char">1.52</td><td char="." align="char">8.57</td></tr><tr><td align="left">1999</td><td char="." align="char">5</td><td char="." align="char">0.45</td><td char="." align="char">11.03</td></tr><tr><td align="left">1999</td><td char="." align="char">1</td><td char="." align="char">1.09</td><td char="." align="char">0.91</td></tr><tr><td align="left">2000</td><td char="." align="char">0</td><td char="." align="char">0.21</td><td char="." align="char">0.00</td></tr></tbody></table></table-wrap></p>
      <p>We now turn to the research institutions data set. For this data set, we observe a very strong relation between on the one hand the CPP/FCSm indicator and on the other hand the MNCS1 indicator and the MNCS2 indicator (see Fig.&#xA0;<xref rid="Fig2" ref-type="fig">2</xref>). The relation is approximately equally strong for both MNCS variants. As can be seen in the left panel of Fig.&#xA0;<xref rid="Fig2" ref-type="fig">2</xref>, there is one university for which the MNCS1 score (1.66) is much higher than the CPP/FCSm score (1.06). It turns out that in 2008 this university, the University of G&#xF6;ttingen, published an article that by the end of 2008 had already been cited 3489 times.<xref ref-type="fn" rid="Fn10">10</xref> Since this is a very recent article, it has much more weight in the MNCS1 indicator than in the CPP/FCSm indicator. This explains the very different CPP/FCSm and MNCS1 scores of the university. Notice that in the MNCS2 indicator articles published in 2008 are not taken into consideration. Because of this, there is no substantial difference between the CPP/FCSm score (1.06) and the MNCS2 score (1.10) of the university.</p>
      <p>The results obtained for the countries data set are similar to those obtained for the research institutions data set. We again observe a very strong relation between the CPP/FCSm indicator and the two MNCS variants (see Fig.&#xA0;<xref rid="Fig3" ref-type="fig">3</xref>), and again the relation is approximately equally strong for both MNCS variants. A striking observation is that there are almost no countries for which the MNCS1 and MNCS2 scores are lower than the CPP/FCSm score. We currently do not have an explanation for this observation. In Table&#xA0;<xref rid="Tab6" ref-type="table">6</xref>, we list the ten highest-ranked countries according to each of the three indicators that we study. As can be seen, the three indicators yield very similar results.<table-wrap id="Tab6"><label>Table&#xA0;6</label><caption><p>The ten highest-ranked countries according to the CPP/FCSm indicator, the MNCS1 indicator, and the MNCS2 indicator</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Rank</th><th align="left">Country</th><th align="left">CPP/FCSm</th><th align="left">Country</th><th align="left">MNCS1</th><th align="left">Country</th><th align="left">MNCS2</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">Switzerland</td><td char="." align="char">1.43</td><td align="left">Switzerland</td><td char="." align="char">1.47</td><td align="left">Switzerland</td><td char="." align="char">1.45</td></tr><tr><td align="left">2</td><td align="left">USA</td><td char="." align="char">1.38</td><td align="left">USA</td><td char="." align="char">1.39</td><td align="left">USA</td><td char="." align="char">1.38</td></tr><tr><td align="left">3</td><td align="left">Netherlands</td><td char="." align="char">1.34</td><td align="left">Denmark</td><td char="." align="char">1.37</td><td align="left">Netherlands</td><td char="." align="char">1.36</td></tr><tr><td align="left">4</td><td align="left">Denmark</td><td char="." align="char">1.31</td><td align="left">Netherlands</td><td char="." align="char">1.37</td><td align="left">Denmark</td><td char="." align="char">1.34</td></tr><tr><td align="left">5</td><td align="left">UK</td><td char="." align="char">1.27</td><td align="left">UK</td><td char="." align="char">1.29</td><td align="left">UK</td><td char="." align="char">1.27</td></tr><tr><td align="left">6</td><td align="left">Ireland</td><td char="." align="char">1.23</td><td align="left">Sweden</td><td char="." align="char">1.24</td><td align="left">Sweden</td><td char="." align="char">1.23</td></tr><tr><td align="left">7</td><td align="left">Canada</td><td char="." align="char">1.22</td><td align="left">Belgium</td><td char="." align="char">1.22</td><td align="left">Belgium</td><td char="." align="char">1.21</td></tr><tr><td align="left">8</td><td align="left">Belgium</td><td char="." align="char">1.21</td><td align="left">Canada</td><td char="." align="char">1.21</td><td align="left">Canada</td><td char="." align="char">1.21</td></tr><tr><td align="left">9</td><td align="left">Sweden</td><td char="." align="char">1.20</td><td align="left">Ireland</td><td char="." align="char">1.20</td><td align="left">Ireland</td><td char="." align="char">1.21</td></tr><tr><td align="left">10</td><td align="left">Norway</td><td char="." align="char">1.18</td><td align="left">Norway</td><td char="." align="char">1.19</td><td align="left">Norway</td><td char="." align="char">1.20</td></tr></tbody></table></table-wrap></p>
      <p>Finally, we turn to the journals data set. For a large majority of the journals, we observe a strong relation between the CPP/FCSm indicator and the MNCS1 indicator (see the left panels of Figs.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>, <xref rid="Fig5" ref-type="fig">5</xref>).<xref ref-type="fn" rid="Fn11">11</xref> However, there are also a substantial number of journals for which the MNCS1 score is much higher or much lower than the CPP/FCSm score. Comparing the CPP/FCSm indicator with the MNCS2 indicator, we observe much less journals with largely different scores (see the right panels of Figs.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>, <xref rid="Fig5" ref-type="fig">5</xref>). Hence, the CPP/FCSm indicator has a considerably stronger relation with the MNCS2 indicator than with the MNCS1 indicator. This is similar to what we found for the research groups data set. Notice that even when CPP/FCSm scores are compared with MNCS2 scores, there are a number of journals for which rather large differences can be observed. However, given that overall we have more than 8,000 journals, these journals constitute a small minority of exceptional cases.<xref ref-type="fn" rid="Fn12">12</xref></p>
    </sec>
    <sec id="Sec5">
      <title>Conclusions</title>
      <p>We have presented an empirical comparison between two normalization mechanisms for citation-based indicators of research performance. One normalization mechanism is implemented in the CPP/FCSm indicator, which is the current so-called crown indicator of CWTS. The other normalization mechanism is implemented in the MNCS indicator, which is the new crown indicator that CWTS is currently exploring. The use of the latter normalization mechanism was advocated by Lundberg (<xref ref-type="bibr" rid="CR14">2007</xref>) and Opthof and Leydesdorff (<xref ref-type="bibr" rid="CR17">2010</xref>), and in a recent theoretical paper (Waltman et al. <xref ref-type="bibr" rid="CR30">2011</xref>) we have also argued in favor of this mechanism. Our empirical results indicate that at high aggregation levels, such as at the level of large research institutions or at the level of countries, the differences between the CPP/FCSm indicator and the MNCS indicator are very small. At lower aggregation levels, such as at the level of research groups or at the level of journals, the differences between the two indicators are somewhat larger. Hence, at lower aggregation levels, the choice between the two indicators is not only of theoretical interest but also has a significant practical relevance.</p>
      <p>We have also pointed out that recent publications need special attention in the calculation of the MNCS indicator. These publications have low citation counts, and because of this their long-run impact cannot be predicted very well. Since the MNCS indicator gives the same weight to recent publications as to older ones, recent publications may introduce a significant amount of noise in this indicator. To alleviate this problem, one may consider leaving out the most recent publications in the calculation of the indicator. In our empirical analysis, we have examined the effect of leaving out publications that have had less than 1&#xA0;year to earn citations. At lower aggregation levels, the effect turns out to be quite substantial. In particular, leaving out the most recent publications in the calculation of the MNCS indicator turns out to lead to a stronger relation between the CPP/FCSm indicator and the MNCS indicator. This suggests that differences between the CPP/FCSm indicator and the MNCS indicator may be partly due to noise introduced in the MNCS indicator by recent publications.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Open Access</title>
      <p>This article is distributed under the terms of the Creative Commons Attribution Noncommercial License which permits any noncommercial use, distribution, and reproduction in any medium, provided the original author(s) and source are credited.</p>
    </ack>
    <ref-list id="Bib1">
      <title>References</title>
      <ref id="CR1">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bornmann</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>Towards an ideal method of measuring research performance: Some comments to the Opthof and Leydesdorff (2010) paper</article-title>
          <source>Journal of Informetrics</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>3</issue>
          <fpage>441</fpage>
          <lpage>443</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.04.004</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR2">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bornmann</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Mutz</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Further steps towards an ideal method of measuring citation performance: The avoidance of citation (ratio) averages in field-normalization</article-title>
          <source>Journal of Informetrics</source>
          <year>2011</year>
          <volume>5</volume>
          <issue>1</issue>
          <fpage>228</fpage>
          <lpage>230</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.10.009</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR3">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Braun</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Gl&#xE4;nzel</surname>
              <given-names>W</given-names>
            </name>
          </person-group>
          <article-title>United Germany: The new scientific superpower?</article-title>
          <source>Scientometrics</source>
          <year>1990</year>
          <volume>19</volume>
          <issue>5&#x2013;6</issue>
          <fpage>513</fpage>
          <lpage>521</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02020712</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR4">
        <mixed-citation publication-type="other">Campbell, D., Archambault, E., C&#xF4;t&#xE9;, G. (2008). <italic>Benchmarking of Canadian Genomics</italic>&#x2014;<italic>1996</italic>&#x2013;<italic>2007</italic>. Retrieved Nov 5, 2010, from <ext-link ext-link-type="uri" xlink:href="http://www.science-metrix.com/pdf/SM_Benchmarking_Genomics_Canada.pdf">http://www.science-metrix.com/pdf/SM_Benchmarking_Genomics_Canada.pdf</ext-link>.</mixed-citation>
      </ref>
      <ref id="CR5">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Colliander</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Ahlgren</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>The effects and their stability of field normalization baseline on relative performance with respect to citation impact: A case study of 20 natural science departments</article-title>
          <source>Journal of Informetrics</source>
          <year>2011</year>
          <volume>5</volume>
          <issue>1</issue>
          <fpage>101</fpage>
          <lpage>113</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.09.003</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR6">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bruin</surname>
              <given-names>RE</given-names>
            </name>
            <name>
              <surname>Kint</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Luwel</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Moed</surname>
              <given-names>HF</given-names>
            </name>
          </person-group>
          <article-title>A study of research evaluation and planning: The University of Ghent</article-title>
          <source>Research Evaluation</source>
          <year>1993</year>
          <volume>3</volume>
          <issue>1</issue>
          <fpage>25</fpage>
          <lpage>41</lpage>
        </mixed-citation>
      </ref>
      <ref id="CR7">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dimitrov</surname>
              <given-names>JD</given-names>
            </name>
            <name>
              <surname>Kaveri</surname>
              <given-names>SV</given-names>
            </name>
            <name>
              <surname>Bayry</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Metrics: Journal&#x2019;s impact factor skewed by a single paper</article-title>
          <source>Nature</source>
          <year>2010</year>
          <volume>466</volume>
          <issue>7303</issue>
          <fpage>179</fpage>
          <pub-id pub-id-type="doi">10.1038/466179b</pub-id>
          <pub-id pub-id-type="pmid">20613817</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR8">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Egghe</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Rousseau</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Averaging and globalising quotients of informetric and scientometric data</article-title>
          <source>Journal of Information Science</source>
          <year>1996</year>
          <volume>22</volume>
          <issue>3</issue>
          <fpage>165</fpage>
          <lpage>170</lpage>
          <pub-id pub-id-type="doi">10.1177/016555159602200302</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR9">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Egghe</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Rousseau</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Average and global impact of a set of journals</article-title>
          <source>Scientometrics</source>
          <year>1996</year>
          <volume>36</volume>
          <issue>1</issue>
          <fpage>97</fpage>
          <lpage>107</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02126648</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR10">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gingras</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Larivi&#xE8;re</surname>
              <given-names>V</given-names>
            </name>
          </person-group>
          <article-title>There are neither &#x201C;king&#x201D; nor &#x201C;crown&#x201D; in scientometrics: Comments on a supposed &#x201C;alternative&#x201D; method of normalization</article-title>
          <source>Journal of Informetrics</source>
          <year>2011</year>
          <volume>5</volume>
          <issue>1</issue>
          <fpage>226</fpage>
          <lpage>227</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.10.005</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR11">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gl&#xE4;nzel</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Thijs</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Schubert</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Debackere</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Subfield-specific normalized relative indicators and a new generation of relational charts: methodological foundations illustrated on the assessment of institutional research performance</article-title>
          <source>Scientometrics</source>
          <year>2009</year>
          <volume>78</volume>
          <issue>1</issue>
          <fpage>165</fpage>
          <lpage>188</lpage>
          <pub-id pub-id-type="doi">10.1007/s11192-008-2109-5</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR12">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leydesdorff</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Opthof</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Normalization at the field level: Fractional counting of citations</article-title>
          <source>Journal of Informetrics</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>4</issue>
          <fpage>644</fpage>
          <lpage>646</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.05.003</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR13">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leydesdorff</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Opthof</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Remaining problems with the &#x201C;new crown indicator&#x201D; (MNCS) of the CWTS</article-title>
          <source>Journal of Informetrics</source>
          <year>2011</year>
          <volume>5</volume>
          <issue>1</issue>
          <fpage>224</fpage>
          <lpage>225</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.10.003</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundberg</surname><given-names>J</given-names></name></person-group><article-title>Lifting the crown&#x2014;citation <italic>z</italic>-score</article-title><source>Journal of Informetrics</source><year>2007</year><volume>1</volume><issue>2</issue><fpage>145</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.joi.2006.09.007</pub-id>2304574</mixed-citation>
      </ref>
      <ref id="CR15">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Moed</surname>
              <given-names>HF</given-names>
            </name>
          </person-group>
          <article-title>CWTS crown indicator measures citation impact of a research group&#x2019;s publication oeuvre</article-title>
          <source>Journal of Informetrics</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>3</issue>
          <fpage>436</fpage>
          <lpage>438</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.03.009</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR16">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Moed</surname>
              <given-names>HF</given-names>
            </name>
            <name>
              <surname>Bruin</surname>
              <given-names>RE</given-names>
            </name>
            <name>
              <surname>Leeuwen</surname>
              <given-names>TN</given-names>
            </name>
          </person-group>
          <article-title>New bibliometric tools for the assessment of national research performance: Database description, overview of indicators and first applications</article-title>
          <source>Scientometrics</source>
          <year>1995</year>
          <volume>33</volume>
          <issue>3</issue>
          <fpage>381</fpage>
          <lpage>422</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02017338</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR17">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Opthof</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Leydesdorff</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>Caveats for the journal and field normalizations in the CWTS (&#x201C;Leiden&#x201D;) evaluations of research performance</article-title>
          <source>Journal of Informetrics</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>3</issue>
          <fpage>423</fpage>
          <lpage>430</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.02.003</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR18">
        <mixed-citation publication-type="other">Rehn, C., &amp; Kronman, U. (2008). <italic>Bibliometric handbook for Karolinska Institutet</italic>. Retrieved Nov 5, 2010, from <ext-link ext-link-type="uri" xlink:href="http://ki.se/content/1/c6/01/79/31/bibliometric_handbook_karolinska_institutet_v_1.05.pdf">http://ki.se/content/1/c6/01/79/31/bibliometric_handbook_karolinska_institutet_v_1.05.pdf</ext-link>.</mixed-citation>
      </ref>
      <ref id="CR19">
        <mixed-citation publication-type="other">Sandstr&#xF6;m, U. (2009). <italic>Bibliometric evaluation of research programs: A study of scientific quality</italic>. Retrieved Nov 5, 2010, from <ext-link ext-link-type="uri" xlink:href="http://www.forskningspolitik.se/DataFile.asp?FileID=182">http://www.forskningspolitik.se/DataFile.asp?FileID=182</ext-link>.</mixed-citation>
      </ref>
      <ref id="CR20">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schubert</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Braun</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Relative indicators and relational charts for comparative assessment of publication output and citation impact</article-title>
          <source>Scientometrics</source>
          <year>1986</year>
          <volume>9</volume>
          <issue>5&#x2013;6</issue>
          <fpage>281</fpage>
          <lpage>291</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02017249</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR21">
        <mixed-citation publication-type="other">SCImago Research Group. (2009). <italic>SCImago Institutions Rankings (SIR): 2009 world report</italic>. Retrieved Nov 5, 2010, from <ext-link ext-link-type="uri" xlink:href="http://www.scimagoir.com/pdf/sir_2009_world_report.pdf">http://www.scimagoir.com/pdf/sir_2009_world_report.pdf</ext-link>.</mixed-citation>
      </ref>
      <ref id="CR22">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Spaan</surname>
              <given-names>JAE</given-names>
            </name>
          </person-group>
          <article-title>The danger of pseudoscience in Informetrics</article-title>
          <source>Journal of Informetrics</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>3</issue>
          <fpage>439</fpage>
          <lpage>440</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.03.010</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR23">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leeuwen</surname>
              <given-names>TN</given-names>
            </name>
            <name>
              <surname>Moed</surname>
              <given-names>HF</given-names>
            </name>
          </person-group>
          <article-title>Development and application of journal impact measures in the Dutch science system</article-title>
          <source>Scientometrics</source>
          <year>2002</year>
          <volume>53</volume>
          <issue>2</issue>
          <fpage>249</fpage>
          <lpage>266</lpage>
          <pub-id pub-id-type="doi">10.1023/A:1014808709694</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR24">
        <mixed-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Raan</surname>
              <given-names>AFJ</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Moed</surname>
              <given-names>HF</given-names>
            </name>
            <name>
              <surname>Gl&#xE4;nzel</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Schmoch</surname>
              <given-names>U</given-names>
            </name>
          </person-group>
          <article-title>Measuring science: Capita selecta of current main issues</article-title>
          <source>Handbook of quantitative science and technology research</source>
          <year>2005</year>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>Springer</publisher-name>
          <fpage>19</fpage>
          <lpage>50</lpage>
        </mixed-citation>
      </ref>
      <ref id="CR25">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Raan</surname>
              <given-names>AFJ</given-names>
            </name>
            <name>
              <surname>Leeuwen</surname>
              <given-names>TN</given-names>
            </name>
            <name>
              <surname>Visser</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Eck</surname>
              <given-names>NJ</given-names>
            </name>
            <name>
              <surname>Waltman</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>Rivals for the crown: Reply to Opthof and Leydesdorff</article-title>
          <source>Journal of Informetrics</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>3</issue>
          <fpage>431</fpage>
          <lpage>435</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.03.008</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR26">
        <mixed-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Veller</surname>
              <given-names>MGP</given-names>
            </name>
            <name>
              <surname>Gerritsma</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Togt</surname>
              <given-names>PL</given-names>
            </name>
            <name>
              <surname>Leon</surname>
              <given-names>CD</given-names>
            </name>
            <name>
              <surname>Zeist</surname>
              <given-names>CM</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Katsirikou</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Skiadas</surname>
              <given-names>CH</given-names>
            </name>
          </person-group>
          <article-title>Bibliometric analyses on repository contents for the evaluation of research at Wageningen UR</article-title>
          <source>Qualitative and quantitative methods in libraries: Theory and applications</source>
          <year>2009</year>
          <publisher-loc>Singapore</publisher-loc>
          <publisher-name>World Scientific</publisher-name>
          <fpage>19</fpage>
          <lpage>26</lpage>
        </mixed-citation>
      </ref>
      <ref id="CR27">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vinkler</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Evaluation of some methods for the relative assessment of scientific publications</article-title>
          <source>Scientometrics</source>
          <year>1986</year>
          <volume>10</volume>
          <issue>3&#x2013;4</issue>
          <fpage>157</fpage>
          <lpage>177</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02026039</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR28">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vinkler</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Model for quantitative selection of relative scientometric impact indicators</article-title>
          <source>Scientometrics</source>
          <year>1996</year>
          <volume>36</volume>
          <issue>2</issue>
          <fpage>223</fpage>
          <lpage>236</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02017315</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR29">
        <mixed-citation publication-type="book">
          <source>Chemistry and chemical engineering (assessment of research quality)</source>
          <year>2002</year>
          <publisher-loc>Utrecht</publisher-loc>
          <publisher-name>VSNU</publisher-name>
        </mixed-citation>
      </ref>
      <ref id="CR30">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Waltman</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Eck</surname>
              <given-names>NJ</given-names>
            </name>
            <name>
              <surname>Leeuwen</surname>
              <given-names>TN</given-names>
            </name>
            <name>
              <surname>Visser</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Raan</surname>
              <given-names>AFJ</given-names>
            </name>
          </person-group>
          <article-title>Towards a new crown indicator: Some theoretical considerations</article-title>
          <source>Journal of Informetrics</source>
          <year>2011</year>
          <volume>5</volume>
          <issue>1</issue>
          <fpage>37</fpage>
          <lpage>47</lpage>
          <pub-id pub-id-type="doi">10.1016/j.joi.2010.08.001</pub-id>
        </mixed-citation>
      </ref>
    </ref-list>
    <fn-group>
      <fn id="Fn1">
        <label>1</label>
        <p>At CWTS, we always use multiple indicators in our performance evaluation studies. Some indicators focus on the productivity dimension of research performance, while others focus on the impact dimension. Also, some indicators are normalized (either at the level of fields or at the level of journals), while others are not. We use the term &#x2018;crown indicator&#x2019; to refer to what we generally consider to be our most informative indicator. However, we emphasize that this &#x2018;crown indicator&#x2019; is not intended to be used in isolation. The indicator should always be used in combination with other indicators.</p>
      </fn>
      <fn id="Fn2">
        <label>2</label>
        <p>The difference between the normalized mean citation rate indicator and the CPP/FCSm indicator is that the former indicator only normalizes for the field and the year in which a publication was published while the latter indicator also normalizes for a publication&#x2019;s document type. In this paper, we do not consider the issue of normalizing for a publication&#x2019;s document type. For our present purpose, the difference between the two indicators is therefore not important.</p>
      </fn>
      <fn id="Fn3">
        <label>3</label>
        <p>In the case of normalization at the level of journals, <italic>e</italic><sub><italic>i</italic></sub> in (2) equals the average number of citations of all publications published in the same journal and in the same year as publication <italic>i</italic>. We do not recommend the use of (2) for normalization at the journal level. When (2) is used for normalization at the journal level, publications in journals with a very low average number of citations may have too much weight in the calculation of the indicator and may cause the indicator to become unstable.</p>
      </fn>
      <fn id="Fn4">
        <label>4</label>
        <p>In a somewhat different context, the difference between ratios of averages and averages of ratios was also studied by Egghe and Rousseau (<xref ref-type="bibr" rid="CR8">1996a</xref>, <xref ref-type="bibr" rid="CR9">b</xref>).</p>
      </fn>
      <fn id="Fn5">
        <label>5</label>
        <p>However, as we will see later on in this paper, there are exceptional publications that receive lots of citations already in the year in which they were published.</p>
      </fn>
      <fn id="Fn6">
        <label>6</label>
        <p>We did not retrieve publications of the document type letter. Like recent publications, letters typically have no or almost no citations. In the calculation of the MNCS indicator, letters therefore cause the same difficulties as recent publications (see Sect.&#xA0;<xref rid="Sec3" ref-type="sec">3</xref>). A solution could be to modify the MNCS indicator in such a way that letters have a lower weight than other publications. (This is essentially what happens in the CPP/FCSm indicator.) In our analysis, however, we do not want to make any modifications to the MNCS indicator, and we therefore leave out letters. The document type note was used in the Web of Science database until 1996. From then on, most documents that would formerly have been classified as notes were classified as ordinary articles. In our analysis, we only have notes in the research groups data set.</p>
      </fn>
      <fn id="Fn7">
        <label>7</label>
        <p>In the case of the research groups data set, this for example means that we count citations until the end of 2000. Of course, we could also count all citations until today. However, we want to replicate as closely as possible the original study in which the data set was used (VSNU <xref ref-type="bibr" rid="CR29">2002</xref>). In this study, citations were counted until the end of 2000. More recent citation data was not available at the time of the study. In bibliometric performance evaluation studies, one almost always has to work with relatively short citation windows.</p>
      </fn>
      <fn id="Fn8">
        <label>8</label>
        <p>Recall from Sect.&#xA0;<xref rid="Sec2" ref-type="sec">2</xref> that the expected number of citations of a publication equals the average number of citations of all publications published in the same field and in the same year as the publication of interest. In our calculations, fields were defined by Web of Science subject categories. When a publication belongs to multiple subject categories, the expected number of citations of the publication was calculated using the approach discussed by Waltman et al. (<xref ref-type="bibr" rid="CR30">2011</xref>, Sect.&#xA0;6).</p>
      </fn>
      <fn id="Fn9">
        <label>9</label>
        <p>Notice in Table&#xA0;<xref rid="Tab5" ref-type="table">5</xref> that the publication with the highest normalized citation score has just five citations. The high normalized citation score of this publication is due to the low expected number of citations of the publication. This illustrates that in the calculation of the MNCS2 indicator a recent publication with a relatively low number of citations can already have a quite large effect.</p>
      </fn>
      <fn id="Fn10">
        <label>10</label>
        <p>The extremely high number of citations of this recently published article was also discussed by Dimitrov et al. (<xref ref-type="bibr" rid="CR7">2010</xref>), who pointed out the enormous effect of this single article on the impact factor of <italic>Acta Crystallographica Section A</italic>, the journal in which the article was published.</p>
      </fn>
      <fn id="Fn11">
        <label>11</label>
        <p>In the case of journals, the CPP/FCSm indicator is also referred to as the JFIS indicator (e.g., Van Leeuwen and Moed <xref ref-type="bibr" rid="CR23">2002</xref>).</p>
      </fn>
      <fn id="Fn12">
        <label>12</label>
        <p>Comparing the two scatter plots in Fig.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>, it can be seen that the journal with the highest CPP/FCSm score (17.68) has extremely different MNCS1 and MNCS2 scores (respectively 32.28 and 2.14). The MNCS1 score of the journal is much higher than the CPP/FCSm score, while the MNCS2 score is much lower. It turns out that in 2008 the journal, <italic>Acta Crystallographica Section A</italic>, published an article that by the end of 2008 had already been cited 3489 times. This is the same article mentioned earlier for the University of G&#xF6;ttingen. This article has much more weight in the MNCS1 indicator than in the CPP/FCSm indicator. In the MNCS2 indicator, the article is not taken into consideration at all. This explains the extremely different CPP/FCSm, MNCS1, and MNCS2 scores of the journal.</p>
      </fn>
    </fn-group>
  </back>
</article>
