<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v3.0 20080202//EN" "archivearticle3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <?properties open_access?>
  <?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
  <?DTDIdentifier.IdentifierType public?>
  <?SourceDTD.DTDName journalpublishing.dtd?>
  <?SourceDTD.Version 2.3?>
  <?ConverterInfo.XSLTName jp2nlmx2.xsl?>
  <?ConverterInfo.Version 2?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Soc Cogn Affect Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">scan</journal-id>
      <journal-id journal-id-type="hwp">scan</journal-id>
      <journal-title-group>
        <journal-title>Social Cognitive and Affective Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1749-5016</issn>
      <issn pub-type="epub">1749-5024</issn>
      <publisher>
        <publisher-name>Oxford University Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3110429</article-id>
      <article-id pub-id-type="pmid">20460301</article-id>
      <article-id pub-id-type="doi">10.1093/scan/nsq039</article-id>
      <article-id pub-id-type="publisher-id">nsq039</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Original Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Stop looking angry and smile, please: start and stop of the very same facial expression differentially activate threat- and reward-related brain networks</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>M&#xFC;hlberger</surname>
            <given-names>Andreas</given-names>
          </name>
          <xref ref-type="aff" rid="AFF1">
            <sup>1</sup>
          </xref>
          <xref ref-type="author-notes" rid="FN1">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Wieser</surname>
            <given-names>Matthias J.</given-names>
          </name>
          <xref ref-type="aff" rid="AFF1">
            <sup>1</sup>
          </xref>
          <xref ref-type="author-notes" rid="FN1">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Gerdes</surname>
            <given-names>Antje B.M.</given-names>
          </name>
          <xref ref-type="aff" rid="AFF1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Frey</surname>
            <given-names>Monika C.M.</given-names>
          </name>
          <xref ref-type="aff" rid="AFF1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Weyers</surname>
            <given-names>Peter</given-names>
          </name>
          <xref ref-type="aff" rid="AFF1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Pauli</surname>
            <given-names>Paul</given-names>
          </name>
          <xref ref-type="aff" rid="AFF1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="AFF1">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="AFF1"><sup>1</sup>Department of Psychology, and <sup>2</sup>Faculty of Medicine, University of W&#xFC;rzburg, D-97070 W&#xFC;rzburg</aff>
      <author-notes>
        <corresp id="COR1">Correspondence should be addressed to Andreas M&#xFC;hlberger, Department of Psychology, Biological Psychology, Clinical Psychology, and Psychotherapy, University of W&#xFC;rzburg, Marcusstr. 9-11, D-97070 W&#xFC;rzburg. E-mail: <email>muehlberger@psychologie.uni-wuerzburg.de</email>.</corresp>
        <fn id="FN1">
          <p>*These authors contributed equally to this work.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="ppub">
        <month>6</month>
        <year>2011</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>11</day>
        <month>5</month>
        <year>2010</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>11</day>
        <month>5</month>
        <year>2010</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub"/>. -->
      <volume>6</volume>
      <issue>3</issue>
      <fpage>321</fpage>
      <lpage>329</lpage>
      <history>
        <date date-type="received">
          <day>8</day>
          <month>10</month>
          <year>2009</year>
        </date>
        <date date-type="accepted">
          <day>8</day>
          <month>4</month>
          <year>2010</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; The Author (2010). Published by Oxford University Press.</copyright-statement>
        <copyright-year>2010</copyright-year>
        <license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.5">
          <license-p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.5">http://creativecommons.org/licenses/by-nc/2.5</ext-link>), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Static pictures of emotional facial expressions have been found to activate brain structures involved in the processing of emotional stimuli. However, in everyday live, emotional expressions are changing rapidly, and the processing of the onset <italic>vs</italic> the offset of the very same emotional expression might rely on different brain networks, presumably leading to different behavioral and physiological reactions (e.g. approach or avoidance). Using functional magnetic resonance imaging, this was examined by presenting video clips depicting onsets and offsets of happy and angry facial expressions. Subjective valence and threat ratings clearly depended on the direction of change. Blood oxygen level dependent responses indicate both reward- and threat-related activations for the offset of angry expressions. Comparing onsets and offsets, angry offsets were associated with stronger ventral striatum activation than angry onsets. Additionally, the offset of happy and the onset of angry expressions showed strong common activity in the lateral orbitofrontal cortex bilaterally, the left amygdala and the left insula, whereas the onset of happy and the offset of angry expressions induced significant activation in the left dorsal striatum. In sum, the results confirm different activity in motivation-related brain areas in response to the onset and offset of the same emotional expression and highlight the importance of temporal characteristics of facial expressions for social communication.</p>
      </abstract>
      <kwd-group>
        <kwd>Functional magnetic resonance imaging</kwd>
        <kwd>face</kwd>
        <kwd>facial expression</kwd>
        <kwd>striatum</kwd>
        <kwd>amygdala</kwd>
      </kwd-group>
      <counts>
        <page-count count="9"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <p>Human daily behavior is guided by social signals. Among the most important signals in non-verbal communication are facial expressions, because from these expressions we can glean information about the internal emotional state and the intentions of others. Consequently, these signals have a deep impact on our motivational systems. In our everyday live, facial expressions are normally changing continuously (e.g. from a smile to a frown). Such changes carry diverging information about the emotional status of the observed person and are of motivational relevance for the observer. The neural correlates of such changes in facial expressions, however, are not very well investigated since until now research has been mostly concerned with static facial expressions.</p>
    <p>Static pictures of emotional facial expressions have consistently been found to activate brain structures involved in emotional processing (for review see <xref ref-type="bibr" rid="B35">Phan <italic>et al.</italic>, 2002</xref>). Pictures of happy faces have been shown to activate reward-related areas like the basal ganglia, including the ventral striatum and the putamen (<xref ref-type="bibr" rid="B27">Morris <italic>et al.</italic>, 1996</xref>; <xref ref-type="bibr" rid="B36">Phillips <italic>et al.</italic>, 1998</xref>; <xref ref-type="bibr" rid="B52">Whalen <italic>et al.</italic>, 1998</xref>). In contrast, threatening faces are expected to activate the fight&#x2013;flight system, and accordingly it has been found that fearful as well as angry faces activate the amygdala (<xref ref-type="bibr" rid="B27">Morris <italic>et al.</italic>, 1996</xref>; <xref ref-type="bibr" rid="B52">Whalen <italic>et al.</italic>, 1998</xref>) and other limbic areas like the insula (e.g. <xref ref-type="bibr" rid="B41">Schienle <italic>et al.</italic>, 2002</xref>).</p>
    <p>However, amygdala responses have also been confirmed for happy, sad and neutral facial expressions (e.g. <xref ref-type="bibr" rid="B53">Yang <italic>et al.</italic>, 2002</xref>; <xref ref-type="bibr" rid="B12">Fitzgerald <italic>et al.</italic>, 2006</xref>); thus, the amgydala might respond to meaningful stimuli in general (see <xref ref-type="bibr" rid="B35">Phan <italic>et al.</italic>, 2002</xref>; <xref ref-type="bibr" rid="B42">Sergerie <italic>et al.</italic>, 2008</xref>). Similarly, Adolphs (<xref ref-type="bibr" rid="B1">2008</xref>) states that the amygdala might be responsible for detecting salience and biological relevance which is thought to serve a fundamental role to facilitate biologically relevant learning (<xref ref-type="bibr" rid="B51">Whalen, 2009</xref>). Additionally, meta-analytic approaches have pointed to hemispheric differences in amygdala reactivity to emotional stimuli. While the right amygdala seems to be indifferent with respect to the emotional valence of the stimulus and to be activated by emotionally salient (facial) stimuli in general, the left amygdala seems to be involved in &#x2018;more detailed, cognitive perceptual emotional information processing&#x2019; (p. 266), to depend on the emotional valence of the stimulus and to be only responsive to negative facial expressions (<xref ref-type="bibr" rid="B14">Fusar-Poli <italic>et al.</italic>, 2009</xref>).</p>
    <p>Comparing static and dynamic facial expressions, it was shown that dynamic facial expressions elicit enhanced ratings of arousal (<xref ref-type="bibr" rid="B50">Weyers <italic>et al.</italic>, 2006</xref>; <xref ref-type="bibr" rid="B40">Sato and Yoshikawa, 2007</xref>), enhanced facial mimicry (<xref ref-type="bibr" rid="B50">Weyers <italic>et al.</italic>, 2006</xref>; <xref ref-type="bibr" rid="B38">Sato <italic>et al.</italic>, 2008</xref>), and stronger amygdala activity (e.g. <xref ref-type="bibr" rid="B21">LaBar <italic>et al.</italic>, 2003</xref>; <xref ref-type="bibr" rid="B39">Sato <italic>et al.</italic>, 2004</xref>; <xref ref-type="bibr" rid="B48">van der Gaag <italic>et al.</italic>, 2007</xref>). Yet, all these studies have examined the dynamic onset of emotional facial expressions; thus, the effect of the dynamic offset of an emotional facial expression is still unknown. In addition, the onset of a positive facial expression may have comparable effects to the offset of a negative expression on threat- or reward-associated systems and vice versa because in each case both dynamic changes carry comparable emotional information. Specifically, the onset of a happy expression and the offset of an angry expression share a positive valence, while the offset of a happy expression and the onset of an angry expression share a negative valence.</p>
    <p>So far, effects of the onset and the offset of stimuli have been examined in the context of pain processing and conditioning. Even if this research did not involve dynamic changes during stimulus presentation, but a discrete onset and offset of stimuli, important information might be drawn for the onset and offset of emotional facial expressions. The first line of research was based on opponent process theories (<xref ref-type="bibr" rid="B45">Solomon, 1980</xref>) and investigated temporal aspects of processing painful stimuli under the assumption that pain onset and pain offset are opposite ends of the reward-aversion continuum (<xref ref-type="bibr" rid="B2">Becerra and Borsook, 2008</xref>). Indeed, brain imaging studies indicate that pain onset (aversive) elicits deactivation in the ventral striatum (nucleus accumbens), whereas pain offset (rewarding) elicits its activation (<xref ref-type="bibr" rid="B2">Becerra and Borsook, 2008</xref>). Interestingly, recent research confirmed that physical pain and pleasure include the same networks as social pain and pleasure (<xref ref-type="bibr" rid="B24">Lieberman, 2009</xref>).</p>
    <p>The other line of research investigated neural structures associated with conditioned stimuli. After fear conditioning, activity of the amygdala and the insula have been confirmed (e.g. <xref ref-type="bibr" rid="B22">LaBar <italic>et al.</italic>, 1998</xref>; <xref ref-type="bibr" rid="B23">LeDoux, 2000</xref>; <xref ref-type="bibr" rid="B26">Maren, 2001</xref>; <xref ref-type="bibr" rid="B7">Craig, 2002</xref>, for review see <xref ref-type="bibr" rid="B8">Delgado <italic>et al.</italic>, 2008</xref>). Contrary to fear conditioning, in appetitive conditioning the striatum (e.g. nucleus caudate, putamen, nucleus accumbens) has been found to be a key structure activated by the conditioned stimulus associated with either a primary (e.g. <xref ref-type="bibr" rid="B31">O'Doherty <italic>et al.</italic>, 2001</xref>; <xref ref-type="bibr" rid="B33">Pagnoni <italic>et al.</italic>, 2002</xref>; <xref ref-type="bibr" rid="B15">Gottfried <italic>et al.</italic>, 2003</xref>) or a secondary reinforcer (e.g. <xref ref-type="bibr" rid="B9">Delgado <italic>et al.</italic>, 2000</xref>; <xref ref-type="bibr" rid="B16">Kirsch <italic>et al.</italic>, 2003</xref>; <xref ref-type="bibr" rid="B8">Delgado <italic>et al.</italic>, 2008</xref>, for review see <xref ref-type="bibr" rid="B8">Delgado <italic>et al.</italic>, 2008</xref>). However, recent studies indicate that the dichotomy of fear conditioning as primarily relying on the amygdala and appetitive conditioning as primarily relying on the striatum is too simple. On the contrary, it seems that the striatum and the amygdala are functionally interconnected and both involved in appetitive and aversive conditioning (e.g. <xref ref-type="bibr" rid="B43">Setlow <italic>et al.</italic>, 2002</xref>; <xref ref-type="bibr" rid="B44">Seymour <italic>et al.</italic>, 2007</xref>, for review see <xref ref-type="bibr" rid="B8">Delgado <italic>et al.</italic>, 2008</xref>). Accordingly, it has been proposed that the lateral nucleus, the central nucleus, and the basal nucleus of the amygdala are associated with the processing of aversive conditioning, while the basolateral nucleus is associated with appetitive conditioning (<xref ref-type="bibr" rid="B8">Delgado <italic>et al.</italic>, 2008</xref>). Regarding the striatum both the ventral and the dorsal striatum have been associated with a prediction error in appetitive conditioning. Additionally, the ventral striatum, mostly the nucleus accumbens, but even the dorsal striatum has been associated with aversive conditioning. However, Delgado <italic>et al.</italic> (<xref ref-type="bibr" rid="B8">2008</xref>) stated that up to now the different contributions of striatum subdivisions (e.g. dorsal/ventral) for aversive conditioning have not been clearly identified. Nevertheless, some authors suggest that the ventral striatum might be solely involved in the processing of appetitive stimuli (<xref ref-type="bibr" rid="B17">Knutson <italic>et al.</italic>, 2001a</xref>).</p>
    <p>The orbitofrontal cortex (OFC) has been investigated in the processing of reinforcement, often applying operant conditioning paradigms. It has been found that medial regions of the OFC are more associated with the reward value of reinforcers, and lateral regions of the OFC are more associated with the evaluation of punishers (e.g. <xref ref-type="bibr" rid="B19">Kringelbach, 2005</xref>). However, it has been assumed that not only the hedonic valence of the reinforcement, but also the choice of a response is important for the activation of the OFC (e.g. <xref ref-type="bibr" rid="B19">Kringelbach, 2005</xref>). A recent study by Elliot <italic>et al.</italic> (<xref ref-type="bibr" rid="B10">2010</xref>) now shows that the medial OFC response is specific to positive outcomes and is independent of the behavioral significance (<xref ref-type="bibr" rid="B10">Elliot <italic>et al.</italic>, 2010</xref>). Additionally, they confirmed that the lateral OFC is activated by negative outcomes. Whereas emotional facial expressions have been confirmed to act as reinforcers using the presentation of static pictures (e.g. <xref ref-type="bibr" rid="B49">Vrticka <italic>et al.</italic>, 2008</xref>; <xref ref-type="bibr" rid="B46">Spreckelmeyer, 2009</xref>), to our knowledge no study has investigated changes of these expressions as reinforcers. To investigate the reinforcing value of changes of facial expressions, however, onset and offset of the same expression have to be differentiated. The <italic>onset</italic> of a smile might be a reinforcer activating the reward circuitry, whereas the <italic>offset</italic> of a smile might serve as a threat or punishing stimulus consequently activating systems involved in fear. In contrast, the <italic>onset</italic> of an angry facial expression might predict threat or punishment and thus activate systems involved in fear, whereas the <italic>offset</italic> of an angry expression might serve as negative reinforcer: watching an angry person calming down might activate reward circuitries.</p>
    <p>According to the reasoning outlined above, the aim of the current study was to investigate whether the dynamic onset and the dynamic offset of angry and happy facial expressions each have opposite effects on reward-aversion related neural structures. We focused on a subset of brain areas involved in processing of pleasure and pain. Our hypotheses were that all emotional expressions will activate the amygdala bilaterally, but that angry facial expressions will activate the left amygdala as well as the insula, whereas happy facial expressions will activate regions within the ventral striatum. More importantly, we further assumed that this effect will be modulated by the temporal change of the expressions (onset, offset). The dynamic onset of happy facial expressions and the dynamic offset of angry facial expressions should lead to stronger activations of reward-related regions within the striatum (all sub-regions, but especially the ventral striatum, e.g. the nucleus accumbens) and in the medial OFC, whereas the onset of angry facial expressions and the offset of happy facial expressions should lead to stronger lateral OFC, left amygdala, and insula activations. To examine these questions we measured neural activation by functional magnetic resonance imaging (fMRI) in response to short video clips displaying the onset and offset of angry and happy facial expressions.</p>
    <sec sec-type="methods">
      <title>METHODS</title>
      <sec sec-type="subjects">
        <title>Participants</title>
        <p>After giving informed written consent 16 volunteers (seven females; age <italic>M</italic> = 22.9, s.d. = 2.3) participated in the pilot study, and 18 in the fMRI study (eight females, age <italic>M =</italic> 22.4, s.d. = 2.6). None of the participants reported any psychiatric or neurological history; furthermore, they reported normal or corrected-to-normal vision. Additionally, all participants in the fMRI study were right-handed (Edinburgh Handedness Inventory, Oldfield, 1971). The study was approved by the local ethics committee.</p>
      </sec>
      <sec>
        <title>Design, stimuli and task</title>
        <p>The present studies employed a 2 &#xD7; 2 factorial design with the factors emotion (angry <italic>vs</italic> happy expression) and dynamic (onset <italic>vs</italic> offset of emotion). The stimuli consisted of computer-generated (virtual) male faces (Poser, Curious Labs, Santa Cruz, CA) depicting the onset or offset of either angry or happy facial expressions (see examples in <xref ref-type="fig" rid="F1">Figure 1</xref>). Virtual faces provide useful research tools because they allow complete control over the facial expression and its dynamics. Compared to photos of real persons they were found to elicit similar brain responses (e.g. <xref ref-type="bibr" rid="B28">Moser <italic>et al.</italic>, 2007</xref>; <xref ref-type="bibr" rid="B30">M&#xFC;hlberger <italic>et al.</italic>, 2009</xref>).
<fig id="F1" position="float"><label>Fig. 1</label><caption><p>Examples of the four experimental conditions. In each column, one experimental condition is depicted with the start and the end frame of the video clip.</p></caption><graphic xlink:href="nsq039f1"/></fig>
</p>
        <p>We used clips of 1.67 s length and a frame rate of 30 frames per second. Altogether, six male characters were created, which differed in hairstyle and hair color. For the onset conditions the clips linearly changed from a neutral into a happy or an angry face. For the offset conditions, the clips linearly turned from the fully expressed emotion into a neutral face (<xref ref-type="fig" rid="F1">Figure 1</xref>). Linear changes were used to secure the same physical features for the presentation of onset and offset. Each character displayed all four experimental conditions.</p>
        <p>In the pilot study, participants were asked to rate the clips with respect to valence, arousal, and threat. The clips were presented in a randomized order, and after each clip, three different 9-point Likert rating scales were presented (valence: 1 = <italic>very unpleasant</italic> to 9 = <italic>very pleasant</italic>; arousal: 1 = <italic>very arousing</italic> to 9 = <italic>not arousing at all</italic>; threat: 1 = <italic>not threatening at all</italic> to 9 = <italic>very threatening</italic>).</p>
        <p>The fMRI experiment was conducted as a block design (8 min in total). The four experimental conditions were repeated twice per session resulting in eight experimental blocks. Two baseline blocks were inserted (fixation cross for 25 s), after the first and the seventh experimental block, while the order of experimental blocks was randomized across participants. Each block contained 12 stimuli each displayed for 1670 ms followed by a 750 ms inter-stimulus interval. Participants were instructed to watch the clips or the fixation cross without any further task. The stimuli were presented on a light gray background via MRI-compatible goggles (VisuaStim; Magnetic Resonance Technologies, Northridge, CA) using Presentation (Version 9.13, Neurobehavioral Systems, Albany, CA, USA).</p>
      </sec>
      <sec>
        <title>Image acquisition</title>
        <p>Functional and structural MRI was performed with a Siemens 1.5 T MRI whole body scanner (SIEMENS Avanto) using a standard head coil and a custom-built head holder. Functional images were obtained using a T2*-weighted single-shot gradient echoplanar imaging (EPI) sequence (TR: 2500 ms, TE: 30 ms, 90&#xB0; flip angle, FOV: 200 mm, matrix: 64 &#xD7; 64, voxel size: 3.1 &#xD7; 3.1 &#xD7; 3 mm<sup>3</sup>). Each EPI volume contained 25 axial slices (thickness 5 mm, 1 mm gap), acquired in interleaved order, covering the whole brain. The orientation of the axial slices was parallel to the AC&#x2013;PC line. Each session contained 190 functional images. The first nine volumes of each session were discarded to allow for T1 equilibration. In addition, a high-resolution T1-weighted magnetization-prepared rapid gradient-echo imaging (MP-RAGE) 3D MRI sequence was obtained from each subject (TR: 2250 ms, TE: 3.93 ms, 98 flip angle, FOV: 256 mm, matrix: 256 &#xD7; 256, voxel size: 1 &#xD7; 1 &#xD7; 1 mm<sup>3</sup>).</p>
      </sec>
      <sec>
        <title>Image preprocessing and analyses</title>
        <p>Data were analyzed by using Statistical Parametric Mapping software (SPM5; Wellcome Department of Imaging Neuroscience, London, UK) implemented in Matlab 7.0 (Mathworks Inc., Sherborn, MA, USA). Functional images were slice-time corrected and realigned by an affine registration. The mean functional image was subsequently normalized to the Montreal Neurological Institute (MNI) single-subject template (<xref ref-type="bibr" rid="B11">Evans <italic>et al.</italic>, 1992</xref>). Normalization parameters were then applied to the functional images and coregistered to the T1-image. Images were re-sampled at a 2 &#xD7; 2 &#xD7; 2 mm<sup>3</sup> voxel size and spatially smoothed using an 8 mm full width half maximum Gaussian kernel, and temporally filtered with a high-pass filter (cutoff 128 s). Each experimental condition was modeled using a boxcar reference vector convolved with a canonical hemodynamic response function. Parameter estimates were subsequently calculated for each voxel using weighted least squares to provide maximum likelihood estimates based on the non-sphericity assumption of the data in order to get identical and independently distributed error terms. Realignment parameters for each session were included to account for residual movement related variance. Parameter estimation was corrected for temporal autocorrelations using a first-order autoregressive model. For each subject, main effects were computed by applying appropriate baseline contrasts (simple effects).</p>
        <p>Afterwards these first-level individual contrasts were fed into a second-level group analysis using an ANOVA (factors: emotion, dynamic, and blocking factor subject), thus employing a random effects model (<xref ref-type="bibr" rid="B34">Penny and Holmes, 2003</xref>). The subject factor models subject constants that absorb much of the inter-subject variability present in most imaging data, which in turn leads to more sensitivity for the experimental effects (including group differences). First, we analyzed simple effects of each condition <italic>vs</italic> baseline and simple effects between onset and offset of both emotional expressions. Second, because we were especially interested in investigating the interaction between the factors emotion and dynamic, and in formally testing differences in simple effects, the following interaction contrast was calculated [(angry-onset &#x2013; angry-offset) <italic>vs</italic> (happy-offset &#x2013; happy-onset)]. Third, common activations of angry-offset and happy-onset and of angry-onset and happy-offset were identified by means of a conjunction analysis using the Global Null, a less conservative approach testing the combined null hypothesis for both contrasts of interest. Thus, a significant conjunction does not mean all the contrasts are individually significant, but that the contrasts are consistently high and jointly significant (cf. <xref ref-type="bibr" rid="B13">Friston <italic>et al.</italic>, 2005</xref>). These analyses were performed using the small volume correction of SPM 5, a height threshold of <italic>P</italic> &lt; 0.05, family-wise correction (FWE), and an extent threshold of <italic>k</italic> = 5 contiguous voxels. Resulting activation peaks were superimposed on standard high-resolution anatomical images. For a priori expected activations, ROI analyses were carried out in the amygdala, the insula, the ventral and dorsal part of the striatum (nucleus accumbens and head of caudate, body of caudate and putamen, respectively), and the medial and lateral part of the OFC based on masks from the WFU Pick Atlas (<xref ref-type="bibr" rid="B25">Maldjian <italic>et al.</italic>, 2003</xref>) as implemented in SPM5.</p>
      </sec>
    </sec>
    <sec sec-type="results">
      <title>RESULTS</title>
      <sec>
        <title>Pilot study</title>
        <p>Valence, arousal and threat ratings are shown in <xref ref-type="table" rid="T1">Table 1</xref>. Concerning valence, a significant main effect of emotion, <italic>F</italic>(1,15) = 64.7, <italic>P</italic> &lt; 0.01, &#x3B7;<sup>2</sup><sub><italic>p</italic></sub> = 0.81, and a significant Emotion &#xD7; Dynamic interaction, <italic>F</italic>(1,15) = 148.3, <italic>P</italic> &lt; 0.01, &#x3B7;<sup>2</sup><sub><italic>p</italic></sub> = 0.91, was observed<italic>. Post hoc</italic> comparisons revealed that the onset of angry expressions was rated as more negative than the offset of angry expressions, <italic>t</italic>(15) = 8.52, <italic>P</italic> &lt; 0.01, and the onset of happy expressions was rated as more positive than the offset of happy expressions, <italic>t</italic>(15) = 11.28, <italic>P</italic> &lt; 0.01. Additionally, the onset of happy expressions was rated as more positive than the onset of angry expressions, <italic>t</italic>(15) = 11.26, <italic>P</italic> &lt; 0.01, while the rating of offset between happy and angry expressions did not differ, <italic>P</italic> &gt; 0.16.
<table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Arousal, valence and threat ratings for angry and happy expressions as well as their onset and offset</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th colspan="2" rowspan="1">Variable<hr/></th><th colspan="2" rowspan="1">Valence<hr/></th><th colspan="2" rowspan="1">Arousal<hr/></th><th colspan="2" rowspan="1">Threat<hr/></th></tr><tr><th rowspan="1" colspan="1">Expression</th><th rowspan="1" colspan="1">Dynamic</th><th rowspan="1" colspan="1"><italic>M</italic></th><th rowspan="1" colspan="1">s.d.</th><th rowspan="1" colspan="1"><italic>M</italic></th><th rowspan="1" colspan="1">s.d.</th><th rowspan="1" colspan="1"><italic>M</italic></th><th rowspan="1" colspan="1">s.d.</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">Angry</td><td rowspan="1" colspan="1">Onset</td><td rowspan="1" colspan="1">2.90</td><td rowspan="1" colspan="1">1.12</td><td rowspan="1" colspan="1">4.51</td><td rowspan="1" colspan="1">1.15</td><td rowspan="1" colspan="1">6.51</td><td rowspan="1" colspan="1">1.05</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Offset</td><td rowspan="1" colspan="1">5.05</td><td rowspan="1" colspan="1">0.71</td><td rowspan="1" colspan="1">5.52</td><td rowspan="1" colspan="1">1.06</td><td rowspan="1" colspan="1">3.36</td><td rowspan="1" colspan="1">1.57</td></tr><tr><td rowspan="1" colspan="1">Happy</td><td rowspan="1" colspan="1">Onset</td><td rowspan="1" colspan="1">7.48</td><td rowspan="1" colspan="1">1.03</td><td rowspan="1" colspan="1">4.49</td><td rowspan="1" colspan="1">0.97</td><td rowspan="1" colspan="1">1.92</td><td rowspan="1" colspan="1">0.96</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Offset</td><td rowspan="1" colspan="1">4.71</td><td rowspan="1" colspan="1">0.42</td><td rowspan="1" colspan="1">5.30</td><td rowspan="1" colspan="1">1.10</td><td rowspan="1" colspan="1">3.84</td><td rowspan="1" colspan="1">1.98</td></tr></tbody></table></table-wrap>
</p>
        <p>For arousal ratings there was only a main effect of dynamic, <italic>F</italic>(1,15) = 64.7, <italic>P</italic> &lt; 0.01, &#x3B7;<sup>2</sup><sub><italic>p</italic></sub> = 0.81, indicating that the onsets of both emotional expressions were rated as more arousing than the offsets.</p>
        <p>Concerning threat ratings, there were significant main effects for emotion, <italic>F</italic>(1,15) = 34.1, <italic>P</italic> &lt; 0.01, &#x3B7;<sup>2</sup><sub><italic>p</italic></sub> = 0.70, and dynamic, <italic>F</italic>(1,15) = 5.4, <italic>P</italic> = 0.03, &#x3B7;<sup>2</sup><sub><italic>p</italic></sub> = 0.27, furthermore, the interaction Emotion &#xD7; Dynamic was significant, <italic>F</italic>(1,15) = 108.1, <italic>P</italic> &lt; 0.01, &#x3B7;<sup>2</sup><sub><italic>p</italic></sub> = 0.88. The onset of an angry expression was perceived as more threatening than the offset of an angry expression, <italic>t</italic>(15) = 9.3, <italic>P</italic> &lt; 0.01, whereas the offset of a happy expression was perceived as more threatening than the onset of a happy expression, <italic>t</italic>(15) = 5.15, <italic>P</italic> &lt; 0.01. Additionally, the onset of happy expressions was perceived as less threatening than the onset of angry expressions, <italic>t</italic>(15) = 14.25, <italic>p</italic> &lt; 0.01, while the threat ratings of the offsets did not differ between happy and angry expressions, <italic>P</italic> &gt; 0.36.</p>
        <p>In sum, valence and threat ratings revealed that the onset of an angry facial expression is perceived as more negative and threatening than the offset of the same emotion, whereas for happy facial expressions, we observed the opposite effect.</p>
      </sec>
      <sec>
        <title>fMRI study</title>
        <p>The regions of interest (ROI) analyses (amygdala, insula, ventral and dorsal striatum, OFC) for the simple effects revealed for the onset of a happy facial expression significant activations (<italic>P</italic> &lt; 0.05, FWE-corrected) in the right putamen (see <xref ref-type="table" rid="T2">Table 2</xref> for all main effects of the ROI analyses). For the offset of happy faces, significant activations were found in the left and right amygdala, the left and right insula, the left and right putamen, and the left and right lateral OFC. Both onset and offset of angry facial expressions revealed significant activations in the right and left amygdala, the right and left insula, and the left and right lateral OFC. The offset of angry facial expressions furthermore showed significant activations in the left and right head of caudate, the right and left body of the caudate, the right and left nucleus accumbens, and the left and right medial OFC.
<table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Significant activations as revealed by ROI analysis for the main effects</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">Contrast</th><th rowspan="1" colspan="1"><italic>x</italic></th><th rowspan="1" colspan="1"><italic>y</italic></th><th rowspan="1" colspan="1"><italic>z</italic></th><th rowspan="1" colspan="1"><italic>Z</italic></th><th rowspan="1" colspan="1"><italic>k</italic></th><th rowspan="1" colspan="1">Brain region</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">Angry onset</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;22</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">&#x2212;16</td><td rowspan="1" colspan="1">3.17</td><td rowspan="1" colspan="1">156</td><td rowspan="1" colspan="1">Amygdala L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">&#x2212;18</td><td rowspan="1" colspan="1">3.00</td><td rowspan="1" colspan="1">130</td><td rowspan="1" colspan="1">Amygdala R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;34</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">4.38</td><td rowspan="1" colspan="1">409</td><td rowspan="1" colspan="1">Insula L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">36</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">3.97</td><td rowspan="1" colspan="1">164</td><td rowspan="1" colspan="1">Insula R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">3.35</td><td rowspan="1" colspan="1">184</td><td rowspan="1" colspan="1">Putamen R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;48</td><td rowspan="1" colspan="1">34</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">5.34</td><td rowspan="1" colspan="1">342</td><td rowspan="1" colspan="1">Lateral OFC L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">54</td><td rowspan="1" colspan="1">34</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">7.23</td><td rowspan="1" colspan="1">302</td><td rowspan="1" colspan="1">Lateral OFC R</td></tr><tr><td rowspan="1" colspan="1">Angry offset</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;20</td><td rowspan="1" colspan="1">&#x2212;8</td><td rowspan="1" colspan="1">&#x2212;16</td><td rowspan="1" colspan="1">3.42</td><td rowspan="1" colspan="1">139</td><td rowspan="1" colspan="1">Amygdala L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">&#x2212;12</td><td rowspan="1" colspan="1">3.71</td><td rowspan="1" colspan="1">107</td><td rowspan="1" colspan="1">Amygdala R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;30</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">4.53</td><td rowspan="1" colspan="1">1089</td><td rowspan="1" colspan="1">Insula L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">&#x2212;2</td><td rowspan="1" colspan="1">4.57</td><td rowspan="1" colspan="1">854</td><td rowspan="1" colspan="1">Insula R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;6</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">3.61</td><td rowspan="1" colspan="1">170</td><td rowspan="1" colspan="1">Caudate head L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">3.84</td><td rowspan="1" colspan="1">187</td><td rowspan="1" colspan="1">Caudate head R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;6</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">&#x2212;2</td><td rowspan="1" colspan="1">2.84</td><td rowspan="1" colspan="1">40</td><td rowspan="1" colspan="1">N. accumbens L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">3.42</td><td rowspan="1" colspan="1">123</td><td rowspan="1" colspan="1">N. accumbens R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;34</td><td rowspan="1" colspan="1">&#x2212;16</td><td rowspan="1" colspan="1">&#x2212;8</td><td rowspan="1" colspan="1">4.14</td><td rowspan="1" colspan="1">743</td><td rowspan="1" colspan="1">Putamen L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">5.07</td><td rowspan="1" colspan="1">863</td><td rowspan="1" colspan="1">Putamen R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;50</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">4.37</td><td rowspan="1" colspan="1">99</td><td rowspan="1" colspan="1">Lateral OFC L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">54</td><td rowspan="1" colspan="1">30</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">5.36</td><td rowspan="1" colspan="1">133</td><td rowspan="1" colspan="1">Lateral OFC R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;24</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">&#x2212;14</td><td rowspan="1" colspan="1">4.17</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">Medial OFC L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">&#x2212;10</td><td rowspan="1" colspan="1">2.95</td><td rowspan="1" colspan="1">17</td><td rowspan="1" colspan="1">Medial OFC R</td></tr><tr><td rowspan="1" colspan="1">Happy onset</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;34</td><td rowspan="1" colspan="1">&#x2212;16</td><td rowspan="1" colspan="1">&#x2212;8</td><td rowspan="1" colspan="1">3.53</td><td rowspan="1" colspan="1">169</td><td rowspan="1" colspan="1">Putamen L</td></tr><tr><td rowspan="1" colspan="1">Happy offset</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;20</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">&#x2212;16</td><td rowspan="1" colspan="1">2.84</td><td rowspan="1" colspan="1">117</td><td rowspan="1" colspan="1">Amygdala L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">&#x2212;20</td><td rowspan="1" colspan="1">3.09</td><td rowspan="1" colspan="1">89</td><td rowspan="1" colspan="1">Amygdala R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;34</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">&#x2212;2</td><td rowspan="1" colspan="1">4.64</td><td rowspan="1" colspan="1">717</td><td rowspan="1" colspan="1">Insula L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">36</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">4.54</td><td rowspan="1" colspan="1">279</td><td rowspan="1" colspan="1">Insula R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;32</td><td rowspan="1" colspan="1">&#x2212;14</td><td rowspan="1" colspan="1">&#x2212;6</td><td rowspan="1" colspan="1">4.49</td><td rowspan="1" colspan="1">476</td><td rowspan="1" colspan="1">Putamen L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">3.43</td><td rowspan="1" colspan="1">454</td><td rowspan="1" colspan="1">Putamen R</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">&#x2212;52</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">5.24</td><td rowspan="1" colspan="1">554</td><td rowspan="1" colspan="1">Lateral OFC L</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">52</td><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">&#x2212;4</td><td rowspan="1" colspan="1">5.08</td><td rowspan="1" colspan="1">308</td><td rowspan="1" colspan="1">Lateral OFC R</td></tr></tbody></table><table-wrap-foot><fn><p>Alpha = 0.05 (FWE-corrected) for ROI analyses with a minimum cluster size of <italic>k</italic> = 5. L = left, R = right hemisphere, OFC = orbitofrontal cortex. <sup>a</sup>The cluster with the largest number of significant voxels within each region is reported. Coordinates <italic>x</italic>, <italic>y</italic> and <italic>z</italic> are given in MNI space.</p></fn></table-wrap-foot></table-wrap>
</p>
        <p>The direct comparison of the onset and offset of happy facial expressions was not significant. In contrast, the same comparison for angry facial expressions revealed significantly stronger activation to the offset compared to the onset in the left and right head of the caudate (<italic>x</italic> = &#x2212;12, <italic>y</italic> = 22, <italic>z</italic> = 0; <italic>Z</italic> = 3.54; FWE <italic>P</italic> = 0.005; 150 voxel; and <italic>x</italic> = 12, <italic>y</italic> = 16, <italic>z</italic> = 0; <italic>Z</italic> = 3.17; FWE <italic>P =</italic> 0.015; 141 voxel, respectively), and the right nucleus accumbens (<italic>x</italic> = 14, <italic>y</italic> = 16, <italic>z</italic> = &#x2212;2; <italic>Z</italic> = 2.83; FWE <italic>P</italic> = 0.049; 94 voxel). To a minor extent using a lowered statistical threshold also stronger activation in right medial OFC was detected (<italic>x</italic> = 16, <italic>y</italic> = 48, <italic>z</italic> = &#x2212;4; <italic>Z</italic> = 3.35; <italic>P &lt;</italic> 0.001, uncorrected; 8 voxel).</p>
        <p>To directly evaluate our hypothesis of common mechanisms of the onset of happy and the offset of angry faces and vice versa we conducted conjunction analyses for the related conditions (e.g. happy-offset and angry-onset) in the specified ROIs. The analysis of common activations between the onset of an angry expression and the offset of a happy expression revealed overlapping activation patterns in the left amygdala and left insula (<xref ref-type="fig" rid="F2">Figure 2</xref>A and B). In contrast, the onset of a happy facial expression and the offset of an angry facial expression significantly activated the left putamen (<xref ref-type="fig" rid="F2">Figure 2</xref>C). Thus, these results partially confirm our hypotheses.
<fig id="F2" position="float"><label>Fig. 2</label><caption><p>Statistical parametric maps for the conjunction analyses of angry-onset and happy-offset, and of angry-offset and happy-onset, respectively. (<bold>A</bold>) Common activation of angry-onset and happy-offset in the left amygdala, <italic>x</italic> = &#x2212;20, <italic>y</italic> = 2, <italic>z</italic> = &#x2212;16; <italic>Z</italic> = 2.84; <italic>P</italic> (FWE-corrected) = 0.035; <italic>k</italic> = 114 voxel. (<bold>B</bold>) Common activation of angry-onset and happy-offset in the left insula, (<italic>x</italic> = &#x2212;34, <italic>y</italic> = 24, <italic>z</italic> = &#x2212;4; <italic>Z</italic> = 4.38; <italic>P</italic> (FWE-corrected) = 0.002; <italic>k</italic> = 264 voxel. (<bold>C</bold>) Common activation of angry-offset and happy-onset in the left putamen, (<italic>x</italic> = &#x2212;34, <italic>y</italic> = &#x2212;16, <italic>z</italic> = &#x2212;8; <italic>Z</italic> = 2.84; <italic>P</italic> (FWE-corrected) = 0.018; <italic>k</italic> = 163 voxel.</p></caption><graphic xlink:href="nsq039f2"/></fig>
</p>
        <p>Regarding the OFC, the conjunction analysis of angry-onset and happy-offset revealed strong common activations in bilateral clusters in the lateral OFC (left: <italic>x</italic>&#x2009;=&#x2009;&#x2212;52, <italic>y</italic>&#x2009;=&#x2009;36, <italic>z</italic>&#x2009;=&#x2009;&#x2212;4; <italic>Z</italic>&#x2009;=&#x2009;6.72; <italic>P</italic> (FWE-corrected)&#x2009;&lt;&#x2009;0.001; <italic>k</italic>&#x2009;=&#x2009;524 voxel; right: <italic>x</italic>&#x2009;=&#x2009;52, <italic>y</italic>&#x2009;=&#x2009;32, <italic>z</italic>&#x2009;=&#x2009;&#x2212;4; <italic>Z</italic>&#x2009;=&#x2009;7.69; <italic>P</italic> (FWE-corrected)&#x2009;&lt;&#x2009;0.001; <italic>k</italic>&#x2009;=&#x2009;436 voxel). A small cluster in the left OFC was also found to be commonly activated by happy-onset and angry-offset (<italic>x</italic>&#x2009;=&#x2009;&#x2212;46, <italic>y</italic>&#x2009;=&#x2009;28, <italic>z</italic>&#x2009;=&#x2009;&#x2212;4; <italic>Z</italic>&#x2009;=&#x2009;4.64; <italic>P</italic> (FWE-corrected)&#x2009;=&#x2009;0.002; <italic>k</italic>&#x2009;=&#x2009;26 voxel).</p>
        <p>To further evaluate the idea that the onset of happy and the offset of angry faces compared to the onset of angry and the offset of happy faces would activate reward-associated brain regions stronger than threat-associated brain regions, respectively, ROI interaction analyses were computed. The ROI analysis of the interaction between onset and offset of angry <italic>vs</italic> happy facial expressions [(angry-offset <italic>vs</italic> angry-onset) <italic>vs</italic> (happy-onset <italic>vs</italic> happy-offset)] partially supported our hypothesis of an interaction within the striatum (left head of caudate, but not in the nucleus accumbens, see <xref ref-type="fig" rid="F3">Figure 3</xref>). However, there was no significant activation for the reversed interaction term [(angry-onset <italic>vs</italic> angry-offset) <italic>vs</italic> (happy-offset <italic>vs</italic> happy-onset)].
<fig id="F3" position="float"><label>Fig. 3</label><caption><p>Statistical parametric maps for the Emotion &#xD7; Dynamic interaction analysis, revealing selective activation in the left caudate head, <italic>x</italic> = &#x2212;14, <italic>y</italic> = 22, <italic>z</italic> = 6; <italic>Z</italic> = 3.29; <italic>P</italic> (FWE-corrected) = 0.011; <italic>k</italic> = 56 voxel.</p></caption><graphic xlink:href="nsq039f3"/></fig>
</p>
      </sec>
    </sec>
    <sec sec-type="discussion">
      <title>DISCUSSION</title>
      <p>To our knowledge, this is the first study investigating the neural effects of the dynamic onset and offset of emotional facial expressions. Subjective ratings confirmed that valence and threat of the investigated facial expressions depend on their temporal change. While the onset of happy facial expressions was rated as highly positive and least threatening, the onset of angry facial expressions was rated as highly negative and highly threatening. Interestingly, the offsets of happy and angry expressions were rated as neutral in valence and only medium threatening, respectively, thus eliciting attenuated responses compared to the onset of the same facial expressions. Arousal ratings for all presentations were at an average level.</p>
      <p>Interestingly, angry offset, angry onset, and happy offset activated the amygdala bilaterally. This result confirms the assumption that the amygdala is involved in the processing of emotionally salient stimuli in general (<xref ref-type="bibr" rid="B1">Adolphs, 2008</xref>). The non-significant results for the happy onset might mean that this condition is emotionally less salient. This interpretation is supported by the fact that also no significant activation of the ventral striatum was found in response to the onset of happy facial expressions. Another explanation could be that the happy faces have not been recognized as &#x2018;real&#x2019; Duchenne smiles, but as social (fake) smiles. However, the valence ratings of our pilot study and the fact that fake smiles are characterized by their relatively short onsets (&lt;0.4 s, see <xref ref-type="bibr" rid="B20">Krumhuber, 2007</xref>), seem to make this explanation unlikely. Furthermore, as humans are keen to detect cheaters (i.e. humans pretending to be friendly to take personal advantage), one would assume even higher salience and thus higher amgydala activations in response to fake smiles (<xref ref-type="bibr" rid="B5">Cosmides, 2005</xref>). Recently, it has been argued that the amygdala responds to facial expressions on the basis of their predictive value as a CS (<xref ref-type="bibr" rid="B51">Whalen, 2009</xref>). According to this line of reasoning, the amygdala will always track the stimulus, which shows the most promise for learning. Probably, in the context of angry offsets and onsets, and also happy offsets, the onset of a happy face is therefore least interesting and salient.</p>
      <p>The insula was activated bilaterally by the same conditions as the amygdala. The activation of the insula in the angry onset and the happy offset condition is easily explained by the role in the (social) pain network (<xref ref-type="bibr" rid="B24">Lieberman, 2009</xref>) and is in line with earlier results investigating facial expressions. Nevertheless, the activation in the angry offset condition as well might point at the insula having a similar functionality as the amygdala in detecting salience for biological learning.</p>
      <p>Furthermore, not only the insula, but also the lateral OFC was activated bilaterally by the same conditions as the amygdala. The activation of the lateral OFC in the angry onset and the happy offset condition is easily explained by the role of the processing of negative reinforcers (<xref ref-type="bibr" rid="B10">Elliot <italic>et al.</italic>, 2010</xref>). Nevertheless, the lateral OFC activation in the angry offset condition as well might indicate that this condition has positive and negative aspects or point at the notion that activations in this region are arousal-related, which has been found in passive viewing of emotional pictures and emotional imagery (<xref ref-type="bibr" rid="B37">Sabatinelli <italic>et al.</italic>, 2007</xref>; <xref ref-type="bibr" rid="B6">Costa <italic>et al.</italic>, 2010</xref>). Furthermore, the distinction between lateral and medial OFC as distinct regions for either processing punishment or reward cues is mainly derived from totally different paradigms.</p>
      <p>Regarding activations within the ventral striatum, it is very interesting that only the angry offset condition was associated with significant activations (nucleus accumbens and head of the caudate bilaterally). Additionally, the anger offset condition was the only one to activate the medial OFC. These results indicate that the offset of an angry facial expression is an important trigger to activate reward- or pleasure-related structures. Thus, while an angry face is supposed to be a prototypical stimulus activating the human fear system (<xref ref-type="bibr" rid="B32">&#xD6;hman, 1986</xref>), the offset of this &#x2018;prepared&#x2019; signal seems to be likewise of evolutionary significance to activate the reward system.</p>
      <p>A direct comparison confirmed a higher activation for the offset than the onset of angry expressions in the head of the caudate bilaterally and in the right nucleus accumbens. Therefore and according to our hypothesis, the offset of angry facial expressions activates reward-associated brain areas within the ventral striatum; these results confirm our findings in the main contrasts that the offset of an angry face is of evolutionary significance by presumably providing information about the end of a threat. Remarkably, these findings are in line with results of a recent study investigating general emotional stimuli that appeared either to approach (&#x2018;onset&#x2019;) or to recede (&#x2018;offset&#x2019;) from the observer (<xref ref-type="bibr" rid="B29">M&#xFC;hlberger <italic>et al.</italic>, 2008</xref>). Interestingly, approaching unpleasant pictures elicited enhanced startle responses compared to receding unpleasant pictures. Thus, depending on movement the same unpleasant picture triggered differential neural responses.</p>
      <p>Furthermore, conjunction analyses confirmed strong common activations in the left amygdala and the left insula as well as the lateral OFC induced by the onset of an angry expression and the offset of a happy expression. This fits to the assumption that the left amygdala is specifically involved in the processing of negative information (<xref ref-type="bibr" rid="B14">Fusar-Poli <italic>et al.</italic>, 2009</xref>), and we might assume that such laterality is even true for the insula. However this is speculative because such insula laterality has not yet been described in the literature. Additionally, the lateral OFC activation fits well to the literature on the role of this region in the evaluation of unpleasant stimuli (e.g. <xref ref-type="bibr" rid="B19">Kringelbach, 2005</xref>; <xref ref-type="bibr" rid="B10">Elliot <italic>et al.</italic>, 2010</xref>). Furthermore, the onset of happy expressions and the offset of angry expressions induced significant activations in the left dorsal striatum (putamen). However, the role of the putamen in reward-processing is still unclear although it is known that this area is involved in motivational processes and has also been related to reward prediction (<xref ref-type="bibr" rid="B4">Breiter <italic>et al.</italic>, 2001</xref>; <xref ref-type="bibr" rid="B18">Knutson <italic>et al.</italic>, 2001b</xref>; <xref ref-type="bibr" rid="B3">Bjork <italic>et al.</italic>, 2004</xref>). It has to be noted however that putamen activations were also present in our study for the main effects of angry onset and happy offset, pointing at a more general involvement of the putamen in the processing of dynamic facial expressions.</p>
      <p>The interaction analysis additionally revealed that the offset of angry facial expressions and the onset of happy facial expressions are associated with activity in the left ventral striatum (head of caudate). This last result confirms the reward association of angry offset, since we speculate that the angry offset contributed more to this effect than the happy onset (see main contrasts).</p>
      <p>To sum up, this study is the first that investigated onset and offset of happy and angry facial expressions. Our results confirm that the angry offset condition is associated with reward-processing (e.g. nucleus accumbens, head of caudate, and to a fewer extent, medial OFC). Furthermore, angry-onset as well as happy-offset were found to activate regions involved in the processing of negative facial expressions (e.g. left amygdala). This finding confirms the laterality of the amygdala in processing of negative facial stimuli.</p>
      <p>Our results also relate to both the literature on pain processing and on conditioning. There is evidence that onset and offset of a painful (unconditioned) stimulus activate threat- and reward-related brain areas in a different way. First, our findings fit well with the results of Becerra and Borsook (<xref ref-type="bibr" rid="B2">2008</xref>) indicating that pain offset activates the nucleus accumbens whereas pain onset leads to its deactivation; similarly we found that the offset of angry facial expressions elicits a bilateral nucleus accumbens activation. We conclude that both the offset of an angry facial expression and the offset of pain signify relief and therefore are associated with the activity in reward-processing brain areas. Second, there are hints from the conditioning literature that the onset and the offset of an unconditioned stimulus have opposite effects on approach/avoidance behavior (e.g. <xref ref-type="bibr" rid="B47">Tanimoto <italic>et al.</italic>, 2004</xref>). Our observation of a different activation of reward- and threat-related brain areas by the onset and the offset of an emotional face are well in line with these results. Furthermore, the left amygdala and left insula responses to the onset of angry faces and the offset of happy faces perfectly fit with the assumption that these dynamic facial expressions both act as (conditioned) aversive stimuli.</p>
      <p>Some caveats, however, have to be discussed. First, because we used only male faces, we have to limit the results for those stimuli. Additionally, it might well be that there are gender differences in the processing of faces, which could not be fully addressed in the present study. However, exploratory analyses did not reveal any gender differences in the processing of the faces in our sample. Further research might include female and male faces and a larger sample to scrutinize gender-related differences. Next, it could be that clips depicting emotion offsets lead to a bidirectional activation of motivational systems. This points to a methodological challenge, namely that the beginning of the stimulus (clip) is always a confounding variable. Dynamically presented offsets have to start with the full emotional expressions, as for example is the case for our angry offset clips which start with a full blown angry expression; thus we cannot disentangle the blood oxygen level dependent responses to the onset of the clip and to the dynamic change. Furthermore, we can not disentangle whether the observed effects relate to the specific event of an emotion appearing or disappearing or to a more sustained psychological state created through the repeated onset or offset of the emotional facial expressions. Further research should try to disentangle these two components by using event-related measures. A further limitation of our study is that only two emotions were investigated. Further research should investigate whether only the offset of angry facial expressions activates the reward system, or whether this is a more general phenomenon apparent for other negative emotional facial expressions as well. Last, although subjective ratings confirmed the positive value of our happy onset clips, brain activations in response to these stimuli were not as strong as expected. It might be that the happy expression could be improved by enhancing the amount of the smile or by confirming that the smile is seen as a Duchenne smile.</p>
      <p>In sum, our results clearly indicate that the onset and offset of the same emotional facial expression are not only rated as being differently threatening, but that they also activate reward- and threat-related brain areas in a different way. As a consequence it seems necessary to take the temporal dynamics of facial expressions into account to understand their impact on social interaction as well as learning in social contexts.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors thank Felix Breuer for his excellent assistance in fMRI data acquisition. This research was supported by German Research Foundation (FOR 605 and SFB TRR 58 B01).</p>
    </ack>
    <ref-list>
      <title>REFERENCES</title>
      <ref id="B1">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Adolphs</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Fear, faces, and the human amygdala</article-title>
          <source>Current Opinion in Neurobiology</source>
          <year>2008</year>
          <volume>18</volume>
          <fpage>166</fpage>
          <lpage>72</lpage>
          <pub-id pub-id-type="pmid">18655833</pub-id>
        </element-citation>
      </ref>
      <ref id="B2">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Becerra</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Borsook</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Signal valence in the nucleus accumbens to pain onset and offset</article-title>
          <source>European Journal of Pain</source>
          <year>2008</year>
          <volume>12</volume>
          <fpage>866</fpage>
          <lpage>9</lpage>
          <pub-id pub-id-type="pmid">18226937</pub-id>
        </element-citation>
      </ref>
      <ref id="B3">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bjork</surname>
              <given-names>JM</given-names>
            </name>
            <name>
              <surname>Knutson</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Fong</surname>
              <given-names>GW</given-names>
            </name>
            <name>
              <surname>Caggiano</surname>
              <given-names>DM</given-names>
            </name>
            <name>
              <surname>Bennett</surname>
              <given-names>SM</given-names>
            </name>
            <name>
              <surname>Hommer</surname>
              <given-names>DW</given-names>
            </name>
          </person-group>
          <article-title>Incentive-elicited brain activation in adolescents: similarities and differences from young adults</article-title>
          <source>The Journal of Neuroscience</source>
          <year>2004</year>
          <volume>24</volume>
          <fpage>1793</fpage>
          <lpage>802</lpage>
          <pub-id pub-id-type="pmid">14985419</pub-id>
        </element-citation>
      </ref>
      <ref id="B4">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Breiter</surname>
              <given-names>HC</given-names>
            </name>
            <name>
              <surname>Aharon</surname>
              <given-names>I</given-names>
            </name>
            <name>
              <surname>Kahneman</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Dale</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Shizgal</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Functional imaging of neural responses to expectancy and experience of monetary gains and losses</article-title>
          <source>Neuron</source>
          <year>2001</year>
          <volume>30</volume>
          <fpage>619</fpage>
          <lpage>39</lpage>
          <pub-id pub-id-type="pmid">11395019</pub-id>
        </element-citation>
      </ref>
      <ref id="B5">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Cosmides</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Tooby</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Buss</surname>
              <given-names>DM</given-names>
            </name>
          </person-group>
          <article-title>Neurocognitive adaptions designed for social exchange</article-title>
          <source>The handbook of evolutionary psychology</source>
          <year>2005</year>
          <publisher-loc>Hoboken, NJ</publisher-loc>
          <publisher-name>John Wiley &amp; Sons Inc</publisher-name>
          <fpage>584</fpage>
          <lpage>627</lpage>
        </element-citation>
      </ref>
      <ref id="B6">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Costa</surname>
              <given-names>VD</given-names>
            </name>
            <name>
              <surname>Lang</surname>
              <given-names>PJ</given-names>
            </name>
            <name>
              <surname>Sabatinelli</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>MM</given-names>
            </name>
            <name>
              <surname>Versace</surname>
              <given-names>F</given-names>
            </name>
          </person-group>
          <article-title>Emotional imagery: assessing pleasure and arousal in the brain's reward circuitry</article-title>
          <source>Human Brain Mapping</source>
          <year>2010</year>
          <volume>31</volume>
          <fpage>1446</fpage>
          <lpage>57</lpage>
          <pub-id pub-id-type="pmid">20127869</pub-id>
        </element-citation>
      </ref>
      <ref id="B7">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Craig</surname>
              <given-names>AD</given-names>
            </name>
          </person-group>
          <article-title>How do you feel? Interoception: the sense of the physiological condition of the body</article-title>
          <source>Nature Review Neuroscience</source>
          <year>2002</year>
          <volume>3</volume>
          <fpage>655</fpage>
          <lpage>66</lpage>
        </element-citation>
      </ref>
      <ref id="B8">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Delgado</surname>
              <given-names>MR</given-names>
            </name>
            <name>
              <surname>Gillis</surname>
              <given-names>MM</given-names>
            </name>
            <name>
              <surname>Phelps</surname>
              <given-names>EA</given-names>
            </name>
          </person-group>
          <article-title>Regulating the expectation of reward via cognitive strategies</article-title>
          <source>Nature Neuroscience</source>
          <year>2008</year>
          <volume>11</volume>
          <fpage>880</fpage>
          <lpage>1</lpage>
        </element-citation>
      </ref>
      <ref id="B9">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Delgado</surname>
              <given-names>MR</given-names>
            </name>
            <name>
              <surname>Nystrom</surname>
              <given-names>LE</given-names>
            </name>
            <name>
              <surname>Fissell</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Noll</surname>
              <given-names>DC</given-names>
            </name>
            <name>
              <surname>Fiez</surname>
              <given-names>JA</given-names>
            </name>
          </person-group>
          <article-title>Tracking the hemodynamic responses to reward and punishment in the striatum</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2000</year>
          <volume>84</volume>
          <fpage>3072</fpage>
          <lpage>7</lpage>
          <pub-id pub-id-type="pmid">11110834</pub-id>
        </element-citation>
      </ref>
      <ref id="B10">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Elliot</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Agnew</surname>
              <given-names>Z</given-names>
            </name>
            <name>
              <surname>Deakin</surname>
              <given-names>J.FW</given-names>
            </name>
          </person-group>
          <article-title>Hedonic and informational functions of the human orbitofrontal cortex</article-title>
          <source>Cerebral Cortex</source>
          <year>2010</year>
          <volume>20</volume>
          <fpage>198</fpage>
          <lpage>204</lpage>
          <pub-id pub-id-type="pmid">19435707</pub-id>
        </element-citation>
      </ref>
      <ref id="B11">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Evans</surname>
              <given-names>AC</given-names>
            </name>
            <name>
              <surname>Marrett</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Neelin</surname>
              <given-names>P</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Anatomical mapping of functional activation in stereotactic coordinate space</article-title>
          <source>Neuroimage</source>
          <year>1992</year>
          <volume>1</volume>
          <fpage>43</fpage>
          <lpage>53</lpage>
          <pub-id pub-id-type="pmid">9343556</pub-id>
        </element-citation>
      </ref>
      <ref id="B12">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fitzgerald</surname>
              <given-names>DA</given-names>
            </name>
            <name>
              <surname>Angstadt</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Jelsone</surname>
              <given-names>LM</given-names>
            </name>
            <name>
              <surname>Nathan</surname>
              <given-names>PJ</given-names>
            </name>
            <name>
              <surname>Phan</surname>
              <given-names>KL</given-names>
            </name>
          </person-group>
          <article-title>Beyond threat: amygdala reactivity across multiple expressions of facial affect</article-title>
          <source>Neuroimage</source>
          <year>2006</year>
          <volume>30</volume>
          <fpage>1441</fpage>
          <lpage>8</lpage>
          <pub-id pub-id-type="pmid">16368249</pub-id>
        </element-citation>
      </ref>
      <ref id="B13">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>KJ</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>WD</given-names>
            </name>
            <name>
              <surname>Glaser</surname>
              <given-names>DE</given-names>
            </name>
          </person-group>
          <article-title>Conjunction revisited</article-title>
          <source>Neuroimage</source>
          <year>2005</year>
          <volume>25</volume>
          <fpage>661</fpage>
          <lpage>7</lpage>
          <pub-id pub-id-type="pmid">15808967</pub-id>
        </element-citation>
      </ref>
      <ref id="B14">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fusar-Poli</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Placentino</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Carletti</surname>
              <given-names>F</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Laterality effect on emotional faces processing: ALE meta-analysis of evidence</article-title>
          <source>Neuroscience Letters</source>
          <year>2009</year>
          <volume>452</volume>
          <fpage>262</fpage>
          <lpage>7</lpage>
          <pub-id pub-id-type="pmid">19348735</pub-id>
        </element-citation>
      </ref>
      <ref id="B15">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gottfried</surname>
              <given-names>JA</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>RJ</given-names>
            </name>
          </person-group>
          <article-title>Encoding predictive reward value in human amygdala and orbitofrontal cortex</article-title>
          <source>Science</source>
          <year>2003</year>
          <volume>301</volume>
          <fpage>1104</fpage>
          <lpage>7</lpage>
          <pub-id pub-id-type="pmid">12934011</pub-id>
        </element-citation>
      </ref>
      <ref id="B16">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kirsch</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Schienle</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Stark</surname>
              <given-names>R</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Anticipation of reward in a nonaversive differential conditioning paradigm and the brain reward system: an event-related fMRI study</article-title>
          <source>Neuroimage</source>
          <year>2003</year>
          <volume>20</volume>
          <fpage>1086</fpage>
          <lpage>95</lpage>
          <pub-id pub-id-type="pmid">14568478</pub-id>
        </element-citation>
      </ref>
      <ref id="B17">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knutson</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>CM</given-names>
            </name>
            <name>
              <surname>Fong</surname>
              <given-names>GW</given-names>
            </name>
            <name>
              <surname>Hommer</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Anticipation of increasing monetary reward selectively recruits nucleus accumbens</article-title>
          <source>Journal of Neuroscience</source>
          <year>2001a</year>
          <volume>21</volume>
          <fpage>RC159</fpage>
          <pub-id pub-id-type="pmid">11459880</pub-id>
        </element-citation>
      </ref>
      <ref id="B18">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knutson</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Fong</surname>
              <given-names>GW</given-names>
            </name>
            <name>
              <surname>Adams</surname>
              <given-names>CM</given-names>
            </name>
            <name>
              <surname>Varner</surname>
              <given-names>JL</given-names>
            </name>
            <name>
              <surname>Hommer</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Dissociation of reward anticipation and outcome with event-related fMRI</article-title>
          <source>Neuroreport</source>
          <year>2001b</year>
          <volume>12</volume>
          <fpage>3683</fpage>
          <lpage>7</lpage>
          <pub-id pub-id-type="pmid">11726774</pub-id>
        </element-citation>
      </ref>
      <ref id="B19">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kringelbach</surname>
              <given-names>ML</given-names>
            </name>
          </person-group>
          <article-title>The human orbitofrontal cortex: Linking reward to hedonic experience</article-title>
          <source>Nature Reviews Neuroscience</source>
          <year>2005</year>
          <volume>6</volume>
          <fpage>691</fpage>
          <lpage>702</lpage>
        </element-citation>
      </ref>
      <ref id="B20">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Krumhuber</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Manstead</surname>
              <given-names>A.SR</given-names>
            </name>
            <name>
              <surname>Kappas</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Temporal aspects of facial displays in person and expression perception: the effects of smile dynamics, head-tilt, gender</article-title>
          <source>Journal of Nonverbal Behaviour</source>
          <year>2007</year>
          <volume>31</volume>
          <fpage>39</fpage>
          <lpage>56</lpage>
        </element-citation>
      </ref>
      <ref id="B21">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>LaBar</surname>
              <given-names>KS</given-names>
            </name>
            <name>
              <surname>Crupain</surname>
              <given-names>MJ</given-names>
            </name>
            <name>
              <surname>Voyvodic</surname>
              <given-names>JT</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Dynamic perception of facial affect and identity in the human brain</article-title>
          <source>Cerebral Cortex</source>
          <year>2003</year>
          <volume>13</volume>
          <fpage>1023</fpage>
          <lpage>33</lpage>
          <pub-id pub-id-type="pmid">12967919</pub-id>
        </element-citation>
      </ref>
      <ref id="B22">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>LaBar</surname>
              <given-names>KS</given-names>
            </name>
            <name>
              <surname>Gatenby</surname>
              <given-names>JC</given-names>
            </name>
            <name>
              <surname>Gore</surname>
              <given-names>JC</given-names>
            </name>
            <name>
              <surname>LeDoux</surname>
              <given-names>JE</given-names>
            </name>
            <name>
              <surname>Phelps</surname>
              <given-names>EA</given-names>
            </name>
          </person-group>
          <article-title>Human amygdala activation during conditioned fear acquisition and extinction: a mixed-trial fMRI study</article-title>
          <source>Neuron</source>
          <year>1998</year>
          <volume>20</volume>
          <fpage>937</fpage>
          <lpage>45</lpage>
          <pub-id pub-id-type="pmid">9620698</pub-id>
        </element-citation>
      </ref>
      <ref id="B23">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>LeDoux</surname>
              <given-names>JE</given-names>
            </name>
          </person-group>
          <article-title>Emotion circuits in the brain</article-title>
          <source>Annual Review of Neuroscience</source>
          <year>2000</year>
          <volume>23</volume>
          <fpage>155</fpage>
          <lpage>84</lpage>
        </element-citation>
      </ref>
      <ref id="B24">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lieberman</surname>
              <given-names>MD</given-names>
            </name>
            <name>
              <surname>Eisenberger</surname>
              <given-names>NI</given-names>
            </name>
          </person-group>
          <article-title>Pains and pleasures of social life</article-title>
          <source>Science</source>
          <year>2009</year>
          <volume>323</volume>
          <fpage>890</fpage>
          <lpage>1</lpage>
          <pub-id pub-id-type="pmid">19213907</pub-id>
        </element-citation>
      </ref>
      <ref id="B25">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maldjian</surname>
              <given-names>JA</given-names>
            </name>
            <name>
              <surname>Laurienti</surname>
              <given-names>PJ</given-names>
            </name>
            <name>
              <surname>Kraft</surname>
              <given-names>RA</given-names>
            </name>
            <name>
              <surname>Burdette</surname>
              <given-names>JH</given-names>
            </name>
          </person-group>
          <article-title>An automated method for neuroanatomic and cytoarchitectonic atlas-based interrogation of fMRI data sets</article-title>
          <source>Neuroimage</source>
          <year>2003</year>
          <volume>19</volume>
          <fpage>1233</fpage>
          <lpage>9</lpage>
          <pub-id pub-id-type="pmid">12880848</pub-id>
        </element-citation>
      </ref>
      <ref id="B26">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maren</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Neurobiology of Pavlovian fear conditioning</article-title>
          <source>Annual Review of Neuroscience</source>
          <year>2001</year>
          <volume>24</volume>
          <fpage>897</fpage>
          <lpage>931</lpage>
        </element-citation>
      </ref>
      <ref id="B27">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morris</surname>
              <given-names>JS</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>CD</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>DI</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>A differential neural response in the human amygdala to fearful and happy facial expressions</article-title>
          <source>Nature</source>
          <year>1996</year>
          <volume>383</volume>
          <fpage>812</fpage>
          <lpage>5</lpage>
          <pub-id pub-id-type="pmid">8893004</pub-id>
        </element-citation>
      </ref>
      <ref id="B28">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Moser</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Derntl</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Fink</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Gur</surname>
              <given-names>RC</given-names>
            </name>
            <name>
              <surname>Grammer</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Amygdala activation at 3T in response to human and avatar facial expressions of emotions</article-title>
          <source>Journal of Neuroscience Methods</source>
          <year>2007</year>
          <volume>161</volume>
          <fpage>126</fpage>
          <lpage>33</lpage>
          <pub-id pub-id-type="pmid">17126910</pub-id>
        </element-citation>
      </ref>
      <ref id="B29">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>M&#xFC;hlberger</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Neumann</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Wieser</surname>
              <given-names>MJ</given-names>
            </name>
            <name>
              <surname>Pauli</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>The impact of changes in spatial distance on emotional responses</article-title>
          <source>Emotion</source>
          <year>2008</year>
          <volume>8</volume>
          <fpage>192</fpage>
          <lpage>8</lpage>
          <pub-id pub-id-type="pmid">18410193</pub-id>
        </element-citation>
      </ref>
      <ref id="B30">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>M&#xFC;hlberger</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Wieser</surname>
              <given-names>MJ</given-names>
            </name>
            <name>
              <surname>Herrmann</surname>
              <given-names>MJ</given-names>
            </name>
            <name>
              <surname>Weyers</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Tr&#xF6;ger</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Pauli</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Early cortical processing of natural and artificial emotional faces differs between lower and higher social anxious persons</article-title>
          <source>Journal of Neural Transmission</source>
          <year>2009</year>
          <volume>116</volume>
          <fpage>735</fpage>
          <lpage>46</lpage>
          <pub-id pub-id-type="pmid">18784899</pub-id>
        </element-citation>
      </ref>
      <ref id="B31">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>O'Doherty</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Kringelbach</surname>
              <given-names>ML</given-names>
            </name>
            <name>
              <surname>Rolls</surname>
              <given-names>ET</given-names>
            </name>
            <name>
              <surname>Hornak</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Andrews</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>Abstract reward and punishment representations in the human orbitofrontal cortex</article-title>
          <source>Nature Neuroscience</source>
          <year>2001</year>
          <volume>4</volume>
          <fpage>95</fpage>
          <lpage>102</lpage>
        </element-citation>
      </ref>
      <ref id="B32">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>&#xD6;hman</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Face the beast and fear the face: animal and social fears as prototypes for evolutionary analyses of emotion</article-title>
          <source>Psychophysiology</source>
          <year>1986</year>
          <volume>23</volume>
          <fpage>123</fpage>
          <lpage>45</lpage>
          <pub-id pub-id-type="pmid">3704069</pub-id>
        </element-citation>
      </ref>
      <ref id="B33">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pagnoni</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Zink</surname>
              <given-names>CF</given-names>
            </name>
            <name>
              <surname>Montague</surname>
              <given-names>PR</given-names>
            </name>
            <name>
              <surname>Berns</surname>
              <given-names>GS</given-names>
            </name>
          </person-group>
          <article-title>Activity in human ventral striatum locked to errors of reward prediction</article-title>
          <source>Nat Neurosci</source>
          <year>2002</year>
          <volume>5</volume>
          <fpage>97</fpage>
          <lpage>8</lpage>
          <pub-id pub-id-type="pmid">11802175</pub-id>
        </element-citation>
      </ref>
      <ref id="B34">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Penny</surname>
              <given-names>WD</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>AP</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Frackowiak</surname>
              <given-names>RS</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>KJ</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>CD</given-names>
            </name>
          </person-group>
          <article-title>Random effects analysis</article-title>
          <source>Human Brain Function</source>
          <year>2003</year>
          <publisher-loc>London, UK</publisher-loc>
          <publisher-name>Academic Press</publisher-name>
          <fpage>843</fpage>
          <lpage>50</lpage>
        </element-citation>
      </ref>
      <ref id="B35">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Phan</surname>
              <given-names>KL</given-names>
            </name>
            <name>
              <surname>Wager</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>SF</given-names>
            </name>
            <name>
              <surname>Liberzon</surname>
              <given-names>I</given-names>
            </name>
          </person-group>
          <article-title>Functional neuroanatomy of emotion: a meta-analysis of emotion activation studies in PET and fMRI</article-title>
          <source>Neuroimage</source>
          <year>2002</year>
          <volume>16</volume>
          <fpage>331</fpage>
          <lpage>48</lpage>
          <pub-id pub-id-type="pmid">12030820</pub-id>
        </element-citation>
      </ref>
      <ref id="B36">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Phillips</surname>
              <given-names>ML</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>AW</given-names>
            </name>
            <name>
              <surname>Scott</surname>
              <given-names>SK</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Neural responses to facial and vocal expressions of fear and disgust</article-title>
          <source>Proceedings of the Royal Society B: Biological Science</source>
          <year>1998</year>
          <volume>265</volume>
          <fpage>1809</fpage>
          <lpage>17</lpage>
        </element-citation>
      </ref>
      <ref id="B37">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sabatinelli</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>MM</given-names>
            </name>
            <name>
              <surname>Lang</surname>
              <given-names>PJ</given-names>
            </name>
            <name>
              <surname>Costa</surname>
              <given-names>VD</given-names>
            </name>
            <name>
              <surname>Versace</surname>
              <given-names>F</given-names>
            </name>
          </person-group>
          <article-title>Pleasure rather than salience activates human nucleus accumbens and medial prefrontal cortex</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2007</year>
          <volume>98</volume>
          <fpage>1374</fpage>
          <lpage>9</lpage>
          <pub-id pub-id-type="pmid">17596422</pub-id>
        </element-citation>
      </ref>
      <ref id="B38">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sato</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Fujimura</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Suzuki</surname>
              <given-names>N</given-names>
            </name>
          </person-group>
          <article-title>Enhanced facial EMG activity in response to dynamic facial expressions</article-title>
          <source>International Journal of Psychophysiology</source>
          <year>2008</year>
          <volume>70</volume>
          <fpage>70</fpage>
          <lpage>4</lpage>
          <pub-id pub-id-type="pmid">18598725</pub-id>
        </element-citation>
      </ref>
      <ref id="B39">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sato</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Kochiyama</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Yoshikawa</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Naito</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Matsumura</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Enhanced neural activity in response to dynamic facial expressions of emotion: an fMRI study</article-title>
          <source>Brain Research: Cognitive Brain Research</source>
          <year>2004</year>
          <volume>20</volume>
          <fpage>81</fpage>
          <lpage>91</lpage>
          <pub-id pub-id-type="pmid">15130592</pub-id>
        </element-citation>
      </ref>
      <ref id="B40">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sato</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Yoshikawa</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Enhanced experience of emotional arousal in response to dynamic facial expressions</article-title>
          <source>Journal of Nonverbal Behaviour</source>
          <year>2007</year>
          <volume>31</volume>
          <fpage>119</fpage>
          <lpage>35</lpage>
        </element-citation>
      </ref>
      <ref id="B41">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schienle</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Stark</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Walter</surname>
              <given-names>B</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>The insula is not specifically involved in disgust processing: an fMRI study</article-title>
          <source>Neuroreport</source>
          <year>2002</year>
          <volume>13</volume>
          <fpage>2023</fpage>
          <lpage>6</lpage>
          <pub-id pub-id-type="pmid">12438918</pub-id>
        </element-citation>
      </ref>
      <ref id="B42">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sergerie</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Chochol</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Armony</surname>
              <given-names>JL</given-names>
            </name>
          </person-group>
          <article-title>The role of the amygdala in emotional processing: a quantitative meta-analysis of functional neuroimaging studies</article-title>
          <source>Neuroscience and Biobehavioral Reviews</source>
          <year>2008</year>
          <volume>32</volume>
          <fpage>811</fpage>
          <lpage>30</lpage>
          <pub-id pub-id-type="pmid">18316124</pub-id>
        </element-citation>
      </ref>
      <ref id="B43">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Setlow</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Holland</surname>
              <given-names>PC</given-names>
            </name>
            <name>
              <surname>Gallagher</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Disconnection of the basolateral amygdala complex and nucleus accumbens impairs appetitive pavlovian second-order conditioned responses</article-title>
          <source>Behavioral Neuroscience</source>
          <year>2002</year>
          <volume>116</volume>
          <fpage>267</fpage>
          <lpage>75</lpage>
          <pub-id pub-id-type="pmid">11996312</pub-id>
        </element-citation>
      </ref>
      <ref id="B44">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seymour</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Daw</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Singer</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Differential encoding of losses and gains in the human striatum</article-title>
          <source>Journal of Neuroscience</source>
          <year>2007</year>
          <volume>27</volume>
          <fpage>4826</fpage>
          <lpage>31</lpage>
          <pub-id pub-id-type="pmid">17475790</pub-id>
        </element-citation>
      </ref>
      <ref id="B45">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Solomon</surname>
              <given-names>RL</given-names>
            </name>
          </person-group>
          <article-title>The opponent-process theory of acquired motivation. The cost of pleasure and the benefit of pain</article-title>
          <source>American Psychologist</source>
          <year>1980</year>
          <volume>35</volume>
          <fpage>691</fpage>
          <lpage>712</lpage>
          <pub-id pub-id-type="pmid">7416563</pub-id>
        </element-citation>
      </ref>
      <ref id="B46">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Spreckelmeyer</surname>
              <given-names>KN</given-names>
            </name>
            <name>
              <surname>Krach</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Kohls</surname>
              <given-names>G</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Anticipation of monetary and social reward differently activates mesolimbic brain structures in men and women</article-title>
          <source>Social Cognitive and Affective Neuroscience</source>
          <year>2009</year>
          <volume>4</volume>
          <fpage>158</fpage>
          <lpage>65</lpage>
          <pub-id pub-id-type="pmid">19174537</pub-id>
        </element-citation>
      </ref>
      <ref id="B47">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tanimoto</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Heisenberg</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Gerber</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Experimental psychology: event timing turns punishment to reward</article-title>
          <source>Nature</source>
          <year>2004</year>
          <volume>430</volume>
          <fpage>983</fpage>
          <pub-id pub-id-type="pmid">15329711</pub-id>
        </element-citation>
      </ref>
      <ref id="B48">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>van der Gaag</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Minderaa</surname>
              <given-names>RB</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>The BOLD signal in the amygdala does not differentiate between dynamic facial expressions</article-title>
          <source>Social Cognitive and Affective Neuroscience</source>
          <year>2007</year>
          <volume>2</volume>
          <fpage>93</fpage>
          <lpage>103</lpage>
          <pub-id pub-id-type="pmid">18985128</pub-id>
        </element-citation>
      </ref>
      <ref id="B49">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vrticka</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Andersson</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Grandjean</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Sander</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Individual attachment style modulates human amygdala and striatum activation during social appraisal</article-title>
          <source>Plos One</source>
          <year>2008</year>
          <volume>3</volume>
          <fpage>e2868</fpage>
          <pub-id pub-id-type="pmid">18682729</pub-id>
        </element-citation>
      </ref>
      <ref id="B50">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Weyers</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>M&#xFC;hlberger</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Hefele</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Pauli</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Electromyographic responses to static and dynamic avatar emotional facial expressions</article-title>
          <source>Psychophysiology</source>
          <year>2006</year>
          <volume>43</volume>
          <fpage>450</fpage>
          <lpage>3</lpage>
          <pub-id pub-id-type="pmid">16965606</pub-id>
        </element-citation>
      </ref>
      <ref id="B51">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Whalen</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Davis</surname>
              <given-names>FC</given-names>
            </name>
            <name>
              <surname>Oler</surname>
              <given-names>JA</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>MJ</given-names>
            </name>
            <name>
              <surname>Netta</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Whalen</surname>
              <given-names>P.J.P.EA</given-names>
            </name>
          </person-group>
          <article-title>Human amygdala responses to facial expressions of emotion</article-title>
          <source>The human amygdala</source>
          <year>2009</year>
          <publisher-loc>New York, NY</publisher-loc>
          <publisher-name>Guilford Press</publisher-name>
          <fpage>265</fpage>
          <lpage>88</lpage>
        </element-citation>
      </ref>
      <ref id="B52">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Whalen</surname>
              <given-names>PJ</given-names>
            </name>
            <name>
              <surname>Rauch</surname>
              <given-names>SL</given-names>
            </name>
            <name>
              <surname>Etcoff</surname>
              <given-names>NL</given-names>
            </name>
            <name>
              <surname>McInerney</surname>
              <given-names>SC</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>MB</given-names>
            </name>
            <name>
              <surname>Jenike</surname>
              <given-names>MA</given-names>
            </name>
          </person-group>
          <article-title>Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge</article-title>
          <source>Journal of Neuroscience</source>
          <year>1998</year>
          <volume>18</volume>
          <fpage>411</fpage>
          <lpage>8</lpage>
          <pub-id pub-id-type="pmid">9412517</pub-id>
        </element-citation>
      </ref>
      <ref id="B53">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yang</surname>
              <given-names>TT</given-names>
            </name>
            <name>
              <surname>Menon</surname>
              <given-names>V</given-names>
            </name>
            <name>
              <surname>Eliez</surname>
              <given-names>S</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Amygdalar activation associated with positive and negative facial expressions</article-title>
          <source>Neuroreport</source>
          <year>2002</year>
          <volume>13</volume>
          <fpage>1737</fpage>
          <lpage>41</lpage>
          <pub-id pub-id-type="pmid">12395114</pub-id>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>
