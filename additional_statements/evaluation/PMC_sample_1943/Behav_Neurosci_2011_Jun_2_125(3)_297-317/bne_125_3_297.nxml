<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v3.0 20080202//EN" "archivearticle3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <?DTDIdentifier.IdentifierValue -//APA//DTD contentItem DTD v1.6 //EN?>
  <?DTDIdentifier.IdentifierType public?>
  <?SourceDTD.DTDName fake-contentItem.dtd?>
  <?SourceDTD.Version 1.6?>
  <?ConverterInfo.XSLTName apa2nlm.xsl?>
  <?ConverterInfo.Version 2?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Behav Neurosci</journal-id>
      <journal-title-group>
        <journal-title>Behavioral Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0735-7044</issn>
      <issn pub-type="epub">1939-0084</issn>
      <publisher>
        <publisher-name>American Psychological Association</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3129331</article-id>
      <article-id pub-id-type="pmid">21534649</article-id>
      <article-id pub-id-type="doi">10.1037/a0023575</article-id>
      <article-id pub-id-type="publisher-id">bne_125_3_297</article-id>
      <article-id pub-id-type="pii">2011-08837-001</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Special Section</subject>
          <subj-group>
            <subject>Translational Models of Prefrontal Cortical Function</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Decision Making and Reward in Frontal Cortex</article-title>
        <subtitle>Complementary Evidence From Neurophysiological and Neuropsychological Studies</subtitle>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Kennerley</surname>
            <given-names>Steven W.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Walton</surname>
            <given-names>Mark E.</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">2</xref>
        </contrib>
        <aff id="aff1"><label>1</label>Institute of Neurology, Sobell Department of Motor Neuroscience, University College London, <addr-line>London, United Kingdom</addr-line></aff>
        <aff id="aff2"><label>2</label>Department of Experimental Psychology, University of Oxford, <addr-line>Oxford, United Kingdom</addr-line></aff>
      </contrib-group>
      <author-notes>
        <corresp>Correspondence concerning this article should be addressed to <addr-line>Steven W. Kennerley, University College London, Institute of Neurology, Sobell Department of Motor Neuroscience - Box 28, Queen Square House, Queen Square, London, England, WC1N 3BG</addr-line>
E-mail: <email>s.kennerley@ion.ucl.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="ppub">
        <month>6</month>
        <year>2011</year>
      </pub-date>
      <pub-date pub-type="epub">
        <month>5</month>
        <day>2</day>
        <year>2011</year>
      </pub-date>
      <volume>125</volume>
      <issue>3</issue>
      <fpage>297</fpage>
      <lpage>317</lpage>
      <history>
        <date date-type="received">
          <day>15</day>
          <month>11</month>
          <year>2010</year>
        </date>
        <date date-type="rev-recd">
          <day>4</day>
          <month>3</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>6</day>
          <month>3</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 American Psychological Association.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>American Psychological Association</copyright-holder>
        <license license-type="open-access">
          <license-p>
This article, manuscript, or document is copyrighted by the American 
Psychological Association (APA). For non-commercial, education 
and research purposes, users may access, download, copy, display, 
and redistribute this article or manuscript as well as adapt, translate, 
or data and text mine the content contained in this document. 
For any such use of this document, appropriate attribution 
or bibliographic citation must be given. Users should not delete 
any copyright notices or disclaimers. For more information or to 
obtain permission beyond that granted here, visit 
http://www.apa.org/about/copyright.html.
</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Patients with damage to the prefrontal cortex (PFC)—especially the ventral and medial parts of PFC—often show a marked inability to make choices that meet their needs and goals. These decision-making impairments often reflect both a deficit in learning concerning the consequences of a choice, as well as deficits in the ability to adapt future choices based on experienced value of the current choice. Thus, areas of PFC must support some value computations that are necessary for optimal choice. However, recent frameworks of decision making have highlighted that optimal and adaptive decision making does not simply rest on a single computation, but a number of different value computations may be necessary. Using this framework as a guide, we summarize evidence from both lesion studies and single-neuron physiology for the representation of different value computations across PFC areas.</p>
      </abstract>
      <kwd-group>
        <kwd>reward</kwd>
        <kwd>decision making</kwd>
        <kwd>learning</kwd>
        <kwd>orbitofrontal cortex (OFC)</kwd>
        <kwd>anterior cingulate cortex (ACC)</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <p>It has been over 150 years since the case of Phineas Gage—the rail worker who suffered a traumatic accident in which an iron rod was propelled through the front of his brain—highlighted the importance of the ventral and medial parts of the prefrontal cortex in decision making. Damasio and colleagues (<xref id="cr12-1" rid="c12" ref-type="bibr">Bechara, Damasio, Damasio, &amp; Anderson, 1994</xref>; <xref id="cr31-1" rid="c31" ref-type="bibr">Damasio, 1994</xref>; <xref id="cr32-1" rid="c32" ref-type="bibr">Damasio &amp; Van Hoesen, 1983</xref>; <xref id="cr39-1" rid="c39" ref-type="bibr">Eslinger &amp; Damasio, 1985</xref>) since documented the cases of several more patients with damage similar to that of Phineas Gage—that is, to the ventromedial prefrontal cortex (VMPFC), the orbitofrontal cortex (OFC) and the peri- and subgenual anterior cingulate cortex (ACC)—and demonstrated in most cases, perhaps surprisingly, that these patients perform within the normal range in neuropsychological tests of intelligence, memory, and cognitive function. However, in real life, patients with such frontal lobe brain damage are far from normal; they live disorganized lives, tend to be impatient, vacillate when making decisions, often invest their money in risky ventures and exhibit socially inappropriate behavior (e.g., are grossly profane or indifferent to the feelings of others). In other words, their defining feature is that they consistently make poor choices.</p>
    <p>One notable finding is that these types of dramatic decision-making deficits are seldom found with damage outside of the PFC; in fact, these functions seem largely to depend on the orbital and medial parts of PFC (OFC and VMPFC) and ACC, as damage to the lateral prefrontal cortex (LPFC) does not appear to cause similar profound impairments in value-guided decisions unless correct behavior is determined by rules (<xref id="cr6-1" rid="c6" ref-type="bibr">Baxter, Gaffan, Kyriazis, &amp; Mitchell, 2008</xref>; <xref id="cr13-1" rid="c13" ref-type="bibr">Bechara, Damasio, Tranel, &amp; Anderson, 1998</xref>; <xref id="cr20-1" rid="c20" ref-type="bibr">Buckley et al., 2009</xref>; <xref id="cr40-1" rid="c40" ref-type="bibr">Fellows, 2006</xref>; <xref id="cr41-1" rid="c41" ref-type="bibr">Fellows &amp; Farah, 2003</xref>; <xref id="cr43-1" rid="c43" ref-type="bibr">Fellows &amp; Farah, 2007</xref>; <xref id="cr202-1" rid="c202" ref-type="bibr">Wheeler &amp; Fellows, 2008</xref>). This implies that we should be able to discover something fundamentally special about the functions of these three PFC areas to allow them to support appropriate decision making.</p>
    <p>Perhaps the first insight into this question came in the 1970s, when <xref id="cr101-1" rid="c101" ref-type="bibr">Niki and Watanabe (1976</xref>, <xref id="cr102-1" rid="c102" ref-type="bibr">1979</xref>) recorded from single neurons in ACC and later also in LPFC. They found that neurons in both regions were modulated by whether the animal received a reward, and some only when receiving reward in the context of a correct response. The work of Rolls and colleagues (<xref id="cr144-1" rid="c144" ref-type="bibr">Rolls, Sienkiewicz, &amp; Yaxley, 1989</xref>; <xref id="cr145-1" rid="c145" ref-type="bibr">Rolls, Yaxley, &amp; Sienkiewicz, 1990</xref>; <xref id="cr179-1" rid="c179" ref-type="bibr">Thorpe, Rolls, &amp; Maddison, 1983</xref>) began to focus on the functions of OFC in the 1980s and found evidence that neurons in this part of PFC encoded the sensory properties of reward, encoded links between stimuli and reward, and seemed to encode information about satiety state. Years later it was found that LPFC neurons not only differentiated multiple rewards, but the value scale encoded by LPFC neurons reflected the subjective reward preferences of the animal (<xref id="cr200-1" rid="c200" ref-type="bibr">Watanabe, 1996</xref>). In a similar manner, it was shown that OFC neurons encoded reward preference but that neurons here adjust their response based on the relative value of the rewards available (<xref id="cr182-1" rid="c182" ref-type="bibr">Tremblay &amp; Schultz, 1999</xref>).</p>
    <p>Still, in all of these cases, neuronal activity was recorded in the absence of any direct choice between possible outcomes of positive value (i.e., only one available option was rewarded); rather activity was correlated with conditioned stimuli that predicted rewards or with the rewards themselves. It was not until <xref id="cr167-1" rid="c167" ref-type="bibr">Shima and Tanji 1998</xref>) documented that single neurons in ACC were sensitive to reductions in reinforcement value concomitant with a change in behavioral response, that we had clear evidence of a neuronal correlate in PFC or ACC that might reflect a decision-making process. Nonetheless, at the very end of the 20th century we had evidence that single neurons in PFC encoded the value of outcomes and conveyed information about when to adapt decision making, representations which might provide a functional explanation for the decision-making deficits present in patients with ventral and medial PFC damage.</p>
    <p>However, as interest in this field grew in the 21st century, we discovered a new confounding issue; many (if not all) areas within the frontal cortex encode (to some degree) a signal that correlates with decision value. This was elegantly demonstrated by <xref id="cr134-1" rid="c134" ref-type="bibr">Roesch and Olson (2003)</xref> who recorded from multiple brain areas spanning both the prefrontal and premotor cortices and found that the encoding of reward value was most commonly found in premotor areas. What was notable about this finding was that damage to premotor cortex does not typically induce decision-making deficits per se. This emphasized that importance of having converging evidence from both correlative and interference techniques when trying to infer function. Moreover, this study highlighted that processes such as attention, arousal, motivation, or motor preparation all strongly correlate with value, meaning that it is seldom straightforward to determine whether neurons are actually encoding the subjective value of a decision or instead some other related variable (<xref id="cr137-1" rid="c137" ref-type="bibr">Roesch &amp; Olson, 2007</xref>). We now know that value signals are in fact a ubiquitous signal in the brain, evident not just in PFC areas, but also in amygdala, striatum, premotor, parietal, posterior cingulate, and visual areas to name a few (<xref id="cr92-1" rid="c92" ref-type="bibr">McCoy, Crowley, Haghighian, Dean, &amp; Platt, 2003</xref>; <xref id="cr115-1" rid="c115" ref-type="bibr">Paton, Belova, Morrison, &amp; Salzman, 2006</xref>; <xref id="cr123-1" rid="c123" ref-type="bibr">Platt &amp; Glimcher, 1999</xref>; <xref id="cr134-2" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>; <xref id="cr168-1" rid="c168" ref-type="bibr">Shuler &amp; Bear, 2006</xref>).</p>
    <p>So we are now at a new junction; neuropsychological studies suggest decision making occurs in the PFC yet neurophysiological studies implicated almost the whole brain in representing a value signal. How do we reconcile the findings from these different methodologies and how do we determine if different brain areas support specialized functions in decision-making? The strategy that we have used in the current review is to try to find converging evidence from studies using neurophysiological and neuropsychological techniques in the same frontal lobe areas to address the issue of functional specialization among PFC areas. The former has unique spatial and temporal resolution, thus allowing us to identify not only in which value is represented, but also at what time course, how it changes with learning or behavioral state, and the encoding scheme in which value is represented. This is particularly important in PFC because many neurons encode value with opposing encoding schemes that when averaged across populations of neurons (e.g., functional MRI and event-related potentials) might not be detected (cf. <xref id="cr68-1" rid="c68" ref-type="bibr">Kennerley, Dahmubed, Lara, &amp; Wallis, 2009</xref>). The latter methodology provides a powerful tool to draw causal inferences between physiology and behavior and allows us to address the question of the “functional importance” of a value representation. Indeed, as will become clear below, it is notable that restricted frontal lobe lesions often cause surprisingly selective impairments in value-based decision making, suggesting that these regions may only be required for a subset of such choices. As focal lesions of single PFC regions are relatively rare in humans, we mainly concentrate on the effects of circumscribed lesions of specific regions of ACC and OFC in animal models.</p>
    <p>Our review is necessarily not an exhaustive survey of the whole of PFC. This is partly due to the fact that we have very little evidence of the “reward” functions of some PFC areas based on neurophysiology and lesions studies. For example, there have been few recording studies to date in areas 9, 10, 14, 32, and 25 (cf. <xref id="cr19-1" rid="c19" ref-type="bibr">Bouret &amp; Richmond, 2010</xref>; <xref id="cr143-1" rid="c143" ref-type="bibr">Rolls, Inoue, &amp; Browning, 2003</xref>; <xref id="cr186-1" rid="c186" ref-type="bibr">Tsujimoto, Genovesio, &amp; Wise, 2010</xref>), sometimes for methodological reasons (<xref id="cr94-1" rid="c94" ref-type="bibr">Mitz, Tsujimoto, Maclarty, &amp; Wise, 2009</xref>), and selective lesions that include these regions are also rare (cf. <xref id="cr20-2" rid="c20" ref-type="bibr">Buckley et al., 2009</xref>; <xref id="cr122-1" rid="c122" ref-type="bibr">Piekema, Browning, &amp; Buckley, 2009</xref>). We also do not give as much attention to the neuroimaging literature as it deserves, and instead direct the interested reader toward reviews on this topic (e.g., <xref id="cr76-1" rid="c76" ref-type="bibr">Knutson &amp; Wimmer, 2007</xref>; <xref id="cr104-1" rid="c104" ref-type="bibr">O'Doherty, Hampton, &amp; Kim, 2007</xref>; <xref id="cr128-1" rid="c128" ref-type="bibr">Rangel &amp; Hare, 2010</xref>). Instead, we review ACC, LPFC, and OFC function based on single neuron electrophysiology and focal lesion studies and attempt to place these functions into recent frameworks of decision making.</p>
    <p>We use an anatomical nomenclature to help synthesize results across studies and techniques. In ACC, we largely focus on the cingulate sulcus as this is the area in which most neurophysiological recordings have taken place. There is some confusion about the classification of the more rostral aspect of the dorsal bank of the ACC sulcus, stemming partly from the fact that early anatomical diagrams labeled this region as 24c or did not include a label (<xref id="cr34-1" rid="c34" ref-type="bibr">Devinsky &amp; Lucuano, 1993</xref>; <xref id="cr37-1" rid="c37" ref-type="bibr">Dum &amp; Strick, 1996</xref>; <xref id="cr57-1" rid="c57" ref-type="bibr">He, Dum, &amp; Strick, 1995</xref>; <xref id="cr132-1" rid="c132" ref-type="bibr">Rizzolatti, Luppino, &amp; Matelli, 1996</xref>). More recent anatomical studies classify the dorsal bank of the ACC sulcus as area 9v and part of the PFC, whereas the ACC begins in the ventral bank of the cingulate sulcus and includes areas 24, 25, and 32 of the cingulate gyrus (<xref id="cr189-1" rid="c189" ref-type="bibr">Vogt, Vogt, Farber, &amp; Bush, 2005</xref>). However, we include studies that have recorded from or lesioned the dorsal bank of the cingulate sulcus in our ACC nomenclature, even though they may include parts of areas 9 and 6. For simplicity, OFC will largely be taken together as areas 11, 13, and 14, despite recent evidence that there may be functional differences between lateral OFC and medial OFC/VMPFC regions (<xref id="cr19-2" rid="c19" ref-type="bibr">Bouret &amp; Richmond, 2010</xref>; <xref id="cr103-1" rid="c103" ref-type="bibr">Noonan et al., 2010</xref>). LPFC will include studies of areas 9, 46, and 45 (<xref id="cr120-1" rid="c120" ref-type="bibr">Petrides &amp; Pandya, 2002</xref>). To aid cross-species comparisons, we use the above common nomenclature to describe studies in both primates and rodents, as there is functional and anatomical evidence that rodent OFC, infralimbic and prelimbic cortex (often termed together as medial frontal cortex), and ACC may be functionally equivalent to agranular parts of OFC (posterior parts of areas 14 and 13), subgenual ACC (area 25), rostral ACC (pregenual area 32), and dorsal ACC (dorsal area 24), respectively in primates (<xref id="cr5-1" rid="c5" ref-type="bibr">Balleine &amp; O'Doherty, 2010</xref>; <xref id="cr153-1" rid="c153" ref-type="bibr">Rushworth, Walton, Kennerley, &amp; Bannerman, 2004</xref>; <xref id="cr204-1" rid="c204" ref-type="bibr">Wise, 2008</xref>). However, it is important to note that there may not be clear homologues of primate granular frontal lobe regions in the rodent brain, many of which are the targets of lesion and recording studies that we discuss.</p>
    <sec id="S-2">
      <title>A Decision-Making Framework for Understanding Frontal Lobe Functions</title>
      <p>Many neurons in the brain are modulated by the value of an outcome. On the one hand, this is very interesting because such a signal might contribute to the process of decision making. However, which decision-making process? Many of the decisions that humans and animals face on a daily basis require a consideration of multiple-decision variables, each of which may have separate effects on the neural representation of value in a particular brain region. Even the routine decision of where to shop (or forage) for food is likely to be influenced by a number of disparate factors. First, humans and animals might evaluate their current internal state (thirst/appetite); the decision whether to expend energy foraging for food will be influenced by one's current (or future) nutrition needs. Assuming dietary resources are desired, one's choice in food might be influenced by how hungry you are (how much should I eat?), what type of food you currently prefer (which is likely to be influenced by your recent history of food choices), what your goals are (save money, eat less/healthy, explore new foraging environments), nonphysical costs associated with each food option (e.g., uncertainty of how palatable the food may be, delay before food will be obtained, potential risks), and physical costs, such as the energy that must be expended to obtain food. And the choices we make today may differ substantially from the ones we made yesterday (or tomorrow), as our current needs and goals change and as we learn from the choices we have made in the past. Thus, optimal decision making is likely to rest on a number of valuation processes and it is critical that we develop a framework of possible valuation processes so that we can begin to identify the unique functional roles different areas contribute to decision making.</p>
      <p>Recently, Rangel and colleagues (<xref id="cr127-1" rid="c127" ref-type="bibr">Rangel, Camerer, &amp; Montague, 2008</xref>; <xref id="cr128-2" rid="c128" ref-type="bibr">Rangel &amp; Hare, 2010</xref>) devised just such a framework of decision making that highlights several processes necessary for optimal goal-directed choice. First, the brain needs to represent what alternatives are available and determine the current and predicted future internal state (e.g., hunger level, subjective preference) that may inform the valuation of those alternatives. Second, given these states, the brain must then evaluate the external variables that will influence the value of the outcome (e.g., risk, probability, delay). Third, the brain needs to determine the value of the action that would obtain the different outcomes, and discount the outcome based on the expected physical costs (e.g., effort). Optimal selection would then be based on comparison of these action values. Finally, once the choice has been made the brain must compute the value of the obtained outcome. Depending on whether the obtained outcome matched the predicted value of that alternative, a prediction error signal can be generated to modify the value of the alternatives thereby ensuring that future choices are adaptive. Although some of the functions associated with ACC, LPFC and OFC cannot necessarily be ascribed to any single level in this framework (e.g., the role of OFC in reversal learning), we use this framework as a general guide to describe the specialized (or nonspecialized) contributions of ACC, LPFC, and OFC in decision-making processes. It should be noted that we are largely focusing on goal-directed types of behavior in our discussion of PFC function. However, there are likely several other influences on choices such as from habitual stimulus-response or Pavlovian associations, which we will not consider in this review (see <xref id="cr5-2" rid="c5" ref-type="bibr">Balleine &amp; O'Doherty, 2010</xref> or <xref id="cr127-2" rid="c127" ref-type="bibr">Rangel et al., 2008</xref>, for further discussion of the role of multiple-valuation systems during decision making).</p>
    </sec>
    <sec id="S-3">
      <title>Representation of Internal States</title>
      <sec id="SS1-1">
        <title>Representation of Incentive Value</title>
        <p>Arguably the starting point of any decision for an organism is an evaluation of its internal needs given the current state of the environment, as well as an evaluation of what outcomes might satisfy those needs. These parameters are present implicitly in almost all behavioral experiments as most tasks with animals and many with humans involve an element of incentive to motivate the subjects to attend and work. In the case of decision making, the requirement to use reward as a reinforcer has been exploited to allow investigators to probe i) how humans and animals make choices to satisfy internal needs, such as metabolic state, ii) how value is represented (whether outcome specific or as an abstract “cached” value) and, iii) how these parameters can be incorporated into models of the computation of value (<xref id="cr35-1" rid="c35" ref-type="bibr">Doya, 2008</xref>; <xref id="cr127-3" rid="c127" ref-type="bibr">Rangel et al., 2008</xref>). Several studies have shown that neuronal activity in OFC (<xref id="cr27-1" rid="c27" ref-type="bibr">Critchley &amp; Rolls, 1996</xref>; <xref id="cr100-1" rid="c100" ref-type="bibr">Nakano et al., 1984</xref>; <xref id="cr142-1" rid="c142" ref-type="bibr">Rolls, Critchley, Browning, Hernadi, &amp; Lenard, 1999</xref>; <xref id="cr144-2" rid="c144" ref-type="bibr">Rolls et al., 1989</xref>) and VMPFC (<xref id="cr19-3" rid="c19" ref-type="bibr">Bouret &amp; Richmond, 2010</xref>) changes as subjects become sated, possibly implemented through interactions with the lateral hypothalamus (<xref id="cr33-1" rid="c33" ref-type="bibr">de Araujo et al., 2006</xref>; <xref id="cr47-1" rid="c47" ref-type="bibr">Floyd, Price, Ferry, Keay, &amp; Bandler, 2001</xref>; <xref id="cr106-1" rid="c106" ref-type="bibr">Ongur, An, &amp; Price, 1998</xref>).</p>
        <p>The OFC is also closely connected with regions such as the anterior insula and frontal operculum that receive inputs from gustatory-responsive parts of the thalamus, and has been proposed to contain an area of secondary taste cortex in caudolateral OFC (<xref id="cr22-1" rid="c22" ref-type="bibr">Cavada, Company, Tejedor, Cruz-Rizzolo, &amp; Reinoso-Suarez, 2000</xref>; <xref id="cr145-2" rid="c145" ref-type="bibr">Rolls et al., 1990</xref>). Thus OFC is in a particularly strong anatomical position to evaluate the incentive value, or preference, of different rewards. Studies that manipulate gustatory rewards have found encoding of these rewards within OFC (<xref id="cr80-1" rid="c80" ref-type="bibr">Lara, Kennerley, &amp; Wallis, 2009</xref>; <xref id="cr140-1" rid="c140" ref-type="bibr">Rolls, 2000</xref>; <xref id="cr145-3" rid="c145" ref-type="bibr">Rolls et al., 1990</xref>), which often reflects a preference ranking of different rewards (<xref id="cr58-1" rid="c58" ref-type="bibr">Hikosaka &amp; Watanabe, 2000</xref>, <xref id="cr59-1" rid="c59" ref-type="bibr">2004</xref>; <xref id="cr182-2" rid="c182" ref-type="bibr">Tremblay &amp; Schultz, 1999</xref>) and the combination of reward preference and magnitude (<xref id="cr111-1" rid="c111" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2006</xref>, <xref id="cr112-1" rid="c112" ref-type="bibr">2008</xref>). Damage to OFC and VMPFC impairs the ability to establish relative and consistent preferences when offered novel foods (<xref id="cr10-1" rid="c10" ref-type="bibr">Baylis &amp; Gaffan, 1991</xref>), and humans with OFC and VMPFC damage show inconsistent preferences (<xref id="cr43-2" rid="c43" ref-type="bibr">Fellows &amp; Farah, 2007</xref>). Interestingly however, in a task that required the animal to remember the sensory characteristics and identity of different rewards across delays to make a subsequent discrimination (rather than use reward preference to guide decision making), we found little evidence that OFC neurons encoded reward preference (<xref id="cr80-2" rid="c80" ref-type="bibr">Lara et al., 2009</xref>). This emphasizes a common feature of PFC function; that behavioral context often influences the type of information encoded to facilitate flexible behavior (<xref id="cr71-1" rid="c71" ref-type="bibr">Kennerley &amp; Wallis, 2009c</xref>; <xref id="cr93-1" rid="c93" ref-type="bibr">Miller &amp; Cohen, 2001</xref>; <xref id="cr126-1" rid="c126" ref-type="bibr">Rainer, Asaad, &amp; Miller, 1998</xref>; <xref id="cr190-1" rid="c190" ref-type="bibr">Wallis &amp; Kennerley, 2010</xref>).</p>
        <p>Both medial and lateral parts of OFC, along with the ACC and subcortical regions such as the amygdala and ventral striatum, also seem to carry representations of the qualities of foods such as the texture, temperature, and flavor (<xref id="cr141-1" rid="c141" ref-type="bibr">Rolls, 2010</xref>). Although there is some evidence that LPFC (<xref id="cr58-2" rid="c58" ref-type="bibr">Hikosaka &amp; Watanabe, 2000</xref>; <xref id="cr200-2" rid="c200" ref-type="bibr">Watanabe, 1996</xref>) and ACC (<xref id="cr85-1" rid="c85" ref-type="bibr">Luk &amp; Wallis, 2009</xref>) neurons also encode gustatory rewards as if encoding reward preference, the OFC may have a specialized role in encoding the incentive value of a reward, especially with respect to current internal state.</p>
      </sec>
      <sec id="SS1-2">
        <title>Adaptive Coding of Incentive Value</title>
        <p>OFC therefore has a potentially rich representation of the incentive value of an anticipated outcome associated with predictive stimuli. However, given the potential range of reinforcers in a natural environment and the limited firing range of neurons (typically &lt; 50 Hz), a question then arises is how such information is encoded to allow appropriate decisions to be taken. One solution would be to have a contextually based relative valuation scale. Some OFC neurons—particularly in area 13—have been shown to adjust their firing rate to the range of values offered (<xref id="cr78-1" rid="c78" ref-type="bibr">Kobayashi, Pinto de Carvalho, &amp; Schultz, 2010</xref>; <xref id="cr110-1" rid="c110" ref-type="bibr">Padoa-Schioppa, 2009</xref>; <xref id="cr182-3" rid="c182" ref-type="bibr">Tremblay &amp; Schultz, 1999</xref>). Such adaptive coding is efficient because it allows for maximum discrimination between each distribution of possible outcomes, and it allows flexibility to encode values across decision contexts that may differ substantially in value (e.g., a choice between dinner entrees on a menu compared to a choice of what type of car to buy).</p>
        <p>However, it is also important not simply to judge value based on relative context. Interestingly, the majority of outcome sensitive OFC neurons actually do not adapt their firing rates to the range (or type) of outcomes available, instead encoding value on a fixed scale (<xref id="cr78-2" rid="c78" ref-type="bibr">Kobayashi et al., 2010</xref>; <xref id="cr112-2" rid="c112" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2008</xref>). The fact that some OFC neurons are not range adaptive and thus are invariant to the set of offers available indicates value transitivity, a key characteristic of economic choice (<xref id="cr112-3" rid="c112" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2008</xref>). Thus, as a population, OFC expresses both range adaptation and value transitivity, indicating two fundamental traits necessary for optimal choice. Although some evidence suggests that ACC neurons may adapt their firing rate depending on the distribution of values available (<xref id="cr60-1" rid="c60" ref-type="bibr">Hillman &amp; Bilkey, 2010</xref>; <xref id="cr154-1" rid="c154" ref-type="bibr">Sallet et al., 2007</xref>), reports of range adaptation in single neurons have typically focused either on OFC or areas outside of frontal cortex, such as parts of the striatum and midbrain dopaminergic nuclei (<xref id="cr28-1" rid="c28" ref-type="bibr">Cromwell, Hassani, &amp; Schultz, 2005</xref>; <xref id="cr181-1" rid="c181" ref-type="bibr">Tobler, Fiorillo, &amp; Schultz, 2005</xref>). It therefore remains an open question whether range adaptation in frontal cortex is a unique trait of OFC neurons. However, neuroimaging studies have shown relative value activation in ACC (<xref id="cr26-1" rid="c26" ref-type="bibr">Coricelli et al., 2005</xref>; <xref id="cr48-1" rid="c48" ref-type="bibr">Fujiwara, Tobler, Taira, Iijima, &amp; Tsutsui, 2009</xref>) and LPFC (<xref id="cr26-2" rid="c26" ref-type="bibr">Coricelli et al., 2005</xref>; <xref id="cr48-2" rid="c48" ref-type="bibr">Fujiwara et al., 2009</xref>; <xref id="cr84-1" rid="c84" ref-type="bibr">Lohrenz, McCabe, Camerer, &amp; Montague, 2007</xref>).</p>
      </sec>
      <sec id="SS1-3">
        <title>Updating Value Representations Through Internal State-Based Manipulations</title>
        <p>One of the cardinal tasks employed to demonstrate how changes in internal states modify the values of potential appetitive outcomes is one known as reinforcer devaluation (<xref id="cr61-1" rid="c61" ref-type="bibr">Holland &amp; Straub, 1979</xref>). Subjects are taught that one of two distinct reward types (i.e., peanuts or chocolate) is associated with particular neutral objects or can only be obtained by making particular actions. Following this training, one of the rewards is “devalued,” either by feeding of the reward to satiety or by pairing the reward with chemically induced illness. Subsequently, in a test session, subjects are presented with pairs of options, one associated with the receipt of each reward type, meaning that they have to make their decisions based on the updated values of the expected outcomes prior to re-experiencing the outcomes (i.e., the decision is goal directed). It has been suggested that this type of decision may not simply be guided by change in the incentive value of the outcome, however, but may also be influenced by the contingent link between a stimulus and a particular outcome type (<xref id="cr108-1" rid="c108" ref-type="bibr">Ostlund &amp; Balleine, 2007a</xref>).</p>
        <p>In a stimulus-based version of this task, both rats and monkeys with damage to OFC (but not to LPFC or VMPFC) continued to select the option associated with the devalued reward (<xref id="cr6-2" rid="c6" ref-type="bibr">Baxter et al., 2008</xref>; <xref id="cr7-1" rid="c7" ref-type="bibr">Baxter, Gaffan, Kyriazis, &amp; Mitchell, 2009</xref>; <xref id="cr50-1" rid="c50" ref-type="bibr">Gallagher, McMahan, &amp; Schoenbaum, 1999</xref>; <xref id="cr64-1" rid="c64" ref-type="bibr">Izquierdo, Suda, &amp; Murray, 2004</xref>; <xref id="cr121-1" rid="c121" ref-type="bibr">Pickens et al., 2003</xref>). This is true whether lesions were made prior to initial stimulus-outcome training or following training. Importantly, this impairment is only present when selecting between objects associated with the devalued reward, rather than when selecting between the two foods directly (<xref id="cr64-2" rid="c64" ref-type="bibr">Izquierdo et al., 2004</xref>). These findings suggest OFC, in conjunction with the amygdala (<xref id="cr8-1" rid="c8" ref-type="bibr">Baxter, Parker, Lindner, Izquierdo, &amp; Murray, 2000</xref>), has an important role in updating stimulus-outcome associations based on current internal state. However, it has been shown in rodents that OFC was not required for appropriate state-based decision making when choices were guided by associations with particular actions (<xref id="cr109-1" rid="c109" ref-type="bibr">Ostlund &amp; Balleine, 2007b</xref>). Instead, only lesions to prelimbic cortex affect response-based reinforcer devaluation, although only if lesions were made prior to training on the response-outcome associations and not if these associations have already been learned prior to surgery (<xref id="cr107-1" rid="c107" ref-type="bibr">Ostlund &amp; Balleine, 2005</xref>).</p>
        <p>Schoenbaum and colleagues (<xref id="cr159-1" rid="c159" ref-type="bibr">Schoenbaum, Roesch, Stalnaker, &amp; Takahashi, 2009</xref>) used such evidence, along with that from a series of their own elegant recording and interference studies in rodents, to present a strong case that the main function of OFC was to signal specific stimulus-based outcome expectancies. Without such associative representations, they argued, it was not possible to generate appropriate error signals following breaks of expectation to guide learning.</p>
      </sec>
    </sec>
    <sec id="S-4">
      <title>Representation of External Variables That Influence Outcome Value</title>
      <sec id="SS1-4">
        <title>Encoding of Decision Variables That Determine Expected Value</title>
        <p>A decision's expected value is not only based on one's internal state, but also on a number of variables that influence that value of the expected outcome. It is important to distinguish neurons that encode information about “expected” outcomes from neurons that encode information after the actual outcome has been received. The former may contribute to the process of making the current decision, whereas the latter signal may have multiple functions, which will be addressed in later sections of this review. Importantly, these two representations often occur in very close temporal proximity (i.e., &lt;1 s) around outcome onset, thus it is important to have methodological techniques that can distinguish between these two representations. Although we showed that some of the same PFC neurons encode information about decision variables (e.g., reward size) at the time of choice (i.e., prior to outcome onset) and at the time of the experienced outcome (<xref id="cr68-2" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr70-1" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>), this also is clearly not the case for many PFC neurons. Thus, it is not simply what value information is encoded (i.e., reward size) but rather when that value information is encoded (pre- or post-outcome) that reflects the type of valuation process represented by different neurons.</p>
        <p>At first glance it would appear as though there is no particular specialization within PFC for the encoding of decision value. Single neurons across most of the brain—but especially within ACC, LPFC, and OFC—are modulated by almost every decision variable investigators have used to manipulate the expected value of an outcome. Neurons in these frontal areas are sensitive to sensory cues that indicate the presence, size and/or probability of an expected positive or negative outcome (<xref id="cr2-1" rid="c2" ref-type="bibr">Amiez, Joseph, &amp; Procyk, 2006</xref>; <xref id="cr62-1" rid="c62" ref-type="bibr">Hosokawa, Kato, Inoue, &amp; Mikami, 2007</xref>; <xref id="cr68-3" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr69-1" rid="c69" ref-type="bibr">Kennerley &amp; Wallis, 2009a</xref>; <xref id="cr71-2" rid="c71" ref-type="bibr">Kennerley &amp; Wallis, 2009c</xref>; <xref id="cr77-1" rid="c77" ref-type="bibr">Kobayashi et al., 2006</xref>; <xref id="cr78-3" rid="c78" ref-type="bibr">Kobayashi et al., 2010</xref>; <xref id="cr97-1" rid="c97" ref-type="bibr">Morrison &amp; Salzman, 2009</xref>; <xref id="cr105-1" rid="c105" ref-type="bibr">O'Neill &amp; Schultz, 2010</xref>; <xref id="cr134-3" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>; <xref id="cr135-1" rid="c135" ref-type="bibr">Roesch &amp; Olson, 2004</xref>; <xref id="cr140-2" rid="c140" ref-type="bibr">Rolls, 2000</xref>; <xref id="cr154-2" rid="c154" ref-type="bibr">Sallet et al., 2007</xref>; <xref id="cr157-1" rid="c157" ref-type="bibr">Schoenbaum, Chiba, &amp; Gallagher, 1998</xref>; <xref id="cr165-1" rid="c165" ref-type="bibr">Seo &amp; Lee, 2009</xref>; <xref id="cr191-1" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>; <xref id="cr201-1" rid="c201" ref-type="bibr">Watanabe, Hikosaka, Sakagami, &amp; Shirakawa, 2002</xref>), size and temporal proximity to reward (<xref id="cr75-1" rid="c75" ref-type="bibr">Kim, Hwang, &amp; Lee, 2008</xref>; <xref id="cr136-1" rid="c136" ref-type="bibr">Roesch &amp; Olson, 2005</xref>; <xref id="cr138-1" rid="c138" ref-type="bibr">Roesch, Taylor, &amp; Schoenbaum, 2006</xref>), reward preference (<xref id="cr58-3" rid="c58" ref-type="bibr">Hikosaka &amp; Watanabe, 2000</xref>; <xref id="cr85-2" rid="c85" ref-type="bibr">Luk &amp; Wallis, 2009</xref>; <xref id="cr111-2" rid="c111" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2006</xref>, <xref id="cr112-4" rid="c112" ref-type="bibr">2008</xref>; <xref id="cr182-4" rid="c182" ref-type="bibr">Tremblay &amp; Schultz, 1999</xref>; <xref id="cr201-2" rid="c201" ref-type="bibr">Watanabe et al., 2002</xref>), effort required to harvest reward (<xref id="cr60-2" rid="c60" ref-type="bibr">Hillman &amp; Bilkey, 2010</xref>; <xref id="cr68-4" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>), and one's confidence in the choice outcome (<xref id="cr73-1" rid="c73" ref-type="bibr">Kepecs, Uchida, Zariwala, &amp; Mainen, 2008</xref>). This ubiquity of value coding across different brain areas has not only made it difficult to understand the specialized functions of different PFC areas (<xref id="cr190-2" rid="c190" ref-type="bibr">Wallis &amp; Kennerley, 2010</xref>) but also has raised speculation that value coding in some brain areas may represent other functions beyond contributing to the decision-making process.</p>
        <p>With respect to single neuron electrophysiology studies, the overlap of these signals across frontal areas highlights the difficulty in inferring functional specialization by comparing across studies. For example, neurons in ACC, LPFC, and OFC all encode reward magnitude but it is very difficult to infer a functional hierarchy by simply comparing which area has more neurons that encode reward magnitude because different investigators use different paradigms, record activity in different training or behavioral states and often use very different analytical methods.</p>
        <p>One resolution to this issue is to examine the activity of neurons in multiple-brain areas simultaneously. We (<xref id="cr68-5" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr70-2" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>) designed an experiment with the precise goal of determining whether neurons in different frontal areas exhibit preferences for encoding different variables related to a decision's value (<xref ref-type="fig" rid="fig1">Figure 1A, B</xref>). Monkeys were trained to make choices based on conditioned stimuli that indicated different behavioral outcomes that varied in terms of either reward probability, reward magnitude, or physical effort (<xref id="cr68-6" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>). We recorded from OFC, ACC, and LPFC simultaneously, thus allowing us to directly pit these three frontal areas against each other in animals in the same behavioral state using the same analytical methods. We found that neurons encoded value across the different decision variables in diverse ways. For example, some neurons encoded the value of just a single decision variable, others encoded the value of choices for two of the variables but not the third, while still others encoded value across all three decision variables (<xref ref-type="fig" rid="fig1">Figure 1C, D</xref>). We found no evidence that any of the three frontal areas were specialized for encoding any particular decision variable (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). Instead we found that ACC was significantly more likely to encode the value of any of the decision variables (<xref ref-type="fig" rid="fig1">Figure 1E</xref>), and significantly more likely to encode two or three decision variables when compared to either LPFC or OFC (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). Thus, single ACC neurons are capable of encoding the value of multiple-decision variables across trials, a type of multiplexed value representation that may allow the integration of the individual components of a decision into a common value signal (see The Encoding of Action Value section for further discussion on this topic) and underlie ACC's critical contribution to decision making.</p>
      </sec>
      <sec id="SS1-5">
        <title>Reward Modulation of Cognitive Processes</title>
        <p>Thus far we argued that the evidence from both neurophysiological and neuropsychological studies implicates both the OFC and ACC in the representation of reward to guide decision making. Although the encoding of reward in many areas is likely to reflect a role in guiding decision making, neuronal encoding of reward also may reflect a change in attentional processes, rather than reward coding per se, because one is likely to direct attention to features or locations predictive of greater reward (<xref id="cr16-1" rid="c16" ref-type="bibr">Bendiksby &amp; Platt, 2006</xref>; <xref id="cr91-1" rid="c91" ref-type="bibr">Maunsell, 2004</xref>). A possible candidate for the encoding of reward to influence attention is LPFC, as this area of PFC has a role in a number of executive control processes including working memory, strategy implementation, shifts of attention, representation of rules/categories/objects, and response inhibition among other functions (for detailed reviews, see <xref id="cr87-1" rid="c87" ref-type="bibr">Mansouri, Tanaka, &amp; Buckley, 2009</xref>; <xref id="cr93-2" rid="c93" ref-type="bibr">Miller &amp; Cohen, 2001</xref>; <xref id="cr119-1" rid="c119" ref-type="bibr">Petrides, 2005</xref>; <xref id="cr177-1" rid="c177" ref-type="bibr">Tanji &amp; Hoshi, 2008</xref>; <xref id="cr204-2" rid="c204" ref-type="bibr">Wise, 2008</xref>). However evidence from both neurophysiological and neuropsychological studies argues that rather than simply maintaining information in working memory (which could potentially be subserved by sensory areas) the crucial role of LPFC appears to be guiding attentional processes of behavioral relevance (<xref id="cr20-3" rid="c20" ref-type="bibr">Buckley et al., 2009</xref>; <xref id="cr42-1" rid="c42" ref-type="bibr">Fellows &amp; Farah, 2005</xref>; <xref id="cr81-1" rid="c81" ref-type="bibr">Lebedev, Messinger, Kralik, &amp; Wise, 2004</xref>; <xref id="cr86-1" rid="c86" ref-type="bibr">Mansouri, Buckley, &amp; Tanaka, 2007</xref>; <xref id="cr118-1" rid="c118" ref-type="bibr">Petrides, 2000</xref>; <xref id="cr152-1" rid="c152" ref-type="bibr">Rushworth, Nixon, Eacott, &amp; Passingham, 1997</xref>; <xref id="cr204-3" rid="c204" ref-type="bibr">Wise, 2008</xref>), which includes the representation of value (<xref id="cr58-4" rid="c58" ref-type="bibr">Hikosaka &amp; Watanabe, 2000</xref>; <xref id="cr75-2" rid="c75" ref-type="bibr">Kim et al., 2008</xref>; <xref id="cr134-4" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>; <xref id="cr163-1" rid="c163" ref-type="bibr">Seo, Barraclough, &amp; Lee, 2007</xref>; <xref id="cr165-2" rid="c165" ref-type="bibr">Seo &amp; Lee, 2009</xref>; <xref id="cr191-2" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>). Yet, LPFC lesions do not appear to cause severe decision-making deficits, thus it remains unclear how reward representations in LPFC contribute to goal-directed behavior.</p>
        <p>One possibility we tested is that value encoding in LPFC reflects a mechanism of prioritization of behaviorally relevant information (<xref id="cr190-3" rid="c190" ref-type="bibr">Wallis &amp; Kennerley, 2010</xref>). Our logic was twofold. First, we know that cognitive processes have capacity constraints (e.g., the limit and precision of information stored in working memory; <xref id="cr11-1" rid="c11" ref-type="bibr">Bays &amp; Husain, 2008</xref>), so there must be a mechanism by which the brain allocates these resources in an efficient and behaviorally relevant manner. Second, it is commonly known that increasing the reward/value of an outcome improves behavioral performance (<xref id="cr137-2" rid="c137" ref-type="bibr">Roesch &amp; Olson, 2007</xref>). Given LPFC neurons encode information about the direction of attention that can be held in working memory (<xref id="cr49-1" rid="c49" ref-type="bibr">Funahashi, Bruce, &amp; Goldman-Rakic, 1989</xref>; <xref id="cr81-2" rid="c81" ref-type="bibr">Lebedev et al., 2004</xref>; <xref id="cr129-1" rid="c129" ref-type="bibr">Rao, Rainer, &amp; Miller, 1997</xref>) and performance improves when a subject expects a larger reward, we reasoned that increasing reward might provide a means of directing attentional resources to effectively modulate the fidelity of goal-relevant information, thereby improving behavioral performance.</p>
        <p>To examine this, we trained monkeys to attend to spatial locations and to maintain this information in working memory (<xref id="cr69-2" rid="c69" ref-type="bibr">Kennerley &amp; Wallis, 2009a</xref>; <xref id="cr71-3" rid="c71" ref-type="bibr">Kennerley &amp; Wallis, 2009c</xref>). On each trial, a picture informed the subject how much juice they would receive for making a saccade to the remembered location. However, in one set of trials (see <xref ref-type="fig" rid="fig2">Figure 2</xref>), the reward cue was presented before the spatial cue (RS) and in the other set of trials the spatial cue was presented before the reward cue (SR), allowing us to compare the effects of reward on the spatial tuning of neurons both independently and conjointly. <xref ref-type="fig" rid="fig2">Figure 2</xref> illustrates an example of reward modulating the spatial selectivity of a LPFC neuron. We recorded from neurons in dorsolateral prefrontal cortex (DLPFC), ventrolateral prefrontal cortex (VLPFC), OFC, and ACC. Many neurons in VLPFC, OFC, and ACC (but not DLPFC) encoded reward information, but spatial information was predominantly encoded in VLPFC. Moreover, reward information was encoded earlier in OFC and VLPFC than in ACC and DLPFC, consistent with previous reports that OFC was one of the initial PFC areas to represent the rewarding value predicted by a conditioned stimulus (<xref id="cr69-3" rid="c69" ref-type="bibr">Kennerley &amp; Wallis, 2009a</xref>; <xref id="cr71-4" rid="c71" ref-type="bibr">Kennerley &amp; Wallis, 2009c</xref>; <xref id="cr191-3" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>). Importantly, although some neurons exhibited a change in spatial tuning as a function of reward, these neurons were only found in VLPFC (<xref id="cr71-5" rid="c71" ref-type="bibr">Kennerley &amp; Wallis, 2009c</xref>). This is consistent with previous reports that have failed to find strong evidence that reward shapes the direction of attention in neurons in DLPFC, frontal eye field, or premotor cortex (<xref id="cr82-1" rid="c82" ref-type="bibr">Leon &amp; Shadlen, 1999</xref>; <xref id="cr134-5" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>), although recent evidence suggests the supplementary eye field may play some role in this function (<xref id="cr170-1" rid="c170" ref-type="bibr">So &amp; Stuphorn, 2010</xref>).</p>
        <p>While only VLPFC neurons exhibited a reward-dependent modulation of spatial selectivity, the behavioral performance of the animals in the two different sets of trials indicated that the encoding of reward in VLPFC neurons reflected an attentional - rather than reward - function; larger expected reward led to increased behavioral performance and increased spatial selectivity when the reward cue was presented before the spatial cue, but decreased spatial selectivity and no improvement in performance when the reward cue was presented after the spatial cue. This suggested that the reward cue competes for limited attentional resources, interfering with ongoing spatial attention processes that are attempting to maintain the location of the peripherally presented mnemonic cue (<xref id="cr4-1" rid="c4" ref-type="bibr">Awh &amp; Jonides, 2001</xref>; <xref id="cr38-1" rid="c38" ref-type="bibr">Duncan, 2001</xref>). This interpretation of our results also is compatible with recent results from neurophysiology (<xref id="cr81-3" rid="c81" ref-type="bibr">Lebedev et al., 2004</xref>) and neuropsychology (<xref id="cr151-1" rid="c151" ref-type="bibr">Rushworth et al., 2005</xref>) studies that suggest a primary role for VLPFC in attentional control, and are consistent with the idea that VLPFC is important for the maintenance of task relevant information and the filtering of irrelevant information (<xref id="cr117-1" rid="c117" ref-type="bibr">Petrides, 1996</xref>).</p>
        <p>Reward-dependent modulation of cognitive resources is not limited to spatial attention; reward can also modulate LPFC encoding of high-level information, such as categories (<xref id="cr113-1" rid="c113" ref-type="bibr">Pan, Sawa, Tsuda, Tsukada, &amp; Sakagami, 2008</xref>). Furthermore, the modulation may be bidirectional: Attentional allocation also may modulate the reward signal based on behavioral goals. In dieters exercising self-control regarding choices involving healthy and unhealthy foods, increased LPFC activation is associated with a concomitant decrease in areas representing value information (e.g., OFC), as though LPFC is dampening the value signal (<xref id="cr54-1" rid="c54" ref-type="bibr">Hare, Camerer, &amp; Rangel, 2009</xref>).</p>
      </sec>
    </sec>
    <sec id="S-5">
      <title>The Encoding of Action Value</title>
      <sec id="SS1-6">
        <title>Representing the Action Costs of a Decision</title>
        <p>Most studies of decision making have tended to focus on variables that influence the rewarding value of an outcome, such as variables like magnitude, probability, and delay as discussed above. However, in natural environments, the distance and terrain that one might encounter in obtaining food (or traveling to work) produces energetic costs (e.g., effort), which is a critical component in optimal choice (<xref id="cr128-3" rid="c128" ref-type="bibr">Rangel &amp; Hare, 2010</xref>; <xref id="cr171-1" rid="c171" ref-type="bibr">Stephens &amp; Krebs, 1986</xref>; <xref id="cr172-1" rid="c172" ref-type="bibr">Stevens, Rosati, Ross, &amp; Hauser, 2005</xref>; <xref id="cr195-1" rid="c195" ref-type="bibr">Walton, Kennerley, Bannerman, Phillips, &amp; Rushworth, 2006</xref>). Growing evidence suggests that ACC may have a specialized role in influencing effort-based decision making. Damage to ACC biases animals toward actions that are associated with less effort even when a more rewarding option is available (<xref id="cr46-1" rid="c46" ref-type="bibr">Floresco &amp; Ghods-Sharifi, 2007</xref>; <xref id="cr162-1" rid="c162" ref-type="bibr">Schweimer &amp; Hauber, 2005</xref>; <xref id="cr192-1" rid="c192" ref-type="bibr">Walton, Bannerman, Alterescu, &amp; Rushworth, 2003</xref>; <xref id="cr193-1" rid="c193" ref-type="bibr">Walton, Bannerman, &amp; Rushworth, 2002</xref>). In contrast, OFC lesions impair delay-based decision making, but not effort-based decision making (<xref id="cr149-1" rid="c149" ref-type="bibr">Rudebeck, Walton, Smyth, Bannerman, &amp; Rushworth, 2006</xref>).</p>
        <p>Relative to reward processing, very few studies have directly manipulated physical effort while recording the activity of frontal neurons. Neurons in ACC increase their activity as monkeys work through multiple actions toward reward (<xref id="cr166-1" rid="c166" ref-type="bibr">Shidara &amp; Richmond, 2002</xref>). Although neurons in ACC are significantly more likely to encode effort than neurons in LPFC or OFC, this is also true for the reward variables as seen in <xref ref-type="fig" rid="fig1">Figure 1E</xref> (<xref id="cr68-7" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr70-3" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>). Thus, although ACC may have a specialized role in encoding effort costs, this may be part of its broader role in integrating the costs and benefits of a choice option in the determination of which action is optimal.</p>
        <p>Nonetheless, the precise role of these regions in allowing animals to overcome such costs is not yet fully understood. For example, despite the finding that when given a choice option that would minimize effort or delay, ACC and OFC lesions make animals effort- or delay-cost averse, respectively (<xref id="cr149-2" rid="c149" ref-type="bibr">Rudebeck, Walton, et al., 2006</xref>; <xref id="cr193-2" rid="c193" ref-type="bibr">Walton et al., 2002</xref>). Yet, damage to either region has no effect on an animal's basic willingness to work or tolerate delays for reward when there are no other potential rewarding alternatives, as shown by normal performance in progressive ratio tests that require animals to work progressively harder and wait progressively longer for reward (<xref id="cr8-2" rid="c8" ref-type="bibr">Baxter et al., 2000</xref>; <xref id="cr64-3" rid="c64" ref-type="bibr">Izquierdo et al., 2004</xref>; <xref id="cr116-1" rid="c116" ref-type="bibr">Pears, Parkinson, Hopewell, Everitt, &amp; Roberts, 2003</xref>). This implies that neither ACC nor OFC encodes a generalized motivational signal that drives behavior in all contexts. Instead, as we will discuss in later sections, these effects likely reflect more general roles for ACC and OFC for maintaining and updating outcome expectancies associated with either actions or stimuli respectively, especially in situations where outcomes are separated from choices either in terms of action steps or in time (<xref id="cr150-1" rid="c150" ref-type="bibr">Rushworth &amp; Behrens, 2008</xref>; <xref id="cr159-2" rid="c159" ref-type="bibr">Schoenbaum et al., 2009</xref>).</p>
      </sec>
      <sec id="SS1-7">
        <title>Integration or Specialization of Decision Variable Representations</title>
        <p>Despite the variety of decision alternatives available in any given moment, the brain must somehow determine which option best meets our current needs and goals. Although some decisions can be evaluated using objective measures along a single dimension (e.g., choosing between identical items that differ only by their price), many of the decisions humans and animals face have incommensurate consequences (e.g., should I spend my extra money on a much needed vacation, or should I spend that money on much needed home repairs). In these latter two examples there is no straightforward way to compare the outcomes because each decision is associated with very different benefits.</p>
        <p>Formal decision models suggest that the determination of an action's overall value rests on the integration of both the costs and benefits of a decision, thus generating a single value estimate for each decision alternative (<xref id="cr95-1" rid="c95" ref-type="bibr">Montague &amp; Berns, 2002</xref>; <xref id="cr128-4" rid="c128" ref-type="bibr">Rangel &amp; Hare, 2010</xref>). The product of such a calculation can be thought of as a type of neuronal currency—equivalent to net utility in economic terms—which can then be used to compare very disparate outcomes (<xref id="cr95-2" rid="c95" ref-type="bibr">Montague &amp; Berns, 2002</xref>). An abstract value signal would be computational efficient as it would allow optimal choice by simple identification of the outcome with the maximal value. However, such a system operating in isolation would make learning about individual decision variables problematic, as it would not be possible to update our estimates of the contribution of, for example, the effort costs in isolation of reward benefits, if the only signal an organism received was in terms of overall utility.</p>
        <p>Whether a brain area is capable of integrating value across decision variables is a topic of great interest. However, it is important to draw distinctions between a neuron (or voxel) that encodes two different decision variables when tested independently (or across studies) and a neuron that encodes the sum or difference of the two variables when they are assessed conjointly in the same testing session (integration). The former case can inform whether a region is capable of encoding the components necessary to form an integrated value signal, whereas only the latter case describes whether a single neuron can integrate across decision variables. Nonetheless, at the population level, we know areas of the frontal cortex—especially ACC and OFC—are particularly good candidates for representing multiple (or integrating across) decision variables because damage here impairs decisions that require a consideration of multiple decision variables (<xref id="cr2-2" rid="c2" ref-type="bibr">Amiez et al., 2006</xref>; <xref id="cr12-2" rid="c12" ref-type="bibr">Bechara et al., 1994</xref>; <xref id="cr40-2" rid="c40" ref-type="bibr">Fellows, 2006</xref>; <xref id="cr42-2" rid="c42" ref-type="bibr">Fellows &amp; Farah, 2005</xref>; <xref id="cr146-1" rid="c146" ref-type="bibr">Rudebeck et al., 2008</xref>; <xref id="cr147-1" rid="c147" ref-type="bibr">Rudebeck, Buckley, Walton, &amp; Rushworth, 2006</xref>; <xref id="cr194-1" rid="c194" ref-type="bibr">Walton, Behrens, Buckley, Rudebeck, &amp; Rushworth, 2010</xref>; <xref id="cr195-2" rid="c195" ref-type="bibr">Walton et al., 2006</xref>).</p>
        <p>At the level of single neurons, some neurons in ACC, LPFC, and OFC appear to integrate across decision variables. OFC neurons integrate reward preference and magnitude as if reflecting the economic value of the different “goods” or outcomes available (<xref id="cr111-3" rid="c111" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2006</xref>, <xref id="cr112-5" rid="c112" ref-type="bibr">2008</xref>). OFC neurons are sensitive to both reward size and delay (<xref id="cr136-2" rid="c136" ref-type="bibr">Roesch &amp; Olson, 2005</xref>) or positive and negative events (<xref id="cr62-2" rid="c62" ref-type="bibr">Hosokawa et al., 2007</xref>; <xref id="cr97-2" rid="c97" ref-type="bibr">Morrison &amp; Salzman, 2009</xref>; <xref id="cr140-3" rid="c140" ref-type="bibr">Rolls, 2000</xref>) as if coding value on a common scale. In ACC, neurons integrate both size and probability of reward (<xref id="cr2-3" rid="c2" ref-type="bibr">Amiez et al., 2006</xref>; <xref id="cr154-3" rid="c154" ref-type="bibr">Sallet et al., 2007</xref>), multiplex reward size and probability with effort cost (<xref id="cr68-8" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>) and integrate both the costs and benefits of a decision indicative of net value (<xref id="cr60-3" rid="c60" ref-type="bibr">Hillman &amp; Bilkey, 2010</xref>). Neurons in LPFC encode both positive and negative events (<xref id="cr77-2" rid="c77" ref-type="bibr">Kobayashi et al., 2006</xref>) and integrate reward and delay information to form a temporally discounted value signal (<xref id="cr75-3" rid="c75" ref-type="bibr">Kim et al., 2008</xref>).</p>
        <p>However, for some OFC neurons, variables such as size and delay to reward (<xref id="cr138-2" rid="c138" ref-type="bibr">Roesch et al., 2006</xref>), risk and reward size (<xref id="cr105-2" rid="c105" ref-type="bibr">O'Neill &amp; Schultz, 2010</xref>), or rewarding and aversive events (<xref id="cr97-3" rid="c97" ref-type="bibr">Morrison &amp; Salzman, 2009</xref>), are encoded by largely separate populations of neurons. It should be noted however that in many studies, different decision variables have been examined independently (i.e., only a single decision variable was examined within a trial). Thus, differences in the degree in which neurons encode multiple decision variables or integrate across variables might depend on the task requirements. Nonetheless, one interpretation of these results is that many OFC neurons encode individual value parameters associated with a stimulus (as opposed to an abstract value signal) because this representation is key for learning and representing why a particular decision option is valuable (see above). If so, these variable-specific neurons in OFC may have a more influential role in influencing the calculation of decision value and in updating these individual parameters following discrepancies, whereas neurons that encode an integrated representation of decision value might reflect the output of the decision process.</p>
      </sec>
      <sec id="SS1-8">
        <title>Linking Value to Action</title>
        <p>Although neurons throughout the frontal cortex encode information about the expected value of an outcome, how these neurons influence action selection clearly differentiates frontal areas. Both ACC and LPFC send projections to the premotor areas, whereas OFC receives strong sensory input but weakly connects with motor areas (<xref id="cr21-1" rid="c21" ref-type="bibr">Carmichael &amp; Price, 1995</xref>; <xref id="cr22-2" rid="c22" ref-type="bibr">Cavada et al., 2000</xref>; <xref id="cr29-1" rid="c29" ref-type="bibr">Croxson et al., 2005</xref>; <xref id="cr36-1" rid="c36" ref-type="bibr">Dum &amp; Strick, 1993</xref>; <xref id="cr198-1" rid="c198" ref-type="bibr">Wang, Shima, Isoda, Sawamura, &amp; Tanji, 2002</xref>). Consistent with this anatomy, neurophysiological studies have reported that ACC neurons tend to encode the value of the outcome and the action that led to the outcome (Figure 1E, 1G; <xref id="cr56-1" rid="c56" ref-type="bibr">Hayden &amp; Platt, 2010</xref>; <xref id="cr68-9" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr85-3" rid="c85" ref-type="bibr">Luk &amp; Wallis, 2009</xref>; <xref id="cr88-1" rid="c88" ref-type="bibr">K. Matsumoto, Suzuki, &amp; Tanaka, 2003</xref>), although studies using eye movements also have found less prominent representation of actions than in adjacent dorsomedial prefrontal structures (<xref id="cr164-1" rid="c164" ref-type="bibr">Seo &amp; Lee, 2007</xref>, <xref id="cr165-3" rid="c165" ref-type="bibr">2009</xref>; <xref id="cr170-2" rid="c170" ref-type="bibr">So &amp; Stuphorn, 2010</xref>). LPFC neurons also encode information about actions, but neurons here tend to encode associations between the stimulus and action, whereas ACC neurons preferentially encode information about the action and outcome (<xref id="cr85-4" rid="c85" ref-type="bibr">Luk &amp; Wallis, 2009</xref>; <xref id="cr88-2" rid="c88" ref-type="bibr">K. Matsumoto et al., 2003</xref>; <xref id="cr191-4" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>). In contrast, OFC neurons encode the value of sensory stimuli with little encoding of motor responses (<xref id="cr68-10" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr70-4" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>; <xref id="cr97-4" rid="c97" ref-type="bibr">Morrison &amp; Salzman, 2009</xref>; <xref id="cr111-4" rid="c111" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2006</xref>, <xref id="cr112-6" rid="c112" ref-type="bibr">2008</xref>; <xref id="cr191-5" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>). Some recent reports suggested that OFC neurons may encode action information but typically after the action has been performed and the outcome is experienced (<xref id="cr19-4" rid="c19" ref-type="bibr">Bouret &amp; Richmond, 2010</xref>; <xref id="cr185-1" rid="c185" ref-type="bibr">Tsujimoto, Genovesio, &amp; Wise, 2009</xref>).</p>
        <p>Few electrophysiology experiments to date have manipulated only an action's value. However, there is evidence that ACC neurons detect changes in action value—or how preferable one action is relative to another—to directly influence adaptive action selection, but show less sensitivity to changes in value cued by nonappetitive sensory stimuli (<xref id="cr85-5" rid="c85" ref-type="bibr">Luk &amp; Wallis, 2009</xref>; <xref id="cr90-1" rid="c90" ref-type="bibr">M. Matsumoto, Matsumoto, Abe, &amp; Tanaka, 2007</xref>; <xref id="cr167-2" rid="c167" ref-type="bibr">Shima &amp; Tanji, 1998</xref>).</p>
      </sec>
    </sec>
    <sec id="S-6">
      <title>The Comparison of Action Values: Making a Choice</title>
      <p>It may seem, after the computation of stimulus and action values, that the process of making a decision itself should be relatively straightforward, requiring a simple comparison of the different integrated values of the available alternatives. However, the role of frontal cortex neurons in allowing certain choices to be made is arguably the least well-understood component of decision making. As discussed above, there are multiple influences on the value of an option, any of which might be influenced by external factors such as rules or attention. Decision making is also not simply a read out of current action values, but instead is a stochastic process that likely uses something equivalent to a logistic function to translate between available options and a selected response (<xref id="cr128-5" rid="c128" ref-type="bibr">Rangel &amp; Hare, 2010</xref>; <xref id="cr175-1" rid="c175" ref-type="bibr">Sutton &amp; Barto, 1998</xref>). In some situations, it may not directly require a comparison of action values at all, actions instead being chosen via a decision policy (<xref id="cr45-1" rid="c45" ref-type="bibr">Fleming, Thomas, &amp; Dolan, 2010</xref>). Moreover, it is sometimes not clear at what point a particular decision is made, given that the evidence for a particular choice can be accumulated over a relatively large number of trials and long time periods. There is increasing evidence that persistent activity between and across trials may be important for choice behavior (<xref id="cr30-1" rid="c30" ref-type="bibr">Curtis &amp; Lee, 2010</xref>).</p>
      <p>It has been argued that of all the frontal lobe regions, LPFC is best placed to control and implement choice behavior through its connections with parietal and premotor cortices as well as with OFC and ACC (<xref id="cr67-1" rid="c67" ref-type="bibr">Kable &amp; Glimcher, 2009</xref>). Some directionally tuned cells in LPFC have been shown to dynamically increase their firing rates during choices based on the integrated value of a target presented within their preferred direction (<xref id="cr75-4" rid="c75" ref-type="bibr">Kim et al., 2008</xref>). Electrophysiology studies have reported chosen value signals in OFC (<xref id="cr73-2" rid="c73" ref-type="bibr">Kepecs et al., 2008</xref>; <xref id="cr111-5" rid="c111" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2006</xref>; <xref id="cr174-1" rid="c174" ref-type="bibr">Sul, Kim, Huh, Lee, &amp; Jung, 2010</xref>). Again, however, whether such signals reflect the process of a decision or the readout from a comparison process made elsewhere is a matter of debate.</p>
      <p>Given the range of possible contributing sources of evidence to be considered during a decision, one potentially important function of the frontal lobe would be to focus attention on the variables pertinent to the current decision. Patients with large lesions encompassing OFC and VMPFC alter the way in which they choose to acquire information when making complex decisions, making them prefer to compare all the attributes of a single available option (in this case, an apartment) rather than evaluating across all available options on an selected set of attributes (for instance, the price or number of bedrooms; <xref id="cr40-3" rid="c40" ref-type="bibr">Fellows, 2006</xref>). Recently, Noonan and colleagues (<xref id="cr103-2" rid="c103" ref-type="bibr">Noonan et al., 2010</xref>) showed that monkeys with selective medial OFC lesions failed to choose the highest value option in a three-armed bandit decision making task when the value of the next best option was itself much greater than value of the worst option. One interpretation of these data is that medial OFC is required to focus attention on the relevant variables prior to making a decision.</p>
      <p>There have been a number of influential theoretical models to explain how response selection might occur. These models typically describe a process by which sensory information about potential actions “accumulate” and potentially compete until a “threshold” is reached, at which point a response is selected (<xref id="cr14-1" rid="c14" ref-type="bibr">Beck et al., 2008</xref>; <xref id="cr18-1" rid="c18" ref-type="bibr">Bogacz, 2007</xref>; <xref id="cr23-1" rid="c23" ref-type="bibr">Cisek, 2007</xref>; <xref id="cr25-1" rid="c25" ref-type="bibr">Cisek, Puskas, &amp; El-Murr, 2009</xref>; <xref id="cr52-1" rid="c52" ref-type="bibr">Gold &amp; Shadlen, 2002</xref>; <xref id="cr79-1" rid="c79" ref-type="bibr">Krajbich, Armel, &amp; Rangel, 2010</xref>; <xref id="cr131-1" rid="c131" ref-type="bibr">Ratcliff &amp; McKoon, 2008</xref>; <xref id="cr188-1" rid="c188" ref-type="bibr">Usher &amp; McClelland, 2001</xref>; <xref id="cr197-1" rid="c197" ref-type="bibr">Wang, 2008</xref>). These models often explain the firing patterns of neurons in the superior colliculus (<xref id="cr98-1" rid="c98" ref-type="bibr">Munoz &amp; Wurtz, 1995</xref>; <xref id="cr130-1" rid="c130" ref-type="bibr">Ratcliff, Hasegawa, Hasegawa, Smith, &amp; Segraves, 2007</xref>), the lateral intraparietal area (<xref id="cr83-1" rid="c83" ref-type="bibr">Leon &amp; Shadlen, 2003</xref>; <xref id="cr139-1" rid="c139" ref-type="bibr">Roitman &amp; Shadlen, 2002</xref>), the frontal eye fields (<xref id="cr51-1" rid="c51" ref-type="bibr">Gold &amp; Shadlen, 2000</xref>; <xref id="cr53-1" rid="c53" ref-type="bibr">Gold &amp; Shadlen, 2003</xref>), the dorsal premotor cortex (<xref id="cr24-1" rid="c24" ref-type="bibr">Cisek &amp; Kalaska, 2005</xref>), and the LPFC (<xref id="cr74-1" rid="c74" ref-type="bibr">Kim &amp; Shadlen, 1999</xref>).</p>
      <p>However, in most cases, these models account for patterns of activity in neurons which have defined receptive fields; in other words, where the value of a decision is coded in an action frame of reference. In contrast, as we described earlier, many neurons in PFC encode aspects of decision value that are independent of an action frame of reference, such as current motivational state or preference for particular rewards. Moreover, even when particular actions are associated with different value parameters (e.g., magnitude of reward), many neurons in ACC, LPFC, and OFC encode the value parameter without encoding any information about the response, as if value is coded in “goods” rather than “action” space (<xref id="cr68-11" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr69-4" rid="c69" ref-type="bibr">Kennerley &amp; Wallis, 2009a</xref>; <xref id="cr111-6" rid="c111" ref-type="bibr">Padoa-Schioppa &amp; Assad, 2006</xref>, <xref id="cr112-7" rid="c112" ref-type="bibr">2008</xref>; <xref id="cr165-4" rid="c165" ref-type="bibr">Seo &amp; Lee, 2009</xref>; <xref id="cr191-6" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>). Thus value coding in many PFC neurons lacks a clear frame of reference for which to bias action selection. It therefore remains a challenge to develop theoretical models to explain precisely how effector independent value representations in areas like OFC and ACC ultimately bias the accumulation of evidence in favor of selecting a particular action.</p>
    </sec>
    <sec id="S-7">
      <title>The Encoding of Experienced Outcomes</title>
      <sec id="SS1-9">
        <title>The Encoding of Outcome Value</title>
        <p>Within the frontal cortex, neurons are particularly sensitive to the experienced outcome of a choice. Neurons in ACC, LPFC, and OFC are modulated by the presence and absence of reward or to unexpected outcomes (<xref id="cr1-1" rid="c1" ref-type="bibr">Amiez, Joseph, &amp; Procyk, 2005</xref>; <xref id="cr63-1" rid="c63" ref-type="bibr">Ito, Stuphorn, Brown, &amp; Schall, 2003</xref>; <xref id="cr70-5" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>; <xref id="cr102-2" rid="c102" ref-type="bibr">Niki &amp; Watanabe, 1979</xref>; <xref id="cr125-1" rid="c125" ref-type="bibr">Quilodran, Rothe, &amp; Procyk, 2008</xref>; <xref id="cr154-4" rid="c154" ref-type="bibr">Sallet et al., 2007</xref>; <xref id="cr163-2" rid="c163" ref-type="bibr">Seo et al., 2007</xref>; <xref id="cr164-2" rid="c164" ref-type="bibr">Seo &amp; Lee, 2007</xref>; <xref id="cr165-5" rid="c165" ref-type="bibr">Seo &amp; Lee, 2009</xref>; <xref id="cr169-1" rid="c169" ref-type="bibr">Simmons &amp; Richmond, 2008</xref>; <xref id="cr184-1" rid="c184" ref-type="bibr">Tremblay &amp; Schultz, 2000b</xref>; <xref id="cr199-1" rid="c199" ref-type="bibr">Watanabe, 1989</xref>; <xref id="cr201-3" rid="c201" ref-type="bibr">Watanabe et al., 2002</xref>) and by the experience of different magnitudes or types of outcomes (<xref id="cr2-4" rid="c2" ref-type="bibr">Amiez et al., 2006</xref>; <xref id="cr58-5" rid="c58" ref-type="bibr">Hikosaka &amp; Watanabe, 2000</xref>; <xref id="cr70-6" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>; <xref id="cr138-3" rid="c138" ref-type="bibr">Roesch et al., 2006</xref>; <xref id="cr140-4" rid="c140" ref-type="bibr">Rolls, 2000</xref>; <xref id="cr145-4" rid="c145" ref-type="bibr">Rolls et al., 1990</xref>; <xref id="cr182-5" rid="c182" ref-type="bibr">Tremblay &amp; Schultz, 1999</xref>; <xref id="cr200-3" rid="c200" ref-type="bibr">Watanabe, 1996</xref>).</p>
        <p>We examined neuronal activity at the time of outcome in our multivariate choice task and found that many frontal neurons encoded reward presence, especially in ACC, in which approximately 60% of ACC neurons differentiated whether a trial was rewarded (<xref id="cr70-7" rid="c70" ref-type="bibr">Kennerley &amp; Wallis, 2009b</xref>). However, we found no evidence that ACC neurons were simply detecting errors because an approximately equal number of neurons increased firing rate based on reward presence as increased firing rate to reward absence; rather, ACC neurons appeared to be encoding the value of the outcome. Although we also found evidence that frontal neurons encoded reward prediction errors (see below), the encoding of reward presence/absence was much more common, as has been reported in other studies (<xref id="cr2-5" rid="c2" ref-type="bibr">Amiez et al., 2006</xref>; <xref id="cr90-2" rid="c90" ref-type="bibr">M. Matsumoto et al., 2007</xref>; <xref id="cr164-3" rid="c164" ref-type="bibr">Seo &amp; Lee, 2007</xref>). Moreover, our results also suggest that an explanation of outcome activity solely in terms of expectancy violation or error monitoring is overly simplistic. Many of the neurons that responded to the presence/absence of the reward encoded other aspects of the outcome, such as the magnitude of the reward and the physical effort necessary to earn the reward. This suggests that for many frontal neurons, their role in outcome evaluation generalizes across different types of outcomes rather than being specific to monitoring for the presence of reward or errors. Thus, frontal neurons contain a particularly rich representation of the behavioral outcome that is not necessarily simply related to the received reward, but also why the reward is valuable.</p>
        <p>Outcome information can also serve as feedback about the relevance of a response or as a cue to guide future decisions. Neurons in several frontal lobe regions are sensitive to feedback indicating when a change in response is necessary to obtain a reward or avoid reward omission (<xref id="cr66-1" rid="c66" ref-type="bibr">Johnston, Levin, Koval, &amp; Everling, 2007</xref>; <xref id="cr86-2" rid="c86" ref-type="bibr">Mansouri et al., 2007</xref>; <xref id="cr88-3" rid="c88" ref-type="bibr">K. Matsumoto et al., 2003</xref>; <xref id="cr191-7" rid="c191" ref-type="bibr">Wallis &amp; Miller, 2003</xref>). In fact, in the majority of animal neuroscience tasks, outcome value directly informs subsequent responding, meaning that the contribution of the value of a received outcome and information obtained from such feedback cannot be dissociated. One exception to this came in a series of studies employing a instructed strategy task in which a cue on each trial instructed the animal whether to switch from its previous required response and therefore could not be solved using a reward-stay/no reward-shift strategy (<xref id="cr185-2" rid="c185" ref-type="bibr">Tsujimoto et al., 2009</xref>; <xref id="cr186-2" rid="c186" ref-type="bibr">Tsujimoto et al., 2010</xref>). At the time of the outcome, LPFC neurons encoded both the response and whether it was rewarded, but OFC neurons only carried information about what response had been chosen (<xref id="cr185-3" rid="c185" ref-type="bibr">Tsujimoto et al., 2009</xref>). Such signals in OFC therefore appear not to be representing outcome value per se, but instead a signal to indicate the appropriateness of a choice.</p>
      </sec>
    </sec>
    <sec id="S-8">
      <title>Adaptive Decision Making</title>
      <sec id="SS1-10">
        <title>Reward Prediction Errors</title>
        <p>Dopamine neurons in the ventral tegmental area and substantia nigra have been suggested to encode a prediction error, which is the discrepancy between a predicted and actual outcome (<xref id="cr9-1" rid="c9" ref-type="bibr">Bayer &amp; Glimcher, 2005</xref>; <xref id="cr44-1" rid="c44" ref-type="bibr">Fiorillo, Tobler, &amp; Schultz, 2003</xref>; <xref id="cr89-1" rid="c89" ref-type="bibr">M. Matsumoto &amp; Hikosaka, 2009</xref>; <xref id="cr96-1" rid="c96" ref-type="bibr">Montague, Dayan, &amp; Sejnowski, 1996</xref>; <xref id="cr133-1" rid="c133" ref-type="bibr">Roesch, Calu, &amp; Schoenbaum, 2007</xref>; <xref id="cr155-1" rid="c155" ref-type="bibr">Satoh, Nakai, Sato, &amp; Kimura, 2003</xref>; <xref id="cr161-1" rid="c161" ref-type="bibr">Schultz, Dayan, &amp; Montague, 1997</xref>; <xref id="cr181-2" rid="c181" ref-type="bibr">Tobler et al., 2005</xref>). The frontal cortex is a major recipient of dopaminergic input (<xref id="cr17-1" rid="c17" ref-type="bibr">Berger, Trottier, Verney, Gaspar, &amp; Alvarez, 1988</xref>; <xref id="cr203-1" rid="c203" ref-type="bibr">Williams &amp; Goldman-Rakic, 1998</xref>), and several studies have shown that neurons in PFC, especially within ACC, encode a type of reward prediction error signal, although not necessarily qualitatively identical to the signal evident in dopamine neurons. For example, in a task in which monkeys have to learn which of two actions is the correct (rewarded) action within a block of trials, many ACC (but fewer LPFC) neurons responded to either positive or negative feedback, especially on the first trial of a block (when the feedback is particularly instructive as to which action to select on subsequent trials). In some neurons, the magnitude of the neuronal response to positive feedback decreased over the next few trials (as the animal learned which action would be rewarded) in correlation with decreases in the prediction error (<xref id="cr90-3" rid="c90" ref-type="bibr">M. Matsumoto et al., 2007</xref>). Yet, although neurons in ACC encode a reward prediction error signal, positive and negative prediction errors seem to be encoded by largely separate populations of neurons. Other studies have identified neuronal activity in ACC that resembles a prediction error (<xref id="cr1-2" rid="c1" ref-type="bibr">Amiez et al., 2005</xref>; <xref id="cr164-4" rid="c164" ref-type="bibr">Seo &amp; Lee, 2007</xref>).</p>
        <p>In contrast, most neurons in OFC do not exhibit a prediction error signal. Instead, OFC neurons signal expected outcomes, as OFC neurons exhibit the same response at the time of outcome to both expected rewards or omitted rewards, and do not exhibit a larger response (relative to an expected reward) to unexpected rewards, thus being qualitatively different to the prediction error signal evident in dopamine neurons (<xref id="cr159-3" rid="c159" ref-type="bibr">Schoenbaum et al., 2009</xref>; <xref id="cr160-1" rid="c160" ref-type="bibr">Schoenbaum, Setlow, Saddoris, &amp; Gallagher, 2003</xref>; <xref id="cr176-1" rid="c176" ref-type="bibr">Takahashi et al., 2009</xref>), although there is some disagreement in the literature (<xref id="cr174-2" rid="c174" ref-type="bibr">Sul et al., 2010</xref>).</p>
        <p>We examined the activity of neurons in ACC, OFC, and LPFC at the time when animals viewed a conditioned stimulus that indicated the probability of receiving a reward, as well as at the time of the outcome. We found that reward prediction error activity was evident only in ACC (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), but that positive prediction errors (response on rewarded trials; <xref ref-type="fig" rid="fig3">Figure 3A</xref>) were more common than negative prediction errors (response on nonrewarded trials; <xref ref-type="fig" rid="fig3">Figure 3C</xref>). We also showed that focal ACC lesions caused reward-based, but not error-based, learning and decision-making impairments (<xref id="cr72-1" rid="c72" ref-type="bibr">Kennerley, Walton, Behrens, Buckley, &amp; Rushworth, 2006</xref>), consistent with a functional link between dopamine and ACC for learning from positive prediction errors. Moreover, the negative prediction error activity rarely took the form of a depression of activity from baseline (e.g., <xref ref-type="fig" rid="fig3">Figure 3B</xref>), as has been reported in dopamine neurons (<xref id="cr44-2" rid="c44" ref-type="bibr">Fiorillo et al., 2003</xref>; <xref id="cr161-2" rid="c161" ref-type="bibr">Schultz et al., 1997</xref>). However this finding may be attributable to the fact that PFC neurons have heterogeneous baseline firing rates that are typically lower than half of the dynamic range of the neuron, thus it can be more difficult to detect a significant effect encoded by a depression from baseline firing rate (compared to excitation from baseline firing rate) simply because the range between baseline and minimum firing rate is often much smaller than the range between baseline and maximum firing rate. In sum, although some PFC neurons—especially in ACC—encode the difference between expected and actual reward, this prediction error activity tends to be qualitatively different than what is evident in dopamine neurons.</p>
      </sec>
      <sec id="SS1-11">
        <title>Learning From Outcomes and the Guidance of Subsequent Choices</title>
        <p>To be able to survive in a changeable world, animals need to be able not only to keep track of whether expected outcomes were received, but also then to use this information to decide whether to persist with the current response or adjust their behavior accordingly. One of the most long-standing and oft-replicated findings is that frontal lobe lesions can cause a variety of behavioral problems when it is necessary to update response rules, alter attentional focus, change associations, or explore alternative options. Although LPFC has been more commonly associated with situations in which a change in context is explicitly cued (<xref id="cr3-1" rid="c3" ref-type="bibr">Aron, Robbins, &amp; Poldrack, 2004</xref>; <xref id="cr173-1" rid="c173" ref-type="bibr">Stuss et al., 2000</xref>), parts of OFC, VMPFC, and ACC appear particularly important when changes in outcome signal a requirement to switch behavior (see reviews in <xref id="cr99-1" rid="c99" ref-type="bibr">Murray, O'Doherty, &amp; Schoenbaum, 2007</xref>; <xref id="cr196-1" rid="c196" ref-type="bibr">Walton, Rudebeck, Behrens, &amp; Rushworth, 2011</xref>).</p>
        <p>The most commonly used task to probe this type of flexible decision making has been reward-guided reversal learning (<xref ref-type="fig" rid="fig4">Figure 4A, B</xref>). Typically in such tasks, subjects choose between two options, only one of which is consistently rewarded. However, at certain points during a session once the rewarded option is being reliably selected, the reward contingencies are reversed so that subjects have to switch to select the alternative option to continue to gain rewards. Importantly, no other cues are presented other than the receipt or absence of reward to signal when to switch between options to guide appropriate behavior.</p>
        <p>As observed with previous tasks, it seems that the nature of the value representation affects the regions implicated in these types of behavior. Rudebeck and colleagues (<xref id="cr64-4" rid="c64" ref-type="bibr">Izquierdo et al., 2004</xref>; <xref id="cr148-1" rid="c148" ref-type="bibr">Rudebeck &amp; Murray, 2008</xref>) found that animals with OFC lesions, who in previous studies had been shown to be impaired on a stimulus reversal task when associations between visual stimuli and reward changed, were just as able as control animals at updating their choices on a comparable joystick-based response reversal task, in which behavior was guided by associations between instrumental actions and reward (<xref id="cr146-2" rid="c146" ref-type="bibr">Rudebeck et al., 2008</xref>). This suggests that the OFC is not required to detect and respond to changes in reinforcement generally, but instead is needed when there is a requirement to update stimulus-reward associations. Conversely, ACC sulcus lesions impair instrumental reversals but do not affect the speed of reversal on a stimulus-based version of the task as measured by the number of errors made prior to reaching a behavioral criterion (though see below for subtle effects on performance based on reinforcement history). A similar double dissociation between the effects of OFC and ACC lesions has been observed in stimulus- and action-based dynamic matching tasks respectively (<xref id="cr72-2" rid="c72" ref-type="bibr">Kennerley et al., 2006</xref>; <xref id="cr146-3" rid="c146" ref-type="bibr">Rudebeck et al., 2008</xref>). Taken together, these findings reinforce the notion that the OFC and ACC play vital roles not merely when reward contingencies change but during all types of choice-outcome associative learning.</p>
        <p>Reversal tasks have been important tools for allowing investigation of flexible behavior. Although they could simply be solved using a win-stay, lose-switch strategy, animals nonetheless appear to weigh the receipt or absence of reward as a piece of evidence in an uncertain environment favoring one response option or an alternative. The importance of this becomes clear when examining OFC- or ACC-lesioned animals' performance as a function of their recent history of reinforcement following a change in reward contingencies (<xref id="cr64-5" rid="c64" ref-type="bibr">Izquierdo et al., 2004</xref>; <xref id="cr72-3" rid="c72" ref-type="bibr">Kennerley et al., 2006</xref>; <xref id="cr99-2" rid="c99" ref-type="bibr">Murray et al., 2007</xref>; <xref id="cr146-4" rid="c146" ref-type="bibr">Rudebeck et al., 2008</xref>; <xref id="cr148-2" rid="c148" ref-type="bibr">Rudebeck &amp; Murray, 2008</xref>; see <xref ref-type="fig" rid="fig4">Figure 4</xref>). Normal subjects show an increased likelihood of continuing to choose the correct option as they gather more rewards for the now correct response. Both OFC- and ACC sulcus-lesioned animals, by contrast, have a marked impairment in persisting with the correct response during a stimulus- or action-based reversal task, respectively, failing to continue to select the currently rewarded option at the same rate as control animals after having received several rewards for such selections (<xref ref-type="fig" rid="fig4">Figure 4C, 4F</xref>). Nonetheless, both sets of animals do show an initial increased tendency to switch to the rewarded option following a reversal, demonstrating that they are not entirely insensitive to errors or changes in reward information.</p>
        <p>These results may at first seem at odds with the previous discussion of the prevalence of ACC value encoding in stimulus-based decision tasks (e.g., <xref ref-type="fig" rid="fig1">Figure 1</xref>). Although there may be a clear functional bias for OFC and ACC being specialized for decisions based on value assignments with stimuli and actions, respectively, ACC-lesioned animals are also shown to be initially less willing to persist with a correct response even on a stimulus-based task (<xref ref-type="fig" rid="fig4">Figure 4e</xref>). Inactivation of ACC also has been shown to disrupt learning about stimulus-outcome associations (<xref id="cr2-6" rid="c2" ref-type="bibr">Amiez et al., 2006</xref>). However, the effect here following ACC lesions is qualitatively different to that seen on the action-based reversal task or in OFC-lesioned animals as they behave comparably to controls after making more than three correct responses. This might relate to the importance of ACC for representing the volatility of the reward environment, which suggests that ACC may play a general role in dictating how much influence individual outcomes should be given to guide adaptive behavior and how much effort might need to be expended to gain new information (<xref id="cr15-1" rid="c15" ref-type="bibr">Behrens, Woolrich, Walton, &amp; Rushworth, 2007</xref>; <xref id="cr65-1" rid="c65" ref-type="bibr">Jocham, Neumann, Klein, Danielmeier, &amp; Ullsperger, 2009</xref>). In contrast, there is little evidence to date that OFC damage causes action-based decision-making impairments.</p>
      </sec>
      <sec id="SS1-12">
        <title>Multiple Learning Systems and Credit Assignment</title>
        <p>It has been known for many years that there are many parallel learning systems in the brain. In complex situations in which there are multiple stimuli and outcome possibilities and when the precise spatial and temporal structure of the environment is unknown, it may not be possible to rely on a system that requires contingent predictions to drive learning (“credit assignment” problem). <xref id="cr178-1" rid="c178" ref-type="bibr">Thorndike (1933)</xref> described such a system that would assign the weight of influence of an outcome not only to immediately preceding choices that led to that outcome, but also temporally contiguous choices made in the recent past or even closely following this outcome (“spread-of-effect”). However, although such a learning system may be adequate in situations in which choice and/or reward histories are relatively uniform, in rapidly changeable or low reward yielding environments in which such conditions are not met, the mixed pattern of choice and reward histories will compromise the accuracy of such stimulus value approximations, resulting in a specific pattern of behavioral impairments. Although some prefrontal cells are tuned for specific choice-outcome conjunctions (<xref id="cr165-6" rid="c165" ref-type="bibr">Seo &amp; Lee, 2009</xref>; <xref id="cr187-1" rid="c187" ref-type="bibr">Uchida, Lu, Ohmae, Takahashi, &amp; Kitazawa, 2007</xref>) and others encode an extended history of past choices or outcomes (<xref id="cr163-3" rid="c163" ref-type="bibr">Seo et al., 2007</xref>; <xref id="cr164-5" rid="c164" ref-type="bibr">Seo &amp; Lee, 2007</xref>, <xref id="cr165-7" rid="c165" ref-type="bibr">2009</xref>; <xref id="cr174-3" rid="c174" ref-type="bibr">Sul et al., 2010</xref>), little is known about which type of learning might be performed by such neurons.</p>
        <p>To investigate the role of OFC in guiding different learning systems in complex, changeable environments, Walton, Rudebeck, and colleagues (<xref id="cr146-5" rid="c146" ref-type="bibr">Rudebeck et al., 2008</xref>; <xref id="cr194-2" rid="c194" ref-type="bibr">Walton et al., 2010</xref>) tested macaque monkeys on a series of changeable three-armed bandit tasks, in which fluctuations in outcome value associated with each stimulus could change dynamically over the course of the session so that at some points in the session, the identity of the most highly rewarding option also changed. Following OFC lesions, the animals were markedly impaired when a change in stimulus value occurred in synchrony with a change in the identity of the highest rewarding stimulus (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Nonetheless, these same animals were just as able as controls to flexibly track local changes in reward likelihood of the currently chosen option when the identity of the highest rewarding stimulus stayed the same (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p>
        <p>To probe the influence of different learning strategies, we performed a multiple logistic regression, which examined the weight of influence of all possible combinations of recent choices and outcomes on current behavior across multiple changeable three-armed bandit tasks (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Normal animals' choices were dominated by appropriate contingent associations between the stimuli that they had selected and the outcomes they received for each of those choices. By contrast, OFC lesions profoundly reduced the ability of specific recent associations to guide behavior while leaving intact the influence based on associations between the integrated recent history of choices and recent history of outcomes. The latter spread-of-effect was no greater than in the normal animals, suggesting that the resultant change in behavior following the lesion was not caused by functional compensation but instead by the unmasking of an existing learning system, the influence of which is usually dwarfed by a mechanism to make specific contingent choice-reward associations.</p>
        <p>One interpretation of these results is that OFC is primarily a system to allow rapid learning about the contingent relationships between stimuli and outcomes. In this light, encoding of stimulus identity and value might be considered as important not simply for the guidance of decisions but also for supporting appropriate credit assignment when there are multiple possible causes for a particular outcome. From this perspective, OFC might be less involved when decisions are made between stimuli with well-learned value associations. This is consistent with the finding that there are a smaller proportion of OFC neurons than in other frontal areas which encode value when decisions are made between well-learned stimuli (<xref id="cr68-12" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr69-5" rid="c69" ref-type="bibr">Kennerley &amp; Wallis, 2009a</xref>).</p>
      </sec>
      <sec id="SS1-13">
        <title>The Ubiquity of Value Representations: Valence Versus Saliency</title>
        <p>As we discussed in the Introduction, it is now clear that single neurons across most regions of the brain encode a value signal to some varying degree. The firing of action potentials requires energy and thus if we assume that the brain acts like most biological organisms in that it seeks to conserve energy, it is reasonable to think that a ubiquitous representation of value is not simply a redundant signal; rather value representations in different brain areas are likely to serve different functions, even if we as investigators have yet to fully describe the functional differences of these representations across areas. Compounding this issue, given the limited complexity of behavioral tasks used, or because of extensive overtraining on a behavioral task, the value functions within a brain area may change to meet task demands, or shift/spread between areas, just as other goal-relevant representations shift during learning (<xref id="cr2-7" rid="c2" ref-type="bibr">Amiez et al., 2006</xref>; <xref id="cr90-4" rid="c90" ref-type="bibr">M. Matsumoto et al., 2007</xref>; <xref id="cr114-1" rid="c114" ref-type="bibr">Pasupathy &amp; Miller, 2005</xref>; <xref id="cr124-1" rid="c124" ref-type="bibr">Procyk, Tanaka, &amp; Joseph, 2000</xref>; <xref id="cr158-1" rid="c158" ref-type="bibr">Schoenbaum, Chiba, &amp; Gallagher, 1999</xref>; <xref id="cr183-1" rid="c183" ref-type="bibr">Tremblay &amp; Schultz, 2000a</xref>).</p>
        <p>An additional factor clouding the issue of functional specialization of value coding is the degree to which value signals can be independently interpreted from saliency signals (<xref id="cr91-2" rid="c91" ref-type="bibr">Maunsell, 2004</xref>; <xref id="cr134-6" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>, <xref id="cr137-3" rid="c137" ref-type="bibr">2007</xref>; <xref id="cr180-1" rid="c180" ref-type="bibr">Tobler, Dickinson, &amp; Schultz, 2003</xref>). Humans and animals are naturally more motivated by more valuable outcomes, thus processes like attention, arousal, motivation, or motor preparation all strongly correlate with value. The studies by Roesch and colleagues highlighted this issue by recording from many different frontal areas. These authors found that neurons encoding reward magnitude were most prevalent in premotor (rather than PFC) areas, which could reflect the way in which increasing value motivates the motor system to facilitate behavior (<xref id="cr134-7" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>). In a subsequent experiment in which they manipulated both the reward and potential penalty of an outcome, these authors were able to demonstrate that neurons in OFC encode a linear value signal while neurons in premotor cortex encode a saliency signal (<xref id="cr135-2" rid="c135" ref-type="bibr">Roesch &amp; Olson, 2004</xref>). However most studies do not manipulate both the costs and benefits of a choice, and thus even if we identify neurons that apparently encode a signal reflecting the subjective rewarding value of an outcome, these neurons could simply be encoding a saliency signal.</p>
        <p>One approach to resolve the valence versus salience confound is to design experiments that contain both appetitive and aversive outcomes, although for ethical reasons, this is often difficult to do in animal studies and therefore much less is known about how aversive outcomes are represented in the brain compared to appetitive outcomes. A brain area that encodes a value signal should encode both rewarding and aversive events on a linear scale, typically being positive for appetitive stimuli and negative for aversive stimuli. In contrast, saliency signals increase as a function of behavioral importance irrespective of its valence, and thus typically follow a v-shaped curve with increasing activation for both increasingly rewarding and increasingly aversive stimuli. LPFC, OFC and premotor cortex each contain neurons that exhibit preferences for aversive or rewarding valence. However, for neurons that encode both positive and negative valence, OFC neurons encode valence along a common value scale whereas premotor and LPFC neurons tend to be modulated both by large rewards and large punishments, indicative of a salience signal (<xref id="cr62-3" rid="c62" ref-type="bibr">Hosokawa et al., 2007</xref>; <xref id="cr77-3" rid="c77" ref-type="bibr">Kobayashi et al., 2006</xref>; <xref id="cr97-5" rid="c97" ref-type="bibr">Morrison &amp; Salzman, 2009</xref>; <xref id="cr135-3" rid="c135" ref-type="bibr">Roesch &amp; Olson, 2004</xref>; <xref id="cr156-1" rid="c156" ref-type="bibr">Scangos &amp; Stuphorn, 2010</xref>). In summary, disambiguating the initial abstraction of an option's value from the associated cognitive processes that arise from the recognition that an option is valuable (e.g., attention, arousal, motivation) is paramount to advancing our understanding of the specialized functions of reward representations in different brain areas.</p>
      </sec>
    </sec>
    <sec id="S-9">
      <title>Conclusions</title>
      <p>Recent frameworks of decision making have helped define some of the essential value computations underling optimal choice (<xref id="cr127-4" rid="c127" ref-type="bibr">Rangel et al., 2008</xref>). Using this framework, we compared the functional correspondence between neurophysiological and neuropsychological studies to help define the roles of different PFC areas in supporting optimal decision-making. VMPFC and the adjacent OFC seem to have an important role in determining the current incentive value of a behavioral outcome, potentially influenced by current internal states. In addition, OFC appears essential in assigning the value of an outcome to the choice that produced that outcome (credit assignment). ACC may integrate information about a decision's expected value (potentially from signals in OFC and amygdala) with information about an action's value to determine the overall value (utility) of each choice alternative. Although it is less clear precisely how the different choice alternatives are compared to determine the optimal choice, recent evidence from both functional neuroimaging and lesion studies suggests VMPFC may be important for this function. Both ACC and LPFC are sensitive to outcomes and appear to track the history of choices and outcomes. Moreover, ACC neurons encode a reward prediction error signal, suggesting these areas may be important for adaptive decision making. In addition to value information, LPFC also encodes a variety of behaviorally relevant information (e.g., object features and/or location, categories, rules), suggesting LPFC's encoding of value information may support allocation of attentional resources or cognitive control toward behaviorally relevant information (<xref id="cr54-2" rid="c54" ref-type="bibr">Hare et al., 2009</xref>; <xref id="cr71-6" rid="c71" ref-type="bibr">Kennerley &amp; Wallis, 2009c</xref>; <xref id="cr81-4" rid="c81" ref-type="bibr">Lebedev et al., 2004</xref>; <xref id="cr93-3" rid="c93" ref-type="bibr">Miller &amp; Cohen, 2001</xref>; <xref id="cr204-4" rid="c204" ref-type="bibr">Wise, 2008</xref>). Although we highlighted a number of important computations necessary for optimal choice, many of these value representations are highly correlated, and thus disambiguating these representations to infer functional specialization between areas continues to be a challenge (<xref id="cr15-2" rid="c15" ref-type="bibr">Behrens et al., 2007</xref>; <xref id="cr55-1" rid="c55" ref-type="bibr">Hare, O'Doherty, Camerer, Schultz, &amp; Rangel, 2008</xref>). Moreover, the ubiquity of these representations across multiple brain areas emphasizes the importance of direct comparison of different brain areas to determine the functional order and hierarchy in which these value computations are being performed (<xref id="cr68-13" rid="c68" ref-type="bibr">Kennerley et al., 2009</xref>; <xref id="cr69-6" rid="c69" ref-type="bibr">Kennerley &amp; Wallis, 2009a</xref>; <xref id="cr134-8" rid="c134" ref-type="bibr">Roesch &amp; Olson, 2003</xref>; <xref id="cr190-4" rid="c190" ref-type="bibr">Wallis &amp; Kennerley, 2010</xref>).</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>Both authors are supported by the Wellcome Trust. The authors have no competing interests.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="c1">
        <mixed-citation publication-type="journal"><person-group><name><surname>Amiez</surname><given-names>C.</given-names></name>, <name><surname>Joseph</surname><given-names>J. P.</given-names></name>, &amp; <name><surname>Procyk</surname><given-names>E.</given-names></name></person-group> (<year>2005</year>). <article-title>Anterior cingulate error-related activity is modulated by predicted reward</article-title>. <source>European Journal of Neuroscience</source>, <volume>21</volume>, <fpage>3447</fpage>–<lpage>3452</lpage>.<pub-id pub-id-type="pmid">16026482</pub-id></mixed-citation>
      </ref>
      <ref id="c2">
        <mixed-citation publication-type="journal"><person-group><name><surname>Amiez</surname><given-names>C.</given-names></name>, <name><surname>Joseph</surname><given-names>J. P.</given-names></name>, &amp; <name><surname>Procyk</surname><given-names>E.</given-names></name></person-group> (<year>2006</year>). <article-title>Reward encoding in the monkey anterior cingulate cortex</article-title>. <source>Cerebral Cortex</source>, <volume>16</volume>, <fpage>1040</fpage>–<lpage>1055</lpage>.<pub-id pub-id-type="pmid">16207931</pub-id></mixed-citation>
      </ref>
      <ref id="c3">
        <mixed-citation publication-type="journal"><person-group><name><surname>Aron</surname><given-names>A. R.</given-names></name>, <name><surname>Robbins</surname><given-names>T. W.</given-names></name>, &amp; <name><surname>Poldrack</surname><given-names>R. A.</given-names></name></person-group> (<year>2004</year>). <article-title>Inhibition and the right inferior frontal cortex</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>8</volume>, <fpage>170</fpage>–<lpage>177</lpage>.<pub-id pub-id-type="pmid">15050513</pub-id></mixed-citation>
      </ref>
      <ref id="c4">
        <mixed-citation publication-type="journal"><person-group><name><surname>Awh</surname><given-names>E.</given-names></name>, &amp; <name><surname>Jonides</surname><given-names>J.</given-names></name></person-group> (<year>2001</year>). <article-title>Overlapping mechanisms of attention and spatial working memory</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>5</volume>, <fpage>119</fpage>–<lpage>126</lpage>.<pub-id pub-id-type="pmid">11239812</pub-id></mixed-citation>
      </ref>
      <ref id="c5">
        <mixed-citation publication-type="journal"><person-group><name><surname>Balleine</surname><given-names>B. W.</given-names></name>, &amp; <name><surname>O'Doherty</surname><given-names>J. P.</given-names></name></person-group> (<year>2010</year>). <article-title>Human and rodent homologies in action control: Corticostriatal determinants of goal-directed and habitual action</article-title>. <source>Neuropsychopharmacology</source>, <volume>35</volume>, <fpage>48</fpage>–<lpage>69</lpage>.<pub-id pub-id-type="pmid">19776734</pub-id></mixed-citation>
      </ref>
      <ref id="c6">
        <mixed-citation publication-type="journal"><person-group><name><surname>Baxter</surname><given-names>M. G.</given-names></name>, <name><surname>Gaffan</surname><given-names>D.</given-names></name>, <name><surname>Kyriazis</surname><given-names>D. A.</given-names></name>, &amp; <name><surname>Mitchell</surname><given-names>A. S.</given-names></name></person-group> (<year>2008</year>). <article-title>Dorsolateral prefrontal lesions do not impair tests of scene learning and decision-making that require frontal-temporal interaction</article-title>. <source>European Journal of Neuroscience</source>, <volume>28</volume>, <fpage>491</fpage>–<lpage>499</lpage>.<pub-id pub-id-type="pmid">18702721</pub-id></mixed-citation>
      </ref>
      <ref id="c7">
        <mixed-citation publication-type="journal"><person-group><name><surname>Baxter</surname><given-names>M. G.</given-names></name>, <name><surname>Gaffan</surname><given-names>D.</given-names></name>, <name><surname>Kyriazis</surname><given-names>D. A.</given-names></name>, &amp; <name><surname>Mitchell</surname><given-names>A. S.</given-names></name></person-group> (<year>2009</year>). <article-title>Ventrolateral prefrontal cortex is required for performance of a strategy implementation task but not reinforcer devaluation effects in rhesus monkeys</article-title>. <source>European Journal of Neuroscience</source>, <volume>29</volume>, <fpage>2049</fpage>–<lpage>2059</lpage>.<pub-id pub-id-type="pmid">19453635</pub-id></mixed-citation>
      </ref>
      <ref id="c8">
        <mixed-citation publication-type="journal"><person-group><name><surname>Baxter</surname><given-names>M. G.</given-names></name>, <name><surname>Parker</surname><given-names>A.</given-names></name>, <name><surname>Lindner</surname><given-names>C. C.</given-names></name>, <name><surname>Izquierdo</surname><given-names>A. D.</given-names></name>, &amp; <name><surname>Murray</surname><given-names>E. A.</given-names></name></person-group> (<year>2000</year>). <article-title>Control of response selection by reinforcer value requires interaction of amygdala and orbital prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>20</volume>, <fpage>4311</fpage>–<lpage>4319</lpage>.<pub-id pub-id-type="pmid">10818166</pub-id></mixed-citation>
      </ref>
      <ref id="c9">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bayer</surname><given-names>H. M.</given-names></name>, &amp; <name><surname>Glimcher</surname><given-names>P. W.</given-names></name></person-group> (<year>2005</year>). <article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title>. <source>Neuron</source>, <volume>47</volume>, <fpage>129</fpage>–<lpage>141</lpage>.<pub-id pub-id-type="pmid">15996553</pub-id></mixed-citation>
      </ref>
      <ref id="c10">
        <mixed-citation publication-type="journal"><person-group><name><surname>Baylis</surname><given-names>L. L.</given-names></name>, &amp; <name><surname>Gaffan</surname><given-names>D.</given-names></name></person-group> (<year>1991</year>). <article-title>Amygdalectomy and ventromedial prefrontal ablation produce similar deficits in food choice and in simple object discrimination learning for an unseen reward</article-title>. <source>Experimental Brain Research</source>, <volume>86</volume>, <fpage>617</fpage>–<lpage>622</lpage>.</mixed-citation>
      </ref>
      <ref id="c11">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bays</surname><given-names>P. M.</given-names></name>, &amp; <name><surname>Husain</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Dynamic shifts of limited working memory resources in human vision</article-title>. <source>Science</source>, <volume>321</volume>(<issue>5890</issue>), <fpage>851</fpage>–<lpage>854</lpage>.<pub-id pub-id-type="pmid">18687968</pub-id></mixed-citation>
      </ref>
      <ref id="c12">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bechara</surname><given-names>A.</given-names></name>, <name><surname>Damasio</surname><given-names>A. R.</given-names></name>, <name><surname>Damasio</surname><given-names>H.</given-names></name>, &amp; <name><surname>Anderson</surname><given-names>S. W.</given-names></name></person-group> (<year>1994</year>). <article-title>Insensitivity to future consequences following damage to human prefrontal cortex</article-title>. <source>Cognition</source>, <volume>50</volume>, <fpage>15</fpage>.</mixed-citation>
      </ref>
      <ref id="c13">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bechara</surname><given-names>A.</given-names></name>, <name><surname>Damasio</surname><given-names>H.</given-names></name>, <name><surname>Tranel</surname><given-names>D.</given-names></name>, &amp; <name><surname>Anderson</surname><given-names>S. W.</given-names></name></person-group> (<year>1998</year>). <article-title>Dissociation of working memory from decision making within the human prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>18</volume>, <fpage>428</fpage>–<lpage>437</lpage>.<pub-id pub-id-type="pmid">9412519</pub-id></mixed-citation>
      </ref>
      <ref id="c14">
        <mixed-citation publication-type="journal"><person-group><name><surname>Beck</surname><given-names>J. M.</given-names></name>, <name><surname>Ma</surname><given-names>W. J.</given-names></name>, <name><surname>Kiani</surname><given-names>R.</given-names></name>, <name><surname>Hanks</surname><given-names>T.</given-names></name>, <name><surname>Churchland</surname><given-names>A. K.</given-names></name>, <name><surname>Roitman</surname><given-names>J.</given-names></name>, . . . <name><surname>Pouget</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Probabilistic population codes for Bayesian decision making</article-title>. <source>Neuron</source>, <volume>60</volume>, <fpage>1142</fpage>–<lpage>1152</lpage>.<pub-id pub-id-type="pmid">19109917</pub-id></mixed-citation>
      </ref>
      <ref id="c15">
        <mixed-citation publication-type="journal"><person-group><name><surname>Behrens</surname><given-names>T. E.</given-names></name>, <name><surname>Woolrich</surname><given-names>M. W.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>, <fpage>1214</fpage>–<lpage>1221</lpage>.</mixed-citation>
      </ref>
      <ref id="c16">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bendiksby</surname><given-names>M. S.</given-names></name>, &amp; <name><surname>Platt</surname><given-names>M. L.</given-names></name></person-group> (<year>2006</year>). <article-title>Neural correlates of reward and attention in macaque area LIP</article-title>. <source>Neuropsychologia</source>, <volume>44</volume>, <fpage>2411</fpage>–<lpage>2420</lpage>.<pub-id pub-id-type="pmid">16757005</pub-id></mixed-citation>
      </ref>
      <ref id="c17">
        <mixed-citation publication-type="journal"><person-group><name><surname>Berger</surname><given-names>B.</given-names></name>, <name><surname>Trottier</surname><given-names>S.</given-names></name>, <name><surname>Verney</surname><given-names>C.</given-names></name>, <name><surname>Gaspar</surname><given-names>P.</given-names></name>, &amp; <name><surname>Alvarez</surname><given-names>C.</given-names></name></person-group> (<year>1988</year>). <article-title>Regional and laminar distribution of the dopamine and serotonin innervation in the macaque cerebral cortex: A radioautographic study</article-title>. <source>Journal of Comparative Neurology</source>, <volume>273</volume>, <fpage>99</fpage>–<lpage>119</lpage>.<pub-id pub-id-type="pmid">3209731</pub-id></mixed-citation>
      </ref>
      <ref id="c18">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bogacz</surname><given-names>R.</given-names></name></person-group> (<year>2007</year>). <article-title>Optimal decision-making theories: Linking neurobiology with behaviour</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>11</volume>, <fpage>118</fpage>–<lpage>125</lpage>.<pub-id pub-id-type="pmid">17276130</pub-id></mixed-citation>
      </ref>
      <ref id="c19">
        <mixed-citation publication-type="journal"><person-group><name><surname>Bouret</surname><given-names>S.</given-names></name>, &amp; <name><surname>Richmond</surname><given-names>B. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Ventromedial and orbital prefrontal neurons differentially encode internally and externally driven motivational values in monkeys</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>, <fpage>8591</fpage>–<lpage>8601</lpage>.<pub-id pub-id-type="pmid">20573905</pub-id></mixed-citation>
      </ref>
      <ref id="c20">
        <mixed-citation publication-type="journal"><person-group><name><surname>Buckley</surname><given-names>M. J.</given-names></name>, <name><surname>Mansouri</surname><given-names>F. A.</given-names></name>, <name><surname>Hoda</surname><given-names>H.</given-names></name>, <name><surname>Mahboubi</surname><given-names>M.</given-names></name>, <name><surname>Browning</surname><given-names>P. G.</given-names></name>, <name><surname>Kwok</surname><given-names>S. C.</given-names></name>, . . . <name><surname>Tanaka</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>Dissociable components of rule-guided behavior depend on distinct medial and prefrontal regions</article-title>. <source>Science</source>, <volume>325</volume>, <fpage>52</fpage>–<lpage>58</lpage>.<pub-id pub-id-type="pmid">19574382</pub-id></mixed-citation>
      </ref>
      <ref id="c21">
        <mixed-citation publication-type="journal"><person-group><name><surname>Carmichael</surname><given-names>S. T.</given-names></name>, &amp; <name><surname>Price</surname><given-names>J. L.</given-names></name></person-group> (<year>1995</year>). <article-title>Sensory and premotor connections of the orbital and medial prefrontal cortex of macaque monkeys</article-title>. <source>Journal of Comparative Neurology</source>, <volume>363</volume>, <fpage>642</fpage>–<lpage>664</lpage>.<pub-id pub-id-type="pmid">8847422</pub-id></mixed-citation>
      </ref>
      <ref id="c22">
        <mixed-citation publication-type="journal"><person-group><name><surname>Cavada</surname><given-names>C.</given-names></name>, <name><surname>Company</surname><given-names>T.</given-names></name>, <name><surname>Tejedor</surname><given-names>J.</given-names></name>, <name><surname>Cruz-Rizzolo</surname><given-names>R. J.</given-names></name>, &amp; <name><surname>Reinoso-Suarez</surname><given-names>F.</given-names></name></person-group> (<year>2000</year>). <article-title>The anatomical connections of the macaque monkey orbitofrontal cortex. A review</article-title>. <source>Cerebral Cortex</source>, <volume>10</volume>, <fpage>220</fpage>–<lpage>242</lpage>.<pub-id pub-id-type="pmid">10731218</pub-id></mixed-citation>
      </ref>
      <ref id="c23">
        <mixed-citation publication-type="journal"><person-group><name><surname>Cisek</surname><given-names>P.</given-names></name></person-group> (<year>2007</year>). <article-title>Cortical mechanisms of action selection: The affordance competition hypothesis</article-title>. <source>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences</source>, <volume>362</volume>, <fpage>1585</fpage>–<lpage>1599</lpage>.</mixed-citation>
      </ref>
      <ref id="c24">
        <mixed-citation publication-type="journal"><person-group><name><surname>Cisek</surname><given-names>P.</given-names></name>, &amp; <name><surname>Kalaska</surname><given-names>J. F.</given-names></name></person-group> (<year>2005</year>). <article-title>Neural correlates of reaching decisions in dorsal premotor cortex: Specification of multiple direction choices and final selection of action</article-title>. <source>Neuron</source>, <volume>45</volume>, <fpage>801</fpage>–<lpage>814</lpage>.<pub-id pub-id-type="pmid">15748854</pub-id></mixed-citation>
      </ref>
      <ref id="c25">
        <mixed-citation publication-type="journal"><person-group><name><surname>Cisek</surname><given-names>P.</given-names></name>, <name><surname>Puskas</surname><given-names>G. A.</given-names></name>, &amp; <name><surname>El-Murr</surname><given-names>S.</given-names></name></person-group> (<year>2009</year>). <article-title>Decisions in changing conditions: The urgency-gating model</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>11560</fpage>–<lpage>11571</lpage>.<pub-id pub-id-type="pmid">19759303</pub-id></mixed-citation>
      </ref>
      <ref id="c26">
        <mixed-citation publication-type="journal"><person-group><name><surname>Coricelli</surname><given-names>G.</given-names></name>, <name><surname>Critchley</surname><given-names>H. D.</given-names></name>, <name><surname>Joffily</surname><given-names>M.</given-names></name>, <name><surname>O'Doherty</surname><given-names>J. P.</given-names></name>, <name><surname>Sirigu</surname><given-names>A.</given-names></name>, &amp; <name><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2005</year>). <article-title>Regret and its avoidance: A neuroimaging study of choice behavior</article-title>. <source>Nature Neuroscience</source>, <volume>8</volume>, <fpage>1255</fpage>–<lpage>1262</lpage>.</mixed-citation>
      </ref>
      <ref id="c27">
        <mixed-citation publication-type="journal"><person-group><name><surname>Critchley</surname><given-names>H. D.</given-names></name>, &amp; <name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>1996</year>). <article-title>Hunger and satiety modify the responses of olfactory and visual neurons in the primate orbitofrontal cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>75</volume>, <fpage>1673</fpage>–<lpage>1686</lpage>.<pub-id pub-id-type="pmid">8727405</pub-id></mixed-citation>
      </ref>
      <ref id="c28">
        <mixed-citation publication-type="journal"><person-group><name><surname>Cromwell</surname><given-names>H. C.</given-names></name>, <name><surname>Hassani</surname><given-names>O. K.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2005</year>). <article-title>Relative reward processing in primate striatum</article-title>. <source>Experimental Brain Research</source>, <volume>162</volume>, <fpage>520</fpage>–<lpage>525</lpage>.</mixed-citation>
      </ref>
      <ref id="c29">
        <mixed-citation publication-type="journal"><person-group><name><surname>Croxson</surname><given-names>P. L.</given-names></name>, <name><surname>Johansen-Berg</surname><given-names>H.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E.</given-names></name>, <name><surname>Robson</surname><given-names>M. D.</given-names></name>, <name><surname>Pinsk</surname><given-names>M. A.</given-names></name>, <name><surname>Gross</surname><given-names>C. G.</given-names></name>, . . . <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2005</year>). <article-title>Quantitative investigation of connections of the prefrontal cortex in the human and macaque using probabilistic diffusion tractography</article-title>. <source>Journal of Neuroscience</source>, <volume>25</volume>, <fpage>8854</fpage>–<lpage>8866</lpage>.<pub-id pub-id-type="pmid">16192375</pub-id></mixed-citation>
      </ref>
      <ref id="c30">
        <mixed-citation publication-type="journal"><person-group><name><surname>Curtis</surname><given-names>C. E.</given-names></name>, &amp; <name><surname>Lee</surname><given-names>D.</given-names></name></person-group> (<year>2010</year>). <article-title>Beyond working memory: The role of persistent activity in decision making</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>, <fpage>216</fpage>–<lpage>222</lpage>.<pub-id pub-id-type="pmid">20381406</pub-id></mixed-citation>
      </ref>
      <ref id="c31">
        <mixed-citation publication-type="journal"><person-group><name><surname>Damasio</surname><given-names>A. R.</given-names></name></person-group> (<year>1994</year>). <source>Descartes' error: Emotion, reason, and the human brain</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Putman</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c32">
        <mixed-citation publication-type="journal"><person-group><name><surname>Damasio</surname><given-names>A. R.</given-names></name>, &amp; <name><surname>Van Hoesen</surname><given-names>G. W.</given-names></name></person-group> (<year>1983</year>). <article-title>Emotional disturbances associated with focal lesions of the limbic frontal lobe</article-title>. In <person-group><name><surname>Heilman</surname><given-names>K. M.</given-names></name> &amp; <name><surname>Satz</surname><given-names>P.</given-names></name> (Eds.)</person-group>, <source>Neuropsychology of human emotion</source> (<volume>Vol. 1</volume>, pp. <fpage>85</fpage>–<lpage>110</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c33">
        <mixed-citation publication-type="journal"><person-group><name><surname>de Araujo</surname><given-names>I. E.</given-names></name>, <name><surname>Gutierrez</surname><given-names>R.</given-names></name>, <name><surname>Oliveira-Maia</surname><given-names>A. J.</given-names></name>, <name><surname>Pereira</surname><given-names>A. Jr.</given-names></name>, <name><surname>Nicolelis</surname><given-names>M. A.</given-names></name>, &amp; <name><surname>Simon</surname><given-names>S. A.</given-names></name></person-group> (<year>2006</year>). <article-title>Neural ensemble coding of satiety states</article-title>. <source>Neuron</source>, <volume>51</volume>, <fpage>483</fpage>–<lpage>494</lpage>.<pub-id pub-id-type="pmid">16908413</pub-id></mixed-citation>
      </ref>
      <ref id="c34">
        <mixed-citation publication-type="journal"><person-group><name><surname>Devinsky</surname><given-names>O.</given-names></name>, &amp; <name><surname>Lucuano</surname><given-names>D.</given-names></name></person-group> (<year>1993</year>). <article-title>The contributions of cingulate cortex to human behavior</article-title>. In <person-group><name><surname>Vogt</surname><given-names>B. A.</given-names></name> &amp; <name><surname>Gabriel</surname><given-names>M.</given-names></name> (Eds.)</person-group>, <source>Neurobiology of cingulate cortex and limbic thalamus: A comprehensive handbook</source> (pp. <fpage>527</fpage>–<lpage>556</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Birkhaeuser</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c35">
        <mixed-citation publication-type="journal"><person-group><name><surname>Doya</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Modulators of decision making</article-title>. <source>Nature Neuroscience</source>, <volume>11</volume>, <fpage>410</fpage>–<lpage>416</lpage>.</mixed-citation>
      </ref>
      <ref id="c36">
        <mixed-citation publication-type="journal"><person-group><name><surname>Dum</surname><given-names>R. P.</given-names></name>, &amp; <name><surname>Strick</surname><given-names>P. L.</given-names></name></person-group> (<year>1993</year>). <article-title>Cingulate motor areas</article-title>. In <person-group><name><surname>Vogt</surname><given-names>B. A.</given-names></name> &amp; <name><surname>Gabriel</surname><given-names>M.</given-names></name> (Eds.)</person-group>, <source>Neurobiology of cingulate cortex and limbic thalamus: A comprehensive handbook</source> (pp. <fpage>415</fpage>–<lpage>441</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Birkhaeuser</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c37">
        <mixed-citation publication-type="journal"><person-group><name><surname>Dum</surname><given-names>R. P.</given-names></name>, &amp; <name><surname>Strick</surname><given-names>P. L.</given-names></name></person-group> (<year>1996</year>). <article-title>Spinal cord terminations of the medial wall motor areas in macaque monkeys</article-title>. <source>Journal of Neuroscience</source>, <volume>16</volume>, <fpage>6513</fpage>–<lpage>6525</lpage>.<pub-id pub-id-type="pmid">8815929</pub-id></mixed-citation>
      </ref>
      <ref id="c38">
        <mixed-citation publication-type="journal"><person-group><name><surname>Duncan</surname><given-names>J.</given-names></name></person-group> (<year>2001</year>). <article-title>An adaptive coding model of neural function in prefrontal cortex</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>2</volume>, <fpage>820</fpage>–<lpage>829</lpage>.</mixed-citation>
      </ref>
      <ref id="c39">
        <mixed-citation publication-type="journal"><person-group><name><surname>Eslinger</surname><given-names>P. J.</given-names></name>, &amp; <name><surname>Damasio</surname><given-names>A. R.</given-names></name></person-group> (<year>1985</year>). <article-title>Severe disturbance of higher cognition after bilateral frontal lobe ablation: Patient EVR</article-title>. <source>Neurology</source>, <volume>35</volume>, <fpage>1731</fpage>–<lpage>1741</lpage>.<pub-id pub-id-type="pmid">4069365</pub-id></mixed-citation>
      </ref>
      <ref id="c40">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fellows</surname><given-names>L. K.</given-names></name></person-group> (<year>2006</year>). <article-title>Deciding how to decide: Ventromedial frontal lobe damage affects information acquisition in multi-attribute decision making</article-title>. <source>Brain</source>, <volume>129</volume>, <fpage>944</fpage>–<lpage>952</lpage>.<pub-id pub-id-type="pmid">16455794</pub-id></mixed-citation>
      </ref>
      <ref id="c41">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fellows</surname><given-names>L. K.</given-names></name>, &amp; <name><surname>Farah</surname><given-names>M. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Ventromedial frontal cortex mediates affective shifting in humans: Evidence from a reversal learning paradigm</article-title>. <source>Brain</source>, <volume>126</volume>(<issue>Pt. 8</issue>), <fpage>1830</fpage>–<lpage>1837</lpage>.<pub-id pub-id-type="pmid">12821528</pub-id></mixed-citation>
      </ref>
      <ref id="c42">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fellows</surname><given-names>L. K.</given-names></name>, &amp; <name><surname>Farah</surname><given-names>M. J.</given-names></name></person-group> (<year>2005</year>). <article-title>Different underlying impairments in decision-making following ventromedial and dorsolateral frontal lobe damage in humans</article-title>. <source>Cerebral Cortex</source>, <volume>15</volume>, <fpage>58</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">15217900</pub-id></mixed-citation>
      </ref>
      <ref id="c43">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fellows</surname><given-names>L. K.</given-names></name>, &amp; <name><surname>Farah</surname><given-names>M. J.</given-names></name></person-group> (<year>2007</year>). <article-title>The role of ventromedial prefrontal cortex in decision making: Judgment under uncertainty or judgment per se?</article-title><source>Cerebral Cortex</source>, <volume>17</volume>, <fpage>2669</fpage>–<lpage>2674</lpage>.<pub-id pub-id-type="pmid">17259643</pub-id></mixed-citation>
      </ref>
      <ref id="c44">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fiorillo</surname><given-names>C. D.</given-names></name>, <name><surname>Tobler</surname><given-names>P. N.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2003</year>). <article-title>Discrete coding of reward probability and uncertainty by dopamine neurons</article-title>. <source>Science</source>, <volume>299</volume>, <fpage>1898</fpage>–<lpage>1902</lpage>.<pub-id pub-id-type="pmid">12649484</pub-id></mixed-citation>
      </ref>
      <ref id="c45">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fleming</surname><given-names>S. M.</given-names></name>, <name><surname>Thomas</surname><given-names>C. L.</given-names></name>, &amp; <name><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Overcoming status quo bias in the human brain</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>107</volume>, <fpage>6005</fpage>–<lpage>6009</lpage>.<pub-id pub-id-type="pmid">20231462</pub-id></mixed-citation>
      </ref>
      <ref id="c46">
        <mixed-citation publication-type="journal"><person-group><name><surname>Floresco</surname><given-names>S. B.</given-names></name>, &amp; <name><surname>Ghods-Sharifi</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Amygdala-prefrontal cortical circuitry regulates effort-based decision making</article-title>. <source>Cerebral Cortex</source>, <volume>17</volume>, <fpage>251</fpage>–<lpage>260</lpage>.<pub-id pub-id-type="pmid">16495432</pub-id></mixed-citation>
      </ref>
      <ref id="c47">
        <mixed-citation publication-type="journal"><person-group><name><surname>Floyd</surname><given-names>N. S.</given-names></name>, <name><surname>Price</surname><given-names>J. L.</given-names></name>, <name><surname>Ferry</surname><given-names>A. T.</given-names></name>, <name><surname>Keay</surname><given-names>K. A.</given-names></name>, &amp; <name><surname>Bandler</surname><given-names>R.</given-names></name></person-group> (<year>2001</year>). <article-title>Orbitomedial prefrontal cortical projections to hypothalamus in the rat</article-title>. <source>Journal of Comparative Neurology</source>, <volume>432</volume>, <fpage>307</fpage>–<lpage>328</lpage>.<pub-id pub-id-type="pmid">11246210</pub-id></mixed-citation>
      </ref>
      <ref id="c48">
        <mixed-citation publication-type="journal"><person-group><name><surname>Fujiwara</surname><given-names>J.</given-names></name>, <name><surname>Tobler</surname><given-names>P. N.</given-names></name>, <name><surname>Taira</surname><given-names>M.</given-names></name>, <name><surname>Iijima</surname><given-names>T.</given-names></name>, &amp; <name><surname>Tsutsui</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>A parametric relief signal in human ventrolateral prefrontal cortex</article-title>. <source>NeuroImage</source>, <volume>44</volume>, <fpage>1163</fpage>–<lpage>1170</lpage>.<pub-id pub-id-type="pmid">18992349</pub-id></mixed-citation>
      </ref>
      <ref id="c49">
        <mixed-citation publication-type="journal"><person-group><name><surname>Funahashi</surname><given-names>S.</given-names></name>, <name><surname>Bruce</surname><given-names>C. J.</given-names></name>, &amp; <name><surname>Goldman-Rakic</surname><given-names>P. S.</given-names></name></person-group> (<year>1989</year>). <article-title>Mnemonic coding of visual space in the monkey's dorsolateral prefrontal cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>61</volume>, <fpage>331</fpage>–<lpage>349</lpage>.<pub-id pub-id-type="pmid">2918358</pub-id></mixed-citation>
      </ref>
      <ref id="c50">
        <mixed-citation publication-type="journal"><person-group><name><surname>Gallagher</surname><given-names>M.</given-names></name>, <name><surname>McMahan</surname><given-names>R. W.</given-names></name>, &amp; <name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>1999</year>). <article-title>Orbitofrontal cortex and representation of incentive value in associative learning</article-title>. <source>Journal of Neuroscience</source>, <volume>19</volume>, <fpage>6610</fpage>–<lpage>6614</lpage>.<pub-id pub-id-type="pmid">10414988</pub-id></mixed-citation>
      </ref>
      <ref id="c51">
        <mixed-citation publication-type="journal"><person-group><name><surname>Gold</surname><given-names>J. I.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2000</year>). <article-title>Representation of a perceptual decision in developing oculomotor commands</article-title>. <source>Nature</source>, <volume>404</volume>, <fpage>390</fpage>–<lpage>394</lpage>.<pub-id pub-id-type="pmid">10746726</pub-id></mixed-citation>
      </ref>
      <ref id="c52">
        <mixed-citation publication-type="journal"><person-group><name><surname>Gold</surname><given-names>J. I.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2002</year>). <article-title>Banburismus and the brain: Decoding the relationship between sensory stimuli, decisions, and reward</article-title>. <source>Neuron</source>, <volume>36</volume>, <fpage>299</fpage>–<lpage>308</lpage>.<pub-id pub-id-type="pmid">12383783</pub-id></mixed-citation>
      </ref>
      <ref id="c53">
        <mixed-citation publication-type="journal"><person-group><name><surname>Gold</surname><given-names>J. I.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2003</year>). <article-title>The influence of behavioral context on the representation of a perceptual decision in developing oculomotor commands</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>632</fpage>–<lpage>651</lpage>.<pub-id pub-id-type="pmid">12533623</pub-id></mixed-citation>
      </ref>
      <ref id="c54">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hare</surname><given-names>T. A.</given-names></name>, <name><surname>Camerer</surname><given-names>C. F.</given-names></name>, &amp; <name><surname>Rangel</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>). <article-title>Self-control in decision-making involves modulation of the vmPFC valuation system</article-title>. <source>Science</source>, <volume>324</volume>(<issue>5927</issue>), <fpage>646</fpage>–<lpage>648</lpage>.<pub-id pub-id-type="pmid">19407204</pub-id></mixed-citation>
      </ref>
      <ref id="c55">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hare</surname><given-names>T. A.</given-names></name>, <name><surname>O'Doherty</surname><given-names>J.</given-names></name>, <name><surname>Camerer</surname><given-names>C. F.</given-names></name>, <name><surname>Schultz</surname><given-names>W.</given-names></name>, &amp; <name><surname>Rangel</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>, <fpage>5623</fpage>–<lpage>5630</lpage>.<pub-id pub-id-type="pmid">18509023</pub-id></mixed-citation>
      </ref>
      <ref id="c56">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hayden</surname><given-names>B. Y.</given-names></name>, &amp; <name><surname>Platt</surname><given-names>M. L.</given-names></name></person-group> (<year>2010</year>). <article-title>Neurons in anterior cingulate cortex multiplex information about reward and action</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>, <fpage>3339</fpage>–<lpage>3346</lpage>.<pub-id pub-id-type="pmid">20203193</pub-id></mixed-citation>
      </ref>
      <ref id="c57">
        <mixed-citation publication-type="journal"><person-group><name><surname>He</surname><given-names>S. Q.</given-names></name>, <name><surname>Dum</surname><given-names>R. P.</given-names></name>, &amp; <name><surname>Strick</surname><given-names>P. L.</given-names></name></person-group> (<year>1995</year>). <article-title>Topographic organization of corticospinal projections from the frontal lobe: Motor areas on the medial surface of the hemisphere</article-title>. <source>Journal of Neuroscience</source>, <volume>15</volume>, <fpage>3284</fpage>–<lpage>3306</lpage>.<pub-id pub-id-type="pmid">7538558</pub-id></mixed-citation>
      </ref>
      <ref id="c58">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hikosaka</surname><given-names>K.</given-names></name>, &amp; <name><surname>Watanabe</surname><given-names>M.</given-names></name></person-group> (<year>2000</year>). <article-title>Delay activity of orbital and lateral prefrontal neurons of the monkey varying with different rewards</article-title>. <source>Cerebral Cortex</source>, <volume>10</volume>, <fpage>263</fpage>–<lpage>271</lpage>.<pub-id pub-id-type="pmid">10731221</pub-id></mixed-citation>
      </ref>
      <ref id="c59">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hikosaka</surname><given-names>K.</given-names></name>, &amp; <name><surname>Watanabe</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>). <article-title>Long- and short-range reward expectancy in the primate orbitofrontal cortex</article-title>. <source>European Journal of Neuroscience</source>, <volume>19</volume>, <fpage>1046</fpage>–<lpage>1054</lpage>.<pub-id pub-id-type="pmid">15009152</pub-id></mixed-citation>
      </ref>
      <ref id="c60">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hillman</surname><given-names>K. L.</given-names></name>, &amp; <name><surname>Bilkey</surname><given-names>D. K.</given-names></name></person-group> (<year>2010</year>). <article-title>Neurons in the rat anterior cingulate cortex dynamically encode cost-benefit in a spatial decision-making task</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>, <fpage>7705</fpage>–<lpage>7713</lpage>.<pub-id pub-id-type="pmid">20519545</pub-id></mixed-citation>
      </ref>
      <ref id="c61">
        <mixed-citation publication-type="journal"><person-group><name><surname>Holland</surname><given-names>P. C.</given-names></name>, &amp; <name><surname>Straub</surname><given-names>J. J.</given-names></name></person-group> (<year>1979</year>). <article-title>Differential effects of two ways of devaluing the unconditioned stimulus after Pavlovian appetitive conditioning</article-title>. <source>Journal of Experimental Psychology: Animal Behavior Processes</source>, <volume>5</volume>, <fpage>65</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">528879</pub-id></mixed-citation>
      </ref>
      <ref id="c62">
        <mixed-citation publication-type="journal"><person-group><name><surname>Hosokawa</surname><given-names>T.</given-names></name>, <name><surname>Kato</surname><given-names>K.</given-names></name>, <name><surname>Inoue</surname><given-names>M.</given-names></name>, &amp; <name><surname>Mikami</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Neurons in the macaque orbitofrontal cortex code relative preference of both rewarding and aversive outcomes</article-title>. <source>Neuroscience Research</source>, <volume>57</volume>, <fpage>434</fpage>–<lpage>445</lpage>.<pub-id pub-id-type="pmid">17239463</pub-id></mixed-citation>
      </ref>
      <ref id="c63">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ito</surname><given-names>S.</given-names></name>, <name><surname>Stuphorn</surname><given-names>V.</given-names></name>, <name><surname>Brown</surname><given-names>J. W.</given-names></name>, &amp; <name><surname>Schall</surname><given-names>J. D.</given-names></name></person-group> (<year>2003</year>). <article-title>Performance monitoring by the anterior cingulate cortex during saccade countermanding</article-title>. <source>Science</source>, <volume>302</volume>, <fpage>120</fpage>–<lpage>122</lpage>.<pub-id pub-id-type="pmid">14526085</pub-id></mixed-citation>
      </ref>
      <ref id="c64">
        <mixed-citation publication-type="journal"><person-group><name><surname>Izquierdo</surname><given-names>A.</given-names></name>, <name><surname>Suda</surname><given-names>R. K.</given-names></name>, &amp; <name><surname>Murray</surname><given-names>E. A.</given-names></name></person-group> (<year>2004</year>). <article-title>Bilateral orbital prefrontal cortex lesions in rhesus monkeys disrupt choices guided by both reward value and reward contingency</article-title>. <source>Journal of Neuroscience</source>, <volume>24</volume>, <fpage>7540</fpage>–<lpage>7548</lpage>.<pub-id pub-id-type="pmid">15329401</pub-id></mixed-citation>
      </ref>
      <ref id="c65">
        <mixed-citation publication-type="journal"><person-group><name><surname>Jocham</surname><given-names>G.</given-names></name>, <name><surname>Neumann</surname><given-names>J.</given-names></name>, <name><surname>Klein</surname><given-names>T. A.</given-names></name>, <name><surname>Danielmeier</surname><given-names>C.</given-names></name>, &amp; <name><surname>Ullsperger</surname><given-names>M.</given-names></name></person-group> (<year>2009</year>). <article-title>Adaptive coding of action values in the human rostral cingulate zone</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>7489</fpage>–<lpage>7496</lpage>.<pub-id pub-id-type="pmid">19515916</pub-id></mixed-citation>
      </ref>
      <ref id="c66">
        <mixed-citation publication-type="journal"><person-group><name><surname>Johnston</surname><given-names>K.</given-names></name>, <name><surname>Levin</surname><given-names>H. M.</given-names></name>, <name><surname>Koval</surname><given-names>M. J.</given-names></name>, &amp; <name><surname>Everling</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Top-down control-signal dynamics in anterior cingulate and prefrontal cortex neurons following task switching</article-title>. <source>Neuron</source>, <volume>53</volume>, <fpage>453</fpage>–<lpage>462</lpage>.<pub-id pub-id-type="pmid">17270740</pub-id></mixed-citation>
      </ref>
      <ref id="c67">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kable</surname><given-names>J. W.</given-names></name>, &amp; <name><surname>Glimcher</surname><given-names>P. W.</given-names></name></person-group> (<year>2009</year>). <article-title>The neurobiology of decision: Consensus and controversy</article-title>. <source>Neuron</source>, <volume>63</volume>, <fpage>733</fpage>–<lpage>745</lpage>.<pub-id pub-id-type="pmid">19778504</pub-id></mixed-citation>
      </ref>
      <ref id="c68">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, <name><surname>Dahmubed</surname><given-names>A. F.</given-names></name>, <name><surname>Lara</surname><given-names>A. H.</given-names></name>, &amp; <name><surname>Wallis</surname><given-names>J. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Neurons in the frontal lobe encode the value of multiple decision variables</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>21</volume>, <fpage>1162</fpage>–<lpage>1178</lpage>.<pub-id pub-id-type="pmid">18752411</pub-id></mixed-citation>
      </ref>
      <ref id="c69">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, &amp; <name><surname>Wallis</surname><given-names>J. D.</given-names></name></person-group> (<year>2009a</year>). <article-title>Encoding of reward and space during a working memory task in the orbitofrontal cortex and anterior cingulate sulcus</article-title>. <source>Journal of Neurophysiology</source>, <volume>102</volume>, <fpage>3352</fpage>–<lpage>3364</lpage>.<pub-id pub-id-type="pmid">19776363</pub-id></mixed-citation>
      </ref>
      <ref id="c70">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, &amp; <name><surname>Wallis</surname><given-names>J. D.</given-names></name></person-group> (<year>2009b</year>). <article-title>Evaluating choices by single neurons in the frontal lobe: Outcome value encoded across multiple decision variables</article-title>. <source>European Journal of Neuroscience</source>, <volume>29</volume>, <fpage>2061</fpage>–<lpage>2073</lpage>.<pub-id pub-id-type="pmid">19453638</pub-id></mixed-citation>
      </ref>
      <ref id="c71">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, &amp; <name><surname>Wallis</surname><given-names>J. D.</given-names></name></person-group> (<year>2009c</year>). <article-title>Reward-dependent modulation of working memory in lateral prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>3259</fpage>–<lpage>3270</lpage>.<pub-id pub-id-type="pmid">19279263</pub-id></mixed-citation>
      </ref>
      <ref id="c72">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2006</year>). <article-title>Optimal decision making and the anterior cingulate cortex</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>, <fpage>940</fpage>–<lpage>947</lpage>.</mixed-citation>
      </ref>
      <ref id="c73">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kepecs</surname><given-names>A.</given-names></name>, <name><surname>Uchida</surname><given-names>N.</given-names></name>, <name><surname>Zariwala</surname><given-names>H. A.</given-names></name>, &amp; <name><surname>Mainen</surname><given-names>Z. F.</given-names></name></person-group> (<year>2008</year>). <article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title>. <source>Nature</source>, <volume>455</volume>, <fpage>227</fpage>–<lpage>231</lpage>.<pub-id pub-id-type="pmid">18690210</pub-id></mixed-citation>
      </ref>
      <ref id="c74">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kim</surname><given-names>J. N.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>1999</year>). <article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title>. <source>Nature Neuroscience</source>, <volume>2</volume>, <fpage>176</fpage>–<lpage>185</lpage>.</mixed-citation>
      </ref>
      <ref id="c75">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kim</surname><given-names>S.</given-names></name>, <name><surname>Hwang</surname><given-names>J.</given-names></name>, &amp; <name><surname>Lee</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <article-title>Prefrontal coding of temporally discounted values during intertemporal choice</article-title>. <source>Neuron</source>, <volume>59</volume>, <fpage>161</fpage>–<lpage>172</lpage>.<pub-id pub-id-type="pmid">18614037</pub-id></mixed-citation>
      </ref>
      <ref id="c76">
        <mixed-citation publication-type="journal"><person-group><name><surname>Knutson</surname><given-names>B.</given-names></name>, &amp; <name><surname>Wimmer</surname><given-names>G. E.</given-names></name></person-group> (<year>2007</year>). <article-title>Splitting the difference: How does the brain code reward episodes?</article-title><source>Annals of the New York Academy of Sciences</source>, <volume>1104</volume>, <fpage>54</fpage>–<lpage>69</lpage>.<pub-id pub-id-type="pmid">17416922</pub-id></mixed-citation>
      </ref>
      <ref id="c77">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kobayashi</surname><given-names>S.</given-names></name>, <name><surname>Nomoto</surname><given-names>K.</given-names></name>, <name><surname>Watanabe</surname><given-names>M.</given-names></name>, <name><surname>Hikosaka</surname><given-names>O.</given-names></name>, <name><surname>Schultz</surname><given-names>W.</given-names></name>, &amp; <name><surname>Sakagami</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>Influences of rewarding and aversive outcomes on activity in macaque lateral prefrontal cortex</article-title>. <source>Neuron</source>, <volume>51</volume>, <fpage>861</fpage>–<lpage>870</lpage>.<pub-id pub-id-type="pmid">16982429</pub-id></mixed-citation>
      </ref>
      <ref id="c78">
        <mixed-citation publication-type="journal"><person-group><name><surname>Kobayashi</surname><given-names>S.</given-names></name>, <name><surname>Pinto de Carvalho</surname><given-names>O.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>Adaptation of reward sensitivity in orbitofrontal neurons</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>, <fpage>534</fpage>–<lpage>544</lpage>.<pub-id pub-id-type="pmid">20071516</pub-id></mixed-citation>
      </ref>
      <ref id="c79">
        <mixed-citation publication-type="journal"><person-group><name><surname>Krajbich</surname><given-names>I.</given-names></name>, <name><surname>Armel</surname><given-names>C.</given-names></name>, &amp; <name><surname>Rangel</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>Visual fixations and the computation and comparison of value in simple choice</article-title>. <source>Nature Neuroscience</source>, <volume>13</volume>, <fpage>1292</fpage>–<lpage>1298</lpage>.</mixed-citation>
      </ref>
      <ref id="c80">
        <mixed-citation publication-type="journal"><person-group><name><surname>Lara</surname><given-names>A. H.</given-names></name>, <name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, &amp; <name><surname>Wallis</surname><given-names>J. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Encoding of gustatory working memory by orbitofrontal neurons</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>765</fpage>–<lpage>774</lpage>.<pub-id pub-id-type="pmid">19158302</pub-id></mixed-citation>
      </ref>
      <ref id="c81">
        <mixed-citation publication-type="journal"><person-group><name><surname>Lebedev</surname><given-names>M. A.</given-names></name>, <name><surname>Messinger</surname><given-names>A.</given-names></name>, <name><surname>Kralik</surname><given-names>J. D.</given-names></name>, &amp; <name><surname>Wise</surname><given-names>S. P.</given-names></name></person-group> (<year>2004</year>). <article-title>Representation of attended versus remembered locations in prefrontal cortex</article-title>. <source>PLoS Biology</source>, <volume>2</volume>, <fpage>e365</fpage>. doi:10.1371/journal.pbio.0020365<pub-id pub-id-type="pmid">15510225</pub-id></mixed-citation>
      </ref>
      <ref id="c82">
        <mixed-citation publication-type="journal"><person-group><name><surname>Leon</surname><given-names>M. I.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>1999</year>). <article-title>Effect of expected reward magnitude on the response of neurons in the dorsolateral prefrontal cortex of the macaque</article-title>. <source>Neuron</source>, <volume>24</volume>, <fpage>415</fpage>–<lpage>425</lpage>.<pub-id pub-id-type="pmid">10571234</pub-id></mixed-citation>
      </ref>
      <ref id="c83">
        <mixed-citation publication-type="journal"><person-group><name><surname>Leon</surname><given-names>M. I.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2003</year>). <article-title>Representation of time by neurons in the posterior parietal cortex of the macaque</article-title>. <source>Neuron</source>, <volume>38</volume>, <fpage>317</fpage>–<lpage>327</lpage>.<pub-id pub-id-type="pmid">12718864</pub-id></mixed-citation>
      </ref>
      <ref id="c84">
        <mixed-citation publication-type="journal"><person-group><name><surname>Lohrenz</surname><given-names>T.</given-names></name>, <name><surname>McCabe</surname><given-names>K.</given-names></name>, <name><surname>Camerer</surname><given-names>C. F.</given-names></name>, &amp; <name><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>2007</year>). <article-title>Neural signature of fictive learning signals in a sequential investment task</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>104</volume>, <fpage>9493</fpage>–<lpage>9498</lpage>.<pub-id pub-id-type="pmid">17519340</pub-id></mixed-citation>
      </ref>
      <ref id="c85">
        <mixed-citation publication-type="journal"><person-group><name><surname>Luk</surname><given-names>C. H.</given-names></name>, &amp; <name><surname>Wallis</surname><given-names>J. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Dynamic encoding of responses and outcomes by neurons in medial prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>7526</fpage>–<lpage>7539</lpage>.<pub-id pub-id-type="pmid">19515921</pub-id></mixed-citation>
      </ref>
      <ref id="c86">
        <mixed-citation publication-type="journal"><person-group><name><surname>Mansouri</surname><given-names>F. A.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, &amp; <name><surname>Tanaka</surname><given-names>K.</given-names></name></person-group> (<year>2007</year>). <article-title>Mnemonic function of the dorsolateral prefrontal cortex in conflict-induced behavioral adjustment</article-title>. <source>Science</source>, <volume>318</volume>, <fpage>987</fpage>–<lpage>990</lpage>.<pub-id pub-id-type="pmid">17962523</pub-id></mixed-citation>
      </ref>
      <ref id="c87">
        <mixed-citation publication-type="journal"><person-group><name><surname>Mansouri</surname><given-names>F. A.</given-names></name>, <name><surname>Tanaka</surname><given-names>K.</given-names></name>, &amp; <name><surname>Buckley</surname><given-names>M. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Conflict-induced behavioural adjustment: A clue to the executive functions of the prefrontal cortex</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>, <fpage>141</fpage>–<lpage>152</lpage>.</mixed-citation>
      </ref>
      <ref id="c88">
        <mixed-citation publication-type="journal"><person-group><name><surname>Matsumoto</surname><given-names>K.</given-names></name>, <name><surname>Suzuki</surname><given-names>W.</given-names></name>, &amp; <name><surname>Tanaka</surname><given-names>K.</given-names></name></person-group> (<year>2003</year>). <article-title>Neuronal correlates of goal-based motor selection in the prefrontal cortex</article-title>. <source>Science</source>, <volume>301</volume>, <fpage>229</fpage>–<lpage>232</lpage>.<pub-id pub-id-type="pmid">12855813</pub-id></mixed-citation>
      </ref>
      <ref id="c89">
        <mixed-citation publication-type="journal"><person-group><name><surname>Matsumoto</surname><given-names>M.</given-names></name>, &amp; <name><surname>Hikosaka</surname><given-names>O.</given-names></name></person-group> (<year>2009</year>). <article-title>Two types of dopamine neuron distinctly convey positive and negative motivational signals</article-title>. <source>Nature</source>, <volume>459</volume>, <fpage>837</fpage>–<lpage>841</lpage>.<pub-id pub-id-type="pmid">19448610</pub-id></mixed-citation>
      </ref>
      <ref id="c90">
        <mixed-citation publication-type="journal"><person-group><name><surname>Matsumoto</surname><given-names>M.</given-names></name>, <name><surname>Matsumoto</surname><given-names>K.</given-names></name>, <name><surname>Abe</surname><given-names>H.</given-names></name>, &amp; <name><surname>Tanaka</surname><given-names>K.</given-names></name></person-group> (<year>2007</year>). <article-title>Medial prefrontal cell activity signaling prediction errors of action values</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>, <fpage>647</fpage>–<lpage>656</lpage>.</mixed-citation>
      </ref>
      <ref id="c91">
        <mixed-citation publication-type="journal"><person-group><name><surname>Maunsell</surname><given-names>J. H.</given-names></name></person-group> (<year>2004</year>). <article-title>Neuronal representations of cognitive state: Reward or attention?</article-title><source>Trends in Cognitive Science</source>, <volume>8</volume>, <fpage>261</fpage>–<lpage>265</lpage>.</mixed-citation>
      </ref>
      <ref id="c92">
        <mixed-citation publication-type="journal"><person-group><name><surname>McCoy</surname><given-names>A. N.</given-names></name>, <name><surname>Crowley</surname><given-names>J. C.</given-names></name>, <name><surname>Haghighian</surname><given-names>G.</given-names></name>, <name><surname>Dean</surname><given-names>H. L.</given-names></name>, &amp; <name><surname>Platt</surname><given-names>M. L.</given-names></name></person-group> (<year>2003</year>). <article-title>Saccade reward signals in posterior cingulate cortex</article-title>. <source>Neuron</source>, <volume>40</volume>, <fpage>1031</fpage>–<lpage>1040</lpage>.<pub-id pub-id-type="pmid">14659101</pub-id></mixed-citation>
      </ref>
      <ref id="c93">
        <mixed-citation publication-type="journal"><person-group><name><surname>Miller</surname><given-names>E. K.</given-names></name>, &amp; <name><surname>Cohen</surname><given-names>J. D.</given-names></name></person-group> (<year>2001</year>). <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annual Review of Neuroscience</source>, <volume>24</volume>, <fpage>167</fpage>–<lpage>202</lpage>.</mixed-citation>
      </ref>
      <ref id="c94">
        <mixed-citation publication-type="journal"><person-group><name><surname>Mitz</surname><given-names>A. R.</given-names></name>, <name><surname>Tsujimoto</surname><given-names>S.</given-names></name>, <name><surname>Maclarty</surname><given-names>A. J.</given-names></name>, &amp; <name><surname>Wise</surname><given-names>S. P.</given-names></name></person-group> (<year>2009</year>). <article-title>A method for recording single-cell activity in the frontal-pole cortex of macaque monkeys</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>177</volume>, <fpage>60</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">18977387</pub-id></mixed-citation>
      </ref>
      <ref id="c95">
        <mixed-citation publication-type="journal"><person-group><name><surname>Montague</surname><given-names>P. R.</given-names></name>, &amp; <name><surname>Berns</surname><given-names>G. S.</given-names></name></person-group> (<year>2002</year>). <article-title>Neural economics and the biological substrates of valuation</article-title>. <source>Neuron</source>, <volume>36</volume>, <fpage>265</fpage>–<lpage>284</lpage>.<pub-id pub-id-type="pmid">12383781</pub-id></mixed-citation>
      </ref>
      <ref id="c96">
        <mixed-citation publication-type="journal"><person-group><name><surname>Montague</surname><given-names>P. R.</given-names></name>, <name><surname>Dayan</surname><given-names>P.</given-names></name>, &amp; <name><surname>Sejnowski</surname><given-names>T. J.</given-names></name></person-group> (<year>1996</year>). <article-title>A framework for mesencephalic dopamine systems based on predictive Hebbian learning</article-title>. <source>Journal of Neuroscience</source>, <volume>16</volume>, <fpage>1936</fpage>–<lpage>1947</lpage>.<pub-id pub-id-type="pmid">8774460</pub-id></mixed-citation>
      </ref>
      <ref id="c97">
        <mixed-citation publication-type="journal"><person-group><name><surname>Morrison</surname><given-names>S. E.</given-names></name>, &amp; <name><surname>Salzman</surname><given-names>C. D.</given-names></name></person-group> (<year>2009</year>). <article-title>The convergence of information about rewarding and aversive stimuli in single neurons</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>11471</fpage>–<lpage>11483</lpage>.<pub-id pub-id-type="pmid">19759296</pub-id></mixed-citation>
      </ref>
      <ref id="c98">
        <mixed-citation publication-type="journal"><person-group><name><surname>Munoz</surname><given-names>D. P.</given-names></name>, &amp; <name><surname>Wurtz</surname><given-names>R. H.</given-names></name></person-group> (<year>1995</year>). <article-title>Saccade-related activity in monkey superior colliculus. I. Characteristics of burst and buildup cells</article-title>. <source>Journal of Neurophysiology</source>, <volume>73</volume>, <fpage>2313</fpage>–<lpage>2333</lpage>.<pub-id pub-id-type="pmid">7666141</pub-id></mixed-citation>
      </ref>
      <ref id="c99">
        <mixed-citation publication-type="journal"><person-group><name><surname>Murray</surname><given-names>E. A.</given-names></name>, <name><surname>O'Doherty</surname><given-names>J. P.</given-names></name>, &amp; <name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>2007</year>). <article-title>What we know and do not know about the functions of the orbitofrontal cortex after 20 years of cross-species studies</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>, <fpage>8166</fpage>–<lpage>8169</lpage>.<pub-id pub-id-type="pmid">17670960</pub-id></mixed-citation>
      </ref>
      <ref id="c100">
        <mixed-citation publication-type="journal"><person-group><name><surname>Nakano</surname><given-names>Y.</given-names></name>, <name><surname>Oomura</surname><given-names>Y.</given-names></name>, <name><surname>Nishino</surname><given-names>H.</given-names></name>, <name><surname>Aou</surname><given-names>S.</given-names></name>, <name><surname>Yamamoto</surname><given-names>T.</given-names></name>, &amp; <name><surname>Nemoto</surname><given-names>S.</given-names></name></person-group> (<year>1984</year>). <article-title>Neuronal activity in the medial orbitofrontal cortex of the behaving monkey: Modulation by glucose and satiety</article-title>. <source>Brain Research Bulletin</source>, <volume>12</volume>, <fpage>381</fpage>–<lpage>385</lpage>.<pub-id pub-id-type="pmid">6733545</pub-id></mixed-citation>
      </ref>
      <ref id="c101">
        <mixed-citation publication-type="journal"><person-group><name><surname>Niki</surname><given-names>H.</given-names></name>, &amp; <name><surname>Watanabe</surname><given-names>M.</given-names></name></person-group> (<year>1976</year>). <article-title>Cingulate unit activity and delayed response</article-title>. <source>Brain Research</source>, <volume>110</volume>, <fpage>381</fpage>–<lpage>386</lpage>.<pub-id pub-id-type="pmid">820408</pub-id></mixed-citation>
      </ref>
      <ref id="c102">
        <mixed-citation publication-type="journal"><person-group><name><surname>Niki</surname><given-names>H.</given-names></name>, &amp; <name><surname>Watanabe</surname><given-names>M.</given-names></name></person-group> (<year>1979</year>). <article-title>Prefrontal and cingulate unit activity during timing behavior in the monkey</article-title>. <source>Brain Research</source>, <volume>171</volume>, <fpage>213</fpage>–<lpage>224</lpage>.<pub-id pub-id-type="pmid">111772</pub-id></mixed-citation>
      </ref>
      <ref id="c103">
        <mixed-citation publication-type="journal"><person-group><name><surname>Noonan</surname><given-names>M. P.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E.</given-names></name>, <name><surname>Sallet</surname><given-names>J.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2010</year>). <article-title>Separate value comparison and learning mechanisms in macaque medial and lateral orbitofrontal cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>107</volume>, <fpage>20547</fpage>–<lpage>20552</lpage>.<pub-id pub-id-type="pmid">21059901</pub-id></mixed-citation>
      </ref>
      <ref id="c104">
        <mixed-citation publication-type="journal"><person-group><name><surname>O'Doherty</surname><given-names>J. P.</given-names></name>, <name><surname>Hampton</surname><given-names>A.</given-names></name>, &amp; <name><surname>Kim</surname><given-names>H.</given-names></name></person-group> (<year>2007</year>). <article-title>Model-based fMRI and its application to reward learning and decision making</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1104</volume>, <fpage>35</fpage>–<lpage>53</lpage>.<pub-id pub-id-type="pmid">17416921</pub-id></mixed-citation>
      </ref>
      <ref id="c105">
        <mixed-citation publication-type="journal"><person-group><name><surname>O'Neill</surname><given-names>M.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>Coding of reward risk by orbitofrontal neurons is mostly distinct from coding of reward value</article-title>. <source>Neuron</source>, <volume>68</volume>, <fpage>789</fpage>–<lpage>800</lpage>.<pub-id pub-id-type="pmid">21092866</pub-id></mixed-citation>
      </ref>
      <ref id="c106">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ongur</surname><given-names>D.</given-names></name>, <name><surname>An</surname><given-names>X.</given-names></name>, &amp; <name><surname>Price</surname><given-names>J. L.</given-names></name></person-group> (<year>1998</year>). <article-title>Prefrontal cortical projections to the hypothalamus in macaque monkeys</article-title>. <source>Journal of Comparative Neurology</source>, <volume>401</volume>, <fpage>480</fpage>–<lpage>505</lpage>.<pub-id pub-id-type="pmid">9826274</pub-id></mixed-citation>
      </ref>
      <ref id="c107">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ostlund</surname><given-names>S. B.</given-names></name>, &amp; <name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2005</year>). <article-title>Lesions of medial prefrontal cortex disrupt the acquisition but not the expression of goal-directed learning</article-title>. <source>Journal of Neuroscience</source>, <volume>25</volume>, <fpage>7763</fpage>–<lpage>7770</lpage>.<pub-id pub-id-type="pmid">16120777</pub-id></mixed-citation>
      </ref>
      <ref id="c108">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ostlund</surname><given-names>S. B.</given-names></name>, &amp; <name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2007a</year>). <article-title>The contribution of orbitofrontal cortex to action selection</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1121</volume>, <fpage>174</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">17872392</pub-id></mixed-citation>
      </ref>
      <ref id="c109">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ostlund</surname><given-names>S. B.</given-names></name>, &amp; <name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2007b</year>). <article-title>Orbitofrontal cortex mediates outcome encoding in Pavlovian but not instrumental conditioning</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>, <fpage>4819</fpage>–<lpage>4825</lpage>.<pub-id pub-id-type="pmid">17475789</pub-id></mixed-citation>
      </ref>
      <ref id="c110">
        <mixed-citation publication-type="journal"><person-group><name><surname>Padoa-Schioppa</surname><given-names>C.</given-names></name></person-group> (<year>2009</year>). <article-title>Range-adapting representation of economic value in the orbitofrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>14004</fpage>–<lpage>14014</lpage>.<pub-id pub-id-type="pmid">19890010</pub-id></mixed-citation>
      </ref>
      <ref id="c111">
        <mixed-citation publication-type="journal"><person-group><name><surname>Padoa-Schioppa</surname><given-names>C.</given-names></name>, &amp; <name><surname>Assad</surname><given-names>J. A.</given-names></name></person-group> (<year>2006</year>). <article-title>Neurons in the orbitofrontal cortex encode economic value</article-title>. <source>Nature</source>, <volume>441</volume>, <fpage>223</fpage>–<lpage>226</lpage>.<pub-id pub-id-type="pmid">16633341</pub-id></mixed-citation>
      </ref>
      <ref id="c112">
        <mixed-citation publication-type="journal"><person-group><name><surname>Padoa-Schioppa</surname><given-names>C.</given-names></name>, &amp; <name><surname>Assad</surname><given-names>J. A.</given-names></name></person-group> (<year>2008</year>). <article-title>The representation of economic value in the orbitofrontal cortex is invariant for changes of menu</article-title>. <source>Nature Neuroscience</source>, <volume>11</volume>, <fpage>95</fpage>–<lpage>102</lpage>.</mixed-citation>
      </ref>
      <ref id="c113">
        <mixed-citation publication-type="journal"><person-group><name><surname>Pan</surname><given-names>X.</given-names></name>, <name><surname>Sawa</surname><given-names>K.</given-names></name>, <name><surname>Tsuda</surname><given-names>I.</given-names></name>, <name><surname>Tsukada</surname><given-names>M.</given-names></name>, &amp; <name><surname>Sakagami</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Reward prediction based on stimulus categorization in primate lateral prefrontal cortex</article-title>. <source>Nature Neuroscience</source>, <volume>11</volume>, <fpage>703</fpage>–<lpage>712</lpage>.</mixed-citation>
      </ref>
      <ref id="c114">
        <mixed-citation publication-type="journal"><person-group><name><surname>Pasupathy</surname><given-names>A.</given-names></name>, &amp; <name><surname>Miller</surname><given-names>E. K.</given-names></name></person-group> (<year>2005</year>). <article-title>Different time courses of learning-related activity in the prefrontal cortex and striatum</article-title>. <source>Nature</source>, <volume>433</volume>, <fpage>873</fpage>–<lpage>876</lpage>.<pub-id pub-id-type="pmid">15729344</pub-id></mixed-citation>
      </ref>
      <ref id="c115">
        <mixed-citation publication-type="journal"><person-group><name><surname>Paton</surname><given-names>J. J.</given-names></name>, <name><surname>Belova</surname><given-names>M. A.</given-names></name>, <name><surname>Morrison</surname><given-names>S. E.</given-names></name>, &amp; <name><surname>Salzman</surname><given-names>C. D.</given-names></name></person-group> (<year>2006</year>). <article-title>The primate amygdala represents the positive and negative value of visual stimuli during learning</article-title>. <source>Nature</source>, <volume>439</volume>, <fpage>865</fpage>–<lpage>870</lpage>.<pub-id pub-id-type="pmid">16482160</pub-id></mixed-citation>
      </ref>
      <ref id="c116">
        <mixed-citation publication-type="journal"><person-group><name><surname>Pears</surname><given-names>A.</given-names></name>, <name><surname>Parkinson</surname><given-names>J. A.</given-names></name>, <name><surname>Hopewell</surname><given-names>L.</given-names></name>, <name><surname>Everitt</surname><given-names>B. J.</given-names></name>, &amp; <name><surname>Roberts</surname><given-names>A. C.</given-names></name></person-group> (<year>2003</year>). <article-title>Lesions of the orbitofrontal but not medial prefrontal cortex disrupt conditioned reinforcement in primates</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>11189</fpage>–<lpage>11201</lpage>.<pub-id pub-id-type="pmid">14657178</pub-id></mixed-citation>
      </ref>
      <ref id="c117">
        <mixed-citation publication-type="journal"><person-group><name><surname>Petrides</surname><given-names>M.</given-names></name></person-group> (<year>1996</year>). <article-title>Specialized systems for the processing of mnemonic information within the primate frontal cortex</article-title>. <source>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences</source>, <volume>351</volume>(<issue>1346</issue>), <fpage>1455</fpage>–<lpage>1461</lpage>.</mixed-citation>
      </ref>
      <ref id="c118">
        <mixed-citation publication-type="journal"><person-group><name><surname>Petrides</surname><given-names>M.</given-names></name></person-group> (<year>2000</year>). <article-title>Dissociable roles of mid-dorsolateral prefrontal and anterior inferotemporal cortex in visual working memory</article-title>. <source>Journal of Neuroscience</source>, <volume>20</volume>, <fpage>7496</fpage>–<lpage>7503</lpage>.<pub-id pub-id-type="pmid">11007909</pub-id></mixed-citation>
      </ref>
      <ref id="c119">
        <mixed-citation publication-type="journal"><person-group><name><surname>Petrides</surname><given-names>M.</given-names></name></person-group> (<year>2005</year>). <article-title>Lateral prefrontal cortex: Architectonic and functional organization</article-title>. <source>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences</source>, <volume>360</volume>, <fpage>781</fpage>–<lpage>795</lpage>.</mixed-citation>
      </ref>
      <ref id="c120">
        <mixed-citation publication-type="journal"><person-group><name><surname>Petrides</surname><given-names>M.</given-names></name>, &amp; <name><surname>Pandya</surname><given-names>D. N.</given-names></name></person-group> (<year>2002</year>). <article-title>Comparative cytoarchitectonic analysis of the human and the macaque ventrolateral prefrontal cortex and corticocortical connection patterns in the monkey</article-title>. <source>European Journal of Neuroscience</source>, <volume>16</volume>, <fpage>291</fpage>–<lpage>310</lpage>.<pub-id pub-id-type="pmid">12169111</pub-id></mixed-citation>
      </ref>
      <ref id="c121">
        <mixed-citation publication-type="journal"><person-group><name><surname>Pickens</surname><given-names>C. L.</given-names></name>, <name><surname>Saddoris</surname><given-names>M. P.</given-names></name>, <name><surname>Setlow</surname><given-names>B.</given-names></name>, <name><surname>Gallagher</surname><given-names>M.</given-names></name>, <name><surname>Holland</surname><given-names>P. C.</given-names></name>, &amp; <name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>2003</year>). <article-title>Different roles for orbitofrontal cortex and basolateral amygdala in a reinforcer devaluation task</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>11078</fpage>–<lpage>11084</lpage>.<pub-id pub-id-type="pmid">14657165</pub-id></mixed-citation>
      </ref>
      <ref id="c122">
        <mixed-citation publication-type="journal"><person-group><name><surname>Piekema</surname><given-names>C.</given-names></name>, <name><surname>Browning</surname><given-names>P. G. F.</given-names></name>, &amp; <name><surname>Buckley</surname><given-names>M. J.</given-names></name></person-group> (<year>2009</year>). <article-title>The role of the frontal pole in episodic and discrimination learning</article-title>. <source>Society for Neuroscience, Abstracts</source>, <volume>98.2</volume>, <fpage>ee126</fpage>.</mixed-citation>
      </ref>
      <ref id="c123">
        <mixed-citation publication-type="journal"><person-group><name><surname>Platt</surname><given-names>M. L.</given-names></name>, &amp; <name><surname>Glimcher</surname><given-names>P. W.</given-names></name></person-group> (<year>1999</year>). <article-title>Neural correlates of decision variables in parietal cortex</article-title>. <source>Nature</source>, <volume>400</volume>, <fpage>233</fpage>–<lpage>238</lpage>.<pub-id pub-id-type="pmid">10421364</pub-id></mixed-citation>
      </ref>
      <ref id="c124">
        <mixed-citation publication-type="journal"><person-group><name><surname>Procyk</surname><given-names>E.</given-names></name>, <name><surname>Tanaka</surname><given-names>Y. L.</given-names></name>, &amp; <name><surname>Joseph</surname><given-names>J. P.</given-names></name></person-group> (<year>2000</year>). <article-title>Anterior cingulate activity during routine and non-routine sequential behaviors in macaques</article-title>. <source>Nature Neuroscience</source>, <volume>3</volume>, <fpage>502</fpage>–<lpage>508</lpage>.</mixed-citation>
      </ref>
      <ref id="c125">
        <mixed-citation publication-type="journal"><person-group><name><surname>Quilodran</surname><given-names>R.</given-names></name>, <name><surname>Rothe</surname><given-names>M.</given-names></name>, &amp; <name><surname>Procyk</surname><given-names>E.</given-names></name></person-group> (<year>2008</year>). <article-title>Behavioral shifts and action valuation in the anterior cingulate cortex</article-title>. <source>Neuron</source>, <volume>57</volume>, <fpage>314</fpage>–<lpage>325</lpage>.<pub-id pub-id-type="pmid">18215627</pub-id></mixed-citation>
      </ref>
      <ref id="c126">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rainer</surname><given-names>G.</given-names></name>, <name><surname>Asaad</surname><given-names>W. F.</given-names></name>, &amp; <name><surname>Miller</surname><given-names>E. K.</given-names></name></person-group> (<year>1998</year>). <article-title>Selective representation of relevant information by neurons in the primate prefrontal cortex</article-title>. <source>Nature</source>, <volume>393</volume>, <fpage>577</fpage>–<lpage>579</lpage>.<pub-id pub-id-type="pmid">9634233</pub-id></mixed-citation>
      </ref>
      <ref id="c127">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rangel</surname><given-names>A.</given-names></name>, <name><surname>Camerer</surname><given-names>C.</given-names></name>, &amp; <name><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>2008</year>). <article-title>A framework for studying the neurobiology of value-based decision making</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>9</volume>, <fpage>545</fpage>–<lpage>556</lpage>.</mixed-citation>
      </ref>
      <ref id="c128">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rangel</surname><given-names>A.</given-names></name>, &amp; <name><surname>Hare</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Neural computations associated with goal-directed choice</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>20</volume>, <fpage>262</fpage>–<lpage>270</lpage>.<pub-id pub-id-type="pmid">20338744</pub-id></mixed-citation>
      </ref>
      <ref id="c129">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rao</surname><given-names>S. C.</given-names></name>, <name><surname>Rainer</surname><given-names>G.</given-names></name>, &amp; <name><surname>Miller</surname><given-names>E. K.</given-names></name></person-group> (<year>1997</year>). <article-title>Integration of what and where in the primate prefrontal cortex</article-title>. <source>Science</source>, <volume>276</volume>, <fpage>821</fpage>–<lpage>824</lpage>.<pub-id pub-id-type="pmid">9115211</pub-id></mixed-citation>
      </ref>
      <ref id="c130">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, <name><surname>Hasegawa</surname><given-names>Y. T.</given-names></name>, <name><surname>Hasegawa</surname><given-names>R. P.</given-names></name>, <name><surname>Smith</surname><given-names>P. L.</given-names></name>, &amp; <name><surname>Segraves</surname><given-names>M. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Dual diffusion model for single-cell recording data from the superior colliculus in a brightness-discrimination task</article-title>. <source>Journal of Neurophysiology</source>, <volume>97</volume>, <fpage>1756</fpage>–<lpage>1774</lpage>.<pub-id pub-id-type="pmid">17122324</pub-id></mixed-citation>
      </ref>
      <ref id="c131">
        <mixed-citation publication-type="journal"><person-group><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, &amp; <name><surname>McKoon</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>The diffusion decision model: Theory and data for two-choice decision tasks</article-title>. <source>Neural Computation</source>, <volume>20</volume>, <fpage>873</fpage>–<lpage>922</lpage>.<pub-id pub-id-type="pmid">18085991</pub-id></mixed-citation>
      </ref>
      <ref id="c132">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rizzolatti</surname><given-names>G.</given-names></name>, <name><surname>Luppino</surname><given-names>G.</given-names></name>, &amp; <name><surname>Matelli</surname><given-names>M.</given-names></name></person-group> (<year>1996</year>). <article-title>The classic supplementary motor area is formed by two independent areas</article-title>. <source>Advances in Neurology</source>, <volume>70</volume>, <fpage>45</fpage>–<lpage>56</lpage>.<pub-id pub-id-type="pmid">8615224</pub-id></mixed-citation>
      </ref>
      <ref id="c133">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roesch</surname><given-names>M. R.</given-names></name>, <name><surname>Calu</surname><given-names>D. J.</given-names></name>, &amp; <name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>2007</year>). <article-title>Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>, <fpage>1615</fpage>–<lpage>1624</lpage>.</mixed-citation>
      </ref>
      <ref id="c134">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roesch</surname><given-names>M. R.</given-names></name>, &amp; <name><surname>Olson</surname><given-names>C. R.</given-names></name></person-group> (<year>2003</year>). <article-title>Impact of expected reward on neuronal activity in prefrontal cortex, frontal and supplementary eye fields and premotor cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>90</volume>, <fpage>1766</fpage>–<lpage>1789</lpage>.<pub-id pub-id-type="pmid">12801905</pub-id></mixed-citation>
      </ref>
      <ref id="c135">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roesch</surname><given-names>M. R.</given-names></name>, &amp; <name><surname>Olson</surname><given-names>C. R.</given-names></name></person-group> (<year>2004</year>). <article-title>Neuronal activity related to reward value and motivation in primate frontal cortex</article-title>. <source>Science</source>, <volume>304</volume>, <fpage>307</fpage>–<lpage>310</lpage>.<pub-id pub-id-type="pmid">15073380</pub-id></mixed-citation>
      </ref>
      <ref id="c136">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roesch</surname><given-names>M. R.</given-names></name>, &amp; <name><surname>Olson</surname><given-names>C. R.</given-names></name></person-group> (<year>2005</year>). <article-title>Neuronal activity in primate orbitofrontal cortex reflects the value of time</article-title>. <source>Journal of Neurophysiology</source>, <volume>94</volume>, <fpage>2457</fpage>–<lpage>2471</lpage>.<pub-id pub-id-type="pmid">15958600</pub-id></mixed-citation>
      </ref>
      <ref id="c137">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roesch</surname><given-names>M. R.</given-names></name>, &amp; <name><surname>Olson</surname><given-names>C. R.</given-names></name></person-group> (<year>2007</year>). <article-title>Neuronal activity related to anticipated reward in frontal cortex: Does it represent value or reflect motivation?</article-title><source>Annals of the New York Academy of Sciences</source>, <volume>1121</volume>, <fpage>431</fpage>-<lpage>446</lpage>.<pub-id pub-id-type="pmid">17846160</pub-id></mixed-citation>
      </ref>
      <ref id="c138">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roesch</surname><given-names>M. R.</given-names></name>, <name><surname>Taylor</surname><given-names>A. R.</given-names></name>, &amp; <name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>2006</year>). <article-title>Encoding of time-discounted rewards in orbitofrontal cortex is independent of value representation</article-title>. <source>Neuron</source>, <volume>51</volume>, <fpage>509</fpage>–<lpage>520</lpage>.<pub-id pub-id-type="pmid">16908415</pub-id></mixed-citation>
      </ref>
      <ref id="c139">
        <mixed-citation publication-type="journal"><person-group><name><surname>Roitman</surname><given-names>J. D.</given-names></name>, &amp; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2002</year>). <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source>Journal of Neuroscience</source>, <volume>22</volume>, <fpage>9475</fpage>–<lpage>9489</lpage>.<pub-id pub-id-type="pmid">12417672</pub-id></mixed-citation>
      </ref>
      <ref id="c140">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>2000</year>). <article-title>The orbitofrontal cortex and reward</article-title>. <source>Cerebral Cortex</source>, <volume>10</volume>, <fpage>284</fpage>–<lpage>294</lpage>.<pub-id pub-id-type="pmid">10731223</pub-id></mixed-citation>
      </ref>
      <ref id="c141">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>2010</year>). <article-title>The affective and cognitive processing of touch, oral texture, and temperature in the brain</article-title>. <source>Neuroscience and Biobehavioral Reviews</source>, <volume>34</volume>, <fpage>237</fpage>–<lpage>245</lpage>.<pub-id pub-id-type="pmid">18468687</pub-id></mixed-citation>
      </ref>
      <ref id="c142">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rolls</surname><given-names>E. T.</given-names></name>, <name><surname>Critchley</surname><given-names>H. D.</given-names></name>, <name><surname>Browning</surname><given-names>A. S.</given-names></name>, <name><surname>Hernadi</surname><given-names>I.</given-names></name>, &amp; <name><surname>Lenard</surname><given-names>L.</given-names></name></person-group> (<year>1999</year>). <article-title>Responses to the sensory properties of fat of neurons in the primate orbitofrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>19</volume>, <fpage>1532</fpage>–<lpage>1540</lpage>.<pub-id pub-id-type="pmid">9952429</pub-id></mixed-citation>
      </ref>
      <ref id="c143">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rolls</surname><given-names>E. T.</given-names></name>, <name><surname>Inoue</surname><given-names>K.</given-names></name>, &amp; <name><surname>Browning</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Activity of primate subgenual cingulate cortex neurons is related to sleep</article-title>. <source>Journal of Neurophysiology</source>, <volume>90</volume>, <fpage>134</fpage>–<lpage>142</lpage>.<pub-id pub-id-type="pmid">12843306</pub-id></mixed-citation>
      </ref>
      <ref id="c144">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rolls</surname><given-names>E. T.</given-names></name>, <name><surname>Sienkiewicz</surname><given-names>Z. J.</given-names></name>, &amp; <name><surname>Yaxley</surname><given-names>S.</given-names></name></person-group> (<year>1989</year>). <article-title>Hunger modulates the responses to gustatory stimuli of single neurons in the caudolateral orbitofrontal cortex of the macaque monkey</article-title>. <source>European Journal of Neuroscience</source>, <volume>1</volume>, <fpage>53</fpage>–<lpage>60</lpage>.<pub-id pub-id-type="pmid">12106174</pub-id></mixed-citation>
      </ref>
      <ref id="c145">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rolls</surname><given-names>E. T.</given-names></name>, <name><surname>Yaxley</surname><given-names>S.</given-names></name>, &amp; <name><surname>Sienkiewicz</surname><given-names>Z. J.</given-names></name></person-group> (<year>1990</year>). <article-title>Gustatory responses of single neurons in the caudolateral orbitofrontal cortex of the macaque monkey</article-title>. <source>Journal of Neurophysiology</source>, <volume>64</volume>, <fpage>1055</fpage>–<lpage>1066</lpage>.<pub-id pub-id-type="pmid">2258734</pub-id></mixed-citation>
      </ref>
      <ref id="c146">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rudebeck</surname><given-names>P. H.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E.</given-names></name>, <name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, <name><surname>Baxter</surname><given-names>M. G.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2008</year>). <article-title>Frontal cortex subregions play distinct roles in choices between actions and stimuli</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>, <fpage>13775</fpage>–<lpage>13785</lpage>.<pub-id pub-id-type="pmid">19091968</pub-id></mixed-citation>
      </ref>
      <ref id="c147">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rudebeck</surname><given-names>P. H.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2006</year>). <article-title>A role for the macaque anterior cingulate gyrus in social valuation</article-title>. <source>Science</source>, <volume>313</volume>, <fpage>1310</fpage>–<lpage>1312</lpage>.<pub-id pub-id-type="pmid">16946075</pub-id></mixed-citation>
      </ref>
      <ref id="c148">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rudebeck</surname><given-names>P. H.</given-names></name>, &amp; <name><surname>Murray</surname><given-names>E. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Amygdala and orbitofrontal cortex lesions differentially influence choices during object reversal learning</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>, <fpage>8338</fpage>–<lpage>8343</lpage>.<pub-id pub-id-type="pmid">18701696</pub-id></mixed-citation>
      </ref>
      <ref id="c149">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rudebeck</surname><given-names>P. H.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Smyth</surname><given-names>A. N.</given-names></name>, <name><surname>Bannerman</surname><given-names>D. M.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2006</year>). <article-title>Separate neural pathways process different decision costs</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>, <fpage>1161</fpage>–<lpage>1168</lpage>.</mixed-citation>
      </ref>
      <ref id="c150">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rushworth</surname><given-names>M. F.</given-names></name>, &amp; <name><surname>Behrens</surname><given-names>T. E.</given-names></name></person-group> (<year>2008</year>). <article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title>. <source>Nature Neuroscience</source>, <volume>11</volume>, <fpage>389</fpage>–<lpage>397</lpage>.</mixed-citation>
      </ref>
      <ref id="c151">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rushworth</surname><given-names>M. F.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, <name><surname>Gough</surname><given-names>P. M.</given-names></name>, <name><surname>Alexander</surname><given-names>I. H.</given-names></name>, <name><surname>Kyriazis</surname><given-names>D.</given-names></name>, <name><surname>McDonald</surname><given-names>K. R.</given-names></name>, &amp; <name><surname>Passingham</surname><given-names>R. E.</given-names></name></person-group> (<year>2005</year>). <article-title>Attentional selection and action selection in the ventral and orbital prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>25</volume>, <fpage>11628</fpage>–<lpage>11636</lpage>.<pub-id pub-id-type="pmid">16354921</pub-id></mixed-citation>
      </ref>
      <ref id="c152">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rushworth</surname><given-names>M. F.</given-names></name>, <name><surname>Nixon</surname><given-names>P. D.</given-names></name>, <name><surname>Eacott</surname><given-names>M. J.</given-names></name>, &amp; <name><surname>Passingham</surname><given-names>R. E.</given-names></name></person-group> (<year>1997</year>). <article-title>Ventral prefrontal cortex is not essential for working memory</article-title>. <source>Journal of Neuroscience</source>, <volume>17</volume>, <fpage>4829</fpage>–<lpage>4838</lpage>.<pub-id pub-id-type="pmid">9169541</pub-id></mixed-citation>
      </ref>
      <ref id="c153">
        <mixed-citation publication-type="journal"><person-group><name><surname>Rushworth</surname><given-names>M. F.</given-names></name>, <name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, &amp; <name><surname>Bannerman</surname><given-names>D. M.</given-names></name></person-group> (<year>2004</year>). <article-title>Action sets and decisions in the medial frontal cortex</article-title>. <source>Trends in Cognitive Science</source>, <volume>8</volume>, <fpage>410</fpage>–<lpage>417</lpage>.</mixed-citation>
      </ref>
      <ref id="c154">
        <mixed-citation publication-type="journal"><person-group><name><surname>Sallet</surname><given-names>J.</given-names></name>, <name><surname>Quilodran</surname><given-names>R.</given-names></name>, <name><surname>Rothe</surname><given-names>M.</given-names></name>, <name><surname>Vezoli</surname><given-names>J.</given-names></name>, <name><surname>Joseph</surname><given-names>J. P.</given-names></name>, &amp; <name><surname>Procyk</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>Expectations, gains, and losses in the anterior cingulate cortex</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>, <volume>7</volume>, <fpage>327</fpage>–<lpage>336</lpage>.</mixed-citation>
      </ref>
      <ref id="c155">
        <mixed-citation publication-type="journal"><person-group><name><surname>Satoh</surname><given-names>T.</given-names></name>, <name><surname>Nakai</surname><given-names>S.</given-names></name>, <name><surname>Sato</surname><given-names>T.</given-names></name>, &amp; <name><surname>Kimura</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>). <article-title>Correlated coding of motivation and outcome of decision by dopamine neurons</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>9913</fpage>–<lpage>9923</lpage>.<pub-id pub-id-type="pmid">14586021</pub-id></mixed-citation>
      </ref>
      <ref id="c156">
        <mixed-citation publication-type="journal"><person-group><name><surname>Scangos</surname><given-names>K. W.</given-names></name>, &amp; <name><surname>Stuphorn</surname><given-names>V.</given-names></name></person-group> (<year>2010</year>). <article-title>Medial frontal cortex motivates but does not control movement initiation in the countermanding task</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>, <fpage>1968</fpage>–<lpage>1982</lpage>.<pub-id pub-id-type="pmid">20130204</pub-id></mixed-citation>
      </ref>
      <ref id="c157">
        <mixed-citation publication-type="journal"><person-group><name><surname>Schoenbaum</surname><given-names>G.</given-names></name>, <name><surname>Chiba</surname><given-names>A. A.</given-names></name>, &amp; <name><surname>Gallagher</surname><given-names>M.</given-names></name></person-group> (<year>1998</year>). <article-title>Orbitofrontal cortex and basolateral amygdala encode expected outcomes during learning</article-title>. <source>Nature Neuroscience</source>, <volume>1</volume>, <fpage>155</fpage>–<lpage>159</lpage>.</mixed-citation>
      </ref>
      <ref id="c158">
        <mixed-citation publication-type="journal"><person-group><name><surname>Schoenbaum</surname><given-names>G.</given-names></name>, <name><surname>Chiba</surname><given-names>A. A.</given-names></name>, &amp; <name><surname>Gallagher</surname><given-names>M.</given-names></name></person-group> (<year>1999</year>). <article-title>Neural encoding in orbitofrontal cortex and basolateral amygdala during olfactory discrimination learning</article-title>. <source>Journal of Neuroscience</source>, <volume>19</volume>, <fpage>1876</fpage>–<lpage>1884</lpage>.<pub-id pub-id-type="pmid">10024371</pub-id></mixed-citation>
      </ref>
      <ref id="c159">
        <mixed-citation publication-type="journal"><person-group><name><surname>Schoenbaum</surname><given-names>G.</given-names></name>, <name><surname>Roesch</surname><given-names>M. R.</given-names></name>, <name><surname>Stalnaker</surname><given-names>T. A.</given-names></name>, &amp; <name><surname>Takahashi</surname><given-names>Y. K.</given-names></name></person-group> (<year>2009</year>). <article-title>A new perspective on the role of the orbitofrontal cortex in adaptive behaviour</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>, <fpage>885</fpage>–<lpage>892</lpage>.</mixed-citation>
      </ref>
      <ref id="c160">
        <mixed-citation publication-type="journal"><person-group><name><surname>Schoenbaum</surname><given-names>G.</given-names></name>, <name><surname>Setlow</surname><given-names>B.</given-names></name>, <name><surname>Saddoris</surname><given-names>M. P.</given-names></name>, &amp; <name><surname>Gallagher</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>). <article-title>Encoding predicted outcome and acquired value in orbitofrontal cortex during cue sampling depends upon input from basolateral amygdala</article-title>. <source>Neuron</source>, <volume>39</volume>, <fpage>855</fpage>–<lpage>867</lpage>.<pub-id pub-id-type="pmid">12948451</pub-id></mixed-citation>
      </ref>
      <ref id="c161">
        <mixed-citation publication-type="journal"><person-group><name><surname>Schultz</surname><given-names>W.</given-names></name>, <name><surname>Dayan</surname><given-names>P.</given-names></name>, &amp; <name><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>1997</year>). <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>, <volume>275</volume>, <fpage>1593</fpage>–<lpage>1599</lpage>.<pub-id pub-id-type="pmid">9054347</pub-id></mixed-citation>
      </ref>
      <ref id="c162">
        <mixed-citation publication-type="journal"><person-group><name><surname>Schweimer</surname><given-names>J.</given-names></name>, &amp; <name><surname>Hauber</surname><given-names>W.</given-names></name></person-group> (<year>2005</year>). <article-title>Involvement of the rat anterior cingulate cortex in control of instrumental responses guided by reward expectancy</article-title>. <source>Learning &amp; Memory</source>, <volume>12</volume>, <fpage>334</fpage>–<lpage>342</lpage>.<pub-id pub-id-type="pmid">15930509</pub-id></mixed-citation>
      </ref>
      <ref id="c163">
        <mixed-citation publication-type="journal"><person-group><name><surname>Seo</surname><given-names>H.</given-names></name>, <name><surname>Barraclough</surname><given-names>D. J.</given-names></name>, &amp; <name><surname>Lee</surname><given-names>D.</given-names></name></person-group> (<year>2007</year>). <article-title>Dynamic signals related to choices and outcomes in the dorsolateral prefrontal cortex</article-title>. <source>Cerebral Cortex</source>, <volume>17</volume>, <fpage>i110</fpage>–<lpage>i117</lpage>.<pub-id pub-id-type="pmid">17548802</pub-id></mixed-citation>
      </ref>
      <ref id="c164">
        <mixed-citation publication-type="journal"><person-group><name><surname>Seo</surname><given-names>H.</given-names></name>, &amp; <name><surname>Lee</surname><given-names>D.</given-names></name></person-group> (<year>2007</year>). <article-title>Temporal filtering of reward signals in the dorsal anterior cingulate cortex during a mixed-strategy game</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>, <fpage>8366</fpage>–<lpage>8377</lpage>.<pub-id pub-id-type="pmid">17670983</pub-id></mixed-citation>
      </ref>
      <ref id="c165">
        <mixed-citation publication-type="journal"><person-group><name><surname>Seo</surname><given-names>H.</given-names></name>, &amp; <name><surname>Lee</surname><given-names>D.</given-names></name></person-group> (<year>2009</year>). <article-title>Behavioral and neural changes after gains and losses of conditioned reinforcers</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>3627</fpage>–<lpage>3641</lpage>.<pub-id pub-id-type="pmid">19295166</pub-id></mixed-citation>
      </ref>
      <ref id="c166">
        <mixed-citation publication-type="journal"><person-group><name><surname>Shidara</surname><given-names>M.</given-names></name>, &amp; <name><surname>Richmond</surname><given-names>B. J.</given-names></name></person-group> (<year>2002</year>). <article-title>Anterior cingulate: Single neuronal signals related to degree of reward expectancy</article-title>. <source>Science</source>, <volume>296</volume>, <fpage>1709</fpage>–<lpage>1711</lpage>.<pub-id pub-id-type="pmid">12040201</pub-id></mixed-citation>
      </ref>
      <ref id="c167">
        <mixed-citation publication-type="journal"><person-group><name><surname>Shima</surname><given-names>K.</given-names></name>, &amp; <name><surname>Tanji</surname><given-names>J.</given-names></name></person-group> (<year>1998</year>). <article-title>Role for cingulate motor area cells in voluntary movement selection based on reward</article-title>. <source>Science</source>, <volume>282</volume>, <fpage>1335</fpage>–<lpage>1338</lpage>.<pub-id pub-id-type="pmid">9812901</pub-id></mixed-citation>
      </ref>
      <ref id="c168">
        <mixed-citation publication-type="journal"><person-group><name><surname>Shuler</surname><given-names>M. G.</given-names></name>, &amp; <name><surname>Bear</surname><given-names>M. F.</given-names></name></person-group> (<year>2006</year>). <article-title>Reward timing in the primary visual cortex</article-title>. <source>Science</source>, <volume>311</volume>, <fpage>1606</fpage>–<lpage>1609</lpage>.<pub-id pub-id-type="pmid">16543459</pub-id></mixed-citation>
      </ref>
      <ref id="c169">
        <mixed-citation publication-type="journal"><person-group><name><surname>Simmons</surname><given-names>J. M.</given-names></name>, &amp; <name><surname>Richmond</surname><given-names>B. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Dynamic changes in representations of preceding and upcoming reward in monkey orbitofrontal cortex</article-title>. <source>Cerebral Cortex</source>, <volume>18</volume>, <fpage>93</fpage>–<lpage>103</lpage>.<pub-id pub-id-type="pmid">17434918</pub-id></mixed-citation>
      </ref>
      <ref id="c170">
        <mixed-citation publication-type="journal"><person-group><name><surname>So</surname><given-names>N. Y.</given-names></name>, &amp; <name><surname>Stuphorn</surname><given-names>V.</given-names></name></person-group> (<year>2010</year>). <article-title>Supplementary eye field encodes option and action value for saccades with variable reward</article-title>. <source>Journal of Neurophysiology</source>, <volume>104</volume>, <fpage>2634</fpage>–<lpage>2653</lpage>.<pub-id pub-id-type="pmid">20739596</pub-id></mixed-citation>
      </ref>
      <ref id="c171">
        <mixed-citation publication-type="journal"><person-group><name><surname>Stephens</surname><given-names>D. W.</given-names></name>, &amp; <name><surname>Krebs</surname><given-names>J. R.</given-names></name></person-group> (<year>1986</year>). <source>Foraging theory</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c172">
        <mixed-citation publication-type="journal"><person-group><name><surname>Stevens</surname><given-names>J. R.</given-names></name>, <name><surname>Rosati</surname><given-names>A. G.</given-names></name>, <name><surname>Ross</surname><given-names>K. R.</given-names></name>, &amp; <name><surname>Hauser</surname><given-names>M. D.</given-names></name></person-group> (<year>2005</year>). <article-title>Will travel for food: Spatial discounting in two new world monkeys</article-title>. <source>Current Biology</source>, <volume>15</volume>, <fpage>1855</fpage>–<lpage>1860</lpage>.<pub-id pub-id-type="pmid">16243033</pub-id></mixed-citation>
      </ref>
      <ref id="c173">
        <mixed-citation publication-type="journal"><person-group><name><surname>Stuss</surname><given-names>D. T.</given-names></name>, <name><surname>Levine</surname><given-names>B.</given-names></name>, <name><surname>Alexander</surname><given-names>M. P.</given-names></name>, <name><surname>Hong</surname><given-names>J.</given-names></name>, <name><surname>Palumbo</surname><given-names>C.</given-names></name>, <name><surname>Hamer</surname><given-names>L.</given-names></name>, . . . <name><surname>Izukawa</surname><given-names>D.</given-names></name></person-group> (<year>2000</year>). <article-title>Wisconsin Card Sorting Test performance in patients with focal frontal and posterior brain damage: Effects of lesion location and test structure on separable cognitive processes</article-title>. <source>Neuropsychologia</source>, <volume>38</volume>, <fpage>388</fpage>–<lpage>402</lpage>.<pub-id pub-id-type="pmid">10683390</pub-id></mixed-citation>
      </ref>
      <ref id="c174">
        <mixed-citation publication-type="journal"><person-group><name><surname>Sul</surname><given-names>J. H.</given-names></name>, <name><surname>Kim</surname><given-names>H.</given-names></name>, <name><surname>Huh</surname><given-names>N.</given-names></name>, <name><surname>Lee</surname><given-names>D.</given-names></name>, &amp; <name><surname>Jung</surname><given-names>M. W.</given-names></name></person-group> (<year>2010</year>). <article-title>Distinct roles of rodent orbitofrontal and medial prefrontal cortex in decision making</article-title>. <source>Neuron</source>, <volume>66</volume>, <fpage>449</fpage>–<lpage>460</lpage>.<pub-id pub-id-type="pmid">20471357</pub-id></mixed-citation>
      </ref>
      <ref id="c175">
        <mixed-citation publication-type="journal"><person-group><name><surname>Sutton</surname><given-names>R. S.</given-names></name>, &amp; <name><surname>Barto</surname><given-names>A. G.</given-names></name></person-group> (<year>1998</year>). <source>Reinforcement learning</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c176">
        <mixed-citation publication-type="journal"><person-group><name><surname>Takahashi</surname><given-names>Y. K.</given-names></name>, <name><surname>Roesch</surname><given-names>M. R.</given-names></name>, <name><surname>Stalnaker</surname><given-names>T. A.</given-names></name>, <name><surname>Haney</surname><given-names>R. Z.</given-names></name>, <name><surname>Calu</surname><given-names>D. J.</given-names></name>, <name><surname>Taylor</surname><given-names>A. R.</given-names></name>, . . . <name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>The orbitofrontal cortex and ventral tegmental area are necessary for learning from unexpected outcomes</article-title>. <source>Neuron</source>, <volume>62</volume>, <fpage>269</fpage>–<lpage>280</lpage>.<pub-id pub-id-type="pmid">19409271</pub-id></mixed-citation>
      </ref>
      <ref id="c177">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tanji</surname><given-names>J.</given-names></name>, &amp; <name><surname>Hoshi</surname><given-names>E.</given-names></name></person-group> (<year>2008</year>). <article-title>Role of the lateral prefrontal cortex in executive behavioral control</article-title>. <source>Physiological Reviews</source>, <volume>88</volume>, <fpage>37</fpage>–<lpage>57</lpage>.<pub-id pub-id-type="pmid">18195082</pub-id></mixed-citation>
      </ref>
      <ref id="c178">
        <mixed-citation publication-type="journal"><person-group><name><surname>Thorndike</surname><given-names>E. L.</given-names></name></person-group> (<year>1933</year>). <article-title>A Proof of the law of effect</article-title>. <source>Science</source>, <volume>77</volume>, <fpage>173</fpage>–<lpage>175</lpage>.<pub-id pub-id-type="pmid">17819705</pub-id></mixed-citation>
      </ref>
      <ref id="c179">
        <mixed-citation publication-type="journal"><person-group><name><surname>Thorpe</surname><given-names>S. J.</given-names></name>, <name><surname>Rolls</surname><given-names>E. T.</given-names></name>, &amp; <name><surname>Maddison</surname><given-names>S.</given-names></name></person-group> (<year>1983</year>). <article-title>The orbitofrontal cortex: Neuronal activity in the behaving monkey</article-title>. <source>Experimental Brain Research</source>, <volume>49</volume>, <fpage>93</fpage>–<lpage>115</lpage>.</mixed-citation>
      </ref>
      <ref id="c180">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tobler</surname><given-names>P. N.</given-names></name>, <name><surname>Dickinson</surname><given-names>A.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2003</year>). <article-title>Coding of predicted reward omission by dopamine neurons in a conditioned inhibition paradigm</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>10402</fpage>–<lpage>10410</lpage>.<pub-id pub-id-type="pmid">14614099</pub-id></mixed-citation>
      </ref>
      <ref id="c181">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tobler</surname><given-names>P. N.</given-names></name>, <name><surname>Fiorillo</surname><given-names>C. D.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2005</year>). <article-title>Adaptive coding of reward value by dopamine neurons</article-title>. <source>Science</source>, <volume>307</volume>, <fpage>1642</fpage>–<lpage>1645</lpage>.<pub-id pub-id-type="pmid">15761155</pub-id></mixed-citation>
      </ref>
      <ref id="c182">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tremblay</surname><given-names>L.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>1999</year>). <article-title>Relative reward preference in primate orbitofrontal cortex</article-title>. <source>Nature</source>, <volume>398</volume>, <fpage>704</fpage>–<lpage>708</lpage>.<pub-id pub-id-type="pmid">10227292</pub-id></mixed-citation>
      </ref>
      <ref id="c183">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tremblay</surname><given-names>L.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2000a</year>). <article-title>Modifications of reward expectation-related neuronal activity during learning in primate orbitofrontal cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>83</volume>, <fpage>1877</fpage>–<lpage>1885</lpage>.<pub-id pub-id-type="pmid">10758099</pub-id></mixed-citation>
      </ref>
      <ref id="c184">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tremblay</surname><given-names>L.</given-names></name>, &amp; <name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>2000b</year>). <article-title>Reward-related neuronal activity during go-nogo task performance in primate orbitofrontal cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>83</volume>, <fpage>1864</fpage>–<lpage>1876</lpage>.<pub-id pub-id-type="pmid">10758098</pub-id></mixed-citation>
      </ref>
      <ref id="c185">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tsujimoto</surname><given-names>S.</given-names></name>, <name><surname>Genovesio</surname><given-names>A.</given-names></name>, &amp; <name><surname>Wise</surname><given-names>S. P.</given-names></name></person-group> (<year>2009</year>). <article-title>Monkey orbitofrontal cortex encodes response choices near feedback time</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>, <fpage>2569</fpage>–<lpage>2574</lpage>.<pub-id pub-id-type="pmid">19244532</pub-id></mixed-citation>
      </ref>
      <ref id="c186">
        <mixed-citation publication-type="journal"><person-group><name><surname>Tsujimoto</surname><given-names>S.</given-names></name>, <name><surname>Genovesio</surname><given-names>A.</given-names></name>, &amp; <name><surname>Wise</surname><given-names>S. P.</given-names></name></person-group> (<year>2010</year>). <article-title>Evaluating self-generated decisions in frontal pole cortex of monkeys</article-title>. <source>Nature Neuroscience</source>, <volume>13</volume>, <fpage>120</fpage>–<lpage>126</lpage>.</mixed-citation>
      </ref>
      <ref id="c187">
        <mixed-citation publication-type="journal"><person-group><name><surname>Uchida</surname><given-names>Y.</given-names></name>, <name><surname>Lu</surname><given-names>X.</given-names></name>, <name><surname>Ohmae</surname><given-names>S.</given-names></name>, <name><surname>Takahashi</surname><given-names>T.</given-names></name>, &amp; <name><surname>Kitazawa</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Neuronal activity related to reward size and rewarded target position in primate supplementary eye field</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>, <fpage>13750</fpage>–<lpage>13755</lpage>.<pub-id pub-id-type="pmid">18077686</pub-id></mixed-citation>
      </ref>
      <ref id="c188">
        <mixed-citation publication-type="journal"><person-group><name><surname>Usher</surname><given-names>M.</given-names></name>, &amp; <name><surname>McClelland</surname><given-names>J. L.</given-names></name></person-group> (<year>2001</year>). <article-title>The time course of perceptual choice: The leaky, competing accumulator model</article-title>. <source>Psychological Review</source>, <volume>108</volume>, <fpage>550</fpage>–<lpage>592</lpage>.<pub-id pub-id-type="pmid">11488378</pub-id></mixed-citation>
      </ref>
      <ref id="c189">
        <mixed-citation publication-type="journal"><person-group><name><surname>Vogt</surname><given-names>B. A.</given-names></name>, <name><surname>Vogt</surname><given-names>L.</given-names></name>, <name><surname>Farber</surname><given-names>N. B.</given-names></name>, &amp; <name><surname>Bush</surname><given-names>G.</given-names></name></person-group> (<year>2005</year>). <article-title>Architecture and neurocytology of monkey cingulate gyrus</article-title>. <source>Journal of Comparative Neurology</source>, <volume>485</volume>, <fpage>218</fpage>–<lpage>239</lpage>.<pub-id pub-id-type="pmid">15791645</pub-id></mixed-citation>
      </ref>
      <ref id="c190">
        <mixed-citation publication-type="journal"><person-group><name><surname>Wallis</surname><given-names>J. D.</given-names></name>, &amp; <name><surname>Kennerley</surname><given-names>S. W.</given-names></name></person-group> (<year>2010</year>). <article-title>Heterogeneous reward signals in prefrontal cortex</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>20</volume>, <fpage>191</fpage>–<lpage>198</lpage>.<pub-id pub-id-type="pmid">20303739</pub-id></mixed-citation>
      </ref>
      <ref id="c191">
        <mixed-citation publication-type="journal"><person-group><name><surname>Wallis</surname><given-names>J. D.</given-names></name>, &amp; <name><surname>Miller</surname><given-names>E. K.</given-names></name></person-group> (<year>2003</year>). <article-title>Neuronal activity in primate dorsolateral and orbital prefrontal cortex during performance of a reward preference task</article-title>. <source>European Journal of Neuroscience</source>, <volume>18</volume>, <fpage>2069</fpage>–<lpage>20681</lpage>.<pub-id pub-id-type="pmid">14622240</pub-id></mixed-citation>
      </ref>
      <ref id="c192">
        <mixed-citation publication-type="journal"><person-group><name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Bannerman</surname><given-names>D. M.</given-names></name>, <name><surname>Alterescu</surname><given-names>K.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2003</year>). <article-title>Functional specialization within medial frontal cortex of the anterior cingulate for evaluating effort-related decisions</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>6475</fpage>–<lpage>6479</lpage>.<pub-id pub-id-type="pmid">12878688</pub-id></mixed-citation>
      </ref>
      <ref id="c193">
        <mixed-citation publication-type="journal"><person-group><name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Bannerman</surname><given-names>D. M.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2002</year>). <article-title>The role of rat medial frontal cortex in effort-based decision making</article-title>. <source>Journal of Neuroscience</source>, <volume>22</volume>, <fpage>10996</fpage>–<lpage>11003</lpage>.<pub-id pub-id-type="pmid">12486195</pub-id></mixed-citation>
      </ref>
      <ref id="c194">
        <mixed-citation publication-type="journal"><person-group><name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E.</given-names></name>, <name><surname>Buckley</surname><given-names>M. J.</given-names></name>, <name><surname>Rudebeck</surname><given-names>P. H.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2010</year>). <article-title>Separable learning systems in the macaque brain and the role of orbitofrontal cortex in contingent learning</article-title>. <source>Neuron</source>, <volume>65</volume>, <fpage>927</fpage>–<lpage>39</lpage>.<pub-id pub-id-type="pmid">20346766</pub-id></mixed-citation>
      </ref>
      <ref id="c195">
        <mixed-citation publication-type="journal"><person-group><name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Kennerley</surname><given-names>S. W.</given-names></name>, <name><surname>Bannerman</surname><given-names>D. M.</given-names></name>, <name><surname>Phillips</surname><given-names>P. E.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2006</year>). <article-title>Weighing up the benefits of work: Behavioral and neural analyses of effort-related decision making</article-title>. <source>Neural Networks</source>, <volume>19</volume>, <fpage>1302</fpage>–<lpage>1314</lpage>.<pub-id pub-id-type="pmid">16949252</pub-id></mixed-citation>
      </ref>
      <ref id="c196">
        <mixed-citation publication-type="journal"><person-group><name><surname>Walton</surname><given-names>M. E.</given-names></name>, <name><surname>Rudebeck</surname><given-names>P. H.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E.</given-names></name>, &amp; <name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2011</year>). <article-title>Cingulate and orbitofrontal contributions to valuing knowns and unknowns in a changeable world</article-title>. In <person-group><name><surname>Delgado</surname><given-names>M. R.</given-names></name>, <name><surname>Phelps</surname><given-names>E.</given-names></name>, &amp; <name><surname>Robbins</surname><given-names>T. W.</given-names></name> (Eds.)</person-group>, <source>Decision making, affect, &amp; learning</source> (pp. <fpage>505</fpage>–<lpage>531</lpage>). <publisher-loc>Oxford, England</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="c197">
        <mixed-citation publication-type="journal"><person-group><name><surname>Wang</surname><given-names>X. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Decision making in recurrent neuronal circuits</article-title>. <source>Neuron</source>, <volume>60</volume>, <fpage>215</fpage>–<lpage>234</lpage>.<pub-id pub-id-type="pmid">18957215</pub-id></mixed-citation>
      </ref>
      <ref id="c198">
        <mixed-citation publication-type="journal"><person-group><name><surname>Wang</surname><given-names>Y.</given-names></name>, <name><surname>Shima</surname><given-names>K.</given-names></name>, <name><surname>Isoda</surname><given-names>M.</given-names></name>, <name><surname>Sawamura</surname><given-names>H.</given-names></name>, &amp; <name><surname>Tanji</surname><given-names>J.</given-names></name></person-group> (<year>2002</year>). <article-title>Spatial distribution and density of prefrontal cortical cells projecting to three sectors of the premotor cortex</article-title>. <source>NeuroReport</source>, <volume>13</volume>, <fpage>1341</fpage>–<lpage>1344</lpage>.<pub-id pub-id-type="pmid">12151799</pub-id></mixed-citation>
      </ref>
      <ref id="c199">
        <mixed-citation publication-type="journal"><person-group><name><surname>Watanabe</surname><given-names>M.</given-names></name></person-group> (<year>1989</year>). <article-title>The appropriateness of behavioral responses coded in post-trial activity of primate prefrontal units</article-title>. <source>Neuroscience Letters</source>, <volume>101</volume>, <fpage>113</fpage>–<lpage>117</lpage>.<pub-id pub-id-type="pmid">2505197</pub-id></mixed-citation>
      </ref>
      <ref id="c200">
        <mixed-citation publication-type="journal"><person-group><name><surname>Watanabe</surname><given-names>M.</given-names></name></person-group> (<year>1996</year>). <article-title>Reward expectancy in primate prefrontal neurons</article-title>. <source>Nature</source>, <volume>382</volume>, <fpage>629</fpage>–<lpage>632</lpage>.<pub-id pub-id-type="pmid">8757133</pub-id></mixed-citation>
      </ref>
      <ref id="c201">
        <mixed-citation publication-type="journal"><person-group><name><surname>Watanabe</surname><given-names>M.</given-names></name>, <name><surname>Hikosaka</surname><given-names>K.</given-names></name>, <name><surname>Sakagami</surname><given-names>M.</given-names></name>, &amp; <name><surname>Shirakawa</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>). <article-title>Coding and monitoring of motivational context in the primate prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>22</volume>, <fpage>2391</fpage>–<lpage>2400</lpage>.<pub-id pub-id-type="pmid">11896178</pub-id></mixed-citation>
      </ref>
      <ref id="c202">
        <mixed-citation publication-type="journal"><person-group><name><surname>Wheeler</surname><given-names>E. Z.</given-names></name>, &amp; <name><surname>Fellows</surname><given-names>L. K.</given-names></name></person-group> (<year>2008</year>). <article-title>The human ventromedial frontal lobe is critical for learning from negative feedback</article-title>. <source>Brain</source>, <volume>131</volume>, <fpage>1323</fpage>–<lpage>1331</lpage>.<pub-id pub-id-type="pmid">18344561</pub-id></mixed-citation>
      </ref>
      <ref id="c203">
        <mixed-citation publication-type="journal"><person-group><name><surname>Williams</surname><given-names>S. M.</given-names></name>, &amp; <name><surname>Goldman-Rakic</surname><given-names>P. S.</given-names></name></person-group> (<year>1998</year>). <article-title>Widespread origin of the primate mesofrontal dopamine system</article-title>. <source>Cerebral Cortex</source>, <volume>8</volume>, <fpage>321</fpage>–<lpage>345</lpage>.<pub-id pub-id-type="pmid">9651129</pub-id></mixed-citation>
      </ref>
      <ref id="c204">
        <mixed-citation publication-type="journal"><person-group><name><surname>Wise</surname><given-names>S. P.</given-names></name></person-group> (<year>2008</year>). <article-title>Forward frontal fields: Phylogeny and fundamental function</article-title>. <source>Trends in Neurosciences</source>, <volume>31</volume>, <fpage>599</fpage>–<lpage>608</lpage>.<pub-id pub-id-type="pmid">18835649</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig id="fig1" position="float">
      <label>Figure 1</label>
      <caption>
        <title>Single neurons encode value and actions in a multivariable decision-making task. (A) Subjects made choices between pairs of presented pictures. (B) There were six sets of pictures, each associated with a specific outcome. We varied the value of the outcome by manipulating either the amount of reward the subject would receive (payoff), the likelihood of receiving a reward (probability) or the number of times the subject had to press a level to earn the reward (effort). We manipulated one parameter at time, holding the other two fixed. Presented pictures were always adjacent to one another in terms of value, that is, choices were 1 versus 2, 2 versus 3, 3 versus 4 or 4 versus 5. (C and D) Spike density histograms illustrating the activity recorded from single neurons under three different types of value manipulation (probability, payoff, or effort). The vertical lines indicate the onset of the pictures indicating the value of the choice (left) and the time at which the animal was able to make his choice (right). The different colored lines indicate the value of the choice under consideration or which action the subject would select. (C) Anterior cingulate cortex (ACC) neuron encodes payoff and effort but not probability. (D) ACC neuron encodes the value and action of all three decision variables. (E) Percentage of all neurons selective for value for each decision variable. All variables are predominately coded in ACC. (F) Percentage of all neurons selective for value as a function of number of decision variables encoded. ACC neurons tend to multiplex decision value across two (as in C) and three (as in D) decision variables. (G) Percentage of all neurons selective for action for each decision variable. Orbitofrontal cortex (OFC) neurons are less likely to encode action information relative to lateral prefrontal cortex (LPFC) and ACC. χ<sup>2</sup> test, * <italic>p</italic> &lt; .05. From “Neurons in the Frontal Lobe Encode the Value of Multiple Decision Variables,” by <xref id="cr68-14" rid="c68" ref-type="bibr">S. W. Kennerley, A. F. Dahmubed, A. H. Lara, and J. D. Wallis, 2009</xref><italic>Journal of Cognitive Neuroscience, 21</italic><xref ref-type="fig" rid="fig1">Figure 1</xref>. Copyright 2008 by the Massachusetts Institute of Technology. Adapted with permission.</title>
      </caption>
      <graphic id="fig1a" xlink:href="bne_125_3_297_fig1a"/>
    </fig>
    <fig id="fig2" position="float">
      <label>Figure 2</label>
      <caption>
        <title>The influence of reward on spatial tuning in a delayed response task. (A) In the reward-space (RS) task, the subject sees two cues separated by a delay. The first cue indicates the amount of juice to expect for successful performance of the task, and the second cue indicates the location the subject must maintain in spatial working memory. The subject indicates his response by making a saccade to the location of the mnemonic cue 1 s later. The fixation cue changes to yellow to tell the subject to initiate his saccade. The space-reward (SR) task is identical except the cues appear in the opposite order. There are five different reward amounts, each predicted by one of two cues, and 24 spatial locations. (B and C) Spike density histograms of single neurons illustrating how the size of an expected reward can modulate spatial tuning of information held in working memory. The graphs illustrate neuronal activity as animals remember different locations on a computer screen under the expectancy of receiving either a small or a large reward for correct performance. The gray bar indicates the presentation of the mnemonic spatial cue. To enable clear visualization, the spatial data is collapsed into four groups consisting of six of the 24 possible spatial locations tested. The inset indicates the mean standardized firing rate of the neuron across the 24 spatial locations. (B) When the subject expected a small reward, the neuron showed little spatial selectivity, which consisted of an increase in firing rate when the subject was remembering locations in the top left of the screen. When the subject expected a large reward for correct performance, spatial selectivity dramatically increased with a high firing rate for locations in the top left of the screen and a low firing rate for locations in the bottom right. Spatial selectivity was primarily evident only during cue presentation. (C) A neuron that showed moderate spatial selectivity when the subject expected a small reward, but a dramatic increase in spatial selectivity for targets in the top right when the subject expected a large reward. This reward modulation of spatial selectivity persisted into the delay period, indicating a reward modulation of the information contained in working memory. Panel A from “Reward-Dependent Modulation of Working Memory in Lateral Prefrontal Cortex,” by S. W. Kennerley and J. D. Wallis, 2009, Journal of Neuroscience, 29, p. 3260, <xref ref-type="fig" rid="fig1">Figure 1</xref><xref id="cr190-5" rid="c190" ref-type="bibr">J. D. Wallis and S. W. Kennerley, 2010</xref><xref ref-type="fig" rid="fig3">Figure 3</xref></title>
      </caption>
      <graphic id="fig2a" xlink:href="bne_125_3_297_fig2a"/>
    </fig>
    <fig id="fig3" position="float">
      <label>Figure 3</label>
      <caption>
        <title>Single neurons encode reward prediction errors. (A and B) Spike density histograms illustrating the activity of single neurons synched to the presentation of conditioned stimuli (left panels) associated with different probabilities of reward delivery, or synched to the onset of reward on rewarded trials (middle columns) or the expected onset of reward on nonrewarded trial (right columns). The vertical lines in the left panel indicate the onset of the choice stimuli (left) and the time at which the animal was able to make his choice (right); the vertical lines in the middle and right columns indicate the time at which the reward was (rewarded trial) or would have been (nonrewarded trial) delivered following the choice. The different colored lines indicate the value of the chosen probability stimulus which also determines the size of the prediction error (PE) where PE equals <italic>1 - chosen probability</italic> for rewarded trials and <italic>0 - chosen probability</italic> for nonrewarded trials. The lower row of plots indicates the regression coefficients (RC) from a sliding linear regression, testing the relationship between the neuron's firing rate and the probability of reward delivery. Red data points indicate time points in which the probability of reward delivery (or size of prediction error) significantly predicted the neuron's firing rate. (A) Anterior cingulate cortex (ACC) neuron encodes expected probability at the time of choice (left panel). This neuron also encodes a positive prediction error at the time of reward onset (middle column), but is insensitive to negative prediction errors (right column). (B) ACC neuron encodes expected probability at the time of choice (left panel), encodes positive prediction errors on rewarded trials (middle column), and encodes negative prediction errors on nonrewarded trials (right column). (C) Percentage of all neurons selective for positive prediction errors only, negative prediction errors only, or both positive and negative prediction errors. ACC neurons are more likely to encode positive prediction errors or both positive and negative prediction errors relative to lateral prefrontal cortex (LPFC) and OFC. OFC = orbitofrontal cortex. χ<sup>2</sup> test, * <italic>p</italic> &lt; .05.</title>
      </caption>
      <graphic id="fig3a" xlink:href="bne_125_3_297_fig3a"/>
    </fig>
    <fig id="fig4" position="float">
      <label>Figure 4</label>
      <caption>
        <title>Use of reward information as evidence for selecting the correct response. (A and B) Schematics of the stimulus- (panel A) and action-based reversal learning tasks (panel B). For the stimulus-based task, animals chose between two stimuli presented on the left and right of a touchscreen, only one of which was associated with reward across a block of trials. Stimulus-outcome contingencies reversed (i.e., the other stimulus became the rewarded stimulus) after animals had performed at 90% correct (27/30) across 2 days of testing. For the action-based task, animals chose between two joystick movements, only one of which was associated with reward across a block of trials. Action-outcome contingencies reversed (i.e., the other action became the rewarded action) after animals had gained 25 rewards for a particular action. (C) Effect of orbitofrontal cortex (OFC) lesions on using reinforcement information in the stimulus-based reversal task. (From “Amygdala and Orbitofrontal Cortex Lesions Differentially Influence Choices During Object Reversal Learning,” by <xref id="cr148-3" rid="c148" ref-type="bibr">P. H. Rudebeck and E. A. Murray, 2008</xref><italic>Journal of Neuroscience, 28</italic><xref ref-type="fig" rid="fig5">Figure 5</xref>. Copyright 2008 by E. A. Murray. Adapted with permission). (D) Effect of OFC lesions on using reinforcement information in the action-based joystick reversal task (From “Frontal cortex subregions play distinct roles in choices between actions and stimuli,” by <xref id="cr146-6" rid="c146" ref-type="bibr">P. H. Rudebeck, T. E. Behrens, S. W. Kennerley, M. G. Baxter, M. J. Buckley, M. E. Walton, and M. F. Rushworth, 2008</xref><italic>Journal of Neuroscience, 28</italic><xref ref-type="fig" rid="fig5">Figure 5</xref>. Copyright 2008 by S. W. Kennerley. Adapted with permission). (E) Effect of anterior cingulate cortex (ACC) lesions on using reinforcement information in the stimulus-based reversal task. (F) Effect of ACC lesions on using reinforcement information in the action-based joystick reversal task (From “Optimal Decision Making and the Anterior Cingulate Cortex,” by <xref id="cr72-4" rid="c72" ref-type="bibr">S. W. Kennerley, M. E. Walton, T. E. Behrens, M. J. Buckley, and M. F. Rushworth, 2006</xref><italic>Nature Neuroscience, 9</italic><xref ref-type="fig" rid="fig3">Figure 3</xref>. Copyright 2006 by S. W. Kennerley. Adapted with permission). E + 1 = performance on a trial after an error; EC + 1 = performance on a trial following a single correct response after an error; EC (<italic>N</italic>) + 1 = performance on a trial following <italic>N</italic> correct responses after an error. Data are included for each trial type for which every animal had at least 10 instances (which is why there are fewer trial types in the analysis of the stimulus-based reversal task in <xref id="cr148-4" rid="c148" ref-type="bibr">Rudebeck &amp; Murray, 2008</xref></title>
      </caption>
      <graphic id="fig4a" xlink:href="bne_125_3_297_fig4a"/>
    </fig>
    <fig id="fig5" position="float">
      <label>Figure 5</label>
      <caption>
        <title>Choices on a changeable three-armed bandit task and the influences on current behavior. (A) Two example predetermined reward schedules. The schedules determined whether reward was delivered for selecting a stimulus (stimulus A to C) on a particular trial. Dashed black lines represent the reversal point in the schedule when the identity of the highest value stimulus changes. (B) Average likelihood of choosing the highest value stimulus in the two schedules in the control (solid black line) and orbitofrontal cortex (OFC) groups (dashed black line). <italic>SEM</italic>s are filled gray and blue areas respectively for the two groups. Colored points represent the reward probability of the highest value stimulus. (C) Matrix of components included in logistic regression and influence of (i) recent choices and their specific outcomes (red Xs, bottom right graph); (ii) the previous choice and each recent past outcome (blue Xs, top right graph); and (iii) the previous outcome and each recent past choice (green Xs, bottom left graph), on current behavior. Green area represents influence of associations between choices and rewards received in the past; blue area represents the influence of associations between past rewards and choices made in the subsequent trials. The data for the first trial in the past in the three plots are identical. Controls, solid black lines; OFCs, dashed gray lines. From “Separable Learning Systems in the Macaque Brain and the Role of Orbitofrontal Cortex in Contingent Learning,” by <xref id="cr194-3" rid="c194" ref-type="bibr">M. E. Walton, T. E. Behrens, M. J. Buckley, P. H. Rudebeck, and M. F. Rushworth, 2010</xref><italic>Neuron, 65</italic><xref ref-type="fig" rid="fig1">Figures 1</xref><xref ref-type="fig" rid="fig2">2</xref></title>
      </caption>
      <graphic id="fig5a" xlink:href="bne_125_3_297_fig5a"/>
    </fig>
  </floats-group>
</article>
