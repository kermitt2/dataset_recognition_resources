<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN">
  <?properties open_access?>
  <?properties no_embargo?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Cogn Neuropsychol</journal-id>
      <journal-id journal-id-type="publisher-id">pcgn</journal-id>
      <journal-title>Cognitive Neuropsychology</journal-title>
      <issn pub-type="ppub">0264-3294</issn>
      <issn pub-type="epub">1464-0627</issn>
      <publisher>
        <publisher-name>Psychology Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2679997</article-id>
      <article-id pub-id-type="pmid">19424881</article-id>
      <article-id pub-id-type="doi">10.1080/13546800802550134</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Grouping in object recognition: The role of a Gestalt law in letter identification</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Pelli</surname>
            <given-names>Denis G.</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Majaj</surname>
            <given-names>Najib J.</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Raizman</surname>
            <given-names>Noah</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Christian</surname>
            <given-names>Christopher J.</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>Edward</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Palomares</surname>
            <given-names>Melanie C.</given-names>
          </name>
        </contrib>
        <aff>Psychology and Neural Science, New York University, New York, NY, USA</aff>
      </contrib-group>
      <author-notes>
        <corresp>Correspondence should be addressed to Denis G. Pelli, Psychology Dept., New York University, New York, NY 10003, USA (E-mail <email>denis.pelli@nyu.edu</email>).</corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>07</day>
        <month>5</month>
        <year>2009</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>2</month>
        <year>2009</year>
      </pub-date>
      <volume>26</volume>
      <issue>1</issue>
      <fpage>36</fpage>
      <lpage>49</lpage>
      <permissions>
        <copyright-statement>&#xA9; 2009 Psychology Press, an imprint of the Taylor &amp; Francis Group, an Informa business</copyright-statement>
        <copyright-year>2009</copyright-year>
        <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0/">
          <p>This is an open access article distributed under the <ext-link ext-link-type="uri" xlink:href="http://www.informaworld.com/mpp/uploads/iopenaccess_tcs.pdf">Supplemental Terms and Conditions for iOpenAccess articles published in Taylor &amp; Francis journals</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p>
        </license>
      </permissions>
      <abstract>
        <p>The Gestalt psychologists reported a set of laws describing how vision groups elements to recognize objects. The Gestalt laws &#x201C;prescribe for us what we are to recognize &#x2018;as one thing&#x2019;&#x201D; (<xref ref-type="bibr" rid="b24">K&#xF6;hler, 1920</xref>). Were they right? Does object recognition involve grouping? Tests of the laws of grouping have been favourable, but mostly assessed only detection, not identification, of the compound object. The grouping of elements seen in the detection experiments with lattices and &#x201C;snakes in the grass&#x201D; is compelling, but falls far short of the vivid everyday experience of recognizing a familiar, meaningful, named thing, which mediates the ordinary identification of an object. Thus, after nearly a century, there is hardly any evidence that grouping plays a role in ordinary object recognition. To assess grouping in object recognition, we made letters out of grating patches and measured threshold contrast for identifying these letters in visual noise as a function of perturbation of grating orientation, phase, and offset. We define a new measure, &#x201C;wiggle&#x201D;, to characterize the degree to which these various perturbations violate the Gestalt law of good continuation. We find that efficiency for letter identification is inversely proportional to wiggle and is wholly determined by wiggle, independent of how the wiggle was produced. Thus the effects of three different kinds of shape perturbation on letter identifiability are predicted by a single measure of goodness of continuation. This shows that letter identification obeys the Gestalt law of good continuation and may be the first confirmation of the original Gestalt claim that object recognition involves grouping.</p>
      </abstract>
      <kwd-group>
        <kwd>Gestalt</kwd>
        <kwd>Grouping</kwd>
        <kwd>Contour integration</kwd>
        <kwd>Good continuation</kwd>
        <kwd>Letter identification</kwd>
        <kwd>Object recognition</kwd>
        <kwd>Features</kwd>
        <kwd>Snake in the grass</kwd>
        <kwd>Snake letters</kwd>
        <kwd>Dot lattice</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <p>In what many take as the defining paper of the Gestalt movement in perception, <xref ref-type="bibr" rid="b57">Wertheimer (1923</xref>; translated in <xref ref-type="bibr" rid="b9">Ellis, 1938</xref>) made a bold claim, the laws of grouping, and set an ambitious goal, to understand object recognition. In that paper, &#x201C;Laws of organization in perceptual forms&#x201D;, he said: &#x201C;I stand at the window and see a house, trees, sky.. . .. I gaze for a long time.. . . And I discover that part of a window sash and part of a bare branch together compose an <italic>N</italic>.&#x201D; Wertheimer presented several &#x201C;Gestalt&#x201D; laws that describe how we group elements to see shape. The Gestalt laws &#x201C;prescribe for us what we are to recognize &#x2018;as one thing&#x2019;&#x201D; (<xref ref-type="bibr" rid="b24">K&#xF6;hler, 1920</xref>; excerpts are translated in <xref ref-type="bibr" rid="b9">Ellis, 1938</xref>. We quote p. 168 [German]/p. 32 [English].). Nearly a century later, the laws have held up well. They are routinely mentioned and accepted. A few more have been added. None have been rejected. Wertheimer got the ball rolling by presenting compelling visual demonstrations of each law. For example, he presented regular lattices of dots with different spacings horizontally and vertically and showed that this spacing determined the perceived grouping into rows or columns (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Many of us show Wertheimer's demonstration, unchanged, in our undergraduate classes in perception because it makes his point well. It shows a Gestalt law in action: Proximity promotes grouping. The grouping is assessed by the observer's binary preference (column vs. row). It is just as exciting today as in 1923 that simple principles can be demonstrated so easily, bringing us closer to understanding how we recognize objects. It was brilliant to play off horizontal versus vertical grouping, allowing simple printed demos to titrate the various laws of grouping against each other. It is a rich paradigm, still bearing fruit (<xref ref-type="bibr" rid="b28">Kubovy &amp; van den Berg, 2008</xref>).</p>
    <fig id="fig1" position="float">
      <label>Figure 1</label>
      <caption>
        <p>Dot lattices, reproduced from <xref ref-type="bibr" rid="b57">Wertheimer (1923)</xref>, demonstrating grouping by proximity. Columns (left) or rows (right) are evident, but they are not familiar, meaningful, named things.</p>
      </caption>
      <graphic xlink:href="pcgn26-36-f1"/>
    </fig>
    <p><xref ref-type="bibr" rid="b34">Palmer and Rock (1994</xref>, p. 30) said, &#x201C;The Gestalt work on perceptual organization has been widely accepted as identifying crucial phenomena of perception, yet it has had curiously little impact on and integration with modern perceptual theory&#x201D;. Wertheimer's dot lattice is exciting as a first step, but disappointing as an end point, if the goal is to understand object recognition. Everyone reports seeing grouping in the lattices, but seeing elements as a group is only a pale shadow of ordinary object recognition (<xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>). Here we present experiments showing that grouping (specifically, good continuation) contributes to object recognition (identifying a letter). Before presenting our experiments, we draw the reader's attention to the surprising omission of object recognition in the large literature on grouping. Thus, this may be the first evidence that grouping contributes to object recognition.</p>
    <fig id="fig2" position="float">
      <label>Figure 2</label>
      <caption>
        <p>An R, demonstrating ordinary object recognition: a familiar, meaningful, named thing.</p>
      </caption>
      <graphic xlink:href="pcgn26-36-f2"/>
    </fig>
    <p>How can this be? Are there not innumerable examples in the literature of grouping influencing object recognition? What about the Gottschaldt embedded figures, and the many papers on figure&#x2013;ground and a modal completion? Most of the studies of grouping, including those just mentioned, used binary discrimination tasks, which tend not to demand ordinary object recognition. <xref ref-type="bibr" rid="b17">Gottschaldt's (1926)</xref> embedded figures show that observers have great difficulty detecting a given familiar simple figure within a complex one; there is only one possible target, and it is a yes/no detection task. It is impressively difficult to find the target, but, even when one does succeed, this task does not seem to be an example of ordinary object recognition, which is quick, familiar, meaningful, and named. Recognition in the Gottschaldt task is familiar, but not quick.</p>
    <sec>
      <title>Grouping elements versus recognizing an object</title>
      <p>We all spend our days recognizing objects, including words. This ordinary process of object recognition is a vivid rich experience. The object is typically a familiar thing. In recognizing it, we typically attach a short name and meaning, and we know its parts and what we can do with it (<xref ref-type="bibr" rid="b15">Gibson, 1979</xref>; <xref ref-type="bibr" rid="b47">Rosch, Mervis, Gray, Johnson, &amp; Boyes-Braem, 1976</xref>; <xref ref-type="bibr" rid="b53">Tversky &amp; Hemenway, 1984</xref>). That ordinary case corresponds, roughly, to <italic>basic</italic> object categorization (<xref ref-type="bibr" rid="b47">Rosch et al., 1976</xref>). Object recognition is vivid in the ordinary case, but becomes less and less vivid as the ordinary conditions (familiarity, name, meaning, basic category, one of many) are stripped away.</p>
      <p>The essence of object recognition is the categorization. Thus the task assigned to the observer greatly affects the experience. We lack a hard and fast rule, but we can identify some important factors that affect whether the observer will see mere grouping of elements or quickly recognize a familiar, meaningful, named thing. Rosch et al. noted that superordinate and subordinate categories, larger and smaller than basic categories, have longer names and longer reaction times. Discrimination tasks (with two alternatives) seem less object oriented than identification tasks (with many alternatives). Object categories seem more evident in tasks that have a higher memory load (see &#x201C;Categorical perception&#x201D; below).</p>
      <p>In psychophysics, we distinguish three tasks: detecting, discriminating, and identifying. In practice, the distinction boils down to the number of response categories allowed: two for detecting and discriminating, and more for identifying. We include detection as a special case of discrimination, because we can always think of the discrimination between A and B as detecting the difference, A minus B. So we concentrate on the difference between discriminating and identifying. Of course, discriminating between two possible objects is equivalent to identifying one of two possible objects. But, when identifying one of <italic>n</italic> objects, it turns out that the <italic>n</italic> = 2 case is very different from the rest, <italic>n</italic> &gt; 2.</p>
      <p>The familiar game of twenty questions is an effective way to probe someone's conception of an object. But, in that game, those binary yes/no questions are all different. When, in the typical psychophysical experiment, observers are asked to make the same binary perceptual discrimination again and again, the task, for the observer, seems less and less about objects and more and more about the raw stimulus experience, the sensation.</p>
      <p>The <italic>n</italic> = 2 case is also special for the ideal observer. Ideal identification of one of <italic>n</italic> possible signals involves comparing the noisy stimulus with <italic>n</italic> templates (to calculate likelihood of the <italic>n</italic> hypotheses). (For treatment of the ideal identifier, see <xref ref-type="bibr" rid="b55">Van Trees, 1968</xref>, or Appendix A of <xref ref-type="bibr" rid="b36">Pelli, Burns, Farell, &amp; Moore-Page, 2006</xref>.) However, as noted above, there is a shortcut when <italic>n</italic> = 2. Identifying one of two signals is equivalent to detecting the difference. The observer can compare the stimulus with the difference template and calculate the likelihood ratio of the two hypotheses and use that as the basis for the binary decision. This is mathematically equivalent and has the virtue of requiring less computation and, most important, requires memory of only one template. When <italic>n</italic> &gt; 2, considering the differences among the signals is no longer attractive as there are at least as many differences (1 vs. 2, 2 vs. 3, 1 vs. 3) as signals.</p>
      <p>By the way, there is nothing wrong with dots. Letters made of dots are still good letters. And let us not forget <xref ref-type="bibr" rid="b19">Johansson's (1973</xref>, <xref ref-type="bibr" rid="b20">1975)</xref> point-light displays: &#x201C;a few bright spots (5&#x2013;12) in &#x2026; motion evoke a vivid impression of a walking, running, etc., human being&#x201D; (<xref ref-type="bibr" rid="b21">Johansson, 1976</xref>). &#x201C;From only a few moving point lights, attached to the joints of an otherwise invisible moving actor, people readily perceive the underlying human figure, categorize the displayed action after viewing it for only fractions of a second, and can even perform subtle tasks such as gender recognition&#x201D; (<xref ref-type="bibr" rid="b2">Beintema, Georg, &amp; Lappe, 2006</xref>).</p>
    </sec>
    <sec>
      <title>No hard and fast rule</title>
      <p>To our surprise, none of the factors that we have identified as important seem to be essential. Identifying a nameless squiggle (or Greeble) is less vivid than the ordinary case, but more vivid than mere grouping. Most binary discriminations fail to yield vivid objects, but the discrimination of certain object properties is much worse when the stimulus is not seen as an object. In these cases, good discrimination demands object recognition. For example, observers are much better at judging whether the barrel/hourglass illusory contour defined by four tilted corners is fat (barrel) or thin (hourglass) if the corners are perceived as four corners of one object rather than as four disconnected elements (<xref ref-type="bibr" rid="b45">Ringach &amp; Shapley, 1996</xref>).</p>
      <p>Our point is not merely semantic. We claim that mere grouping is not object recognition, but we do not know where to draw the line for what to accept as object recognition. We could relinquish that claim and accept mere grouping as a very weak form of object recognition, lacking essential qualities of ordinary object recognition. We insist that ordinary everyday object recognition is quick, familiar, meaningful, and named, and that most of these qualities are absent from most, if not all, of the existing tests of grouping.</p>
    </sec>
    <sec>
      <title>Categorical perception</title>
      <p>One of the hallmarks of object recognition is categorical perception, whereby observers discriminate the same physical difference in a stimulus parameter much better if the difference crosses a category boundary, so that the two alternatives are perceived as different things. Consider a well-known example from speech perception. (For similar evidence of categorical perception in vision, see <xref ref-type="bibr" rid="b16">Goldstone, 1994</xref>.) A syllable sound can be synthesized with various voice onset times. The voice onset time can be set to any value on a continuous scale, but the synthesized sound is perceived as qualitatively different over that range&#x2014;for example, ba, da, pa. The breaks between categories are at different voice onset times for native speakers of different languages. This categorization is demonstrated in a hard task, &#x201C;ABX&#x201D;, that requires the observer to retain three sounds in order to make a judgement. (The observer must say whether the stimulus was ABA or ABB, where A and B are sounds played one after another. A and B change randomly from trial to trial.) However, if the task is replaced by a binary discrimination of a single sound, A or B (which do not change within a block), the just-noticeable difference for voice onset time is reduced enormously and shows no correlation with the location of the category boundaries of the listener's language (<xref ref-type="bibr" rid="b5">Carney, Widin, &amp; Viemeister, 1977</xref>).</p>
      <p>The easy binary discrimination with light memory load seems to assess early sensory limits. The hard ABX task is also binary (identifying X as A or B) but has a high memory load and exhibits category boundaries like those observed in perception of speech, in which the memory load may be similarly high. It seems that we can judge a single sensory impression without categorizing coarsely, but when forced to compare several impressions we rely on object-based memories that are coarsely categorized.</p>
    </sec>
    <sec>
      <title>Snake in the grass</title>
      <p>Subsequent investigators refined Wertheimer's dot lattice technique, studying factors that bias the observer to report the elements as grouped in one way or the other (<xref ref-type="bibr" rid="b10">Epstein, 1988</xref>; <xref ref-type="bibr" rid="b18">Hochberg &amp; Peterson, 1987</xref>; <xref ref-type="bibr" rid="b22">Kanizsa, 1976</xref>; <xref ref-type="bibr" rid="b27">Kubovy, Holcombe, &amp; Wagemans, 1998</xref>; <xref ref-type="bibr" rid="b42">Peterson &amp; Gibson, 1994</xref>; <xref ref-type="bibr" rid="b46">Rock &amp; Palmer, 1990</xref>). <xref ref-type="bibr" rid="b11">Field, Hayes, and Hess (1993)</xref> updated Wertheimer's paradigm, asking observers to detect a contour (a curvilinear grouping) in a field of randomly perturbed elements (gratings). This task is affectionately called detecting a &#x201C;snake in the grass&#x201D; (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Elements (gratings) are placed along an invisible path. Proximity and good continuation among the elements increase the probability that the observer will see the elements as a group and thus detect the path. It is now well established that observers are less likely to detect contours that violate the Gestalt laws of good continuation (<xref ref-type="bibr" rid="b1">Beck, Rosenfeld, &amp; Ivry, 1989</xref>; <xref ref-type="bibr" rid="b4">Brunswik &amp; Kamiya, 1953</xref>; <xref ref-type="bibr" rid="b6">Dakin &amp; Hess, 1998</xref>; <xref ref-type="bibr" rid="b25">Kovacs, 1996</xref>; <xref ref-type="bibr" rid="b26">Kovacs &amp; Julesz, 1994</xref>; <xref ref-type="bibr" rid="b32">McIlhagga &amp; Mullen, 1996</xref>). Geisler et al. measured the edge co-occurrence statistics of natural images and showed that a grouping model based on these statistics predicts the observer's contour-detection performance (<xref ref-type="bibr" rid="b8">Elder &amp; Goldberg, 2002</xref>; <xref ref-type="bibr" rid="b14">Geisler, Perry, Super, &amp; Gallogly, 2001</xref>). However, all this only addresses the observer's ability to detect (not identify) a contour. When the contour represents a recognizable shape, does grouping help identification, as Wertheimer claimed? Detection is a binary discrimination and, we argued above, does not typically result in object recognition. Just detecting (noting a difference) shows a role for grouping in perception, but falls short of showing a role in object recognition.</p>
      <fig id="fig3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>A snake (left) and a snake in the grass (right). From <xref ref-type="bibr" rid="b11">Field, Hayes, and Hess (1993)</xref>. &#x201C;In this example each successive element differs in orientation by &#xB1;30 deg and for this difference in orientation the string of aligned elements is easily detected.&#x201D; We detect the &#x201C;snake&#x201D; but it is not a familiar, meaningful, named thing.</p>
        </caption>
        <graphic xlink:href="pcgn26-36-f3"/>
      </fig>
    </sec>
    <sec>
      <title>Letters</title>
      <p>Letter identification is mediated by feature detection (<xref ref-type="bibr" rid="b36">Pelli et al., 2006</xref>). The features are simple and detected independently. The feature detectors mediating letter identification are the same well-known spatial frequency channels as those that mediate grating detection (<xref ref-type="bibr" rid="b30">Majaj, Liang, Martelli, Berger, &amp; Pelli, 2003</xref>; <xref ref-type="bibr" rid="b31">Majaj, Pelli, Kurshan, &amp; Palomares, 2002</xref>; <xref ref-type="bibr" rid="b50">Solomon &amp; Pelli, 1994</xref>). Despite reading a billion letters over a lifetime, people still recognize letters (and words) by detecting many simple features rather than detecting each letter (or word) as a whole, which would be much more efficient (<xref ref-type="bibr" rid="b13">Geisler &amp; Murray, 2003</xref>; <xref ref-type="bibr" rid="b36">Pelli et al., 2006</xref>; <xref ref-type="bibr" rid="b38">Pelli, Farell, &amp; Moore, 2003</xref>).</p>
      <p>We argue above that the binary discrimination tasks typically do not demand object recognition, and that the observer may not be doing it. Requiring the observer to identify is important. But it is not necessary to bring the whole world into the lab to get observers to do ordinary object recognition. The humble task of identifying letters is enough. It is quick, familiar, meaningful, named recognition (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p>
    </sec>
    <sec>
      <title>Snake letters</title>
      <p>To get back to Wertheimer's original goal of understanding object recognition, especially letter identification, we created letter-shaped contours and displayed them on a background of visual noise. Our alphabet, based on Sloan's, has 10 letters (see Method). This task allows us to directly measure efficiency of letter identification as a function of deviation from collinearity. Each standard (Sloan) letter is defined by the path a pen's stroke would follow in drawing it. In the standard condition, gratings are placed at regular intervals along the letter's (invisible) path, aligned with the path. We perturbed collinearity by rotating, offsetting, or phase shifting successive gratings, right or left alternately, relative to the path (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p>
      <fig id="fig4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Measuring wiggle. The first row shows three unperturbed letters: The gratings are collinear with the path of the letter. The second row shows a sample letter for each of our three perturbations: orientation (Z), offset (R), and phase (S). In the third row, we use a straight stroke path and fit a sinusoid tangent to the white&#x2013;black zero crossings nearest to the centre of each grating. White is always to the left of the sinusoid. Finally, in the bottom row, we measure the angle the sinusoid makes with its own axis.</p>
        </caption>
        <graphic xlink:href="pcgn26-36-f4"/>
      </fig>
      <p><xref ref-type="fig" rid="fig4">Figure 4</xref> shows some perturbed letters. Note that the perturbation seems to bend the stroke, making it seem serpentine or wiggly. Inspired by this impression, we fitted a sinusoid, tangent to the white&#x2013;black (not black&#x2013;white) crossing nearest to the centre of the gratings. We define <italic>wiggle</italic> as the angle the sinusoid makes with its axis.</p>
      <p>Each wiggled alphabet was created once and was then used unchanged through all training and testing.</p>
      <p>The noise background was fresh (independent, identically distributed) on each presentation. The visual noise background swamps any additive intrinsic noise in the observer and makes the task an explicit computational problem, for which the optimal algorithm (maximum likelihood choice among the possible letters) may be solved mathematically and implemented as a computer program that represents the <italic>ideal observer</italic> (Appendix A of <xref ref-type="bibr" rid="b36">Pelli et al., 2006</xref>). We measured threshold contrast for 82% correct letter identification for both human and ideal observers. At threshold, we computed the contrast energy, integrated square of the contrast function over the signal area. The ratio of threshold energies, ideal over human, is called <italic>efficiency</italic> (<xref ref-type="bibr" rid="b37">Pelli &amp; Farell, 1999</xref>).<xref ref-type="fn" rid="fn1">1</xref> Efficiency strips away the intrinsic difficulty of the task to reveal a pure measure of human ability. See <xref ref-type="bibr" rid="b37">Pelli and Farell (1999)</xref> for a tutorial explaining how to measure efficiency.</p>
      <p>Our paradigm is similar in some ways to the tumbling E test introduced by <xref ref-type="bibr" rid="b29">Levi, Sharma, and Klein (1997)</xref>. Like our snake letters, their letters consisted of gabors. However, instead of adding a white noise background they perturbed the position of each gabor randomly on each presentation. Like us, they compare human and ideal thresholds to compute efficiency, but their manipulations did not assess the role of grouping, so their results are not relevant here.</p>
      <p>More relevant is the tumbling C test of <xref ref-type="bibr" rid="b48">Saarinen and Levi (2001)</xref>. They made a Landolt C (a perfect circle with a gap) out of gabors and presented the C at one of four orientations (90&#xB0; apart), asking the observer to say which. They compared the threshold contrast for Cs made up of gabors that were all collinear with the C's path, or all orthogonal with the path, or each randomly collinear or orthogonal. Like us, they found that the orthogonal case resulted in higher thresholds than the collinear case. (The random case elevated threshold slightly more than the orthogonal case, but this difference was statistically significant for only one of the three observers, and in the group average.) They note in their abstract that their use of four-way identification was an advance on the prior work, which was all binary discrimination: &#x201C;A number of previous studies have reported that integration of local information can aid &#x2018;pop-out&#x2019; or enhance discrimination of figures embedded in distractors. Our study differs from the previous studies in that, rather than a figure&#x2013;ground discrimination, our experiments measured contrast thresholds for shape identification&#x201D; (<xref ref-type="bibr" rid="b48">Saarinen &amp; Levi, 2001</xref>). While four-way identification is indeed an advance, it is our impression (confirmed by Levi, personal communication) that, at least subjectively, this particular task quickly reduces to detecting the gap and reporting its location, especially when near threshold. Thus, even though they were asking observers to identify four versions of a letter, it does not seem that the observers were doing ordinary object recognition.</p>
      <p><xref ref-type="fig" rid="fig5">Figure 5</xref> presents letter-chart versions of two of our three experiments, perturbing orientation (left panel) and offset (right panel). (We could not make a similar three-column chart for phase wiggle, because, as we defined it, there are only two strengths: on and off.) The perturbation increases from left to right. Letter contrast diminishes from bottom to top. For each column (perturbation) your efficiency is given by the highest (faintest) letter you can identify. Note the drop in efficiency as wiggle increases from left to right.</p>
      <fig id="fig5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Letters in noise, demonstrating that good continuation is important for letter identification. For each letter chart, starting from the bottom, read up each column as far as you can. The height of the faintest identifiable letter is your contrast sensitivity for such letters. a. The orientation of the gratings relative to the letter stroke alternates &#xB1;0&#xB0;, &#xB1;30&#xB0;, or &#xB1;60&#xB0; (left to right). b. The offset of the gratings from the letters stroke alternates &#xB1;0, &#xB1;2, or &#xB1;4 cycles (left to right). Letter contrast <italic>L</italic><sub>max</sub>&#x2212;<italic>L</italic><sub>background</sub>) / <italic>L</italic><sub>background</sub> decreases by factors of &#x221A;2 from 0.87 in the bottom row to 0.11 in the top row. The root mean square noise contrast is 0.15.</p>
        </caption>
        <graphic xlink:href="pcgn26-36-f5"/>
      </fig>
      <p>A &#x201C;wiggle&#x201D; is &#x201C;a wavy line drawn by a pen, pencil, etc.&#x201D; (<italic>Oxford English Dictionary</italic>, noun, 3). Others have measured sinusoidal curvature in order to study shape perception (e.g., <xref ref-type="bibr" rid="b44">Prins, Kingdom, &amp; Hayes, 2007</xref>; <xref ref-type="bibr" rid="b49">Siddiqi, Kimia, Tannenbaum, &amp; Zucker, 1999</xref>; <xref ref-type="bibr" rid="b54">Tyler, 1973</xref>; <xref ref-type="bibr" rid="b58">Wilson &amp; Richards, 1989</xref>). Our treatment of wiggle is novel in applying one metric to three different kinds of perturbation, to test whether the effect of the various perturbations is mediated by this one parameter.</p>
    </sec>
    <sec sec-type="methods">
      <title>Method</title>
      <sec>
        <title>Observers</title>
        <p>There were two observers. C.J.C. was an undergraduate intern and is an author. A.S. was an undergraduate. Both observers had normal or corrected-to-normal acuity and were tested binocularly, with their correction, if any. Both gave written consent.</p>
      </sec>
      <sec>
        <title>Display</title>
        <p>The stimulus consists of a letter added to a background of noise. The stimuli are created on a Power Macintosh using MATLAB and the Psychophysics Toolbox (<xref ref-type="bibr" rid="b3">Brainard, 1997</xref>; <xref ref-type="bibr" rid="b35">Pelli, 1997</xref>; <ext-link ext-link-type="uri" xlink:href="http://psychtoolbox.org">http://psychtoolbox.org</ext-link>). The observer views a gamma-corrected computer monitor (<xref ref-type="bibr" rid="b41">Pelli &amp; Zhang, 1991</xref>) from a distance of 100 cm. Each pixel subtends 0.019 deg. There are 74 pixels per inch. The frame rate is 75.5 Hz. The video attenuator drives just the green gun of the Apple 1700 Multiscan color monitor. The background luminance is set to the middle of the monitor's range, 16 cd/m<sup>2</sup>.</p>
      </sec>
      <sec>
        <title>Snake letters</title>
        <p>In effect, we created a new font for each kind and degree of perturbation. This was done once. Each font, once made, never changed and was used unchanged throughout training and testing of both observers. (Here we are interested in how well an observer can perform, after adequate training with the font, in identifying a wiggly font. We are not studying how well observers can generalize from one font&#x2014;and wiggle&#x2014;to another.)</p>
        <p>Each snake letter in a font is made from a letter path (based on Sloan), a perturbation rule (orientation, offset, or phase), a mark, and a mark spacing. The standard mark <italic>m</italic>(<italic>x</italic>, <italic>y</italic>) is a gabor, the product of a sine wave grating and a Gaussian envelope,
<disp-formula><mml:math id="M1"><mml:mrow><mml:mi>m</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext>sin</mml:mtext><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x3C0;</mml:mi><mml:mi>f</mml:mi><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x2212;</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>&#x3BB;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic>m</italic>(<italic>x</italic>, <italic>y</italic>) is a unit-contrast mark (vertical at the origin), <italic>x</italic> and <italic>y</italic> are horizontal and vertical positions in deg, <italic>f</italic> = 1 c/deg is spatial frequency, and &#x3BB; = 0.3 deg is the space constant of its envelope. The mark interval (travel distance along the path from making a mark to making the next mark) is 0.91 deg.</p>
        <p>Sloan is a special font designed by Louise Sloan for eye charts and contains only the 10 letters C D H K N O R S V Z. The shapes of the 10 Sloan characters are specified by the NAS-NRC Committee on Vision (<xref ref-type="bibr" rid="b33">NAS-NRC, 1980</xref>), based on Louise Sloan's design. Sloan is available from us for research purposes. We used MATLAB to create a simple Logo-like language in which we wrote a short computer program for each letter that describes its path as instructions to a &#x201C;turtle&#x201D; holding a pen&#x2014;for example, activate pen, advance 1 unit, turn 90&#xB0; to the right, deactivate pen, and so on [<ext-link ext-link-type="uri" xlink:href="http://en.wikipedia.org/wiki/Logo_(programming_language)">http://en.wikipedia.org/wiki/Logo_(programming_language)</ext-link>]. The imaginary turtle moved along the path. If the pen had ink, its stroke would draw the letter. However, to make a snake letter, the turtle instead made a mark at regular intervals during its pen-active travel along the path. The location and orientation of each mark are the same as those of the turtle, plus any perturbation. The sign of the perturbation was alternately positive and negative from mark to mark. A particular font had a particular kind of perturbation (orientation, offset, or phase) and a particular value (angle, displacement, or phase angle). The only nonzero phase perturbation we used was &#xB1;180. In this way the turtle walked the path of the letter and made many marks as it travelled. Each letter in the font consists of the sum of all the marks made during the turtle's walk along the letter's path. Each mark is a copy of the standard mark, moved and rotated to the turtle's current location and orientation, and possibly further rotated, offset, and phase shifted. The imaginary bounding box of the zero-thickness paths of the Sloan letters was 4 deg &#xD7; 4 deg.</p>
      </sec>
      <sec>
        <title>Letters</title>
        <p>All the fonts are rendered off screen (in computer memory) at a reduced scale. Independent Gaussian noise is added to each pixel. Then the image is expanded by pixel replication to its final size&#x2014;each pixel growing to become a square check&#x2014;and copied to the screen. The expansion is a doubling of size, horizontally and vertically. The experiments reported here present only one letter at a time, at fixation.</p>
        <p>Ordinary reading presents many adjoining letters spanning a range of eccentricities. In that case, the number of letters that the observer can acquire in each glimpse is limited by &#x201C;crowding&#x201D; of the more peripheral letters (<xref ref-type="bibr" rid="b39">Pelli &amp; Tillman, 2008</xref>; <xref ref-type="bibr" rid="b40">Pelli et al., 2007</xref>). However, there was no crowding in the experiments reported here.</p>
      </sec>
      <sec>
        <title>Noise</title>
        <p>The noise is static, made up of square checks: 2 &#xD7; 2 pixels. Each check is a luminance incrementor decrement, sampled independently from a zero-mean Gaussian distribution truncated at &#xB1;2 standard deviations. The power spectral density of a random checkerboard (with statistically independent check luminances) equals the product of the contrast power and the area of a noise check. The root mean square contrast of the noise is 0.15. The power spectral density of a random checkerboard (with stochastically independent check luminances) equals the product of contrast power and the area of a noise check. At a distance of 100 cm, a 2 &#xD7; 2-pixel check subtends 0.041 deg so the power spectral density <italic>N</italic> is 0.15<sup>2</sup> 0.041<sup>2</sup> = 10<sup>&#x2212;4.42</sup> deg<sup>2</sup>. The noise covers the letter and extends 1 deg beyond its (invisible) bounding box.</p>
      </sec>
      <sec>
        <title>Training</title>
        <p>For each observer, the results of the first 2,000 trials with each font were discarded before collecting the data reported here. This criterion is based on the finding that efficiency for identifying letters from a new alphabet initially grows rapidly but grows very slowly after 2,000 trials (<xref ref-type="bibr" rid="b36">Pelli et al., 2006</xref>).</p>
      </sec>
      <sec>
        <title>A trial: The identification task</title>
        <p>On each trial, the observer is briefly shown a faint letter in visual noise and is then asked to select the letter from a display of all the letters in the alphabet. Each trial begins with the appearance of a fixation point on the grey background. The observer moves a mouse-controlled cursor to the fixation point and clicks the mouse button to initiate the trial. The stimulus consists of a signal and zero-mean white Gaussian noise added to the steady uniform background. The signal is a snake letter, randomly selected from a given font (see &#x201C;Snake letters&#x201D; above). This static stimulus is displayed for 200 ms and disappears. After a 200-ms delay, the whole alphabet is displayed at 80% contrast at the same size as the letter in the stimulus. The observer is asked to identify the signal letter by clicking a letter in the whole-alphabet display. After the observer responds, the correct letter is highlighted. A correct response is rewarded with a beep. The alphabet then disappears, and the fixation point reappears.</p>
        <p>The signal letter and the whole-alphabet display are in the same font, and the font is the same for every trial in a block.</p>
      </sec>
      <sec>
        <title>A block: Threshold</title>
        <p>The Michelson contrast <italic>c</italic> of a letter is (<italic>L</italic><sub>max</sub> &#x2212; <italic>L</italic><sub>min</sub>)/(<italic>L</italic><sub>max</sub> + <italic>L</italic><sub>min</sub>). Threshold contrast is measured by 40-trial blocks of the modified Quest staircase procedure (<xref ref-type="bibr" rid="b23">King-Smith, Grigsby, Vingrys, Benes, &amp; Supowit, 1994</xref>; <xref ref-type="bibr" rid="b56">Watson &amp; Pelli, 1983</xref>) using a threshold criterion of 82% correct and a &#x3B2; of 3.5. For identification, the guessing rate &#x3B3; is the reciprocal of the number of letters in the alphabet, since we presented all letters equally often. For experienced observers the proportion correct at high contrast is nearly 1, so we set the lapsing (or &#x201C;finger error&#x201D;) rate &#x3B4; to 0.01. Threshold energy <italic>E</italic> for the alphabet is the average letter energy (across all the letters) at the threshold contrast for the alphabet. The reported efficiencies are based on the average log contrast threshold estimate from three 40-trial blocks.</p>
        <p>Readers more accustomed to thinking about contrast should note that efficiency and energy are proportional to squared contrast.</p>
      </sec>
      <sec>
        <title>Efficiency</title>
        <p><xref ref-type="bibr" rid="b52">Tanner and Birdsall (1958)</xref> introduced the notion of comparing human and ideal thresholds to compute <italic>efficiency</italic>, &#x3B7; = <italic>E</italic><sub>ideal</sub>/<italic>E</italic>. Here, <italic>E</italic> is the human observer's letter threshold energy measured in the presence of display noise with power spectral density <italic>N</italic>. <italic>E</italic><sub>ideal</sub> is the threshold for the ideal observer. <xref ref-type="bibr" rid="b37">Pelli and Farell (1999)</xref> point out several advantages to instead computing <italic>high-noise efficiency</italic>,
<disp-formula><mml:math id="M2"><mml:mrow><mml:msup><mml:mi>&#x3B7;</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>ideal</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>&#x2212;</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p><italic>E</italic><sub>0</sub> is the letter threshold energy for the human observer, measured with zero display noise. &#x3B7;* counts only the extra energy needed to overcome the display noise, discounting the energy needed to see the signal on a blank screen. The distinction between the two efficiencies, &#x3B7;* and &#x3B7;*&#x2014;that is, the correction for the zero-noise threshold <italic>E</italic><sub>0</sub>&#x2014;becomes insignificant when the display noise is sufficiently strong to greatly elevate threshold, <italic>E</italic> &gt; &gt; <italic>E</italic><sub>0</sub>. Since this was true for most of the efficiencies reported here, we just say &#x201C;efficiency&#x201D;, though it was always computed by Equation 2.</p>
        <p>The ideal observer performs the same task as the human&#x2014;identifying letters in noise&#x2014;and we measure its threshold in the same way: On each trial the ideal-observer computer program receives a noisy stimulus and returns an identification response, which is scored as right or wrong. The mathematical description of the computation performed by the ideal observer is given by the theory of signal detectability for identifying one of many known signals in white noise (<xref ref-type="bibr" rid="b55">Van Trees, 1968</xref>). The ideal observer must decide from which of the 10 letters of the alphabet the letter-in-noise stimulus was most probably created.</p>
        <p>The ideal observer is not intended as a model of the human observer. It merely provides a reference that allows us to place human performance on an absolute scale (<xref ref-type="bibr" rid="b12">Geisler, 1989</xref>). Human efficiency below 100% indicates a failure to fully utilize the available information. Finding a high human efficiency would rule out inefficient models. It is usually easy to impair an overly efficient model to match human efficiency, but difficult or impossible to salvage an inefficient model.</p>
      </sec>
    </sec>
    <sec>
      <title>Results</title>
      <p><xref ref-type="fig" rid="fig6">Figure 6</xref> plots efficiency as a function of wiggle for our three perturbations: orientation (solid symbols), offset (open symbols), and phase (x-in-square symbol). The three kinds of perturbation look quite different (<xref ref-type="fig" rid="fig4">Figure 4</xref>) but have the same effect on efficiency, all tracing out one curve. Efficiency is 8% at zero wiggle and falls, in inverse proportion to wiggle, for wiggles higher than 15&#xB0;.</p>
      <fig id="fig6" position="float">
        <label>Figure 6</label>
        <caption>
          <p>Efficiency as a function of wiggle of orientation (solid symbols), offset (open symbols), and phase (x-in-square symbol). The observers are C.J.C. (squares) and A.S. (circles). We measured threshold contrast energy (integrated square contrast) for letter identification as we perturbed grating orientation, offset, and relative phase. We implemented the ideal observer as a computer program and measured its threshold contrast energy for the same letter sets as those used for the human observer. The ratio of energy threshold of ideal to human is efficiency, an absolute scale that allows us to compare human performance across all our conditions (<xref ref-type="bibr" rid="b37">Pelli &amp; Farell, 1999</xref>). Furthermore, it allows us to compare our new results to previous results for letters of various fonts, alphabets, and sizes. The bent line is the best fit of the clipped reciprocal &#x3B7;<sub>0</sub>(w) = &#x3B7;<sub>0</sub> / min(1, w/w<sub>0</sub>), where <italic>w</italic> is wiggle, with two degrees of freedom, &#x3B7;<sub>0</sub> = .074 and <italic>w</italic><sub>0</sub> = 15 deg, to minimize the fitting error (log &#x3B7;&#x2013;log &#x3B7;),, where &#x3B7; is efficiency, and rms is root mean square.</p>
        </caption>
        <graphic xlink:href="pcgn26-36-f6"/>
      </fig>
      <p>It is traditional for psychophysics papers to have a lot of data on few observers, which may seem strange to colleagues from other branches of psychology. In some studies in psychology the limited data that can be obtained from each observer are too variable to yield any conclusion. Averaging over many observers may overcome this, but at the cost of drawing conclusions that are valid for the average but may not be true of any individual. That is not the case here. In psychophysics, we are more concerned with the perceptual phenomena themselves than their incidence. Here, the data from each observer stand on their own, yielding valid conclusions for each observer. Given that our result is valid, independently, for each observer tested, we can say that it is valid for them (2 out of 2), and that this result must be fairly common in the population.<xref ref-type="fn" rid="fn2">2</xref> Our data show both that this phenomenon is real for two people, and that it is quite common, with an incidence somewhere between 37% and 100%.</p>
    </sec>
    <sec>
      <title>Discussion</title>
      <p>One simple explanation for the drop in efficiency with increasing wiggle might be that our human observers use internal letter templates that do not incorporate the wiggle exceeding 15&#xB0;. The wiggle makes the letters different from the templates, making their identification harder. It is possible that observers used inaccurate templates, but it is not for lack of training. After only 2,000 trials, a novice observer's ability to identify letters of a foreign alphabet reaches the performance of life-long readers of that alphabet, and even an enormous amount of further practice provides relatively little further improvement (<xref ref-type="bibr" rid="b13">Geisler &amp; Murray, 2003</xref>; <xref ref-type="bibr" rid="b36">Pelli et al., 2006</xref>). All results in <xref ref-type="fig" rid="fig6">Figure 6</xref> are after at least 2,000 trials of practice with that perturbed set of letters and should thus be robust, little affected by the observer's prior exposure or further practice. If we trained without wiggle and tested with wiggle, then we would be assessing the observer's ability to generalize across wiggle.<xref ref-type="fn" rid="fn3">3</xref> But in fact each experiment used the same wiggly alphabet for testing and training, so we are measuring the observer's ability to identify a wiggly alphabet, and the results show that more wiggle (poorer continuation) makes identification harder. More precisely, wiggle raises human threshold, but has no effect on the threshold of the ideal observer.</p>
      <p>Why is the ideal immune to wiggle? It is proven in Appendix A of <xref ref-type="bibr" rid="b36">Pelli et al. (2006)</xref> that the threshold for the ideal observer depends only on the covariance among the <italic>m</italic> possible signals and the level of white noise (Equations A.12 and A.24). The wiggle has practically no effect on the covariance between letters, so the ideal's threshold is practically unaffected by wiggle. The intuition is that the ideal observer compares the noisy stimulus with each of <italic>m</italic> templates and picks the most similar. For the ideal it does not matter whether the templates are wiggly or not.</p>
      <p>Another simple explanation is that wiggle increases complexity, the number of features in the object. <xref ref-type="bibr" rid="b36">Pelli et al. (2006)</xref> found inverse proportionality between efficiency and perimetric complexity, which they suggested might be a plausible estimate of number of features. That idea seems plausible here too. By this interpretation, grouping reduces the number of features, which improves the efficiency.</p>
      <p>Past work has explored integration of nonoverlapping gratings using two experimental paradigms: contour integration and masking. Some scientists extended the paradigm of the early Gestalt psychologists, exploring the role of the Gestalt laws in the detection of objects (contours) made of gratings&#x2014;that is, seeing a &#x201C;snake in the grass&#x201D;. In the masking paradigm, scientists studied how visibility of a single grating is affected by flanking gratings. We wondered how results with our &#x201C;snake&#x201D; letters would compare to existing results of the masking paradigm. We reexamined their data using our scales. <xref ref-type="bibr" rid="b11">Field et al. (1993)</xref> measured the probability of detecting contours consisting of relatively aligned gratings in a field of randomly oriented gratings. They found that proportion correct drops with increasing angle between successive gratings along the contour. We calculated the wiggle of their contours and converted proportion correct to (<italic>d</italic>&#x2032;)<sup>2</sup>, which is proportional to efficiency. Log-log regression of (<italic>d</italic>&#x2032;)<sup>2</sup> versus wiggle reveals log-log slopes of &#x2212;1.2 (<italic>r</italic> = .98) and &#x2212;1.1 (<italic>r</italic> = .97) for their two observers, which agrees with the slope of &#x2212;1 we fitted to our results. Solomon et al. measured the effect of nonoverlapping flanking gratings on the detection of a single grating, finding that the threshold contrast is a factor of &#x221A;2 lower if the flanks are in phase with the target than if they are out of phase (<xref ref-type="bibr" rid="b43">Polat &amp; Sagi, 1993</xref>; <xref ref-type="bibr" rid="b51">Solomon, Watson, &amp; Morgan 1999</xref>). This is consistent with the difference in efficiency between our in- and out-of-phase letters.<xref ref-type="fn" rid="fn4">4</xref></p>
    </sec>
    <sec>
      <title>CONCLUSION</title>
      <p>Our experiments show that wiggle, a measure of sinusoidal curvature, characterizes the effect of good continuation on letter identification, independent of the kind of perturbation. This shows that this Gestalt law of grouping plays an important role in letter identification. This may be the first evidence that a Gestalt law of grouping plays a role in ordinary object recognition: quick, familiar, meaningful, and named.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Charles Peskin for showing us how to generalize our sinusoidal measure of wiggle to curved stroke paths, Katharine Tillman, Rama Chakravarthi, Dennis Levi, and Athena Vouloumanos for helpful suggestions, Nava Rubin and Jeremy Wolfe for help with historical sources, and Fred Kingdom and Chris Tyler for sharing their wisdom on wiggle. Noah Raizman and Chris Christian participated as undergraduates, and Edward Kim as a high-school student. We thank the NYU Center for Neural Science Summer Undergraduate Research Program, organized by Chiye Aoki, for supporting Noah Raizman's summer internship during which this project was done. Edward Kim, as a student at Stuyvesant High School, measured thresholds in our lab for snake letters as a function of spacing for his Intel National Talent Search Project, &#x201C;What makes a letter?&#x201D; Supported by National Eye Institute Grant R01-EY04432 to Denis Pelli. Najib J. Majaj is now at Brain and Cognitive Science, MIT, Cambridge, MA, USA. Noah Raizman is now at Columbia Medical School, New York, NY, USA. Christopher J. Christian is now at Albert Einstein College of Medicine of Yeshiva University, New York, NY, USA. Edward Kim is now at Stuyvesant High School, New York, NY, USA. Melanie C. Palomares is now at Smith-Kettlewell Eye Research Institute, San Francisco, CA, USA.</p>
    </ack>
    <ref-list>
      <title>REFERENCES</title>
      <ref id="b1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beck</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rosenfeld</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ivry</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Line segregation</article-title>
          <source>Spatial Vision</source>
          <year>1989</year>
          <volume>4</volume>
          <fpage>75</fpage>
          <lpage>101</lpage>
          <pub-id pub-id-type="pmid">2487165</pub-id>
        </citation>
      </ref>
      <ref id="b2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beintema</surname>
              <given-names>J. A.</given-names>
            </name>
            <name>
              <surname>Georg</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Lappe</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Perception of biological motion from limited-lifetime stimuli</article-title>
          <source>Perception &amp; Psychophysics</source>
          <year>2006</year>
          <volume>68</volume>
          <fpage>613</fpage>
          <lpage>624</lpage>
          <pub-id pub-id-type="pmid">16933426</pub-id>
        </citation>
      </ref>
      <ref id="b3">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brainard</surname>
              <given-names>D. H.</given-names>
            </name>
          </person-group>
          <article-title>The Psychophysics Toolbox</article-title>
          <source>Spatial Vision</source>
          <year>1997</year>
          <volume>10</volume>
          <fpage>433</fpage>
          <lpage>436</lpage>
          <pub-id pub-id-type="pmid">9176952</pub-id>
        </citation>
      </ref>
      <ref id="b4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brunswik</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Kamiya</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Ecological cue-validation of &#x201C;proximity&#x201D; and of other Gestalt factors</article-title>
          <source>American Journal of Psychology</source>
          <year>1953</year>
          <volume>66</volume>
          <fpage>20</fpage>
          <lpage>32</lpage>
          <pub-id pub-id-type="pmid">13030843</pub-id>
        </citation>
      </ref>
      <ref id="b5">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carney</surname>
              <given-names>A. E.</given-names>
            </name>
            <name>
              <surname>Widin</surname>
              <given-names>G. P.</given-names>
            </name>
            <name>
              <surname>Viemeister</surname>
              <given-names>N. F.</given-names>
            </name>
          </person-group>
          <article-title>Non-categorical perception of stop consonants differing in VOT</article-title>
          <source>The Journal of the Acoustical Society of America</source>
          <year>1977</year>
          <volume>62</volume>
          <fpage>961</fpage>
          <lpage>970</lpage>
          <pub-id pub-id-type="pmid">908791</pub-id>
        </citation>
      </ref>
      <ref id="b6">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dakin</surname>
              <given-names>S. C.</given-names>
            </name>
            <name>
              <surname>Hess</surname>
              <given-names>R. F.</given-names>
            </name>
          </person-group>
          <article-title>Spatial-frequency tuning of visual contour integration</article-title>
          <source>Journal of the Optical Society of America. A, Optics, Image Science, and Vision</source>
          <year>1998</year>
          <volume>15</volume>
          <fpage>1486</fpage>
          <lpage>1499</lpage>
        </citation>
      </ref>
      <ref id="b7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Flash</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Ullman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Reading cursive handwriting by alignment of letter prototypes</article-title>
          <source>International Journal of Computer Vision</source>
          <year>1990</year>
          <volume>5</volume>
          <fpage>303</fpage>
          <lpage>331</lpage>
        </citation>
      </ref>
      <ref id="b8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Elder</surname>
              <given-names>J. H.</given-names>
            </name>
            <name>
              <surname>Goldberg</surname>
              <given-names>R. M.</given-names>
            </name>
          </person-group>
          <article-title>Ecological statistics of Gestalt laws for the perceptual organization of contours</article-title>
          <source>Journal of Vision</source>
          <year>2002</year>
          <volume>2</volume>
          <fpage>324</fpage>
          <lpage>353</lpage>
          <pub-id pub-id-type="pmid">12678582</pub-id>
        </citation>
      </ref>
      <ref id="b9">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Ellis</surname>
              <given-names>W. D.</given-names>
            </name>
          </person-group>
          <source>A source book of Gestalt psychology</source>
          <year>1938</year>
          <publisher-loc>London</publisher-loc>
          <publisher-name>K. Paul, Trench, Trubner &amp; Co</publisher-name>
        </citation>
      </ref>
      <ref id="b10">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Epstein</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Has the time come to rehabilitate Gestalt theory?</article-title>
          <source>Psychological Research</source>
          <year>1988</year>
          <volume>50</volume>
          <fpage>2</fpage>
          <lpage>6</lpage>
          <pub-id pub-id-type="pmid">3212147</pub-id>
        </citation>
      </ref>
      <ref id="b11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Field</surname>
              <given-names>D. J.</given-names>
            </name>
            <name>
              <surname>Hayes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Hess</surname>
              <given-names>R. F.</given-names>
            </name>
          </person-group>
          <article-title>Contour integration by the human visual system: Evidence for a local &#x201C;association field&#x201D;</article-title>
          <source>Vision Research</source>
          <year>1993</year>
          <volume>33</volume>
          <fpage>173</fpage>
          <lpage>193</lpage>
          <pub-id pub-id-type="pmid">8447091</pub-id>
        </citation>
      </ref>
      <ref id="b12">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Geisler</surname>
              <given-names>W. S.</given-names>
            </name>
          </person-group>
          <article-title>Sequential ideal-observer analysis of visual discriminations</article-title>
          <source>Psychological Review</source>
          <year>1989</year>
          <volume>96</volume>
          <fpage>267</fpage>
          <lpage>314</lpage>
          <pub-id pub-id-type="pmid">2652171</pub-id>
        </citation>
      </ref>
      <ref id="b13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Geisler</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Murray</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Cognitive neuroscience: Practice doesn't make perfect</article-title>
          <source>Nature</source>
          <year>2003</year>
          <volume>423</volume>
          <fpage>696</fpage>
          <lpage>697</lpage>
          <pub-id pub-id-type="pmid">12802318</pub-id>
        </citation>
      </ref>
      <ref id="b14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Geisler</surname>
              <given-names>W. S.</given-names>
            </name>
            <name>
              <surname>Perry</surname>
              <given-names>J. S.</given-names>
            </name>
            <name>
              <surname>Super</surname>
              <given-names>B. J.</given-names>
            </name>
            <name>
              <surname>Gallogly</surname>
              <given-names>D. P.</given-names>
            </name>
          </person-group>
          <article-title>Edge co-occurrence in natural images predicts contour grouping performance</article-title>
          <source>Vision Research</source>
          <year>2001</year>
          <volume>41</volume>
          <fpage>711</fpage>
          <lpage>724</lpage>
          <pub-id pub-id-type="pmid">11248261</pub-id>
        </citation>
      </ref>
      <ref id="b15">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Gibson</surname>
              <given-names>J. J.</given-names>
            </name>
          </person-group>
          <source>The ecological approach to visual perception</source>
          <year>1979</year>
          <publisher-loc>Boston</publisher-loc>
          <publisher-name>Houghton Mifflin</publisher-name>
        </citation>
      </ref>
      <ref id="b16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Goldstone</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Influences of categorization on perceptual discrimination</article-title>
          <source>Journal of Experimental Psychology. General</source>
          <year>1994</year>
          <volume>123</volume>
          <fpage>178</fpage>
          <lpage>200</lpage>
          <pub-id pub-id-type="pmid">8014612</pub-id>
        </citation>
      </ref>
      <ref id="b17">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gottschaldt</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>&#xDC;ber den Einfluss der Erfahrung auf die Wahrnehmung von Figuren [The influence of experience upon the perception of figures]</article-title>
          <source>Psychologische Forschung</source>
          <year>1926</year>
          <volume>8</volume>
          <fpage>261</fpage>
          <lpage>317</lpage>
        </citation>
      </ref>
      <ref id="b18">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hochberg</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Peterson</surname>
              <given-names>M. A.</given-names>
            </name>
          </person-group>
          <article-title>Piecemeal organization and cognitive components in object perception: Perceptually coupled responses to moving objects</article-title>
          <source>Journal of Experimental Psychology. General</source>
          <year>1987</year>
          <volume>116</volume>
          <fpage>370</fpage>
          <lpage>380</lpage>
          <pub-id pub-id-type="pmid">2960775</pub-id>
        </citation>
      </ref>
      <ref id="b19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Johansson</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Visual perception of biological motion and a model for its analysis</article-title>
          <source>Perception &amp; Psychophysics</source>
          <year>1973</year>
          <volume>14</volume>
          <fpage>201</fpage>
          <lpage>211</lpage>
          <comment>[Reprinted (1994) in G. Jansson, S. S. Bergstrom, &amp; W. Epstein (Eds.), <italic>Perceiving events and objects</italic> (pp. 185&#x2013;207). Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.]</comment>
        </citation>
      </ref>
      <ref id="b20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Johansson</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Visual motion perception</article-title>
          <source>Scientific American</source>
          <year>1975</year>
          <volume>232</volume>
          <fpage>76</fpage>
          <lpage>89</lpage>
          <pub-id pub-id-type="pmid">1145169</pub-id>
        </citation>
      </ref>
      <ref id="b21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Johansson</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Spatio-temporal differentiation and integration in visual motion perception: An experimental and theoretical analysis of calculus-like functions in visual data processing</article-title>
          <source>Psychological Research/Psychologische Forschung</source>
          <year>1976</year>
          <volume>38</volume>
          <fpage>379</fpage>
          <lpage>393</lpage>
        </citation>
      </ref>
      <ref id="b22">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kanizsa</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Subjective contours</article-title>
          <source>Scientific American</source>
          <year>1976</year>
          <volume>234</volume>
          <fpage>48</fpage>
          <lpage>52</lpage>
          <pub-id pub-id-type="pmid">1257734</pub-id>
        </citation>
      </ref>
      <ref id="b23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>King-Smith</surname>
              <given-names>P. E.</given-names>
            </name>
            <name>
              <surname>Grigsby</surname>
              <given-names>S. S.</given-names>
            </name>
            <name>
              <surname>Vingrys</surname>
              <given-names>A. J.</given-names>
            </name>
            <name>
              <surname>Benes</surname>
              <given-names>S. C.</given-names>
            </name>
            <name>
              <surname>Supowit</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Efficient and unbiased modifications of the QUEST threshold method: Theory, simulations, experimental evaluation and practical implementation</article-title>
          <source>Vision Research</source>
          <year>1994</year>
          <volume>34</volume>
          <fpage>885</fpage>
          <lpage>912</lpage>
          <pub-id pub-id-type="pmid">8160402</pub-id>
        </citation>
      </ref>
      <ref id="b24">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>K&#xF6;hler</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <source>Die physischen Gestalten in Ruhe und im station&#xE4;ren Zustand <italic>[The physical Gestalten at rest and in a stationary state]</italic></source>
          <year>1920</year>
          <publisher-loc>Erlangen, Germany</publisher-loc>
          <publisher-name>Verlag der Philosophischen Akademie</publisher-name>
        </citation>
      </ref>
      <ref id="b25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kovacs</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Gestalten of today: Early processing of visual contours and surfaces</article-title>
          <source>Behavioural Brain Research</source>
          <year>1996</year>
          <volume>82</volume>
          <fpage>1</fpage>
          <lpage>11</lpage>
          <pub-id pub-id-type="pmid">9021065</pub-id>
        </citation>
      </ref>
      <ref id="b26">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kovacs</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Julesz</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual sensitivity maps within globally defined visual shapes</article-title>
          <source>Nature</source>
          <year>1994</year>
          <volume>370</volume>
          <fpage>644</fpage>
          <lpage>646</lpage>
          <pub-id pub-id-type="pmid">8065449</pub-id>
        </citation>
      </ref>
      <ref id="b27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kubovy</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Holcombe</surname>
              <given-names>A. O.</given-names>
            </name>
            <name>
              <surname>Wagemans</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>On the lawfulness of grouping by proximity</article-title>
          <source>Cognitive Psychology</source>
          <year>1998</year>
          <volume>35</volume>
          <fpage>71</fpage>
          <lpage>98</lpage>
          <pub-id pub-id-type="pmid">9520318</pub-id>
        </citation>
      </ref>
      <ref id="b28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kubovy</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>van den Berg</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The whole is equal to the sum of its parts: A probabilistic model of grouping by proximity and similarity in regular patterns</article-title>
          <source>Psychological Review</source>
          <year>2008</year>
          <volume>115</volume>
          <fpage>131</fpage>
          <lpage>154</lpage>
          <pub-id pub-id-type="pmid">18211188</pub-id>
        </citation>
      </ref>
      <ref id="b29">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Levi</surname>
              <given-names>D. M.</given-names>
            </name>
            <name>
              <surname>Sharma</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Klein</surname>
              <given-names>S. A.</given-names>
            </name>
          </person-group>
          <article-title>Feature integration in pattern perception</article-title>
          <source>Proceedings of the National Academy of Sciences of the United States of America</source>
          <year>1997</year>
          <volume>94</volume>
          <fpage>11742</fpage>
          <lpage>11746</lpage>
          <pub-id pub-id-type="pmid">9326681</pub-id>
        </citation>
      </ref>
      <ref id="b30">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Majaj</surname>
              <given-names>N. J.</given-names>
            </name>
            <name>
              <surname>Liang</surname>
              <given-names>Y. X.</given-names>
            </name>
            <name>
              <surname>Martelli</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Berger</surname>
              <given-names>T. D.</given-names>
            </name>
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
          </person-group>
          <article-title>The channel for reading</article-title>
          <source>Journal of Vision</source>
          <year>2003</year>
          <volume>3</volume>
          <fpage>813</fpage>
        </citation>
      </ref>
      <ref id="b31">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Majaj</surname>
              <given-names>N. J.</given-names>
            </name>
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Kurshan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Palomares</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The role of spatial frequency channels in letter identification</article-title>
          <source>Vision Research</source>
          <year>2002</year>
          <volume>42</volume>
          <fpage>1165</fpage>
          <lpage>1184</lpage>
          <pub-id pub-id-type="pmid">11997055</pub-id>
        </citation>
      </ref>
      <ref id="b32">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McIlhagga</surname>
              <given-names>W. H.</given-names>
            </name>
            <name>
              <surname>Mullen</surname>
              <given-names>K. T.</given-names>
            </name>
          </person-group>
          <article-title>Contour integration with colour and luminance contrast</article-title>
          <source>Vision Research</source>
          <year>1996</year>
          <volume>36</volume>
          <fpage>1265</fpage>
          <lpage>1279</lpage>
          <pub-id pub-id-type="pmid">8711906</pub-id>
        </citation>
      </ref>
      <ref id="b33">
        <citation citation-type="journal">
          <collab>NAS-NRC</collab>
          <article-title>Recommended standard procedures for the clinical measurement and specification of visual acuity. Report of Working Group 39. Committee on Vision. Assembly of Behavioral and Social Sciences, National Research Council, National Academy of Sciences, Washington, DC</article-title>
          <source>Advances in Ophthalmology</source>
          <year>1980</year>
          <volume>41</volume>
          <fpage>103</fpage>
          <lpage>148</lpage>
          <pub-id pub-id-type="pmid">7001873</pub-id>
        </citation>
      </ref>
      <ref id="b34">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Palmer</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rock</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Rethinking perceptual organization: The role of uniform connectedness</article-title>
          <source>Psychonomic Bulletin &amp; Review</source>
          <year>1994</year>
          <volume>1</volume>
          <fpage>29</fpage>
          <lpage>55</lpage>
        </citation>
      </ref>
      <ref id="b35">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
          </person-group>
          <article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title>
          <source>Spatial Vision</source>
          <year>1997</year>
          <volume>10</volume>
          <fpage>437</fpage>
          <lpage>442</lpage>
          <pub-id pub-id-type="pmid">9176953</pub-id>
        </citation>
      </ref>
      <ref id="b36">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Burns</surname>
              <given-names>C. W.</given-names>
            </name>
            <name>
              <surname>Farell</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Moore-Page</surname>
              <given-names>D. C.</given-names>
            </name>
          </person-group>
          <article-title>Feature detection and letter identification</article-title>
          <source>Vision Research</source>
          <year>2006</year>
          <volume>46</volume>
          <fpage>4646</fpage>
          <lpage>4674</lpage>
          <pub-id pub-id-type="pmid">16808957</pub-id>
        </citation>
      </ref>
      <ref id="b37">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Farell</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Why use noise?</article-title>
          <source>Journal of the Optical Society of America. A, Optics, Image Science, and Vision</source>
          <year>1999</year>
          <volume>16</volume>
          <fpage>647</fpage>
          <lpage>653</lpage>
        </citation>
      </ref>
      <ref id="b38">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Farell</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Moore</surname>
              <given-names>D. C.</given-names>
            </name>
          </person-group>
          <article-title>The remarkable inefficiency of word recognition</article-title>
          <source>Nature</source>
          <year>2003</year>
          <volume>423</volume>
          <fpage>752</fpage>
          <lpage>756</lpage>
          <pub-id pub-id-type="pmid">12802334</pub-id>
        </citation>
      </ref>
      <ref id="b39">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Tillman</surname>
              <given-names>K. A.</given-names>
            </name>
          </person-group>
          <article-title>The uncrowded window of object recognition</article-title>
          <source>Nature Neuroscience</source>
          <year>2008</year>
          <volume>11</volume>
          <fpage>1129</fpage>
          <lpage>1135</lpage>
          <comment>
            <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/neuro/journal/v11/n10/#pe">http://www.nature.com/neuro/journal/v11/n10/#pe</ext-link>
          </comment>
        </citation>
      </ref>
      <ref id="b40">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Tillman</surname>
              <given-names>K. A.</given-names>
            </name>
            <name>
              <surname>Freeman</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Su</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Berger</surname>
              <given-names>T. D.</given-names>
            </name>
            <name>
              <surname>Majaj</surname>
              <given-names>N. J.</given-names>
            </name>
          </person-group>
          <article-title>Crowding and eccentricity determine reading rate</article-title>
          <source>Journal of Vision</source>
          <year>2007</year>
          <volume>7</volume>
          <issue>2</issue>
          <fpage>20</fpage>
          <fpage>1</fpage>
          <lpage>36</lpage>
          <pub-id pub-id-type="pmid">18217835</pub-id>
        </citation>
      </ref>
      <ref id="b41">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Accurate control of contrast on microcomputer displays</article-title>
          <source>Vision Research</source>
          <year>1991</year>
          <volume>31</volume>
          <fpage>1337</fpage>
          <lpage>1350</lpage>
          <pub-id pub-id-type="pmid">1891822</pub-id>
        </citation>
      </ref>
      <ref id="b42">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Peterson</surname>
              <given-names>M. A.</given-names>
            </name>
            <name>
              <surname>Gibson</surname>
              <given-names>B. S.</given-names>
            </name>
          </person-group>
          <article-title>Object recognition contributions to figure&#x2013;ground organization: Operations on outlines and subjective contours</article-title>
          <source>Perception &amp; Psychophysics</source>
          <year>1994</year>
          <volume>56</volume>
          <fpage>551</fpage>
          <lpage>564</lpage>
          <pub-id pub-id-type="pmid">7991352</pub-id>
        </citation>
      </ref>
      <ref id="b43">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Polat</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Sagi</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Lateral interactions between spatial channels: Suppression and facilitation revealed by lateral masking experiments</article-title>
          <source>Vision Research</source>
          <year>1993</year>
          <volume>33</volume>
          <fpage>993</fpage>
          <lpage>999</lpage>
          <pub-id pub-id-type="pmid">8506641</pub-id>
        </citation>
      </ref>
      <ref id="b44">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Prins</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Kingdom</surname>
              <given-names>F. A.</given-names>
            </name>
            <name>
              <surname>Hayes</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Detecting low shape-frequencies in smooth and jagged contours</article-title>
          <source>Vision Research</source>
          <year>2007</year>
          <volume>47</volume>
          <fpage>2390</fpage>
          <lpage>2402</lpage>
          <pub-id pub-id-type="pmid">17651781</pub-id>
        </citation>
      </ref>
      <ref id="b45">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ringach</surname>
              <given-names>D. L.</given-names>
            </name>
            <name>
              <surname>Shapley</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Spatial and temporal properties of illusory contours and amodal boundary completion</article-title>
          <source>Vision Research</source>
          <year>1996</year>
          <volume>36</volume>
          <fpage>3037</fpage>
          <lpage>3050</lpage>
          <pub-id pub-id-type="pmid">8917767</pub-id>
        </citation>
      </ref>
      <ref id="b46">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rock</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Palmer</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The legacy of Gestalt psychology</article-title>
          <source>Scientific American</source>
          <year>1990</year>
          <volume>263</volume>
          <fpage>84</fpage>
          <lpage>90</lpage>
          <pub-id pub-id-type="pmid">2270461</pub-id>
        </citation>
      </ref>
      <ref id="b47">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rosch</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Mervis</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Gray</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Johnson</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Boyes-Braem</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Basic objects in natural categories</article-title>
          <source>Cognitive Psychology</source>
          <year>1976</year>
          <volume>8</volume>
          <fpage>382</fpage>
          <lpage>439</lpage>
        </citation>
      </ref>
      <ref id="b48">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saarinen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Levi</surname>
              <given-names>D. M.</given-names>
            </name>
          </person-group>
          <article-title>Integration of local features into a global shape</article-title>
          <source>Vision Research</source>
          <year>2001</year>
          <volume>41</volume>
          <fpage>1785</fpage>
          <lpage>1790</lpage>
          <pub-id pub-id-type="pmid">11369042</pub-id>
        </citation>
      </ref>
      <ref id="b49">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Siddiqi</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kimia</surname>
              <given-names>B. B.</given-names>
            </name>
            <name>
              <surname>Tannenbaum</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Zucker</surname>
              <given-names>S. W.</given-names>
            </name>
          </person-group>
          <article-title>Shapes, shocks and wiggles</article-title>
          <source>Image and Vision Computing</source>
          <year>1999</year>
          <volume>17</volume>
          <fpage>365</fpage>
          <lpage>373</lpage>
        </citation>
      </ref>
      <ref id="b50">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Solomon</surname>
              <given-names>J. A.</given-names>
            </name>
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
          </person-group>
          <article-title>The visual filter mediating letter identification</article-title>
          <source>Nature</source>
          <year>1994</year>
          <volume>369</volume>
          <fpage>395</fpage>
          <lpage>397</lpage>
          <pub-id pub-id-type="pmid">8196766</pub-id>
        </citation>
      </ref>
      <ref id="b51">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Solomon</surname>
              <given-names>J. A.</given-names>
            </name>
            <name>
              <surname>Watson</surname>
              <given-names>A. B.</given-names>
            </name>
            <name>
              <surname>Morgan</surname>
              <given-names>M. J.</given-names>
            </name>
          </person-group>
          <article-title>Transducer model produces facilitation from opposite-sign flanks</article-title>
          <source>Vision Research</source>
          <year>1999</year>
          <volume>39</volume>
          <fpage>987</fpage>
          <lpage>992</lpage>
          <pub-id pub-id-type="pmid">10341950</pub-id>
        </citation>
      </ref>
      <ref id="b52">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tanner</surname>
              <given-names>W. P.</given-names>
              <suffix>Jr.</suffix>
            </name>
            <name>
              <surname>Birdsall</surname>
              <given-names>T. G.</given-names>
            </name>
          </person-group>
          <article-title>Definitions of <italic>d</italic>&#x2032; and &#x3B7; as psychophysical measures</article-title>
          <source>Journal of the Acoustical Society of America</source>
          <year>1958</year>
          <volume>30</volume>
          <fpage>922</fpage>
          <lpage>928</lpage>
        </citation>
      </ref>
      <ref id="b53">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tversky</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Hemenway</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Objects, parts, and categories</article-title>
          <source>Journal of Experimental Psychology. General</source>
          <year>1984</year>
          <volume>113</volume>
          <fpage>169</fpage>
          <lpage>197</lpage>
          <pub-id pub-id-type="pmid">6242749</pub-id>
        </citation>
      </ref>
      <ref id="b54">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tyler</surname>
              <given-names>C. W.</given-names>
            </name>
          </person-group>
          <article-title>Periodic vernier acuity</article-title>
          <source>The Journal of Physiology (London)</source>
          <year>1973</year>
          <volume>228</volume>
          <fpage>637</fpage>
          <lpage>647</lpage>
          <pub-id pub-id-type="pmid">4702150</pub-id>
        </citation>
      </ref>
      <ref id="b55">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Van Trees</surname>
              <given-names>H. L.</given-names>
            </name>
          </person-group>
          <source>Detection, estimation, and modulation theory</source>
          <year>1968</year>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>Wiley</publisher-name>
        </citation>
      </ref>
      <ref id="b56">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watson</surname>
              <given-names>A. B.</given-names>
            </name>
            <name>
              <surname>Pelli</surname>
              <given-names>D. G.</given-names>
            </name>
          </person-group>
          <article-title>QUEST: A Bayesian adaptive psychometric method</article-title>
          <source>Perception &amp; Psychophysics</source>
          <year>1983</year>
          <volume>33</volume>
          <fpage>113</fpage>
          <lpage>120</lpage>
          <pub-id pub-id-type="pmid">6844102</pub-id>
        </citation>
      </ref>
      <ref id="b57">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wertheimer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Untersuchungen zur Lehre von der Gestalt, II [Laws of organization in perceptual forms]</article-title>
          <source>Psychologische Forschung</source>
          <year>1923</year>
          <volume>4</volume>
          <fpage>301</fpage>
          <lpage>350</lpage>
        </citation>
      </ref>
      <ref id="b58">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wilson</surname>
              <given-names>H. R.</given-names>
            </name>
            <name>
              <surname>Richards</surname>
              <given-names>W. A.</given-names>
            </name>
          </person-group>
          <article-title>Mechanisms of contour curvature discrimination</article-title>
          <source>Journal of the Optical Society of America. A, Optics and Image Science</source>
          <year>1989</year>
          <volume>6</volume>
          <fpage>106</fpage>
          <lpage>115</lpage>
        </citation>
      </ref>
    </ref-list>
    <fn-group>
      <fn id="fn1">
        <label>1</label>
        <p>To be precise, we plot high-noise efficiency &#x3B7;<sup>+</sup> = <italic>E</italic><sub>ideal</sub>/(<italic>E</italic> &#x2212; <italic>E</italic><sub>0</sub>), where <italic>E</italic><sub>ideal</sub> and E are the ideal and human thresholds in noise, and <italic>E</italic><sub>0</sub> is the human threshold without noise, but the <italic>E</italic><sub>0</sub> correction is negligible at high noise levels (<xref ref-type="bibr" rid="b37">Pelli &amp; Farell, 1999</xref>).</p>
      </fn>
      <fn id="fn2">
        <label>2</label>
        <p>To be precise, if one takes two independent samples from a population of any size and discovers that both samples have a certain property, then one may conclude, with 95% confidence, that at least 37% of the population has that property. The webpage <ext-link ext-link-type="uri" xlink:href="http://www.causascientia.org/math_stat/ProportionCI.html">http://www.causascientia.org/math_stat/ProportionCI.html</ext-link> calculates the binomial confidence interval.</p>
      </fn>
      <fn id="fn3">
        <label>3</label>
        <p>Our ability to read many fonts and handwritings suggests that we generalize well (<xref ref-type="bibr" rid="b7">Edelman, Flash, &amp; Ullman, 1990</xref>).</p>
      </fn>
      <fn id="fn4">
        <label>4</label>
        <p>The ideal observer's threshold is unaffected by our perturbation, so the factor of 2 difference in human efficiency represents a factor of 2 in threshold energy, which is a factor of &#x221A;2 in threshold contrast.</p>
      </fn>
    </fn-group>
  </back>
</article>
