<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v3.0 20080202//EN" "archivearticle3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
  <?DTDIdentifier.IdentifierType public?>
  <?SourceDTD.DTDName A++V2.4.dtd?>
  <?SourceDTD.Version 2.4?>
  <?ConverterInfo.XSLTName springer2nlmx2.xsl?>
  <?ConverterInfo.Version 2?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroinformatics</journal-id>
      <journal-title-group>
        <journal-title>Neuroinformatics</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1539-2791</issn>
      <issn pub-type="epub">1559-0089</issn>
      <publisher>
        <publisher-name>Springer-Verlag</publisher-name>
        <publisher-loc>New York</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3104133</article-id>
      <article-id pub-id-type="pmid">21547564</article-id>
      <article-id pub-id-type="publisher-id">9120</article-id>
      <article-id pub-id-type="doi">10.1007/s12021-011-9120-3</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Original Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Automated Reconstruction of Neuronal Morphology Based on Local Geometrical and Global Structural Models</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Zhao</surname>
            <given-names>Ting</given-names>
          </name>
          <address>
            <email>tingzhao@gmail.com</email>
          </address>
          <xref ref-type="aff" rid="Aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>Jun</given-names>
          </name>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Amat</surname>
            <given-names>Fernando</given-names>
          </name>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Clack</surname>
            <given-names>Nathan</given-names>
          </name>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ahammad</surname>
            <given-names>Parvez</given-names>
          </name>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>Hanchuan</given-names>
          </name>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Long</surname>
            <given-names>Fuhui</given-names>
          </name>
          <address>
            <email>longf@janelia.hhmi.org</email>
          </address>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Myers</surname>
            <given-names>Eugene</given-names>
          </name>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <aff id="Aff1"><label>1</label>Qiushi Academy for Advanced Studies, Zhejiang University, 38 ZheDa Road, Hangzhou, 310027 China </aff>
        <aff id="Aff2"><label>2</label>HHMI Janelia Farm Research Campus, 19700 Helix Dr., Ashburn, VA 20147 USA </aff>
      </contrib-group>
      <pub-date pub-type="epub">
        <day>6</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>6</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>9</month>
        <year>2011</year>
      </pub-date>
      <volume>9</volume>
      <issue>2-3</issue>
      <fpage>247</fpage>
      <lpage>261</lpage>
      <permissions>
        <copyright-statement>&#xA9; The Author(s) 2011</copyright-statement>
      </permissions>
      <abstract id="Abs1">
        <p>Digital reconstruction of neurons from microscope images is an important and challenging problem in neuroscience. In this paper, we propose a model-based method to tackle this problem. We first formulate a model structure, then develop an algorithm for computing it by carefully taking into account morphological characteristics of neurons, as well as the image properties under typical imaging protocols. The method has been tested on the data sets used in the DIADEM competition and produced promising results for four out of the five data sets.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>DIADEM</kwd>
        <kwd>Neuron tracing</kwd>
        <kwd>Tube models</kwd>
        <kwd>Tree structure reconstruction</kwd>
        <kwd>3D microscopy</kwd>
      </kwd-group>
      <custom-meta-group>
        <custom-meta>
          <meta-name>issue-copyright-statement</meta-name>
          <meta-value>&#xA9; Springer Science+Business Media, LLC 2011</meta-value>
        </custom-meta>
      </custom-meta-group>
    </article-meta>
  </front>
  <body>
    <sec id="Sec1">
      <title>Introduction</title>
      <p>Progress in microscopy has generated a need for automated computational analysis and research into methods for such analyses has been termed bioimage informatics, e.g. Peng (<xref ref-type="bibr" rid="CR13">2008</xref>). In this paper we address a specific problem in this field, that of reconstructing neuronal morphologies from 3D microscopy images. It can be stated as follows:<disp-quote><p>Given a 3D image that is acquired via a common 3D microscopy protocol, automatically reconstruct the morphology of the neurons present in the image.</p></disp-quote></p>
      <p>This specific problem is important because a good solution will have a significant impact on neuroscience. The ultimate goal of neuroscience is to understand how nervous systems work. This cannot be achieved without obtaining the structure of a real neuronal network, which reveals how neurons are connected. This in turn requires the extraction of morphologies of individual neurons in the system. However, biologists have to rely on time-consuming manual or semi-manual methods to turn the images into morphological models. Given the number of neurons in a nervous system, we can easily foresee the emergence of a bottleneck. Therefore, an accurate fully-automated reconstruction method is critical to the advancement of neuroscience.</p>
      <p>The importance of the problem has led to quite a few attempts at developing automated methods for neuron reconstruction (Meijering <xref ref-type="bibr" rid="CR10">2010</xref>). To understand these methods, we need to remember two important common properties of the morphology of a neuron:
<list list-type="order"><list-item><p>The fibers of a neuron form a tree.</p></list-item><list-item><p>At the typical resolution of a light microscope, a fiber of a neuron often has a smooth tubular shape.</p></list-item></list>The most successful automated methods take advantages of one or both of these two properties. They can be further classified into two main categories:</p>
      <p><bold>Local Tracing</bold> A method in this category usually starts from a seed, which can be located automatically or manually, and traces where a neuronal fiber goes in the given image. The direction of tracing is determined based on the signal around the current location. A representative of this class is the method that was proposed in Al-Kofahi et al. (<xref ref-type="bibr" rid="CR2">2002</xref>). The authors used template fitting to determine the direction of tracing. The template they used consists of four parallel edge detectors, each of which locates a part of the branch boundary with a greedy search. A local tracing method produces one branch at a time and does not directly trace through branch points where a fiber forks into two or more continuing fibers. So a separate branch point detection method is required to complete the reconstruction (Al-Kofahi et al. <xref ref-type="bibr" rid="CR3">2007</xref>). Model-free strategies of local tracing, such as Rayburst Sampling (Rodriguez et al. <xref ref-type="bibr" rid="CR16">2006</xref>) and Voxel Scooping (Rodriguez et al. <xref ref-type="bibr" rid="CR17">2009</xref>), can trace multiple branches with one seed. However, the quality of the tracing relies heavily on the existence of a preprocessing step that accurately separates foreground and background.</p>
      <p><bold>Global Skeletonization</bold> In contrast to local tracing methods, the other category of methods extract skeletons of neurons based on the global signal distribution in an image. One straightforward way of doing this is to use a selected segmentation algorithm to turn the image into a binary foreground/background form, and then apply a 3D binary skeletonization algorithm (Dima et al. <xref ref-type="bibr" rid="CR7">2002</xref>; Weaver et al. <xref ref-type="bibr" rid="CR23">2004</xref>; Evers et al. <xref ref-type="bibr" rid="CR8">2005</xref>; Narro et al. <xref ref-type="bibr" rid="CR12">2007</xref>). But this has not always been a good choice because of the difficulty of the first step, binarization. A Hessian-based vesselness measurement has been used to enhance line structures in images and improve skeletonization (Abdul-Karim et al. <xref ref-type="bibr" rid="CR1">2005</xref>; Yuan et al. <xref ref-type="bibr" rid="CR26">2009</xref>; Vasilkoski and Stepanyants <xref ref-type="bibr" rid="CR21">2009</xref>). But it requires predefined scales and is computationally expensive when the number of scales is large. In an alternate strategy, Dijkstra&#x2019;s shortest path algorithm has been adopted to extract skeletons directly from gray-scale images (Zhang et al. <xref ref-type="bibr" rid="CR27">2007</xref>; Peng et al. <xref ref-type="bibr" rid="CR15">2010b</xref>). This algorithm was applied to find the path that gives the shortest geodesic distance between two points. As long as the geodesic distance is reasonably defined, the path found is indeed the one desired. Since Dijkstra&#x2019;s algorithm provides the global optimal solution, the method is robust when the seed points are well located (Meijering et al. <xref ref-type="bibr" rid="CR11">2004</xref>; Xie et al. <xref ref-type="bibr" rid="CR25">2010</xref>; Peng et al. <xref ref-type="bibr" rid="CR14">2010a</xref>). But such a method is not reliable when there are multiple neurons in an image and it requires manual selection of the termini to trace between.Both types of methods have been shown to be useful for neuron tracing. However, these automated results still require significant human curation and correction in order to be perfect. In this paper our goal is to develop a better method for reconstructing neurons whose morphology adheres to the two common properties mentioned above. For tracing neurons that do no show smooth neurites in the images (e.g. neurons imaged by electron microscopy), we would expect very different methods to work and it is beyond the scope of this paper. So we employ the idea of local tracing, and then refine the result with the use of shortest paths. Especially, we formulate the procedure of model based tracing, in the spirit of Al-Kofahi et al. (<xref ref-type="bibr" rid="CR2">2002</xref>) but by realizing it with a formal tube model, improve performance significantly. A general framework of tree-like morphology reconstruction from the resulting fiber segments is also proposed. Based on the framework, we have developed an automated pipeline to produce a final reconstruction from a raw or preprocessed image. The method was tested on the DIADEM data sets (Brown et al. <xref ref-type="bibr" rid="CR4">2011</xref>). The main purpose of this paper is to describe the method that brought us to the DIADEM final, so we do not formally evaluate it against the many algorithmic ideas that have been explored previously.</p>
    </sec>
    <sec id="Sec4" sec-type="methods">
      <title>Methods</title>
      <sec id="Sec5">
        <title>Model-based Neurite Fiber Tracing in 3D</title>
        <p>The shape of a neurite fiber can be approximated as a series of circular cross sections along a continuous curve (Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>) that are deformed to an ellipse along the axial direction by the anisotropy of the point spread function (PSF) of the microscope. More formally, its surface <italic>N</italic>(<italic>t</italic>,<italic>u</italic>) for parameters <italic>t</italic>,<italic>u</italic>&#x2009;&#x2208;&#x2009;[0,1] can be defined as:
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ N(t,u) = C(t) + O(u,t) \mathbf{R}(t) \mathbf{A} $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>C</italic>(<italic>t</italic>)&#x2009;=&#x2009;( <italic>x</italic>(<italic>t</italic>), <italic>y</italic>(<italic>t</italic>), <italic>z</italic>(<italic>t</italic>) ) is a continuous and differentiable curve, <italic>O</italic>(<italic>u</italic>,<italic>t</italic>)&#x2009;=&#x2009;( <italic>r</italic>(<italic>t</italic>) cos2<italic>&#x3C0;u</italic>, <italic>r</italic>(<italic>t</italic>) sin 2<italic>&#x3C0;u</italic>, 0 ) is a circle of radius <italic>r</italic>(<italic>t</italic>) in the <italic>z</italic>&#x2009;=&#x2009;0 plane,
<disp-formula id="Equa"><alternatives><tex-math id="M2">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{R}(t) = \left( \begin{array}{c} \mathbf{r_y} \times \mathbf{r_z} \\ \mathbf{r_y} = \mathbf{k} \times \mathbf{r_z} \\[4pt] \mathbf{r_z} = \dfrac{\Delta C(t)}{\| \Delta C(t) \|} \end{array} \right) $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equa.gif" position="anchor"/></alternatives></disp-formula> is a fixed matrix at each value of <italic>t</italic> that maps the circle from the <italic>z</italic>&#x2009;=&#x2009;0 plane into a plane perpendicular to the tangent of the curve <italic>C</italic>,<xref ref-type="fn" rid="Fn1">1</xref> and
<disp-formula id="Equb"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{A} = \left( \begin{array}{ccc} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; a(t) \end{array} \right) $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equb.gif" position="anchor"/></alternatives></disp-formula>stretches or squeezes the <italic>z</italic>-dimension by the parameter <italic>a</italic>(<italic>t</italic>)&#x2009;&gt;&#x2009;0 reflecting the asymmetry of the PSF and the sampling rate.
<fig id="Fig1"><label>Fig.&#xA0;1</label><caption><p>Neurite model and example. <bold>a</bold> is a cartoon to show that the model is composed of a set of cross sections along a principle axis. <bold>b</bold>&#x2013;<bold>e</bold> are neurites from the real images of the 4 DIADEM datasets. <bold>b</bold>, <bold>c</bold> are examples of darkfield microscopy and <bold>d</bold>, <bold>e</bold> are examples of brightfield microscopy. Refer to the &#x201C;<xref rid="Sec10" ref-type="sec">Results</xref>&#x201D; section for more details about the imaging conditions</p></caption><graphic xlink:href="12021_2011_9120_Fig1_HTML" id="d28e505"/></fig></p>
        <p>When a neurite is smooth enough, which is often true in real data, we can approximate a neurite segment as a discrete series of elliptical cylinders. So one way to reliably detect if a point (<italic>x</italic>,<italic>y</italic>,<italic>z</italic>) is on the neurite&#x2019;s principle axis <italic>C</italic>(<italic>t</italic>), is to see if there is a good fit between the signal and a cylindrical model centered at (<italic>x</italic>,<italic>y</italic>,<italic>z</italic>) of fixed height <italic>h</italic> reflecting the &#x201C;mesh size&#x201D; of the proposed series. Such an elliptic cylinder has four free parameters: its radius <italic>r</italic>, two Euler angles <italic>&#x3D5;</italic> and <italic>&#x3C8;</italic> that orient it along a vector in space, and the anisotropy calibration <italic>a</italic> in the axial direction. This also defines a deformable model of a canonical cylinder, which has unit radius and orientation parallel to the axial or <italic>z</italic>-axis. Therefore designing a more reasonable filter-like structure for the canonical cylinder will allow us to estimate the parameters more efficiently and accurately.</p>
        <sec id="Sec6">
          <title>A 3D Cylinder Filter</title>
          <p>To evaluate the fit of a cylinder model to the data, we derived a 3D filter for a cylinder, which we also call a template. The fitting score between the model and the data is defined as the the correlation between the intensity data and the template. Due to its averaging effect, this simple defintion can effectively suppress the disturbance of imaging noise or artifcacts, even if our modeling procedure does not consider imaging noise or artifcacts explcitly. Our template is designed for darkfield images, where signal is brighter than background. One can simply invert the template for brightfield images.</p>
          <p>In cross-section, a neurite fiber looks like a Gaussian- diffused spot possibly scaled along the axial direction, so we use an elliptical Mexican Hat filter (Laplacian of a Gaussian) to convolve with the signal along the symmetric axis of the cylinder. The choice of using a Mexican Hat filter is similar to the one in Schmitt et al. (<xref ref-type="bibr" rid="CR19">2004</xref>), except that the shape of our filter can be elliptical. So our canonical unit vector is given by:
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M4">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ U(x,y,z) = \left(1-\left(x^2+y^2\right)\right) e^{-(x^2+y^2)} $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>z</italic>&#x2009;&#x2208;&#x2009;[&#x2009;&#x2212;&#x2009;<italic>h</italic>/2,<italic>h</italic>/2]. To obtain the space of all possible cylinder templates, one can scale <italic>U</italic> in <italic>x</italic> and <italic>y</italic> by radius <italic>r</italic>, then rotate it in any manner desired, and final scale it along <italic>z</italic> (making it elliptical) by factor <italic>a</italic>.</p>
          <p>Of course, the support of the filter must be finite not only for computational purposes, but also because, while the model demands that background surround (most) of the neurite fiber, making this zone too large means that fibers passing very near by will disrupt the fit of the filter. So for a given filter instance, regardless of <italic>a</italic> and <italic>r</italic>, we limit the support of the filter to <italic>&#x3C4;</italic> pixels beyond the zero-crossing of the Mexican Hat. The second consideration, is that for very thick neurons, their intensity profile often has a flattened top due to saturation of the signal in the center (e.g. Fig.&#xA0;<xref rid="Fig2" ref-type="fig">2</xref>). For such a profile a slight deformation of the template induces little or no change in score, so we empirically found that regularizing the template family by multiplying the positive part of the Mexican Hat by (<italic>ar</italic><sup>2</sup>)<sup>1/4</sup> solves the problem.
<fig id="Fig2"><label>Fig.&#xA0;2</label><caption><p>Example of a thick neuron cross-section where the intensity profile is flattened in the center. <bold>a</bold> is the actual image cross section. <bold>b</bold> is a plot of the intensity profile of the cross section in <bold>a</bold></p></caption><graphic xlink:href="12021_2011_9120_Fig2_HTML" id="d28e637"/></fig></p>
          <p>As long as the neurite fiber section under consideration is surrounded by background, the filter essentially gives a large score for any cross section surrounding the bright region. To rectify this the cross correlation score of the filter convolved with the signal is normalized by dividing by the integral of the absolute value of the filter over its support. In the optimization step to follow, the <italic>r</italic> and <italic>a</italic> parameters are varied along with the orientation angles at a specified center point in space to those for which the template yields the largest normalized score when convolved with the signal.</p>
          <p>Note that <italic>h</italic> and <italic>&#x3C4;</italic> are the two parameters that need to be chosen prior to running our method for any particular image acquisition conditions and they are primarily a function of pixel size. For example, for most images at 40X <italic>h</italic>&#x2009;=&#x2009;10 and <italic>&#x3C4;</italic>&#x2009;=&#x2009;2 suffice. In our experience the method is robust to these parameter choices and they remain fixed for any set of images acquired with the same microscope and imaging protocol.</p>
        </sec>
        <sec id="Sec7">
          <title>Tracing a Neurite Fiber</title>
          <p>One could use a greedy search to optimize the four free parameters (two orientation parameters and two scale parameters) of the template when it is placed at a given point in space. But this is less appropriate for such a large number of parameters because search time increases exponentially in the number of parameters. If the score function is smooth and has a single peak, gradient descent is certainly preferred. Fortunately, our scoring function does have this property in a fairly large zone of the parameter space around the true optimum. Moreover, the symmetry of the function makes it well fit by a quadratic function within this zone, so as long as the template is placed in a reasonable initial position (which could for example be determined by a coarse discrete sampling of the parameter space), one can use the conjugate gradient descent method, which has been shown to be the best for optimizing general quadratic functions. In our implementation, we used the Polak&#x2013;Ribi&#xE8;re conjugate gradient descent method (Wright and Nocedal <xref ref-type="bibr" rid="CR24">2006</xref>). Results showed that it is significantly better than steepest gradient descent (e.g. Fig.&#xA0;<xref rid="Fig3" ref-type="fig">3</xref>).
<fig id="Fig3"><label>Fig.&#xA0;3</label><caption><p>Conjugate gradient descent reaches the optimal score faster than steepest gradient descent</p></caption><graphic xlink:href="12021_2011_9120_Fig3_HTML" id="d28e679"/></fig></p>
          <p>There is no closed form expression for calculating the gradients because of the lack of a closed form describing the image. So numerical estimation is necessary, and as per standard practice we use the approximation (<italic>S</italic>(<italic>u</italic>&#x2009;+&#x2009;&#x394;<italic>u</italic>)&#x2009;&#x2212;&#x2009;<italic>S</italic>(<italic>u</italic>&#x2009;&#x2212;&#x2009;&#x394;<italic>u</italic>))/ (2&#x394;<italic>u</italic>) for the partial derivative <inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\partial S / \partial u$\end{document}</tex-math><inline-graphic xlink:href="12021_2011_9120_Article_IEq1.gif"/></alternatives></inline-formula> of a variable <italic>u</italic>.</p>
          <p>After fitting a cylinder at a given position, we have only modeled a small section of the target neurite fiber. To cover the whole neurite, we use a strategy similar to the one introduced in Al-Kofahi et al. (<xref ref-type="bibr" rid="CR2">2002</xref>) to traverse the entire fiber in mesh steps of size <italic>h</italic>/2. Once we have fitted a cylinder <italic>c</italic><sub><italic>i</italic></sub>, we then place a cylinder <italic>c</italic><sub><italic>i</italic>&#x2009;+&#x2009;1</sub> with its center at one end of <italic>c</italic><sub><italic>i</italic></sub>&#x2019;s symmetric axis in the same orientation and of the same cross-section shape, and then optimize the orientation and shape of <italic>c</italic><sub><italic>i</italic>&#x2009;+&#x2009;1</sub> from this starting position. In this way, given an initial cylinder <italic>c</italic><sub>0</sub>, one can walk in both direction to traverse a fiber. The pseudo-code for tracing in one direction is simply as follows.
<graphic xlink:href="12021_2011_9120_Figa_HTML.gif" id="d28e754"/></p>
          <p>In the next subsection, we discuss how to arrive at a set of seed cylinders <italic>c</italic><sub>0</sub> for an entire image.</p>
        </sec>
        <sec id="Sec8">
          <title>Tracing All Neurite Fibers</title>
          <p>In the previous section we showed how to trace a neurite fiber given an initial filter fit <italic>c</italic><sub>0</sub>. To find a set of initial filters, one for each fiber, we developed a seed detection method to locate all locations and approximate orientations of points on the curve of a neurite based on two image features. The first feature is pixel intensity: when a pixel is brighter it is more likely on a neurite. The second feature is local geometry. We prefer a seed to be on a line structure. This can be measured by examining the eigenvalues of a Hessian matrix (Sato et al. <xref ref-type="bibr" rid="CR18">1998</xref>) computed at a point, typically at a number of scales. But the calculation of a Hessian matrix is expensive in both time and space, so we only do the calculation once at the smallest scale (3 &#xD7;3 &#xD7;3), and assume that thick fibers are bright enough that they will be picked up by the intensity feature. For each of these two features a threshold is computed with the triangle method over the histogram of the local maxima of feature scores at all pixels. Any pixel that has either of its two features above threshold is considered to be an on pixel in a binarization of the image that roughly covers all the neurites or at least a portion of every neurite fiber.</p>
          <p>Since we want to place our initial filter fits <italic>c</italic><sub>0</sub> at the center of a neurite, we consider as possible <italic>seed</italic> locations those points that are local maxima of the distance map of the binary image. Obviously, many possible seeds can be reported for a given neurite fiber whereas only one is needed. So we optimize the fit of a cylinder template at every possible seed. The optimization at each point is initialized with the best-scoring <italic>&#x3C4;</italic>-pixel circular cylinder over a fixed set of orientation sampling the space of all possible orientations. We then sort the seeds in the order of their optimized model scores for <italic>c</italic><sub>0</sub>. We start with the best seed and trace its neurite fiber, removing from consideration any seeds that are covered by the tracing. We then pick the next best remaining seed and trace it, and continue greedily in this fashion until all the seeds are exhausted. In this way we build a model of (almost) every neurite fiber in the image. The caveats are that if the signal is sufficiently dim in parts then the fiber may not be spanned leading to the occasional broken fiber, and in some cases the tracing moves directly through a branch point, but this is benign in that it is technically the fusion of two fibers that should ultimately be fused anyway.</p>
        </sec>
      </sec>
      <sec id="Sec9">
        <title>Reconstruction of Neuronal Morphology</title>
        <p>Once the set of individual neurite fibers or fragmentary trace have been obtained for an image, they can then be assembled to form a neuronal tree structure. There are typically many ways to join them together, but by prohibiting the formation of cycles during the assembly process we guarantee that the final structure is a tree. This can be formulated as a graph problem.</p>
        <p>Suppose we have a set of neurite fibers, <inline-formula id="IEq2"><alternatives><tex-math id="M6">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\{N_k\}_{k=1}^N$\end{document}</tex-math><inline-graphic xlink:href="12021_2011_9120_Article_IEq2.gif"/></alternatives></inline-formula>. The goal is to determine how they are connected. We first create a <italic>neurite graph</italic>, in wich each node is a neurite and each edge indicates a possible connection between two neurites. In contrast to a usual graph, a node in a neurite graph has three parts, two ends and a body. So an edge between two nodes in this undirected graph must also specify at each node whether it connects to an end or the body. The connection pattern of an edge can be either end-to-end or end-to-body (Fig.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>), but never body-to-body. Moreover, only one edge is allowed between two neurites. Our problem, in the framework of this graph, is to find a minimum weight spanning tree in the case one neuron is under view and all the <italic>N</italic><sub><italic>k</italic></sub> are true positives. The whole procedure is illustrated in Fig.&#xA0;<xref rid="Fig5" ref-type="fig">5</xref>. In our method, we do not consider the connection between a pair of neurites that are too far away from each other. The distance threshold is set to 20 pixels, which is twice as long as the height of the cylinder templates. Any two neurites that have a distance larger than the threshold are supposed to be from different neurons.
<fig id="Fig4"><label>Fig.&#xA0;4</label><caption><p>Graph of neurites. A neurite is modeled as a 3-part node <bold>a</bold>, which can form end-to-end connection <bold>b</bold> or end-to-body connection <bold>c</bold> with another node. Real examples of end-to-end connection and end-to-body connection are shown in <bold>d</bold> and <bold>e</bold> respectively. <italic>Colors</italic> indicate different neurites</p></caption><graphic xlink:href="12021_2011_9120_Fig4_HTML" id="d28e849"/></fig><fig id="Fig5"><label>Fig.&#xA0;5</label><caption><p>Flowchart of the tree reconstruction procedure</p></caption><graphic xlink:href="12021_2011_9120_Fig5_HTML" id="d28e858"/></fig></p>
        <p>So the design issue is how to assign a cost to each possible edge, which will join fibers if selected to be in the result. The cost must be such that the smaller the value the more desirable the edge for inclusion. One of the simplest schemes for the cost of connecting <italic>N</italic><sub><italic>i</italic></sub> to <italic>N</italic><sub><italic>j</italic></sub> is the distance between the center of the end of <italic>N</italic><sub><italic>i</italic></sub> and the center of the end of <italic>N</italic><sub><italic>j</italic></sub> in the case of an end-to-end edge, and the distance of the center of the end of <italic>N</italic><sub><italic>i</italic></sub> to the nearest point on the surface of the body of <italic>N</italic><sub><italic>j</italic></sub> in the case of an end-to-body edge. This definition is quite natural because two fibers tend to be close to each other when they join to form a branch point in the image. However, when such gaps start being as large as the nearest fiber to one of the fibers under consideration, a wrong choice can be made. This does happen with some low frequency. For example, there was one such occurrence for a traced neuron which has about 40 branches. So other cues must be considered.</p>
        <p>One such strong cue to tell if two tubes are truly connected is the strength of the image signal between them. If we can find a path from one neurite fiber end or body to the other endpoint along a path of bright pixels, then it is highly likely that the two tubes connect to each other. Therefore we added another measurement, the geodesic distance, as an option. The geodesic distance between two points <italic>x</italic><sub>0</sub> and <italic>x</italic><sub>1</sub> is defined as
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm geo}_g(x_0,x_1) = \min\limits_{c \in \{\text{all possible paths}\}} \int_c g[I(c(t))] \,\, ||dc(t)|| $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <italic>c</italic>(0)&#x2009;=&#x2009;<italic>x</italic><sub>0</sub>, <italic>c</italic>(1)&#x2009;=&#x2009;<italic>x</italic><sub>1</sub>, <inline-formula id="IEq3"><alternatives><tex-math id="M8">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$||dc(t)|| = \sqrt{dc_x^2(t) + dc_y^2(t) + dc_z^2(t)}$\end{document}</tex-math><inline-graphic xlink:href="12021_2011_9120_Article_IEq3.gif"/></alternatives></inline-formula> is the differential of the arc length of <italic>c</italic>(<italic>t</italic>), and <italic>I</italic>(<italic>x</italic>) is the image intensity at <italic>x</italic>. The function <italic>g</italic> defines how image intensity contributes to the geodesic distance. In our study, we expect the shortest path <italic>c</italic>, to be on the foreground. This can be expressed by a sigmoid function
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ g(x) = \frac{1}{1+e^{\frac{x - \alpha}{\beta}}} $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>&#x3B1;</italic> and <italic>&#x3B2;</italic> are selected to reflect the separability between the foreground and background and we do not have to set them arbitrarily. For example, we can take the signal inside a tube as foreground and those around the tube as background and calculate their average values, which are denoted as <italic>c</italic><sub><italic>f</italic></sub> and <italic>c</italic><sub><italic>b</italic></sub>, respectively. If we want <italic>g</italic>(<italic>c</italic><sub><italic>f</italic></sub>)&#x2009;=&#x2009;0.99 and <italic>g</italic>(<italic>c</italic><sub><italic>b</italic></sub>)&#x2009;=&#x2009;0.01, it is easy to solve for <italic>&#x3B1;</italic> and <italic>&#x3B2;</italic> yielding <inline-formula id="IEq4"><alternatives><tex-math id="M10">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\alpha = \frac{c_f+c_b}{2}$\end{document}</tex-math><inline-graphic xlink:href="12021_2011_9120_Article_IEq4.gif"/></alternatives></inline-formula> and <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\beta = \frac{c_f - c_b}{2 ln (99)}$\end{document}</tex-math><inline-graphic xlink:href="12021_2011_9120_Article_IEq5.gif"/></alternatives></inline-formula>.</p>
        <p>A neurite graph becomes a typical weighted undirected graph if we ignore the internal structure of its nodes and the connection pattern of its edges. In some sense, the minimal spanning tree of this graph maximizes the likelihood of being the appropriate tree reconstruction if the cost function on edges properly reflects the likelihood that two neurites involved have a direct connection. Unfortunately there is the case that when two neuron fibers cross each other very closely, even the quite reasonable geodesic cost function fails to meet this criterion.</p>
        <p>When one fiber passes another very closely, especially in the axial <italic>z</italic>-dimension where resolution is lower with most microscopes, their signal may overlap to the extent that the geodesic cost function (falsely) indicates that they should be joined (Fig.&#xA0;<xref rid="Fig6" ref-type="fig">6</xref>). In other words, the overlap pattern cannot be identified by the MST algorithm. We call such a pattern a <italic>crossover</italic>, and it must be distinguished from the real fusions that need to occur at branch points in a neuron. In the neurite graph, a crossover has one of two special signatures depending on whether the fiber tracing passes through the crossover region or not. If the tracing does not pass, the pattern will be pairwise end-to-end connections among four or more nodes (Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>). Otherwise, the pattern will be the connections from the ends of two or more neurites to the body of another neurite (imagine fibers 1 and 3 are already joined into a single fiber in Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>). For the latter case, the problem is compounded as the local tracing that went through the crossover region may have &#x201C;jumped tracks&#x201D; to another fiber. So conservatively, we break any fibers that pass through the connection region. This has the further advantage of reducing the problem to the first case where all possible connections are end-to-end.
<fig id="Fig6"><label>Fig.&#xA0;6</label><caption><p>An example of crossover from real data. The <italic>top</italic> image and the <italic>bottom</italic> image are showing the same two neurites projected onto X-Y plane and X-Z plane respectively. The <italic>color lines</italic> indicate how the two neurites cross</p></caption><graphic xlink:href="12021_2011_9120_Fig6_HTML" id="d28e1065"/></fig><fig id="Fig7"><label>Fig.&#xA0;7</label><caption><p>Crossover <bold>a</bold> in a neurite graph <bold>b</bold>. The solution <bold>c, d</bold> gives the minimal sum of the angles between matched neurites. The <italic>red and green lines</italic> in <bold>c</bold> and <bold>d</bold> show how the neurites are merged after matching</p></caption><graphic xlink:href="12021_2011_9120_Fig7_HTML" id="d28e1093"/></fig></p>
        <p>Crossover cannot be solved directly with minimum spanning tree as it will tend to just join all the fibers together (in the case that multiple neurons are present), or join fibers depending on the signal strength between them which is not a good indicator of which fiber should be joined with which. A better indicator is the angle between two neurite end vectors: if there is no or little change in direction as one goes from one fiber to the next, then it is likely that the two fibers should be joined. So for the fibers that end at the crossover region we find the best set of pairings based on minimizing the total of the join angles using the Hungarian algorithm. These neurites are then fused. The cross-over process takes place prior to the greedy minimum spanning tree algorithm (MST).</p>
      </sec>
    </sec>
    <sec id="Sec10">
      <title>Results</title>
      <p>We tested the algorithm on 4 of the 5 data sets<xref ref-type="fn" rid="Fn2">2</xref> from the Digital Reconstruction of Axonal and Dentritic Morphology (DIADEM) competition (<ext-link ext-link-type="uri" xlink:href="http://www.diademchallenge.org">http://www.diademchallenge.org</ext-link>). Named after the stained neuron types, the 4 datasets are CF (Cerebellar Climbing Fibers) (Sugihara et al. <xref ref-type="bibr" rid="CR20">1999</xref>), HC (Hippocampal CA3 Interneuron) (Calixto et al. <xref ref-type="bibr" rid="CR5">2008</xref>), NL (Neocortical Layer6 Axons) (De Paola et al. <xref ref-type="bibr" rid="CR6">2006</xref>) and OP (Olfactory Projection Fibers) (Jefferis et al. <xref ref-type="bibr" rid="CR9">2007</xref>). The imaging protocol for each dataset is listed briefly in Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref>. The images of the datasets CF and HC are from bright-field microscopy and some special preprocessing steps, to be described, are necessary before applying model fitting on them. For the NL dataset, an image contains multiple neurons. Given the coordinates of a point on each neuron, we built a single tree first and then cut the edges with largest connection cost to get multiple trees. Also the crossover prior described in the previous section was applied to the NL data only. The final results on all 4 datasets are illustrated in Fig.&#xA0;<xref rid="Fig8" ref-type="fig">8</xref> (CF), Fig.&#xA0;<xref rid="Fig9" ref-type="fig">9</xref> (HC), Fig.&#xA0;<xref rid="Fig10" ref-type="fig">10</xref> (NL), Fig.&#xA0;<xref rid="Fig11" ref-type="fig">11</xref> (OP).
<table-wrap id="Tab1"><label>Table&#xA0;1</label><caption><p>Summary of the datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>CF</th><th>HC</th><th>NL</th><th>OP</th></tr></thead><tbody><tr><td><italic>Species</italic></td><td>Rat</td><td>Rat</td><td>Mouse</td><td>Drosophila</td></tr><tr><td><italic>Nervous system</italic></td><td>Cerebellar cortex</td><td>Hippocampus CA3</td><td>Peripheral</td><td>Olfactory bulb</td></tr><tr><td><italic>Fiber type</italic></td><td>Axon terminals</td><td>Dendrites and axons</td><td>Axons</td><td>Axons</td></tr><tr><td><italic>Microscopy</italic></td><td>Transmitted light brightfield</td><td>Transmitted light brightfield</td><td>2-photon microscopy</td><td>Confocal microscopy</td></tr><tr><td><italic>Voxel size</italic></td><td>1 &#xD7;1 &#xD7;8.8&#xA0;&#x3BC;m</td><td>0.217 &#xD7;0.217 &#xD7;0.33&#xA0;&#x3BC;m</td><td>0.294 &#xD7;0.294 &#xD7;1&#xA0;&#x3BC;m</td><td>0.033 &#xD7;0.033 &#xD7;1&#xA0;&#x3BC;m</td></tr></tbody></table></table-wrap><fig id="Fig8"><label>Fig.&#xA0;8</label><caption><p>The tracing result (<italic>green</italic>) of an CF image stack overlaps with a slice of the original stack. The result is translated a little from its original position for better view</p></caption><graphic xlink:href="12021_2011_9120_Fig8_HTML" id="d28e1266"/></fig><fig id="Fig9"><label>Fig.&#xA0;9</label><caption><p>The tracing result (<italic>red</italic>) of an HC image stack overlaps with a slice of the original stack. The result is translated a little from its original position for better view</p></caption><graphic xlink:href="12021_2011_9120_Fig9_HTML" id="d28e1278"/></fig><fig id="Fig10"><label>Fig.&#xA0;10</label><caption><p>The tracing result (<italic>colored</italic>) of an NL image stack overlaps with the volume rendering of the original stack. The result is translated a little from its original position for better view. Note that there is plenty of signal that has no corresponding neuronal structure. This is because the structures are excluded from the specified neuron set, despite that the tracing did not miss them</p></caption><graphic xlink:href="12021_2011_9120_Fig10_HTML" id="d28e1290"/></fig><fig id="Fig11"><label>Fig.&#xA0;11</label><caption><p>The tracing result (<italic>red</italic>) of an OP image stack overlaps with the volume rendering of the original stack. The result is translated a little from its original position for better view</p></caption><graphic xlink:href="12021_2011_9120_Fig11_HTML" id="d28e1302"/></fig></p>
      <p><bold>Testing for Robustness to Noise</bold> We also tested our method on different noise levels to show its strength. The testing images were created by adding Gaussian noise to the OP image stack (Fig.&#xA0;<xref rid="Fig11" ref-type="fig">11</xref>). We used five noise levels, measured by the standard deviation of the noise distribution: <italic>&#x3C3;</italic>&#x2009;=&#x2009;20, <italic>&#x3C3;</italic>&#x2009;=&#x2009;40, <italic>&#x3C3;</italic>&#x2009;=&#x2009;60, <italic>&#x3C3;</italic>&#x2009;=&#x2009;80, <italic>&#x3C3;</italic>&#x2009;=&#x2009;100 where values in the image range from 0 to 255. The neuron becomes less visible when <italic>&#x3C3;</italic> is larger (Fig.&#xA0;<xref rid="Fig12" ref-type="fig">12</xref>), making tracing progressively more difficult. To quantitatively evaluate how robust our method is to noise, we calculated the scores of tracing quality using the DIADEM metric (<ext-link ext-link-type="uri" xlink:href="http://www.diademchallenge.org/metric.html">http://www.diademchallenge.org/metric.html</ext-link>). The results were also compared with those obtained from the free software NeuroStudio (Wearne et al. <xref ref-type="bibr" rid="CR22">2005</xref>), which was developed based on the Rayburst Sampling tracing algorithm. As shown in Fig.&#xA0;<xref rid="Fig13" ref-type="fig">13</xref>, our method produced reasonable result (score = 0.866) even when the noise level is at 100. In contrast, NeuroStudio&#x2019;s performance degrades rapidly reaching a score of 0 when the noise is at 80. Moreover, our method outperformed NeuroStudio significantly for all the noise levels, including the case where there is no noise.
<fig id="Fig12"><label>Fig.&#xA0;12</label><caption><p>An OP image stack was contaminated by different levels of Gaussian noise: <bold>a</bold><italic>&#x3C3;</italic>&#x2009;=&#x2009;20, <bold>b</bold><italic>&#x3C3;</italic>&#x2009;=&#x2009;40, <bold>c</bold><italic>&#x3C3;</italic>&#x2009;=&#x2009;60, <bold>d</bold><italic>&#x3C3;</italic>&#x2009;=&#x2009;80, <bold>e</bold><italic>&#x3C3;</italic>&#x2009;=&#x2009;100</p></caption><graphic xlink:href="12021_2011_9120_Fig12_HTML" id="d28e1379"/></fig><fig id="Fig13"><label>Fig.&#xA0;13</label><caption><p>The tracing results on different noise levels generated by our method (<italic>solid line</italic>) are compared to the results obtained from NeuroStudio (<italic>dash-dot line</italic>). It shows that our result is much more robust to the noise</p></caption><graphic xlink:href="12021_2011_9120_Fig13_HTML" id="d28e1394"/></fig></p>
      <p><bold>Preprocessing for the CF Dataset</bold> In the CF images neurons are brown and nuclei are blue. In some areas they overlap due to the nature of the bright-field point spread function which does not optically section in <italic>z</italic>. This overlap can not be resolved by extracting a certain color component as in some regions light from both objects is present. We solved the problem based on a color mixing model. In this model, there is an average (bright) background <italic>B</italic> and there are two different materials, <italic>m</italic><sub>1</sub> and <italic>m</italic><sub>2</sub>, in the imaging field and each material absorbs light of a certain color, <italic>c</italic><sub>1</sub> and <italic>c</italic><sub>2</sub>, respectively. At any voxel <italic>x</italic>, the total observed intensity <italic>I</italic>(<italic>x</italic>) is:
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M12">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ I(x)= B - [c_1, c_2] \cdot \left[ \begin{array}{c} p_1(x)\\ p_2(x) \\ \end{array} \right] \label{eq:color_mix} $$\end{document}</tex-math><graphic xlink:href="12021_2011_9120_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <italic>p</italic><sub><italic>i</italic></sub>(<italic>x</italic>) denotes the absorption contribution from material <italic>m</italic><sub><italic>i</italic></sub>. We estimate <italic>B</italic> as the average intensity of each frame which is a good estimate as the background occupies most of each frame. <italic>c</italic><sub>1</sub> and <italic>c</italic><sub>2</sub> are calculated reliably by taking the average values of the two separable peaks in the color histogram of <italic>B</italic>&#x2009;&#x2212;&#x2009;<italic>I</italic>. Once we have these three values, we compute the amount of each material at each voxel by solving Eq.&#xA0;<xref rid="Equ5" ref-type="">5</xref> by linear regression. The result is shown in Fig.&#xA0;<xref rid="Fig14" ref-type="fig">14</xref>.
<fig id="Fig14"><label>Fig.&#xA0;14</label><caption><p>The color component corresponding to neurons <bold>b</bold> is extracted from an image of the CF dataset <bold>a</bold></p></caption><graphic xlink:href="12021_2011_9120_Fig14_HTML" id="d28e1500"/></fig></p>
      <p><bold>Preprocessing for the HC Dataset</bold> Much of the preprocessing required for this dataset was due to either poor microscopy or poor stitching of the multiple 3D stacks that made up each data set. In particular, the <italic>z</italic>-planes of a given tile were offset with respect to each other and the luminence of each plane varied significantly. We do not know how these artifacts were introduced, but we perforce had to correct them.First the images were converted to gray-scale for the neuron intensity using the color model scheme used for CF, save that here matters were particular easy as there was only one material. Next the motion artifacts were corrected by splitting the full volume into a series of subvolumes corresponding to the lateral tiling used to originally acquire the data. Each subvolume was then processed independently. For each pair of successive <italic>z</italic>-planes, a lateral translation was estimated as that maximizing the correlation between each edge-enhanced representations of the respective planes. Edge enhanced images were computed by filtering with a difference-of-boxes filter (box sizes 5 and 15 pixels) followed by masking with the original data binarized according to the Ostu threshold. Linear interpolation was used to align images according to the estimated translation. Border regions were filled by clamping to the edges. After motion correction, the volume was median filtered along <italic>z</italic> (window size 1 &#xD7;1 &#xD7;13) in order to correct for intensity fluctuations between planes. The window size was chosen to approximate the observed extent of a single neurite image along the <italic>z</italic> direction. Finally, the vertical blur from strongly labeled objects, such as the cell soma, added an approximate constant signal to all planes above and below the object. To remove this signal, we estimated it as the median plane along <italic>z</italic> and subtracted that from each plane clamping negative values to zero. An example of processing result is shown in Fig.&#xA0;<xref rid="Fig15" ref-type="fig">15</xref>.
<fig id="Fig15"><label>Fig.&#xA0;15</label><caption><p>Preprocessing result for the HC dataset: <bold>a</bold> Original image; <bold>b</bold> Processed image</p></caption><graphic xlink:href="12021_2011_9120_Fig15_HTML" id="d28e1541"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Discussion</title>
      <p>There have been numerous articles on methods for the automated reconstruction of neuronal morphology. However, the quest for better, more powerful reconstruction algorithms remains. Existing methods fall into the two main classes of <italic>local tracing</italic> and <italic>global skeletonization</italic>. Both paradigms have proved to be useful, but we feel their potential has not been fully explored. In this paper, we refined a local tracing approach by designing a more sophisticated template for which we carefully optimize its orientation and positioning as the tracing progresses. Combining it with a novel neurite fiber graph model, we have developed a robust neuron reconstruction method. The method works on various types of images with few modifications. Even though the method was originally designed for darkfield images, it generates reliable results for preprocessed brightfield images as well.</p>
      <p>We proposed a geometrical model to formulate the shape of a neurite fiber. From the model, we derived a tracing algorithm based on deformable templates. We also found that the template parameters can be estimated efficiently by conjugate gradient descent. As a result the method can deal with neurites with various sizes and produce accurate measurement of the surface of a neuron.</p>
      <p>One main advantage of our model-based approach is its robustness to noise. This is due to the intrinsic averaging effect of the score calculation. So it does not need an additional noise reduction method to get acceptable results. This is especially well-suited for interactive tracing, which allows a user to extract a neurite with one click on raw data.</p>
      <p>We have also defined a special graph model to derive algorithms for finding the most likely tree structure given a set of neurite fibers. The graph model is flexible and allowed us to add useful priors. For example, we have shown that adding a prior for crossover patterns can improve the reconstruction results of the NL data set dramatically.</p>
      <p>The positive feature of our template model is that given sufficient support <italic>h</italic> it clearly distinguishes neurite from non-neurite artifacts. That is it has a low false positive rate of identification (an example is shown in Fig.&#xA0;<xref rid="Fig16" ref-type="fig">16</xref>). The problem is that it does not detect short features that are at fewer than <italic>h</italic> pixels in size such as short side branches, or sometimes it will erroneously fit the model over a small break that actually separates two fibers. To further improve the method, its limitation in these circumstances must be addressed (Fig.&#xA0;<xref rid="Fig17" ref-type="fig">17</xref>) and we suggest approaches as follows:
<fig id="Fig16"><label>Fig.&#xA0;16</label><caption><p>Our method can avoid tracing blobs (marked by <italic>green arrows</italic>) that are as bright as some neurites</p></caption><graphic xlink:href="12021_2011_9120_Fig16_HTML" id="d28e1584"/></fig><fig id="Fig17"><label>Fig.&#xA0;17</label><caption><p>Scenarios causing problems for our tracing method: <bold>a</bold> The two branch tips are so close that the tracing jumps from one to the other; <bold>b</bold> The cylinder model may fail to fit on a short branch between two close branch points; <bold>c</bold> Two examples of broken neurite signal on which the tracing will stop too early at any seeding point</p></caption><graphic xlink:href="12021_2011_9120_Fig17_HTML" id="d28e1602"/></fig></p>
      <p><bold>Dense Branches</bold> When many branches are present in a small region, such as the end of an axonal projection, the fitting template may jump from one branch tip to another or fail to fit on a short segment between two branch points. Both mistakes will result in topological errors. The first type of mistake is hard to fix because of the loop structures formed in the image due to the limited resolution. We may have to correct them manually or add topological constraints for reconstruction. The second one may be less a problem because it is easier to detect the missing signal than to correct an over-fitting. Once we find a bright region not being included in the reconstruction, we can extract it and estimate the orientation and size by principle component analysis if the cylinder model does not fit.</p>
      <p><bold>Broken Branch Signal</bold> Although a neurite is continuous, we may only see a sequence of isolated bright dots when it is imaged. This can be caused by uneven staining or uneven distribution of GFP particles and is generally indicative of poor sample preparation. Our tube model will generally fail on data of this quality because the assumption of continuity is no longer valid. One could treat this as a special case and use a different tracing method, such as the one proposed in Peng et al. (<xref ref-type="bibr" rid="CR14">2010a</xref>) to attempt to span such dark zones.</p>
    </sec>
    <sec id="Sec17">
      <title>Information Sharing Statement</title>
      <p content-type="availability">All codes for our neuron tracing pipeline are available in open source and can be found on the DIADEM website (<ext-link ext-link-type="uri" xlink:href="http://diademchallenge.org">http://diademchallenge.org</ext-link>).</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgements</title>
      <p content-type="acknowledgment">The authors thank Shiv Vitaladevuni, Mark Longair, and Saket Navlakha for helpful discussions. This work was supported by Howard Hughes Medical Institute.</p>
      <p><bold><bold>Open Access</bold></bold> This article is distributed under the terms of the Creative Commons Attribution Noncommercial License which permits any noncommercial use, distribution, and reproduction in any medium, provided the original author(s) and source are credited.</p>
    </ack>
    <ref-list id="Bib1">
      <title>References</title>
      <ref id="CR1">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abdul-Karim</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Roysam</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Dowell-Mesfin</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Jeromin</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Yuksel</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Kalyanaraman</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Automatic selection of parameters for vessel/neurite segmentation algorithms</article-title>
          <source>IEEE Transactions on Image Processing</source>
          <year>2005</year>
          <volume>14</volume>
          <issue>9</issue>
          <fpage>1338</fpage>
          <lpage>1350</lpage>
          <pub-id pub-id-type="doi">10.1109/TIP.2005.852462</pub-id>
          <pub-id pub-id-type="pmid">16190469</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR2">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Al-Kofahi</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Lasek</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Szarowski</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Pace</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Nagy</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Turner</surname>
              <given-names>J</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Rapid automated three-dimensional tracing of neurons from confocal image stacks</article-title>
          <source>IEEE Transactions on Information Technology in Biomedicine</source>
          <year>2002</year>
          <volume>6</volume>
          <issue>2</issue>
          <fpage>171</fpage>
          <lpage>187</lpage>
          <pub-id pub-id-type="doi">10.1109/TITB.2002.1006304</pub-id>
          <pub-id pub-id-type="pmid">12075671</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR3">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Al-Kofahi</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Dowell-Mesfin</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Pace</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Shain</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Turner</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Roysam</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Improved detection of branching points in algorithms for automated neuron tracing from 3D confocal images</article-title>
          <source>Cytometry Part A</source>
          <year>2007</year>
          <volume>73</volume>
          <issue>1</issue>
          <fpage>36</fpage>
          <lpage>43</lpage>
        </mixed-citation>
      </ref>
      <ref id="CR4">
        <mixed-citation publication-type="other">Brown, K., Barrionuevo, G., Canty, A., De Paola, V., Hirsch, J., Jefferis, G., et al. (2011). The DIADEM data sets: Representative light microscopy images of neuronal morphology to advance automation of digital reconstructions. <italic>Neuroinformatics</italic>. doi:10.1007/s12021-010-9095-5.</mixed-citation>
      </ref>
      <ref id="CR5">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calixto</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Galv&#xE1;n</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Card</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Barrionuevo</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Coincidence detection of convergent perforant path and mossy fibre inputs by CA3 interneurons</article-title>
          <source>The Journal of Physiology</source>
          <year>2008</year>
          <volume>586</volume>
          <issue>11</issue>
          <fpage>2695</fpage>
          <lpage>2712</lpage>
          <pub-id pub-id-type="doi">10.1113/jphysiol.2008.152751</pub-id>
          <pub-id pub-id-type="pmid">18388134</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR6">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Paola</surname>
              <given-names>V</given-names>
            </name>
            <name>
              <surname>Holtmaat</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Knott</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Wilbrecht</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Caroni</surname>
              <given-names>P</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Cell type-specific structural plasticity of axonal branches and boutons in the adult neocortex</article-title>
          <source>Neuron</source>
          <year>2006</year>
          <volume>49</volume>
          <issue>6</issue>
          <fpage>861</fpage>
          <lpage>875</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuron.2006.02.017</pub-id>
          <pub-id pub-id-type="pmid">16543134</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR7">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dima</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Scholz</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Obermayer</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Automatic segmentation and skeletonization of neurons from confocal microscopy images based on the 3-D wavelet transform</article-title>
          <source>IEEE Transactions on Image Processing</source>
          <year>2002</year>
          <volume>11</volume>
          <issue>7</issue>
          <fpage>790</fpage>
          <lpage>801</lpage>
          <pub-id pub-id-type="doi">10.1109/TIP.2002.800888</pub-id>
          <pub-id pub-id-type="pmid">18244675</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR8">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Evers</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Schmitt</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Sibila</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Duch</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>Progress in functional neuroanatomy: Precise automatic geometric reconstruction of neuronal morphology from confocal image stacks</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2005</year>
          <volume>93</volume>
          <issue>4</issue>
          <fpage>2331</fpage>
          <pub-id pub-id-type="doi">10.1152/jn.00761.2004</pub-id>
          <pub-id pub-id-type="pmid">15537815</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR9">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jefferis</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Potter</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Chan</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Marin</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Rohlfing</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Maurer</surname>
              <given-names>C</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Comprehensive maps of Drosophila higher olfactory centers: Spatially segregated fruit and pheromone representation</article-title>
          <source>Cell</source>
          <year>2007</year>
          <volume>128</volume>
          <issue>6</issue>
          <fpage>1187</fpage>
          <lpage>1203</lpage>
          <pub-id pub-id-type="doi">10.1016/j.cell.2007.01.040</pub-id>
          <pub-id pub-id-type="pmid">17382886</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR10">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Meijering</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Neuron tracing in perspective</article-title>
          <source>Cytometry Part A</source>
          <year>2010</year>
          <volume>77</volume>
          <issue>7</issue>
          <fpage>693</fpage>
          <lpage>704</lpage>
          <pub-id pub-id-type="doi">10.1002/cyto.a.20895</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR11">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Meijering</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Jacob</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Sarria</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Steiner</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Hirling</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Unser</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Design and validation of a tool for neurite tracing and analysis in fluorescence microscopy images</article-title>
          <source>Cytometry Part A</source>
          <year>2004</year>
          <volume>58</volume>
          <issue>2</issue>
          <fpage>167</fpage>
          <lpage>176</lpage>
          <pub-id pub-id-type="doi">10.1002/cyto.a.20022</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR12">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Narro</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Kraft</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Wenk</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Efrat</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Restifo</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>NeuronMetrics: Software for semi-automated processing of cultured neuron images</article-title>
          <source>Brain Research</source>
          <year>2007</year>
          <volume>1138</volume>
          <fpage>57</fpage>
          <lpage>75</lpage>
          <pub-id pub-id-type="doi">10.1016/j.brainres.2006.10.094</pub-id>
          <pub-id pub-id-type="pmid">17270152</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR13">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Peng</surname>
              <given-names>H</given-names>
            </name>
          </person-group>
          <article-title>Bioimage informatics: A new area of engineering biology</article-title>
          <source>Bioinformatics</source>
          <year>2008</year>
          <volume>24</volume>
          <issue>17</issue>
          <fpage>1827</fpage>
          <lpage>1836</lpage>
          <pub-id pub-id-type="doi">10.1093/bioinformatics/btn346</pub-id>
          <pub-id pub-id-type="pmid">18603566</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR14">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Peng</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Ruan</surname>
              <given-names>Z</given-names>
            </name>
            <name>
              <surname>Atasoy</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Sternson</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Automatic reconstruction of 3D neuron structures using a graph-augmented deformable model</article-title>
          <source>Bioinformatics</source>
          <year>2010</year>
          <volume>26</volume>
          <issue>12</issue>
          <fpage>38</fpage>
          <lpage>46</lpage>
          <pub-id pub-id-type="doi">10.1093/bioinformatics/btq212</pub-id>
          <pub-id pub-id-type="pmid">19861355</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR15">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Peng</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Ruan</surname>
              <given-names>Z</given-names>
            </name>
            <name>
              <surname>Long</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Simpson</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Myers</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>V3D enables real-time 3D visualization and quantitative analysis of large-scale biological image data sets</article-title>
          <source>Nature Biotechnology</source>
          <year>2010</year>
          <volume>28</volume>
          <issue>4</issue>
          <fpage>348</fpage>
          <lpage>353</lpage>
          <pub-id pub-id-type="doi">10.1038/nbt.1612</pub-id>
          <pub-id pub-id-type="pmid">20231818</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR16">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rodriguez</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Ehlenberger</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Hof</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Wearne</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Rayburst sampling, an algorithm for automated three-dimensional shape analysis from laser scanning microscopy images</article-title>
          <source>Nature Protocols</source>
          <year>2006</year>
          <volume>1</volume>
          <issue>4</issue>
          <fpage>2152</fpage>
          <lpage>2161</lpage>
          <pub-id pub-id-type="doi">10.1038/nprot.2006.313</pub-id>
          <pub-id pub-id-type="pmid">17487207</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR17">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rodriguez</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Ehlenberger</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Hof</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Wearne</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Three-dimensional neuron tracing by voxel scooping</article-title>
          <source>Journal of Neuroscience Methods</source>
          <year>2009</year>
          <volume>184</volume>
          <issue>1</issue>
          <fpage>169</fpage>
          <lpage>175</lpage>
          <pub-id pub-id-type="doi">10.1016/j.jneumeth.2009.07.021</pub-id>
          <pub-id pub-id-type="pmid">19632273</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR18">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sato</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Nakajima</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Shiraga</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Atsumi</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Yoshida</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Koller</surname>
              <given-names>T</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Three-dimensional multi-scale line filter for segmentation and visualization of curvilinear structures in medical images</article-title>
          <source>Medical Image Analysis</source>
          <year>1998</year>
          <volume>2</volume>
          <issue>2</issue>
          <fpage>143</fpage>
          <lpage>168</lpage>
          <pub-id pub-id-type="doi">10.1016/S1361-8415(98)80009-1</pub-id>
          <pub-id pub-id-type="pmid">10646760</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR19">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schmitt</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Evers</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Duch</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Scholz</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Obermayer</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>New methods for the computer-assisted 3-D reconstruction of neurons from confocal image stacks</article-title>
          <source>Neuroimage</source>
          <year>2004</year>
          <volume>23</volume>
          <issue>4</issue>
          <fpage>1283</fpage>
          <lpage>1298</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.06.047</pub-id>
          <pub-id pub-id-type="pmid">15589093</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR20">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sugihara</surname>
              <given-names>I</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Shinoda</surname>
              <given-names>Y</given-names>
            </name>
          </person-group>
          <article-title>Morphology of single olivocerebellar axons labeled with biotinylated dextran amine in the rat</article-title>
          <source>The Journal of Comparative Neurology</source>
          <year>1999</year>
          <volume>414</volume>
          <issue>2</issue>
          <fpage>131</fpage>
          <lpage>148</lpage>
          <pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19991115)414:2&lt;131::AID-CNE1&gt;3.0.CO;2-F</pub-id>
          <pub-id pub-id-type="pmid">10516588</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR21">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vasilkoski</surname>
              <given-names>Z</given-names>
            </name>
            <name>
              <surname>Stepanyants</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Detection of the optimal neuron traces in confocal microscopy images</article-title>
          <source>Journal of Neuroscience Methods</source>
          <year>2009</year>
          <volume>178</volume>
          <issue>1</issue>
          <fpage>197</fpage>
          <lpage>204</lpage>
          <pub-id pub-id-type="doi">10.1016/j.jneumeth.2008.11.008</pub-id>
          <pub-id pub-id-type="pmid">19059434</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR22">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wearne</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Rodriguez</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Ehlenberger</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Rocher</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>New techniques for imaging, digitization and analysis of three-dimensional neural morphology on multiple scales</article-title>
          <source>Neuroscience</source>
          <year>2005</year>
          <volume>136</volume>
          <issue>3</issue>
          <fpage>661</fpage>
          <lpage>680</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroscience.2005.05.053</pub-id>
          <pub-id pub-id-type="pmid">16344143</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR23">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Weaver</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Hof</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Wearne</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Lindquist</surname>
              <given-names>W</given-names>
            </name>
          </person-group>
          <article-title>Automated algorithms for multiscale morphometry of neuronal dendrites</article-title>
          <source>Neural Computation</source>
          <year>2004</year>
          <volume>16</volume>
          <issue>7</issue>
          <fpage>1353</fpage>
          <lpage>1383</lpage>
          <pub-id pub-id-type="doi">10.1162/089976604323057425</pub-id>
          <pub-id pub-id-type="pmid">15165394</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR24">
        <mixed-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Wright</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Nocedal</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <source>Numerical optimization</source>
          <year>2006</year>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>Springer</publisher-name>
        </mixed-citation>
      </ref>
      <ref id="CR25">
        <mixed-citation publication-type="other">Xie, J., Zhao, T., Lee, T., Myers, E., &amp; Peng, H. (2010). Automatic neuron tracing in volumetric microscopy images with anisotropic path searching. In: Medical image computing and computer-assisted intervention&#x2013;MICCAI 2010 (pp. 427&#x2013;429). Springer.</mixed-citation>
      </ref>
      <ref id="CR26">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yuan</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Trachtenberg</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Potter</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Roysam</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>MDL constrained 3-D grayscale skeletonization algorithm for automated extraction of dendrites and spines from fluorescence confocal images</article-title>
          <source>Neuroinformatics</source>
          <year>2009</year>
          <volume>7</volume>
          <issue>4</issue>
          <fpage>213</fpage>
          <lpage>232</lpage>
          <pub-id pub-id-type="doi">10.1007/s12021-009-9057-y</pub-id>
          <pub-id pub-id-type="pmid">20012509</pub-id>
        </mixed-citation>
      </ref>
      <ref id="CR27">
        <mixed-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Degterev</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Lipinski</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Adjeroh</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Yuan</surname>
              <given-names>J</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Automated neurite extraction using dynamic programming for high-throughput screening of neuron-based assays</article-title>
          <source>NeuroImage</source>
          <year>2007</year>
          <volume>35</volume>
          <issue>4</issue>
          <fpage>1502</fpage>
          <lpage>1515</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.01.014</pub-id>
          <pub-id pub-id-type="pmid">17363284</pub-id>
        </mixed-citation>
      </ref>
    </ref-list>
    <fn-group>
      <fn id="Fn1">
        <label>1</label>
        <p>The product for <bold>r</bold><sub><bold>y</bold></sub> can give a singular 0-vector when <italic>r</italic><sub><italic>z</italic></sub> = <italic>k</italic>. In this case, its value is the limit of the expression as the singularity is reached.</p>
      </fn>
      <fn id="Fn2">
        <label>2</label>
        <p>The excluded dataset, Neuromuscular Projectio Fibers, contains neurons that have irregular surfaces and uneven internal stainings. Therefore we used a model-free region growing method to process the dataset instead.</p>
      </fn>
    </fn-group>
  </back>
</article>
