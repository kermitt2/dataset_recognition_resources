<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v3.0 20080202//EN" "archivearticle3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.1.0//EN//XML?>
  <?DTDIdentifier.IdentifierType public?>
  <?SourceDTD.DTDName art510.dtd?>
  <?SourceDTD.Version 5.1.0?>
  <?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
  <?ConverterInfo.Version 2?>
  <?origin publisher?>
  <?FILEmeta_YNIMG7217 xml ?>
  <?FILEmain xml ?>
  <?FILEgr1 jpg ?>
  <?FILEgr2 jpg ?>
  <?FILEgr3 jpg ?>
  <?FILEgr4 jpg ?>
  <?FILEgr5 jpg ?>
  <?FILEgr6 jpg ?>
  <?FILEgr7 jpg ?>
  <?FILEmmc1 doc ?>
  <?FILEmmc2 jpg ?>
  <?FILEmmc2 avi ?>
  <?FILEmmc3 avi ?>
  <?FILEmmc3 jpg ?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3084455</article-id>
      <article-id pub-id-type="pmid">20385243</article-id>
      <article-id pub-id-type="publisher-id">YNIMG7217</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2010.04.011</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Decoding of coherent but not incoherent motion signals in early dorsal visual cortex</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Schwarzkopf</surname>
            <given-names>Dietrich Samuel</given-names>
          </name>
          <email>s.schwarzkopf@fil.ion.ucl.ac.uk</email>
          <xref rid="af0005" ref-type="aff">a</xref>
          <xref rid="af0010" ref-type="aff">b</xref>
          <xref rid="cr0005" ref-type="corresp">&#x204E;</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Sterzer</surname>
            <given-names>Philipp</given-names>
          </name>
          <xref rid="af0015" ref-type="aff">c</xref>
          <xref rid="fn0015" ref-type="fn">3</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Rees</surname>
            <given-names>Geraint</given-names>
          </name>
          <xref rid="af0005" ref-type="aff">a</xref>
          <xref rid="af0010" ref-type="aff">b</xref>
          <xref rid="fn0005" ref-type="fn">1</xref>
          <xref rid="fn0010" ref-type="fn">2</xref>
        </contrib>
      </contrib-group>
      <aff id="af0005"><label>a</label>UCL Institute of Cognitive Neuroscience, 17 Queen Square, London WC1N 3AR, UK</aff>
      <aff id="af0010"><label>b</label>Wellcome Trust Centre for Neuroimaging at UCL, 12 Queen Square, London WC1N 3BG, UK</aff>
      <aff id="af0015"><label>c</label>Department of Psychiatry, Charit&#xE9; Campus Mitte, Charit&#xE9;platz 1, D-10117 Berlin, Germany</aff>
      <author-notes>
        <corresp id="cr0005"><label>&#x204E;</label>Corresponding author. UCL Institute of Cognitive Neuroscience, 17 Queen Square, London WC1N 3AR, UK. Fax: +44 020 7813 2835. <email>s.schwarzkopf@fil.ion.ucl.ac.uk</email></corresp>
        <fn id="fn0005">
          <label>1</label>
          <p>Fax: +&#xA0;44 20 7813 1420.</p>
        </fn>
        <fn id="fn0010">
          <label>2</label>
          <p>Fax: +44 020 7813 2835.</p>
        </fn>
        <fn id="fn0015">
          <label>3</label>
          <p>Fax: +&#xA0;49 30 450 517944.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>15</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>15</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <volume>56</volume>
      <issue>2-10</issue>
      <fpage>688</fpage>
      <lpage>698</lpage>
      <permissions>
        <copyright-statement>&#xC2;&#xA9; 2011 Elsevier Inc.</copyright-statement>
        <copyright-year>2010</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>When several scattered grating elements are arranged in such a way that their directions of motion are consistent with a common path, observers perceive them as belonging to a globally coherent moving object. Here we investigated how this coherence changes the representation of motion signals in human visual cortex using functional magnetic resonance imaging (fMRI) and multivariate voxel pattern decoding, which have the potential to reveal how well a stimulus is encoded in different contexts. Only during globally coherent motion was it possible to reliably distinguish fMRI signals evoked by different directions of motion in early visual cortex. This effect was specific to the retinotopic representation of the visual field quadrant in V1 traversed by the coherent element path and could not simply be attributed to a general increase in signal strength. Decoding was more reliable for cortical areas corresponding to the lower visual field. Because some previous studies observed poorer speed discrimination when motion was grouped, we also conducted behavioural experiments to investigate this with our stimuli, but did not reveal a consistent relationship between coherence and perceived speed. Taken together, these data show that neuronal populations in early visual cortex represent information that could be used for interpreting motion signals as unified objects.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Coherent object motion</kwd>
        <kwd>Functional brain imaging</kwd>
        <kwd>Multivariate pattern decoding</kwd>
        <kwd>Direction</kwd>
        <kwd>Perceptual grouping</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="s0005">
      <title>Introduction</title>
      <p>The detection and identification of partially occluded objects, such as spotting a predator or prey moving through foliage, is essential for survival. Our visual system has an almost effortless ability to extrapolate objects even when only limited information is available by grouping elements from different portions of the visual field. Despite its ubiquity, the processes by which the brain groups such simple but separated features to form percepts of coherent objects remains poorly understood.</p>
      <p>Many psychophysical studies have explored how grouping affects perception. Detection thresholds are enhanced for targets presented in a coherent context (<xref rid="bb0140 bb0175 bb0180" ref-type="bibr">Kovacs and Julesz, 1994; Polat and Bonneh, 2000; Polat and Sagi, 1993</xref>). Observers are also more adept at finding smooth contours and shapes embedded in noisy environments than simple feedforward models of visual processing would predict (<xref rid="bb0065 bb0110" ref-type="bibr">Field et al., 1993; Hess et al., 1997</xref>). Not all effects are facilitatory. Vernier acuity is reduced when a collinear stimulus is placed in between the two Vernier targets (<xref rid="bb0255" ref-type="bibr">Zhu and Liu, 2009</xref>). Moreover, observers are poorer at judging the speed of several moving stimuli that are perceived as being grouped relative to when they are perceived as being independent (<xref rid="bb0235 bb0240" ref-type="bibr">Verghese and McKee, 2006; Verghese and Stone, 1996</xref>). Thus grouping can both facilitate and interfere with the processing of grouped features.</p>
      <p>How is information about a coherent object encoded in the visual cortex? Neurophysiological studies on perceptual integration have resulted in conflicting results. Single-unit microelectrode recordings in animals suggest a role for early visual cortex in grouping segregated image features into a coherent global percept. For example, the firing of V1 neurons in response to oriented bars is modulated by the presence of flanking bars outside the classical receptive field (<xref rid="bb0090 bb0130" ref-type="bibr">Gilbert, 1992; Kapadia et al., 2000</xref>) or when their receptive fields fall inside a segregated surface compared to a homogeneous field (<xref rid="bb0260" ref-type="bibr">Zipser et al., 1996</xref>). Neuroimaging studies in humans are inconsistent, showing both weaker (<xref rid="bb0060 bb0100 bb0160" ref-type="bibr">Fang et al., 2008; Harrison et al., 2007; Murray et al., 2002</xref>), and stronger responses for grouped or spatially coherent stimuli (<xref rid="bb0005 bb0195 bb0255" ref-type="bibr">Altmann et al., 2003; Schwarzkopf et al., 2009; Zhu and Liu, 2009</xref>). One possible explanation for this discrepancy is that V1 activity is driven by low level image statistics (<xref rid="bb0045" ref-type="bibr">Dumoulin and Hess, 2006</xref>). Reduced activity may also reflect a reduction in inhibitory neuronal activity, which obscures the selective facilitatory effects measured with single-unit recordings (<xref rid="bb0135" ref-type="bibr">Kinoshita et al., 2009</xref>).</p>
      <p>Previous research focused only on the level of activity rather than exploring qualitatively how grouping alters the encoding of a stimulus. We therefore set out to investigate this issue using high-resolution functional magnetic resonance imaging (fMRI) and multivariate voxel pattern decoding. Rather than merely establishing that a stimulus dimension is encoded within a brain region, the strength of multivariate voxel pattern decoding lies in its potential for examining how well a stimulus presented in different contexts is encoded in distributed responses across visual cortex (<xref rid="bb0105 bb0120" ref-type="bibr">Haynes and Rees, 2005; Kamitani and Tong, 2005</xref>). For instance, it has been employed to study differences in conscious and unconscious stimulus representations (<xref rid="bb0105 bb0225" ref-type="bibr">Haynes and Rees, 2005; Sterzer et al., 2008</xref>), or to infer the focus of feature-based attention (<xref rid="bb0120 bb0125" ref-type="bibr">Kamitani and Tong, 2005, 2006</xref>). Here we explored how coherent motion altered the encoding of direction of motion in retinotopic visual cortex. We examined the phenomenon that occurs when only local parts of an object are visible, such as when an object moves behind occluding surfaces. This can be mimicked when several small drifting grating elements are arranged in such a way that the individual directions of motion are together consistent with a smooth path (<xref rid="f0005" ref-type="fig">Figs.&#xA0;1</xref>A&#x2013;B; and see the accompanying movies in the <xref rid="s0145" ref-type="sec">supplementary materials</xref>). Under these conditions, observers perceive all elements as part of a larger entity, while this is not the case for grating elements that are also positioned along a path but whose directions of motion are inconsistent with the path (<xref rid="f0005" ref-type="fig">Figs.&#xA0;1</xref>C&#x2013;D). This paradigm allowed us to examine how the representation of the motion of individual stimulus elements in early visual cortex varied depending on whether their motion was part of a larger coherent context. Since we presented elements in different visual quadrants, one element was separated from its context not only in visual space but in terms of its representation in distinct parts of retinotopic cortex compared to the context. Only the relationship between this element and the context (coherent versus incoherent) varied while the individual motion of the stimulus element itself remained constant. Thus any changes in spatial patterns of blood oxygen level dependent (BOLD) signals evoked by this element in visual cortex must reflect the effect of such global coherence rather than changes in the individual stimulus elements.</p>
      <p>To anticipate our findings, we showed that only when elements are spatially coherent was it possible to decode the direction of a moving grating element from voxel response patterns in early visual cortex. Decoding was only reliable in regions corresponding to the lower visual field compared to the upper visual field. Because previous behavioural studies reported that motion grouping impaired speed discrimination (<xref rid="bb0235 bb0240" ref-type="bibr">Verghese and McKee, 2006; Verghese and Stone, 1996</xref>), we also performed behavioural experiments outside the scanner to test whether our observed changes in the neural representation of motion are involved in this process. We did not reveal a consistent relationship between coherent motion and perceived speed.</p>
    </sec>
    <sec sec-type="materials|methods" id="s0010">
      <title>Materials and methods</title>
      <sec id="s0015">
        <title>Functional imaging experiment</title>
        <sec id="s0020">
          <title>Participants</title>
          <p>Nine healthy participants (4 females, 2 left-handed, age: 20&#x2013;33) gave written informed consent to participate in the experiment, which was approved by the local ethics committee. Participants were na&#xEF;ve to the purpose of the experiment, except for one of the authors (DSS), and had normal or corrected-to-normal vision.</p>
        </sec>
        <sec id="s0025">
          <title>Stimuli</title>
          <p>During fMRI scanning, participants viewed movies comprising several drifting Gabor elements, i.e. sinusoidal carrier gratings (spatial frequency: 2.7&#xA0;cycles/&#xB0;) convolved with Gaussian apertures (standard deviation: 0.55&#xB0;), in which drift was induced by advancing the phase of the carrier by 30&#xB0; on each video frame (i.e. they drifted at 5&#xA0;cycles/s). Each stimulus movie always comprised six Gabor elements, five of which were positioned on a curved imaginary path (160&#xB0; sector of a circular path) that arched through three quadrants of the visual field (eccentricities: 4.1&#xB0;&#x2013;8.4&#xB0;). The elements on this path were separated by 5.5&#xB0; of visual angle. There were two types of stimuli that differed in their global context, coherent and incoherent. In the coherent context the orientation of the Gabors was orthogonal to the path and thus their motion trajectories were tangential to it. We generated the incoherent context by swapping the orientations of the elements flanking the curve element (that is, e.g. the outer element in the upper visual field was swapped with the outer element in the lower visual field). This ensured that the difference in orientation/direction between neighbouring elements was similar to the coherent stimuli, but that the motion was no longer consistent with the curved path. Crucially, the middle element of the context (curve element) was identical for both the coherent and incoherent contexts. Moreover, the middle element was located in a different visual field quadrant than the nearest context element (<xref rid="f0005" ref-type="fig">Fig.&#xA0;1</xref>). As individual quadrants can be reliably separated in early retinotopic cortex, activity related to the middle element could thus be dissociated from activity evoked by the context elements. The sixth Gabor element (distractor element) was positioned in the visual field quadrant diagonally opposite the curve element at 4.1&#xB0; from the centre of gaze. The distractor element always had the same orientation as the curve element, but to prevent the distractor from being grouped with the global context, the direction of motion of the distractor was always opposite to that of the curve element.</p>
          <p>The global context (that is the curved path) always spanned three visual field quadrants between the lower-left and upper-right quadrants. However, it could curve either through the lower-right (<xref rid="f0005" ref-type="fig">Figs.&#xA0;1</xref>A, C) or the upper-left quadrant (<xref rid="f0005" ref-type="fig">Figs.&#xA0;1</xref>B, D). Within any one fMRI session the location of the path was constant. A small black fixation cross was present at all times. Stimuli were back-projected onto a screen participants viewed via a front-surface mirror attached to the headcoil. The stimuli are illustrated in <xref rid="f0005" ref-type="fig">Fig.&#xA0;1</xref> and examples of the movies can be viewed in the <xref rid="s0145" ref-type="sec">supplementary information</xref>. Stimuli were generated in MATLAB (Mathworks) and presented using the Cogent toolbox (<ext-link ext-link-type="uri" xlink:href="http://www.vislab.ucl.ac.uk/cogent.php">http://www.vislab.ucl.ac.uk/cogent.php</ext-link>).</p>
        </sec>
        <sec id="s0030">
          <title>Procedure</title>
          <p>In each scanning run, participants viewed continuous movies of the four stimulus conditions, coherent and incoherent, with anti-clockwise or clockwise motion, respectively. Each condition was presented twice, in a pseudo-randomized order (with the constraint that the same condition could never be presented twice in a row). Movies lasted 19.2&#xA0;s and were interleaved with 19.2&#xA0;s blank periods during which only the fixation cross was being presented. In order to ensure fixation and maintain arousal, the participants were required to monitor the fixation cross for a small increase in luminance to which they responded by pressing a button on a MRI-compatible keypad. These events were 200&#xA0;ms in duration and occurred with a probability of 0.05 every 400&#xA0;ms throughout the run. Altogether, there were 8 scanning runs of the main experiment per session.</p>
          <p>In addition to the main experiment, during one of the scanning sessions participants also participated in a number of different &#x2018;localiser&#x2019; scans. First, an &#x2018;element localiser&#x2019; was used to define retinotopic representations of the individual grating elements in early visual cortex. Participants viewed contrast-reversing (4&#xA0;Hz) checkerboard elements of the same physical dimensions as the Gabor elements in the main experiment, alternating between the positions of the distractor and curve elements of the main experiment. The flickering elements were presented in 8 blocks of 25.6&#xA0;s interleaved by 9.6&#xA0;s fixation periods. In a second &#x2018;motion localiser&#x2019; scan, participants viewed random dot stimuli consisting of 2000 dots (equal number of black and white dots) presented around fixation within a circular aperture (radius: 11.5&#xB0;). Stimulus conditions were similar to the ones described in <xref rid="bb0055" ref-type="bibr">Dupont et al. (1997)</xref>: (1) static dots, (2) transparent motion in which half the dots moved in opposite directions and (3) kinetic contours in which bands (width: 2.3&#xB0;) moved in opposite directions. For stimuli containing motion the direction of motion changed every 800&#xA0;ms (directions from 0 to 345&#xB0; with 15&#xB0; increments). For the static stimuli, a new random dot stimulus was presented every 800&#xA0;ms. Finally, we also collected fMRI data for retinotopic mapping showing 10&#xA0;cycles (duration: 38.4&#xA0;s) of a smoothly rotating contrast-reversing (4&#xA0;Hz) checkerboard wedge.</p>
        </sec>
        <sec id="s0035">
          <title>Data acquisition</title>
          <p>Functional data were acquired on a 3&#xA0;T Allegra head scanner (Siemens Medical Systems, Erlangen, Germany), using a standard transmit&#x2013;receive head coil with a single-shot gradient echo isotropic high-resolution EPI sequence (matrix size: 128&#xA0;&#xD7;&#xA0;128; FOV: 192&#xA0;&#xD7;&#xA0;192&#xA0;mm<sup>2</sup>; in-plane resolution: 1.5&#xA0;&#xD7;&#xA0;1.5&#xA0;mm<sup>2</sup>; 32 oblique transverse slices with interleaved acquisition; slice thickness: 1.5&#xA0;mm, no gap; TE: 30&#xA0;ms; acquisition time per slice: 100&#xA0;ms; TR: 3200&#xA0;ms; echo spacing: 560&#xA0;&#xB5;s; receiver bandwidth: 250&#xA0;kHz; 30% ramp sampling; 2-fold read oversampling to allow for <italic>k</italic>-space re-gridding; read gradient amplitude: 34.47&#xA0;mT/m; read gradient slew rate: 344.7&#xA0;mT/m/ms; flip angle <italic>&#x3B1;</italic>&#xA0;=&#xA0;90&#xB0;). Slices were angled at 30&#xB0; to maximize coverage of the calcarine sulcus and the occipital lobes. For two participants we measured eye movements and pupil diameter (continuously sampled at 60&#xA0;Hz) during scanning using a video eye tracker (ASL 504LRO Eye Tracking System, Mass).</p>
          <p>In each scanning run in the main experiment and the motion localiser we acquired 108 volumes, in the &#x2018;element localiser&#x2019; 97 volumes and in the retinotopic mapping run 130 volumes. The first six volumes were removed from any subsequent analysis to allow for T1 equilibration. To correct for EPI distortions induced by susceptibility artifacts, we acquired double echo FLASH images to estimate maps of the <italic>B</italic><sub>0</sub> field. Finally, we acquired T1-weighted anatomical images using a MDEFT sequence.</p>
        </sec>
        <sec id="s0040">
          <title>Initial data analysis</title>
          <p>Neuroimaging data were preprocessed and analysed using SPM5 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>). Functional images were corrected for slice acquisition time, realigned to the first image using an affine transformation to correct for small head movements and EPI distortions unwarped using <italic>B</italic><sub>0</sub> field maps (<xref rid="bb0115" ref-type="bibr">Hutton et al., 2002</xref>). Data were smoothed with a Gaussian kernel with 5&#xA0;mm FWHM. The resulting images were entered into a participant-specific general linear model with conditions of interest corresponding to each category of visual stimuli. Blocks were convolved with a canonical haemodynamic response function to generate regressors. In addition, the estimated head movement parameters were entered as regressors of no interest. Linear contrasts among the condition-specific regressors were used to identify regions of interest in the localiser scans.</p>
        </sec>
        <sec id="s0045">
          <title>Delineation of visual areas</title>
          <p>From the anatomical images we reconstructed and inflated the surface of each cortical hemisphere using FreeSurfer (<ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/fswiki">http://surfer.nmr.mgh.harvard.edu/fswiki</ext-link>) (<xref rid="bb0035" ref-type="bibr">Dale et al., 1999</xref>). Polar maps of the visual cortex were calculated using phase-encoded retinotopic mapping techniques (<xref rid="bb0200" ref-type="bibr">Sereno et al., 1995</xref>) and retinotopic visual areas were delineated manually. The boundaries of V1&#x2013;V3 were delineated by identifying the representation of the vertical and horizontal meridians from the mirror reversals in the phase map, separating the ventral and dorsal subregions of these areas. V4 and V3A were defined as maps of a full visual hemifield, anterior to V3v and V3d, respectively. We also mapped regions of interest (ROI) for the activations in the element localiser in left dorsal V1 (lower-right element) and right ventral V1 (upper-left element). We identified the motion-selective V5/MT complex by the linear contrast between transparent motion stimuli and the static random dot stimuli. Further, we mapped a region of interest anterior to area V3A in the lateral occipital cortex that was activated preferentially by kinetic boundaries relative to the transparent motion. We refer to this region as KO (&#x2018;kinetic occipital&#x2019;) (<xref rid="bb0055" ref-type="bibr">Dupont et al., 1997</xref>), although this encompasses several retinotopic areas and parts of the lateral occipital complex (<xref rid="bb0150" ref-type="bibr">Larsson and Heeger, 2006</xref>).</p>
        </sec>
        <sec id="s0050">
          <title>Multivariate voxel pattern decoding</title>
          <p>Preprocessed functional data in volume space were further analysed using custom software written in MATLAB. The time course from each run was <italic>z</italic>-score normalized. The voxels belonging to each ROI were identified by projecting the labelled surface vertices back into voxel space. For each ROI the data of voxels in each volume (shifted by 1 volume&#xA0;=&#xA0;3.2&#xA0;s to account for the lag of the haemodynamic response) were extracted and vectorized. Volumes from the same stimulus block were averaged so that there was only one voxel pattern (henceforth &#x2018;samples&#x2019;) for each block.</p>
          <p>These data were then used for multivariate voxel pattern decoding using a leave-one-run-out cross-validation procedure, i.e. samples from all except one run were assigned to a training set and the remaining samples were used as a test set. For each condition we calculated the mean sample across all blocks in the training set. To decode we then calculated a linear correlation between each sample in the test set and the mean samples from the training set. A test sample was then assigned to the condition which produced the greater correlation coefficient. Decoding performance for each cross-validation was estimated as the percentage of correct classifications, and the final decoding accuracy was calculated by averaging performances from all eight cross-validations.</p>
          <p>Since we used high-resolution fMRI, each ROI contained hundreds to thousands of voxels. We employed spatial smoothing with a narrow Gaussian kernel of 5&#xA0;mm FWHM. The spatial pattern information exploited by many multivariate pattern decoding analyses is represented on a relatively coarse spatial scale (<xref rid="bb0080 bb0085 bb0145 bb0210 bb0230" ref-type="bibr">Gardner, 2010; Gardner et al., 2008; Kriegeskorte et al., 2010; Shmuel et al., 2010; Swisher et al., 2010</xref>) and spatial smoothing in this way does not diminish and can even improve decoding performance (<xref rid="bb0170" ref-type="bibr">Op de Beeck, 2010</xref>). We calculated the <italic>t</italic>-statistic for comparing the two conditions of interest only on the training data set, and then selected the most discriminative voxels by ranking voxels in both training and test sets in descending order (ignoring the sign of the <italic>t</italic>-statistic). Because the univariate voxel-wise difference was calculated only on the training data this ensured that the test data were unbiased. While this &#x201C;nearest neighbour by correlation&#x201D; method is arguably simpler than other more sophisticated machine learning algorithms and since the use of a linear SVM did not afford an increase in decoding accuracy we therefore chose a simple method for our analysis.</p>
          <p>When decoding the type of context we grouped the samples from the clockwise and anti-clockwise motion from a particular context into a data set for one condition. This means that for this analysis there were twice the number of samples as for decoding the direction of motion, which was conducted separately for the coherent and incoherent contexts.</p>
          <p>For most comparisons, the decoding accuracy obtained with the first 150 voxels was used for further statistical analysis, except for the decoding from the small element ROIs for which a cut-off of 28 voxels was used instead. These cut-offs were chosen by taking the minimal size of the ROIs across all participants.</p>
        </sec>
      </sec>
      <sec id="s0055">
        <title>Behavioural experiment</title>
        <sec id="s0060">
          <title>Participants</title>
          <p>Four participants, all of whom had participated in the functional imaging experiment, were recruited for a subsequent behavioural experiment (2 females, all right-handed, age: 27&#x2013;30). Except for one of the authors (DSS) all participants were na&#xEF;ve to the purpose of this experiment. Participants had normal or corrected-to-normal vision and gave written informed consent for the experiment, which had been approved by the local ethics committee.</p>
        </sec>
        <sec id="s0065">
          <title>Stimuli</title>
          <p>The stimuli used were the same as in the functional imaging experiment, except that we removed the distractor element so that only the elements on the path were visible. Moreover, in an additional condition only the curve element was presented without its neighbours.</p>
        </sec>
        <sec id="s0070">
          <title>Procedure</title>
          <p>Participants took part in three sessions containing 630 trials each. We monitored eye movements using a high temporal-resolution (250&#xA0;Hz) eye tracker (Cambridge Research Systems). Each trial was initiated when participants fixated on a small black fixation cross for a period of 600&#xA0;ms. Subsequently, they viewed two 500&#xA0;ms intervals with stimulus movies separated by a 500&#xA0;ms blank period during which only the fixation cross was presented. If eye movements strayed from a circular window with 1.25&#xB0; diameter around fixation, a red-circle appeared on the screen as feedback to the participant and the trial was discarded from any further analysis.</p>
          <p>The participants' task was to decide which of the two stimulus movies was moving faster. One interval always contained only the curve element moving at the reference speed, which was varied on every trial (2.5&#x2013;4.2&#xA0;cycles/&#xB0;). In the other interval, the test stimulus, Gabors moved at one of seven speeds relative to the reference speed (including a condition in which they were equal). The stimulus could either be only the curve element, the coherent context or the incoherent context. The direction of motion (anti-clockwise and clockwise) was chosen at random on every trial but was the same in both intervals. The order of the intervals was randomized. In half the trials the curve element was positioned in the lower-right or the upper-left visual field quadrant. All experimental conditions (i.e. stimulus configuration, visual field location and relative speed) were presented in a randomly interleaved order.</p>
        </sec>
        <sec id="s0075">
          <title>Data analysis</title>
          <p>Psychophysical performance at the speed discrimination task was measured as the proportion of trials in which participants judged the test interval to be moving faster at each relative speed level. The raw data were then fitted with a logistic function using the psignifit toolbox (<ext-link ext-link-type="uri" xlink:href="http://bootstrap-software.org/psignifit">http://bootstrap-software.org/psignifit</ext-link>) implementing a maximum-likelihood procedure (<xref rid="bb0245 bb0250" ref-type="bibr">Wichmann and Hill, 2001a,b</xref>). From the fitted psychometric functions we extrapolated the point of subjective equality (PSE), i.e. the relative speed at which participants believed the speed of the test stimulus to be equal to the reference.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s0080">
      <title>Results</title>
      <sec id="s0085">
        <title>Decoding the global context: coherent versus incoherent</title>
        <p>To investigate how object motion that was coherent across the individual elements (other than the distractor) altered the representation of motion in early visual cortex we measured fMRI blood oxygen level dependent (BOLD) signals while participants viewed movies comprising drifting Gabors (<xref rid="f0005" ref-type="fig">Fig.&#xA0;1</xref>). The individual Gabor elements were either arranged so that their local motion was consistent with a global context of a smooth curve (coherent) or had their directions of motion scrambled (incoherent). First, we tested if it is possible to decode from voxel response patterns in early visual areas whether the global context was coherent or incoherent.</p>
        <p>We used linear correlation for decoding by first calculating the average pattern for each condition from the samples in the training set, and then correlating these average patterns with each sample in the test set. Each test sample was assigned to the condition which produced the stronger correlation. Before decoding, data were spatially smoothed with a 5&#xA0;mm FWHM Gaussian kernel in order to enhance the true pattern of voxel biases while reducing high frequency measurement noise. Qualitatively similar, albeit lower, decoding performance was obtained when unsmoothed data were used.</p>
        <p><xref rid="f0010" ref-type="fig">Fig.&#xA0;2</xref> plots the accuracy averaged across participants when decoding the global context (coherent versus incoherent) for visual areas. For V1&#x2013;V4 and V3A this included all voxels from each area as delineated by the retinotopic mapping scan. For the higher extrastriate areas, i.e. KO and the V5/MT complex, the ROIs included all voxels which in the &#x2018;motion localiser&#x2019; scan responded significantly (<italic>p</italic>&#xA0;&lt;&#xA0;0.05, uncorrected) more to kinetic contours than transparent motion (KO) or more to transparent motion than to static stimuli (V5/MT). This showed that when the curve traversed the lower-right visual field (<xref rid="f0010" ref-type="fig">Fig.&#xA0;2</xref>A), accuracy for V2, V3, and V4 was greater than chance. These findings are consistent with the explanation that neuronal populations in higher extrastriate areas respond to the presence of a coherently moving object.</p>
      </sec>
      <sec id="s0090">
        <title>No decoding of direction of motion for individual elements</title>
        <p>The main purpose of our experiment was to examine how the presence of globally coherent motion changed the neural representation of motion associated with the retinotopic location of an individual Gabor element. In separate blocks the Gabors moved in opposite directions (anti-clockwise or clockwise with respect to the curved context). We reasoned that if perceptual grouping altered the representation of motion signals in early visual cortex, it should also affect the accuracy with which we could decode the direction of motion from spatially distributed voxel patterns in early visual cortex. Our stimulus design ensured that the physical stimulation in the lower-right and upper-left visual field quadrants was identical for the coherent and incoherent contexts. Therefore, on the basis of an independent &#x2018;element localiser&#x2019; scan we defined retinotopic regions of interest in V1 corresponding to the Gabor elements in the lower-right and upper-left quadrants, and conducted our decoding analysis on voxels from these ROIs. It was impossible to decode direction of motion better than chance from voxels in the curve element regardless of retinotopic position (lower-right: <italic>t</italic>(8)&#xA0;=&#xA0;0.33, <italic>p</italic>&#xA0;=&#xA0;0.373; upper-left: <italic>t</italic>(8)&#xA0;=&#xA0;&#x2212;&#xA0;0.70, <italic>p</italic>&#xA0;=&#xA0;0.748). Because it could be argued that spatial smoothing blurred the high spatial frequency patterns in these small ROIs, we conducted this analysis on unsmoothed data. However, for unsmoothed data performance was also consistently at chance (lower-right: <italic>t</italic>(8)&#xA0;=&#xA0;&#x2212;&#xA0;0.76, <italic>p</italic>&#xA0;=&#xA0;0.765; upper-left: <italic>t</italic>(8)&#xA0;=&#xA0;&#x2212;&#xA0;0.66, <italic>p</italic>&#xA0;=&#xA0;0.737). Thus, when restricting the analysis to the individual stimulus elements, it was not possible to reliably discriminate response patterns to the two directions of motion, in either global contexts.</p>
      </sec>
      <sec id="s0095">
        <title>Decoding direction of motion from visual field quadrants</title>
        <p>Next, we tested if there were contextual effects when also including parts of retinotopic visual cortex that did not represent parts of the visual field where our stimuli were presented. We performed the same decoding analysis for direction of motion on ROIs containing the entire quarter-field representations in early visual cortex, which received identical physical stimulation in the coherent and incoherent contexts. Thus we compared the decoding for ROIs representing the lower-right and upper-left visual fields. Henceforth, we will refer to the ROIs representing the visual field quadrants containing the curve and distractor elements as the &#x2018;curve quadrant&#x2019; and &#x2018;distractor quadrant,&#x2019; respectively (see <xref rid="f0005" ref-type="fig">Fig.&#xA0;1</xref>).</p>
        <p><xref rid="f0015" ref-type="fig">Fig.&#xA0;3</xref> depicts the decoding accuracy for each condition in areas V1&#x2013;V3. We tested if decoding direction of motion was reliable, that is whether it was significantly greater than chance levels. In the curve quadrant in V1 decoding was better than chance for the coherent context (<italic>t</italic>(8)&#xA0;=&#xA0;2.42, <italic>p</italic>&#xA0;=&#xA0;0.020) but not for the incoherent context (<italic>t</italic>(8)&#xA0;=&#xA0;&#x2212;&#xA0;0.66, <italic>p</italic>&#xA0;=&#xA0;0.737). Again, this difference was only significant when the curve quadrant was the lower-right quadrant; when it was the upper-left quadrant this difference was not significant (coherent: <italic>t</italic>(8)&#xA0;=&#xA0;&#x2212;&#xA0;0.40, <italic>p</italic>&#xA0;=&#xA0;0.651; incoherent: <italic>t</italic>(8)&#xA0;=&#xA0;&#x2212;&#xA0;0.27, <italic>p</italic>&#xA0;=&#xA0;0.601). At the level of individual participants we found that decoding of direction for the coherent context when the curve quadrant was the lower-right was significantly greater than chance in five out of the nine participants, while it was numerically greater than chance in another two. Conversely, when the curve quadrant was the upper-left only one participant showed above chance performance. Finally, decoding for the distractor quadrant was never significantly greater than chance. Taken together, our decoding results indicate that during grouping unstimulated parts of early retinotopic cortex contain information about the direction of motion of the grouped stimulus elements.</p>
      </sec>
      <sec id="s0100">
        <title>The nature of the neural representation</title>
        <p>The curve quadrant contained only the curve element, which remained constant between the coherent and incoherent contexts. The visual field quadrants are represented by spatially distinct regions of retinotopic cortex. Moreover, the population receptive field size of voxels in these regions and at the eccentricity of our stimulus is well below the separation of our Gabor elements (<xref rid="bb0050 bb0215" ref-type="bibr">Dumoulin and Wandell, 2008; Smith et al., 2001</xref>). Although it is thus highly likely that the curve quadrant received physical stimulation from the visual quadrants containing the remaining elements on the curve, it cannot be ruled out completely that voxels in the curve quadrant might receive some input from the neighbouring quadrant representations. Moreover, it could be argued that voxels outside the ROI defined by the element localizer still showed a weak response to the experimental stimulus containing the full context.</p>
        <p>In <xref rid="s0145" ref-type="sec">Fig. S1</xref> we show maps of a representative participant on a reconstructed, inflated and flattened pial surface of the left occipital cortex. In these maps, V1d and V2d represent the curve quadrant, while V1v and V2v contain a map of the upper-right visual field, in which two of the inducer elements were presented. It is evident that even at a very relaxed statistical threshold (<italic>p</italic>&#xA0;&lt;&#xA0;0.05, uncorrected) the response to the stimulus in V1d does not dramatically exceed the ROI defined by means of the element localizer (yellow dotted line). More importantly, the activation evoked by the inducer elements in the context in V1v is distant from the response to the curve patch. Importantly, these maps are constructed from spatially smoothed data, and smoothing could conceivably have increased correlations between signals in voxels that encoded nearby locations in retinotopic space. However, since the smoothing kernel was small (5&#xA0;mm FWHM), we observed that consistently good separation was achieved between the regions responding to the curve element and the inducers, respectively.</p>
        <p>Improved decoding of the direction of coherent versus incoherent motion could be explained by a change of the signal-to-noise ratio of the pattern of voxel biases. We therefore calculated the absolute <italic>t</italic>-value for comparing clockwise and anti-clockwise motion across all runs in the data set, separately for the coherent and incoherent contexts. We reasoned that an increased signal-to-noise ratio would be reflected in a greater proportion of significantly biased (<italic>p</italic>&#xA0;&lt;&#xA0;0.05 on a <italic>t</italic>-test comparing response to clockwise and anti-clockwise motion) voxels for the coherent context. This revealed a trend towards significance in the effect of coherence (<italic>F</italic>(1,8)&#xA0;=&#xA0;3.84, <italic>p</italic>&#xA0;=&#xA0;0.086), providing some tentative evidence that indeed the voxels may have been more biased during coherent than incoherent motion. In the flat maps in <xref rid="s0145" ref-type="sec">Fig. S1</xref> we plotted the absolute <italic>t</italic>-values for comparing clockwise and anti-clockwise motion for the coherent and incoherent context of V1d (representing the curve quadrant) in one participant. This map illustrates that when motion was coherent, more voxels exhibited a bias for the direction of motion, which resulted in above chance decoding for the coherent context only.</p>
      </sec>
      <sec id="s0105">
        <title>Control analyses</title>
        <p>The interpretation of our results requires that participants maintained accurate fixation throughout this experiment. While viewing the drifting Gabor stimuli they were asked to fixate on a small cross and press a response button whenever the cross changed luminance. Moreover, for two participants we tracked eye movements during the scan. Both measures indicate that participants maintained good fixation and were attentive (hit rate: 71.8%; see <xref rid="s0145" ref-type="sec">Supplementary information</xref> for full details of analyses).</p>
        <p>We also tested whether our MVPA results could be attributed to the size of overall signal evoked by the coherent and incoherent contexts. We conducted standard univariate analyses using a general linear model to estimate the overall activity evoked by each experimental condition within the quarter-field representations of retinotopic areas V1&#x2013;V3 (<xref rid="f0020" ref-type="fig">Fig.&#xA0;4</xref>). Because our multivariate voxel pattern decoding was only significantly better than chance for decoding direction of motion when the curve quadrant was the lower-right visual field we focused the conventional analysis also on this retinotopic location. A 3-way repeated measures ANOVA with the factors condition (global context: coherent and incoherent), quadrant (curve and distractor) and ROI (V1, V2 and V3) showed that there was a significant effect of ROI (<italic>F</italic>(2,16)&#xA0;=&#xA0;13.24, <italic>p</italic>&#xA0;&lt;&#xA0;0.001), and a significant interaction between ROI and quadrant (<italic>F</italic>(2,16)&#xA0;=&#xA0;5.83, <italic>p</italic>&#xA0;=&#xA0;0.013). The response to the incoherent context was somewhat stronger than that to the coherent context, but the effect of context only showed a trend towards statistical significance (<italic>F</italic>(1,8)&#xA0;=&#xA0;3.76, <italic>p</italic>&#xA0;=&#xA0;0.088). We also compared the responses in retinotopic regions of interest within V1 that corresponded to the curve and distractor element, respectively, defined by means of the independent &#x2018;element localiser&#x2019; scan. The difference between the coherent and incoherent contexts showed a trend towards significance (<italic>F</italic>(1,8)&#xA0;&lt;&#xA0;1, <italic>p</italic>&#xA0;=&#xA0;0.071). There was no significant difference in the activity between the two elements (<italic>F</italic>(1,8)&#xA0;&lt;&#xA0;1, <italic>p</italic>&#xA0;=&#xA0;0.807), and no interaction between condition and quadrant (<italic>F</italic>(1,8)&#xA0;&lt;&#xA0;1, <italic>p</italic>&#xA0;=&#xA0;0.711). Taken together, there was no increase in overall signal for the globally coherent context in the curve quadrant which would result in enhanced voxel biases. If anything, the response to the incoherent context was subtly greater than that to the coherent context. Therefore, our MVPA results were not trivially accounted for by a difference in signal strength between global context conditions.</p>
      </sec>
      <sec id="s0110">
        <title>Behavioural measurement of perceived speed</title>
        <p>Finally, we also conducted a psychophysical experiment outside the scanner to investigate whether the enhanced decoding we observed for globally coherent context in early visual cortex might have any consequences for behaviour (other than the obvious perceptual difference in coherent versus incoherent motion). Previous reports indicate that perceptual grouping of moving stimuli can interfere with speed judgements (<xref rid="bb0240" ref-type="bibr">Verghese and Stone, 1996</xref>). Using a two-interval forced choice design we now tested whether the changes in representation of motion signals in early visual cortex that we had observed with our stimuli was associated with a similar change in perceived speed. During a probe interval either a single Gabor element (control) was presented or coherent or incoherent stimuli similar to those in the fMRI experiment were shown (except that the distractor element had been removed). Participants were asked to judge the speed against that of a single drifting Gabor element presented during a reference interval.</p>
        <p><xref rid="f0025" ref-type="fig">Fig.&#xA0;5</xref> shows the points of subjective equality for the four participants, i.e. the ratio (in logarithmic units) between test and reference speed at which participants judged the speed in both intervals to be equal. While participants showed a difference in their speed judgements between stimuli with several Gabor elements and the control condition with the single element, there was no consistent pattern of the bias across participants. While two participants (MS and DSS) perceived the speed of several elements to be slower than that of a single element, the other two participants (CP and JS) showed the opposite effect. Importantly, only participants MS and DSS perceived the coherent context to be slower than the incoherent context (the psychometric curves for each participant are plotted in <xref rid="s0145" ref-type="sec">Fig. S2</xref>).</p>
      </sec>
    </sec>
    <sec id="s0115">
      <title>Discussion</title>
      <p>Here we used functional MRI and multivariate voxel pattern decoding to investigate how motion signals in visual cortex were altered when the motion of individual elements scattered across the visual field was consistent with a coherent object. Participants viewed stimuli comprising drifting Gabor elements that were either aligned along a curved path or misaligned so that the local relationship between elements was preserved but globally motion was perceived as incoherent. We show that only for the coherent context presented to the lower hemifield was it possible to successfully decode the direction of motion of individual Gabor elements. We were unable to successfully decode direction for either context from voxels representing the upper hemifield. A relative lack of statistical power at the group level could conceivably account for our failure to find any significant decoding for the incoherent context or from any stimulus condition in the upper visual field. However, the same pattern of results was seen at the level of individual participants, with most showing significant decoding only for the coherent context when the curve quadrant was in the lower visual field.</p>
      <p>Crucially, unlike previous neuroimaging studies on coherent motion, our use of multivariate pattern decoding went beyond a comparison of the level of responses evoked by coherent compared to incoherent motion. Rather, it allowed us to make a qualitative comparison of the neural representation of a stimulus feature (direction of motion). Our study thus contributes to our understanding of the neural processes through which retinotopically separated motion signals are interpreted as objects: when retinotopically separate stimulus features are consistent with the interpretation of a global entity, responses in the early visual cortex encode information about the unified object. Such contextual enhancement of motion signals may allow the visual system to extrapolate the movement of partially occluded objects. Because neurons representing the space between visible parts of an object are informative about the object's motion, they may also provide signals to infer the space the larger object occupies. This provides evidence that a coherent stimulus is encoded differently than just the sum of its individual component elements.</p>
      <p>The present results are consistent with the finding that prolonged viewing of a perceptually grouped stimulus induces adaptation effects in parts of the visual field that do not receive direct physical stimulation (<xref rid="bb0185" ref-type="bibr">Roach et al., 2008</xref>). It is also in line with neuroimaging experiments showing that the size illusion caused by the three-dimensional context of a stimulus is accompanied by an enlarged retinotopic representation of the stimulus in V1 (<xref rid="bb0165" ref-type="bibr">Murray et al., 2006</xref>), by showing that other forms of contextual modulation also affect neuronal stimulus representations in human V1. Moreover, it also supports behavioural and electrophysiological evidence that contextual effects qualitatively alter the neuronal encoding of stimulus features in visual cortex (<xref rid="bb0130" ref-type="bibr">Kapadia et al., 2000</xref>).</p>
      <sec id="s0120">
        <title>What underpins improved decoding?</title>
        <p>Interestingly, we only observed reliable decoding of direction of motion of a single grating element when taking voxels from the entire visual field quadrant containing the element that belonged to the globally coherent stimulus. On the other hand, when we restricted our analysis to the retinotopic regions of interest corresponding to the stimulus elements, decoding was not significantly above chance. One possibility is that the ROI for individual elements may have contained too few voxels to permit reliable decoding, because elements were relatively small (standard deviation: 0.55&#xB0;). We employed high spatial resolution fMRI with a voxel size of 1.5&#xA0;&#xD7;&#xA0;1.5&#xA0;&#xD7;&#xA0;1.5&#xA0;mm<sup>3</sup>. With these parameters for most participants the ROIs for a single stimulus element contained only 50 voxels that may not have contained a sufficient number of biased voxels to result in reliable decoding. This possibility is also supported by recent methodological studies on the biological underpinnings of multivariate voxel pattern decoding. There are indications that biased voxels for simple stimulus features like orientation or the eye-of-stimulation are distributed across a relatively large scale, because decoding is not very susceptible to spatial smoothing (<xref rid="bb0170 bb0210 bb0230" ref-type="bibr">Op de Beeck, 2010; Shmuel et al., 2010; Swisher et al., 2010</xref>). One previous study suggested that orientation decoding was not due to very large scale biases, such as an imbalance in the responses to radial versus tangential orientations (<xref rid="bb0105" ref-type="bibr">Haynes and Rees, 2005</xref>). However, voxel biases may be the result of low spatial frequency harmonics of the high frequency columnar pattern of the cortex (<xref rid="bb0230" ref-type="bibr">Swisher et al., 2010</xref>), or have a more complex relationship to the neuronal populations encompassed by a voxel (<xref rid="bb0145" ref-type="bibr">Kriegeskorte et al., 2010</xref>). Alternatively, biases may reflect stimulus-selective blood vessels (<xref rid="bb0080 bb0085" ref-type="bibr">Gardner, 2010; Gardner et al., 2008</xref>), which in turn may reflect the anisotropy of the underlying functional architecture of the cortex. In particular, this may be the case for fMRI at 3&#xA0;T compared to higher field strengths where the fMRI signal is less susceptible to the influence of larger blood vessels (<xref rid="bb0210" ref-type="bibr">Shmuel et al., 2010</xref>), although a direct comparison of voxel pattern decoding at different field strengths has not yet been reported.</p>
        <p>The decoding of opposite directions of motion may be difficult even with larger stimuli, because there may be only relatively weak biases in direction preferences evident at the scale of single voxels. Previous MVPA studies varied in their success for decoding the direction of motion from responses in early visual cortex (<xref rid="bb0025 bb0125" ref-type="bibr">Brouwer and van Ee, 2007; Kamitani and Tong, 2006</xref>). If voxel biases are related (directly or indirectly) to the direction-preference map in visual cortical areas, these weaker biases could be due to the fact that opposite motion directions are encoded by populations within the same orientation columns (<xref rid="bb0205" ref-type="bibr">Shmuel and Grinvald, 1996</xref>). In turn this would mean that the largest difference in voxel biases should exist between orthogonal, not opposite, directions of motion. Recent optical imaging experiments, however, found no direction domains in macaque V1 (<xref rid="bb0155" ref-type="bibr">Lu et al., 2009</xref>), which also suggests that only very weak biases for motion direction may be present in human V1.</p>
        <p>We therefore make no claim that the globally coherent context in our experiment enhances motion signals only outside the direct retinotopic regions responding to the stimulus elements. Similarly, our failure to decode the direction of incoherent motion for larger regions of interest from entire visual field quadrants need not mean that decoding for a more effective stimulus would also be at chance. Instead, our study directly pitted globally coherent and incoherent contexts against each other. Our key finding is that decoding was possible for the coherent context but not the incoherent context. This result is not confounded by the question of what biological mechanism underlies direction decoding <italic>per se</italic>, but shows that perceptual grouping enhances the discriminability of motion signals.</p>
        <p>Our curve element and the inducers were not only separated in visual space, but were also presented to spatially distinct brain regions. It could nonetheless be argued that because we could only decode when taking voxels corresponding to an entire visual field quadrant, the enhanced decoding for the coherent context was due to &#x2018;spill-over&#x2019; of responses from the adjacent visual field quadrant. We believe this is an unlikely explanation because the physical stimulation of the curve quadrant was very similar for the coherent and incoherent contexts. Specifically, inducer elements were always present at a distance of 5.5&#xB0; from the curve element. At the visual eccentricity employed here, in the early retinotopic areas the population receptive field sizes of individual voxels (<xref rid="bb0050 bb0215" ref-type="bibr">Dumoulin and Wandell, 2008; Smith et al., 2001</xref>) are much smaller than the inter-element separation in our stimulus (&lt;&#xA0;1&#xB0; of visual angle for both V1 and V2). This suggests that voxels in the curve quadrant did not respond directly to any of the inducer elements. Moreover, the globally coherent context was defined by the directions of motion of inducer and curve elements being consistent with a curved path; however, locally the angle between the direction of the curve element and the inducers was identical, merely of the opposite sign. So even if the physical stimulation of the curve quadrant differed for the two contexts, our results must be due to differences in the integration of motion signals, even if this means that locally the receptive fields of voxels encompassed adjacent stimulus elements. Any such interactions between neighbouring elements across the visual field meridians must take into account both the locations and directions (orientations) of the elements. Such a mechanism, whether through local or global interactions, reflects the overall coherence of the stimulus configuration which is precisely the phenomenon we set out to study.</p>
        <p>Naturally, in higher extrastriate areas where neurons (and voxels) have larger receptive fields encompassing both the curve element and some or all of the inducer elements the physical difference between the two contexts could account for differences observed in direction decoding. However, interestingly we did not observe above chance decoding of direction of motion in such higher areas.</p>
        <p>Improved decoding for direction could be due to a general enhancement of fMRI signals throughout visual cortex. An overall signal increase in an area might also enhance the pattern of voxel biases and thus result in improved decoding performance. We analysed the overall response from regions of interest in the framework of a general linear model used in conventional fMRI analyses. This showed that there were no significant differences in average responses within individual ROIs comparing the coherent and incoherent contexts. If anything, there was a trend for the response to the incoherent context to be greater. This finding is consistent with previous research (<xref rid="bb0100 bb0160" ref-type="bibr">Harrison et al., 2007; Murray et al., 2002</xref>), but it is incompatible with a stronger response to globally coherent motion. The difference in signal strength for the two contexts probably also accounts for the reliable decoding of context in areas V2, V3, and V4. In accordance with a study combining optical imaging and electrophysiology (<xref rid="bb0135" ref-type="bibr">Kinoshita et al., 2009</xref>), the reduced metabolic activity during coherent motion may reflect the absence of inhibitory neuronal activity, which in turn results in the response facilitation of neurons tuned to the coherent directions of motion.</p>
      </sec>
      <sec id="s0125">
        <title>Neuronal mechanisms</title>
        <p>Perceptual integration may recruit long-range horizontal connections between simple feature detectors in the primary visual cortex that are known to extend several degrees through visual space (<xref rid="bb0010 bb0020 bb0030 bb0070" ref-type="bibr">Angelucci et al., 2002; Bosking et al., 1997; Chisum et al., 2003; Fitzpatrick, 2000</xref>). The profile of these connections has been well-described and they are likely to play a role in various contextual interactions that modulate neuronal responses (<xref rid="bb0030 bb0130" ref-type="bibr">Chisum et al., 2003; Kapadia et al., 2000</xref>). They link neurons with similar orientation preferences (<xref rid="bb0020 bb0095" ref-type="bibr">Bosking et al., 1997; Gilbert and Wiesel, 1989</xref>). However, they are organized primarily along the axis of the preferred orientation of a neuron. They would thus facilitate the activity evoked by co-circular edges, which argues against their involvement in our motion stimulus where elements are oriented to be near parallel to one another. Also, at the eccentricity we used here (between 4.1&#xB0; and 8.4&#xB0;), the individual grating elements are placed close to the spatial extent of these lateral connections (<xref rid="bb0010" ref-type="bibr">Angelucci et al., 2002</xref>), which does not rule their involvement, although it makes other factors more likely.</p>
        <p>Neurons in higher visual cortical areas with large receptive fields pool the signals from individual stimulus elements. Neurons selective for moving contours and shapes will respond more strongly to the coherent context. We found that it was possible to use voxel patterns from areas V2, V3, and V4 to decode between the coherent and incoherent contexts. It is therefore possible that feedback from higher extrastriate cortex to earlier retinotopic cortex enhances the response of neuronal populations selective for the current direction of the moving stimulus (either directly or indirectly by reducing inhibition between populations with different direction-selectivity).</p>
        <p>One previous study employed dynamic causal modelling (<xref rid="bb0075" ref-type="bibr">Friston et al., 2003</xref>) to investigate the role of feedforward and feedback connections between V1 and V5/MT during apparent motion using a stimulus configuration very similar to the one we employed in the present study (<xref rid="bb0220" ref-type="bibr">Sterzer et al., 2006</xref>). During the percept of apparent motion, feedback from V5/MT to the retinotopic location of the apparent motion in V1 was enhanced (in the absence of physical stimulation). Moreover, in behavioural studies, drifting Gabor stimuli also result in an illusory percept that may be related to apparent motion: the Gabor is perceived as displaced from its veridical location along the axis of motion (<xref rid="bb0015 bb0040" ref-type="bibr">Bex et al., 2001; De Valois and De Valois, 1991</xref>). We speculate that the percept of globally coherent motion associated with our stimuli also involves feedback from higher extrastriate cortex and that it differed between the coherent and incoherent contexts. This could explain why we observed better decoding when taking into account voxels that arguably received no direct physical stimulation, and may represent a promising direction for future study.</p>
      </sec>
      <sec id="s0130">
        <title>Upper versus lower hemifield asymmetry</title>
        <p>We observed differences in decoding accuracy comparing upper and lower visual fields. Decoding was only significantly different for the coherent and incoherent contexts when the global context was in the lower-right quadrant but not when it was in the upper-left quadrant. Similarly, only for the lower-right quadrant was decoding accuracy for direction of motion above chance. We therefore surmise that the effect of globally coherent motion may be stronger for the lower visual field. Indeed, there have been reports of an asymmetry between the upper and lower visual fields for perceptual integration (<xref rid="bb0190" ref-type="bibr">Rubin et al., 1996</xref>). This may be because vision in the lower visual field is required predominantly for detecting and identifying objects, such as prey or predators, and to ascertain the topography of the ground to navigate steps and steep edges.</p>
      </sec>
      <sec id="s0135">
        <title>Grouping and perceived speed</title>
        <p>In behavioural experiments outside the scanner environment we examined the effect of the globally coherent and incoherent contexts we employed in the main fMRI experiment had on the perceived speed of the Gabor elements. One previous study reported that when several grating elements are moving in the same direction speed discrimination is worse than when a single grating is shown in isolation suggesting that grouping interferes with speed judgements (<xref rid="bb0240" ref-type="bibr">Verghese and Stone, 1996</xref>). While most of our observers showed worse speed judgements for the contextual stimuli containing several scattered elements relative to stimuli with only a single element, we found no difference in this effect between coherent and incoherent contexts. Further, the direction of the effect was not consistent across participants, as for some participants speed was perceived as faster while for others it was perceived to be slower than the veridical speed. We therefore surmise that previously reported effects of grouping on perceived speed (<xref rid="bb0235 bb0240" ref-type="bibr">Verghese and McKee, 2006; Verghese and Stone, 1996</xref>) are unrelated to the enhanced discriminability of motion signals in visual cortex that we report here.</p>
      </sec>
    </sec>
    <sec id="s0140">
      <title>Conclusion</title>
      <p>Here we showed that coherent moving stimuli alluding to the presence of a global object resulted in reliable decoding of the direction of motion, as long as the stimulus was in the lower visual field. This indicates that early visual cortex contains information about the presence of moving objects, not merely their component motion features. An enhanced representation of the direction of motion may allow the visual system to infer the trajectory of movement across the gaps between individual stimulus features and thus play a role in perceptual grouping when local elements are interpreted as being part of a coherent whole.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bb0005">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Altmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Bulthoff</surname>
              <given-names>H.H.</given-names>
            </name>
            <name>
              <surname>Kourtzi</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual organization of local elements into global shapes in the human visual cortex</article-title>
          <source>Curr. Biol.</source>
          <volume>13</volume>
          <issue>4</issue>
          <year>2003</year>
          <fpage>342</fpage>
          <lpage>349</lpage>
          <pub-id pub-id-type="pmid">12593802</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0010">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Angelucci</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Levitt</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Walton</surname>
              <given-names>E.J.</given-names>
            </name>
            <name>
              <surname>Hupe</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Bullier</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lund</surname>
              <given-names>J.S.</given-names>
            </name>
          </person-group>
          <article-title>Circuits for local and global signal integration in primary visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>22</volume>
          <issue>19</issue>
          <year>2002</year>
          <fpage>8633</fpage>
          <lpage>8646</lpage>
          <pub-id pub-id-type="pmid">12351737</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0015">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bex</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Simmers</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Dakin</surname>
              <given-names>S.C.</given-names>
            </name>
          </person-group>
          <article-title>Snakes and ladders: the role of temporal modulation in visual contour integration</article-title>
          <source>Vis. Res.</source>
          <volume>41</volume>
          <issue>27</issue>
          <year>2001</year>
          <fpage>3775</fpage>
          <lpage>3782</lpage>
          <pub-id pub-id-type="pmid">11712989</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0020">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bosking</surname>
              <given-names>W.H.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Schofield</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Fitzpatrick</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>17</volume>
          <issue>6</issue>
          <year>1997</year>
          <fpage>2112</fpage>
          <lpage>2127</lpage>
          <pub-id pub-id-type="pmid">9045738</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0025">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brouwer</surname>
              <given-names>G.J.</given-names>
            </name>
            <name>
              <surname>van Ee</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Visual cortex allows prediction of perceptual states during ambiguous structure-from-motion</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <issue>5</issue>
          <year>2007</year>
          <fpage>1015</fpage>
          <lpage>1023</lpage>
          <pub-id pub-id-type="pmid">17267555</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0030">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chisum</surname>
              <given-names>H.J.</given-names>
            </name>
            <name>
              <surname>Mooser</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Fitzpatrick</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Emergent properties of layer 2/3 neurons reflect the collinear arrangement of horizontal connections in tree shrew visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>23</volume>
          <issue>7</issue>
          <year>2003</year>
          <fpage>2947</fpage>
          <lpage>2960</lpage>
          <pub-id pub-id-type="pmid">12684482</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0035">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dale</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Fischl</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Sereno</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Cortical surface-based analysis. I. Segmentation and surface reconstruction</article-title>
          <source>NeuroImage</source>
          <volume>9</volume>
          <issue>2</issue>
          <year>1999</year>
          <fpage>179</fpage>
          <lpage>194</lpage>
          <pub-id pub-id-type="pmid">9931268</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0040">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>De Valois</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>De Valois</surname>
              <given-names>K.K.</given-names>
            </name>
          </person-group>
          <article-title>Vernier acuity with stationary moving Gabors</article-title>
          <source>Vis. Res.</source>
          <volume>31</volume>
          <issue>9</issue>
          <year>1991</year>
          <fpage>1619</fpage>
          <lpage>1626</lpage>
          <pub-id pub-id-type="pmid">1949630</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0045">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dumoulin</surname>
              <given-names>S.O.</given-names>
            </name>
            <name>
              <surname>Hess</surname>
              <given-names>R.F.</given-names>
            </name>
          </person-group>
          <article-title>Modulation of V1 activity by shape: image-statistics or shape-based perception?</article-title>
          <source>J. Neurophysiol.</source>
          <volume>95</volume>
          <issue>6</issue>
          <year>2006</year>
          <fpage>3654</fpage>
          <lpage>3664</lpage>
          <pub-id pub-id-type="pmid">16510776</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0050">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dumoulin</surname>
              <given-names>S.O.</given-names>
            </name>
            <name>
              <surname>Wandell</surname>
              <given-names>B.A.</given-names>
            </name>
          </person-group>
          <article-title>Population receptive field estimates in human visual cortex</article-title>
          <source>NeuroImage</source>
          <volume>39</volume>
          <issue>2</issue>
          <year>2008</year>
          <fpage>647</fpage>
          <lpage>660</lpage>
          <pub-id pub-id-type="pmid">17977024</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0055">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dupont</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>De Bruyn</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Vandenberghe</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rosier</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Michiels</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Marchal</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>The kinetic occipital region in human visual cortex</article-title>
          <source>Cereb. Cortex</source>
          <volume>7</volume>
          <issue>3</issue>
          <year>1997</year>
          <fpage>283</fpage>
          <lpage>292</lpage>
          <pub-id pub-id-type="pmid">9143447</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0060">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Kersten</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Murray</surname>
              <given-names>S.O.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual grouping and inverse fMRI activity patterns in human visual cortex</article-title>
          <source>J. Vis.</source>
          <volume>8</volume>
          <issue>7</issue>
          <year>2008</year>
          <fpage>2.1</fpage>
          <lpage>9</lpage>
          <pub-id pub-id-type="pmid">19146235</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0065">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Field</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Hayes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Hess</surname>
              <given-names>R.F.</given-names>
            </name>
          </person-group>
          <article-title>Contour integration by the human visual system: evidence for a local &#x201C;association field&#x201D;</article-title>
          <source>Vis. Res.</source>
          <volume>33</volume>
          <issue>2</issue>
          <year>1993</year>
          <fpage>173</fpage>
          <lpage>193</lpage>
          <pub-id pub-id-type="pmid">8447091</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0070">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fitzpatrick</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Seeing beyond the receptive field in primary visual cortex</article-title>
          <source>Curr. Opin. Neurobiol.</source>
          <volume>10</volume>
          <issue>4</issue>
          <year>2000</year>
          <fpage>438</fpage>
          <lpage>443</lpage>
          <pub-id pub-id-type="pmid">10981611</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0075">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic causal modelling</article-title>
          <source>NeuroImage</source>
          <volume>19</volume>
          <issue>4</issue>
          <year>2003</year>
          <fpage>1273</fpage>
          <lpage>1302</lpage>
          <pub-id pub-id-type="pmid">12948688</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0080">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gardner</surname>
              <given-names>J.L.</given-names>
            </name>
          </person-group>
          <article-title>Is cortical vasculature functionally organized?</article-title>
          <source>NeuroImage</source>
          <volume>49</volume>
          <issue>3</issue>
          <year>2010</year>
          <fpage>1953</fpage>
          <lpage>1956</lpage>
          <pub-id pub-id-type="pmid">19596071</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0085">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gardner</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Tanaka</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Cheng</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Inferring population responses in human visual cortex with classification analysis</article-title>
          <source>J. Vis.</source>
          <volume>8</volume>
          <issue>17</issue>
          <year>2008</year>
          <comment>Abstract 34</comment>
        </element-citation>
      </ref>
      <ref id="bb0090">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gilbert</surname>
              <given-names>C.D.</given-names>
            </name>
          </person-group>
          <article-title>Horizontal integration and cortical dynamics</article-title>
          <source>Neuron</source>
          <volume>9</volume>
          <issue>1</issue>
          <year>1992</year>
          <fpage>1</fpage>
          <lpage>13</lpage>
          <pub-id pub-id-type="pmid">1632964</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0095">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gilbert</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Wiesel</surname>
              <given-names>T.N.</given-names>
            </name>
          </person-group>
          <article-title>Columnar specificity of intrinsic horizontal and corticocortical connections in cat visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>9</volume>
          <issue>7</issue>
          <year>1989</year>
          <fpage>2432</fpage>
          <lpage>2442</lpage>
          <pub-id pub-id-type="pmid">2746337</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Harrison</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Extra-classical receptive field effects measured in striate cortex with fMRI</article-title>
          <source>NeuroImage</source>
          <volume>34</volume>
          <issue>3</issue>
          <year>2007</year>
          <fpage>1199</fpage>
          <lpage>1208</lpage>
          <pub-id pub-id-type="pmid">17169579</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0105">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haynes</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Predicting the orientation of invisible stimuli from activity in human primary visual cortex</article-title>
          <source>Nat. Neurosci.</source>
          <volume>8</volume>
          <issue>5</issue>
          <year>2005</year>
          <fpage>686</fpage>
          <lpage>691</lpage>
          <pub-id pub-id-type="pmid">15852013</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0110">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hess</surname>
              <given-names>R.F.</given-names>
            </name>
            <name>
              <surname>McIlhagga</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Field</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Contour integration in strabismic amblyopia: the sufficiency of an explanation based on positional uncertainty</article-title>
          <source>Vis. Res.</source>
          <volume>37</volume>
          <issue>22</issue>
          <year>1997</year>
          <fpage>3145</fpage>
          <lpage>3161</lpage>
          <pub-id pub-id-type="pmid">9463696</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0115">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hutton</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Bork</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Josephs</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Deichmann</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Turner</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Image distortion correction in fMRI: a quantitative evaluation</article-title>
          <source>NeuroImage</source>
          <volume>16</volume>
          <issue>1</issue>
          <year>2002</year>
          <fpage>217</fpage>
          <lpage>240</lpage>
          <pub-id pub-id-type="pmid">11969330</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0120">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kamitani</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Tong</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Decoding the visual and subjective contents of the human brain</article-title>
          <source>Nat. Neurosci.</source>
          <volume>8</volume>
          <issue>5</issue>
          <year>2005</year>
          <fpage>679</fpage>
          <lpage>685</lpage>
          <pub-id pub-id-type="pmid">15852014</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0125">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kamitani</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Tong</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Decoding seen and attended motion directions from activity in the human visual cortex</article-title>
          <source>Curr. Biol.</source>
          <volume>16</volume>
          <issue>11</issue>
          <year>2006</year>
          <fpage>1096</fpage>
          <lpage>1102</lpage>
          <pub-id pub-id-type="pmid">16753563</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0130">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kapadia</surname>
              <given-names>M.K.</given-names>
            </name>
            <name>
              <surname>Westheimer</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Gilbert</surname>
              <given-names>C.D.</given-names>
            </name>
          </person-group>
          <article-title>Spatial distribution of contextual interactions in primary visual cortex and in visual perception</article-title>
          <source>J. Neurophysiol.</source>
          <volume>84</volume>
          <issue>4</issue>
          <year>2000</year>
          <fpage>2048</fpage>
          <lpage>2062</lpage>
          <pub-id pub-id-type="pmid">11024097</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0135">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kinoshita</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gilbert</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Das</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Optical imaging of contextual interactions in v1 of the behaving monkey</article-title>
          <source>J. Neurophysiol.</source>
          <volume>102</volume>
          <issue>3</issue>
          <year>2009</year>
          <fpage>1930</fpage>
          <lpage>1944</lpage>
          <pub-id pub-id-type="pmid">19587316</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0140">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kovacs</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Julesz</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual sensitivity maps within globally defined visual shapes</article-title>
          <source>Nature</source>
          <volume>370</volume>
          <issue>6491</issue>
          <year>1994</year>
          <fpage>644</fpage>
          <lpage>646</lpage>
          <pub-id pub-id-type="pmid">8065449</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0145">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kriegeskorte</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Cusack</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bandettini</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>How does an fMRI voxel sample the neuronal activity pattern: compact-kernel or complex spatiotemporal filter?</article-title>
          <source>NeuroImage</source>
          <volume>49</volume>
          <issue>3</issue>
          <year>2010</year>
          <fpage>1965</fpage>
          <lpage>1976</lpage>
          <pub-id pub-id-type="pmid">19800408</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0150">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Larsson</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Two retinotopic visual areas in human lateral occipital cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>26</volume>
          <issue>51</issue>
          <year>2006</year>
          <fpage>13128</fpage>
          <lpage>13142</lpage>
          <pub-id pub-id-type="pmid">17182764</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0155">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lu</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Roe</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Motion processing in the ventral pathway: evidence for direction maps in macaque V2 and V4</article-title>
          <source>J. Vis.</source>
          <volume>9</volume>
          <issue>8</issue>
          <year>2009</year>
          <comment>Abstract 743</comment>
        </element-citation>
      </ref>
      <ref id="bb0160">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Murray</surname>
              <given-names>S.O.</given-names>
            </name>
            <name>
              <surname>Kersten</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Olshausen</surname>
              <given-names>B.A.</given-names>
            </name>
            <name>
              <surname>Schrater</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Woods</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>Shape perception reduces activity in human primary visual cortex</article-title>
          <source>Proc. Natl. Acad. Sci. U.S.A.</source>
          <volume>99</volume>
          <issue>23</issue>
          <year>2002</year>
          <fpage>15164</fpage>
          <lpage>15169</lpage>
          <pub-id pub-id-type="pmid">12417754</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0165">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Murray</surname>
              <given-names>S.O.</given-names>
            </name>
            <name>
              <surname>Boyaci</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Kersten</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>The representation of perceived angular size in human primary visual cortex</article-title>
          <source>Nat. Neurosci.</source>
          <volume>9</volume>
          <issue>3</issue>
          <year>2006</year>
          <fpage>429</fpage>
          <lpage>434</lpage>
          <pub-id pub-id-type="pmid">16462737</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0170">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Op de Beeck</surname>
              <given-names>H.P.</given-names>
            </name>
          </person-group>
          <article-title>Against hyperacuity in brain reading: spatial smoothing does not hurt multivariate fMRI analyses?</article-title>
          <source>NeuroImage</source>
          <volume>49</volume>
          <issue>3</issue>
          <year>2010</year>
          <fpage>1943</fpage>
          <lpage>1948</lpage>
          <pub-id pub-id-type="pmid">19285144</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0175">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Polat</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Bonneh</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Collinear interactions and contour integration</article-title>
          <source>Spat. Vis.</source>
          <volume>13</volume>
          <issue>4</issue>
          <year>2000</year>
          <fpage>393</fpage>
          <lpage>401</lpage>
          <pub-id pub-id-type="pmid">11310533</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0180">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Polat</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Sagi</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Lateral interactions between spatial channels: suppression and facilitation revealed by lateral masking experiments</article-title>
          <source>Vis. Res.</source>
          <volume>33</volume>
          <issue>7</issue>
          <year>1993</year>
          <fpage>993</fpage>
          <lpage>999</lpage>
          <pub-id pub-id-type="pmid">8506641</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0185">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Roach</surname>
              <given-names>N.W.</given-names>
            </name>
            <name>
              <surname>Webb</surname>
              <given-names>B.S.</given-names>
            </name>
            <name>
              <surname>McGraw</surname>
              <given-names>P.V.</given-names>
            </name>
          </person-group>
          <article-title>Adaptation to global structure induces spatially remote distortions of perceived orientation</article-title>
          <source>J. Vis.</source>
          <volume>8</volume>
          <issue>3</issue>
          <year>2008</year>
          <fpage>31.1</fpage>
          <lpage>12</lpage>
          <pub-id pub-id-type="pmid">18484837</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0190">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rubin</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Shapley</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Enhanced perception of illusory contours in the lower versus upper visual hemifields</article-title>
          <source>Science</source>
          <volume>271</volume>
          <issue>5249</issue>
          <year>1996</year>
          <fpage>651</fpage>
          <lpage>653</lpage>
          <pub-id pub-id-type="pmid">8571128</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0195">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schwarzkopf</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kourtzi</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <article-title>Flexible learning of natural statistics in the human brain</article-title>
          <source>J. Neurophysiol.</source>
          <volume>102</volume>
          <issue>3</issue>
          <year>2009</year>
          <fpage>1854</fpage>
          <lpage>1867</lpage>
          <pub-id pub-id-type="pmid">19605615</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0200">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sereno</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Dale</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Reppas</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Kwong</surname>
              <given-names>K.K.</given-names>
            </name>
            <name>
              <surname>Belliveau</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Brady</surname>
              <given-names>T.J.</given-names>
            </name>
            <name>
              <surname>Rosen</surname>
              <given-names>B.R.</given-names>
            </name>
            <name>
              <surname>Tootell</surname>
              <given-names>R.B.</given-names>
            </name>
          </person-group>
          <article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title>
          <source>Science</source>
          <volume>268</volume>
          <issue>5212</issue>
          <year>1995</year>
          <fpage>889</fpage>
          <lpage>893</lpage>
          <pub-id pub-id-type="pmid">7754376</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0205">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shmuel</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Grinvald</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Functional organization for direction of motion and its relationship to orientation maps in cat area 18</article-title>
          <source>J. Neurosci.</source>
          <volume>16</volume>
          <issue>21</issue>
          <year>1996</year>
          <fpage>6945</fpage>
          <lpage>6964</lpage>
          <pub-id pub-id-type="pmid">8824332</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0210">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shmuel</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Chaimow</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Raddatz</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Ugurbil</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Yacoub</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Mechanisms underlying decoding at 7&#xA0;T: coarse structures, macroscopic blood vessels, and gray matter regions in V1 convey information on the stimulated eye</article-title>
          <source>NeuroImage</source>
          <volume>49</volume>
          <issue>3</issue>
          <year>2010</year>
          <fpage>1957</fpage>
          <lpage>1964</lpage>
          <pub-id pub-id-type="pmid">19715765</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0215">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>A.T.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>K.D.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>A.L.</given-names>
            </name>
            <name>
              <surname>Greenlee</surname>
              <given-names>M.W.</given-names>
            </name>
          </person-group>
          <article-title>Estimating receptive field size from fMRI data in human striate and extrastriate visual cortex</article-title>
          <source>Cereb. Cortex</source>
          <volume>11</volume>
          <issue>12</issue>
          <year>2001</year>
          <fpage>1182</fpage>
          <lpage>1190</lpage>
          <pub-id pub-id-type="pmid">11709489</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0220">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sterzer</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Haynes</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Primary visual cortex activation on the path of apparent motion is mediated by feedback from hMT+/V5</article-title>
          <source>NeuroImage</source>
          <volume>32</volume>
          <issue>3</issue>
          <year>2006</year>
          <fpage>1308</fpage>
          <lpage>1316</lpage>
          <pub-id pub-id-type="pmid">16822682</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0225">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sterzer</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Haynes</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Fine-scale activity patterns in high-level visual areas encode the category of invisible objects</article-title>
          <source>J. Vis.</source>
          <volume>8</volume>
          <issue>15</issue>
          <year>2008</year>
          <fpage>10.1</fpage>
          <lpage>12</lpage>
          <pub-id pub-id-type="pmid">19146294</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0230">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Swisher</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Gatenby</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Gore</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Wolfe</surname>
              <given-names>B.A.</given-names>
            </name>
            <name>
              <surname>Moon</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Multiscale pattern analysis of orientation-selective activity in the primary visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>30</volume>
          <issue>1</issue>
          <year>2010</year>
          <fpage>325</fpage>
          <lpage>330</lpage>
          <pub-id pub-id-type="pmid">20053913</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0235">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Verghese</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>McKee</surname>
              <given-names>S.P.</given-names>
            </name>
          </person-group>
          <article-title>Motion grouping impairs speed discrimination</article-title>
          <source>Vis. Res.</source>
          <volume>46</volume>
          <issue>8&#x2013;9</issue>
          <year>2006</year>
          <fpage>1540</fpage>
          <lpage>1546</lpage>
          <pub-id pub-id-type="pmid">16168457</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0240">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Verghese</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Stone</surname>
              <given-names>L.S.</given-names>
            </name>
          </person-group>
          <article-title>Perceived visual speed constrained by image segmentation</article-title>
          <source>Nature</source>
          <volume>381</volume>
          <issue>6578</issue>
          <year>1996</year>
          <fpage>161</fpage>
          <lpage>163</lpage>
          <pub-id pub-id-type="pmid">8610014</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0245">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wichmann</surname>
              <given-names>F.A.</given-names>
            </name>
            <name>
              <surname>Hill</surname>
              <given-names>N.J.</given-names>
            </name>
          </person-group>
          <article-title>The psychometric function: II. Bootstrap-based confidence intervals and sampling</article-title>
          <source>Percept. Psychophys.</source>
          <volume>63</volume>
          <issue>8</issue>
          <year>2001</year>
          <fpage>1314</fpage>
          <lpage>1329</lpage>
          <pub-id pub-id-type="pmid">11800459</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0250">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wichmann</surname>
              <given-names>F.A.</given-names>
            </name>
            <name>
              <surname>Hill</surname>
              <given-names>N.J.</given-names>
            </name>
          </person-group>
          <article-title>The psychometric function: I. Fitting, sampling, and goodness of fit</article-title>
          <source>Percept. Psychophys.</source>
          <volume>63</volume>
          <issue>8</issue>
          <year>2001</year>
          <fpage>1293</fpage>
          <lpage>1313</lpage>
          <pub-id pub-id-type="pmid">11800458</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0255">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhu</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>The functional asymmetry of the lower and upper visual fields in attention and perceptual grouping</article-title>
          <source>J. Vis.</source>
          <volume>9</volume>
          <issue>8</issue>
          <year>2009</year>
          <comment>Abstract 919</comment>
        </element-citation>
      </ref>
      <ref id="bb0260">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zipser</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Lamme</surname>
              <given-names>V.A.</given-names>
            </name>
            <name>
              <surname>Schiller</surname>
              <given-names>P.H.</given-names>
            </name>
          </person-group>
          <article-title>Contextual modulation in primary visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>16</volume>
          <issue>22</issue>
          <year>1996</year>
          <fpage>7376</fpage>
          <lpage>7389</lpage>
          <pub-id pub-id-type="pmid">8929444</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="s0145" sec-type="supplementary-material">
      <label>Appendix A</label>
      <title>Supplementary data</title>
      <p>
        <supplementary-material content-type="local-data" id="ec0005">
          <media xlink:href="mmc1.doc" mimetype="application" mime-subtype="msword"/>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="ec0010">
          <media xlink:href="mmc2.jpg" mimetype="text" mime-subtype="plain"/>
        </supplementary-material>
        <fig id="f0030" position="anchor">
          <label>Fig. S1</label>
          <caption>
            <p>Flat maps from a representative participant. A. The response to all stimuli in the main experiment relative to blocks of fixation is plotted at a relaxed statistical threshold (<italic>p</italic>&#xA0;&lt;&#xA0;0.05, uncorrected). B&#x2013;C. Voxels in V1d (representing the curve quadrant) showing a moderately significant bias for direction of motion (<italic>p</italic>&#xA0;&lt;&#xA0;0.1, uncorrected) in the coherent context (B) and the incoherent context (C). The dotted black lines indicate the boundaries of visual areas. The yellow dotted line denotes the location of the ROI defined by the &#x2018;element localizer&#x2019;. The mean decoding accuracy (&#xB1;&#xA0;standard error of the mean) for direction of motion in V1d across all instances of cross-validation is denoted above each map.</p>
          </caption>
          <graphic xlink:href="gr6"/>
        </fig>
        <fig id="f0035" position="anchor">
          <label>Fig. S2</label>
          <caption>
            <p>Psychometric curves in the behavioural experiment for each of the four participants (in rows). We plotted the proportion of trials in which the test stimulus was perceived as faster than the reference as a function of the veridical ratio between test and reference speed (in logarithmic units). Thus a rightward shift of the curve would indicate that participants saw the stimulus as moving more slowly than the reference stimulus. Data are shown either for pooling data from the two possible positions of the curve quadrant (left), or separately for when the curve quadrant was the lower-right (middle) or upper-left quadrant (right). Symbols indicate raw data; the solid lines are the best fitting models. Blue: coherent context. Red: incoherent context. Green: control (single element in both reference as well as test stimulus).</p>
          </caption>
          <graphic xlink:href="gr7"/>
        </fig>
        <supplementary-material content-type="local-data" id="ec0015">
          <caption>
            <p>Supplementary materials</p>
          </caption>
          <media xlink:href="mmc3.avi" mimetype="video" mime-subtype="x-msvideo"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was supported by the Wellcome Trust. PS received funding from the German Research Foundation (STE-1430/2-1).</p>
    </ack>
  </back>
  <floats-group>
    <fig id="f0005">
      <label>Fig.&#xA0;1</label>
      <caption>
        <p>Static illustrations of the stimuli used. Five Gabors were placed on an imaginary curved path. Elements were either oriented in a coherent (A&#x2013;B) or incoherent (C&#x2013;D) relationship with the global context of the path. A sixth Gabor (the distractor element) was located in the diametrically opposite location to the middle element of the curve (the curve element). Within separate scanning sessions the individual elements making up the curve either traversed the lower-right (A, C) or the upper-left (B, D) visual field. Movies of the actual stimuli used in the experiment are included in the <xref rid="s0145" ref-type="sec">supplementary materials</xref>.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="f0010">
      <label>Fig.&#xA0;2</label>
      <caption>
        <p>Discriminating the coherent versus incoherent contexts using voxel patterns from visual areas. Decoding accuracy averaged across participants is depicted for each ROI separately for when the curve traversed the lower-right visual field (A) or the upper-left visual field (B). Error bars denote &#xB1;&#xA0;1 standard error of the mean. Asterisks indicate accuracy was significantly higher than chance (one-tailed <italic>t</italic>-test, <italic>p</italic>&#xA0;&lt;&#xA0;0.05). The arrows in the stimulus schematics indicate the directions of motion. Black arrows: coherent context. Grey arrows: incoherent context.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="f0015">
      <label>Fig.&#xA0;3</label>
      <caption>
        <p>Decoding the direction of motion from voxel patterns in human visual cortex. Accuracy averaged across participants is plotted for retinotopic areas V1&#x2013;V3 (error bars denote &#xB1;&#xA0;1 standard error of the mean). The plots are superimposed on a stimulus schematic to indicate the ROI (i.e. the curve quadrant traversed by the global context or the distractor quadrant in the opposite hemifield). In separate experiments, the curve quadrant was either the lower-right (A) or the upper-left (B) visual field. Black arrows/bars: coherent context. Grey arrows/bars: incoherent context.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="f0020">
      <label>Fig.&#xA0;4</label>
      <caption>
        <p>Mean BOLD signals evoked in early visual cortex by the globally coherent and incoherent contexts. Mean parameter estimates from the GLM analysis of all visually responsive voxels (see <xref rid="s0010" ref-type="sec">Materials and methods</xref>; averaged across participants) are plotted for regions of interest in early visual cortex. Panels are superimposed on a stimulus schematic indicating the ROI (curve quadrant and distractor quadrant). Only data from experiments when the curve quadrant was the lower-right visual field are shown. Black bars: coherent context. Grey bars: incoherent context. Error bars denote &#xB1;&#xA0;1 standard error of the mean.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="f0025">
      <label>Fig.&#xA0;5</label>
      <caption>
        <p>Behavioural experiment. The points of subjective equality for judging whether the Gabors moved faster than a reference element are plotted for each experimental condition and each of the four participants. Values indicate the ratio between the test and reference speeds (in logarithmic units). Thus, positive numbers indicate that participants saw the test interval as moving slower than the reference interval. Different symbols denote the data from individual participants. All data here are pooled across the two possible locations of the curve quadrant (lower-right and upper-left). Psychometric curves for individual observers and global context locations are shown in <xref rid="s0145" ref-type="sec">Fig. S2</xref>.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
  </floats-group>
</article>
