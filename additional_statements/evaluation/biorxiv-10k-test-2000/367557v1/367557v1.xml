<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/367557</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Objective Evaluation of Multiple Sclerosis Lesion Segmentation using a Data Management and Processing Infrastructure</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7345-6752</contrib-id>
<name><surname>Commowick</surname>
<given-names>Olivier</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Istace</surname>
<given-names>Audrey</given-names></name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kain</surname>
<given-names>Micha&#x00EB;l</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Laurent</surname>
<given-names>Baptiste</given-names></name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Leray</surname>
<given-names>Florent</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Simon</surname>
<given-names>Mathieu</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Pop</surname>
<given-names>Sorina Camarasu</given-names></name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Girard</surname>
<given-names>Pascal</given-names></name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Am&#x00E9;li</surname>
<given-names>Roxana</given-names></name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Ferr&#x00E9;</surname>
<given-names>Jean-Christophe</given-names></name>
<xref ref-type="aff" rid="a5">e</xref>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kerbrat</surname>
<given-names>Anne</given-names></name>
<xref ref-type="aff" rid="a6">f</xref>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Tourdias</surname>
<given-names>Thomas</given-names></name>
<xref ref-type="aff" rid="a7">g</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Cervenansky</surname>
<given-names>Fr&#x00E9;d&#x00E9;ric</given-names></name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Glatard</surname>
<given-names>Tristan</given-names></name>
<xref ref-type="aff" rid="a8">h</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Beaumont</surname>
<given-names>J&#x00E9;r&#x00E9;my</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Doyle</surname>
<given-names>Senan</given-names></name>
<xref ref-type="aff" rid="a9">i</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Forbes</surname>
<given-names>Florence</given-names></name>
<xref ref-type="aff" rid="a9">i</xref>
<xref ref-type="aff" rid="a10">j</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Knight</surname>
<given-names>Jesse</given-names></name>
<xref ref-type="aff" rid="a11">k</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Khademi</surname>
<given-names>April</given-names></name>
<xref ref-type="aff" rid="a12">l</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Mahbod</surname>
<given-names>Amirreza</given-names></name>
<xref ref-type="aff" rid="a13">m</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wang</surname>
<given-names>Chunliang</given-names></name>
<xref ref-type="aff" rid="a13">m</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>McKinley</surname>
<given-names>Richard</given-names></name>
<xref ref-type="aff" rid="a14">n</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wagner</surname>
<given-names>Franca</given-names></name>
<xref ref-type="aff" rid="a14">n</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Muschelli</surname>
<given-names>John</given-names></name>
<xref ref-type="aff" rid="a15">o</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Sweeney</surname>
<given-names>Elizabeth</given-names></name>
<xref ref-type="aff" rid="a15">o</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Roura</surname>
<given-names>Eloy</given-names></name>
<xref ref-type="aff" rid="a16">p</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Llad&#x00F3;</surname>
<given-names>Xavier</given-names></name>
<xref ref-type="aff" rid="a16">p</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Santos</surname>
<given-names>Michel M.</given-names></name>
<xref ref-type="aff" rid="a17">q</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Santos</surname>
<given-names>Wellington P.</given-names></name>
<xref ref-type="aff" rid="a18">r</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Silva-Filho</surname>
<given-names>Abel G.</given-names></name>
<xref ref-type="aff" rid="a17">q</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Tomas-Fernandez</surname>
<given-names>Xavier</given-names></name>
<xref ref-type="aff" rid="a19">s</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Urien</surname>
<given-names>H&#x00E9;l&#x00E8;ne</given-names></name>
<xref ref-type="aff" rid="a20">t</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Bloch</surname>
<given-names>Isabelle</given-names></name>
<xref ref-type="aff" rid="a20">t</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Valverde</surname>
<given-names>Sergi</given-names></name>
<xref ref-type="aff" rid="a16">p</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Cabezas</surname>
<given-names>Mariano</given-names></name>
<xref ref-type="aff" rid="a16">p</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Vera-Olmos</surname>
<given-names>Francisco Javier</given-names></name>
<xref ref-type="aff" rid="a21">u</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Malpica</surname>
<given-names>Norberto</given-names></name>
<xref ref-type="aff" rid="a21">u</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Guttmann</surname>
<given-names>Charles</given-names></name>
<xref ref-type="aff" rid="a22">v</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Vukusic</surname>
<given-names>Sandra</given-names></name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Edan</surname>
<given-names>Gilles</given-names></name>
<xref ref-type="aff" rid="a6">f</xref>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Dojat</surname>
<given-names>Michel</given-names></name>
<xref ref-type="aff" rid="a23">w</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Styner</surname>
<given-names>Martin</given-names></name>
<xref ref-type="aff" rid="a24">x</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Warfield</surname>
<given-names>Simon K.</given-names></name>
<xref ref-type="aff" rid="a19">s</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Cotton</surname>
<given-names>Fran&#x00E7;ois</given-names></name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1589-7696</contrib-id>
<name><surname>Barillot</surname>
<given-names>Christian</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<aff id="a1"><label>a</label><institution>VISAGES: INSERM U1228 - CNRS UMR6074 - Inria - University of Rennes I</institution>, <country>France</country></aff>
<aff id="a2"><label>b</label><institution>Department of Radiology, Lyon Sud Hospital, Hospices Civils de Lyon</institution>, Lyon, <country>France</country></aff>
<aff id="a3"><label>c</label><institution>LaTIM, INSERM, UMR 1101, University of Brest</institution>, IBSAM, Brest, <country>France</country></aff>
<aff id="a4"><label>d</label><institution>Univ Lyon, INSA-Lyon, Universit&#x00E9; Claude Bernard Lyon 1</institution>, UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1206, F-69621, LYON, <country>France</country></aff>
<aff id="a5"><label>e</label><institution>CHU Rennes, Department of Neuroradiology</institution>, F-35033 Rennes, <country>France</country></aff>
<aff id="a6"><label>f</label><institution>CHU Rennes, Department of Neurology</institution>, F-35033 Rennes, <country>France</country></aff>
<aff id="a7"><label>g</label><institution>CHU de Bordeaux, Service de Neuro-Imagerie, Bordeaux</institution>, <country>France</country></aff>
<aff id="a8"><label>h</label><institution>Department of Computer Science and Software Engineering, Concordia University</institution>, Montreal, <country>Canada</country></aff>
<aff id="a9"><label>i</label><institution>Pixyl Medical</institution>, Grenoble, <country>France</country></aff>
<aff id="a10"><label>j</label><institution>Inria Grenoble Rh&#x00F4;ne-Alpes</institution>, Grenoble, <country>France</country></aff>
<aff id="a11"><label>k</label><institution>Image Analysis in Medicine Lab, School of Engineering, University of Guelph</institution>, <country>Canada</country></aff>
<aff id="a12"><label>l</label><institution>Image Analysis in Medicine Lab (IAMLAB), Ryerson University</institution>, <country>Canada</country></aff>
<aff id="a13"><label>m</label><institution>School of Technology and Health, KTH Royal Institute of Technology</institution>, Stockholm, <country>Sweden</country></aff>
<aff id="a14"><label>n</label><institution>Department of Diagnostic and Interventional Neuroradiology, Inselspital, University of Bern</institution>, <country>Switzerland</country></aff>
<aff id="a15"><label>o</label><institution>Johns Hopkins Bloomberg School of Public Health</institution>, Baltimore MD</aff>
<aff id="a16"><label>p</label><institution>Research institute of Computer Vision and Robotics (VICOROB), University of Girona</institution>, <country>Spain</country></aff>
<aff id="a17"><label>q</label><institution>Centro de Inform&#x00E1;tica, Universidade Federal de Pernambuco</institution>, Pernambuco, <country>Brazil</country></aff>
<aff id="a18"><label>r</label><institution>Depto. de Eng. Biom&#x00E9;dica, Universidade Federal de Pernambuco</institution>, Pernambuco, <country>Brazil</country></aff>
<aff id="a19"><label>s</label><institution>Computational Radiology Laboratory, Department of Radiology, Children&#x2019;s Hospital</institution>, 300 Longwood Avenue, Boston, MA, <country>USA</country></aff>
<aff id="a20"><label>t</label><institution>LTCI, T&#x00E9;l&#x00E9;com ParisTech, Universit&#x00E9; Paris-Saclay</institution>, Paris, <country>France</country></aff>
<aff id="a21"><label>u</label><institution>Medical Image Analysis Lab, Universidad Rey Juan Carlos</institution>, <country>Spain</country></aff>
<aff id="a22"><label>v</label><institution>Center for Neurological Imaging, Department of Radiology, Brigham and Women&#x2019;s Hospital</institution>, Boston, MA, <country>USA</country></aff>
<aff id="a23"><label>w</label><institution>Inserm U1216, University Grenoble Alpes</institution>, CHU Grenoble, GIN, Grenoble, <country>France</country></aff>
<aff id="a24"><label>x</label><institution>Department of Computer Science, University of North Carolina</institution>, Chapel Hill, NC, <country>USA</country></aff>
</contrib-group>
<author-notes>
<fn fn-type="other"><p><italic>Email address:</italic> <email>Olivier.Commowick@inria.fr</email> (Olivier Commowick)</p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>367557</elocation-id>
<history>
<date date-type="received">
<day>13</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>13</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>13</day>
<month>7</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="367557.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>We present a study of multiple sclerosis segmentation algorithms conducted at the international MICCAI 2016 challenge. This challenge was operated using a new open-science computing infrastructure. This allowed for the automatic and independent evaluation of a large range of algorithms in a fair and completely automatic manner. This computing infrastructure was used to evaluate thirteen methods of MS lesions segmentation, exploring a broad range of state-of-the-art algorithms, against a high-quality database of 53 MS cases coming from four centers following a common definition of the acquisition protocol. Each case was annotated manually by an unprecedented number of seven different experts. Results of the challenge highlighted that automatic algorithms, including the recent machine learning methods (random forests, deep learning, &#x2026;), are still trailing human expertise on both detection and delineation criteria. In addition, we demonstrate that computing a statistically robust consensus of the algorithms performs closer to human expertise on one score (segmentation) although still trailing on detection scores.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Multiple sclerosis</kwd>
<kwd>image segmentation</kwd>
<kwd>performance evaluation</kwd>
<kwd>computing infrastructure</kwd>
<kwd>open science</kwd>
<kwd>distributed computing</kwd>
</kwd-group>
<counts>
<page-count count="30"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<p>Multiple Sclerosis (MS) is a chronic inflammatory disease of the central nervous system affecting around 2.5 million persons worldwide, with a prevalence rate of 83 per 100000 (higher rates in countries of the northern hemisphere) and a woman:man ratio of around 2.0 [<xref ref-type="bibr" rid="c1">1</xref>]. It is characterized by widespread inflammation, focal demyelination, and a variable degree of axonal loss. With the appearance of new treatment molecules modifying the disease evolution (disease modifying drugs - DMD), one of the major challenges in treating multiple sclerosis is now to overcome classical clinical criteria, such as the expanded disability status scale (EDSS), to go towards more sensitive and specific criteria. In this context, Magnetic Resonance Imaging (MRI) plays an important role for the diagnosis [<xref ref-type="bibr" rid="c2">2</xref>] and evaluation of the evolution of the disease, thus providing insights to adapt the treatment to each individual due to the highly variable nature of the MS disease course [<xref ref-type="bibr" rid="c3">3</xref>].</p>
<p>In this context, the number and spread of lesions in the patient&#x2019;s parenchyma (and their evolution) [<xref ref-type="bibr" rid="c2">2</xref>] has become a crucial information on the patient&#x2019;s disease status, which may then be used for validating the patient treatment. This task however requires the delineation of MS lesions: a tedious, manual operation performed by the radiologist. In addition, this delineation is prone to interexpert variability, especially when the images being used for segmentation differ from a center to another (in terms of protocols, modalities and intrinsic MRI quality). Doing this task manually on large databases of patients is therefore almost impossible and automatic algorithms, thoroughly validated, have become a crucial need for the clinical community. To simplify the clinician&#x2019;s task, a large literature of automatic segmentation methods has been devised [<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>] with a large spectrum of algorithms from classical tissue intensity classification and lesion modeling to machine learning.</p>
<p>All published approaches are however evaluated on different datasets, usually not calibrated, and their results are therefore usually not directly comparable, making difficult the choice of the most relevant method adapted to a clinical context. To overcome this issue, competitions (so-called challenges) have been organized in MS lesion segmentation in the past years. The first one was organized at the MICCAI 2008 conference [<xref ref-type="bibr" rid="c7">7</xref>]. It evaluated nine different methods on a database of 45 patient images (from two different centers: 20 for training and 25 for testing), with respect to a ground truth composed of two expert segmentations for each case. However, no protocol standardization was performed between the two sites, therefore two raters were not enough to handle the variability in the acquired images and get a sufficiently reliable consensus manual segmentation. The second major challenge on MS lesion segmentation was held in 2015 at the IEEE ISBI international conference [<xref ref-type="bibr" rid="c8">8</xref>]. It was more focused on the study of longitudinal lesion evolution with specific evaluation metrics based on segmentation volume evolution (in addition to the regular segmentation overlap metrics used in 2008). This challenge evaluated 10 different methods on a dataset composed of five patients images each with an average of 4.4 time points, each time point being manually delineated by two experts. As for the MICCAI 2008 challenge, two raters were not enough to account for disparities in the different raters manual segmentations and get a representative consensus. The process of evaluation was similar for the two challenges. A subset of the patient images was provided to the participants with the ground truth (GT) segmentation to the participants for them to train their respective methods. In a second step, a testing set was provided (without the ground truth) to the participants asking them to submit back their results. Evaluation was then performed on those results using overlap-based metrics.</p>
<p>Several problems may however affect such challenges. First, as a general comment for all challenges, a lack of fairness may exist between the participants: since the testing images are provided, some participants may indeed optimize the parameters of their algorithms on a patient basis to obtain better results. Doing this illustrates the potential of the method but not its practical usability: a clinician would prefer to use always the same set of parameters to process each new or returning patient. In addition, since participants run their algorithm on their own computing environment, no evaluation relative to computing performance (e.g. required memory of computing time) is possible. There is therefore a need for computing platforms for supporting challenges including data storage, processing pipelines (i.e. segmentation algorithms work-flow used) integration and evaluation on stored datasets. Such platforms would provide a truly fair comparison between fully automatic methods. In addition, such remote computing platforms, able to host a large variety of algorithms, announce what the future cloud computing services will provide to assist clinicians (radiologists, neurologists, &#x2026;) in using computer aided diagnosis solutions. This computing environment also opens the road to open-science platforms where people will find solutions to post their data, send or retrieve algorithmic solutions and provide an independent yet secure environment to compare, assess and combine various algorithms outcomes and solve clinical problems.</p>
<p>Another issue in segmentation challenges is the number of manual delineations to compute the ground truth. Usually only two are available, which is insufficient to illustrate the inter-expert variability, particularly when considering MS lesions segmentation. Finally, and specifically to MS lesions segmentation, previous challenges considered only segmentation based metrics, ignoring the number of correctly detected lesions independently of their shape, which is an acute criterion to assess the disease evolution [<xref ref-type="bibr" rid="c2">2</xref>]. This would be very beneficial for the clinician, especially when considering MS evolution where the number of new lesions is critical.</p>
<p>We proposed and organized in 2016 a new generation of segmentation challenge hosted at the MICCAI international conference <bold>(<ext-link ext-link-type="uri" xlink:href="http://www.miccai2016.org">http://www.miccai2016.org</ext-link>)</bold>. It aimed at proposing solutions to several of the previously mentioned defects first by gathering an unprecedented database of MS patients, coming from three different centers (representing four different scanners, one of which was intentionally hidden at the training phase from the challengers to test their algorithms&#x2019; adaptation capabilities) but all following a common consensus protocol [<xref ref-type="bibr" rid="c9">9</xref>], each patient being delineated by seven experts to evaluate not only automatic methods performance but also inter-expert variability of manual segmentation. We have performed the evaluation on a dedicated computing platform provided by France Life Imaging (<bold><ext-link ext-link-type="uri" xlink:href="https://www.francelifeimaging.fr/en">https://www.francelifeimaging.fr/en</ext-link></bold>), providing pipeline integration, database storage and automatic execution capabilities. Challenge participants were asked to train their algorithms on a reduced set (<italic>n</italic> &#x003D; 15) and then integrate their pipeline on the platform, requiring no action from them in the latter parts of the evaluation process (<italic>n</italic> &#x003D; 38). We also proposed an evaluation strategy on two separate levels: a segmentation level where the overlap precision of the segmentation was evaluated; and a detection level where the number of correctly detected lesions was evaluated, independently of the precision of their shape.</p>
<p>We present in this article a retrospective analysis of this challenge and the methods we used to obtain those results. The main outcomes of the challenge highlighted that automatic algorithms are still trailing human expertise on the front of MS lesions segmentation and sensitive to unknown images (different scanners) even with an harmonized acquisition protocol. This happens for all methods, independently of their category (recent machine learning algorithms including deep learning or random forests or more classical tissue classification algorithms). In addition, we demonstrate how using an open-science computing environment allows for the combination of multiple algorithmic outcomes, and how combining these algorithms could lead to improvements in detection and contouring of MS lesions. Together with the computing platform introduced in this paper, this could lead to tremendous help for the clinicians in the use of automatic segmentation algorithms to support their diagnosis and treatment follow-up in MS.</p>
</sec>
<sec id="s2">
<label>2.</label>
<title>Results</title>
<sec id="s2a">
<label>2.1</label>
<title>Challenge data, computing platform and participating teams</title>
<p>The first major result of this study is the gathering of a database of 53 multiple sclerosis patients with &#x201C;ground truth&#x201D; of very high-quality. The database patient scans were following the OFSEP protocol recommendations in [<xref ref-type="bibr" rid="c9">9</xref>], which is currently applied in France for the constitution of the national cohort in MS (for more details on the protocol, see <xref ref-type="sec" rid="s4a">Section 4.1</xref>). Following this approach has allowed for an evaluation representative of the current imaging protocols standards and easily usable to characterize the best performing algorithm for future use. This standardization of imaging protocols announces how the dissemination of computer aided diagnosis and imaging biomarkers solutions will be implemented in the future. Image processing algorithms indeed need image normalization and quality control to ensure peak performance. In addition, the images came from three different sites in France on four different MRI scanners and different manufacturers (Siemens, Philips and GE) including three 3T and one 1.5T magnets. For each MS patient case, an unprecedented number of seven manual delineations was gathered, from trained experts split over the three sites providing MR images. From these segmentations, a consensus &#x201C;ground truth&#x201D; segmentation was built for evaluation with the LOP STAPLE algorithm [<xref ref-type="bibr" rid="c10">10</xref>]. We present in <xref ref-type="fig" rid="fig1">Fig. 1</xref> an example of a patient 3D FLAIR, the seven manual segmentations of lesions and their consensus segmentation, illustrating the variability for a representative patient between expert segmentations. Patients demographic data were the following: average age of 45.3 years (&#x00B1; 10.3 years) with a male:female ratio of 0.4. This database was then split into two sets: one training set of 15 patients from three scanners (thus intentionally missing one scanner from the database) given to participants, and one testing set of 38 patients, not seen by the participants, used for evaluation. Demographics of patients do not vary significantly over the different sitesin terms of age. Some variations exist in the male:female ratios in some centers. The training and testing sets have an average age difference of 5 years (training set patients are 5 years younger).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label><caption><p>Illustration of an MS patient delineations overlaid on the 3D FLAIR image. (ag): individual manual delineations of MS lesions from each of the experts, (h): consensus segmentation considered as the ground truth.</p></caption>
<graphic xlink:href="367557_fig1.tif"/>
</fig>
<p>A total of thirteen teams were evaluated, and the website (<ext-link ext-link-type="uri" xlink:href="http://portal.fli-iam.irisa.fr/msseg-challenge/">http://portal.fli-iam.irisa.fr/msseg-challenge/</ext-link>), databases and algorithms will remain open for future use. A summary of the evaluated methods is presented in <xref ref-type="table" rid="tbl1">Table 1</xref> with a short description of their characteristics (MR sequences used as input, implementation, main methodology). The algorithms evaluated in the challenge are representative of a broad range of the available methods in the recent literature, with unsupervised tissue classification methods, level-sets, random forests and deep learning (convolutional neural network, artificial neural networks). Depending on the challenger team, the image modalities used for the segmentation varied from just one (usually FLAIR) to all provided modalities. Most evaluated algorithms ran on regular computer CPU, while two (team 6 and 12) leveraged specific hardware (GPUs) for intensive computation (e.g. deep learning). The computing infrastructure was able to provide the relevant computing solution for all requirements.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label><caption>
<title>MS lesion segmentation methods evaluated at the MICCAI 2016 challenge</title></caption>
<graphic xlink:href="367557_tbl1.tif"/>
</table-wrap>
<p>These teams were evaluated in a distributed Web platform based on software containers provided by the France Life Imaging platform, allowing for the automatic, challenger independent evaluation of the algorithms (see <xref ref-type="sec" rid="s4c">Section 4.3</xref> for more details on the challenge execution platform). Using such a platform, providing integrated storage and computing facilities for challenges, allowed for fair comparisons as challengers could not tune their algorithm specifically for each test patient. Each challenger was indeed asked only to provide a binary image (i.e. an annotated Docker container image) of their processing pipeline and the evaluation was later on run automatically on the platform with the following metrics used.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Two kinds of performance metrics were set up for evaluation</title>
<p>Clinicians evaluate lesion segmentation in multiple sclerosis with different criteria. Lesion segmentation precision, i.e. the precision of contours delineated for each lesion, is crucial as the total volume of lesions (total lesion load - TLL) is part of the criteria to evaluate disease severity [<xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c34">34</xref>]. When coming to pathology evolution or treatment efficiency evaluation however, lesion count and particularly the number of new lesions independently of their sizes is key. Moreover, this lesion count is a crucial component of MS diagnosis according to McDonald criteria [<xref ref-type="bibr" rid="c2">2</xref>]. For these tasks, detecting all lesions is more important than their precise contours. We have therefore implemented a large set of evaluation measures for the challenge with the goal of evaluating these different aspects. Evaluation in the following is therefore split into three major categories of evaluation metrics:</p>
<list list-type="bullet">
<list-item><p>Segmentation evaluation: does the algorithm provide a precise delineation of each lesion? This category includes average surface distance and Dice overlaps as the main metrics</p></list-item>
<list-item><p>Lesion detection evaluation: does the algorithm find all lesions in the image independently of its precise delineation? This category includes the <italic>F</italic><sub>1</sub> score, gathering in one scalar information on the number of lesions correctly and incorrectly detected</p></list-item>
</list>
</sec>
<sec id="s2c">
<label>2.3.</label>
<title>All methods are outperformed by the experts</title>
<p>We have automatically clustered the average algorithms and experts annotations agreements (with their covariances accounted for) with respect to the &#x201C;ground truth&#x201D; (see <xref ref-type="sec" rid="s4d">Section 4.4</xref> for more details). Results of this clustering, illustrated in <xref ref-type="fig" rid="fig2">Fig. 2</xref> for all couples of measures considered in the challenge, highlight a major result of the challenge: over all patients and all evaluation metrics, each individual method performs slightly below all experts. On all graphs in <xref ref-type="fig" rid="fig2">Fig. 2</xref>, all experts (and only them) are indeed always grouped in a single cluster that performs better than all automatic algorithms. Two other clusters are also distinguished in these graphs, which vary depending on the evaluation metric, that regroup better performing and lower performing algorithms for each couple of evaluation metrics.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label><caption>
<title>Graphical results illustration of automatic clustering of average results for each team and expert into three groups (scatter plots of pairs of two evaluation parameters:</title>
<p>(a): Dice and <italic>F</italic><sub>1</sub> scores, (b): surface distance and <italic>F</italic><sub>1</sub> scores, (c): surface distance and Dice scores). Legend: blue crosses: group 1 (always containing only the seven experts even though the clustering is automatic), green crosses: group 2 (best performing algorithms), red crosses: group 3 (lower &#x201C;quality&#x201D; algorithms). Team numbers associated with each point on the graph are indicated as labels. Team fusion indicates a composite segmentation result further discussed in <xref ref-type="sec" rid="s2e">Section 2.5</xref>.</p></caption>
<graphic xlink:href="367557_fig2.tif"/>
</fig>
<p>In those graphs, we can additionally study the performance of automatic algorithms with regards to each evaluation metric considered (average surface distance, Dice score and <italic>F</italic><sub>1</sub> score). Automatic methods fail much more on the detection of lesions (F score), with a minimum average score of 0.13 and maximum average of 0.49, while the minimum average score obtained by an expert is 0.66 (significant difference, Wilcoxon signed rank test, <italic>p</italic> &#x003D; 3.7 &#x00D7; 10<sup>&#x2212;5</sup>). This is understandable however as all algorithms are primarily designed to obtain the best segmentation scores while not considering lesion detection which is a somewhat different task. However, even on the Dice score, which is a segmentation metric, the best automatic method performs lower than the lowest expert average score: it reaches an average of 0.59 while the lowest expert is on average at 0.67 (significant difference, Wilcoxon signed rank test, <italic>p</italic> &#x003D; 2.9 &#x00D7; 10<sup>&#x2212;3</sup>). The average surface distance is a more balanced metric in terms of results with the second group of algorithms in each graph reaching the level of agreement that the experts do with the consensus.</p>
</sec>
<sec id="s2d">
<label>2.4.</label>
<title>Segmentation on an unknown scanner leads to poorer performance</title>
<p>Scanner 3 in the testing database was unknown to the teams participating to the challenge. On this center, we have evaluated how automatic algorithms performed without knowing the image characteristics beforehand. The results of this comparison highlight for a large number of automatic algorithms a slight decrease in performance when encountering unknown images, even if they come from a common protocol. This evaluation per center and per evaluation metric is presented in <xref ref-type="fig" rid="fig3">Fig. 3</xref>.</p>
<p>Looking closer at the graphs in <xref ref-type="fig" rid="fig3">Fig. 3</xref>, we can observe for the detection metric (<italic>F<sub>1</sub></italic> score, <xref ref-type="fig" rid="fig3">Fig. 3.b</xref>) a slight decrease for 8 teams among the thirteen evaluated, leading to an average score over all teams of 0.22 for center 3 while the same automatic methods range between 0.32 and 0.39 for other centers. The same trend can be observed for the Dice score segmentation metric (<xref ref-type="fig" rid="fig3">Fig. 3.a</xref>) with a slight decrease in performance for 8 teams as well, and an average score over all teams of 0.38 while the same algorithms reach a level ranging between 0.48 and 0.50 on other centers. The observations are different for the average surface distance (<xref ref-type="fig" rid="fig3">Fig. 3.c</xref>), where results for center 3 are at the same level as center 8, however the variance in results is much higher, preventing from finding any statistically significant difference on that metric.</p>
</sec>
<sec id="s2e">
<label>2.5.</label>
<title>Combining methods through label fusion improves over individual algorithms</title>
<p>In addition to the individual automatic algorithms, we have evaluated a composite team named &#x201C;team fusion&#x201D;. This method gathered the other thirteen teams segmentations in a consensus through label fusion using the LOP STAPLE algorithm [<xref ref-type="bibr" rid="c10">10</xref>]. The goal of this fourteenth method was to evaluate the capability of such a label fusion method to overpass the individual difficulties of each method and thus obtain results closer to the ground truth. We present the results of this evaluation on the different evaluation metrics in <xref ref-type="fig" rid="fig4">Fig. 4</xref>.</p>
<p>This composite algorithm improves the average results the average results of individual automatic algorithms for all metrics, suggesting its ability to incorporate the best of each team into a consensus segmentation, better in line with the experts. These results are confirmed by points &#x201C;Team fusion&#x201D; in the clustering graphs in <xref ref-type="fig" rid="fig2">Fig. 2</xref>. However, the results obtained are still not perfect and lag behind the experts level of agreement with the &#x201C;ground truth&#x201D;. More precisely, the improvement of team fusion over other algorithms is particularly visible on segmentation metrics (Dice scores and average surface distance) since it provides segmentation performances similar to the lowest experts. This improvement is however less important on the detection metric (<italic>F<sub>1</sub></italic> score). This smaller improvement seems logical as the label fusion algorithm used for team fusion is primarily designed to optimize segmentation performance and not specifically detection. With that said, the first position of Team fusion among the segmentation methods illustrates how a composite algorithm mixing results of other teams is able to perform better than each individual automatic method. This also illustrates the importance to provide an open-science computing platform able to combine results of independent algorithms.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label><caption><p>Dice scores (a), <italic>F</italic><sub>1</sub> scores (b) and average surface distances (c) with respect to the consensus per team for each center and averaged over all centers.</p></caption>
<graphic xlink:href="367557_fig3.tif"/>
</fig>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label><caption><p>Dice scores (a), <italic>F</italic><sub>1</sub> scores (b) and average surface distances (c) with respect to the consensus for each center and averaged over all centers for composite Team fusion with respect to the average experts agreement level.</p></caption>
<graphic xlink:href="367557_fig4.tif"/>
</fig>
</sec>
<sec id="s2f">
<label>2.6.</label>
<title>Lesion load and lesion size directly influences automatic segmentation quality</title>
<p>We additionally performed an experiment to evaluate, independently of their individual behaviors, the algorithms sensitivity to the true amount of lesions in the &#x201C;ground truth&#x201D; for a given patient. To this end, we averaged the Dice scores (respectively the average surface distances and <italic>F</italic><sub>1</sub> scores) over all methods for each patient and plotted in <xref ref-type="fig" rid="fig5">Fig. 5</xref> this average value with respect to either the number of lesions or the total lesion load in the consensus. On each graph, we then computed a log-linear regression for which we display the Spearman squared correlation.</p>
<p>From <xref ref-type="fig" rid="fig5">Fig. 5</xref>, it is clear that the worst results are obtained for patients whose total lesion load is low. This is especially true for segmentation performance scores: the Dice score (the squared correlation <italic>R<sup>2</sup></italic> of the regression reaches 0.82) and the average surface distance (<italic>R<sup>2</sup></italic> of 0.71). For the <italic>F</italic><sub>1</sub> score (a detection metric), the correlation is however weaker than for the total lesion load (<italic>R<sup>2</sup></italic> of 0.45). From these graphs, the correlation between the number of lesions and the obtained scores is less clear, all correlations being smaller than with the total lesion load (<italic>R<sup>2</sup></italic> of 0.46 with the Dice score, 0.38 with the <italic>F</italic><sub>1</sub> score, and 0.60 with the average surface distance). This result however seems reasonable since a patient presenting many small lesions is intuitively more difficult to delineate than a patient with a small number of large lesions.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label><caption><p>Link between average scores of all methods and number of lesions (first column) and total lesion load (cm<sup>3</sup>, second column). First line: Dice score, second line: <italic>F</italic><sub>1</sub>, third line: average surface distance.</p></caption>
<graphic xlink:href="367557_fig5.tif"/>
</fig>
<p>Total lesion load in a patient is thus very correlated with segmentation and detection scores while not with the number of lesions. To further qualify this fact, we performed an experiment considering detection scores individually for each lesion in regard of its volume. We have thus computed, for each team and for each lesion of the &#x201C;ground truth&#x201D; of each patient, a binary detection score telling whether the lesion was detected or not by a specific team. Counting the number of teams which detected the lesion thus provides us with a rate of detection for each lesion (a rate of 0&#x0025; meaning that no team detected the lesion, and 100&#x0025; meaning that all teams detected the lesion). Those detection rates were further binned according to lesion volume. The graph in <xref ref-type="fig" rid="fig6">Fig. 6</xref> illustrates their relation with respect to lesion volume (in mm<sup>3</sup>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label><caption><p>Individual lesion detection rate (average over all methods) as a function of lesion size. X-axis: individual lesion volume on a logarithmic scale. Y-axis: detection rate (in percentages, number of teams detecting a lesion of this volume over all patients).</p></caption>
<graphic xlink:href="367557_fig6.tif"/>
</fig>
<p>From <xref ref-type="fig" rid="fig6">Fig. 6</xref>, we can clearly see that not only total lesion load influences segmentation quality, but lesion volume is also clearly linked with lesion detection (<italic>R<sup>2</sup></italic> of 0.88 after a logarithmic linear regression). All methods tend to fail (rates of detection going to zero) for small lesions, while almost all teams are detecting the lesions when their volume is sufficiently large.</p>
</sec>
<sec id="s2g">
<label>2.7.</label>
<title>Delineating an image with empty consensus</title>
<p>We finally present in <xref ref-type="table" rid="tbl2">Table 2</xref> results obtained by each expert and each evaluated pipeline on a specific case, from Center 7, where no lesion was present in the consensus segmentation. In this specific case, none of the proposed detection and segmentation measures can be used since they all rely on the fact that the consensus is not empty. We thus instead defined two specific metrics: the number of lesions detected (i.e. the number of connected components whose size is larger than 3 mm<sup>3</sup> in the segmentation), and the total lesion load (i.e. the total volume of the previously extracted connected components) found by each algorithm. For both metrics, since the consensus contains no lesions, a perfect value is 0 while the results get worse when the metrics grow.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label><caption>
<title>Number of lesions and lesion volume detected by each team and expert on the no consensus lesion case.</title></caption>
<graphic xlink:href="367557_tbl2.tif"/>
</table-wrap>
<p>Several observations may be drawn from this table. First of all, among experts, two delineated no lesions while five actually delineated one or several lesions (from one to 8 depending on the expert, and from 0.02 to 11 cm<sup>3</sup>). The fact that the consensus is empty therefore means that the experts were not agreeing on the position and extent of lesions, which lead to no lesions in the final &#x201C;ground truth&#x201D;. Among the automatic segmentation pipelines, the results are also largely varying: depending on the team, the number of lesions delineated varies from 0 to 522, while the lesion load detected varies from 0 to 28.44 cm<sup>3</sup>. In addition, this image caused problems to some algorithms not initially designed for patients without lesions (team 4). This is an interesting case as it highlights the different behaviors of the algorithms on a case for which the pipelines were not designed. Overall, we can notice that most of the methods behave well in comparison to the experts.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>Discussion</title>
<p>We have presented the first challenge based on an integrated computing platform, applied to multiple sclerosis lesions segmentation. The challenge computing platform was constituted of 1- a database to store the challenge images and results from the challengers, 2- a computing platform on which the evaluation was performed independently of the participants who were asked to post their processing pipelines, and 3- an automatic evaluation of the results against the &#x201C;ground truth&#x201D;. This open-science computing platform has many advantages, including a fair comparison of the participants algorithms being run on the same platform and with the same set of parameters for all patients. In addition, the packaged algorithms may be re-used for other applications or if the validation database gets extended. As future work, we plan at transitioning to use the BIDS format (<ext-link ext-link-type="uri" xlink:href="http://bids.neuroimaging.io">http://bids.neuroimaging.io</ext-link>) to provide a standardized and more intuitive way of storing both the input data and output results. This would provide a great improvement in easing the pipeline design and integration in the platform.</p>
<p>This platform was put together for the specific organization of a challenge on multiple sclerosis segmentation with a database of 53 patients each with an unprecedented number of seven manual segmentations from trained experts. A total of thirteen teams participated, illustrating the variety of algorithms both in terms of methodology and implementation. All results computed from the challenge were very insightful and revealed several points worth of discussion. First of all, despite that methods vary in their results, the point where a single automatic method is able to perform as well as the consensus of the experts has not yet been reached. The experts are indeed always slightly better than any method for all performance measures. More specifically, all methods perform relatively poorly on detection metrics, which is however an important point for MS diagnostic and clinical evaluation of the patient evolution. Historically all methods have been interested in segmenting well the contours of the lesions rather than counting well the number of lesions. As a consequence the detection metrics are not optimal, which explains why results are well below the experts. On a more positive point, recent methods such as those based on machine learning (especially deep learning) have made great progress and the gap is reducing, which leaves hope to reach the same level of agreement than the experts. In addition, it should be remembered that it is always difficult to define a &#x201C;ground truth&#x201D; for MS lesions segmentation. The experts have indeed a relatively large variability, which comes from different appreciations of the image and of the definition of a lesion. Finally on this point, it is also interesting to note that a composite method for segmentation (team fusion) combining the different automatic methods while rejecting outliers is able to drastically improve segmentation results and get closer to the ground truth. However, this happens mainly for segmentation performance metrics and less for detection performance metrics. This may be due to the inherent design of the label fusion methods that do not work on a lesion basis but rather on a voxel basis, and thus favor segmentation based metrics. In addition, since many methods fail at delineating well lesions when the total lesion load is small (see <xref ref-type="fig" rid="fig5">Fig. 5</xref>), this composite method is not able to perform a good segmentation for these cases.</p>
<p>We have also illustrated through this challenge the behavior of methods in several specific cases: testing for scanner dependency of the algorithms, where we compared the results for four different scanners, one of them being hidden from the training dataset. This study illustrated that all methods are still sensitive to scanners on which they were not trained for (either training in the machine learning sense or training in the sense of parameters tuning by a human being), obtaining lower scores for those images. On the contrary, when the training set included representative images of different scanners, all algorithms behaved equally independently of the center or scanner. This suggests the importance of looking for more training independent methods or, meanwhile, to have enough representative cases to train on (at the high cost of providing multiple manual image annotations from experts). A second specific case considered a patient with no lesions in the ground truth provided from the experts. For that patient, even if some methods had not planned this case, all methods behaved globally well even though participants were not told in advance about this fact.</p>
<p>While not mentioned explicitly in this article, we also looked at the relation between algorithm performance and preprocessing or modalities used. For both aspects, there is no clear evidence of a link. Some algorithms perform well while using only a subset of modalities, while some other that use all modalities perform less well. However the reverse is also true: some of the best algorithms use all modalities while some less good ones use a smaller number of modalities. This is however a crucial aspect as information on this could help in the design of shorter acquisition protocols in the future, using only those modalities useful for automatic segmentation. Future works, which have to be in close link with the challenge participants (but facilitated thanks to our computing platform), will look at the robustness of results of the individual algorithms with respect to both preprocessing used and modalities used. This will provide a great insight into optimal, fast protocol design and optimal preprocessing.</p>
<p>We have clearly demonstrated in <xref ref-type="fig" rid="fig5">Fig. 5</xref> a link between the total lesion load in a patient and the performance of segmentation methods: the smaller the true total lesion load, the worse the segmentation results were for every metric. As mentioned earlier, this is partly linked to the fact that voxel-based performance metrics are much more sensitive when the number of voxels in the true segmentation is small. However, this is not the only reason: automatic segmentation methods are indeed behaving slightly worse on these cases and a focus on them should probably help in designing algorithms adapted to all situations. This link between performance and lesion load does not generalize to the number of lesions (also seen in the same figure), which illustrates that there is no clear sensitivity of the methods to the number of lesions for a patient. However, this link is clearly related to a correlation between lesion volume and lesion detection rate, as demonstrated in <xref ref-type="fig" rid="fig6">Fig. 6</xref>. This further indicates that lesions are clearly less well detected or even not at all when they are small, which seems rather logical as it intuitively seems tougher for an algorithm to properly locate a small lesion than a larger one.</p>
<p>Evaluation metrics presented in this article are a selection per category (segmentation and detection) of the metrics described in <xref ref-type="sec" rid="s4d">Section 4.4</xref> and computed for the challenge. We chose them as being representative and most informative of the main qualities and defaults of the algorithms. Of course, as illustrated for more general segmentation evaluation purpose [<xref ref-type="bibr" rid="c35">35</xref>], three metrics may not be enough for describing the behavior of each method in its entirety. As explained in <xref ref-type="sec" rid="s4">Section 4</xref>, we have complemented these three measures with many other complementary measures, for which we encourage the interested reader to look at the supplementary materials (<bold><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5281/zenodo.1307653">http://dx.doi.org/10.5281/zenodo.1307653</ext-link></bold>).</p>
</sec>
<sec id="s4">
<label>4.</label>
<title>Methods</title>
<p>We present in the following the methodological details that allowed us to draw the results and conclusions previously outlined. This section is split in several subparts. <xref ref-type="sec" rid="s4a">Sections 4.1</xref> and <xref ref-type="sec" rid="s4b">4.2</xref> present in more details the evaluation database used in the challenge and the way in which the manual delineations were carried out and averaged into a &#x201C;ground truth&#x201D;. <xref ref-type="sec" rid="s4c">Section 4.3</xref> then outlines the computing platform used in the challenge which was necessary to guarantee a fair comparison of the algorithms. Finally, <xref ref-type="sec" rid="s4d">Section 4.4</xref> presents the evaluation metrics used in the challenge as well as the analyses plan derived from them in this article.</p>
<sec id="s4a">
<label>4.1.</label>
<title>Reference Images Database</title>
<p>In this segmentation evaluation challenge, we relied on a database of images of 53 multiple sclerosis patients following the OFSEP protocol recommendations in [<xref ref-type="bibr" rid="c9">9</xref>], which is currently applied in France for the constitution of the national cohort of MS patients. Following this approach allows for an evaluation representative of the current standards and easily usable for newly acquired images. For our challenge, images came from three different sites in France on four different MRI scanners from different manufacturers (Siemens, Philips and GE) including three 3T and on 1.5T magnets. The repartition of the 53 patients is shown in <xref ref-type="table" rid="tbl3">Table 3</xref>. More demographic details on the ages and gender repartitions into the training and testing groups are provided in supplementary material (<bold><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5281/zenodo.1307653">http://dx.doi.org/10.5281/zenodo.1307653</ext-link></bold>). Overall, no significant difference of age can be seen between the different centers. While gender differences exist between some centers (in particular center 8), we believe this is of little importance with regard to lesion segmentation and detection quality compared to scanner to scanner differences.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label><caption><p>Demographics data of multiple sclerosis patients collected for the challenge and their repartition among training and testing datasets.</p></caption>
<graphic xlink:href="367557_tbl3.tif"/>
</table-wrap>
<p>These patients were selected to have variable amounts of lesions both in volume and number, and from different centers to represent the variability that may be encountered across sites. For each patient, the following images were provided for each MS patient (see details of the sequence parameters in <xref ref-type="table" rid="tbl4">Table 4</xref>): a 3D FLAIR sequence, a 3D T1 weighted sequence pre and post-Gadolinium injection, an axial dual PD-T2 weighted sequence. These patients were then split (see <xref ref-type="table" rid="tbl3">Table 3</xref>) between a training and testing datasets. The testing dataset was not made available to the challengers and was used to evaluate the different methods while the training dataset was provided, together with the ground truth segmentations, for challengers to train their algorithms. Images acquired on one center (3) were not part of the training dataset, with the goal of evaluating how much algorithms were dependent on the training set and sensitive to acquisition settings.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label><caption><p>Acquisition details for each sequence and each scanner for the training and testing MS patients databases.</p></caption>
<graphic xlink:href="367557_tbl4.tif"/>
</table-wrap>
<p>For each patient, the challenge data includes raw datasets, and preprocessed datasets where the following steps were performed:</p>
<list list-type="bullet">
<list-item><p>Denoising of each modality using the non local means algorithm [<xref ref-type="bibr" rid="c36">36</xref>]</p></list-item>
<list-item><p>Rigid registration of each modality on the FLAIR image [<xref ref-type="bibr" rid="c37">37</xref>]</p></list-item>
<list-item><p>Brain extraction (skull stripping) using the volBrain platform [<xref ref-type="bibr" rid="c38">38</xref>], from the T1-w image and applied to other modalities</p></list-item>
<list-item><p>Bias field correction of each modality using the N4 algorithm [<xref ref-type="bibr" rid="c39">39</xref>]</p></list-item>
</list>
</sec>
<sec id="s4b">
<label>4.2.</label>
<title>MS Lesions Ground Truth</title>
<p>Based on manual segmentation on our MS database, we first aimed at getting ground truth segmentations of multiple sclerosis lesions. This task is difficult and variability exists between experts depending on various factors, even when they follow common protocol, depending on many factors (image quality, training, modalities&#x2026;). We chose to build for this challenge an unprecendented set of seven manual delineations for each patient. These delineations were performed manually on the 3D FLAIR image with control on the T2 weighted image. Each manual segmentation was performed by a trained junior expert, validated and corrected under the supervision of senior radiologists with a long experience in multiple sclerosis. More specifically, a first meeting between senior radiologists and workshop organizers of each site took place to determine the segmentation strategy and adopt a common tool (ITK-Snap) to perform manual segmentation. Junior radiologists were then recruited on each site and trained by the expert radiologists on a separate training set and when their agreement was above a threshold of 80&#x0025;, they were allowed to delineate the 53 patient cases. Each case was segmented in isolation of the other cases to limit possible bias. Segmentation experts were split between the three sites which provided the patient images: 4 in Lyon, 2 in Rennes and one in Bordeaux.</p>
<p>MS lesions segmentation is known to be expert- and center-dependent, which can lead to relatively large discrepancies between individual manual segmentations. To cope with this problem, we computed for each patient a consensus segmentation by using the Logarithmic Opinion Pool Based STAPLE (LOP STAPLE) algorithm proposed by [<xref ref-type="bibr" rid="c10">10</xref>]. This algorithm computes iteratively, using an Expectation-Maximization approach, a consensus segmentation based on penalties for individual deviations from agreement between manual experts segmentations. This algorithm has several advantages: it is robust to differences between manual expert segmentations, and it allows the computation of agreement scores with respect to the consensus segmentation considered then as ground truth.</p>
</sec>
<sec id="s4c">
<label>4.3.</label>
<title>Computing Architecture for Automatic MS Lesions Segmentation Evaluation</title>
<p>One of the critical aspects in performing an independent challenge and benchmarking of medical image processing solutions is to provide a unified infrastructure able to:</p>
<list list-type="bullet">
<list-item><p>anonymize and upload the training and testing data in a single place that all participants can access though the Web</p></list-item>
<list-item><p>integrate and execute the image processing algorithms through a web-based portal where all algorithms are executed on the test dataset in identical conditions</p></list-item>
<list-item><p>host the processed images and make them available to the participants</p></list-item>
<list-item><p>provide a cloud-based integrated solution with interoperable distributed resource management systems</p></list-item>
</list>
<p>Most of the past and existing challenges in the field of image processing were able to provide part of these solutions but none of them was able to provide a computing solution able to perform all of these tasks seamlessly.</p>
<p>We used the France Life Imaging (FLI) - Information Analysis and Management (IAM) (FLI-IAM in short) computing infrastructure for this challenge. FLI is a national infrastructure, which aims to coordinate and harmonize the network of resources on in-vivo imaging in France. Its IAM node represents the computing node of France Life Imaging (<bold><ext-link ext-link-type="uri" xlink:href="https://www.francelifeimaging.fr/en/about/noeuds/iam/">https://www.francelifeimaging.fr/en/about/noeuds/iam/</ext-link></bold>). This architecture allows (see <xref ref-type="fig" rid="fig7">Figure 7</xref>) the storage and management of preclinical and clinical <italic>in vivo</italic> imaging data and offers services of images processing and analysis.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption>
<title>FLI-IAM architecture</title></caption>
<graphic xlink:href="367557_fig7.tif"/>
</fig>
<p>FLI-IAM is based on existing, technologically ready software solutions, coming from multiple research teams over France. It proposes a web portal (blue box in <xref ref-type="fig" rid="fig7">Fig. 7</xref>) to unify the access to all resources and tools and provides multiple solutions for storage and computation on medical images.</p>
<p>To operate this challenge, three components of the entire FLI-IAM portfolio have been used:</p>
<list list-type="bullet">
<list-item><p>Web portal</p></list-item>
<list-item><p>Shanoir (SHAring NeurOImaging Resources) for the database [<xref ref-type="bibr" rid="c40">40</xref>]</p></list-item>
<list-item><p>VIP (Virtual Imaging Platform) for the computing platform [<xref ref-type="bibr" rid="c41">41</xref>]</p></list-item>
</list>
<p>In addition to these three major components, additional tools/services have been developed to provide the required level of interoperability and to finally integrate all components into one unique workflow.</p>
<p>The web portal has been used as a communication platform with all challengers. All information concerning the challenge has been distributed there, e.g. the organizational aspects, dataset descriptions, evaluation details, etc. Challengers had to subscribe on the portal to participate in the challenge.</p>
<p>Shanoir (SHAring NeurOImaging Resources) served as central database for all datasets necessary for the challengers, all their processed results and challenger&#x2019;s scores. Shanoir is an open source neuro-informatics platform designed to share, archive, search and visualize neuroimaging data. It provides a user-friendly secure web access and offers an intuitive workflow to facilitate the collection and retrieval of neuroimaging data from multiple sources. Shanoir comes along many features such as anonymization of data, support for multi-center clinical studies on subjects or group of subjects.</p>
<p>VIP (Virtual Imaging Platform) provided all necessary resources for the integration and the execution of all challenger processing pipelines. The pipelines were provided by challengers as Docker containers and were integrated into VIP using the Boutiques application repository. Boutiques relies on Linux containers to solve the problem of application installation in a lightweight manner and it uses a versatile JSON format to describe command line tools. VIP also ensured the execution of the challenger pipelines (and the subsequent segmentation performance analysis) on the computing resources available for the challenge.</p>
<p><xref ref-type="fig" rid="fig8">Figure 8</xref> gives an overview of the integration level between database and computing platform and describes the workflow that was set up for the hosting of the challenge.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8:</label><caption>
<title>Workflow for database and computing platform integration.</title></caption>
<graphic xlink:href="367557_fig8.tif"/>
</fig>
<p>After the preparation of the challenge data, all source datasets were imported into Shanoir. The training data were shared with the challengers using the portal and its file download feature. The testing data was processed by VIP using a static export folder exported from the database - containing all necessary metadata from the database to import results back into the database and attach them to the source dataset for each challenger.</p>
<p>After the algorithms produced their results, the segmentation performance analysis (including all measures described in the next section) was run to compare challengers results with the consensus ground truth and calculate the scores. The continuously running DataTransferModule has been connected to the results folder of VIP to automatically import back the result datasets into Shanoir. All result datasets and their corresponding scores have been made available in Shanoir for challengers. The challenge organization team could then easily access the scores summary within Shanoir.</p>
</sec>
<sec id="s4d">
<label>4.4.</label>
<title>Challenge Evaluation Strategy and Metrics</title>
<p>Using the computing platform, challengers were asked to provide algorithms delineating lesions in the FLAIR reference space. This was asked to match the space in which the manual delineations were carried out and therefore avoid any unwanted discrepancies due to interpolation of the challengers&#x2019; results. To evaluate these results, we have implemented a large set of evaluation measures for the challenge with the goal of evaluating the different aspects evaluated by clinicians when looking at MS patient images. For this reason, we have separated the evaluation into two major categories of evaluation metrics:</p>
<list list-type="bullet">
<list-item><p>Segmentation evaluation: does the algorithm provide a precise delineation of each lesion?</p></list-item>
<list-item><p>Lesion detection evaluation: does the algorithm find all lesions in the image independently of its precise delineation?</p></list-item>
</list>
<p>Each of these categories may contain several metrics that characterize differently the segmentation quality. We describe in more details each of the chosen metrics for the challenge in the following sections. All evaluation algorithms used for this paper are available open-source as part of the Anima software (<bold><ext-link ext-link-type="uri" xlink:href="http://github.com/Inria-Visages/Anima-Public">http://github.com/Inria-Visages/Anima-Public</ext-link></bold>). Although not presented in this article (but available as part of supplementary material <bold>(<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5281/zenodo.1307653">http://dx.doi.org/10.5281/zenodo.1307653</ext-link>)</bold>, we remind the strategy that was used at the challenge to rank, for each of these metrics, the different methods on all patients:</p>
<list list-type="bullet">
<list-item><p>For each patient, compute the selected metric for each algorithm by comparing it to the ground truth previously computed</p></list-item>
<list-item><p>For each patient, rank the algorithms according to the selected metric (from 1: best performing to <italic>N</italic>: worst performing)</p></list-item>
<list-item><p>Compute for each algorithm its average ranking over all patients evaluated. This average rank is used for the final ranking of the methods</p></list-item>
</list>
<p>We had selected this approach instead of simply averaging the metric scores for each algorithm to avoid a bias of some methods that would get a few very good metric scores that would not represent their true behavior. This approach instead considers as the best method the one that ranks the best on average for all patients evaluated, thereby discarding this bias problem. Instead in this work, we focus more on the graphical analysis of the cluster analysis of the algorithms with respect to the experts who delineated the structures. To this end, we performed a multi-parametric analysis of the results. For each couple of metrics presented in the following (average surface distance, Dice score and <italic>F</italic><sub>1</sub> score), we computed a 2D scatter representation of the average results on all testing patients of each of the teams and of the experts. Since different clusters of results quality may be outlined by such graphs, we then ran for each combination of metrics a clustering into three groups of the average performance of the teams and experts. For this clustering to be precise enough however, we need to account for the variance around the average points. We have therefore chosen to perform a spectral clustering [<xref ref-type="bibr" rid="c42">42</xref>], considering each point of the 2D graph not as a mean but as a multivariate Gaussian, using a distance between multivariate Gaussians as expressed in [<xref ref-type="bibr" rid="c43">43</xref>], thus accounting for the covariance in the individual scores.</p>
<sec id="s4d1">
<label>4.4.1.</label>
<title>Segmentation evaluation</title>
<p>The first category of evaluation metrics is also the most known in the literature and concerns segmentation evaluation, i.e. are the contours of the lesions precisely delineated compared to the ground truth. In this group, we distinguish two sub-categories, each quantifying the precision of lesions delineation: overlap-based and surface-based metrics. In the following, we will consider two binary images representing respectively the lesions consensus (i.e. the ground truth): <italic>G</italic>, and the evaluated segmentation (i.e. one algorithm segmentation result): <italic>A</italic>, both illustrated in <xref ref-type="fig" rid="fig9">Fig. 9</xref>.</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9:</label><caption>
<title>Illustration of overlap-based segmentation evaluation: quantities used for measures computation. <italic>A</italic> denotes the evaluated segmentation, <italic>G</italic> the ground truth, and <italic>B</italic> the image domain.</title></caption>
<graphic xlink:href="367557_fig9.tif"/>
</fig>
<p><italic>Overlap metrics</italic>. These measures consider the voxel-based overlap of A and G based on the quantities illustrated in <xref ref-type="fig" rid="fig9">Fig. 9</xref>. Among those measures, we use the following ones:
<list list-type="bullet">
<list-item><p>Dice score [<xref ref-type="bibr" rid="c44">44</xref>]: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline1.gif"/></alternatives></inline-formula></p></list-item>
<list-item><p>Positive predictive value: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline2.gif"/></alternatives></inline-formula></p></list-item>
<list-item><p>Sensitivity: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline3.gif"/></alternatives></inline-formula></p></list-item>
<list-item><p>Specificity: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline4.gif"/></alternatives></inline-formula></p></list-item>
</list>
where <italic>A</italic> &#x222A; <italic>G</italic> is computed from other quantities: <italic>A</italic> &#x222A; <italic>G</italic> &#x003D; <italic>A</italic> &#x2229; <italic>G</italic> &#x002B; <italic>A</italic>\<italic>G</italic> &#x002B; <italic>G</italic>\<italic>A</italic>. For all formulas in this section, the notation |.| denotes taking the cardinal of a set of voxels, e.g. |<italic>A</italic> &#x2229; <italic>G</italic>| denotes the number of voxels in that set. As a final remark for this category, the choice of the size of image <italic>B</italic> is quite important as it will influence specificity. A too large region for <italic>B</italic> could indeed lead all specificity values to be very close to 1 by construction and therefore make them difficult to compare. We therefore chose for the challenge to compute <italic>B</italic> as the union of all available segmentations for a patient (automatic and manual), dilated three times by a 6-connectivity kernel.</p>
<p>Each overlap-based metric varies between 0 and 1, 1 being a perfect result and 0 the worst result. Each measure is however sensitive to a different phenomenon in the quality of segmentations: positive predictive value and specificity are influenced by false positives and are therefore sensitive to overly large segmentations; sensitivity is influenced by false negatives and is thus sensitive to overly small segmentations. Finally, the Dice score is a composite measure attempting to summarize all influences into a single scalar measure.</p>
<p><italic>Surface metric</italic>. In addition to overlap-based metrics, we have computed the average symmetric surface distance, also used in MICCAI 2008 challenge on MS lesions segmentation organized by [<xref ref-type="bibr" rid="c7">7</xref>]. Instead of using voxel-based overlaps, this measure uses contours extracted from the two input segmentations <italic>A</italic> and <italic>G</italic>, denoted respectively <italic>A<sub>S</sub></italic> and <italic>G<sub>S</sub></italic>. This distance is expressed as the following sum:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="367557_eqn1.gif"/></alternatives>
</disp-formula>
where <italic>d</italic> denotes the minimal Euclidean distance between a point of one surface and the other surface, <italic>N<sub>A</sub></italic> and <italic>N<sub>G</sub></italic> denote the number of points of each surface.</p>
</sec>
<sec id="s4d2">
<label>4.4.2.</label>
<title>Detection evaluation</title>
<p>As mentioned in the introduction, evaluation of the detection of lesions is as crucial, if not even more, as segmentation precision as the number of lesions is used for MS diagnosis. We wanted to evaluate in this category how many lesions have been (in)correctly detected, independently of the precision of their contours.</p>
<p><italic>Defining lesion detection</italic>. This whole category of measures relies on identifying individual lesions in the ground truth <italic>G</italic> and evaluated segmentations. For this task, we first compute the connected components of G and A (with a 18- connectivity kernel) and remove all lesions that are smaller in size than 3 mm<sup>3</sup>. We therefore get label images <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline5.gif"/></alternatives></inline-formula> and <italic>&#x00C3;</italic> where each label denotes a specific lesion.</p>
<p>From these two labeled images, two quantities are computed that will be used to characterize the detection power of an algorithm:</p>
<list list-type="bullet">
<list-item><p>TP<italic><sub>G</sub></italic>: the number of lesions among the <italic>M</italic> lesions in the ground truth <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline6.gif"/></alternatives></inline-formula> that are correctly detected by <italic>&#x00C3;</italic></p></list-item>
<list-item><p>TP<italic><sub>A</sub></italic>: the number of lesions among the <italic>N</italic> lesions in the automatic segmentation <italic>&#x00C3;</italic> that are correctly detected by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline7.gif"/></alternatives></inline-formula></p></list-item>
</list>
<p>Let us consider only the case of TP<sub><italic>G</italic></sub>, TP<italic><sub>A</sub></italic> being computed with the same procedure but reverting the roles of <italic>&#x00C3;</italic> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline8.gif"/></alternatives></inline-formula>. We first construct the joint histogram <italic>H</italic> of <italic>&#x00C3;</italic> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline9.gif"/></alternatives></inline-formula> where <italic>H<sub>i,j</sub></italic> corresponds to the number of voxels having label <italic>i</italic> &#x2208; {0 &#x2026; <italic>M</italic>} in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline10.gif"/></alternatives></inline-formula> and label <italic>j</italic> &#x2208; {0 &#x2026; <italic>N</italic>} in <italic>&#x00C3;</italic>. We consider a lesion <italic>j</italic> in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline11.gif"/></alternatives></inline-formula> (<inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline12.gif"/></alternatives></inline-formula><sub><italic>j</italic></sub>) to be detected if it respects the following rules:</p>
<list list-type="bullet">
<list-item><p>The lesion <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline13.gif"/></alternatives></inline-formula><italic>j</italic> is overlapped at least at a rate of &#x03B1;&#x0025; by lesions of <italic>&#x00C3;</italic></p></list-item>
<list-item><p>Lesions of <italic>&#x00C3;</italic> that contribute the most to the detection of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline14.gif"/></alternatives></inline-formula><italic>j</italic> (summing up to &#x03B3;&#x0025; of the total overlap) do not go outside of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline15.gif"/></alternatives></inline-formula><italic>j</italic> by more than <italic>&#x03B2;</italic>&#x0025;.</p></list-item>
</list>
<p>While the first condition ensures that the lesion to be detected is sufficiently overlapped, the second condition ensures that the detection is not due to an overly large segmentation in <italic>&#x00C3;</italic> that would overlap many lesions in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline16.gif"/></alternatives></inline-formula> by chance. These two conditions are implemented in <xref ref-type="statement" rid="Algorithm1">Algorithm 1</xref>.</p>
<statement id="Algorithm1">
<label>Algorithm 1</label>
<title>TP<sub><italic>G</italic></sub> computation algorithm</title>
<p><fig id="alg1" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="367557_alg1.tif"/>
</fig></p>
</statement>
<p>For the challenge, we used this algorithm with values heuristically defined on several independent tests to give meaningful values for TP<sub><italic>G</italic></sub> and TP<sub>A</sub>: <italic>&#x03B1;</italic> &#x003D; 10&#x0025;, &#x03B3; &#x003D; 65&#x0025;, <italic>&#x03B2;</italic> &#x003D; 70&#x0025;.</p>
<p><italic>Detection metrics</italic>. From the number of lesions <italic>M</italic> and <italic>N</italic> respectively in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline20.gif"/></alternatives></inline-formula> and <italic>&#x00C3;</italic>, and the numbers computed above (TP<sub><italic>G</italic></sub> and TP<sub><italic>A</italic></sub>), the following detection metrics are computed, named after their similarity to overlap-based metrics:</p>
<list list-type="bullet">
<list-item><p>Lesion sensitivity, i.e. the proportion of detected lesions in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline21.gif"/></alternatives></inline-formula></p></list-item>
<list-item><p>Lesion positive predictive value, i.e. the proportion of true positive lesions inside <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="367557_inline22.gif"/></alternatives></inline-formula></p></list-item>
</list>
<p>In addition to these two metrics, we have computed a summary metric to get, like the Dice score for segmentation metrics, a one-glance idea of the detection performance of a given method (0 meaning worst performance and 1 meaning perfect detection performance). This summary metric, the <italic>F</italic><sub>1</sub> score, considers both lesion sensitivity and positive predictive value to compute the score. It is defined as follows:</p>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="367557_eqn2.gif"/></alternatives>
</disp-formula>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was partly funded by France Life Imaging (grant ANR-11-INBS-0006 from the French &#x201C;Investissements d&#x2019;Avenir&#x201D; program) for funding and sponsoring the challenge. This work has also been partly supported by a grant (OF-SEP) provided by the French State and handled by the &#x201C;Agence nationale de la recherche&#x201D;, within the framework of the &#x201C;Investissements d&#x2019;Avenir&#x201D; program, under the reference ANR-10-COHO-002. We also thank the French national cohort OFSEP (a French &#x201C;Investissements d&#x2019;Avenir&#x201D; program), and particularly the imaging group inside this cohort consortium for their constant support, fruitful discussions on the challenge and providing the MR images.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Pugliatti</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rosati</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Carton</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Riise</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Drulovic</surname></string-name>, <string-name><given-names>L.</given-names> <surname>V&#x00E9;csei</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Milanov</surname></string-name>, <article-title>The epidemiology of multiple sclerosis in europe</article-title>, <source>European Journal of Neurology</source> (<volume>13</volume>) (<year>2006</year>) <fpage>700</fpage>&#x2013;<lpage>722</lpage>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>C. H.</given-names> <surname>Polman</surname></string-name>, <string-name><given-names>S. C.</given-names> <surname>Reingold</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Banwell</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Clanet</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Cohen</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Filippi</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Fujihara</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Havrdova</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Hutchinson</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Kappos</surname></string-name>, <string-name><given-names>F. D.</given-names> <surname>Lublin</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Montalban</surname></string-name>, <string-name><given-names>P.</given-names> <surname>O&#x2019;Connor</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Sandberg-Wollheim</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Thompson</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Waubant</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Weinshenker</surname></string-name>, <string-name><given-names>J. S.</given-names> <surname>Wolinsky</surname></string-name>, <article-title>Diagnostic criteria for multiple sclerosis: 2010 Revisions to the McDonald criteria</article-title>, <source>Annals of Neurology</source> <volume>69</volume> (<issue>2</issue>) (<year>2011</year>) <fpage>292</fpage>&#x2013;<lpage>302</lpage>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Leray</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Yaouanq</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Le Page</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Coustans</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Laplaud</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Oger</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Edan</surname></string-name>, <article-title>Evidence for a two-stage disability progression in multiple sclerosis</article-title>, <source>Brain</source> <volume>133</volume> (<issue>7</issue>) (<year>2010</year>) <fpage>1900</fpage>&#x2013;<lpage>1913</lpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Mortazavi</surname></string-name>, <string-name><given-names>A. Z.</given-names> <surname>Kouzani</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Soltanian-Zadeh</surname></string-name>, <article-title>Segmentation of multiple sclerosis lesions in mr images: a review</article-title>, <source>Neuroradiology</source> <volume>54</volume> (<issue>4</issue>) (<year>2012</year>) <fpage>299</fpage>&#x2013;<lpage>320</lpage>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>X.</given-names> <surname>Llad&#x00F3;</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Oliver</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Cabezas</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Freixenet</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Vilanova</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Quiles</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Valls</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Rami&#x00F3;-Torrent&#x00E0;</surname></string-name>, <string-name><given-names>&#x00C0;.</given-names> <surname>Rovira</surname></string-name>, <article-title>Segmentation of multiple sclerosis lesions in brain mri: A review of automated approaches</article-title>, <source>Information Sciences</source> <volume>186</volume> (<issue>1</issue>) (<year>2012</year>) <fpage>164</fpage>&#x2013;<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Garc&#x00ED;a-Lorenzo</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Francis</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Narayanan</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Arnold</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Collins</surname></string-name>, <article-title>Review of automatic segmentation methods of multiple sclerosis white matter lesions on conventional magnetic resonance imaging</article-title>, <source>Medical Image Analysis</source> <volume>17</volume> (<issue>1</issue>) (<year>2013</year>) <fpage>1</fpage>&#x2013;<lpage>18</lpage>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="other"><string-name><given-names>M.</given-names> <surname>Styner</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Chin</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Chin</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Tran</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Markovic-Plese</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Jewells</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Warfield</surname></string-name>, <article-title>3D Segmentation in the Clinic: A Grand Challenge II: MS lesion segmentation</article-title>, <source>MIDAS Journal</source>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Carass</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Roy</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Jog</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Cuzzocreo</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Magrath</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Gherman</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Button</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Nguyen</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Prados</surname></string-name>, <string-name><given-names>C. H.</given-names> <surname>Sudre</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Cardoso</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Cawley</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Ciccarelli</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Wheeler-Kingshott</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ourselin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Catanese</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Desh-pande</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Maurel</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Tomas-Fernandez</surname></string-name>, <string-name><given-names>S. K.</given-names> <surname>Warfield</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Vaidya</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Chunduru</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Muthuganapathy</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Krishnamurthi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Jesson</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Arbel</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Maier</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Handels</surname></string-name>, <string-name><given-names>L. O.</given-names> <surname>Iheme</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Unay</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Jain</surname></string-name>, <string-name><given-names>D. M.</given-names> <surname>Sima</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Smeets</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Ghafoorian</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Platel</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Biren-baum</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Greenspan</surname></string-name>, <string-name><given-names>P.-L.</given-names> <surname>Bazin</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Calabresi</surname></string-name>, <string-name><given-names>C. M.</given-names> <surname>Crainiceanu</surname></string-name>, <string-name><given-names>L. M.</given-names> <surname>Ellingsen</surname></string-name>, <string-name><given-names>D. S.</given-names> <surname>Reich</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Prince</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Pham</surname></string-name>, <article-title>Longitudinal Multiple Sclerosis Lesion Segmentation: Resource &#x0026; Challenge</article-title>, <source>Neuroimage</source> <volume>148</volume> (<year>2017</year>) <fpage>77</fpage>&#x2013;<lpage>102</lpage>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>F.</given-names> <surname>Cotton</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Kremer</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Hannoun</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Vukusic</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Dousset</surname></string-name>, <article-title>OFSEP, a nationwide cohort of people with multiple sclerosis: Consensus minimal MRI protocol</article-title>, <source>Journal of Neuroradiology</source> <volume>42</volume> (<issue>3</issue>) (<year>2015</year>) <fpage>133</fpage>&#x2013;<lpage>140</lpage>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Akhondi-Asl</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Hoyte</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Lockhart</surname></string-name>, <string-name><given-names>S. K.</given-names> <surname>Warfield</surname></string-name>, <article-title>A Logarithmic Opinion Pool Based STAPLE Algorithm for the Fusion of Segmentations With Associated Reliability Weights</article-title>, <source>IEEE Transactions on Medical Imaging</source> <volume>33</volume> (<issue>10</issue>) (<year>2014</year>) <fpage>1997</fpage>&#x2013;<lpage>2009</lpage>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Beaumont</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <article-title>Multiple sclerosis lesion segmentation using an automated multimodal graph cut</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>1</fpage>&#x2013;<lpage>7</lpage>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Garc&#x00ED;a-Lorenzo</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Lecoeur</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Arnold</surname></string-name>, <string-name><given-names>D. L.</given-names> <surname>Collins</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <article-title>Multiple sclerosis lesion segmentation using an automatic multimodal graph cuts</article-title>, <source>in: 12th International Conference on Medical Image Computing and Computer Assisted Intervention</source>, <volume>Vol. 5762</volume> of LNCS, <year>2009</year>, pp. <fpage>584</fpage>&#x2013;<lpage>591</lpage>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Beaumont</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <article-title>Automatic Multiple Sclerosis lesion segmentation from Intensity-Normalized multi-channel MRI</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>8</fpage>&#x2013;<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Y.</given-names> <surname>Karpate</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <article-title>Robust Detection of Multiple Sclerosis Lesions from Intensity-Normalized Multi-Channel MRI</article-title>, in: <source>SPIE Medical Imaging</source>, <year>2015</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>F.</given-names> <surname>Forbes</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Doyle</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Garcia-Lorenzo</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Dojat</surname></string-name>, <article-title>A weighted multi-sequence markov model for brain lesion segmentation</article-title>, in: <source>Proceedings of the Thirteenth International Conference on Arti cial Intelligence and Statistics (AISTATS)</source>, <year>2010</year>, pp. <fpage>225</fpage>&#x2013;<lpage>232</lpage>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>F.</given-names> <surname>Forbes</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Doyle</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Garc&#x00ED;a-Lorenzo</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Dojat</surname></string-name>, <article-title>Adaptive weighted fusion of multiple MR sequences for brain lesion segmentation</article-title>, in: <source>ISBI</source>, <year>2010</year>, pp. <fpage>69</fpage>&#x2013;<lpage>72</lpage>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Khademi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Venetsanopoulos</surname></string-name>, <string-name><given-names>A. R.</given-names> <surname>Moody</surname></string-name>, <article-title>Generalized method for partial volume estimation and tissue segmentation in cerebral magnetic resonance images</article-title>, <source>Journal of Medical Imaging</source> <volume>1</volume> (<issue>1</issue>) (<year>2014</year>) <fpage>14002</fpage>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Knight</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Khademi</surname></string-name>, <article-title>MS Lesion Segmentation Using FLAIR MRI Only</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>21</fpage>&#x2013;<lpage>28</lpage>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Mahbod</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Chowdhury</surname></string-name>, <string-name><given-names>&#x00D6;</given-names>. <surname>Smedby</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Wang</surname></string-name>, <article-title>Automatic brain segmentation using artificial neural networks with shape context</article-title>, <source>Pattern Recognition Letters</source> <volume>101</volume> (<year>2018</year>) <fpage>74</fpage>&#x2013;<lpage>79</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.patrec.2017.11.016">https://doi.org/10.1016/j.patrec.2017.11.016</ext-link>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Mahbod</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>&#x00D6;</given-names>. <surname>Smedby</surname></string-name>, <article-title>Automatic multiple sclerosis lesion segmentation using hybrid artificial neural networks</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>29</fpage>&#x2013;<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>McKinley</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Gundersen</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Wagner</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Chan</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Wiest</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Reyes</surname></string-name>, <article-title>Nabla-net: a deep dag-like convolutional architecture for biomedical image segmentation: application to white-matter lesion segmentation in multiple sclerosis</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>37</fpage>&#x2013;<lpage>43</lpage>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Muschelli</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Sweeney</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Maronge</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Crainiceanu</surname></string-name>, <article-title>Prediction of MS Lesions using Random Forests</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>45</fpage>&#x2013;<lpage>50</lpage>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Cabezas</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Oliver</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Roura</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Freixenet</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Vilanova</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Rami&#x00F3;-Torrent&#x00E0;</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Rovira</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Llad&#x00F3;</surname></string-name>, <article-title>Automatic multiple sclerosis lesion detection in brain MRI by FLAIR thresholding</article-title>, <source>Computer Methods and Programs in Biomedicine</source> <volume>115</volume> (<issue>3</issue>) (<year>2014</year>) <fpage>147</fpage>&#x2013;<lpage>161</lpage>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Roura</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Oliver</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Cabezas</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Valverde</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Pareto</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Vilanova</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Rami&#x00F3;-Torrent&#x00E0;</surname></string-name>, <string-name><given-names>&#x00C0;.</given-names> <surname>Rovira</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Llad&#x00F3;</surname></string-name>, <article-title>A toolbox for multiple sclerosis lesion segmentation</article-title>, <source>Neuroradiology</source> <volume>57</volume> (<issue>10</issue>) (<year>2015</year>) <fpage>1031</fpage>&#x2013;<lpage>1043</lpage>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>M. M.</given-names> <surname>Santos</surname></string-name>, <string-name><given-names>P. R. B.</given-names> <surname>Diniz</surname></string-name>, <string-name><given-names>A. G.</given-names> <surname>Silva-Filho</surname></string-name>, <string-name><given-names>W. P.</given-names> <surname>Santos</surname></string-name>, <article-title>Evaluation-Oriented Training via Surrogate Metrics for Multiple Sclerosis Segmentation</article-title>, <volume>Vol. 9901</volume> of <source>LNCS, Springer</source>, <year>2016</year>, pp. <fpage>398</fpage>&#x2013;<lpage>405</lpage>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>M. M.</given-names> <surname>Santos</surname></string-name>, <string-name><given-names>P. R.</given-names> <surname>Diniz</surname></string-name>, <string-name><given-names>A. G.</given-names> <surname>Silva-Filho</surname></string-name>, <string-name><given-names>W. P.</given-names> <surname>Santos</surname></string-name>, <article-title>Evaluation-Oriented Training Strategy on MS Segmentation Challenge 2016</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>57</fpage>&#x2013;<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>X.</given-names> <surname>Tomas-Fernandez</surname></string-name>, <string-name><given-names>S. K.</given-names> <surname>Warfield</surname></string-name>, <article-title>A Model of Population and Subject (MOPS) Intensities With Application to Multiple Sclerosis Lesion Segmentation</article-title>, <source>IEEE Transactions on Medical Imaging</source> <volume>34</volume> (<issue>6</issue>) (<year>2015</year>) <fpage>1349</fpage>&#x2013;<lpage>1361</lpage>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>X.</given-names> <surname>Tomas-Fernandez</surname></string-name>, <string-name><given-names>S. K.</given-names> <surname>Warfield</surname></string-name>, <article-title>MRI Robust Brain Tissue Segmentation with application to Multiple Sclerosis</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>63</fpage>&#x2013;<lpage>67</lpage>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>H.</given-names> <surname>Urien</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Buvat</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Rougon</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Soussan</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Bloch</surname></string-name>, <article-title>Brain lesion detection in 3D PET images using max-trees and a new spatial context criterion</article-title>, in: <source>International Symposium on Mathematical Morphology (ISMM)</source>, <volume>Vol. 10225</volume> of LNCS, <year>2017</year>, pp. <fpage>455</fpage>&#x2013;<lpage>466</lpage>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>H.</given-names> <surname>Urien</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Buvat</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Rougon</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Bloch</surname></string-name>, <article-title>A 3D hierarchical multimodal detection and segmentation method for multiple sclerosis lesions in MRI</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>69</fpage>&#x2013;<lpage>73</lpage>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Valverde</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Cabezas</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Roura</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gonz&#x00E1;lez-Vill&#x00E0;</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Pareto</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Vilanova</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Rami&#x00F3;-Torrent&#x00E0;</surname></string-name>, <string-name><given-names>&#x00C0;</given-names>. <surname>Rovira</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Oliver</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Llad&#x00F3;</surname></string-name>, <article-title>Improving automated multiple sclerosis lesion segmentation with a cascaded 3D convolutional neural network approach</article-title>, <source>Neuroimage</source> <volume>155</volume> (<year>2017</year>) <fpage>159</fpage>&#x2013;<lpage>168</lpage>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>F.</given-names> <surname>Vera-Olmos</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Melero</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Malpica</surname></string-name>, <article-title>Random Forest for Multiple Sclerosis Lesion Segmentation</article-title>, in: <source>Proceedings of the 1st MICCAI Challenge on Multiple Sclerosis Lesions Segmentation Challenge Using a Data Management and Processing Infrastructure - MICCAI-MSSEG</source>, <year>2016</year>, pp. <fpage>81</fpage>&#x2013;<lpage>86</lpage>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Filippi</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Horsfield</surname></string-name>, <string-name><given-names>S. P.</given-names> <surname>Morrissey</surname></string-name>, <string-name><given-names>D. G.</given-names> <surname>MacManus</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Rudge</surname></string-name>, <string-name><given-names>W. I.</given-names> <surname>McDonald</surname></string-name>, <string-name><given-names>D. H.</given-names> <surname>Miller</surname></string-name>, <article-title>Quantitative brain mri lesion load predicts the course of clinically isolated syndromes suggestive of multiple sclerosis</article-title>, <source>Neurology</source> <volume>44</volume> (<issue>4</issue>) (<year>1994</year>) <fpage>635</fpage>&#x2013;<lpage>635</lpage>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>R. A.</given-names> <surname>Rudick</surname></string-name>, <string-name><given-names>J.-C.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Simon</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Fisher</surname></string-name>, <article-title>Significance of t2 lesions in multiple sclerosis: A 13-year longitudinal study</article-title>, <source>Annals of Neurology</source> <volume>60</volume> (<issue>2</issue>) (<year>2006</year>) <fpage>236</fpage>&#x2013;<lpage>242</lpage>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>A. S.</given-names> <surname>Ribeiro</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Nutt</surname></string-name>, <string-name><given-names>J.</given-names> <surname>McGonigle</surname></string-name>, <article-title>Which metrics should be used in non-linear registration evaluation?</article-title>, in: <source>Medical Image Computing and Computer-Assisted Intervention &#x2013; MICCAI 2015</source>, <year>2015</year>, pp. <fpage>388</fpage>&#x2013;<lpage>395</lpage>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Coup&#x00E9;</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Yger</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Prima</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Hellier</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Kervrann</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <article-title>An optimized blockwise nonlocal means denoising filter for 3-D magnetic resonance images</article-title>, <source>IEEE Transactions on Medical Imaging</source> <volume>27</volume> (<issue>4</issue>) (<year>2008</year>) <fpage>425</fpage>&#x2013;<lpage>441</lpage>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Wiest-Daessl&#x00E9;</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Prima</surname></string-name>, <article-title>Block-matching strategies for rigid registration of multimodal medical images</article-title>, in: <source>9th IEEE International Symposium on Biomedical Imaging (ISBI)</source>, <year>2012</year>, pp. <fpage>700</fpage>&#x2013;<lpage>703</lpage>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>J. V.</given-names> <surname>Manj&#x00F3;n</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Coup&#x00E9;</surname></string-name>, <article-title>volBrain: An Online MRI Brain Volumetry System</article-title>, <source>Frontiers in Neuroinformatics</source> <volume>10</volume> (<year>2016</year>) <fpage>30</fpage>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>N. J.</given-names> <surname>Tustison</surname></string-name>, <string-name><given-names>B. B.</given-names> <surname>Avants</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Cook</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Egan</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Yushkevich</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Gee</surname></string-name>, <article-title>N4ITK: Improved N3 Bias Correction</article-title>, <source>IEEE Transactions on Medical Imaging</source> <volume>29</volume> (<issue>6</issue>) (<year>2010</year>) <fpage>1310</fpage>&#x2013;<lpage>1320</lpage>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="other"><string-name><given-names>C.</given-names> <surname>Barillot</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Bannier</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Commowick</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Corouge</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Baire</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Fackfack</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Guillaumont</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Yao</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Kain</surname></string-name>, <article-title>Shanoir: Applying the Software as a Service Distribution Model to Manage Brain Imaging Research Repositories</article-title>, <source>Frontiers in information and communication technologies</source> <pub-id pub-id-type="doi">doi:10.3389/fict.2016.00025</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Glatard</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Lartizien</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Gibaud</surname></string-name>, <string-name><given-names>R. F.</given-names> <surname>da Silva</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Forestier</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Cervenansky</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Alessandrini</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Benoit-Cattin</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Bernard</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Camarasu-Pop</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Cerezo</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Clarysse</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Gaignard</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Hugonnard</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Liebgott</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Marache</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Marion</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Montagnat</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Tabary</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Friboulet</surname></string-name>, <article-title>A virtual imaging platform for multi-modality medical image simulation</article-title>, <source>IEEE Transactions on Medical Imaging</source> <volume>32</volume> (<issue>1</issue>) (<year>2013</year>) <fpage>110</fpage>&#x2013;<lpage>118</lpage>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>A. Y.</given-names> <surname>Ng</surname></string-name>, <string-name><given-names>M. I.</given-names> <surname>Jordan</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Weiss</surname></string-name>, <article-title>On spectral clustering: Analysis and an algorithm</article-title>, in: <source>Advances in Neural Information Processing Systems</source> <volume>14</volume>, <year>2001</year>, pp. <fpage>849</fpage>&#x2013;<lpage>856</lpage>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="other"><string-name><given-names>M.</given-names> <surname>Calvo</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Oller</surname></string-name>, <article-title>An explicit solution of information geodesic equations for the multivariate normal model</article-title>, <source>Statistics and Decisions</source> <fpage>9</fpage>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Dice</surname></string-name>, <article-title>Measures of the amount of ecologic association between species</article-title>, <source>Ecology</source> <volume>26</volume> (<issue>3</issue>) (<year>1945</year>) <fpage>297</fpage>&#x2013;<lpage>302</lpage>.</mixed-citation></ref>
</ref-list>
<sec>
<title>Additional Information</title>
<p>Authors of this article contributed to the article in the following manner:</p>
<list list-type="bullet">
<list-item><p>J&#x00E9;r&#x00E9;my Beaumont, Olivier Commowick, Christian Barillot, Senan Doyle, Michel Dojat, Florence Forbes, Jesse Knight, April Khademi, Amirreza Mahbod, Chunliang Wang, Richard McKinley, Franca Wagner, John Muschelli, Elizabeth Sweeney, Eloy Roura, Xavier Llad&#x00F3;, Michel M. Santos, Wellington P. Santos, Abel G. Silva-Filho, Xavier Tomas-Fernandez, Simon K. Warfield, H&#x00E9;l&#x00E8;ne Urien, Isabelle Bloch, Sergi Valverde, Mariano Cabezas, Francisco Javier Vera-Olmos and Norberto Malpica designed the challengers&#x2019; repsective algorithms, participated to the challenge, participated in the writing and proof-reading of the evaluated teams description in particular, and of the proof-reading of the whole article.</p></list-item>
<list-item><p>Micha&#x00EB;l Kain, Baptiste Laurent, Florent Leray, Mathieu Simon, Sorina Camarasu Pop, Pascal Girard, Fr&#x00E9;d&#x00E9;ric Cervenansky, Tristan Glatard, Olivier Commowick, Christian Barillot and Michel Dojat participated in the setup of the platform and running of the experiments on the France Life Imaging platform, the writing and proof-reading of the pipeline processing description and results in particular, and of the proof-reading of the whole article.</p></list-item>
<list-item><p>Olivier Commowick, Audrey Istace, Florent Leray, Baptiste Laurent, Roxana Am&#x00E9;li, Jean-Christophe Ferr&#x00E9;, Anne Kerbrat, Thomas Tourdias, Sandra Vukusic, Gilles Edan and Fran&#x00E7;ois Cotton participated in the constitution of the evaluation database (selection of the patients, expert guidance on the delineation of the lesions), in the analysis of results, and in the writing of the corresponding sections of the paper in particular. They also participated in the proof-reading of the whole article.</p></list-item>
<list-item><p>Olivier Commowick, Charles Guttmann, Fr&#x00E9;d&#x00E9;ric Cervenansky, Martin Styner, Simon K. Warfield, Fran&#x00E7;ois Cotton and Christian Barillot participated in all aspects of the challenge organization, design of the results evaluation experiments and metrics, writing and proof-reading of all sections of the paper.</p></list-item>
</list>
<p>The authors of this article have no competing interests as defined by Nature Research, or other interests that might be perceived to influence the results and/or discussion reported in this paper.</p>
</sec>
</back>
</article>