<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/132993</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Biophysics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Statistical mechanics of phase space partitioning in large-scale spiking neuron circuits</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Touzel</surname>
<given-names>Maximilian Puelma</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wolf</surname>
<given-names>Fred</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Max Planck Institute for Dynamics and Self-Organization</institution>, G&#x00F6;ttingen, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Bernstein Center for Computational Neuroscience</institution>, G&#x00F6;ttingen, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Laboratoire de Physique Th&#x00E9;orique, ENS-PSL Research University</institution>, Paris, <country>France</country></aff>
<aff id="a4"><label>4</label><institution>Kavli Institute for Theoretical Physics, University of California Santa Barbara</institution>, Santa Barbara, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding Author: Maximilian Puelma Touzel Laboratoire de Physique Th&#x00E9;orique Ecole Normale Sup&#x00E9;rieure 24 rue Lhomond 75231 Paris Cedex 05 Paris, France Ph. &#x002B;49 551 51 76 420 e-mail: <email>puelma@lpt.ens.fr</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>132993</elocation-id>
<history>
<date date-type="received">
<day>01</day>
<month>5</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>02</day>
<month>5</month>
<year>2017</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="132993.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Synaptic interactions structure the phase space of the dynamics of neural circuits and constrain neural computation. Understanding how requires methods that handle those discrete interactions, yet few exist. Recently, it was discovered that even random networks exhibit dynamics that partitions the phase space into numerous attractor basins. Here we utilize this phenomenon to develop theory for the geometry of phase space partitioning in spiking neural circuits. We find basin boundaries structuring the phase space are pre-images of spike-time collision events. Formulating a statistical theory of spike-time collision events, we derive expressions for the rate of divergence of neighboring basins and for their size distribution. This theory reveals that the typical basin diameter grows with inhibitory coupling strength and shrinks with the rate of spike events. Our study provides an analytical and generalizable approach for dissecting how connectivity, coupling strength, single neuron dynamics and population activity shape the phase space geometry of spiking circuits.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>neuronal circuits</kwd>
<kwd>dynamics of networks</kwd>
<kwd>disordered systems</kwd>
<kwd>basins of attraction</kwd>
<kwd>high dimensional systems</kwd>
<kwd>pulse-coupled systems</kwd>
<kwd>sequence generation</kwd>
</kwd-group>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec>
<p>Computing devices, whether natural or artificial, perform their function by finely orchestrated state changes of internal dynamical variables. In nervous systems these dynamical variables are physico-chemical states of nerve cells and synapses that connect them into complex networks called neural circuits. The causal dependencies arising from the synaptic interactions between cells greatly extend the space of functions computable by the circuit, beyond that of single neurons.</p>
<p>Mathematical models of neural circuits have been formulated in two fundamentally distinct ways <sup><xref rid="c1" ref-type="bibr">1</xref></sup>. Most synaptic interactions in the brain are driven by sparsely-fired nerve impulses, called spikes, each lasting only a millisecond. In spiking neural network models this fundamental granularity of neuronal interactions is explicitly represented: all interactions depend on a discrete set of spike event times. Alternatively, continuous variable models for neural circuit dynamics are formulated by assuming that a frequency of nerve impulse generation, the firing rate, represents the information-encoding variable causally relevant for neural circuit computation. Firing rate models have been commonly used to model neural circuits <sup><xref rid="c2" ref-type="bibr">2</xref></sup>, theoretically study their dynamics <sup><xref rid="c3" ref-type="bibr">3</xref>,<xref rid="c4" ref-type="bibr">4</xref></sup> and learning <sup><xref rid="c5" ref-type="bibr">5</xref>&#x2013;<xref rid="c8" ref-type="bibr">8</xref></sup>, and are the basis of spectacular advances in artificial computing systems <sup><xref rid="c9" ref-type="bibr">9</xref></sup>. Statistical physics has played a role in this development, e.g. in clarifying the disordered phase space organization <sup><xref rid="c10" ref-type="bibr">10</xref></sup>.</p>
<p>From a dynamical systems perspective, attractor states and their basins of attraction play a fundamental role in theories of neural computation. While analogous in some cases <sup><xref rid="c11" ref-type="bibr">11</xref>,<xref rid="c12" ref-type="bibr">12</xref></sup>, however, rate models are not equivalent to temporally coarse-grained versions of spiking neural networks, even if they are closely matched in structure <sup><xref rid="c13" ref-type="bibr">13</xref></sup>. Moreover, low firing rates (not much more than 1 Hz) in the cerebral cortex <sup><xref rid="c14" ref-type="bibr">14</xref></sup> make it hard to imagine how continuous rate variables associated to single neurons could provide a causally accurate description on behavioral time scales (hundreds of milliseconds). Developing theory for spiking networks may well require a dedicated approach. The absence of relevant averages and even a tractable ensemble of spiking trajectories, however, has thus far limited statistical approaches. Methods to design them <sup><xref rid="c15" ref-type="bibr">15</xref></sup> or to theoretically dissect the associated phase space organization are only starting to emerge.</p>
<p>Recently it has been discovered that, with dominant inhibition, even randomly wired networks partition their phase space into a complex set of basins of attraction, termed <italic>flux tubes</italic> <sup><xref rid="c16" ref-type="bibr">16</xref>,<xref rid="c17" ref-type="bibr">17</xref></sup>. Here we utilize this setting to develop a statistical theory of phase space partitioning in spiking neural circuits. We first present a simulation study of flux tubes, uncovering their shape and revealing it is structured by a spike time collision event. Formulating these events, we then derive the conditions for and rate of the mutual divergence of neighboring tubes. Our main calculation is the derivation of the distribution of flux tube sizes, which we obtain from statistics of these events by leveraging the random connectivity to average over the disorder. Our analytical approach provides a transparent method to determine how coupling strength, connectivity, single neuron dynamics and population activity combine to shape the phase space geometry of spiking neural circuits.</p>
</sec>
<sec id="s1">
<title>Methods</title>
<p>We study a tractable instance of the inhibition-dominated regime of neural circuits. <italic>N</italic> neurons are connected by an Erd&#x0151;s-R&#x00E9;nyi graph with adjacency matrix <italic>A</italic> = (<italic>A</italic><sub><italic>mn</italic></sub>). <italic>A</italic><sub><italic>mn</italic></sub> = 1 denotes a connection from neuron <italic>n</italic> to <italic>m</italic>, realized with probability, <italic>p</italic> = <italic>K/N</italic>. The neurons&#x2019; membrane potentials, <italic>V</italic><sub><italic>n</italic></sub> &#x2208;(&#x2212;<italic>&#x221E;</italic>, <italic>V</italic><sub><italic>T</italic></sub>], are governed by Leaky Integrate-and-Fire (LIF) dynamics,
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="132993_eqn1.gif"/></alternatives>
</disp-formula>
for <italic>n</italic> &#x2208; {1, &#x2026;, <italic>N</italic>}. Here, <italic>&#x03C4;</italic> is the membrane time constant and <italic>I</italic><sub><italic>n</italic></sub> (<italic>t</italic>) the synaptic current received by neuron <italic>n</italic>; when <italic>V</italic><sub><italic>n</italic></sub> reaches a threshold, <italic>V</italic><sub><italic>T</italic></sub> = 0, neuron <italic>n</italic> &#x2018;spikes&#x2019;, and <italic>V</italic><sub><italic>n</italic></sub> is reset to <italic>V</italic><sub><italic>R</italic></sub> = &#x2212;1. At the spike time, <italic>t</italic><sub><italic>s</italic></sub>, the spiking neuron, <italic>n</italic><sub><italic>s</italic></sub>, delivers a current pulse of strength <italic>J</italic> to its <italic>&#x1D4AA;</italic> (<italic>K</italic>) postsynaptic neurons, {<italic>m &#x007C;A</italic><sub><italic>mns</italic></sub> = 1}, (<italic>s</italic> indexes the spikes in the observation window). The total synaptic current is
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="132993_eqn2.gif"/></alternatives>
</disp-formula>
where <italic>I</italic><sub>Ext</sub> <italic>&#x003E;</italic> 0 is a constant external current and <italic>J &#x003C;</italic> 0 is the recurrent coupling strength. An <inline-formula><alternatives><inline-graphic xlink:href="132993_inline1.gif"/></alternatives></inline-formula>-scaling of <italic>J</italic> is chosen to maintain finite current fluctuations at large <italic>K</italic> and implies that the external drive is balanced by the recurrent input. As a consequence, firing in this network is robustly asynchronous and irregular <sup><xref rid="c18" ref-type="bibr">18</xref>&#x2013;<xref rid="c21" ref-type="bibr">21</xref></sup>. Setting <inline-formula><alternatives><inline-graphic xlink:href="132993_inline2.gif"/></alternatives></inline-formula>, with <italic>I</italic><sub>0</sub> <italic>&#x003E;</italic> 0, and <inline-formula><alternatives><inline-graphic xlink:href="132993_inline3.gif"/></alternatives></inline-formula> with <italic>J</italic><sub>0</sub> <italic>&#x003E;</italic> 0, the corresponding stationary mean-field equation for the population-averaged firing rate, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline4.gif"/></alternatives></inline-formula>, is <sup><xref rid="c17" ref-type="bibr">17</xref></sup>
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="132993_eqn3.gif"/></alternatives>
</disp-formula></p>
<p>It is convenient to map the voltage dynamics to a pseudophase representation <sup><xref rid="c17" ref-type="bibr">17</xref>,<xref rid="c22" ref-type="bibr">22</xref></sup>, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline5.gif"/></alternatives></inline-formula>, with
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="132993_eqn4.gif"/></alternatives>
</disp-formula>
where <italic>T</italic><sub><italic>free</italic></sub> is the oscillation period of a neuron driven only by <italic>I</italic><sub>Ext</sub>. <italic>&#x03D5;</italic><sub><italic>n</italic></sub> (<italic>t</italic>) evolves linearly in time,
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="132993_eqn5.gif"/></alternatives>
</disp-formula>
between spike events, <italic>i.e. t</italic> &#x2209; {<italic>t</italic><sub><italic>s</italic></sub>}, and undergoes shifts given by the phase response curve, <italic>Z</italic>(<italic>&#x03D5;</italic>), across input spike times where <italic>&#x03D5;</italic> is the state at spike reception. In the large-<italic>K</italic> limit, <italic>T</italic><sub>free</sub> and <italic>Z</italic> (<italic>&#x03D5;</italic>) simplify to
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="132993_eqn6.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="132993_eqn7.gif"/></alternatives>
</disp-formula>
respectively (see Supplemental Methods for details). The differential phase response,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline6.gif"/></alternatives></inline-formula>, is essential for the strongly dissipative nature of the collective dynamics. For <italic>J</italic> = 0, the dynamics (<xref ref-type="disp-formula" rid="eqn5">equation (5)</xref>) would preserve phase space volume. This volume, however, is strongly contracted by spikes received in the post-synaptic neurons. Consider trajectories from a small ball of initial conditions as they emit the same future spike. The ball of phases at this spike contracts by a factor 1 &#x2212; <italic>d</italic> along each of the <italic>K</italic> dimensions of the subspace spanned by the post-synaptic neurons. The volume thus contracts by (1 &#x2212; <italic>d</italic>)<sup><italic>K</italic></sup> &#x2192; <italic>e</italic><sup><italic>&#x03BB;</italic><sub>inh</sub></sup> per spike, for <italic>K</italic> &#x226B; 1, with exponential rate,
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="132993_eqn8.gif"/></alternatives>
</disp-formula>
<italic>&#x03BB;</italic><sub>inh</sub> <italic>&#x003C;</italic> 0 is responsible for the linear stability of the dynamics given by <xref ref-type="disp-formula" rid="eqn1">equations (1)</xref> and <xref ref-type="disp-formula" rid="eqn2">(2)</xref>, first shown in Refs. <sup><xref rid="c16" ref-type="bibr">16</xref>,<xref rid="c22" ref-type="bibr">22</xref></sup>.</p>
</sec>
<sec id="s2">
<title>Phase-space partitioning</title>
<p>The phase space volume taken up by an ensemble of nearby trajectories at a given spike is contracted at the spike&#x2019;s reception. Larger phase space volumes, however, are not uniformly contracted but torn apart, with the pieces individually contracted and overall dispersed across the entire traversed phase space volume. The elementary phenomenon is illustrated in <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1</label>
<caption><p>Finite-size perturbation instability and phase space partitioning in spiking networks. The three panels display the same slightly subcritical and supercritical perturbation of strength <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup><italic>&#x00B1; &#x03B4;</italic>, <italic>&#x03B4; &#x2273;</italic> 0, respectively, applied once at <italic>t</italic> = 0 and in a random direction away from an equilibriated trajectory. <bold>(a)</bold> Temporal responses of the system. <italic>Top</italic>: The corresponding distance time series, <italic>Dt</italic>(<italic>&#x220A;</italic>), between the perturbed and unperturbed trajectories (gray: sub-critical, blue: super-critical; arrows in all three panels indicate the respective the perturbation). The divergence of <italic>Dt</italic>(<italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> &#x002B; <italic>&#x03B4;</italic>) begins at <italic>t</italic><sup><italic>&#x002A;</italic></sup> &#x2248; 3 <italic>ms</italic>, and saturates at the average distance between randomly chosen trajectories, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline69.gif"/></alternatives></inline-formula> (dashed line) <sup><xref rid="c17" ref-type="bibr">17</xref></sup>, while <italic>Dt</italic>(<italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup>&#x2212; <italic>&#x03B4;</italic>) only decays exponentially. <italic>Middle</italic>: The spike times as vertical ticks of the first 50 randomly labeled neurons from the network. The unperturbed sequence is shown in black. <italic>Bottom</italic>: The subthreshold voltage time course of an example neuron. The spike sequence and membrane potentials of the sub and supercritical trajectories decorrelate after <italic>t</italic><sup><italic>&#x002A;</italic></sup>. <bold>(b)</bold> A 2D cross-section (<italic>&#x03B4;&#x03D5;</italic><sub>1</sub>, <italic>&#x03B4;&#x03D5;</italic><sub>2</sub>) of the pseudophase representation of the phase space, orthogonal to and centered on the unperturbed trajectory from (a) at <italic>t</italic> = 0 (see also Ref. 15). The black dot at the origin indicates the latter, whose attractor basin is colored gray. The other colors distinguish basins in the local neighborhood. The two perturbed trajectories from (a) were initiated from (<italic>&#x03B4;&#x03D5;</italic><sub>1</sub>, <italic>&#x03B4;&#x03D5;</italic><sub>2</sub>) = (0, <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup><italic>&#x00B1; &#x03B4;</italic>), respectively (shown as gray and blue dots, respectively, in the inset, in (a,Top and Bottom), and in (c)). <bold>(c)</bold> Schematic phase space caricature of two neighboring flux tubes with subcritical perturbations decaying on the order of the membrane time constant, <italic>&#x03C4;</italic>, and typical basin diameter, <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup>. The pseudoLyapunov exponent, <italic>&#x03BB;</italic><sub><italic>p</italic></sub>, is the rate at which neighboring tubes separate from each other (parameters: <italic>N</italic> = 200, <italic>K</italic> = 50, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline70.gif"/></alternatives></inline-formula>, <italic>&#x03C4;</italic> = 10 ms, <italic>J</italic><sub>0</sub> = 1).</p></caption>
<graphic xlink:href="132993_fig1.tif"/>
</fig>
<p>We define the <italic>critical perturbation strength</italic>, <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup>, as the flux tube&#x2019;s extent out from a given state <inline-formula><alternatives><inline-graphic xlink:href="132993_inline7.gif"/></alternatives></inline-formula> on the equilibriated trajectory, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline8.gif"/></alternatives></inline-formula>, and in a given orthogonal perturbation direction, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline9.gif"/></alternatives></inline-formula>,
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="132993_eqn9.gif"/></alternatives>
</disp-formula></p>
<p>Here, <italic>D</italic><sub><italic>t</italic></sub> (<italic>&#x220A;</italic>) is the 1-norm distance,
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="132993_eqn10.gif"/></alternatives>
</disp-formula>
between <inline-formula><alternatives><inline-graphic xlink:href="132993_inline10.gif"/></alternatives></inline-formula> and the perturbed trajectory, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline11.gif"/></alternatives></inline-formula> evolving freely from the perturbed state, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline12.gif"/></alternatives></inline-formula> (reference time <italic>t</italic> = 0 and <inline-formula><alternatives><inline-graphic xlink:href="132993_inline13.gif"/></alternatives></inline-formula>; Supplemental Methods for details). <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> is the largest value below which <italic>D</italic><sub><italic>t</italic></sub> (<italic>&#x220A;</italic>) vanishes in time. <italic>D</italic><sub><italic>t</italic></sub> initially decays exponentially, but for a supercritical perturbation, <italic>&#x220A;</italic> &#x003E; <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup>, there exists a <italic>divergence event time, t</italic><sup><italic>&#x002A;</italic></sup> <italic>&#x003E;</italic> 0, defined and obtained as the time at which a sustained divergence in <italic>D</italic><sub><italic>t</italic></sub> begins (see <xref rid="fig1" ref-type="fig">Fig. 1a</xref>).</p>
<p>A 2D cross-section of the phase space around <inline-formula><alternatives><inline-graphic xlink:href="132993_inline14.gif"/></alternatives></inline-formula> (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>) reveals that the locations of these critical perturbations form lines which intersect to form polygon-shaped basin boundaries. Before developing a theory for this phase space organization (caricatured in <xref rid="fig1" ref-type="fig">Fig. 1c</xref>), we first analyze two main features of the geometry of a flux tube: the punctuated exponential decay of its cross-sectional volume and the exponential separation of neighboring tubes.</p>
</sec>
<sec id="s3">
<title>Punctuated geometry of flux tubes</title>
<p>As expected from the typical phase space volume contraction (see <xref ref-type="disp-formula" rid="eqn8">equation (8)</xref>), we find along a simulated trajectory that the orthogonal phase space volume enclosed by the local flux tube exhibits exponential decay. This decay, however, is punctuated by blowup events. <xref rid="fig2" ref-type="fig">Figure 2a</xref> displays the spiking activity produced by the typical trajectory,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline15.gif"/></alternatives></inline-formula> The neighborhood around <inline-formula><alternatives><inline-graphic xlink:href="132993_inline16.gif"/></alternatives></inline-formula> a time window is visualized in a <italic>folded representation</italic> using a fixed, 2D projection of the phase space (<xref rid="fig2" ref-type="fig">Fig. 2b</xref> and Supplementary Video; see Supplemental Information for construction details). The basin of attraction surrounding <inline-formula><alternatives><inline-graphic xlink:href="132993_inline17.gif"/></alternatives></inline-formula> (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>) consists of lines which remain fixed between spike times. Across spike times, new lines appear and existing lines disappear. At irregular intervals breaking up time windows of exponential contraction, large abrupt blowup events take the boundary away from the center trajectory (<xref rid="fig2" ref-type="fig">Fig. 2b, c</xref>), producing jumps in the area enclosed by the boundary. It is important to note that these events do not mean that the evolving phase space volume from an ensemble of states contained in the tube would expand. Such volumes only contract and converge to the same asymptotic trajectory. The basin of attraction itself, however, does not exclusively contract with time. In fact, it should on average maintain a typical size.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2</label>
<caption><p>The basin boundary contracts towards and can blowup away from the stable trajectory within it. <bold>(a)</bold> Spike times from all neurons of the simulated trajectory,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline54.gif"/></alternatives></inline-formula>, in a 150 ms window. <bold>(b)</bold> 2&#x002B;1D folded phase space volume, (<italic>&#x03B4;&#x03D5;</italic><sub>1</sub>, <italic>&#x03B4;&#x03D5;</italic><sub>2</sub>, <italic>t</italic>), centered around <inline-formula><alternatives><inline-graphic xlink:href="132993_inline55.gif"/></alternatives></inline-formula> located at (0, 0, <italic>t</italic>) (black line) and extended in two fixed, random directions, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline56.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="132993_inline57.gif"/></alternatives></inline-formula>. The center tube is filled gray in this volume, and the two cross-sections, (<italic>&#x03B4;&#x03D5;</italic><sub>1</sub>, <italic>&#x03B4;&#x03D5;</italic><sub>2</sub>, 0) and (<italic>&#x03B4;&#x03D5;</italic><sub>1</sub>, <italic>&#x03B4;&#x03D5;</italic><sub>2</sub>, 150), are shown. <bold>(c)</bold> Cross-sectional area of the center tube from (b) versus time. The area decays exponentially but can undergo abrupt expansions at blow-up times, e.g. at spikes <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> (note the logarithmic scale on the ordinate). <bold>(d)</bold> The absolute time of the next divergence event, <italic>t</italic><sup><italic>&#x002A;</italic></sup> (see <xref ref-type="fig" rid="fig1">Fig. 1a</xref>, top), versus time, for perturbations along <inline-formula><alternatives><inline-graphic xlink:href="132993_inline58.gif"/></alternatives></inline-formula>. Note the step increase coincident with the blowup events seen in (b,c) (vertical, dashed lines). (Same parameters as <xref ref-type="fig" rid="fig1">Fig. 1</xref>.)</p></caption>
<graphic xlink:href="132993_fig2.tif"/>
</fig>
<p>The blowup events typically coincide with a divergence event time, <italic>t</italic><sup><italic>&#x002A;</italic></sup> (<xref rid="fig1" ref-type="fig">Fig. 1a</xref>), in some perturbation direction. Two such coincidences are visible in <xref rid="fig2" ref-type="fig">Fig. 2c</xref>,d. We conclude that the local basin at any time extends out in phase space until the perturbed trajectory approaches the pre-image of a divergence event occurring at a future time. Flux tube shape is then determined by the statistics of such events.</p>
</sec>
<sec id="s4">
<title>Tube boundary and divergence</title>
<p>We analyzed a set of divergence events from simulations. We find that a collision of a pair of spikes constitutes the elementary event triggering the divergence of the perturbed trajectory. These pairs, hereon called <italic>susceptible</italic> spike pairs, were generated by connected pairs of neurons. Moreover, a perturbation-induced collision of a susceptible spike pair generated an abrupt spike time shift in one or both of the connected neurons&#x2019; spike times. We found that the nature of the spike time shift depends on the motif by which the two neurons connect. We denote the <italic>backward-connected</italic> pair motif <italic>n</italic><sub><italic>s</italic>&#x002A;</sub> <italic>&#x2190; n</italic><sub><italic>s</italic>&#x2032;</sub>, where <italic>s</italic><sup><italic>&#x002A;</italic></sup>, the <italic>decorrelation event index</italic>, is the spike index of the earlier of the pair (note that <italic>t</italic><sup><italic>&#x002A;</italic></sup> <italic>&#x2261; t</italic><sub><italic>s</italic>&#x002A;</sub>), and <italic>s</italic><sup>&#x2032;</sup> &#x003E; <italic>s</italic>&#x002A; labels the later spike in the pair.</p>
<p>For <italic>&#x220A;</italic> &#x2272; <italic>&#x220A;</italic>&#x002A;, the presynaptic spike time, <italic>t</italic><sub><italic>s</italic>&#x2032;=<italic>s</italic>&#x002A;&#x002B;1</sub>, is advanced with increasing <italic>&#x220A;</italic> relative to the postsynaptic spike time, <italic>t</italic><sub><italic>s</italic>&#x002A;</sub>, until the two spikes collide (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>). At collision (<italic>&#x220A;</italic> = <italic>&#x220A;</italic>&#x002A;), the pulsed inhibition and the rate of approach to voltage threshold cause an abrupt delay of <italic>t</italic><sub><italic>s</italic>&#x002A;</sub> by &#x0394;<italic>t</italic><sub>jump</sub>. Using <xref ref-type="disp-formula" rid="eqn3">equation (3)</xref>, we obtain
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="132993_eqn11.gif"/></alternatives>
</disp-formula>
for <italic>d</italic> &#x226A; 1. Further details and the other two motifs (forward-connected and symmetrical) are discussed in the Supplementary Notes.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3</label>
<caption><p>The collision of a susceptible spike pair causes an abrupt change in spike time. <bold>(a)</bold> A schematic illustration of the collision event for the backward-connected pair motif (shown in inset). For this motif, the interval vanishes as <italic>&#x220A;</italic> &#x2192; <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> from below. Perturbation strength, <italic>&#x220A;</italic>, is plotted versus time, where the timings of spikes for every perturbation strength are indicated as ticks on lines. The spike times shift continuously for <italic>&#x220A;</italic> &#x003C; <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup>. As the next input spike time, <italic>t</italic><sub><italic>s</italic>&#x002A;<sup>&#x002B;1</sup></sub> (<italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> &#x2212; <italic>&#x03B4;</italic>), is advanced over <italic>t</italic><sub><italic>s</italic></sub><italic>&#x002A;</italic> (<italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> &#x002B; <italic>&#x03B4;</italic>)A discontinuous jump of size &#x0394;<italic>t</italic><sub>jump</sub>occurs in the spike time of the post-synaptic neuron, <italic>n</italic><sub><italic>s</italic></sub><italic>&#x002A;</italic> (light to dark blue) from <italic>t</italic><sub><italic>s</italic></sub><italic>&#x002A;</italic> (<italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> &#x2212; <italic>&#x03B4;</italic>) to <italic>t</italic><sub><italic>s</italic>&#x2032;&#x003E;<italic>s</italic>&#x002A;</sub> (<italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> &#x002B; <italic>&#x03B4;</italic>),<italic>&#x03B4;</italic> &#x227F; 0. <bold>(b)</bold> Schematic illustration of the voltage of the <italic>n</italic><sub><italic>s</italic></sub><italic>&#x002A;</italic> neuron versus time for <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup> <italic>&#x00B1; &#x03B4;</italic>. The inhibitory kick of size <inline-formula><alternatives><inline-graphic xlink:href="132993_inline59.gif"/></alternatives></inline-formula> (not shown to scale) delays the spike time by an amount <inline-formula><alternatives><inline-graphic xlink:href="132993_inline60.gif"/></alternatives></inline-formula>.</p></caption>
<graphic xlink:href="132993_fig3.tif"/>
</fig>
<p>For each spike in the network sequence, the rate of its susceptible spike partners is
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="132993_eqn12.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="132993_inline18.gif"/></alternatives></inline-formula> is the average distance between successive spikes. Since <inline-formula><alternatives><inline-graphic xlink:href="132993_inline18a.gif"/></alternatives></inline-formula>, the spike time of neuron <italic>n</italic><sub><italic>s</italic>&#x002A;</sub> is shifted forward typically as far as its next nearest susceptible partner spike. Thus, one collision event will typically induce another in at least one of the <inline-formula><alternatives><inline-graphic xlink:href="132993_inline18b.gif"/></alternatives></inline-formula> neurons to which the involved pair of neurons are presynaptic. A cascade of collision events then follows with near certainty (see Supplemental Notes for details).</p>
<p>The shift in <italic>t</italic><sub><italic>s</italic>&#x002A;</sub> by &#x0394;<italic>t</italic><sub>jump</sub> is carried forward to all future spike times of <italic>n</italic><sub><italic>s</italic>&#x002A;</sub>, so that <italic>n</italic><sub><italic>s</italic>&#x002A;</sub> becomes a source of collision events. The total collision rate is then <italic>&#x03BB;</italic><sub>sus</sub> multiplied by the number of source neurons, which approximately increments with each collision in the cascade. Averaging over realizations of the cascade (reference time <italic>t</italic><sup><italic>&#x002A;</italic></sup> = 0), the average number of collisions, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline19a.gif"/></alternatives></inline-formula>, grows as <inline-formula><alternatives><inline-graphic xlink:href="132993_inline19.gif"/></alternatives></inline-formula>. Finally, since each collision produces a jump in distance of equal size, we obtain the pseudoLyapunov exponent, <italic>&#x03BB;</italic><sub><italic>p</italic></sub> = <italic>&#x03BB;</italic><sub>sus</sub> from its implicit definition, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline20.gif"/></alternatives></inline-formula> (see Supplemental Notes), as the exponential rate at which flux tubes diverge.</p>
</sec>
<sec id="s5">
<title>Statistical theory of flux tube diameter</title>
<p>The geometry of a flux tube is captured by the <italic>flux tube indicator function</italic>, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline21.gif"/></alternatives></inline-formula>, evaluated across network states,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline22.gif"/></alternatives></inline-formula>, of its contained attracting trajectory and perturbation directions,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline23.gif"/></alternatives></inline-formula>. Using the Heaviside function, &#x0398;(<italic>x</italic>), &#x1D55D;<sub>FT</sub> (<italic>&#x220A;</italic>) = 1 for perturbations remaining in the tube (<italic>&#x220A;</italic> &#x003C; <italic>&#x220A;</italic><sup><italic>&#x002A;</italic></sup>), and 0 otherwise. The average of &#x1D55D;<sup>FT</sup> (<italic>&#x220A;</italic>) over <inline-formula><alternatives><inline-graphic xlink:href="132993_inline24.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="132993_inline25.gif"/></alternatives></inline-formula>,
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="132993_eqn13.gif"/></alternatives>
</disp-formula>
is the <italic>survival function</italic>: the probability that an <italic>&#x220A;</italic>-sized perturbation does not lead to a divergence event later in the perturbed trajectory, <italic>i.e. &#x220A;</italic> &#x003C; <italic>&#x220A;</italic>&#x002A;, and is formally defined as <inline-formula><alternatives><inline-graphic xlink:href="132993_inline26.gif"/></alternatives></inline-formula>, with <italic>&#x03C1;</italic> (<italic>&#x220A;</italic>&#x002A;) the transformed density over <italic>&#x220A;</italic>&#x002A;. <inline-formula><alternatives><inline-graphic xlink:href="132993_inline27.gif"/></alternatives></inline-formula> and decays to 0 as <italic>&#x220A; &#x2192;&#x221E;</italic>. The scale of this decay defines the typical flux tube size. Calculating <inline-formula><alternatives><inline-graphic xlink:href="132993_inline28.gif"/></alternatives></inline-formula> requires two steps: firstly, establishing a tractable representation of <inline-formula><alternatives><inline-graphic xlink:href="132993_inline29.gif"/></alternatives></inline-formula> and secondly, performing the average in <xref ref-type="disp-formula" rid="eqn13">equation (13)</xref>. Both of these in general pose intricate problems. However, as we will see next, both substantially simplify when generic properties of the asynchronous, irregular state are taken into account.</p>
<p>Perturbed spike intervals are obtained using the spike time deviations, <italic>&#x03B4;t</italic><sub><italic>s</italic></sub> (<italic>&#x220A;</italic>) := <italic>t</italic><sub><italic>s</italic></sub> (<italic>&#x220A;</italic>) &#x2212; <italic>t</italic><sub><italic>s</italic></sub> (0), <italic>s</italic> = 1, 2, <italic>&#x2026;</italic>,
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="132993_eqn14.gif"/></alternatives>
</disp-formula></p>
<p>In a linear approximation we find,
<disp-formula id="eqn15">
<alternatives><graphic xlink:href="132993_eqn15.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="132993_inline30.gif"/></alternatives></inline-formula> converts network phase deviation to spike time deviation and <italic>a</italic><sub><italic>s</italic></sub> is a dimensionless susceptibility that depends on the adjacency matrix, <italic>A</italic> = (<italic>A</italic><sub><italic>mn</italic></sub>), derivatives of the phase response curve evaluated at the network states at past spike times, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline31.gif"/></alternatives></inline-formula> for <italic>s</italic>&#x2032; &#x003C; <italic>s</italic>, and the perturbation direction <inline-formula><alternatives><inline-graphic xlink:href="132993_inline32.gif"/></alternatives></inline-formula> (see Supplemental Notes for its derivation). Substituting <xref ref-type="disp-formula" rid="eqn15">equation (15)</xref> into <xref ref-type="disp-formula" rid="eqn14">equation (14)</xref> gives
<disp-formula id="eqn16">
<alternatives><graphic xlink:href="132993_eqn16.gif"/></alternatives>
</disp-formula>
with &#x0394;<italic>t</italic><sub><italic>s</italic></sub> = &#x0394;<italic>t</italic><sub><italic>s</italic></sub> (0). Note that &#x0394;<italic>t</italic><sub><italic>s</italic></sub> (<italic>&#x220A;</italic>) can have a zero, <italic>i.e.</italic> a spike time collision only when &#x0394;<italic>a</italic><sub><italic>s</italic></sub> = <italic>a</italic><sub><italic>s</italic></sub> &#x2212;<italic>a</italic><sub><italic>s</italic>&#x2212;1</sub> <italic>&#x003E;</italic> 0.</p>
<p>To obtain the scaling behavior of the flux tube geometry it is sufficient to examine the statistics of flux tube borders using the corresponding divergence events generated by collisions of backward-connected susceptible spike pairs in the perturbed trajectory (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). In these cases, the perturbation strength <italic>&#x220A;</italic> &#x2192; <italic>&#x220A;</italic>&#x002A; as the network spike interval <inline-formula><alternatives><inline-graphic xlink:href="132993_inline67.gif"/></alternatives></inline-formula> for <inline-formula><alternatives><inline-graphic xlink:href="132993_inline68.gif"/></alternatives></inline-formula>. In fact, the latter condition serves in these cases as an implicit definition of <italic>&#x220A;</italic>&#x002A; and <italic>s</italic>&#x002A;.</p>
<p>According to <xref ref-type="disp-formula" rid="eqn16">equation (16)</xref>, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline33.gif"/></alternatives></inline-formula> in principle depends on the adjacency matrix, <italic>A</italic> = (<italic>A</italic><sub><italic>mn</italic></sub>), of the network realization. Removing this dependence by averaging over the ensemble of graphs, <italic>P</italic><sub><italic>A</italic></sub> ((<italic>A</italic><sub><italic>mn</italic></sub>)), simplifies the calculation of the survival function,
<disp-formula id="eqn17">
<alternatives><graphic xlink:href="132993_eqn17.gif"/></alternatives>
</disp-formula></p>
<p>Evaluating the right-hand side of <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref> using the perturbed spike intervals, linearized in <italic>&#x220A;</italic>, requires knowledge of the joint probability density of all variables present in <xref ref-type="disp-formula" rid="eqn16">equation (16)</xref>,
<disp-formula id="eqn18">
<alternatives><graphic xlink:href="132993_eqn18.gif"/></alternatives>
</disp-formula>
where we have chosen the perturbation direction, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline34.gif"/></alternatives></inline-formula>, to be statistically independent of the state,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline35.gif"/></alternatives></inline-formula>, being perturbed at <italic>t</italic> = 0. Here, the unperturbed spike pattern is represented by two random variables: <italic>M</italic>, the number of spikes in the time interval [0, <italic>T</italic>] after the perturbation, and {&#x0394;<italic>t</italic><sub><italic>s</italic></sub>}, the set of all <italic>M</italic> &#x2212; 1 inter-spike intervals in this window. It is well understood that in the large-system limit in a sparse graph, 1 &#x226A; <italic>K</italic> &#x226A; <italic>N</italic>, the currents driving individual neurons in the network converge to independent, stationary Gaussian random functions <sup><xref rid="c23" ref-type="bibr">23</xref></sup>. For low average firing rates, this implies that the pattern of network spikes (<italic>M</italic>, {&#x0394;<italic>t</italic><sub><italic>s</italic></sub>}) resembles a Poisson process <sup><xref rid="c24" ref-type="bibr">24</xref></sup>. Furthermore, the susceptibility becomes state-independent in this limit. Neglecting the weak dependence between the distribution of network spike patterns and <italic>A</italic> = (<italic>A</italic><sub><italic>mn</italic></sub>), the full density, <italic>&#x03C1;T</italic> (<xref ref-type="disp-formula" rid="eqn18">equation (18)</xref>), approximately factorizes,
<disp-formula id="eqn19">
<alternatives><graphic xlink:href="132993_eqn19.gif"/></alternatives>
</disp-formula>
with distribution of a single adjacency matrix element, <italic>P</italic><sub><italic>A</italic><sub><italic>mn</italic></sub></sub> (<italic>A</italic><sub><italic>mn</italic></sub> = 1) = <italic>p</italic>, <italic>P</italic><sub><italic>A</italic><sub><italic>mn</italic></sub></sub> (<italic>A</italic><sub><italic>mn</italic></sub> = 0) = 1 &#x2212; <italic>p</italic>, count distribution of spikes in the observation window, <italic>P</italic><sub><italic>T</italic></sub> (<italic>M</italic>), and distribution of single inter-spike interval <italic>&#x03C1;</italic><sub><italic>t</italic></sub> (&#x0394;<italic>t</italic>). The latter is exponential with rate <inline-formula><alternatives><inline-graphic xlink:href="132993_inline36.gif"/></alternatives></inline-formula>. With these approximations (see Supplementary Notes for details), all dependencies on the distribution of perturbation direction are mediated by the susceptibilities, {&#x0394;<italic>a</italic><sub><italic>s</italic></sub>}. For any isotropic <inline-formula><alternatives><inline-graphic xlink:href="132993_inline37.gif"/></alternatives></inline-formula> having finite-variance, <italic>&#x03C1;</italic><sub><italic>a</italic></sub> (&#x0394;<italic>a</italic><sub><italic>s</italic></sub>) has zero mean and standard deviation proportional to <inline-formula><alternatives><inline-graphic xlink:href="132993_inline38.gif"/></alternatives></inline-formula>, with the average contraction rate per neuron, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline39.gif"/></alternatives></inline-formula>, due to the inhibition. The factor 2&#x0398;(&#x0394;<italic>a</italic><sub><italic>s</italic></sub>) places support only positive values of &#x0394;<italic>a</italic><sub><italic>s</italic></sub> as required.</p>
<p>As <italic>&#x03C1;</italic><sub><italic>T</italic></sub> factorizes, so does <italic>S</italic> (<italic>&#x220A;</italic>),
<disp-formula id="eqn20">
<alternatives><graphic xlink:href="132993_eqn20.gif"/></alternatives>
</disp-formula>
where <italic>S</italic><sub><italic>s</italic></sub> (<italic>&#x220A;</italic>) is the probability that a perturbation of strength <italic>&#x220A;</italic> does not lead to a collision event involving the <italic>s</italic><sup>th</sup> spike. With the above simplifications,
<disp-formula id="eqn21">
<alternatives><graphic xlink:href="132993_eqn21.gif"/></alternatives>
</disp-formula></p>
<p>Evaluating <xref ref-type="disp-formula" rid="eqn21">equation (21)</xref> (see Supplementary Notes for the derivation), we find
<disp-formula id="eqn22">
<alternatives><graphic xlink:href="132993_eqn22.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="132993_inline40.gif"/></alternatives></inline-formula>, and Erfcx <inline-formula><alternatives><inline-graphic xlink:href="132993_inline41.gif"/></alternatives></inline-formula> is the scaled complementary error function. Erfcx [<italic>x</italic><sub><italic>s</italic></sub>] &#x2212; 1 &#x2248; &#x2212;<italic>x</italic><sub><italic>s</italic></sub> for <inline-formula><alternatives><inline-graphic xlink:href="132993_inline42.gif"/></alternatives></inline-formula>, so that finally
<disp-formula id="ueqn2">
<alternatives><graphic xlink:href="132993_ueqn2.gif"/></alternatives>
</disp-formula>
where we have identified <inline-formula><alternatives><inline-graphic xlink:href="132993_inline43.gif"/></alternatives></inline-formula>. Employing the logarithm and <inline-formula><alternatives><inline-graphic xlink:href="132993_inline44.gif"/></alternatives></inline-formula>,
<disp-formula id="eqn23">
<alternatives><graphic xlink:href="132993_eqn23.gif"/></alternatives>
</disp-formula>
with
<disp-formula id="eqn24">
<alternatives><graphic xlink:href="132993_eqn24.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn25">
<alternatives><graphic xlink:href="132993_eqn25.gif"/></alternatives>
</disp-formula>
where we have used <xref ref-type="disp-formula" rid="eqn6">equations (6)</xref> and <xref ref-type="disp-formula" rid="eqn7">(7)</xref> in the second line and note the cancellation of <italic>p</italic> and <italic>I</italic><sub>Ext</sub>. <xref ref-type="disp-formula" rid="eqn23">Equation (23)</xref> shows for 1 &#x226A; <italic>K</italic> &#x226A; <italic>N</italic> that the basin diameter, <italic>&#x220A;</italic>&#x002A;, is exponentially distributed and so completely determined by its characteristic scale, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline45.gif"/></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="eqn25">equation (25)</xref>), that is smaller for larger network size, higher average in-degree, higher population activity, and larger membrane time constant, <italic>&#x03C4;</italic>. <inline-formula><alternatives><inline-graphic xlink:href="132993_inline46.gif"/></alternatives></inline-formula> grows, however, with the synaptic coupling strength, <italic>J</italic><sub>0</sub>. In <xref rid="fig4" ref-type="fig">Fig. 4b</xref>, we see quantitative agreement in simulations between the definition of <inline-formula><alternatives><inline-graphic xlink:href="132993_inline47.gif"/></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="eqn13">equation (13)</xref> using the definition of <italic>&#x220A;</italic>&#x002A;, <xref ref-type="disp-formula" rid="eqn9">equation (9)</xref>) and its approximate microstate parametrization (<xref ref-type="disp-formula" rid="eqn20">equations (20)</xref>, <xref ref-type="disp-formula" rid="eqn22">(21)</xref>). These also confirm the exponential form of our reduced expression (<xref ref-type="disp-formula" rid="eqn23">equations (23)</xref>, <xref ref-type="disp-formula" rid="eqn25">(25)</xref>) and a scaling dependence on <italic>J</italic><sub>0</sub> (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). The latter holds until <italic>J</italic> is no longer of size <inline-formula><alternatives><inline-graphic xlink:href="132993_inline48.gif"/></alternatives></inline-formula>. The other scalings were reported in Ref. <sup><xref rid="c17" ref-type="bibr">17</xref></sup>. A derivation of only the characteristic scaling of <inline-formula><alternatives><inline-graphic xlink:href="132993_inline49.gif"/></alternatives></inline-formula>, but not depending on the Poisson spiking assumption, is given in the Supplemental Notes.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4</label>
<caption><p>The flux tube indicator function, once expressed with microstate variables and averaged, gives the survival probability to remain in the containing flux tube. <bold>(a)</bold> Spike-time deviations, <italic>&#x03B4;t</italic><sub><italic>s</italic></sub> (<italic>&#x220A;</italic>) (dots), as a function of perturbation strength up to the positive and negative critical strength, <italic>&#x220A;</italic><sup><italic>&#x002A;&#x2212;</italic></sup> and <italic>&#x220A;</italic><sup>&#x002A;&#x002B;</sup>, respectively, for <italic>s</italic> = 1, <italic>&#x2026;,</italic> 15 (colors) with their linear approximation (lines) given by <xref ref-type="disp-formula" rid="eqn15">equation (15)</xref>. Inset: <italic>&#x03B4;t</italic><sub><italic>s</italic></sub> (<italic>&#x220A;</italic>) as a function of <italic>s</italic> (shown for <italic>&#x220A;</italic> = 0.2<italic>&#x220A;</italic><sup><italic>&#x002A;&#x00B1;</italic></sup>, 0.4<italic>&#x220A;</italic><sup><italic>&#x002A;&#x00B1;</italic></sup>, 0.6<italic>&#x220A;</italic><sup><italic>&#x002A;&#x00B1;</italic></sup>, 0.8<italic>&#x220A;</italic><sup><italic>&#x002A;&#x00B1;</italic></sup>) decays exponentially at a rate near the maximum and mean Lyapunov exponent, <italic>&#x03BB;</italic><sub>max</sub> (black line) and <italic>&#x03BB;</italic><sub>mean</sub> (black-dashed line) respectively <sup><xref rid="c17" ref-type="bibr">17</xref></sup>. <bold>(b)</bold> The survival probability function <italic>S</italic> (<italic>&#x220A;</italic>) from simulations (dots, <xref ref-type="disp-formula" rid="eqn13">equation (13)</xref>; bars are standard error), theory (line, <xref ref-type="disp-formula" rid="eqn20">equations (20)</xref>,<xref ref-type="disp-formula" rid="eqn21">(21)</xref>), and the simplified theory at large <italic>K</italic>, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline61.gif"/></alternatives></inline-formula> (dotted line, <xref ref-type="disp-formula" rid="eqn23">equation (23)</xref>), where <inline-formula><alternatives><inline-graphic xlink:href="132993_inline62.gif"/></alternatives></inline-formula>. <bold>(c)</bold> <italic>S</italic> (<italic>&#x220A;</italic>) from simulations (dots) and <inline-formula><alternatives><inline-graphic xlink:href="132993_inline63.gif"/></alternatives></inline-formula> (lines) for <italic>J</italic><sub>0</sub> = 2<sup><italic>n</italic></sup>, <italic>n</italic> = &#x2212;2, &#x2212;1, 0, 1, 2. (Same parameters as <xref ref-type="fig" rid="fig1">Fig. 1</xref> except <italic>N</italic> = 10<sup>4</sup>, <italic>K</italic> = 10<sup>3</sup>.)</p></caption>
<graphic xlink:href="132993_fig4.tif"/>
</fig>
</sec>
<sec id="s6">
<title>The geometry of phase space partitioning</title>
<p><xref rid="fig5" ref-type="fig">Figure 5</xref> presents the phase space organization of these spiking circuits as we have revealed it, replacing the caricature of <xref rid="fig1" ref-type="fig">Fig. 1c</xref>. For a perturbation made to a stable trajectory, the geometry of the determining collision event is shown in <xref rid="fig5" ref-type="fig">Figure 5a</xref>, in a folded representation. The pre-images of this event determine the flux tube boundary back to the perturbation. Our results also provide a global, i.e. non-folded geometry of the partitioning (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>(left)). Susceptible spike collisions are edges of the <italic>N</italic>-dimensional unit hypercube of phases where the corresponding voltages of two connected neurons both approach threshold. The Poincare section obtained by projecting the dynamics orthogonal to the trajectory (since no motion exists orthogonal to this subspace) then reveals the intrinsic partition. Here, the polygon basin boundaries arise as the pre-images of the projections of susceptible edges lying nearby the trajectory at future spike times (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>(right)).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5</label>
<caption><p>Flux tube boundaries are the pre-images of future susceptible spike collisions. <bold>(a)</bold> A folded phase space representation of a susceptible spike collision. Spikes (ticks) occur at a rate <inline-formula><alternatives><inline-graphic xlink:href="132993_inline64.gif"/></alternatives></inline-formula> in the unperturbed trajectory (black line). For an example spike (blue tick), its susceptible spike partners (red ticks) occur at lower rate <inline-formula><alternatives><inline-graphic xlink:href="132993_inline65.gif"/></alternatives></inline-formula>. Small perturbations (gray arrows) lead to trajectories (gray) exhibiting spike time deviations that decay over time (tick alignment). A larger perturbation (example just beyond the critical perturbation strength: blue arrow) can push a spike and one of its susceptible partner spikes in the subsequent trajectory (blue and red, respectively) to collide, generating a divergence event at spike <italic>s</italic>&#x002A;. The indicator function, &#x1D55D;<sub>FT</sub> (<italic>&#x220A;</italic>), has support (dark gray) only over the local tube. <bold>(b)</bold> Constructing the local flux-tube partition in the non-folded phase space. <italic>Left</italic>: Susceptible spikes are represented by susceptible edges (thick green lines) of the unit hypercube having <inline-formula><alternatives><inline-graphic xlink:href="132993_inline66.gif"/></alternatives></inline-formula> (black dot) as an endpoint. An intrinsic random partition (thin green lines) is generated by projecting these edges onto the hyper-plane orthogonal to <inline-formula><alternatives><inline-graphic xlink:href="132993_inline71.gif"/></alternatives></inline-formula> (light gray). A given trajectory (labeled sequence of small dots) and its local neighborhood (within black dashed lines) is shown. <italic>Right</italic>: The flux tube partition for this trajectory at a given spike (here <italic>s</italic><sub>1</sub>) is obtained from back-iterating the intrinsic partition from all future spikes (here only partitions from <italic>s</italic><sub>2</sub>, <italic>s</italic><sub>3</sub>, and <italic>s</italic><sub>4</sub> are back-iterated; dashed lines). The partition at sufficiently distant future spikes (here the gray edge at <italic>s</italic><sub>4</sub>) will no longer refine the partition in the local neighborhood at <italic>s</italic><sub>1</sub>, since the expansive backwards dynamics maps the projected edges outside the neighborhood. A concrete example obtained from simulations is presented in the Supplemental Notes.</p></caption>
<graphic xlink:href="132993_fig5.tif"/>
</fig>
</sec>
<sec id="s7">
<title>Discussion</title>
<p>We have developed a theory of phase space partitioning in spiking neural circuits, exemplified using the phenomenon of flux tubes. Importantly, the approach yields the dependence on various control parameters. We find the flux tube diameter contracts with the rate of volume contraction per neuron, <inline-formula><alternatives><inline-graphic xlink:href="132993_inline50.gif"/></alternatives></inline-formula>, due to the inhibition received across the post-synaptic subspace of each spike. This contraction is punctuated, however, by collision events between susceptible spikes, <italic>i.e.</italic> those from pairs of connected neurons, occurring at rate <inline-formula><alternatives><inline-graphic xlink:href="132993_inline51.gif"/></alternatives></inline-formula> and across which the basin volume expands out to a pre-image of the next collision event. For some neighboring tube, this collision event sets off a cascade of such events with exponential rate, <italic>&#x03BB;</italic><sub>sus</sub> that is responsible for their mutual divergence. Using these collision events to identify the spiking trajectories lying on flux tube boundaries, we were able calculate the size distribution of these basins. The average size is controlled by the ratio of these two exponential rates. Leaving out a factor converting shifts in spike time to shifts in state,
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="132993_ueqn1.gif"/></alternatives>
</disp-formula></p>
<p>The final scaling,<inline-formula><alternatives><inline-graphic xlink:href="132993_inline52.gif"/></alternatives></inline-formula>, thus combines the contraction from the single neuron dynamics responsible for the dissipative dynamics, with the overall rate of spikes, which appears since each spike can be involved in a destabilizing collision event. Both contracting and expanding rates scale with the probability of connection, <italic>p</italic>, so we intuitively expect <italic>p</italic> to appear in <inline-formula><alternatives><inline-graphic xlink:href="132993_inline53.gif"/></alternatives></inline-formula> only implicitly through <italic>J</italic> and, reassuringly, <italic>p</italic> indeed cancels out.</p>
<p>Our framework motivates a variety of extensions. Our calculations can be performed for different disordered connectivity ensembles (e.g. correlated entries from annealed dilution processes <sup><xref rid="c25" ref-type="bibr">25</xref></sup> and structured second-order statistics <sup><xref rid="c26" ref-type="bibr">26</xref></sup>), different activity regimes (e.g. non-Markovian spike interval processes <sup><xref rid="c27" ref-type="bibr">27</xref></sup>), and different single neuron models (e.g. any threshold neuron with known phase response curve). We have applied the theory to an instability caused by abrupt changes in spike time due to an inhibitory input near voltage threshold, a scenario that can also be analyzed in neuron models with smooth thresholds (e.g. the rapid theta-neuron <sup><xref rid="c28" ref-type="bibr">28</xref></sup> that has the LIF neuron as a limit). The theory may also apply to other, as yet unknown instabilities involving spike collision events. Finally, while the linear stability of the dynamics precludes finite, asymptotic (Kolmogorov-Sinai) entropy production, the partition refinement picture we provide in <xref rid="fig5" ref-type="fig">Fig. 5b</xref> suggests a transient production of information about the perturbation on timescales of the order of the divergence event time, <italic>t</italic>&#x002A;. Making this connection to ergodic theory more precise is an interesting direction for future research.</p>
<p>Applying our approach in a relatively idealized context allowed for a tractable assessment of phase space organization. Despite its simplicity, however, the LIF neuron accurately captures many properties of cortical neurons, such as their dynamic response <sup><xref rid="c29" ref-type="bibr">29</xref></sup>. We have also neglected heterogeneity in many properties. For instance, in contrast to the locally stable regime studied here, mixed networks of excitatory and inhibitory neurons can instead be conventionally chaotic <sup><xref rid="c30" ref-type="bibr">30</xref></sup>. This chaos can nevertheless be suppressed in the ubiquitous presence of fluctuating external drive <sup><xref rid="c31" ref-type="bibr">31</xref>,<xref rid="c32" ref-type="bibr">32</xref></sup> or with spatially-structured connectivity <sup><xref rid="c33" ref-type="bibr">33</xref></sup>, suggesting a generality to locally stable dynamics and phase space partitioning in neural computation. Our approach, in particular the way we have quantified the ensemble of perturbed spiking trajectories, can inform formulations of local stability in these more elaborate contexts. Of particular interest are extensions where a macroscopic fraction of tubes remain large enough to realize encoding schemes tolerant of intrinsic and stimulus noise. For example, extensions to random dynamical systems <sup><xref rid="c34" ref-type="bibr">34</xref>,<xref rid="c35" ref-type="bibr">35</xref></sup> could provide theoretical control over spiking dynamic variants of rate network-based learning schemes to generate stable, input-specific trajectories <sup><xref rid="c7" ref-type="bibr">7</xref></sup>.</p>
<p>Recent advances in experimental neuroscience have allowed for probes of the finite-size stability properties of cortical circuit dynamics call for <italic>in vivo</italic>. For example, simultaneous intra- and extra-cellular recordings in the whisker motion-sensing system of the rat reveal that the addition of a single spike makes a measurable impact on the underlying spiking dynamics of the local cortical area <sup><xref rid="c36" ref-type="bibr">36</xref></sup>. Indeed, rats can be trained to detect perturbations to single spikes emitted in this area <sup><xref rid="c37" ref-type="bibr">37</xref></sup>. Representative toy theories, such as the one we provide, can guide this work by highlighting the features of spiking neural circuits that contribute to phase space partitioning. The combined effort promises to elucidate the dynamical substrate for neural computation at the level at which the neuronal interactions actually operate.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>M.P.T. would like to acknowledge discussions with Michael Monteforte, Sven Jahnke and Rainer Engelken. This work was supported by BMBF (01GQ07113, 01GQ0811, 01GQ0922, 01GQ1005B), GIF (906-17.1/2006), DFG (SFB 889), VW-Stiftung (ZN2632), and the Max Planck Society.</p>
</ack>
<sec>
<title>Author Contributions</title>
<p>M.P.T. conceived the project, developed the concepts, and wrote the manuscript. F.W. supervised the project, discussed the results and edited the manuscript.</p>
</sec>
<sec>
<title>Additional Information</title>
<p>The authors declare no competing financial interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Vogels</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Sprekeler</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Clopath</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name> <article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title>. <source>Science</source>, <volume>334</volume>, <fpage>1569</fpage>&#x2013;<lpage>73</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname>, <given-names>H. R.</given-names></string-name> and Cowan, <string-name><given-names>J. D.</given-names> <surname>Excitatory</surname></string-name> and <string-name><given-names>inhibitory interactions in localized populations of model</given-names> <surname>neurons</surname></string-name>. <source>Biophysical journal</source>, <volume>12</volume>, <fpage>1</fpage>&#x2013;<lpage>24</lpage>, <year>1972</year>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Crisanti</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Sommers</surname>, <given-names>H. J.</given-names></string-name> <article-title>Chaos in random neural networks</article-title>. <source>Physical Review Letters</source>,<volume>61</volume>, <fpage>259</fpage>&#x2013;<lpage>262</lpage>, <year>1988</year>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Kadmon</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name> <article-title>Transition to chaos in random neuronal networks</article-title>. <source>Physical Review X</source>, <volume>5</volume>, <fpage>1</fpage>&#x2013;<lpage>28</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Hopfield</surname>, <given-names>J. J.</given-names></string-name> <article-title>Neural Networks and Physical Systems with Emergent Collective Computational Abilities</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>79</volume>, <fpage>2554</fpage>&#x2013;<lpage>2558</lpage>, <year>1982</year>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Sussillo</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Abbott</surname>, <given-names>L. F.</given-names></string-name> <article-title>Generating Coherent Patterns of Activity from Chaotic Neural Networks</article-title>. <source>Neuron</source>, <volume>63</volume>, <fpage>544</fpage>&#x2013;<lpage>557</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Laje</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Buonomano</surname>, <given-names>D. V.</given-names></string-name> <article-title>Robust timing and motor patterns by taming chaos in recurrent neural networks</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>, <fpage>925</fpage>&#x2013;<lpage>933</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Brunel,</surname> <given-names>N.</given-names></string-name> <article-title>Is cortical connectivity optimized for storing information?</article-title> <source>Nature Neuroscience</source>, <volume>19</volume>, <fpage>749</fpage>&#x2013;<lpage>755</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>Hinton</surname>, <given-names>G.</given-names></string-name> <article-title>Deep learning</article-title>. <source>Nature</source>, <volume>521</volume>, <fpage>436</fpage>&#x2013;<lpage>444</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Gardner</surname>, <given-names>E.</given-names></string-name> <article-title>Optimal basins of attraction in randomly sparse neural network models</article-title>. <source>Journal of Physics A: Mathematical and General</source>, <volume>22</volume>, <fpage>1969</fpage>&#x2013;<lpage>1974</lpage>, <year>1988</year>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Harish</surname>, <given-names>O.</given-names></string-name> and <string-name><surname>Hansel</surname>, <given-names>D.</given-names></string-name> <article-title>Asynchronous Rate Chaos in Spiking Neuronal Circuits</article-title>. <source>PLoS Computational Biology</source>, <volume>11</volume>, <fpage>e1004266</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Mastrogiuseppe</surname>, <given-names>F.</given-names></string-name> and <string-name><surname>Ostojic</surname>, <given-names>S.</given-names></string-name> <article-title>Intrinsically-generated fluctuating activity in excitatory-inhibitory networks</article-title>. <source>PLOS Computational Biology</source>, <volume>13</volume>, <fpage>1</fpage>&#x2013;<lpage>40</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Engelken</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Farkhooi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Hansel</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>van Vreeswijk</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Wolf</surname>, <given-names>F. A</given-names></string-name> <article-title>reanalysis of &#x201C;Two types of asynchronous activity in networks of excitatory and inhibitory spiking neurons</article-title>. <source>F1000Research</source>, <volume>5</volume>, <fpage>2043</fpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Roxin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brunel</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Hansel</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Mongillo</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Van Vreeswijk</surname>, <given-names>C.</given-names></string-name> On the distribution of firing rates in networks of cortical neurons. <source>J Neurosci</source>, <volume>31</volume>, <fpage>16217</fpage>&#x2013;<lpage>26</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Memmesheimer</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Rubin</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>&#x00D6;lveczky</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name> <article-title>Learning Precisely Timed Spikes</article-title>. <source>Neuron</source>, <volume>82</volume>, <fpage>925</fpage>&#x2013;<lpage>938</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Jahnke</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Memmesheimer</surname>, <given-names>R.-M.</given-names></string-name>, and <string-name><surname>Timme</surname>, <given-names>M.</given-names></string-name> <article-title>Stable Irregular Dynamics in Complex Neural Networks</article-title>. <source>Physical Review Letters</source>, <volume>100</volume>, <fpage>2</fpage>&#x2013;<lpage>5</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Monteforte</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Wolf</surname>, <given-names>F.</given-names></string-name> <source>Dynamic flux tubes form reservoirs of stability in neuronal circuits</source>., <volume>2</volume>, <fpage>041007</fpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="book"><string-name><surname>van Vreeswijk</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name> <chapter-title>Chaos in neuronal networks with balanced excitatory and inhibitory activity</chapter-title>. <source>Science</source> (<publisher-loc>New York, N.Y</publisher-loc>.), <volume>274</volume>, <fpage>1724</fpage>&#x2013;<lpage>6</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Brunel</surname>, <given-names>N.</given-names></string-name> and <string-name><surname>Hakim</surname>, <given-names>V.</given-names></string-name> <article-title>Fast global oscillations in networks of integrate-and-fire neurons with low firing rates</article-title>. <source>Neural Computation</source>, <volume>11</volume>, <fpage>1621</fpage>&#x2013;<lpage>71</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Renart</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>de la Rocha</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bartho</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Hollender</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Parga</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Reyes</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name> <article-title>The asynchronous state in cortical circuits</article-title>. <source>Science</source>, <volume>327</volume>, <fpage>587</fpage>&#x2013;<lpage>590</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Barral</surname>, <given-names>J.</given-names></string-name> and <string-name><given-names>D</given-names> <surname>Reyes</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Synaptic</surname></string-name> <article-title>scaling rule preserves excitatory&#x2013;inhibitory balance and salient neuronal network dynamics</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>, <fpage>1690</fpage>&#x2013;<lpage>1696</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Jin,</surname> <given-names>D</given-names></string-name>. <article-title>Fast Convergence of Spike Sequences to Periodic Patterns in Recurrent Networks</article-title>. <source>Physical Review Letters</source>, <volume>89</volume>, <fpage>1</fpage>&#x2013;<lpage>4</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="book"><string-name><surname>Tuckwell</surname>, <given-names>H.</given-names></string-name> <source>Introduction to Theoretical Neurobiology</source> vols. <volume>1 and 2</volume>. <publisher-name>Cambridge University Press</publisher-name>, <year>1988</year>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Lindner</surname>, <given-names>B.</given-names></string-name> <article-title>Superposition of many independent spike trains is generally not a Poisson process</article-title>. <source>Physical Review E</source>, <volume>73</volume>, <fpage>1</fpage>&#x2013;<lpage>4</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Boutent</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Engels</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Komodat</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Serneelst</surname>, <given-names>R.</given-names></string-name> <article-title>Quenched versus annealed dilution in neural networks</article-title>. <source>J. Phys. A: Math. Gen</source>, <volume>23</volume>, <fpage>4643</fpage>&#x2013;<lpage>4657</lpage>, <year>1990</year>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Zhao</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Beverlin</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Netoff</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Nykamp</surname>, <given-names>D. Q.</given-names></string-name> <article-title>Synchronization from second order network connectivity statistics</article-title>. <source>Frontiers in computational neuroscience</source>, <volume>5</volume>, <fpage>28</fpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Schwalger</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Droste</surname>, <given-names>F.</given-names></string-name>, and <string-name><surname>Lindner</surname>, <given-names>B.</given-names></string-name> <article-title>Statistical structure of neural spiking under non-poissonian or other non-white stimulation</article-title>. <source>Journal of Computational Neuroscience</source>, <volume>39</volume>, <fpage>29</fpage>&#x2013;<lpage>51</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Monteforte</surname>, <given-names>M.</given-names></string-name> <source>Chaotic Dynamics in Networks of Spiking Neurons in the Balanced State. PhD thesis</source>, <year>2011</year>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Brette</surname>, <given-names>R.</given-names></string-name> <article-title>What Is the Most Realistic Single-Compartment Model of Spike Initiation?</article-title> <source>PLOS Computational Biology</source>, <volume>11</volume>, <fpage>e1004114</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Monteforte</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Wolf</surname>, <given-names>F.</given-names></string-name> <article-title>Dynamical Entropy Production in Spiking Neuron Networks in the Balanced State</article-title>. <source>Phys. Rev. Lett</source>., <volume>105</volume>(<issue>26</issue>), <fpage>1</fpage>&#x2013;<lpage>4</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Molgedey</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Schuchhardt</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Schuster</surname>, <given-names>H. G.</given-names></string-name> <article-title>Suppressing chaos in neural networks by noise</article-title>. <source>Physical Review Letters</source>, <volume>69</volume>, <fpage>3717</fpage>&#x2013;<lpage>3719</lpage>, <year>1992</year>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Goedeke</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Schuecker</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Helias</surname>, <given-names>M.</given-names></string-name> <source>Noise dynamically suppresses chaos in neural networks</source>., pages <fpage>1</fpage>&#x2013;<lpage>5</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Rosenbaum</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Doiron</surname>, <given-names>B.</given-names></string-name> <article-title>Balanced networks of spiking neurons with spatially dependent recurrent connections</article-title>. <source>Physical Review X</source>, <volume>4</volume>, <fpage>1</fpage>&#x2013;<lpage>9</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Lajoie</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Thivierge</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Shea-Brown</surname>, <given-names>E.</given-names></string-name> <article-title>Structured chaos shapes spike-response noise entropy in balanced neural networks</article-title>. <source>Frontiers in computational neuroscience</source>, <volume>8</volume>, <fpage>2014</fpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Arnold</surname>, <given-names>L.</given-names></string-name> <source>Random Dynamical Systems. Springer</source>, <year>1998</year>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>London</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Beeren</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>H&#x00E4;usser</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name> <article-title>Sensitivity to perturbations in vivo implies high noise and suggests rate coding in cortex</article-title>. <source>Nature</source>, <volume>466</volume>, <fpage>123</fpage>&#x2013;<lpage>127</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Houweling</surname>, <given-names>A. R.</given-names></string-name> and <string-name><surname>Brecht</surname>, <given-names>M.</given-names></string-name> <article-title>Behavioural report of single neuron stimulation insomatosensory cortex</article-title>. <source>Nature</source>, <volume>451</volume>, <fpage>65</fpage>&#x2013;<lpage>8</lpage>, <year>2008</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>