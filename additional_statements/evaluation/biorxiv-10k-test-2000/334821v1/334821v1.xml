<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/334821</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Fast Hebbian Plasticity explains Working Memory and Neural Binding</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Fiebig</surname>
<given-names>Florian</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6553-823X</contrib-id>
<name>
<surname>Herman</surname>
<given-names>Pawel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2358-7815</contrib-id>
<name>
<surname>Lansner</surname>
<given-names>Anders</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Lansner Laboratory, Department of Computational Science and Technology, Royal Institute of Technology</institution>, 10044 Stockholm, <country>Sweden</country></aff>
<aff id="a2"><label>2</label><institution>Department of Mathematics, Stockholm University</institution>, 10691 Stockholm, <country>Sweden</country></aff>
</contrib-group>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>334821</elocation-id>
<history>
<date date-type="received">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="334821.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>We have extended a previous spiking neural network model of prefrontal cortex with fast Hebbian plasticity to also include interactions between short-term and long-term memory stores. We investigated how prefrontal cortex could bind and maintain multi-modal long-term memory representations by simulating three cortical patches in macaque brain, i.e. in prefrontal cortex together with visual and auditory temporal cortex.</p><p>Our simulation results demonstrate how simultaneous brief multi-modal activation of items in longterm memory could build a temporary joint cell assembly linked via prefrontal cortex. The latter can then activate spontaneously and thereby reactivate the associated long-term representations. Cueing one long-term memory item rapidly pattern completes the associated un-cued item via prefrontal cortex. The short-term memory network flexibly updates as new stimuli arrive thereby gradually overwriting older representation. In a wider context, this working memory model suggests a novel solution to the &#x201C;binding problem&#x201D;, a long-standing and fundamental issue in cognitive neuroscience.</p>
</abstract>
<counts>
<page-count count="29"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>By working memory (WM), we typically understand a flexible but volatile kind of memory capable of holding a small number of items over shorter time span. This allows acting beyond the immediate here and now and bringing on-line task relevant information in long-term memory (LTM). WM is a key component in cognition and often affected early on in neurological and psychiatric conditions, like e.g. Alzheimers disease and schizophrenia<sup><xref rid="c1" ref-type="bibr">1</xref></sup>. Prefrontal cortex (PFC) has been repeatedly implicated as a key structure for WM in humans and non-human primates<sup><xref rid="c2" ref-type="bibr">2</xref>,<xref rid="c3" ref-type="bibr">3</xref></sup>.</p>
<p>The prevalent theory of WM for thirty years has been that of persistent activity in PFC recurrent networks, proposed by Goldman-Rakic and colleagues<sup><xref rid="c4" ref-type="bibr">4</xref>,<xref rid="c5" ref-type="bibr">5</xref></sup> and supported by computational models<sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c7" ref-type="bibr">7</xref></sup>. Although there is solid support for delay activity in PFC during WM, recent experimental observations of e.g. the variability of this activity<sup><xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c9" ref-type="bibr">9</xref></sup> and the observation of &#x201C;activity silent working memory&#x201D;<sup><xref rid="c10" ref-type="bibr">10</xref></sup> have cast doubt on persistent activity as the main neural mechanism underlying WM.</p>
<p>Proposals for and simulations of synaptic plasticity as a main neural mechanism behind WM were made earlier using abstract attractor neural networks with non-spiking units<sup><xref rid="c11" ref-type="bibr">11</xref>&#x2013;<xref rid="c15" ref-type="bibr">15</xref></sup>. In 2008 Mongillo et al.<sup><xref rid="c16" ref-type="bibr">16</xref></sup> suggested a &#x201C;synaptic working memory theory&#x201D; and demonstrated a spiking model of a piece of cortex which displayed WM in the form of self-sustained bursty delay activity, thus also allowing single WM memory items to remain silent for short periods of time. However, this model was based on nonHebbian forms of synaptic plasticity where synaptic weight changes have no dependence on postsynaptic activity. Such processes can only facilitate memory items already encoded in a prestructured synaptic matrix of sufficient stimulus-specificity, which precludes encoding of genuinely novel memories.</p>
<p>Building on an earlier abstract model<sup><xref rid="c18" ref-type="bibr">18</xref></sup>, we recently modeled a human word-list learning task using a spiking short-term memory (STM) model of PFC based on fast Hebbian synaptic plasticity<sup><xref rid="c19" ref-type="bibr">19</xref></sup>. We demonstrated our model&#x2019;s capability to encode novel items, to quantitatively reproduce key characteristics of human cued and non-cued recall, and to reproduce several important network dynamic features of memory replay and recall. To function in this context, synaptic plasticity needs to operate on a time-scale of a few hundred milliseconds. Although processes like LTP has typically been seen as a slowly inducing and expressing, early<sup><xref rid="c20" ref-type="bibr">20</xref></sup> as well as more recent research has shown the existence also of faster forms, e.g. Short-Term Potentiation (STP)<sup><xref rid="c21" ref-type="bibr">21</xref>,<xref rid="c22" ref-type="bibr">22</xref></sup>, which opens up the possibility for this type of WM model.</p>
<p>In the following we present an extended WM model which integrates STM in PFC<sup><xref rid="c19" ref-type="bibr">19</xref></sup> with network components representing multi-modal LTM areas. Thus, this new model factors in that STM does not operate in isolation to support WM but interacts closely with processes like attention and LTM. For instance, unattended stimuli rarely end up in WM or get consolidated in LTM, so there is an &#x201C;attentional gate&#x201D; that controls that only relevant items get encoded<sup><xref rid="c23" ref-type="bibr">23</xref></sup>. Furthermore, WM is often described as activating or bringing LTM representations on-line<sup><xref rid="c24" ref-type="bibr">24</xref></sup>. Our extended model allows for a quantitative analysis of such key interactions between STM and LTM.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We simulate three cortical patches, i.e. an STM and two slightly smaller LTM networks (LTMa, LTMb) representing PFC and temporal visual and auditory cortical areas respectively (<bold><xref rid="fig1" ref-type="fig">Figure 1</xref></bold>). The computational network model used here represents a modular cortical microcircuit architecture in line with previous models<sup><xref rid="c25" ref-type="bibr">25</xref>,<xref rid="c26" ref-type="bibr">26</xref></sup>. In particular, the current model is an extension of a recent STM model<sup><xref rid="c19" ref-type="bibr">19</xref></sup>. The abstract, sub-sampled associative cortical layer 2/3 network of that model was sub-divided into layers 2, 3A, and 3B and extended with an input layer 4 and corticocortical connectivity to LTM stores in temporal cortical regions to allow for the study of memory binding and interaction. This composite model synthesizes many different kinds of cortical data and produces complex output dynamics. It is beyond the scope of this work to explore and analyze all its properties in detail. We provide references to particularly interesting aspects that have been intensively studied in preceding related models. Additional model details are found in the <italic>Online Methods</italic>.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Schematic of modeled connectivity within and across representative STM and LTM areas in macaque.</title>
<p>The model organizes cells into grids of nested hypercolumns (HC) and minicolumns (MC), sometimes referred to as macro columns, and &#x201C;functional columns&#x201D; respectively. Each network spans several hundred mm<sup>2</sup> and the simulated columns constitute a spatially distributed subsample, which is important due to the implied conduction delays. Pyramidal cells in the simulated supragranular layers form connections both within and across columns of their respective networks. Unlike STM, LTM areas do not feature an input layer 4, but are instead stimulated directly to cue the activation of previously learned long-term memories. Additional corticocortical connections are sparse (&#x003C;1&#x0025; connection probability) and implemented with terminal clusters and specific laminar connection profiles. The connection schematic illustrates laminar connections realizing a direct supragranular forward-projection, as well as a common supragranular back-projection. Layer 2/3 recurrent connections in STM and corticocortical backprojections feature fast Hebbian plasticity. For an in-depth model description, including the columnar microcircuits, please refer to <italic>Online Methods</italic> and <bold>Supplementary Figure 1</bold>.</p></caption>
<graphic xlink:href="334821_fig1.tif"/>
</fig>
<p>We introduce the performance of the corticocortical model in several steps. First, we take a brief look at ground and attractor states in the isolated networks. Second, we describe the effect of active LTM memories on STM withand without plasticity. Third, we add the plastic backprojections from STM to LTM and monitor the encoding and propagation of several memories in the resulting closed cortical loop. We track the evolution of acquired memory indices in STM and their driving role in WM maintenance (aka. delay activity). We then demonstrate that the emerging WM network system stays plastic and capable of updating its maintained set of memories. Finally, we stimulate several unconnected (i.e. multi-modal) pairs of memories in parallel and study how they flexibly bind in STM. We explore temporal characteristics of network activations during WM encoding, maintenance, and cue-driven associative recall of memory pairs associated in this manner. Our simulation output then allows us to analyze cross-cortical activation delay distributions and compare these with biological data on bottom-up and top-down response delays in a related study by Tomita et al.<sup><xref rid="c27" ref-type="bibr">27</xref></sup>.</p>
<sec id="s2a">
<title>Ground state and Attractor activity</title>
<p>In the untrained network, fluctuations in membrane voltages evoke a ground state with low-rate, irregular, asynchronous spiking that transitions into an alpha/beta oscillation at medium input rates (<bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-A</bold>). This is largely an effect of fast feedback inhibition from local basket cells (<bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>), high connection density within MCs, and low latency local spike transmission.<sup><xref rid="c28" ref-type="bibr">28</xref></sup> If the network has embedded attractors, a slightly stronger background excitation (&#x002B;39&#x0025;, <inline-formula><alternatives><inline-graphic xlink:href="334821_inline1.gif"/></alternatives></inline-formula>, <bold>Supplementary Table 2</bold>) can occasionally trigger memory item reactivations accompanied by oscillations in the form of theta-nested gamma bursts<sup><xref rid="c29" ref-type="bibr">29</xref></sup> (<bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-B</bold>). Because attractor activity is self-limiting through neural adaptation and synaptic depression, this can result in a random walk across stored memories when background excitation is strong. Any attractors, whether randomly or specifically triggered, are subject to known and previously well characterized associative memory dynamics, such as pattern completion, rivalry, perceptual blink, bursty reactivation dynamics, oscillations in different frequency bands, etc.<sup><xref rid="c28" ref-type="bibr">28</xref>&#x2013;<xref rid="c30" ref-type="bibr">30</xref></sup>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Basic Network behavior in spike rasters and exponential moving averages.</title>
<p><bold>A</bold>: Alpha/beta oscillations characterize the ground state of both STM (top) and LTM (bottom) in the absence of attractor activity. The underlying spike raster shows layer 2/3 activity of one MC from each HC (separated by grey horizontal lines) in the simulated network, revealing weak transient spatial synchronization of activity. <bold>B:</bold> LTM attractor activations express as theta-nested gamma bursts. The underlying spike raster shows layer 2/3 activity of the activated MC in each HC, revealing spatially-dependent, transient synchronization. <bold>C:</bold> LTM-to-STM forward dynamics as shown in exponential moving averages of STM and LTM activity following LTM-activation through a 50 ms targeted stimulus at time 0. LTM-driven activations of STM are characterized by a feedforward delay (FF). Shadows indicate the standard deviation of 100 peri-stimulus activations in LTM (blue) and STM with plasticity (orange) and without plasticity (dark orange). Horizontal bars at the bottom indicate activation half-width. Onset is denoted by vertical dashed lines. A shaded arrow denotes the stimulus <bold>D:</bold> Subsampled spike raster of STM (top) and LTM (bottom) during forward activation of the na&#x00EF;ve STM by five different LTM-attractors, triggered via specific cues in LTM at times marked by the vertical dashed lines. Bottom spike raster shows LTM layer 2/3 activity of one selective MC per activated pattern (colors indicate different patterns). Top spike raster shows layer 2/3 activity of one HC in STM. STM spikes are colored according to each cells dominant pattern-selectivity (based on simple spike counts in each patterns initial activation time window).</p></caption>
<graphic xlink:href="334821_fig2.tif"/>
</fig>
</sec>
<sec id="s2b">
<title>Open loop STM Dynamics</title>
<p>We now consider cued activation of several memories embedded in LTM. Each HC in LTM features a selectively coding MC for any given memory pattern. These distributed memory representations activate as a whole (<bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-B</bold>), so we only need to observe the pattern-specific component MCs in a single HC to get a sense of LTM activations. Five different LTM attractors are triggered by brief cues (<italic>Online Methods</italic>), see <bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-D bottom</bold>. To indicate the spatio-temporal structure of evoked activations in STM, we also show a simultaneous subsampled STM spike raster (<bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-D top</bold>).</p>
<p>As seen in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold>, STM activations are sparse (ca 5&#x0025;) and random. The spatial and temporal structure of STM activity is caused by the tendency of cells in the same MC to fire together (e.g. see Ground state). The distributed, but patchy character of the STM response is further a result of branching forward-projections from LTM layer 3B cells, which tend to activate close-by cells. Input layer 4 receives half of these corticocortical connections and features very high fine-scale specificity in its projections to layer 2/3 pyramidal neurons, which furthers recruitment of local clusters with shared selectivity. STM cells initially fire less than those in LTM because the latter received a brief, but strong activation cue and also features strong recurrent weights between cells in embedded attractors. STM neurons in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-D</bold> are colored according to their dominant memory pattern selectivity, which reveals that STM activations are mostly non-overlapping as well. Although MC activity is not exclusive to any given input pattern (unlike the strictly orthogonal LTM patterns), they are clearly clustered. This is not only an effect of competition via basket cell feedback inhibition, but also a result of short-term dynamics, such as neural adaptation and synaptic depression. Neurons that were recently activated by a strong, busting input from LTM are refractory and thus less prone to spike again for some time thereafter (&#x03C4;<sub><italic>rec</italic></sub> and <inline-formula><alternatives><inline-graphic xlink:href="334821_inline2.gif"/></alternatives></inline-formula>, <bold>Supplementary Table 1</bold>), further reducing the likelihood of activating overlapping STM activations. <bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-C</bold> shows a peri-stimulus exponential moving average (EMA) of both networks (across 100 trials with five triggered memories each). There is a bottom-up response delay between stimulus onset at t=0 and LTM activation, as well as a substantial forward delay (which we will scrutinize in more detail later on). Initial oscillatory activity in STM has a lower frequency than LTM because the na&#x00EF;ve STM is less active than LTM (compare left and right y-axis) in our model and subsequently does not trigger its basket cells as quickly (the main driver of alpha/beta and gamma). STM oscillations speed up later as new cell assemblies become stronger (e.g. <bold><xref rid="fig3" ref-type="fig">Figure 3</xref>-A</bold> and <bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>). As seen in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-B</bold>, co-activated MCs in LTM are not always in phase with respect to gamma and large, dispersed forward axonal conduction delays further decorrelate gamma input to STM. Activating strong plasticity in STM (<italic>k</italic><sub><italic>p</italic></sub>, <italic>Online Methods</italic> and <bold>Supplementary Table 1</bold>) has a noticeable effect on the amplitude of stimulus-locked oscillatory STM activity after as little as 100ms.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Indexing and reactivation of LTM.</title>
<p><bold>A</bold>: Exponential moving averages of pattern-specific subpopulations in STM (top) and LTM (bottom) during indexing and subsequent maintenance of five memories (the first pattern is often not maintained). From 0 to 1000 ms (shaded grey), five LTM memories are cued via targeted 50 ms stimuli. Plasticity is temporarily boosted during this time and activated attractors are thus indexed in STM. Thereafter, strong noise drive to STM causes random activations and consolidation of pattern-specific subpopulations in STM. Backprojections reactivate associated LTM memories. <bold>B:</bold> Updating of WM. Rapid encoding and subsequent maintenance of a second group of memories following an earlier set. Times of external input and plasticity modulation shaded grey. Bottom: Spike raster shows layer 2/3 activity of one LTM HC (MCs separated by grey horizontal lines). <bold>C:</bold> STM-to-LTM feedback dynamics during a reactivation event. STM-driven activations of LTM memories are characterized by a feedback delay. Horizontal bars at the bottom indicate activation half-width. Onset is denoted by vertical dashed lines.</p></caption>
<graphic xlink:href="334821_fig3.tif"/>
</fig>
</sec>
<sec id="s2c">
<title>Closed-loop STM-LTM Dynamics</title>
<p>In <bold><xref rid="fig2" ref-type="fig">Figure 2</xref>-D</bold> we already demonstrated a relatively simple way to extract pattern-specific subpopulations in STM from forward input spiking activity. By enabling backprojections we can now track activated memories in the closed cortical loop<bold>. In <xref rid="fig3" ref-type="fig">Figure 3</xref>-A</bold>, we show network activity following targeted activation of five LTM memories (Spike raster in <bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>). Under an increased unspecific noise-drive (<inline-formula><alternatives><inline-graphic xlink:href="334821_inline3.gif"/></alternatives></inline-formula>, <bold>Supplementary Table 2</bold>), STM cell assemblies, formed during the brief input-period, may activate randomly. These brief bursts of activity are initially weak and different from full-fledged theta-nested gamma-bursts seen in LTM attractor activity.</p>
<p>The closed cortical loop allows for additional amplification of these brief STM activations if the indexed LTM memory becomes active. Whilst memory pattern specificity in STM is random (but emergent from circuit architecture, short-term dynamics and plasticity), backprojections are plastic and thus acquire specificity from STM-LTM co-activations during forward stimulation. Given a high enough STM firing rate, the sparse but potentiated backprojections can trigger indexed LTMs. In turn, LTM activation will again feed into STM, typically causing a second peak of activation in STM following the first by about 40 ms (<bold><xref rid="fig3" ref-type="fig">Figure 3</xref>-C</bold>). A small set of memories are now maintained and intermittently active, so the closed cortical loop now constitutes a fully functional WM. Furthermore, there is a noticeable ramp-up in the strength of STM pattern-specific activity over the course of the delay period. Since STM remains plastic throughout our simulation, reactivation events further strengthen pattern-specific cell assemblies in STM and their link to associated LTM attractors. Eventually, STM assemblies become strong attractors themselves, capable of reliably activating their LTM associate. This effect may be called autoconsolidation and it is an emergent feature of the plastic cortical loop in this model. It happens on a timescale governed by the unmodulated plasticity time constant (<italic>k</italic> = <italic>k</italic><sub><italic>normal</italic></sub>, &#x03C4;<sub><italic>p</italic></sub> = 5 <italic>s</italic>, <bold>Supplementary Table 1</bold>). After a few seconds, the network has effectively stabilized and typically maintains a small set of 3-4 activated long-term memories.</p>
<p>A crucial feature of any WM system is its flexibility, and <bold><xref rid="fig3" ref-type="fig">Figure 3</xref>-B</bold> highlights an example of rapid updating., i.e. the maintained set of activated memories can be quickly overwritten by yet another set of input memories. As LTM attractors are non-overlapping, two sets of five memories imply that we used a network with at least ten simulated MC per HC here (The original model features only nine but was slightly scaled up). Generally speaking, earlier items will be reliably displaced from active maintenance in our model if activation of those new items is accompanied by the same transient elevation of plasticity (<italic>k</italic><sub><italic>p</italic></sub>/<italic>k</italic><sub><italic>normal</italic></sub>, <bold>Supplementary Table 1</bold>) used during the original indexing of the first five memories. For STM rates and subsampled spike raster see <bold><xref rid="figS2" ref-type="fig">Supplementary Figures 2</xref></bold>, and <bold><xref rid="figS3" ref-type="fig">3</xref></bold>.</p>
<p>In analogy with earlier results<sup><xref rid="c19" ref-type="bibr">19</xref></sup>, cued activation can often still recall previously maintained items. The rate of memory decay depends critically on the amount of noise in the system, which erodes learned correlations between STM and LTM neurons as well as STM cell assemblies. We note that such activitydependent memory decay is substantially different from time-dependent decay, as in Mi et al.<sup><xref rid="c31" ref-type="bibr">31</xref></sup>.</p>
<p>Analogous to forward delays in the LTM-driven scenario, we observe a feedback delay in the STMdriven closed-loop mode of operation (<bold><xref rid="fig3" ref-type="fig">Figure 3</xref>-C</bold>). The forward delay is still evident here in a delayed secondary increase of the STM activation following LTM onset, which extends the STM activation (we will scrutinize these delays in more detail later on).</p>
</sec>
<sec id="s2d">
<title>Multi-modal, Multi-item Working Memory</title>
<p>Next, we explore the ability of the closed STM-LTM loop system to flexibly bind co-active pairs of longterm memories from different modalities (LTMa and LTMb respectively). As both LTM activations propagate into PFC a unique joint STM index of both memories is created when forward-activations combine non-linearly with each other (see <bold>Online Methods)</bold> as well as with prior STM content. <bold><xref rid="fig4" ref-type="fig">Figure 4</xref></bold> illustrates how this index then supports WM operations, including cue-driven associative pair completion and delay maintenance through STM-driven discrete co-activation events. The three columns of <bold><xref rid="fig4" ref-type="fig">Figure 4</xref></bold> illustrate three fundamental modes of the closed loop system: Stimulus driven binding, WM maintenance, and associative recall. The top three rows show sampled activity of a single trial (see also <bold><xref rid="figS4" ref-type="fig">Supplementary Figures 4</xref>,<xref rid="figS5" ref-type="fig">5</xref></bold>), whereas the bottom shows multi-trial averages.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Exponential Moving Averages (EMA) of memoryand network-activations during three different modes of network activity</title>
<p>: <bold>TopHalf</bold>: Activation of three memories (blue,green,red respectivly) in STM (1<sup>st</sup> row), LTMa (2<sup>nd</sup> row), and LTMb (3<sup>rd</sup> row) during three different modes of network activity: The initial binding of pairs of LTM memory activations in STM (left column), WM Maintenance through STMdriven activations of bound LTM memory pairs (middle column), and cue-driven associative recall of previously paired stimuli (right column). <bold>Bottom-Half</bold>: Multi-trial peri-stimulus activity traces from the three cortical patches across 100 trials (495 traces, as each trial features 5 activated and maintained LTM memory pairs and very few failures of paired activation). Shaded areas indicate a standard deviation from the underlying traces. Vertical dashed lines denote mean onset of each network&#x2019;s activity, as determined by attractor half-width, also denoted by a rectangle underneath the traces. Error bars indicate a standard deviation from activation onset and offset. Mean peak activation is denoted by a triangle on the rectangle, and shaded arrows denote targeted pattern stimulation of a network. As there are no external cues during WM maintenance (aka delay period), we use detected STM activation onset to average EMA network traces of 5168 STM-driven LTMreactivations across trials and reactivation events. White arrows annotate feedforward (FF) and feedback (FB) delay, as defined by respective network onsets.</p></caption>
<graphic xlink:href="334821_fig4.tif"/>
</fig>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Distributions of key delays in the trained system during associative recall, averaged over 100 trials with 5 paired stimuli each.:</title>
<p>Top-Left: Feedforward delays distribution, as defined by the temporal delay between LTMa onset and STM onset (as shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>, Bottom-right). Top-Right: Bottom-up delay distribution, as defined by the temporal delay between stimulation onset and LTMa peak activation. The red lines denotes the mean bottom-up delay, as measured by Tomita et al.<sup><xref rid="c27" ref-type="bibr">27</xref></sup>. Bottom-Left: Feedback delays distribution, as defined by the temporal delay between STM onset and LTMb onset (measured by half-width, as shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>, Bottom-right). Bottom-Right: TopDown delay distribution, as defined by the temporal delay between stimulation onset and LTMb peak activation. The red lines denotes the mean bottom-up delay, as measured by Tomita et al.<sup><xref rid="c27" ref-type="bibr">27</xref></sup>.</p></caption>
<graphic xlink:href="334821_fig5.tif"/>
</fig>
<p>During stimulus-driven binding, we co-activate pairs of LTM memories. As before, when we used only one LTM network, this involves a brief 50 ms cue to each patterns specific sub-population, which then triggers activation of the corresponding attractor. As all long-term memories are encoded equally well in LTM, activations are almost perfectly synchronized. The multi-trial (and multi-pattern) average of peri-stimulus activations reveals a 45 &#x00B1; 7.3 ms attractor activation delay, followed by a 43 &#x00B1; 7.8 ms feedforward delay (about half of which is explained by the spatial distance between LTM and STM) from the practically simultaneous onset of the two LTM activations to the onset of the input-specific STM response (also <bold><xref rid="fig5" ref-type="fig">Figure 5</xref> top-left</bold>).</p>
<p>During WM maintenance, - a 10 s delay period - paired LTM memories reactivate together. Onset of these paired activations is a lot more variable than during cued activation, mostly because the driving STM-indices are of variable size and strength, which has an impact on the feedback delay distribution, with mean 41.5 &#x00B1; 15.3 ms.</p>
<p>Following the maintenance period, we test the memory system&#x2019;s ability for associative recall. To this end, we cue LTMa, again using a targeted 50 ms cue for each memory, and track the systems response across the cortical loop. We compute multi-trial averages of peri-stimulus activations during recall testing (<bold><xref rid="fig4" ref-type="fig">Figure 4</xref> bottom-right).</bold> Following cued activation of LTMa, STM responds with the related index as the input is strongly correlated to learned inputs from the simultaneous activation with LTMb earlier on, and input-specific STM activation patterns have become temporarily stable attractors in their own right. The completed STM index then triggers the associated memory in LTMb through its backprojections. STM activation extends beyond the transient activity of LTMa because the cortical loop keeps it active (now driven from LTMb-inputs). Temporal overlap between associated LTMa and LTMb memory activations peaks around 125 ms after the initial stimulus to LTMa.</p>
<p>We collect distributions of feedforward and feedback delays during associative recall (<bold><xref rid="fig5" ref-type="fig">Figure 5</xref>)</bold>. To facilitate a more immediate comparison with biological data we also computed the Bottom-Up and Top-Down response latency of the model in analogy to Tomita et al.<sup><xref rid="c27" ref-type="bibr">27</xref></sup>. Their study explicitly tested widely held believes about the executive control of PFC over ITC in memory retrieval. To this end, they identified and recorded neurons in ITC of monkeys trained to memorize several visual stimulusstimulus associations. They employed a posterior-split brain paradigm to cleanly disassociate the timing of the bottom-up (contralateral stimuli) and top-down response (ipsilateral stimuli) in 43 neurons significantly stimulus-selective in both conditions and observed that the latency of the topdown response (178 ms) was longer than that of the bottom-up response (73 ms).</p>
<p>Our simulation is analogous to this experimental setup with respect to some key features, such as the spatial extent of memory areas (about 289 mm<sup>2</sup>) and inter-area distances (40 mm cortical distance between PFC and ITC). These measures heavily influence the resulting connection delays and time needed for information integration. In analogy to the posterior-split brain experiment our model&#x2019;s LTMa and LTMb are unconnected. The display of a cue in one hemi-field in the experiment corresponds to the LTMa-sided stimulation of an associated memory pair in the model. This arrangement forces any LTM interaction through STM (representing PFC), and allows us to treat the cued LTMa memory activation as a Bottom-up response, whereas the much later activation of the associated LTMb representation is related to the Top-down response in the experimental study. <bold><xref rid="fig5" ref-type="fig">Figure 5</xref></bold> shows the distribution of these latencies in our simulations, where we also marked the mean latencies measured by Tomita et al. The mean of our bottom-up delay (72.9 ms) matches the experimental data (73 ms), whereas the mean of the broader top-down latency distribution (155.2 ms) is a bit lower than in the monkey study (178 ms). Of these 155.2 ms, only 48 ms are explained by the spatial distance between networks, as verified by a fully functional alternative model with 0 mm distance between networks.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have presented the design and evaluation of a spiking neural network WM model, featuring STM (PFC) and LTM components (temporal cortex) as well as fast Hebbian synaptic plasticity. We demonstrated how single memory items could be encoded by one-shot learning and how PFC rapidly enhances synaptic connections intrinsically as well as those targeting LTM representations, which are thereby &#x201C;brought on-line&#x201D;. The PFC cell assembly serves as a temporary index into LTM in a similar manner as suggested by the &#x201C;Hippocampal Indexing Theory&#x201D; for the relation between hippocampus and neocortex in episodic memory and memory consolidation<sup><xref rid="c17" ref-type="bibr">17</xref>,<xref rid="c32" ref-type="bibr">32</xref></sup>. When a pair of LTM items are bound together by being simultaneously indexed in this manner, activating one will also activate the other indirectly via PFC with a short latency. We further demonstrated that this kind of WM is readily updated such that as new items get encoded, old ones are gradually over-written.</p>
<p>Recall dynamics in the model presented is in most respects identical to our previous cortical associative memory models<sup><xref rid="c33" ref-type="bibr">33</xref></sup>. From that we can deduce e.g. that sequential learning and recall could readily be incorporated in the model<sup><xref rid="c34" ref-type="bibr">34</xref></sup>. This could support encoding of e.g. sequences of items in WM rather than unrelated ones, resulting in a reactivation dynamic reminiscent of the &#x201C;phonological loop&#x201D;<sup><xref rid="c35" ref-type="bibr">35</xref></sup>.</p>
<sec id="s3a">
<title>The Case for Hebbian Plasticity</title>
<p>A requirement of our model is fast Hebbian plasticity, not only in the intrinsic PFC connectivity, but also in the projections from PFC to LTM stores. The former has some experimental support<sup><xref rid="c21" ref-type="bibr">21</xref>,<xref rid="c22" ref-type="bibr">22</xref>,<xref rid="c36" ref-type="bibr">36</xref>,<xref rid="c37" ref-type="bibr">37</xref></sup> whereas the latter remains a prediction of the model. Dopamine D1 receptor (D1R) activation by dopamine (DA) is strongly implicated in reward learning and synaptic plasticity regulation in the basal ganglia<sup><xref rid="c38" ref-type="bibr">38</xref></sup>. In analogy we propose that D1R activation is also critically involved in the synaptic plasticity intrinsic to PFC and in projections to LTM stores which would also explain prominent WM effects of PFC DA level manipulation<sup><xref rid="c39" ref-type="bibr">39</xref>,<xref rid="c40" ref-type="bibr">40</xref></sup>. In our model, kappa represents the level of DA-D1R activation, which in turn regulates its synaptic plasticity. We typically increase kappa 4-8 fold temporarily in conjunction with LTM stimulation and WM encoding, i.e. a form of as attentional gating. Larger modulation limits WM capacity to 1-2 items, while less modulation diminishes the strength of cell assemblies beyond what is necessary for reactivation and LTM maintenance.</p>
<p>When the synaptic plasticity WM hypothesis was first presented and evaluated, it was based on synaptic facilitation<sup><xref rid="c16" ref-type="bibr">16</xref>,<xref rid="c29" ref-type="bibr">29</xref></sup>. However, such non-Hebbian plasticity is only capable of less specific forms of memory. Activating a cell assembly comprising a subset of neurons in a na&#x00EF;ve STM network would merely facilitate all outgoing synapses from active neurons. Likewise, an enhanced elevated resting potential resulting from intrinsic plasticity would make the targeted neurons more excitable. In either case, there would be no coordination of activity specifically within the stimulated cell assembly. Thus, if superimposed on an existing LTM such forms of plasticity may well contribute to WM, but they are alone not capable of supporting encoding of novel memory items or the multi-modal binding of already existing ones. In our previous paper<sup><xref rid="c19" ref-type="bibr">19</xref></sup> we showed that fast Hebbian plasticity in the form of STP<sup><xref rid="c21" ref-type="bibr">21</xref></sup> allows such one-shot encoding of new STM items. In the current extended model, by also assuming the same kind of plasticity in backprojections from PFC to parieto-temporal LTM stores, PFC will also be capable to bind and bring on-line previously not associated LTM items.</p>
<p>Our implementation of a fast Hebbian plasticity reproduces a remarkable aspect of STP: It decays in an activity-dependent manner<sup><xref rid="c36" ref-type="bibr">36</xref>,<xref rid="c37" ref-type="bibr">37</xref></sup>. Its decay is not noticeably time-dependent, and silence preserves synaptic information. The detrimental effects of distractors on performance in virtually all kinds of WM tasks suggests an activity-dependent update, as does the duration of &#x201C;activity-silent WM&#x201D; in recent experiments<sup><xref rid="c10" ref-type="bibr">10</xref></sup>. Although we used the BCPNN learning rule to reproduce these effects, we expect that other Hebbian learning rules allowing for neuromodulated fast synaptic plasticity could give comparable results.</p>
</sec>
<sec id="s3b">
<title>Model Robustness</title>
<p>Because our model is quite complex and synthesizes many different components and processes it is beyond the scope of this work to perform a detailed parameter sensitivity analysis. However, from our extensive simulations we conclude that it is generally robust and degrades gracefully. Almost all uncertain parameters can be varied &#x00B1;30&#x0025; without breaking WM function. The model is dramatically sub-sampled and scaling up would be possible. This could be expected to further improve overall robustness. Highly related modular cortical network models have been studied extensively elsewhere<sup><xref rid="c19" ref-type="bibr">19</xref>,<xref rid="c29" ref-type="bibr">29</xref>,<xref rid="c34" ref-type="bibr">34</xref>,<xref rid="c41" ref-type="bibr">41</xref>,<xref rid="c42" ref-type="bibr">42</xref></sup>, so we here prioritize novel aspects, namely the parameterization of corticocortical connectivity and spatial scale.</p>
<p>In the feedback pathway, a mere 0.66&#x0025; connectivity is sufficient to support STM-driven LTM activation in maintenance and recall. Even lower connectivity degrades WM capacity, unless we increase the total number of co-active STM cells by other means. Forward connectivity can be even lower (0.015&#x0025;), because terminal clusters in STM are smaller and provide more information contrast (see Online Methods). In both cases, our model uses these low density values, but they could be increased/decreased if single synaptic currents are reduced/increased proportionally. In fact, we found that we needed to increase the corticocortical conductance of the back-projections <inline-formula><alternatives><inline-graphic xlink:href="334821_inline4.gif"/></alternatives></inline-formula> by the same factor 1.8 (over the local conductance gain <inline-formula><alternatives><inline-graphic xlink:href="334821_inline5.gif"/></alternatives></inline-formula>) as another detailed model account of macaque visual cortex<sup><xref rid="c43" ref-type="bibr">43</xref></sup> to achieve functional WM at the stated long-distance connection probabilities.</p>
<p>There is an upper, but no lower limit on corticocortical distances in our model. When conduction delays exceed 65 ms (130 mm), STM feedback can no longer activate the LTM network, because bursts desynchronize before they arrive. On the other end, STM and LTM could even be adjacent as we briefly mentioned at the end of the result section. Additionally, there is a minimum spatial scale to each component network. Theta oscillations degrade at 45&#x0025; and completely break at 20&#x0025; spatial scale, when the largest inter-HC delays fall below 5 ms. Attractor activity then collapses into a single gamma cycle (rather than longer bursts), which degrades learning and effective information transmission both within and across networks. Networks may be much smaller however, but this needs to be compensated by slower axonal conductance velocities (&#x003C;2 mm/ms).</p>
</sec>
<sec id="s3c">
<title>Experimental support and testable predictions</title>
<p>Unfortunately, the detailed neural processes represented in our new model are not easily accessible experimentally and it is therefore quite hard to find direct and quantitative results to validate it. Yet, in analyzing our resulting bottom-up and top-down delays, we drew an analogy to a split-brain experiment<sup><xref rid="c27" ref-type="bibr">27</xref></sup> because of its clean experimental design (even controlling for subcortical pathways). The timing of inter-area signals also constitute a testable prediction for multi-modal memory experiments. Furthermore, reviews of intracranial recording conclude that theta band oscillations plays an important role in long-range communication during successful retrieval<sup><xref rid="c44" ref-type="bibr">44</xref></sup>. With respect to theta in our model, STM leads the rest of cortex during maintenance, engages bi-directionally during recall (due to the closed cortical loop), and lags with respect to the theta phase during stimulus-driven encoding and LTM activation, reflecting experimental observations<sup><xref rid="c45" ref-type="bibr">45</xref></sup>. These effects can be explained by our model architecture, which imposes delays due to the spatial extent of networks and their distances from each other. Gamma power, while often theta-nested, is more strongly linked to local processing and individual foreground items in our model, also matching experimental findings<sup><xref rid="c44" ref-type="bibr">44</xref></sup>. Cross frequency coupling is abundant with significant phase-amplitude coupling (e.g. <bold><xref rid="fig2" ref-type="fig">Figure 2B</xref></bold>), and was well characterized in related models<sup><xref rid="c46" ref-type="bibr">46</xref></sup>.</p>
<p>The most critical requirement and thus prediction of our model is the presence of fast Hebbian plasticity in the PFC back-projections to temporal memory areas. Without such plasticity, our model cannot explain STM-LTM binding. This is likely to co-exist with neuromodulatory control over that plasticity, likely with DA and D1R activation involvement. Since the STP decays with activity a high noise level could be an issue since it could shorten WM duration.</p>
<p>Our model also makes specific predictions about corticocortical long-range connectivity. For example, as few as six active synapses (see <bold>Online Methods</bold>) onto each coding pyramidal neuron is sufficient to transfer specific memory identities across the cortical hierarchy and to support maintenance and recall.</p>
<p>Finally, our model suggests the occurrence of a double peak of frontal activation in executive control of LTM memories (e.g. see STM EMA during WM Maintenance in <bold><xref rid="fig4" ref-type="fig">Figure 4</xref></bold>). The first one originates from the top-down control signal itself, and the second one is a result of corticocortical reentry of a successfully activated LTM. As such, the second peak should also be correlated to successful memory maintenance or associative recall.</p>
</sec>
<sec id="s3d">
<title>The Neural Binding Problem</title>
<p>The so called &#x201C;binding problem&#x201D; refers to the brain&#x2019;s ability to temporarily connect items previously not connected by earlier experience and learning<sup><xref rid="c47" ref-type="bibr">47</xref></sup>. The fast Hebbian plasticity proposed here as a mechanism for WM offers without any modification an additional possible neural mechanism for binding that solves the binding problem. For instance, visual feature binding refers to the instant association of e.g. shape and color of multiple objects without mixing them up during recall (<bold><xref rid="fig6" ref-type="fig">Figure 6A</xref></bold>). Suggested neural mechanisms include temporal binding by synchronization<sup><xref rid="c48" ref-type="bibr">48</xref></sup> or feature integration<sup><xref rid="c49" ref-type="bibr">49</xref></sup>. Filling roles with instances, like e.g. in &#x201C;Charlie is my parrot&#x201D;, is a second form of variablevalue binding (<bold><xref rid="fig6" ref-type="fig">Figure 6</xref>-B</bold>). This and other forms of neural binding underlie even more complex functions in human cognition including logic reasoning<sup><xref rid="c50" ref-type="bibr">50</xref></sup>. That PFC may be involved is supported by the fact that its temporary inactivation in humans affect feature binding<sup><xref rid="c51" ref-type="bibr">51</xref></sup>, and that successful feature binding requires attention<sup><xref rid="c23" ref-type="bibr">23</xref></sup>. Gamma band oscillations, frequently implicated when binding is observed, are also a prominent output of our model&#x2019;s WM networks<sup><xref rid="c52" ref-type="bibr">52</xref></sup>.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Feature binding and variable binding via PFC. A: Feature Binding:</title>
<p>When a red triangle and followed by a blue star is shown and attended these shape &#x2013; color binding is formed by fast Hebbian plasticity via PFC to form a composite cell assembly. It supports pattern completion meaning that stimulation with shape will trigger the color representation and vice versa. <bold>B: Name-Object binding:</bold> Initially the representation of &#x201C;parrot&#x201D; exists in LTM comprising symbolic and sub-symbolic components. When it is for the first time stated that &#x201C;Charlie is my parrot&#x201D;, the name &#x201C;Charlie&#x201D; is bound reciprocally by fast Hebbian plasticity via PFC to the parrot representation, thus temporarily extending the composite &#x201C;parrot&#x201D; cell assembly. Pattern completion now allows &#x201C;Charlie&#x201D; to trigger the entire assembly and &#x201C;flying&#x201D; or the sight of Charlie to trigger &#x201C;Charlie&#x201D;. If important enough or repeated a couple of times this association could consolidate in LTM.</p></caption>
<graphic xlink:href="334821_fig6.tif"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>Conclusions</title>
<p>Our simulations have demonstrated the versatile WM properties of a spiking neural network composed of STM and LTM components and we have partly connected them to existing experimental data. Although our model is still quite abstract, and theory and simulation models can never prove anything about biology, it nevertheless offers a biologically plausible mechanistic understanding of WM which connects microscopic processes with macroscopic observations and function in a way that only computational models can do. While we applied this model to macaque, it is quite generic and we expect model findings to apply also to mammals including human, commensurate with changes in key parameters (cortical distances, axonal conductance speeds, etc.).</p>
<p>WM dysfunction has an outsized impact on mental health, intelligence, and quality of life, progress in this respect is very important for society. Our hope is that our new computational model, which reproduces several important aspects of human WM, will trigger many more targeted experiments aimed to evaluate and improve it. More adequate models and understanding can help position future research and development appropriately even in the clinical and pharmaceutical realm.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by the EuroSPIN Erasmus Mundus doctoral program, SeRC (Swedish e-science Research Center), and StratNeuro (Strategic Area Neuroscience at Karolinska Institutet, Ume&#x00E5; University and KTH). The simulations were performed using computing resources provided by the Swedish National Infrastructure for Computing at PDC Centre for High Performance Computing. We are grateful for helpful comments and suggestions from Drs Jeanette Hellgren Kotaleski, and Arvind Kumar.</p>
</ack>
<sec id="s5" sec-type="COI-statement">
<title>Conflict of Interest</title>
<p>Nothing to declare</p>
</sec>
<sec id="s6">
<title>Online Methods</title>
<sec id="s6a">
<title>Neuron Model</title>
<p>We use an integrate-and-fire point neuron model with spike-frequency adaptation<sup><xref rid="c53" ref-type="bibr">53</xref></sup> which was modified<sup><xref rid="c42" ref-type="bibr">42</xref></sup> for compatibility with a custom-made BCPNN synapse model in NEST through the addition of the intrinsic excitability current <inline-formula><alternatives><inline-graphic xlink:href="334821_inline6.gif"/></alternatives></inline-formula>. The model was simplified by excluding the subthreshold adaptation dynamics. Membrane potential <italic>V</italic><sub><italic>m</italic></sub> and adaptation current are described by the following equations:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="334821_eqn1.gif"/></alternatives>
</disp-formula>
</p>
<p>The membrane voltage changes through incoming currents over the membrane capacitance <italic>C</italic><sub><italic>m</italic></sub>. A leak reversal potential <italic>E</italic><sub><italic>L</italic></sub> drives a leak current through the conductance <italic>g</italic><sub><italic>L</italic></sub>, and an upstroke slope factor &#x0394;<bold><sub><italic>T</italic></sub></bold> determines the sharpness of the spike threshold <italic>V</italic><sub><italic>t</italic></sub>. Spikes are followed by a reset of membrane potential to <italic>V</italic><sub><italic>r</italic></sub>. Each spike increments the adaptation current by <italic>b</italic>, which decays with time constant <inline-formula><alternatives><inline-graphic xlink:href="334821_inline7.gif"/></alternatives></inline-formula>. Simulated basket cells feature neither the intrinsic excitability current <inline-formula><alternatives><inline-graphic xlink:href="334821_inline8.gif"/></alternatives></inline-formula> nor this spike-triggered adaptation.</p>
<p>Besides external input <italic>I</italic><sub><italic>ext</italic></sub> (<italic>Stimulation Protocol</italic>) neurons receive a number of different synaptic currents from its presynaptic neurons in the network (AMPA, NMDA and GABA), which are summed at the membrane accordingly:
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="334821_eqn3.gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s6b">
<title>Synapse Model</title>
<p>Excitatory AMPA and NMDA synapses have a reversal potential <italic>E</italic><sup><italic>AMPA</italic></sup> = <italic>E</italic><sup><italic>NMDA</italic></sup>, while inhibitory synapses drive the membrane potential toward <italic>E</italic><sup><italic>GABA</italic></sup>. In addition to BCPNN learning (next Section), plastic synapses are also subject to synaptic depression (vesicle depletion) according to the TsodyksMarkram formalism<sup><xref rid="c54" ref-type="bibr">54</xref></sup>:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="334821_eqn4.gif"/></alternatives>
</disp-formula>
</p>
<p>The fraction of synaptic resources available at each synapse <inline-formula><alternatives><inline-graphic xlink:href="334821_inline9.gif"/></alternatives></inline-formula> is depleted by a synaptic utilization factor (<italic>U</italic>) with each spike transmission and decays with &#x03C4;<sub><italic>rec</italic></sub> back towards its maximum value of 1. Every presynaptic input spike (at <inline-formula><alternatives><inline-graphic xlink:href="334821_inline10.gif"/></alternatives></inline-formula> with transmission delay <italic>t</italic><sub><italic>ij</italic></sub>) thus evokes a transient synaptic current through a change in synaptic conductance that follows an exponential decay with time constants &#x03C4;<sup><italic>syn</italic></sup> depending on the synapse type (&#x03C4;<sup><italic>AMPA</italic></sup> <italic>&#x2264;</italic> &#x03C4;<sup><italic>NMDA</italic></sup>).</p>
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="334821_eqn5.gif"/></alternatives>
</disp-formula>
<p><italic>H</italic>(&#x00B7;) denotes the Heaviside step function, and <inline-formula><alternatives><inline-graphic xlink:href="334821_inline11.gif"/></alternatives></inline-formula> is the peak amplitude of the conductance transient, learned by the following <italic>Spike-based BCPNN Learning Rule</italic>.</p>
</sec>
<sec id="s6c">
<title>Spike-based BCPNN Learning Rule</title>
<p>Plastic AMPA and NMDA synapses are modeled to mimic short-term potentiation (STP)<sup><xref rid="c21" ref-type="bibr">21</xref></sup> with a spikebased version of the Bayesian Confidence Propagation Neural Network (BCPNN) learning rule<sup><xref rid="c42" ref-type="bibr">42</xref>,<xref rid="c55" ref-type="bibr">55</xref></sup>. For a full derivation from Bayes rule, deeper biological motivation, and proof of concept, see <xref rid="c42" ref-type="bibr">Tully et al. (2014)</xref> and the earlier STM model implementation<sup><xref rid="c19" ref-type="bibr">19</xref></sup>.</p>
<p>Briefly, the BCPNN learning rule makes use of biophysically plausible local traces to estimate normalized preand post-synaptic firing rates, as well as co-activation, which can be combined to implement Bayesian inference because connection strengths and MC activations have a statistical interpretation<sup><xref rid="c13" ref-type="bibr">13</xref>,<xref rid="c17" ref-type="bibr">17</xref>,<xref rid="c42" ref-type="bibr">42</xref></sup>. Crucial parameters include the synaptic activation trace Z, which is computed from spike trains via preand post-synaptic time constants <inline-formula><alternatives><inline-graphic xlink:href="334821_inline12.gif"/></alternatives></inline-formula>, which are the same here but differ between AMPA and NMDA synapses:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="334821_eqn6.gif"/></alternatives>
</disp-formula>
</p>
<p>The larger NMDA time constant reflects the slower closing dynamics of NMDA-receptor gated channels. All excitatory connections are drawn as AMPA and NMDA pairs, such that they feature both components. Further filtering of the Z traces leads to rapidly expressing memory traces (referred to as P-traces) that estimate activation and coactivation:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="334821_eqn7.gif"/></alternatives>
</disp-formula>
</p>
<p>These traces constitute memory itself and decay in a palimpsest fashion. STP decay is known to take place on timescales that are highly variable and activity dependent<sup><xref rid="c37" ref-type="bibr">37</xref></sup>; see Discussion &#x2013; The case for Hebbian plasticity.</p>
<p>We make use of the learning rule parameter <italic>k</italic> (<bold><xref ref-type="disp-formula" rid="eqn7">Equation 7</xref></bold>), which may reflect the action of endogenous neuromodulators, like e.g. dopamine acting on D1 receptors, that signal relevance and thus modulate learning efficacy. It can be dynamically modulated to switch off learning to fixate the network, or temporarily increase plasticity (<italic>k</italic><sub><italic>p</italic></sub>, <italic>k</italic><sub><italic>normal</italic></sub>, <bold>Supplementary Table 1</bold>). In particular, we trigger a transient increase of plasticity concurrent with external stimulation.</p>
<p>Tully et al. <sup><xref rid="c42" ref-type="bibr">42</xref></sup> show that Bayesian inference can be recast and implemented in a network using the spike-based BCPNN learning rule. Prior activation levels are realized as an intrinsic excitability of each postsynaptic neuron, which is derived from the post-synaptic firing rate estimate pj and implemented in the NEST neural simulator<sup><xref rid="c56" ref-type="bibr">56</xref></sup> as an individual neural current <inline-formula><alternatives><inline-graphic xlink:href="334821_inline13.gif"/></alternatives></inline-formula> with scaling constant &#x03B2;<sub>gain</sub>
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="334821_eqn8.gif"/></alternatives>
</disp-formula>
<inline-formula><alternatives><inline-graphic xlink:href="334821_inline14.gif"/></alternatives></inline-formula> is thus an activity-dependent intrinsic membrane current to the neurons, similar to the A-type K&#x002B; channel <sup><xref rid="c57" ref-type="bibr">57</xref></sup> or TRP channel <sup><xref rid="c58" ref-type="bibr">58</xref></sup>. Synaptic weights are modeled as peak amplitudes of the conductance transient (<bold><xref ref-type="disp-formula" rid="eqn5">Equation 5</xref></bold>) and determined from the logarithmic BCPNN weight, as derived from the Ptraces with a synaptic scaling constant<inline-formula><alternatives><inline-graphic xlink:href="334821_inline15.gif"/></alternatives></inline-formula>.</p>
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="334821_eqn9.gif"/></alternatives>
</disp-formula>
<p>In our model, AMPA and NMDA synapses make use of <inline-formula><alternatives><inline-graphic xlink:href="334821_inline16.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="334821_inline17.gif"/></alternatives></inline-formula> respectively. The logarithm in <bold><xref ref-type="disp-formula" rid="eqn8">Equations 8</xref>,9</bold> is motivated by the Bayesian underpinnings of the learning rule, and means that synaptic weights <inline-formula><alternatives><inline-graphic xlink:href="334821_inline18.gif"/></alternatives></inline-formula> multiplex both the learning of excitatory and di-synaptic inhibitory interaction. The positive weight component is here interpreted as the conductance of a monosynaptic excitatory pyramidal to pyramidal synapse (<bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>, plastic connection to the co-activated MC), while the negative component (<bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>, plastic connection to the competing MC) is interpreted as di-synaptic via a dendritic targeting and vertically projecting inhibitory interneuron like a double bouquet and/or bipolar cell<sup><xref rid="c59" ref-type="bibr">59</xref>&#x2013;<xref rid="c62" ref-type="bibr">62</xref></sup>. Accordingly, BCPNN connections with a negative weight use a GABAergic reversal potential instead, as in previously published models<sup><xref rid="c19" ref-type="bibr">19</xref>,<xref rid="c25" ref-type="bibr">25</xref>,<xref rid="c42" ref-type="bibr">42</xref></sup>. Model networks with negative synaptic weights have been shown to be functionally equivalent to ones with both excitatory and inhibitory neurons with only positive weights<sup><xref rid="c63" ref-type="bibr">63</xref></sup>.</p>
<p>Code for the NEST implementation of the BCPNN synapse is openly available (see <bold>Simulation Environment</bold>).</p>
</sec>
<sec id="s6d">
<title>Axonal Conduction Delays</title>
<p>We compute axonal delays <italic>t</italic><sub><italic>ij</italic></sub> between presynaptic neuron i and postsynaptic neuron j, based on a constant conduction velocity <italic>V</italic> and the Euclidean distance between respective columns. Conduction delays were randomly drawn from a normal distribution with mean according to the connection distance divided by conduction speed and with a relative standard deviation of 15&#x0025; of the mean in order to account for individual arborization differences. Further, we add a minimal conduction delay <inline-formula><alternatives><inline-graphic xlink:href="334821_inline19.gif"/></alternatives></inline-formula> of 1.5 ms to reflect not directly modeled delays, such as diffusion of transmitter over the synaptic cleft, dendritic branching, thickness of the cortical sheet, and the spatial extent of columns:
<disp-formula id="eqn7a">
<alternatives><graphic xlink:href="334821_eqn7a.gif"/></alternatives>
</disp-formula>
</p>
<fig id="figS1a" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Local columnar connectivity within STM and LTM.</title>
<p>Connection probabilities are given by the percentages, further details in <bold>Supplementary Tables 1 and 3</bold>. The strength of plastic connections develops according to the synaptic learning rule described in <italic>Spike-based Bayesian Learning</italic>. Dashed connections are not plastic in LTM (besides the STD of <bold><xref ref-type="disp-formula" rid="eqn4">Equation 4</xref></bold>), but already encode attractors previously learned through an LTP protocol, and loaded at simulation using effective weights found in <bold>Supplementary Table 2</bold>.</p></caption>
<graphic xlink:href="334821_figS1.tif"/>
</fig>
</sec>
<sec id="s6e">
<title>STM Network Architecture</title>
<p>We simulate <inline-formula><alternatives><inline-graphic xlink:href="334821_inline20.gif"/></alternatives></inline-formula> HC on a grid with spatial extent of 17&#x00D7;17 mm. This spatially distributed network of columns has sizable conduction delays due to the distance between columns and can be interpreted as a spatially distributed subsampling of columns from the extent of dorsolateral PFC (such as BA 46 and 9/46, which also have a combined spatial extent of about 289 mm<sup>2</sup> in macaque).</p>
<p>Each of the non-overlapping HCs has a diameter of about 640 &#x03BC;m, comparable to estimates of cortical column size<sup><xref rid="c64" ref-type="bibr">64</xref></sup>, contains 24 basket cells, and its pyramidal cell population has been divided into twelve functional columns (MC). This constitutes another sub-sampling from the roughly 100 MC per HC when mapping the model to biological cortex. We simulate 20 pyramidal neurons per MC to represent roughly the layer 2 population of a MC, 5 cells for layer 3A, 5 cells for layer 3B, and another 30 pyramidal cells for layer 4, as macaque BA 46 and 9/46 have a well-developed granular layer<sup><xref rid="c65" ref-type="bibr">65</xref></sup>. The STM model thus contains about 18.000 simulated pyramidal cells in four layers (although layers 2, 3A, and 3B are often treated as one layer 2/3).</p>
</sec>
<sec id="s6f">
<title>STM Network Connectivity</title>
<p>The most relevant connectivity parameters are found in <bold>Supplementary Tables 1-3</bold>. Pyramidal cells project laterally to basket cells within their own HC via AMPA-mediated excitatory projections with a connection probability of <italic>p</italic><sub><italic>P-</italic><bold><italic>B</italic></bold></sub>, i.e. connections are randomly drawn without duplicates until the target fraction of all possible pre-post connections exist. In turn, they receive GABAergic feedback inhibition from basket cells (<italic>p</italic><sub><bold><italic>B</italic></bold><italic>-P</italic></sub>) that connect via static inhibitory synapses rather than plastic BCPNN synapses. This strong loop implements a competitive soft-WTA subnetwork within each HC <sup><xref rid="c66" ref-type="bibr">66</xref></sup>. Local basket cells fire in rapid bursts, and induces alpha/beta oscillations in the absence of attractor activity and gamma, when attractors are present and active.</p>
<p>Pyramidal cells in layer 2/3 form connections both within and across HCs at connection probability <italic>p</italic><sub><italic>L</italic><bold><italic>23e</italic></bold><italic>-L</italic><bold><italic>23e</italic></bold></sub>. These projections are implemented with plastic synapses and contain parallel AMPA and an NMDA components, as explained in subsection <italic>Spike-based BCPNN Learning Rule.</italic> Connections across columns and areas may feature sizable conduction delays due to the implied spatial distance between them (<italic>Online Methods</italic>, and <bold>Supplementary Table 1</bold>)</p>
<p>Pyramidal cells in layer 4 project to pyramidal cells of layer 2/3, targeting 25&#x0025; of cells within their respective MC only. Experimental characterization of excitatory connections from layer 4 to layer 2/3 pyramidal cells have confirmed similarly high fine-scale specificity in rodent cortex<sup><xref rid="c67" ref-type="bibr">67</xref></sup> and in-turn, fullscale cortical simulation models without functional columns have found it necessary to specifically strengthen these connections to achieve defensible firing rates<sup><xref rid="c68" ref-type="bibr">68</xref></sup>.</p>
<p>In summary, the STM model thus features a total of 16.2 million plastic AMPAand NMDA-mediated connections between 18.000 simulated pyramidal cells in STM, as well as 67.500 static connections from 9.000 layer 4 pyramidals to layer 2/3 targets within their respective MC, and 604.800 static connections to and from 600 simulated basket cells.</p>
</sec>
<sec id="s6g">
<title>LTM network</title>
<p>We simulate two structurally identical LTM networks, referred to as LTMa, and LTMb. LTM networks may be interpreted as a spatially distributed subsampling of columns from areas of the temporal cortex commonly associated with auditory and visual LTM. For example Inferior Temporal Cortex (ITC) is often referred to as the storehouse of visual LTM<sup><xref rid="c69" ref-type="bibr">69</xref></sup>. Two such LTM areas are indicated in <bold><xref rid="fig1" ref-type="fig">Figure 1</xref>.</bold></p>
<p>We simulate <inline-formula><alternatives><inline-graphic xlink:href="334821_inline21.gif"/></alternatives></inline-formula> HC in each area and nine MC per HC (further details in <bold>Supplementary Tables 1-3</bold>). Both LTM networks are structurally very similar to the previously described STM, yet they do not feature plasticity beyond short-term dynamics in the form of synaptic depression. Unlike STM, LTM areas also do not feature an input layer 4, but are instead stimulated directly to cue the activation of previously learned long-term memories (<italic>Online Methods</italic>). Various previous models with identical architecture have demonstrated how attractors can be learned via plastic BCPNN synapses<sup><xref rid="c18" ref-type="bibr">18</xref>,<xref rid="c19" ref-type="bibr">19</xref>,<xref rid="c25" ref-type="bibr">25</xref>,<xref rid="c42" ref-type="bibr">42</xref></sup>. We load each LTM network with nine orthogonal attractors. Each memory pattern consists of 16 active MCs, distributed across the 16 HCs of the network. We load-in BCPNN weights from a previously trained network (<bold>Supplementary Table 2</bold>), but thereafter set <italic>k</italic> = <bold>0</bold> to deactivate plasticity in all LTM stores.</p>
<p>In summary, the two LTM models thus features a total of 7.46 million connections between 8.640 pyramidal cells, as well as 13.608 static connections to and from 576 basket cells.</p>
</sec>
<sec id="s6h">
<title>Corticocortical Connectivity</title>
<p>Our model implements supragranular feedforward and feedback pathways, as inspired by recent characterizations of such pathways by Markov et al.<sup><xref rid="c70" ref-type="bibr">70</xref></sup> between cortical areas that are at a medium distance in the cortical hierarchy. The approximate cortical distance between Inferior Temporal Cortex (ITC) and dlPFC in macque is about 40 mm and with an axonal conductance speed of 2 m/s, distributed conduction delays in our model (<bold><xref ref-type="disp-formula" rid="eqn9">Equation 9</xref></bold>) average just above 20 ms between these areas<sup><xref rid="c71" ref-type="bibr">71</xref>&#x2013;<xref rid="c73" ref-type="bibr">73</xref></sup>.</p>
<p>In the forward path, layer 3B cells in LTM project towards STM (<bold><xref rid="fig1" ref-type="fig">Figure 1</xref></bold>). We do not draw these connection one-by-one, but as branching axons targeting 25&#x0025; of the pyramidal cells in a randomly chosen MC (the chance of any layer 3B cell to target any MC in STM is only 0.0015). The resulting split between targets in layer 2/3 and 4 is typical for feedforward connections at medium distances in the cortical hierarchy<sup><xref rid="c70" ref-type="bibr">70</xref></sup> and has important functional implications for the model (<italic>Cortical Forward Dynamics</italic>). To increase the information contrast in the forward response and balance the total current delivered to STM we also branch off some inhibitory corticocortical connections as follows: For every excitatory connection within the selected targeted MC, an inhibitory connection is created from the same pyramidal layer 3B source cell onto a randomly selected cell outside the targeted MC, but inside the local HC. This is best understood as di-synaptic inhibition via a vertically projecting inhibitory interneuron like a double bouquet and/or bipolar cell<sup><xref rid="c59" ref-type="bibr">59</xref>&#x2013;<xref rid="c62" ref-type="bibr">62</xref></sup>. Although we do not explicitly simulate such cells, such an interneuron would be local to a MC and targeted by incoming excitatory connections (same arrangement as <xref rid="c42" ref-type="bibr">Tully et al. 2014</xref>, <xref rid="c25" ref-type="bibr">2016</xref>). Simultaneous inputs add in non-trivial ways, as excitation and inhibition from several inputs can interfere with each other. This way of drawing random forward-projections retains a degree of functional specificity due to its spatial clustering and yields patchy sparse forward-projections with a resulting inter-area connection probability of only 0.0125&#x0025; (648 projections from L3B cells to STM layers 2/3 and 4 results in &#x02DC;20k total connections after branching as described above.</p>
<p>Long feedback pathways across the cortical hierarchy are dominated by infra-granular projections (projections from large cells in layer 5 and 6), yet especially between association cortices and at short and medium range there are reciprocal projections from layer 3A cells to the cortical areas below <sup><xref rid="c70" ref-type="bibr">70</xref></sup>. In our model we draw sparse plastic connections from layer 3A cells in STM to layer 2/3 cells in LTM: Branching axons target 25&#x0025; of the pyramidal cells in a randomly chosen HC in LTM, again simulating a degree of axonal branching found in the literature<sup><xref rid="c74" ref-type="bibr">74</xref></sup>. Using this method, we obtain biologically plausible sparse and structured feedback projections with an inter-area connection probability of 0.66&#x0025;, which &#x2013; unlike the forward pathway &#x2013; do not have any built-in MC-specificity but may develop such through activity dependent plasticity. More parameters on corticocortical projections can be found in <bold>Supplementary Table 3.</bold> On average, each LTM pyramidal cell receives about 120 corticocortical connections from STM. Because about 5&#x0025; of STM cells fire together during memory reactivation, this means that a mere 6 active synapses per target cell are sufficient for driving (and thus maintaining) LTM activity from STM (there are 96 active synapses from coactive pyramidal cells in LTM).</p>
<p>Notably LTMa and LTMb have no direct pathways connecting them in our model since plasticity of biological connections are likely too slow (LTP timescale) to make a difference in WM dynamics. This arrangement also guarantees that any binding of long-term memories across LTM areas must be the result of interaction via STM instead. Corticocortical connectivity is very sparse, below 1&#x0025; total network connectivity.</p>
</sec>
<sec id="s6i">
<title>Stimulation Protocol</title>
<p>The term <italic>I</italic><sub><italic>ext</italic></sub> in <bold><xref ref-type="disp-formula" rid="eqn1">Equation 1</xref></bold> subsumes specific and unspecific external inputs. To simulate unspecific input from non-simulated columns, and other areas, pyramidal cells are continually stimulated with a zero mean noise background throughout the simulation. In each layer, two independent Poisson sources generate spikes at rate<inline-formula><alternatives><inline-graphic xlink:href="334821_inline22.gif"/></alternatives></inline-formula>, and connect onto all pyramidal neurons in that layer, via nondepressing conductances <inline-formula><alternatives><inline-graphic xlink:href="334821_inline23.gif"/></alternatives></inline-formula> (<bold>Supplementary Table 2</bold>).</p>
<p>To cue the activation of a specific attractor, we drive LTM pyramidal cells belonging to a memory patterns component MC with an additional excitatory Poisson spike train (rate <italic>r</italic><bold><sub><italic>cue</italic></sub></bold>, length <italic>t</italic><bold><sub><italic>cue</italic></sub></bold>, conductance <italic>g</italic><bold><sub><italic>cue</italic></sub></bold>). As LTM attractors are already strongly encoded in each LTM, a single, targeted 50 ms cue is usually sufficient to activate any given memory.</p>
</sec>
<sec id="s6j">
<title>Spike Train Analysis and Memory Activity Tracking</title>
<p>We track memory activity in time by analyzing the exponential moving average (EMA) of patternspecific and network-wide spiking activity usually using a filter time-constant of 20 ms. As activations are characterized by sizable gamma-bursts, a simple threshold detector can extract candidate activation events and decode the activated pattern (which is trivial due to the orthogonal and known nature of LTM activation patterns). We measure onset and offset by thresholding each individual activation by half of its peak value. In LTM, we further assess pattern completion by checking for component MC activation. Whenever targeted stimuli are used, we analyze peri-stimulus activation traces. When activations onsets are less predictable, such as during WM maintenance, we extract activations candidates via a threshold detector trained at the 50<sup>th</sup> percentile of the cumulative distribution of the EMA signal.</p>
</sec>
<sec id="s6k">
<title>Simulation Environment</title>
<p>We use the NEST simulator<sup><xref rid="c56" ref-type="bibr">56</xref></sup> version 2.2 for our simulations, running on a Cray XC-40 Supercomputer of the PDC Centre for High Performance Computing. The custom-build spiking neural network implementation of the BCPNN learning rule for MPI-parallelized NEST is available on github: <ext-link ext-link-type="uri" xlink:href="https://github.com/Florian-Fiebig/BCPNN-for-NEST222-MPI">https://github.com/Florian-Fiebig/BCPNN-for-NEST222-MPI</ext-link></p>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1.</label>
<caption><title>Neurons, synapses, and plasticity.</title></caption>
<graphic xlink:href="334821_tblS1.tif"/>
</table-wrap>
<table-wrap id="tblS2" orientation="portrait" position="float">
<label>Table S2.</label>
<caption><title>Network size, Conduction delay, Stimulation, LTM Preload BCPNN weights. Layer 4 for not simulated in LTM.</title></caption>
<graphic xlink:href="334821_tblS2.tif"/>
</table-wrap>
<table-wrap id="tblS3" orientation="portrait" position="float">
<label>Table S3.</label>
<caption><title>Projections</title></caption>
<graphic xlink:href="334821_tblS3.tif"/>
</table-wrap>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Slifstein</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Deficits in prefrontal cortical and extrastriatal dopamine release in schizophrenia a positron emission tomographic functional magnetic resonance imaging study</article-title>. <source>JAMA Psychiatry</source> <volume>72</volume>, <fpage>316</fpage>&#x2013;<lpage>324</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Fuster</surname>, <given-names>J. M.</given-names></string-name> <article-title>Cortex and Memory: Emergence of a New Paradigm</article-title>. <source>J. Cogn. Neurosci</source>. <volume>21</volume>, <fpage>2047</fpage>&#x2013;<lpage>2072</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>D&#x2019;Esposito</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name> <article-title>The Cognitive Neuroscience of Working Memory</article-title>. <source>Annu. Rev. Psychol</source>. <volume>66</volume>, <fpage>115</fpage>&#x2013;<lpage>142</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Funahashi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bruce</surname>, <given-names>C. J.</given-names></string-name> &#x0026; <string-name><surname>Goldman-Rakic</surname>, <given-names>P. S.</given-names></string-name> <article-title>Mnemonic coding of visual space in the monkey&#x2019;s dorsolateral prefrontal cortex</article-title>. <source>J. Neurophysiol</source>. <volume>61</volume>, <fpage>331</fpage>&#x2013;<lpage>349</lpage> (<year>1989</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Goldman-Rakic</surname>, <given-names>P. S.</given-names></string-name> <article-title>Cellular basis of working memory</article-title>. <source>Neuron</source> <volume>14</volume>, <fpage>477</fpage>&#x2013;<lpage>485</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Camperi</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> <article-title>A model of visuospatial working memory in prefrontal cortex: Recurrent network and cellular bistability</article-title>. <source>J. Comput. Neurosci</source>. <volume>5</volume>, <fpage>383</fpage>&#x2013;<lpage>405</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Compte</surname>, <given-names>A.</given-names></string-name> <article-title>Synaptic Mechanisms and Network Dynamics Underlying Spatial Working Memory in a Cortical Network Model</article-title>. <source>Cereb. Cortex</source> <volume>10</volume>, <fpage>910</fpage>&#x2013;<lpage>923</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Shafi</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Variability in neuronal activity in primate cortex during working memory tasks</article-title>. <source>Neuroscience</source> <volume>146</volume>, <fpage>1082</fpage>&#x2013;<lpage>1108</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Lundqvist</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Gamma and Beta Bursts Underlie Working Memory</article-title>. <source>Neuron</source> <volume>90</volume>, <fpage>152</fpage>&#x2013;<lpage>164</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name> <article-title>&#x2018;Activity-silent&#x2019; working memory in prefrontal cortex: A dynamic coding framework</article-title>. <source>Trends Cogn. Sci</source>. <volume>19</volume>, <fpage>394</fpage>&#x2013;<lpage>405</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Reilly</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Braver</surname>, <given-names>T. S.</given-names></string-name> &#x0026; <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name> <article-title>A Biologically-Based Computational Model of Working Memory</article-title>. <source>Model. Work. Mem. Mech. Act. Maint. Exec. Control</source> <fpage>375</fpage>&#x2013;<lpage>411</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="confproc"><collab>Lansner, Sandberg, Petersson &#x0026; Ingvar</collab>. <article-title>On forgetful attractor network memories</article-title>. in <conf-name>Artificial neural networks in medicine and biology: Proceedings of the ANNIMAB-1 Conference</conf-name> <fpage>54</fpage>&#x2013;<lpage>62</lpage> (<conf-loc>Springer, London</conf-loc>, <year>2000</year>). doi:<pub-id pub-id-type="doi">10.1007/978-1-4471-0513-8&#x005F;7</pub-id></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Sandberg</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Petersson</surname>, <given-names>K. M.</given-names></string-name> &#x0026; <string-name><surname>Ekeberg</surname>, <given-names>O.</given-names></string-name> <article-title>A Bayesian attractor network with incremental learning</article-title>. <source>Network</source> <volume>13</volume>, <fpage>179</fpage>&#x2013;<lpage>194</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Sandberg</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tegn&#x00E9;r</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>A working memory model based on fast Hebbian learning</article-title>. <source>Network: Computation in Neural Systems</source> <volume>14</volume>, <fpage>789</fpage>&#x2013;<lpage>802</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Amit</surname>, <given-names>D. J.</given-names></string-name> &#x0026; <string-name><surname>Mongillo</surname>, <given-names>G.</given-names></string-name> <article-title>Spike-Driven Synaptic Dynamics Generating Working Memory States</article-title>. <source>Neural Comput</source>. <volume>15</volume>, <fpage>565</fpage>&#x2013;<lpage>596</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Mongillo</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Barak</surname>, <given-names>O.</given-names></string-name> &#x0026; <string-name><surname>Tsodyks</surname>, <given-names>M.</given-names></string-name> <article-title>SynaptiC Theory of Working Memory</article-title>. <source>Science (80-.)</source>. <volume>319</volume>, <fpage>1543</fpage>&#x2013;<lpage>1546</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Fiebig</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Memory consolidation from seconds to weeks: a three-stage neural network model with autonomous reinstatement dynamics</article-title>. <source>Front. Comput. Neurosci</source>. <volume>8</volume>, <fpage>1</fpage>&#x2013;<lpage>17</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Marklund</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Sikstr&#x00F6;m</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Nilsson</surname>, <given-names>L.</given-names></string-name> <article-title>Reactivation in Working Memory: An Attractor Network Model of Free Recall</article-title>. <source>PLoS One</source> <volume>8</volume>, <fpage>e73776</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Fiebig</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>A Spiking Working Memory Model Based on Hebbian Short-Term Potentiation</article-title>. <source>J. Neurosci</source>. <volume>37</volume>, <fpage>83</fpage>&#x2013;<lpage>96</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Hanse</surname>, <given-names>E.</given-names></string-name> &#x0026; <string-name><surname>Gustafsson</surname>, <given-names>B.</given-names></string-name> <article-title>Onset and stabilization of NMDA receptor-dependent hippocampal long-term potentiation</article-title>. <source>Neurosci. Res</source>. <volume>20</volume>, <fpage>15</fpage>&#x2013;<lpage>25</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Erickson</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Maramara</surname>, <given-names>L. A.</given-names></string-name> &#x0026; <string-name><surname>Lisman</surname>, <given-names>J.</given-names></string-name> <article-title>A Single Brief Burst Induces GluR1-dependent Associative Short-term Potentiation: A Potential Mechanism for Short-term Memory</article-title>. <source>J. Cogn. Neurosci</source>. <volume>22</volume>, <fpage>2530</fpage>&#x2013;<lpage>2540</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Park</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>NMDA receptor-dependent long-term potentiation comprises a family of temporally overlapping forms of synaptic plasticity that are induced by different patterns of stimulation</article-title>. <source>Philos. Trans. R. Soc. Lond. B. Biol. Sci</source>. <volume>369</volume>, <fpage>20130131</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Adam</surname>, <given-names>G.</given-names></string-name> <article-title>The relationship between attention and working memory</article-title>. <source>Front. Hum. Neurosci</source>. <volume>5</volume>, <fpage>1</fpage>&#x2013;<lpage>45</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Norris</surname>, <given-names>D.</given-names></string-name> <article-title>Short-term memory and long-term memory are still different</article-title>. <source>Psychol. Bull</source>. <volume>143</volume>, <fpage>992</fpage>&#x2013;<lpage>1009</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Tully</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Lind&#x00E9;n</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Enrik, Hennig</surname>, <given-names>M. H.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Spike-Based Bayesian-Hebbian Learning of Temporal Sequences</article-title>. <source>PLoS Comput. Biol</source>. <volume>12</volume>, <fpage>e1004954</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Lundqvist</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rehn</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Djurfeldt</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Attractor dynamics in a modular network model of neocortex</article-title>. <source>Netw. Comput. Neural Syst</source>. <volume>17</volume>, <fpage>253</fpage>&#x2013;<lpage>276</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Tomita</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ohbayashi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nakahara</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hasegawa</surname>, <given-names>I.</given-names></string-name> &#x0026; <string-name><surname>Miyashita</surname>, <given-names>Y.</given-names></string-name> <article-title>Top-down signal from prefrontal cortex in executive control of memory retrieval</article-title>. <source>Nature</source> <volume>401</volume>, <fpage>699</fpage>&#x2013;<lpage>703</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Lundqvist</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Compte</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Bistable, irregular firing and population oscillations in a modular attractor memory network</article-title>. <source>PLoS Comput Biol</source>. <volume>6</volume>, (<year>2010</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Lundqvist</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Herman</surname>, <given-names>P.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Theta and gamma power increases and alpha/beta power decreases with memory load in an attractor network model</article-title>. <source>J. Cogn. Neurosci</source>. <volume>23</volume>, <fpage>3008</fpage>&#x2013;<lpage>3020</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Silverstein</surname>, <given-names>D. N.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Is Attentional Blink a Byproduct of Neocortical Attractors?</article-title> <source>Front. Comput. Neurosci</source>. <volume>5</volume>, (<year>2011</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Mi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Katkov</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Tsodyks</surname>, <given-names>M.</given-names></string-name> <article-title>Synaptic Correlates of Working Memory Capacity</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>323</fpage>&#x2013;<lpage>330</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Teyler</surname>, <given-names>T. J.</given-names></string-name> &#x0026; <string-name><surname>Rudy</surname>, <given-names>J. W.</given-names></string-name> <article-title>The hippocampal indexing theory and episodic memory: Updating the index</article-title>. <source>Hippocampus</source> <volume>17</volume>, <fpage>1158</fpage>&#x2013;<lpage>1169</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Associative memory models: from the cell-assembly theory to biophysically detailed cortex simulations</article-title>. <source>Trends in Neurosciences</source> <volume>32</volume>, <fpage>178</fpage>&#x2013;<lpage>186</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Tully, Lind&#x00E9;n</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hennig</surname>, <given-names>M. H.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Probabilistic computation underlying sequence learning in a spiking attractor memory network</article-title>. <source>BMC Neurosci</source>. <volume>14</volume>, <fpage>P236</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Baddeley</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gathercole</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Papagno</surname>, <given-names>C.</given-names></string-name> <article-title>The Phonological Loop as a Language Learning Device</article-title>. <source>Psychol. Rev</source>. <volume>105</volume>, <fpage>158</fpage>&#x2013;<lpage>173</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Volianskis</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Jensen</surname>, <given-names>M. S.</given-names></string-name> <article-title>Transient and sustained types of long-term potentiation in the CA1 area of the rat hippocampus</article-title>. <source>J. Physiol</source>. <volume>550</volume>, <fpage>459</fpage>&#x2013;<lpage>92</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Volianskis</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>Long-term potentiation and the role of N-methyl-D-aspartate receptors</article-title>. <source>Brain Res</source>. <volume>1621</volume>, <fpage>5</fpage>&#x2013;<lpage>16</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Wickens</surname>, <given-names>J. R.</given-names></string-name> <article-title>Synaptic plasticity in the basal ganglia</article-title>. <source>Behavioural Brain Research</source> <volume>199</volume>, <fpage>119</fpage>&#x2013;<lpage>128</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Arnsten, A. F.</surname> <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Jin</surname>, <given-names>L. E.</given-names></string-name> <article-title>Molecular influences on working memory circuits in dorsolateral prefrontal cortex</article-title>. <source>Prog. Mol. Biol. Transl. Sci</source>. <volume>122</volume>, <fpage>211</fpage>&#x2013;<lpage>231</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Goto</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>C. R.</given-names></string-name> &#x0026; <string-name><surname>Otani</surname>, <given-names>S.</given-names></string-name> <article-title>Functional and Dysfunctional Synaptic Plasticity in Prefrontal Cortex: Roles in Psychiatric Disorders</article-title>. <source>Biological Psychiatry</source> <volume>67</volume>, <fpage>199</fpage>&#x2013;<lpage>207</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Lundqvist</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Compte</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Bistable, irregular firing and population oscillations in a modular attractor memory network</article-title>. <source>PLoS Comput. Biol</source>. <volume>6</volume>, <fpage>1</fpage>&#x2013;<lpage>12</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Tully</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Hennig</surname>, <given-names>M. H.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Synaptic and nonsynaptic plasticity approximating probabilistic inference</article-title>. <source>Front. Synaptic Neurosci</source>. <volume>6</volume>, (<year>2014</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="other"><string-name><surname>Schmidt</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Full-density multi-scale account of structure and dynamics of macaque visual cortex</article-title>. (<year>2015</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Johnson</surname>, <given-names>E. L.</given-names></string-name> &#x0026; <string-name><surname>Knight</surname>, <given-names>R. T.</given-names></string-name> <article-title>Intracranial recordings and human memory</article-title>. <source>Current Opinion in Neurobiology</source> <volume>31</volume>, <fpage>18</fpage>&#x2013;<lpage>25</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Anderson</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Rajagovindan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ghacibeh</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Meador</surname>, <given-names>K. J.</given-names></string-name> &#x0026; <string-name><surname>Ding</surname>, <given-names>M.</given-names></string-name> <article-title>Theta oscillations mediate interaction between prefrontal cortex and medial temporal lobe in human memory</article-title>. <source>Cereb. Cortex</source> <volume>20</volume>, <fpage>1604</fpage>&#x2013;<lpage>1612</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Herman</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Lundqvist</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Nested theta to gamma oscillations and precise spatiotemporal firing during memory retrieval in a simulated attractor network</article-title>. in <source>Brain Research</source> <volume>1536</volume>, <fpage>68</fpage>&#x2013;<lpage>87</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="book"><string-name><surname>Cer</surname>, <given-names>D. M.</given-names></string-name> &#x0026; <string-name><surname>O&#x2019;Reily</surname>, <given-names>R. C.</given-names></string-name> <chapter-title>in Handbook of Binding and Memory</chapter-title>: <source>Perspectives from Cognitive Neuroscience</source> (eds. <person-group person-group-type="editor"><string-name><surname>Zimmer</surname>, <given-names>H. D.</given-names></string-name>, <string-name><surname>Mecklinger</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Lindenberger</surname>, <given-names>U.</given-names></string-name></person-group>) <fpage>193</fpage>&#x2013;<lpage>220</lpage> (<publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>, <year>2012</year>). doi:<pub-id pub-id-type="doi">10.1093/acprof:oso/9780198529675.003.0008</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Gray</surname>, <given-names>C. M.</given-names></string-name> &#x0026; <string-name><surname>Singer</surname>, <given-names>W.</given-names></string-name> <article-title>Stimulus-specific neuronal oscillations in orientation columns of cat visual cortex</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>86</volume>, <fpage>1698</fpage>&#x2013;<lpage>1702</lpage> (<year>1989</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Treisman</surname>, <given-names>A.</given-names></string-name> <article-title>The binding problem Abbreviations FIT feature integration theory IC illusory conjunction IT inferior temporal cortex PET positron emission tomography</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>6</volume>, <fpage>171</fpage>&#x2013;<lpage>78</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Pinkas</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lima</surname>, <given-names>P.</given-names></string-name> &#x0026; <string-name><surname>Cohen</surname>, <given-names>S.</given-names></string-name> <article-title>A dynamic binding mechanism for retrieving and unifying complex predicate-logic knowledge</article-title>. in <source>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 7552 LNCS</source>, <fpage>482</fpage>&#x2013;<lpage>490</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Zmigrod</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Colzato</surname>, <given-names>L. S.</given-names></string-name> &#x0026; <string-name><surname>Hommel</surname>, <given-names>B.</given-names></string-name> <article-title>Evidence for a role of the right dorsolateral prefrontal cortex in controlling stimulus-response integration: a transcranial direct current stimulation (tDCS) study</article-title>. <source>Brain Stimul</source> <volume>7</volume>, <fpage>516</fpage>&#x2013;<lpage>520</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Tallon-Baudry</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Bertrand</surname>, <given-names>O.</given-names></string-name> <article-title>Oscillatory gamma activity in humans and its role in object representation</article-title>. <source>Trends in Cognitive Sciences</source> <volume>3</volume>, <fpage>151</fpage>&#x2013;<lpage>162</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Brette</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name> <article-title>Adaptive exponential integrate-and-fire model as an effective description of neuronal activity</article-title>. <source>J. Neurophysiol</source>. <volume>94</volume>, <fpage>3637</fpage>&#x2013;<lpage>42</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Tsodyks</surname>, <given-names>M. V.</given-names></string-name> &#x0026; <string-name><surname>Markram</surname>, <given-names>H.</given-names></string-name> <article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>94</volume>, <fpage>719</fpage>&#x2013;<lpage>723</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Wahlgren</surname>, <given-names>N.</given-names></string-name> &#x0026; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Biological evaluation of a Hebbian-Bayesian learning rule</article-title>. <source>Neurocomputing</source> <volume>38&#x2013;40</volume>, <fpage>433</fpage>&#x2013;<lpage>438</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Gewaltig</surname>, <given-names>M.-O.</given-names></string-name> &#x0026; <string-name><surname>Diesmann</surname>, <given-names>M.</given-names></string-name> <article-title>NEST (NEural Simulation Tool)</article-title>. <source>Scholarpedia</source> <volume>2</volume>, <fpage>1430</fpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="other"><string-name><surname>Hoffman</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Magee</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Colbert</surname>, <given-names>C. M.</given-names></string-name> &#x0026; <string-name><surname>Johnston</surname>, <given-names>D.</given-names></string-name> <article-title>K&#x002B; channel regulation of signal propagation in dendrites of hippocampal pyramidal neurons</article-title>. <volume>387</volume>, <fpage>869</fpage>&#x2013;<lpage>875</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Petersson</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Yoshida</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Frans&#x00E9;n</surname>, <given-names>E. A.</given-names></string-name> <article-title>Low-frequency summation of synaptically activated transient receptor potential channel-mediated depolarizations</article-title>. <source>Eur. J. Neurosci</source>. <volume>34</volume>, <fpage>578</fpage>&#x2013;<lpage>93</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>Tucker</surname>, <given-names>T. R.</given-names></string-name> <article-title>Recruitment of Local Inhibitory Networks by Horizontal Connections in Layer 2/3 of Ferret Visual Cortex</article-title>. <source>J. Neurophysiol</source>. <volume>89</volume>, <fpage>501</fpage>&#x2013;<lpage>512</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Ren</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Yoshimura</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Takada</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Horibe</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Komatsu</surname>, <given-names>Y.</given-names></string-name> <article-title>Specialized inhibitory synaptic actions between nearby neocortical pyramidal neurons</article-title>. <source>Science</source> <volume>316</volume>, <fpage>758</fpage>&#x2013;<lpage>61</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Silberberg</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Markram</surname>, <given-names>H.</given-names></string-name> <article-title>Disynaptic inhibition between neocortical pyramidal cells mediated by Martinotti cells</article-title>. <source>Neuron</source> <volume>53</volume>, <fpage>735</fpage>&#x2013;<lpage>46</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Kapfer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Glickfeld</surname>, <given-names>L. L.</given-names></string-name>, <string-name><surname>Atallah, B.</surname> <given-names>V</given-names></string-name> &#x0026; <string-name><surname>Scanziani</surname>, <given-names>M.</given-names></string-name> <article-title>Supralinear increase of recurrent inhibition during sparse activity in the somatosensory cortex</article-title>. <source>Nat. Neurosci</source>. <volume>10</volume>, <fpage>743</fpage>&#x2013;<lpage>53</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><surname>Parisien</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>C. H.</given-names></string-name> &#x0026; <string-name><surname>Eliasmith</surname>, <given-names>C.</given-names></string-name> <article-title>Solving the Problem of Negative Synaptic Weights in Cortical Models</article-title>. <source>Neural Comput</source>. <volume>20</volume>, <fpage>1473</fpage>&#x2013;<lpage>1494</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><surname>Mountcastle</surname>, <given-names>V. B.</given-names></string-name> <article-title>The columnar organization of the cerebral cortex</article-title>. <source>Brain</source> <volume>120</volume>, <fpage>701</fpage>&#x2013;<lpage>722</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>Petrides</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Pandya</surname>, <given-names>D. N.</given-names></string-name> <article-title>Dorsolateral prefrontal cortex: comparative cytoarchitectonic analysis in the human and the macaque brain and corticocortical connection patterns</article-title>. <source>Eur. J. Neurosci</source>. <volume>11</volume>, <fpage>1011</fpage>&#x2013;<lpage>1036</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><string-name><surname>Douglas</surname>, <given-names>R. J.</given-names></string-name> &#x0026; <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name> <article-title>C. C. Neuronal circuits of the neocortex</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>27</volume>, <fpage>419</fpage>&#x2013;<lpage>51</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><string-name><surname>Yoshimura</surname>, <given-names>Y.</given-names></string-name> &#x0026; <string-name><surname>Callaway</surname>, <given-names>E. M.</given-names></string-name> <article-title>Fine-scale specificity of cortical networks depends on inhibitory cell type and connectivity</article-title>. <source>Nat. Neurosci</source>. <volume>8</volume>, <fpage>1552</fpage>&#x2013;<lpage>1559</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><string-name><surname>Potjans</surname>, <given-names>T. C.</given-names></string-name> &#x0026; <string-name><surname>Diesmann</surname>, <given-names>M.</given-names></string-name> <article-title>The cell-type specific cortical microcircuit: Relating structure and activity in a full-scale spiking network model</article-title>. <source>Cereb. Cortex</source> <volume>24</volume>, <fpage>785</fpage>&#x2013;<lpage>806</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><string-name><surname>Miyashita</surname>, <given-names>Y.</given-names></string-name> <article-title>Inferior Temporal Cortex: Where Visual Perception Meets Memory</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>16</volume>, <fpage>245</fpage>&#x2013;<lpage>263</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><string-name><surname>Markov</surname>, <given-names>N. T.</given-names></string-name> <etal>et al.</etal> <article-title>Anatomy of hierarchy: Feedforward and feedback pathways in macaque visual cortex</article-title>. <source>J. Comp. Neurol</source>. <volume>522</volume>, <fpage>225</fpage>&#x2013;<lpage>259</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><string-name><surname>Girard</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Hupe</surname>, <given-names>J. M.</given-names></string-name> &#x0026; <string-name><surname>Bullier</surname>, <given-names>J.</given-names></string-name> <article-title>Feedforward and feedback connections between areas V1 and V2 of the monkey have similar rapid conduction velocities</article-title>. <source>J Neurophysiol</source> <volume>85</volume>, <fpage>1328</fpage>&#x2013;<lpage>31</lpage>. (<year>2001</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><string-name><surname>Thorpe</surname>, <given-names>S. J.</given-names></string-name> &#x0026; <string-name><surname>Fabre-Thorpe</surname>, <given-names>M.</given-names></string-name> <article-title>Seeking categories in the brain</article-title>. <source>Science</source> <volume>291</volume>, <fpage>260</fpage>&#x2013;<lpage>263</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><string-name><surname>Caminiti</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Diameter, Length, Speed, and Conduction Delay of Callosal Axons in Macaque Monkeys and Humans: Comparing Data from Histology and Magnetic Resonance Imaging Diffusion Tractography</article-title>. <source>J. Neurosci</source>. <volume>33</volume>, <fpage>14501</fpage>&#x2013;<lpage>14511</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><string-name><surname>Zufferey</surname>, <given-names>P. D.</given-names></string-name>, <string-name><surname>Jin</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nakamura</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Tettoni</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Innocenti</surname>, <given-names>G. M.</given-names></string-name> <article-title>The role of pattern vision in the development of cortico-cortical connections</article-title>. <source>Eur. J. Neurosci</source>. <volume>11</volume>, <fpage>2669</fpage>&#x2013;<lpage>2688</lpage> (<year>1999</year>).</mixed-citation></ref>
</ref-list>
<sec id="s7" sec-type="supplementary-material">
<title>Supplementary Material</title>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Indexing and feedback reactivation of long-term memories.</title>
<p><bold>A</bold>: Subsampled spike raster of STM (top) and LTM (bottom). From 0 to 1000 ms (shaded grey), five LTM memories are cued via targeted 50 ms stimuli. Plasticity is temporarily boosted during this time and activated attractors are thus indexed in STM. Thereafter, strong noise drive to STM causes random activations and consolidation of pattern-specific subpopulations in STM. Backprojections reactivate associated LTM memories. Top: STM spike raster shows layer 2/3 activity in a single hypercolumn (HC). Minicolumns (MC) are separated by grey horizontal lines. STM spikes are colored according to each cells dominant pattern-selectivity (based on simple spike counts in each patterns initial activation time window), similar to <bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold>. Bottom: LTM spike raster only shows the activity of five coding MC in a single LTM HC, but indicates the activation of distributed LTM attractors. LTM Spikes are colored according to the pattern-specificity of each cell.</p></caption>
<graphic xlink:href="334821_figS1a.tif"/>
</fig>
<fig id="figS2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>WM updating.</title>
<p>Exponential moving averages of pattern-specific subpopulations in STM (top) and LTM (bottom) during indexing and subsequent maintenance of two sets of five LTM memories. After encoding and 10 s maintenance of the first set, WM contents are overwritten with the second set of memories, maintained thereafter. The grey shading indicates input-driven updates to the WM system. Plasticity is temporarily boosted during these times and activated attractors are thus indexed in STM. Subsequent strong noise drive to STM causes random activations and consolidation of pattern-specific subpopulations in STM following each stimulation period. Backprojections reactivate associated LTM memories.</p></caption>
<graphic xlink:href="334821_figS2.tif"/>
</fig>
<fig id="figS3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>WM updating.</title>
<p>Subsampled spike raster of the layer 2/3 population in a Hypercolumn of STM (top) and LTM (bottom) respectively during indexing and subsequent maintenance of two sets of five LTM memories. STM spikes are colored according to each cells dominant pattern-selectivity (based on simple spike counts in each patterns activation time window). LTM Spikes are colored according to the pattern-specificity of each cell. After encoding and 10 s maintenance of the first set, WM contents are overwritten with the second set of memories, maintained thereafter. Plasticity is temporarily boosted during the initial activation of LTM attractors. Strong noise drive to STM causes random activations and consolidation of pattern-specific subpopulations in STM following each stimulation period. Backprojections reactivate associated LTM memories.</p></caption>
<graphic xlink:href="334821_figS3.tif"/>
</fig>
<fig id="figS4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 4.</label>
<caption><title>Exponential Moving Averages of patterspecific subpopulations in the three networks, during the Feature binding task.</title>
<p>Three memory pairs (blue, green, red respectivly) in STM (1<sup>st</sup> row), LTMa (2<sup>nd</sup> row), and LTMb (3<sup>rd</sup> row) during three different modes of network activity: The initial binding of pairs of pairwise LTM memory activations in STM (0 &#x2013; 1 s), WM Maintenance (1 s &#x2013; 10 s), and cue-driven associative recall of previously paired stimuli (11 s &#x2013; 12 s).</p></caption>
<graphic xlink:href="334821_figS4.tif"/>
</fig>
<fig id="figS5" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 5.</label>
<caption><title>Spiking activity in the three networks, during the multi-modal LTM binding task.</title>
<p>Subsampled spike raster of the layer 2/3 population in a Hypercolumn of STM (top), and five coding minicolumns in LTMa (middle) and LTMb (bottom) respectively during indexing, subsequent maintenance, and associative cued recall of five paired LTM patterns (orange,purple,blue,green,red). Minicolumns are separated by grey horizontal lines. STM spikes are colored according to each cells dominant memory pair-selectivity (based on simple spike counts in each patterns activation time window). LTM Spikes are colored according to the memory pair-specificity of each cell in slightly shifted hues to illustrate that LTMa and LTMb code for different, but associated memories. The spike rasters shows a brief period of noisy activity in all three networks, before the targeted sequential activation of five LTM pairs. From 3000 ms to 13000 ms the rasters show STM-driven WM maintainance of the encoded pairs. Finally, at 13.000 ms LTMa alone is cued and retrieves the corresponding LTMb activation with some delay through STM activation.</p></caption>
<graphic xlink:href="334821_figS5.tif"/>
</fig>
</sec>
</back>
</article>
