<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/217869</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Minerva: An Alignment and Reference Free Approach to Deconvolve Linked-Reads for Metagenomics</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1456-9498</contrib-id>
<name>
<surname>Danko</surname>
<given-names>David C.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Meleshko</surname>
<given-names>Dmitry</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1203-8239</contrib-id>
<name>
<surname>Bezdan</surname>
<given-names>Daniela</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mason</surname>
<given-names>Christopher</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0600-3371</contrib-id>
<name>
<surname>Hajirasouliha</surname>
<given-names>Iman</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Tri-Institutional Computational Biology &#x0026; Medicine Program, Cornell University</institution>, NY, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Institute for Computational Biomedicine, Department of Physiology and Biophysics, Weill Cornell Medicine of Cornell University</institution>, NY, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>The Feil Family Brain and Mind Research Institute, Weill Cornell Medicine</institution>, NY, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Englander Institute for Precision Medicine, The Meyer Cancer Center, Weill Cornell Medicine</institution>, NY, <country>USA</country></aff>
</contrib-group>
<author-notes><corresp id="cor1"><label>&#x002A;</label>Corresponding author</corresp></author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>217869</elocation-id>
<history>
<date date-type="received">
<day>10</day>
<month>11</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>10</day>
<month>11</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>10</day>
<month>11</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions>
<self-uri xlink:href="217869.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Emerging linked-read technologies (aka read-cloud or barcoded short-reads) have revived interest in standard short-read technology as a viable way to understand large scale structure in genomes and metagenomes. Linked-read technologies, such as the 10X Chromium system, use a microfluidic system and a set of specially designed 3&#x2019; barcodes (aka UIDs) to tag short DNA reads which were originally sourced from the same long fragment of DNA; subsequently these specially barcoded reads are sequenced on standard short read platforms. This approach results in interesting compromises. Each long fragment of DNA is covered only sparsely by short reads, no information about the relative ordering of reads from the same fragment is preserved, and typically each 3&#x2019; barcode matches reads from 5-20 long fragments of DNA. However, the cost per base to sequence is far lower than single molecule long read sequencing systems, far less input DNA is required, and the error rate is that of standard short-reads.</p>
<p>Linked-reads represent a new set of algorithmic challenges. In this paper we formally describe one particular issue common to all applications of linked-read technology: the deconvolution of reads with a single barcode into clusters that correspond to a single long fragment of DNA. We introduce <bold>Minerva</bold>, A graph-based algorithm which approximately solves the barcode deconvolution problem for metagenomic data (where reference genomes may be incomplete or unavailable). Additionally, we demonstrate that deconvolved barcoded reads significantly improve downstream results by improving the specificity of taxonomic assignments, and by improving the ability of topic models to identify clusters of related sequences.</p>
</abstract>
<counts>
<page-count count="12"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>INTRODUCTION</title>
<sec id="s1a">
<label>1.1</label>
<title>Linked-Read Sequencing</title>
<p>Recently, long-read sequencing technologies (e.g. PacBio, Oxford Nanopore) have become commercially available. These techniques promise the ability to improve de novo assembly, particularly in metagenomics [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c9">9</xref>]. While these technologies offer much longer reads than standard short-read sequencing, their base-pair error rates are substantially higher than short reads (10-15&#x0025; error vs. 0.3&#x0025;). More important, long-read technologies have substantially higher costs, lower throughput, and require large amounts of DNA, or PCR amplification, as input. Currently, this makes long-reads impractical for large-scale screening of whole genome or metagenome samples and most low-input clinical samples.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Cartoon representing linked-read sequencing, Different colors represent reads from different fragments that can be mixed together and tagged with the same barcode.</p></caption>
<graphic xlink:href="217869_fig1.tif"/>
</fig>
<p>As an alternative, low-cost, and low-input (&#x02DC;1ng) DNA library preparation techniques using microfluidic molecular barcoding methods have recently emerged (e.g. Moleculo/Illumina, 10X Genomics) that address these shortcomings. With these new technologies, input DNA is sheared into long fragments of tens to hundreds of kbp before a barcode is ligated to short reads from the fragments such that short reads from the same fragment share the same barcode (N.B. this barcode is in addition to any barcode used for sample deconvolution). Finally, the short reads are sequenced using industry standard sequencing technologies (e.g. Illumina Hiseq). This process is commonly referred to as, linked-read sequencing. Linked-reads offer additional <italic>long-range</italic> information over standard short-reads that are present on the same DNA fragment (i.e. phased) and has been used recently to phase large-scale somatic structural variations [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c17">17</xref>] and to improve metagenomic assembly [<xref ref-type="bibr" rid="c13">13</xref>].</p>
<p>With respect to sequence coverage, linked-read sequencing technologies consist of two key parameters: <italic>C</italic><sub><italic>f</italic></sub>, the average physical coverage of the target genome with long fragments, and <italic>C</italic><sub><italic>r</italic></sub>, the average coverage of long fragments with standard short-reads. The overall sequence coverage can be, thus, approximated as <italic>C</italic> &#x003D; <italic>C</italic><sub><italic>f</italic></sub> &#x00D7; <italic>C</italic><sub><italic>r</italic></sub>. In the case of the 10X Genomics system, which is the technique we used to generate our metagenomics linked-read data, <italic>C</italic><sub><italic>r</italic></sub> is kept very light (e.g. 0.1 &#x2013; 0.2&#x00D7;; covering each long fragment only fractionally), while the total coverage <italic>C</italic> is in the typical range of standard short-read experiments.</p>
<p>State of the art linked-read sequencing systems group reads drawn from several long fragments under the same barcode. This is done to improve throughput given a finite number of barcodes; in practice there are roughly 5-20 long fragments represented per barcode. This can complicate downstream applications like metagenomic assembly and structural variant detection. Since many fragments are represented per barcode, a single barcode is insufficient evidence that its representative sequences occur near one another in the absence of a strong prior (e.g. an assembled genome).</p>
<p>Each long fragment of DNA is only fractionally covered by short reads (typically 10-20&#x0025;). Thus, reads from the same fragment do not typically overlap (this is not the case with certain older technologies and types of sample preparation). As such it is not possible to do de novo assembly using only reads with the same barcode. However, linked-reads still provide significantly more information about the proximity of short reads than standard short read sequencing. Given a large amount of background sequence the co-occurrence of particular sequences in multiple barcodes provides strong guarantees that the co-occurring sequences were drawn from the same underlying fragments of DNA, provided the sequences are not extremely common.</p>
</sec>
<sec id="s1b">
<label>1.2</label>
<title>Applications of Linked-Reads in Metagenomics</title>
<p>Linked-reads carry several potential benefits for metagenomic research compared to standard short-reads. Linked-reads can be used to improve taxonomic classification of reads, improve the assembly of microbial genomes, identify horizontally transferred sequences, quantify the genetic structure of low-abundance organisms and catalog intra-sample genetic structural variants. In the near term many algorithms for analyzing short read sequences can be used on linked-read data without modification.</p>
<p>Compared to long-read sequencing, linked-reads can be used to sequence samples far more deeply for the same amount of money and can accept much smaller amounts of input DNA. Even at the same read depth, linked-reads may be more useful for studying low abundance organisms because linked-reads span a much longer stretch of a genome for the number of bases sequenced (i.e. very high physical coverage).</p>
<p>In this paper, we address the barcode deconvolution problem, a fundamental problem of using linked-reads for metagenomics. We show that several applications of linked reads can improve on short reads and that specifically addressing the barcode deconvolution problem may improve downstream results for multiple applications.</p>
</sec>
<sec id="s1c">
<label>1.3</label>
<title>The Barcode Deconvolution Problem</title>
<p>We formally define the barcode deconvolution problem. As input we are given a set of <italic>n</italic> reads. Each read has the same barcode and an unobserved class that represents the fragment that the read was drawn from. For a given barcode with <italic>n</italic> reads drawn from <italic>f</italic> fragments we have <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline1.gif"/></alternatives></inline-formula> where <italic>r</italic><sub><italic>i</italic></sub> represents the unobserved class for read <italic>i</italic>, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline2.gif"/></alternatives></inline-formula>, the set of possible fragments [1, <italic>f</italic>].</p>
<p>A solution to the barcode deconvolution problem would be a function
<disp-formula id="ueqn1">
<alternatives>
<graphic xlink:href="217869_ueqn1.gif"/>
</alternatives>
</disp-formula>
such that
<disp-formula id="ueqn2">
<alternatives>
<graphic xlink:href="217869_ueqn2.gif"/>
</alternatives>
</disp-formula></p>
<p>When a reference genome is available and structural variants are not expected the barcode deconvolution problem is relatively trivial. All individual reads with the same barcode can be mapped to the reference genome using any good read alignment method. Reads from the same fragment will tend to be clustered near one another on the reference genome and, unless the genome in question is small, there is little chance that reads from different fragments will be proximal. However, if a reference genome is not available, is relatively small, or structural variation is present read mapping may not provide a good solution to the barcode deconvolution problem. All of these conditions are common in metagenomics.</p>
</sec>
<sec id="s1d">
<label>1.4</label>
<title>Summary</title>
<p>We have developed a novel method, <bold>Minerva</bold>, that explicitly uses barcode co-occurrence information to cluster reads with the same barcode into groups of reads that were drawn from a single long fragment. Our approach draws heavily from the field of topic modeling in Natural Language Processing (NLP) which studies methods to find groups of co-occurring words in text. In particular, we introduce a procedure <xref rid="s2b" ref-type="sec">2.2</xref> that achieves great specificity and performance when certain features of linked-reads are explicitly encoded as well as a probabilistic generative model justifying key assumptions of our procedure <xref rid="s2a" ref-type="sec">2.1</xref>. We report our negative results, models that we tested but performed poorly <xref rid="s2e" ref-type="sec">2.5</xref>. Finally, we demonstrate how our techniques can be effectively applied to real metagenomic linked-read data <xref rid="s4a" ref-type="sec">4.1</xref> and improve downstream analysis <xref rid="s4b" ref-type="sec">4.2</xref>, <xref rid="s4c" ref-type="sec">4.3</xref>.</p>
</sec>
</sec>
<sec id="s2">
<label>2</label>
<title>Barcode Deconvolution Using a Graphical Model</title>
<p>We developed a graph based algorithm to subdivide reads with the same barcode into groups that better corresponded to a single molecule. The core intuition behind this approach was that reads from the same fragment would tend to overlap with similar sets of reads that had different barcodes. Though each set of reads with the same barcode can contain reads from several fragments (5-20), it is unlikely that two sets of reads with two different barcodes would contain reads from multiple separate overlapping fragments. If multiple reads with the same barcode overlapped with reads that had another barcode it would suggest that the original reads came from the same fragment.</p>
<sec id="s2a">
<label>2.1</label>
<title>Mathematical Justification of the Model</title>
<p>We have developed a simple and conservative generative model to justify our intuition that reads from the same fragment will overlap with similar barcodes. This model is similar to empirical results and can be used to inform the parameters used for deconvolution.</p>
<p>We model each microbial genome <italic>G</italic><sub><italic>i</italic></sub> in a metagenome <italic>G</italic> as a discrete collection of fragments <italic>F</italic><sub><italic>i</italic></sub> that do not overlap. The probability of selecting a given fragment <italic>F</italic><sub><italic>i,j</italic></sub> from a given microbial genome <italic>G</italic><sub><italic>i</italic></sub> is given by a uniform distribution. We model each microbial genome as a set of <italic>N</italic><sub><italic>g</italic></sub> discrete fragments that do not overlap and model the probability of selecting a given genome conservatively as a Geometric distribution.</p>
<disp-formula id="ueqn3">
<alternatives>
<graphic xlink:href="217869_ueqn3.gif"/>
</alternatives>
</disp-formula>
<p>This gives us the probability of drawing a single fragment as well as the probability of drawing the same fragment twice</p>
<disp-formula id="ueqn4">
<alternatives>
<graphic xlink:href="217869_ueqn4.gif"/>
</alternatives>
</disp-formula>
<p>We model each barcode as a selection of <italic>N</italic><sub><italic>b</italic></sub> fragments with the simplification that a fragment is never drawn twice even though the probability of drawing a given fragment is not altered between draws. We can model the probability of two barcodes sharing exactly <italic>k</italic> fragments.</p>
<disp-formula id="ueqn5">
<alternatives>
<graphic xlink:href="217869_ueqn5.gif"/>
</alternatives>
</disp-formula>
<p>If we choose reasonable, conservative, values for all parameters <italic>N</italic><sub><italic>b</italic></sub> &#x003D; 5, <italic>N</italic><sub><italic>g</italic></sub> &#x003D; 100, |<italic>G</italic>| &#x003D; 10</p>
<disp-formula id="ueqn6">
<alternatives>
<graphic xlink:href="217869_ueqn6.gif"/>
</alternatives>
</disp-formula>
<p>We find that it is about 100 times more likely to have exactly one overlapping fragment than multiple overlapping fragments with the same barcode, even with conservative parameters. However, this model does not account for the fact that individual fragments may have similar sequences, this is a major source of noise for <bold>Minerva</bold>. However, we can use the parameters of this model to justify removing any overlaps that occur far more often than expected.</p>
<p>We can further inform our models parameters by accounting for the light coverage of each long fragment. On average, each fragment in a dataset is only fractionally covered at a rate of <italic>C</italic><sub><italic>r</italic></sub> (with a read depth of 1). While the precise coverage might vary between fragments this parameter can be used to estimate the size of overlaps between fragments and their expected sparsity. Two long fragments could be expected to overlap at <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline3.gif"/></alternatives></inline-formula> points in their overlap. By measuring actual overlap compared to the number of reads not overlapping it should be possible to estimate the size of the overlap. In cases where fragments overlap much more frequently than <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline4.gif"/></alternatives></inline-formula> it can be inferred that the sequence present is repetitive or well conserved.</p>
<p>These facts are used in <bold>Minerva</bold> to filter connections between repetitive regions, restrict overlaps to regions of a certain length, and to heuristically filter comparisons between barcodes unlikely to have significant overlap. This carries practical performance benefits and reduces errors.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>From left 1) Fragments are generated 2) Fragments are sequenced and tagged 3) Reads in a given barcode are aligned to other barcodes 4) A bipartite graph between reads and barcodes is constructed 5) A graph between reads that co-occur with barcode is constructed 6) Reads are clustered into groups</p></caption>
<graphic xlink:href="217869_fig2.tif"/>
</fig>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>A Graphical Model of Barcode Deconvolution</title>
<p>We have developed a graphical model that effectively deconvolves the reads within a given barcode. In essence, the model works by constructing a bipartite graph between all reads with a particular barcode and all other barcodes. Reads have an edge to a barcode if they are found to contain a kmer that is specific to exactly one read in the foreign barcode. Once the bipartite graph is constructed barcodes and reads with too many or too few edges (by user supplied parameters) are removed. The filtered bipartite graph is used to construct an adjacency matrix between reads and the matrix is clustered into groups of reads.</p>
<p>Initially each barcode in a given dataset is parsed into a sketch of minimizing kmers (see <xref rid="s2d" ref-type="sec">section 2.4</xref>, <xref rid="fig2" ref-type="fig">figure 2</xref> part 2). Global counts for kmers are retained, kmers that occur exactly once or 10 times more than average are discarded. Singleton kmers cannot possibly overlap between barcodes and overly common kmers tend to create false positives, this is analogous to removing stop words in Natural Language Processing applications. A map of kmers to reads is retained for every barcode.</p>
<p>After parsing, each barcode is compared to every other barcode (<xref rid="fig2" ref-type="fig">figure 2</xref> parts 3 and 4). Comparisons between barcodes that share too many kmers are discarded as these likely represent low complexity or evolutionarily conserved regions as opposed to real overlaps. Comparisons between barcodes that share too few kmers are also rejected. The intersection of the kmer sets between both barcodes is calculated and edges are added between every read with an intersecting kmer and a node representing the foreign barcode. If the degree of the node representing the barcode is too high it is discarded. All cutoffs are determined by user supplied thresholds.</p>
<p>Each bipartite graph representing the reads with a given barcode is given a final round of filtering where reads that matched too many barcodes are removed based on a user supplied threshold. The filtered bipartite graph is converted to an adjacency matrix of reads where the similarity between reads is equivalent to the number of barcodes both reads mutually overlapped with (<xref rid="fig2" ref-type="fig">figure 2</xref> part 5). This adjacency matrix is converted to a binary matrix by setting all values below a user supplied threshold to zero and all remaining values to one (<xref rid="fig2" ref-type="fig">figure 2</xref> part 6).</p>
<p>All connected components in the binary matrix are found. Connected components consisting of single reads are discarded, the remaining components define clusters. This process is analogous to DBSCAN [<xref ref-type="bibr" rid="c4">4</xref>] for graphs.</p>
<p>Depending on the parameters and dataset used the clustering step may produce clusters that are large and imprecise or small and incomplete; this is partly a consequence of using a small number of discrete components to define connections. To mitigate this issue we have introduced two enhancements to the clustering step that may optionally be used. We have based these enhancements on the two step procedure used for community recovery by [<xref ref-type="bibr" rid="c2">2</xref>] and [<xref ref-type="bibr" rid="c14">14</xref>].</p>
<p>We term the first enhancement read-rescue; in some instances it is useful to rescue components that consist of single reads by connecting them to clusters that they unambiguously share connections with. To do this all single reads are checked for connections to any read in a cluster. If the single read is connected to enough reads (by a user supplied parameter) in no more than one cluster the read is added to that cluster. We term the second enhancement edge-cracking; when clusters are too large it is useful to break certain edges that bridge two individually well-connected components. To do this all edges in the adjacency matrix are considered. If the two reads attached to an edge do not share enough neighboring reads (by a user supplied parameter) the edge is removed from the adjacency graph.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Information Theory Bounds on Barcode Deconvolution</title>
<p>We note that the barcode deconvolution on the graphical model we have described in <xref rid="s2b" ref-type="sec">2.2</xref> is analagous to the cluster recovery problem [<xref ref-type="bibr" rid="c6">6</xref>] in Information Theory. In particular, barcodes that overlap with reads being deconvolved provide linkage information between reads. We have used this linkage information to construct a graph between the reads being deconvolved with the expectation that reads from the same fragment will have a better chance of being linked than reads from different fragments. Formally we say that two reads are connected with probability <italic>p</italic> if they are from the same fragment and probability <italic>q</italic> if they are from different fragments. Termed differently <italic>p</italic> is the true positive rate while <italic>q</italic> is the false positive rate.</p>
<p>If we make a simplifying assumption that all fragments in our barcode produced equal numbers of reads we can use the formula determined by [<xref ref-type="bibr" rid="c8">8</xref>] to determine the minimum connectivity of linking barcodes necessary to deconvolve our reads. We define the number of reads per fragment as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline5.gif"/></alternatives></inline-formula>, where <italic>N</italic><sub><italic>r</italic></sub> is the total number of reads being deconvolved and <italic>N</italic><sub><italic>b</italic></sub> is the number of fragments in the given barcode.</p>
<p>For the community recovery problem [<xref ref-type="bibr" rid="c8">8</xref>] have provided a lower bound on the size of graph that can be accurately clustered given values of <italic>p</italic> and <italic>q</italic>, regardless of the algorithm used. If a graph is smaller than this threshold it is unlikely that it will be possible to distinguish clusters from spurious edges. This boundary requires us to assume that all fragments with the same barcode produced equal numbers of reads. We define the number of reads per fragment as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline6.gif"/></alternatives></inline-formula>, where <italic>N</italic><sub><italic>r</italic></sub> is the total number of reads being deconvolved and <italic>N</italic><sub><italic>b</italic></sub> is the number of fragments in the given barcode. With this definition we can apply the following inequality to barcode deconvolution:</p>
<disp-formula id="ueqn7">
<alternatives>
<graphic xlink:href="217869_ueqn7.gif"/>
</alternatives>
</disp-formula>
<p>If a barcode graph does not meet this inequality it is unlikely that it will be possible to accurately reconstruct all clusters, This can be used to estimate the minimum number of reads and maximum error rates which can lead to effective barcode deconvolutions. In principle, this inequality should apply to all barocde deconvolution algorithms that can be formulated as a graph. However different algorithms may have different values of <italic>p</italic> and <italic>q</italic>. We also note that the above formula is based on asymptotic behavior for graphs with thousands of nodes. Typical deconvolution graphs have less than 100 nodes.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Minimum Sparse Hashing</title>
<p>Minerva frequently tests whether pairs of reads overlap. Many solutions to finding overlaps between reads exist, such as: sequence clustering algorithms, sequence aligners, and kmer matching. These techniques typically make trade offs between overall performance and error rates. Since Minerva is meant to be relatively fast and can tolerate some errors we elected to use a minimal sparse hash of kmers to match read pairs. This technique was originally developed independently for biological sequence search and natural language document search [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c16">16</xref>] (in natural language search the technique is referred to as winnowing). While the original application of this technique in biology defined minimization as the lexicographic minimum of a set of sequences we use a uniform random hash function to determine the minimal sequence in a set. This is a common practical enhancement and the mathematics of its use are recently detailed by [<xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>Minimum sparse hashing for sequences takes three parameters, a length <italic>k</italic>, a window size <italic>w</italic>, and a hash function <italic>h</italic>. Given a set <italic>K</italic> of <italic>n, n</italic> &#x2265; <italic>w</italic> kmers, the min-sparse hash computes the hash <italic>h</italic> of each kmer then selects the kmer with the smallest hash from each consecutive set of <italic>w</italic> kmers in <italic>K</italic>. The final set of minimizers is the unique set of kmers generated <italic>W</italic>, since each consecutive window shares <italic>w</italic> 1 kmers there is a good chance that each window shares the same minimum with its predecessor. Formally <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline7.gif"/></alternatives></inline-formula>. This algorithm guarantees that any pair of reads with an exact overlap of at least <italic>w</italic> &#x002B; <italic>k</italic> 1 bases will share at least one minimum sparse kmer while drastically reducing the number of kmers which must be stored in memory (<xref rid="fig3" ref-type="fig">figure 3</xref>). In certain implementations minimum sparse kmers may also improve performance by allowing a kmer that can be stored in a single 64 bit cell (<italic>k</italic>32) of memory to represent a longer sequence.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Top, Hamming distance between windows in reads that share kmers, using various parameters. Bottom, number of representative kmers per read</p></caption>
<graphic xlink:href="217869_fig3.tif"/>
</fig>
<p>Minimum sparse kmers are prone to false positives when presented with similar, but not identical, runs of <italic>w</italic> bases in read pairs. We measured this phenomenon by comparing all kmers of length <italic>w</italic> from pairs of reads that share a minimum sparse hash. <xref rid="fig3" ref-type="fig">Figure 3</xref> shows the minimum hamming distance for windows of length <italic>w</italic> between reads that share a minsparse hash. When <italic>k</italic> is larger the average hamming distance is smaller though outliers persist. Small values of <italic>k</italic> produce many distant false positives. In practice we found that false positives could be controlled through downstream techniques. Raising <italic>k</italic> from 20 to 30 (<italic>w</italic> &#x003D; 40) improved accuracy and precision but not overwhelmingly so (<italic>k</italic> &#x003D; 10 performed poorly in all cases).</p>
<p>The mathematics that underly minimum sparse hashing may also be used to efficiently approximate the overlap between sets, another important operation for Minerva. We did not use this technique in our current implementation of Minerva but plan to explore this for later versions.</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>Failed Models</title>
<p>While developing this model we tested several variants that performed poorly. In this section we report these models as negative results, parameters and outcomes may be found in the supplement. We define three distinct components of our model:</p>
<list list-type="order">
<list-item>
<p>Barcode reduction, a technique to generate a matrix with rows representing reads and columns related to barcodes</p>
</list-item>
<list-item>
<p>Cell weighting, a technique to reweight the cells of our reduced matrix</p>
</list-item>
<list-item>
<p>Clustering, alternate techniques to cluster our reduced, reweighted matrix.</p>
</list-item>
</list>
<p>We tried several techniques to reduce our matrix (our final technique was to build a bipartite graph that was converted into an adjacency matrix) including: Principal Component Analysis, Latent Dirichlet Allocation (treating each read as a document of barcodes), the jaccard, dice and kulsinski distance matrices between reads.</p>
<p>For most reductions we tried to reweight our matrices by normalizing row and column sums. We also tried term frequency - inverse document frequency and just inverse document frequency. For our final model we did not use any reweighting scheme.</p>
<p>To cluster our reduced and reweighted matrix we tried xmeans, kmedoids, hierarchical clustering with various linkages and Markov clustering. Hierarchical clustering yielded reasonable performance but dbscan was faster, had more intuitive parameters, and had slightly better performance.</p>
<p>Additionally, we tried to use LDA globally (treating each barcode as a document of kmers) to discover sets of kmers that uniquely identified fragments. This technique provided surprisingly good barcode deconvolution (and automatically defined globally clusterings of barcodes) but was extremely computationally costly and did not yield results as good as our final model.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Primary Data Sets</title>
<p>We tested Minerva using two primary real data sets from two microbial mock communities. The first community (Dataset 1) contained five bacterial species: <italic>E. coli, Enterobacter cloacae, Micrococcus luteus, Pseudomonas antarctica, and Staph. epidermis</italic>. The second community (Dataset 2) contained 8 bacterial species and 2 fungi: <italic>Bacillus subtilis, Cryptococcus neoformans, Enterococcus faecalis, E. coli, Lactobacillus fermentum, Listeria monocytogenes, Psuedomonas aeruginosa, Sachharomyces cerevisiae, Salmonella enterica, and Staphylococcus aureus</italic>.</p>
<p>Roughly 1ng of high molecular weight DNA was extracted from each sample. The HMW DNA was processed using a 10X Chromium instrument and we prepared sequencing libraries. Each library was sequenced on an Illumina Hiseq with 2x150 paired-end reads. Roughly 20M reads were generated for each sample, for testing we selected 10M reads from each while ensuring that we only selected complete barcodes. Both samples showed some evidence of human contamination, reads that mapped to the human genome were not removed from the samples (but were not used to generate statistics on barcode purity) since some amount of human DNA is typical in metagenomic samples.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Dataset Properties</p></caption>
<graphic xlink:href="217869_tbl1.tif"/>
</table-wrap>
<p>In both samples reads were evenly distributed over 3M barcodes. We used <italic>LongRanger Basic</italic> [<xref ref-type="bibr" rid="c1">1</xref>] to attach barcodes to reads and perform error correction on barcodes. Both samples has a similar number of reads per barcode. Sample 2 had more species represented in each barcode on average, though not necessarily more fragments since fragments can originate from the same genome. Statistics about the datasets are summarized in <xref rid="tbl1" ref-type="table">Table 1</xref>. Both datasets are available through the 10X Metagenomics Consortium.</p>
</sec>
<sec id="s4">
<label>4</label>
<title>Experimental Results</title>
<sec id="s4a">
<label>4.1</label>
<title>Minerva Deconvolves Barcodes</title>
<p>Minerva was able to identify subgroups in barcodes that largely corresponded to individual fragments of DNA. We term these subgroups &#x2018;Enhanced Bar-codes&#x2019;. We measured the quality of each enhanced barcode using two metrics: shannon diversity index <italic>H</italic> &#x003D; &#x03A3;<italic>p</italic><sub><italic>i</italic></sub> log <italic>p</italic><sub><italic>i</italic></sub> and purity <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="217869_inline8.gif"/></alternatives></inline-formula> where <italic>p</italic><sub><italic>i</italic></sub> indicates the proportion of an enhanced barcode that belongs to each fragment. These values are shown in <xref rid="fig4" ref-type="fig">figure 4</xref> as compared to barcodes that were not enhanced. In general, Minerva produced a large number of perfect (<italic>P</italic> &#x003D; 1<italic>, H</italic> &#x003D; 0) enhanced barcodes. Note that the results in figure 4 were produced without using read-rescue or edge-cracking.</p>
<p>We also tested whether the quality of the enhanced barcodes changed with the number of reads in the barcode. We found a small inverse relationship between barcode size and purity but established that our previous results were not being inflated by a large number of very small enhanced barcodes (enhanced barcodes of size 1 are always excluded from results).</p>
<p>In testing we found three parameters that seemed to have the most effect of Minerva&#x2019;s performance. The number of links required between reads to form a cluster (<italic>eps</italic>), the kmer size within each MinSparse hash (<italic>K</italic>), and the maximum allowed frequency of each read (<italic>maxk</italic>). In supplementary figure 1 we show how these parameters affect Minerva&#x2019;s performance under three different metrics: mean enhanced barcode purity, mean enhanced barcode size, and total reads clustered. Large, pure, and complete clusters being the ideal. We found that Minerva&#x2019;s parameters could be used to tune performance between very large and very pure enhanced barcodes depending on the downstream application.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Clockwise from top left 1) Purity in dataset one for enhanced and standard barcodes 2) Shannon index in dataset one for enhanced and standard barcodes 3) Shannon index in dataset two for enhanced and standard barcodes 4) Purity in dataset two for enhanced and</p></caption>
<graphic xlink:href="217869_fig4.tif"/>
</fig>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Enhanced Barcodes can be Clustered into Meaningful Groups Using Topic Models</title>
<p>After deconvolving barcodes into enhanced barcodes it is useful to group enhanced barcodes that likely came from the same genome. This is essentially a clustering problem. Initially we explored graphical approaches similar to our algorithm for read cloud deconvolution. These algorithms relied on the assumption that elements being clustered would have small numbers of distinguishing elements and a relatively high a priori probability of originating from the same cluster. When dealing with individual barcodes these assumptions proved reasonable; faced with the complexity of a full dataset these assumptions became inaccurate and graph based algorithms performed poorly.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Abundance of different chromosomes across clusters as assigned by LDA. Enhanced barcodes dramatically improve LDA&#x2019;s ability to distinguish structure.</p></caption>
<graphic xlink:href="217869_fig5.tif"/>
</fig>
<p>With relatively little structure in the data that could be known a priori we turned to topic modeling algorithms to discover implicit genetic structures in our data. Latent Dirichlet Allocation is a classic model in Natural Language Processing [<xref ref-type="bibr" rid="c3">3</xref>]. LDA is a generative model that assumes data was created using a certain, well defined, stochastic process. Unlike our graph based algorithm this model had a large number of parameters that could be adjusted until a model that fit the data well was found. Training the model consists of finding parameters that make it more likely that the observed data would be generated using the given stochastic process; typically this is done with Gibbs sampling.</p>
<p>Typically LDA is used to analyse corpora of natural language. Natural language corpora are organized into documents (e.g. emails or book chapters) that consist of words. The base version of LDA does not consider what order words in a document occur, just how often each word occurs in a given document; this is referred to as a bag-of-words model. Formally, documents are modeled as a sparse vector over a large vocabulary of words where entries represent the number of times a word occurs in the document. LDA maps documents from a high dimensional word-space to a lower dimensional topic-space. In NLP topics typically have intuitive interpretations as thematically consistent units. A key advantage of LDA is that it can classify words based on context (i.e. a river bank vs. a financial bank), this may be useful for classifying conserved motifs.</p>
<p>We used LDA to project enhanced and standard barcodes into a lower dimensional space. We treated each barcode as a document containing minimum sparse kmers as words. We removed kmers that occured far more often than average in a process similar to removing stop-words in NLP. We ran LDA with hyper-parameter optimization on our barcode-documents and clustered to obtain a topic cluster for each barcode using the implementation LDA in Mallet [<xref ref-type="bibr" rid="c11">11</xref>]. Using X-Means we clustered the barcode vectors into discrete groups.</p>
<p>Without enhanced barcodes LDA essentially cannot distinguish any structure, with enhanced barcodes LDA can generate clusters that are less diverse. This could be used to improve assemblies by clustering similar reads and reducing spurious connections.</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Minerva Improves Short Read Taxonomic Assignment</title>
<p>We used Minerva to improve the specificity of short read taxonomic assignments obtained from Kraken, a popular pseudo-alignment based tool [<xref ref-type="bibr" rid="c18">18</xref>]. We selected Kraken because it was found to have good precision but relatively poor recall in a study by McIntyre et al. [<xref ref-type="bibr" rid="c12">12</xref>]. We observed that if reads from a single linked fragment were classified using Kraken or similar pseudo-aligners many of the reads could not be assigned to low taxonomic ranks, however since the reads must have come from the same underlying fragment of DNA they must all have the same taxonomic rank. This fact could be used to rescue reads without a specific annotation. Since Minerva approximates pure read groups we used it to rescue taxonomic assignments used by Kraken. Since Minerva&#x2019;s enhanced barcodes can contain impurities we restricted annotation-rescue to cases where the given taxonomic assignment was not in direct conflict with the lowest level taxonomic assignment present. (i.e. a read assigned by Kraken to Bacteroidetes would never be promoted to E. Coli). Additionally we required that the lowest taxonomic rank be supported by at least two annotated reads, in principle reads could actually be demoted.</p>
<p>Using this technique we were able to rescue a large number of reads from unspecific taxonomic assignments. This is shown in figure 6 for E. Coli. All observed taxonomic assignments were correct after promotion. Without enhanced reads many annotations cannot be rescued or are incorrect.</p>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Conclusion</title>
<p>We have introduced <bold>Minerva</bold> a graph based algorithm to provide a partial solution to the barcode deconvolution problem. By design Minerva provides conservative solutions to barcode deconvolution for metagenomics and uses essentially no information (except kmer overlaps) about the sequences being clustered. As such Minerva is a relatively pure demonstration of how information can be extracted from linked-reads. With some modification the algorithms underlying Minerva may even be useful for detecting structural variations and other genetic structures in the human genome.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><p>Using enhanced barcodes we can promote the taxonomic assignment of reads. Width of each frond is proportional to the number of reads promoted from a specific rank.</p></caption>
<graphic xlink:href="217869_fig6.tif"/>
</fig>
<p>However, the current version of Minerva could be enhanced by leveraging a number of practical sequence features: such as known taxonomic assignment, GC content, tetramer frequency, or motifs. These have been shown to be good indicators of lineage in metagenomics and could be easily incorporated to improve Minerva&#x2019;s clusterings. In particular, taxonomic assignments could be incorporated into Minerva to evaluate barcode deconvolution, since there is no a-priori reason to think reads with a known taxonomic classification would be deconvolved more effectively than reads that could not be classified.</p>
<p>The current version of Minerva provides reasonable performance but can still up to 100 cpu-hours to deconvolve some large-scale datasets. A large performance bottleneck is Minerva&#x2019;s routine to calculate the size of an intersection between two sets which is naive and exact. Jain et al. [<xref ref-type="bibr" rid="c9">9</xref>] has shown that bloom filters can be effectively used to speed up the calculation of set intersection in biology with acceptable errors. Future versions of Minerva will employ similar techniques to improve performance. Minerva uses the same parameters to process every barcode, however the nature of linked-read sequencing provides a rich source of information that could be used to optimize model parameters for deconvolving individual barcodes. This would require a more thorough mathematical model of linked reads which we leave to a future work. Similarly, external sequence annotation could be incorporated as a practical approach to setting parameters for individual barcodes though it is unlikely that such a technique would generalize to non-microbial applications.</p>
<p>Of particular interest to us is the possibility of using Minerva to directly improve downstream applications. For simple applications Minerva may be used with a single set of parameters to produce a deconvolution that meets certain requirements. For applications built to take advantage of barcode deconvolution Minerva could be run with multiple parameters to produce increasingly strict tiers of enhancement. This may be particularly important for de-bruijn graph assembly. DBG assembly typically relies on effectively trimming and finding paths through a de-bruijn graph. Multiple tiers of linkage between reads could be used to inform trimming or path finding programs about likely paths and spurious connections. This could likely be modeled either as an information theory or probabilistic approach depending on the situation and assembler.</p>
<p>Overall we believe that Minerva is an important step towards building techniques designed to take advantage of linked-reads. Linked-reads have the potential to dramatically improve detection of large genetic structures without dramatically increasing sequencing costs and while taking advantage of existing techniques to process short reads.</p>
</sec>
<sec id="s6">
<label>6</label>
<title>Availability</title>
<p>The version of Minerva used to write this paper is freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/dcdanko/minerva_barcode_deconvolution">https://github.com/dcdanko/minerva_barcode_deconvolution</ext-link>. The fresh data sets used to evaluate Minerva is available upon request.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgement</title>
<p>We acknowledge Victoria Popic and her team at Illumina Inc. for fruitful discussions on the problem and her help in benchmarking. We sincerely thank 10X Genomics Inc. for providing us valuable fresh sequencing data sets used in this study for evaluations. We also thank Stephen Williams of 10X Genomics Inc. for coordinating the 10X Metagenomics consortium in which our team participates. DCD and DM were supported by the Tri-Institutional Training Program in Computational Biology and Medicine (CBM) funded by an NIH T32 grant.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="website"><collab>10x genomics long ranger pipelines</collab>: <ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/software/pipelines/latest/advanced/other-pipelines">https://support.10xgenomics.com/genome-exome/software/pipelines/latest/advanced/other-pipelines</ext-link>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>Emmanuel</given-names> <surname>Abbe</surname></string-name>, <string-name><given-names>Afonso S.</given-names> <surname>Bandeira</surname></string-name>, and <string-name><given-names>Georgina</given-names> <surname>Hall</surname></string-name>. <article-title>Exact recovery in the stochastic block model</article-title>. <source>IEEE Transactions on Information Theory</source>, <volume>62</volume>(<issue>1</issue>):<fpage>471</fpage>&#x2013;<lpage>487</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>David M</given-names> <surname>Blei</surname></string-name>, <string-name><given-names>Andrew Y</given-names> <surname>Ng</surname></string-name>, and <string-name><given-names>Michael I</given-names> <surname>Jordan</surname></string-name>. <article-title>Latent Dirichlet Allocation</article-title>. <source>Journal of Machine Learning Research</source>, <volume>3</volume>:<fpage>993</fpage>&#x2013;<lpage>1022</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="other"><string-name><given-names>Martin</given-names> <surname>Ester</surname></string-name>, <string-name><given-names>Hans-Peter</given-names> <surname>Kriegel</surname></string-name>, <string-name><given-names>Jorg</given-names> <surname>Sander</surname></string-name>, and <string-name><given-names>Xiaowei</given-names> <surname>Xu</surname></string-name>. <article-title>A density-based algorithm for discovering clusters in large spatial databases with noise</article-title>. In <source>International Conference on Knowledge Discovery and Information Retrieval</source>, pages <fpage>226</fpage>&#x2013;<lpage>231</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="other"><string-name><given-names>J. A.</given-names> <surname>Frank</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Pan</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Tooming-Klunderud</surname></string-name>, <string-name><given-names>V. G. H.</given-names> <surname>Eijsink</surname></string-name>, <string-name><given-names>A. C.</given-names> <surname>McHardy</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Nederbragt</surname></string-name>, and <string-name><given-names>P. B.</given-names> <surname>Pope</surname></string-name>. <article-title>Improved metagenome assemblies and taxonomic binning using long-read circular consensus sequence data</article-title>. <volume>6</volume>:25373 EP &#x2013;, 05 <year>2016</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Girvan</surname></string-name> and <string-name><given-names>M. E. J.</given-names> <surname>Newman</surname></string-name>. <article-title>Community structure in social and biological networks</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>99</volume>(<issue>12</issue>):<fpage>7821</fpage>&#x2013;<lpage>7826</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Stephanie U.</given-names> <surname>Greer</surname></string-name>, <string-name><given-names>Lincoln D.</given-names> <surname>Nadauld</surname></string-name>, <string-name><given-names>Billy T.</given-names> <surname>Lau</surname></string-name>, <string-name><given-names>Jiamin</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Christina</given-names> <surname>Wood-Bouwens</surname></string-name>, <string-name><given-names>James M.</given-names> <surname>Ford</surname></string-name>, <string-name><given-names>Calvin J.</given-names> <surname>Kuo</surname></string-name>, and <string-name><given-names>Hanlee P.</given-names> <surname>Ji</surname></string-name>. <article-title>Linked read sequencing resolves complex genomic rearrangements in gastric cancer metastases</article-title>. <source>Genome Medicine</source>, <volume>9</volume>(<issue>1</issue>):<fpage>57</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Bruce</given-names> <surname>Hajek</surname></string-name>, <string-name><given-names>Yihong</given-names> <surname>Wu</surname></string-name>, and <string-name><given-names>Jiaming</given-names> <surname>Xu</surname></string-name>. <article-title>Achieving Exact Cluster Recovery Threshold via Semidefinite Programming: Extensions</article-title>. In <source>IEEE Transactions on Information Theory</source>, volume <volume>62</volume>, pages <fpage>5918</fpage>&#x2013;<lpage>5937</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="other"><string-name><given-names>Miten</given-names> <surname>Jain</surname></string-name>, <string-name><given-names>Sergey</given-names> <surname>Koren</surname></string-name>, <string-name><given-names>Josh</given-names> <surname>Quick</surname></string-name>, <string-name><given-names>Arthur C</given-names> <surname>Rand</surname></string-name>, <string-name><given-names>Thomas A</given-names> <surname>Sasani</surname></string-name>, <string-name><given-names>John R</given-names> <surname>Tyson</surname></string-name>, <string-name><given-names>Andrew D</given-names> <surname>Beggs</surname></string-name>, <string-name><given-names>Alexander T</given-names> <surname>Dilthey</surname></string-name>, <string-name><given-names>Ian T</given-names> <surname>Fiddes</surname></string-name>, <string-name><given-names>Sunir</given-names> <surname>Malla</surname></string-name>, <string-name><given-names>Hannah</given-names> <surname>Marriott</surname></string-name>, <string-name><given-names>Karen H</given-names> <surname>Miga</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>Nieto</surname></string-name>, <string-name><given-names>Justin</given-names> <surname>O&#x2019;Grady</surname></string-name>, <string-name><given-names>Hugh E</given-names> <surname>Olsen</surname></string-name>, <string-name><given-names>Brent S</given-names> <surname>Pedersen</surname></string-name>, <string-name><given-names>Arang</given-names> <surname>Rhie</surname></string-name>, <string-name><given-names>Hollian</given-names> <surname>Richardson</surname></string-name>, <string-name><given-names>Aaron</given-names> <surname>Quinlan</surname></string-name>, <string-name><given-names>Terrance P</given-names> <surname>Snutch</surname></string-name>, <string-name><given-names>Louise</given-names> <surname>Tee</surname></string-name>, <string-name><given-names>Benedict</given-names> <surname>Paten</surname></string-name>, <string-name><given-names>Adam M.</given-names> <surname>Phillippy</surname></string-name>, <string-name><given-names>Jared T</given-names> <surname>Simpson</surname></string-name>, <string-name><given-names>Nicholas</given-names> <surname>James Loman</surname></string-name>, and <string-name><given-names>Matthew</given-names> <surname>Loose</surname></string-name>. <article-title>Nanopore sequencing and assembly of a human genome with ultra-long reads</article-title>. <source>bioRxiv</source>, 01 <year>2017</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>Guillaume</given-names> <surname>Mar&#x00E7;ais</surname></string-name>, <string-name><given-names>David</given-names> <surname>Pellow</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Bork</surname></string-name>, <string-name><given-names>Yaron</given-names> <surname>Orenstein</surname></string-name>, <string-name><given-names>Ron</given-names> <surname>Shamir</surname></string-name>, and <string-name><given-names>Carl</given-names> <surname>Kingsford</surname></string-name>. <article-title>Improving the performance of minimizers and winnowing schemes</article-title>. In <source>Bioinformatics</source>, <volume>volume 33</volume>, pages <fpage>i110</fpage>&#x2013;<lpage>i117</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="other"><string-name><given-names>Andrew</given-names> <surname>Kachites McCallum</surname></string-name>. <article-title>MALLET: A Machine Learning for Language Toolkit</article-title>, <year>2002</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="other"><string-name><given-names>Alexa</given-names> <surname>McIntyre</surname></string-name>, <string-name><given-names>Rachid</given-names> <surname>Ounit</surname></string-name>, <string-name><given-names>Ebrahim</given-names> <surname>Afshinnekoo</surname></string-name>, <string-name><given-names>Robert</given-names> <surname>Prill</surname></string-name>, <string-name><given-names>Elizabeth</given-names> <surname>Henaff</surname></string-name>, <string-name><given-names>Noah</given-names> <surname>Alexander</surname></string-name>, <string-name><given-names>Sam</given-names> <surname>Minot</surname></string-name>, <string-name><given-names>David</given-names> <surname>Danko</surname></string-name>, <string-name><given-names>Jonathan</given-names> <surname>Foox</surname></string-name>, <string-name><given-names>Sofia</given-names> <surname>Ahsanuddin</surname></string-name>, <string-name><given-names>Scott</given-names> <surname>Tighe</surname></string-name>, <string-name><given-names>Nur A</given-names> <surname>Hasan</surname></string-name>, <string-name><given-names>Poorani</given-names> <surname>Subramanian</surname></string-name>, <string-name><given-names>Kelly</given-names> <surname>Moffat</surname></string-name>, <string-name><given-names>Shawn</given-names> <surname>Levy</surname></string-name>, <string-name><given-names>Stefano</given-names> <surname>Lonardi</surname></string-name>, <string-name><given-names>Nick</given-names> <surname>Greenfield</surname></string-name>, <string-name><given-names>Rita</given-names> <surname>Colwell</surname></string-name>, <string-name><given-names>Gail</given-names> <surname>Rosen</surname></string-name>, and <string-name><given-names>Christopher E</given-names> <surname>Mason</surname></string-name>. <article-title>Comprehensive Benchmarking and Ensemble Approaches for Metagenomic Classifiers</article-title>. <source>bioRxiv</source>, jun <year>2017</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="other"><string-name><given-names>Eli</given-names> <surname>Moss</surname></string-name>, <string-name><given-names>Alex</given-names> <surname>Bishara</surname></string-name>, <string-name><given-names>Ekaterina</given-names> <surname>Tkachenko</surname></string-name>, <string-name><given-names>Joyce B</given-names> <surname>Kang</surname></string-name>, <string-name><given-names>Tessa M</given-names> <surname>Andermann</surname></string-name>, <string-name><given-names>Christina</given-names> <surname>Wood</surname></string-name>, <string-name><given-names>Christine</given-names> <surname>Handy</surname></string-name>, <string-name><given-names>Hanlee</given-names> <surname>Ji</surname></string-name>, <string-name><given-names>Serafim</given-names> <surname>Batzoglou</surname></string-name>, and <string-name><given-names>Ami S</given-names> <surname>Bhatt</surname></string-name>. <article-title>De novo assembly of microbial genomes from human gut metagenomes using barcoded short read sequences</article-title>. <source>bioRxiv</source>, apr <year>2017</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="other"><string-name><given-names>Elchanan</given-names> <surname>Mossel</surname></string-name>, <string-name><given-names>Joe</given-names> <surname>Neeman</surname></string-name>, and <string-name><given-names>Allan</given-names> <surname>Sly</surname></string-name>. <article-title>Consistency Thresholds for Binary Symmetric Block Models</article-title>. <source>arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1407.1591</pub-id>, <year>2014</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Yaron</given-names> <surname>Orenstein</surname></string-name>, <string-name><given-names>David</given-names> <surname>Pellow</surname></string-name>, <string-name><given-names>Guillaume</given-names> <surname>Mar&#x00E7;ais</surname></string-name>, <string-name><given-names>Ron</given-names> <surname>Shamir</surname></string-name>, and <string-name><given-names>Carl</given-names> <surname>Kingsford</surname></string-name>. <article-title>Compact universal k-mer hitting sets</article-title>. In <source>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</source>, <volume>volume 9838</volume>, pages <fpage>257</fpage>&#x2013;<lpage>268</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="other"><string-name><given-names>Saul</given-names> <surname>Schleimer</surname></string-name>, <string-name><given-names>Daniel S.</given-names> <surname>Wilkerson</surname></string-name>, and <string-name><given-names>Alex</given-names> <surname>Aiken</surname></string-name>. <article-title>Winnowing: Local Algorithms for Document Fingerprinting</article-title>. <source>Proceedings of the 2003 ACM SIGMOD international conference on on Management of data - SIGMOD '03</source>, pages <fpage>76</fpage>&#x2013;<lpage>85</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="other"><string-name><given-names>Noah</given-names> <surname>Spies</surname></string-name>, <string-name><given-names>Ziming</given-names> <surname>Weng</surname></string-name>, <string-name><given-names>Alex</given-names> <surname>Bishara</surname></string-name>, <string-name><given-names>Jennifer</given-names> <surname>McDaniel</surname></string-name>, <string-name><given-names>David</given-names> <surname>Catoe</surname></string-name>, <string-name><given-names>Justin M</given-names> <surname>Zook</surname></string-name>, <string-name><given-names>Marc</given-names> <surname>Salit</surname></string-name>, <string-name><given-names>Robert B</given-names> <surname>West</surname></string-name>, <string-name><given-names>Serafim</given-names> <surname>Batzoglou</surname></string-name>, and <string-name><given-names>Arend</given-names> <surname>Sidow</surname></string-name>. <article-title>Genome-wide reconstruction of complex structural variants using read clouds</article-title>. <source>Nat Meth</source>, advance online publication:&#x2013;, 07 <year>2017</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>Derrick E</given-names> <surname>Wood</surname></string-name> and <string-name><given-names>Steven L</given-names> <surname>Salzberg</surname></string-name>. <article-title>Kraken: ultrafast metagenomic sequence classification using exact alignments</article-title>. <source>Genome Biology</source>, <volume>15</volume>(<issue>3</issue>):<fpage>R46</fpage>, <year>2014</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>
