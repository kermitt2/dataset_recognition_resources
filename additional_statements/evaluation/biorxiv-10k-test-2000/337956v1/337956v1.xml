<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/337956</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Biochemistry</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Practical model selection for prospective virtual screening</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2030-2367</contrib-id>
<name>
<surname>Liu</surname>
<given-names>Shengchao</given-names>
</name>
<xref ref-type="aff" rid="a1">&#x2020;</xref>
<xref ref-type="aff" rid="a2">&#x2021;</xref>
<xref ref-type="author-notes" rid="n1">&#x0023;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6792-5348</contrib-id>
<name>
<surname>Alnammi</surname>
<given-names>Moayad</given-names>
</name>
<xref ref-type="aff" rid="a1">&#x2020;</xref>
<xref ref-type="aff" rid="a2">&#x2021;</xref>
<xref ref-type="author-notes" rid="n1">&#x0023;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ericksen</surname>
<given-names>Spencer S.</given-names>
</name>
<xref ref-type="aff" rid="a3">&#x00B6;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1691-0618</contrib-id>
<name>
<surname>Voter</surname>
<given-names>Andrew F.</given-names>
</name>
<xref ref-type="aff" rid="a4">&#x00A7;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5961-0220</contrib-id>
<name>
<surname>Keck</surname>
<given-names>James L.</given-names>
</name>
<xref ref-type="aff" rid="a4">&#x00A7;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2770-9656</contrib-id>
<name>
<surname>Hoffmann</surname>
<given-names>F. Michael</given-names>
</name>
<xref ref-type="aff" rid="a3">&#x00B6;</xref>
<xref ref-type="aff" rid="a5">&#x2225;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8598-0751</contrib-id>
<name>
<surname>Wildman</surname>
<given-names>Scott A.</given-names>
</name>
<xref ref-type="aff" rid="a3">&#x00B6;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5324-9833</contrib-id>
<name>
<surname>Gitter</surname>
<given-names>Anthony</given-names>
</name>
<xref ref-type="aff" rid="a6">&#x22A5;</xref>
<xref ref-type="aff" rid="a1">&#x2020;</xref>
<xref ref-type="aff" rid="a2">&#x2021;</xref>
</contrib>
<aff id="a1"><label>&#x2020;</label><institution>Department of Computer Sciences, University of Wisconsin-Madison</institution></aff>
<aff id="a2"><label>&#x2021;</label><institution>Morgridge Institute for Research</institution></aff>
<aff id="a3"><label>&#x00B6;</label><institution>Small Molecule Screening Facility, University of Wisconsin Carbone Cancer Center</institution></aff>
<aff id="a4"><label>&#x00A7;</label><institution>Department of Biomolecular Chemistry, University of Wisconsin School of Medicine and Public Health</institution></aff>
<aff id="a5"><label>&#x2225;</label><institution>McArdle Laboratory for Cancer Research, University of Wisconsin-Madison</institution></aff>
<aff id="a6"><label>&#x22A5;</label><institution>Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison</institution></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="other"><label>&#x0023;</label><p><italic>Co-first author</italic> E-mail: <email>gitter@biostat.wisc.edu</email></p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>337956</elocation-id>
<history>
<date date-type="received">
<day>03</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>03</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>04</day>
<month>6</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="337956.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Virtual (computational) high-throughput screening provides a strategy for prioritizing compounds for experimental screens, but the choice of virtual screening algorithm depends on the dataset and evaluation strategy. We consider a wide range of ligand-based machine learning and docking-based approaches for virtual screening on two protein-protein interactions, PriA-SSB and RMI-FANCM, and present a strategy for choosing which algorithm is best for prospective compound prioritization. Our workflow identifies a random forest as the best algorithm for these targets over more sophisticated neural network-based models. The top 250 predictions from our selected random forest recover 40 of the 62 active compounds from a library of 25,279 new molecules assayed on PriA-SSB. We show that virtual screening methods that perform well in public datasets and synthetic benchmarks, like multi-task neural networks, may not always translate to prospective screening performance on a specific assay of interest.</p>
</abstract>
<counts>
<page-count count="30"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Drug discovery is time consuming and expensive. After a specific protein or mechanistic pathway is identified to play an essential role in a disease process, the search begins for a chemical or biological ligand that can perturb the action or abundance of the disease target in order to mitigate the disease phenotype. A standard approach to discover a chemical ligand is to screen thousands to millions of candidate compounds against the target in biochemical or cell-based assays via a process called high-throughput screening (HTS), which produces vast sets of valuable pharmacological data. Even though HTS assays are highly automated, screens of thousands of compounds sample only a small fraction of the millions of commercially-available, drug-like compounds. Cost and time preclude academic laboratories and even pharmaceutical companies from blindly testing the full set of millions of drug-like compounds in HTS assays. Thus, there is a crucial need for an effective virtual screening (VS) process as a preliminary step in prioritizing compounds for HTS assays.</p>
<p>Virtual screening comprises two categories: structure-based<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref></sup> and ligand-based methods.<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c4">4</xref></sup> Structure-based methods require that the target protein&#x2019;s molecular structure be known so that the 3D interactions between the target and each chemical compound (binding poses) may be predicted <italic>in silico</italic>. These interactions are given numerical scores, which are then used to rank compounds for potential binding to the target. These methods do not require or typically make use of historical screening data in compound scoring. In contrast, ligand-based methods require no structural information about the target but use data generated from testing molecules in biochemical or functional assays of the target to fit empirical models that relate compound attributes to assay outcomes.</p>
<p>For targets with abundant assay data or where a druggable binding site is not well-defined, such as the targets considered here, ligand-based methods are generally superior to structure-based methods.<sup><xref ref-type="bibr" rid="c5">5</xref>&#x2013;<xref ref-type="bibr" rid="c7">7</xref></sup> Confronted with the variety of ligand-based model building methods (e.g., regression models, random forests, support vector machines, etc.),<sup><xref ref-type="bibr" rid="c8">8</xref></sup> compound input representations, and performance metrics, how should one proceed? The Merck Molecular Activity Challeng.<sup><xref ref-type="bibr" rid="c9">9</xref></sup> incited the development of many ligand-based deep learning VS methods,<sup><xref ref-type="bibr" rid="c10">10</xref>&#x2013;<xref ref-type="bibr" rid="c14">14</xref></sup> as recently reviewed.<sup><xref ref-type="bibr" rid="c15">15</xref></sup> These methods are often assessed with cross-validation on existing HTS data, but there is presently little experimental evidence on the best option for prioritizing new compounds given a fixed screening budget.</p>
<p>We critically evaluated a collection of VS algorithms that include both structure-based and ligand-based methods. We present a VS workflow that first uses available HTS training data to systematically prune the specific versions of the algorithms and calculate their cross-validation performance on a variety of evaluation metrics. Based on the cross-validation results and analysis of the various evaluation metrics, we selected a single virtual screening algorithm. The selected method, a random forest model, was the best option for prioritizing a small number of compounds from a new library, as verified by experimental screening. These model selection and evaluation strategies can guide VS practitioners to select the best model for their target even as the landscape of available VS algorithms continues to evolve.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Methods</title>
<sec id="s2a">
<label>2.1</label>
<title>Datasets</title>
<p>Our case studies were on new and recently generated datasets.<sup><xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c17">17</xref></sup> for the targets PriA-SSB and RMI-FANCM. The PriA-SSB interaction is important in bacterial DNA replication and is a potential target for antibiotics.<sup><xref ref-type="bibr" rid="c18">18</xref></sup> The RMI-FANCM interaction is involved in DNA repair that is induced in human cancer cells to confer chemoresistance to cytotoxic DNA-cross-linking agents, making it an attractive drug target.<sup><xref ref-type="bibr" rid="c19">19</xref></sup> We previously screened these targets with a library of compounds obtained from Life Chemicals Inc. (LC) in different assay formats. In addition, we screened new LC compounds on the PriA-SSB target to evaluate our VS models. The four datasets derived from these screens are described below and summarized in <xref ref-type="table" rid="tbl1">Table 1</xref>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Summary statistics for the four binary datasets.</p></caption>
<graphic xlink:href="337956_tbl1.tif"/>
</table-wrap>
<sec id="s2a1">
<title>PriA-SSB AlphaScreen</title>
<p>PriA-SSB was initially screened using an AlphaScreen (AS) assay in 1536-well forma.<sup><xref ref-type="bibr" rid="c17">17</xref></sup> on 72,423 LC compounds at a single concentration (33.3 &#x03BC;M), with data reported as &#x0025; inhibition compared to controls. We refer to these continuous values as &#x201C;PriA-SSB &#x0025; inhibition&#x201D;. Those compounds that tested above a certain activity threshold (&#x2265; 35&#x0025; inhibition) and passed PAINS chemical structural filters<sup><xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c21">21</xref></sup> were retested in the same AS assay. Compounds that were confirmed in the AS retest screen (&#x2265; 35&#x0025; inhibition) were marked as actives, creating the binary dataset <bold>PriA-SSB AS</bold>.</p>
</sec>
<sec id="s2a2">
<title>PriA-SSB fluorescence polarization</title>
<p>Compounds that had PriA-SSB &#x0025; inhibition &#x2265; 35&#x0025; and passed the PAINS filters were also tested in a fluorescence polarization (FP) assay as a secondary screen. Those compounds with FP inhibition &#x2265;30&#x0025; were labeled as actives, creating the binary dataset <bold>PriA-SSB FP</bold>, with all other compounds in the screening set labeled inactive.</p>
</sec>
<sec id="s2a3">
<title>RMI-FANCM fluorescence polarization</title>
<p>The RMI-FANCM interaction was initially screened with a subset of 49,796 compounds from the same LC library as PriA-SSB.<sup><xref ref-type="bibr" rid="c16">16</xref></sup> This FP assay was run at a single compound concentration (32 &#x03BC;M). We refer to these continuous values as &#x201C;RMI-FANCM &#x0025; inhibition&#x201D;. Those compounds that demonstrated activity &#x2265; 2 standard deviations (SD) above the assay mean and passed PAINS filters were marked as actives in the binary dataset <bold>RMI-FANCM FP</bold>.</p>
</sec>
<sec id="s2a4">
<title>PriA-SSB prospective</title>
<p>In subsequent screens used for prospective testing, we tested an additional 25,279 compounds, purchased from LC after the initial screening was complete. There was no overlap between these compounds and the 72,423 LC compounds described above that were used to train VS models. As with the initial library, the PriA-SSB AS assay was used in the same 1536-well format at a single concentration (33.3 &#x03BC;M) to test the additional 25,279 LC compounds. Actives were defined with the same criteria used for the binary dataset <bold>PriA-SSB AS</bold>. Compounds with at least 35&#x0025; inhibition that passed the PAINS filters were retested with the AS assay. Those with at least 35&#x0025; inhibition in the AS retest were labeled as actives, creating the binary dataset <bold>PriA-SSB prospective</bold>.</p>
<p>Because secondary screens and structural filters were used to define the active compounds, there was no single primary screen &#x0025; inhibition threshold that separated the actives from the inactives. Some compounds exhibiting high &#x0025; inhibition values were labeled as inactive because they did not satisfy the structural requirements or were not active in the secondary screen.</p>
<p>To help learn a better chemical representation with multi-task neural networks, we considered other screening contexts from which to transfer useful knowledge. We used a specific subset of 128 assays (AIDs) from the <bold>PubChem BioAssay (PCBA)</bold><sup><xref ref-type="bibr" rid="c22">22</xref></sup> repository. This dataset was used in previous work on multi-task neural networks.<sup><xref ref-type="bibr" rid="c14">14</xref></sup> This subset contained assays for which the assays were developed to probe a specific protein target and dose-response measurements were obtained for each compound (among other assay query filters, see Appendix A). Potency and curve quality are factored into a PubChem Activity Score. Regardless of assay, compounds receiving a PubChem Score of 40 or greater (0-100) were assigned a PCBA Bioactivity outcome (label) of &#x201C;Active&#x201D;. Compounds receiving PC Activity Scores 1-39 were labeled &#x201C;Inconclusive,&#x201D; and those receiving 0 are labeled &#x201C;Inactive&#x201D; (Appendices B and C).</p>
</sec>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Compound Features</title>
<p>Ligand-based virtual screening methods require each chemical compound to be represented in a particular format as input to the model. We adopted two common representations. All of the ligand-based algorithms except the Long Short-Term Memory (LSTM) neural network use 1024-bit Extended Connectivity Fingerprints (ECFP4).<sup><xref ref-type="bibr" rid="c23">23</xref></sup> For LSTM networks, we used the Simplified Molecular Input Line Entry System (SMILES) representation,<sup><xref ref-type="bibr" rid="c24">24</xref></sup> where the characters were treated as sequential features. Both ECFP and canonical SMILES were generated in RDKit.<sup><xref ref-type="bibr" rid="c25">25</xref></sup></p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Virtual Screening Models</title>
<p>We selected a variety of existing virtual screening approaches for our benchmarks and prospective predictions. These included ligand-based supervised learning approaches, structure-based docking, and a chemical similarity baseline. <xref ref-type="table" rid="tbl2">Table 2</xref> summarizes the types of training data used by each algorithm. We discuss hyperparameter tuning for these models in <xref ref-type="sec" rid="s2e">Section 2.5</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>A summary of the virtual screening methods and which labels each model used during training. The docking and consensus docking models do not train on the PriA-SSB or RMI-FANCM datasets.</p></caption>
<graphic xlink:href="337956_tbl2.tif"/>
</table-wrap>
<sec id="s2c1">
<label>2.3.1</label>
<title>Ligand-Based Neural Networks</title>
<p>Deep learning is a machine learning approach that encompasses neural network models with multiple hidden layer architectures and the techniques for training these models. It represents the state of the art for many predictive tasks, which has generated extensive interest in deep learning for biomedical research, including virtual screening.<sup><xref ref-type="bibr" rid="c15">15</xref></sup> We evaluated multiple types of established neural network architectures for virtual screening.</p>
<sec id="s2c1a">
<title>Single-task Neural Network (STNN)</title>
<p>A single-task neural network (<xref ref-type="fig" rid="fig1">Figure 1</xref>(a)) makes a single prediction for a single target (also referred to as a task). We trained a separate model for each of the <bold>PriA-SSB AS, PriA-SSB FP</bold>, and <bold>RMI-FANCM FP</bold> datasets, taking a compound&#x2019;s ECFP4 elements (1024 bits) as the input features. We trained the neural networks using Keras<sup><xref ref-type="bibr" rid="c26">26</xref></sup> with the Theano backend.<sup><xref ref-type="bibr" rid="c27">27</xref></sup> The single-task neural networks were trained on each task to predict either the binary activity label in the classification setting (STNN-C) or the continuous &#x0025; inhibition in the regression setting (STNN-R).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Neural network structures. The neural networks map the input features (e.g. fingerprints) in the input (bottom) layer to intermediate chemical representations in the hidden (middle) layers and finally to the output (top) layer, which makes either continuous or binary predictions. <xref ref-type="fig" rid="fig1">Figure 1</xref>(a) has only one unit in the output layer. <xref ref-type="fig" rid="fig1">Figure 1</xref>(b) has multiple units in the output layer representing different targets, one for our new target of interest and the others for PCBA targets.</p></caption>
<graphic xlink:href="337956_fig1.tif"/>
</fig>
</sec>
<sec id="s2c1b">
<title>Multi-task Neural Network (MTNN)</title>
<p>Multi-task neural networks make different predictions for multiple targets or tasks but share knowledge by training the first few hidden layers together. Each of our multi-task neural networks included one target task (<bold>PriA-SSB AS, PriA-SSB FP</bold>, or <bold>RMI-FANCM FP</bold>) and 128 tasks from PCBA. We only trained multi-task neural networks in the classification setting (MTNN-C).</p>
</sec>
<sec id="s2c1c">
<title>Single-task Atom-level LSTM (LSTM)</title>
<p>The LSTM is one of most prevalent recurrent neural network models,<sup><xref ref-type="bibr" rid="c28">28</xref></sup> which has been applied previously in virtual screening.<sup><xref ref-type="bibr" rid="c29">29</xref></sup> An LSTM assumes there exists a sequential pattern in the input string. We used a one hot encoding of the SMILES strings as input for the LSTM model. In a one hot encoding, each character in a SMILES string is replaced by a binary vector. The binary vector has one bit for each possible unique character in all SMILES strings. At each position in a SMILES string, the bit corresponding to the character at that position is set to 1, and all other bits are set to 0. We trained the LSTM model to predict the binary activity labels.</p>
</sec>
<sec id="s2c1d">
<title>Influence Relevance Voter (IRV)</title>
<p>IRV<sup><xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c31">31</xref></sup> is a hybrid between k-nearest neighbors and neural networks. Each compound&#x2019;s output value is a non-linear combination of the similarity scores from its most closely related compounds in the training dataset. We used ECFP4 fingerprints as the input and trained separate IRV models for each dataset.</p>
</sec>
</sec>
<sec id="s2c2">
<label>2.3.2</label>
<title>Other Ligand-Based Models</title>
<sec id="s2c2a">
<title>Random Forest (RF)</title>
<p>Random forests are ensembles of decision trees that are often used as a baseline in virtual screening benchmarks.<sup><xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup> We used scikit-learn34 to train a random forest classifier for each binary label with ECFP4 fingerprints as features.</p>
</sec>
</sec>
<sec id="s2c3">
<label>2.3.3</label>
<title>Protein-Ligand Docking</title>
<sec id="s2c3a">
<title>Target Preparation</title>
<p>Our structure-based VS approach involved the docking-based ranking of the LC library to the holo-form of PriA, using the crystal structure (PDB: 4NL8)<sup><xref ref-type="bibr" rid="c35">35</xref></sup> in which it is bound to a C-terminal segment of an SSB protein. A missing loop in this structure was added from the the apo-form (PBD: 4NL4), though this is not near the SSB binding site. The docking search space was limited to 8&#x00C5; from the coordinates of the co-crystallized SSB C-terminal tripeptide.</p>
</sec>
<sec id="s2c3b">
<title>Compound Preparation</title>
<p>LC library compounds were assigned 3D coordinates and Merck Molecular Force Field partial charges using OpenEye OMEGA and Molcharge.<sup><xref ref-type="bibr" rid="c36">36</xref></sup> Compounds in the LC library with ambiguous stereochemistry were enumerated in all possibilities, and the best resulting docking score was retained for each.</p>
</sec>
<sec id="s2c3c">
<title>Docking (Dock) and Consensus Docking (CD)</title>
<p>We ran eight different docking programs and generated nine docking scores. The docking programs and names we use for their scores are AutoDock v4.2.6<sup><xref ref-type="bibr" rid="c37">37</xref></sup> (Dock&#x005F;ad4), Dock v6.7<sup><xref ref-type="bibr" rid="c38">38</xref></sup> (Dock&#x005F;dock6), FRED v3.0.1<sup><xref ref-type="bibr" rid="c39">39</xref></sup> (Dock&#x005F;fred), HYBRID v3.0.1<sup><xref ref-type="bibr" rid="c39">39</xref></sup> (Dock&#x005F;hybrid), PLANTS v1.2<sup><xref ref-type="bibr" rid="c40">40</xref></sup> (Dock&#x005F;plants), rDock v2013.1<sup><xref ref-type="bibr" rid="c41">41</xref></sup> (Dock&#x005F;rdocktot and Dock&#x005F;rdockint), Smina v1.1.2<sup><xref ref-type="bibr" rid="c42">42</xref></sup> (Dock&#x005F;smina), and Surflex-Dock v3.040<sup><xref ref-type="bibr" rid="c43">43</xref></sup> (Dock&#x005F;surflex). In addition, we calculated consensus docking scores using three traditional approaches (CD&#x005F;mean, CD&#x005F;median, and CD&#x005F;max) and two versions of the Boosting Consensus Score (CD&#x005F;efr1&#x005F;opt and CD&#x005F;rocauc&#x005F;opt).<sup><xref ref-type="bibr" rid="c44">44</xref></sup> The Boosting Consensus Score method was trained using 21 of the DUD-E benchmark targets<sup><xref ref-type="bibr" rid="c45">45</xref></sup> without any PriA-SSB or RMI-FANCM assay data. Compounds with missing scores due to preparation or docking failures were not considered during evaluation.</p>
</sec>
</sec>
<sec id="s2cd">
<label>2.3.4</label>
<title>Chemical Similarity Baseline</title>
<p>In the prospective screening stage, we introduced a simple baseline compound ranking method against which to compare more sophisticated VS methods. Each of the 25,279 compounds in the prospective screening set was compared to the actives in <bold>PriA-SSB AS</bold> using Tanimoto similarity on the ECFP4 fingerprints. Compounds in the prospective library were ranked by their similarity, and those with Tanimoto similarity &#x2265; 0.45 to any active compound in the initial screen were predicted to be active.</p>
<p>In addition, all compounds were clustered by two separate approaches to describe chemical series. Chemical similarity based hierarchical clusters on ECFP4 using Ward&#x2019;s clustering are described as SIM. Maximum common substructure clusters, used to group molecules with similar scaffolds, are described as MCS. JKlustor was used for both types of clustering (JChem v17.26.0, ChemAxon).</p>
</sec>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Evaluation Metrics</title>
<p>Given our goal of developing VS methods that enable very small, cost-effective, productive screens, we considered how metrics weight early active retrieval. All of the VS algorithms produce a ranked list of compounds, where compounds are ordered by the probability of being active, the continuous predicted &#x0025; inhibition, the docking score, or a comparable output value. For a ranked list of compounds, we can threshold the ranked list and consider all compounds above the threshold as positive (active) predictions and those below the threshold as negative (inactive). By comparing those predictions to the experimentally-observed activity, we can compute true positive (TP), false positive (FP), true negative (TN), and false negative (FN) predictions for that ranked list at that threshold. We explored several options for summarizing how well each algorithm ranks the known active compounds.</p>
<p>The area under the receiver operating characteristic curve (AUC[ROC]) has been recommended for virtual screening because it is robust, interpretable, and does not depend on user-defined parameters.<sup><xref ref-type="bibr" rid="c46">46</xref></sup> The ROC curve plots the relationship between true positive rate (TPR, also known as sensitivity or recall) and false positive rate (FPR, equivalent to 1 - specificity), which are defined in Equation 1. As the FPR goes to 100&#x0025;, all ROC curves will converge, whereas early active retrieval (a more meaningful characteristic of VS performance) can be assessed in the low FPR region of the ROC curve, which exhibits greater variability across VS methods. Thus, we also considered the Boltzmann-enhanced discrimination of receiver operating characteristic (BEDROC).<sup><xref ref-type="bibr" rid="c47">47</xref></sup> It emphasizes the early part of the ROC curve through a scaling function &#x03B1;, which we set to 10 for our purposes of early enrichment up to 20&#x0025;. We used the BEDROC implementation from the CROC Python package.<sup><xref ref-type="bibr" rid="c48">48</xref></sup></p>
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="337956_eqn1.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="337956_eqn2.gif"/></alternatives>
</disp-formula>
<p>Area under the precision-recall curve (AUC[PR]) is another common metric (Equation 2). AUC[PR] has an advantage over AUC[ROC] for summarizing classifier performance when the class labels are highly-skewed, as in virtual screening where there are few active compounds in a typical library. AUC[PR] evaluates a classifier on its ability to retrieve actives (recall) and which of the predicted actives correctly classified (precision) as we vary the prediction threshold. We used the PRROC R package<sup><xref ref-type="bibr" rid="c49">49</xref></sup> to compute AUC[PR] because it correctly interpolates between points in the PR curve when there are ties in the compound rankings.<sup><xref ref-type="bibr" rid="c50">50</xref></sup></p>
<p>Another VS metric is enrichment factor (EF), which is the ratio between the number of actives found in some prioritized subset of compounds versus the expected number of actives in a random subset of same size. In other words, it assesses how much better the VS method performs over random compound selection. Let <italic>R</italic> &#x2208; [0&#x0025;, 100&#x0025;] be a pre-defined fraction of the compounds from the total library of compounds screened.</p>
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="337956_eqn3.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="337956_eqn4.gif"/></alternatives>
</disp-formula>
<p><italic>EF<sub>max,R</sub></italic> represents the maximum enrichment factor possible at <italic>R</italic>. Difficulty arises when interpreting EF scores because they vary with the dataset and threshold <italic>R</italic>. We defined the normalized enrichment factor (NEF) as:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="337956_eqn5.gif"/></alternatives>
</disp-formula></p>
<p>Because <italic>NEF<sub>R</sub></italic> &#x2208; [0,1], it is easier to compare performance across datasets and thresholds. 1.0 is the perfect normalized enrichment factor. Furthermore, we can create an NEF curve as <italic>NEF<sub>R</sub></italic> versus <italic>R</italic> &#x2208; [0&#x0025;, 100&#x0025;] and compute the area under that curve to obtain AUC[NEF] &#x2208; [0,1]. However, most models tend to exhibit similar late enrichment behavior. We are typically interested in early enrichment behavior so we computed AUC[NEF] using <italic>R</italic> &#x2208; [0&#x0025;, 20&#x0025;].</p>
<p>Finally, we introduce the metric n<sub><italic>hits</italic></sub> which is simply the number of actives found in a selected number of tested compounds (e.g. how many hits or actives were found in 250 tested compounds). This metric represents the typical desired utility of a screening process: retrieve as many actives as possible in the selected number of tests (denoted as <italic>n<sub>tests</sub></italic>). We compare <italic>n<sub>hits</sub></italic> at various <italic>n<sub>tests</sub></italic> to the different evaluation metrics to identify which metrics best mimic the <italic>n<sub>hits</sub></italic> utility.</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>Pipeline</title>
<p>Our virtual screening workflow contains three stages:
<list list-type="order">
<list-item><p>Tune hyperparameters in order to prune the model search space.</p></list-item>
<list-item><p>Train, evaluate, and compare models with k-fold cross-validation results.</p></list-item>
<list-item><p>Assess the best models&#x2019; ability to prospectively identify active compounds in a new set.</p></list-item>
</list></p>
<p>In contrast to most other virtual screening studies, the experimental screen was not conducted until after all models were trained and evaluated in the cross-validation stage. For the first two stages, we first split the <bold>PriA-SSB AS, PriA-SSB FP</bold>, and <bold>RMI-FANCM FP</bold> datasets into five stratified folds as described in Appendix B.</p>
<sec id="s2e1">
<label>2.5.1</label>
<title>Hyperparameter Sweeping Stage</title>
<p>Hyperparameters are model configurations or settings that can be set by an expert as opposed to the weights or parameters that are learned or fit during model training. For example, in neural networks the hyperparameters include the number of hidden layers, the number of hidden units in each layer, types of activation functions, drop out ratios, learning rates, etc. In random forests, hyperparameters include the number and depth of trees, the size of the subsamples, etc.</p>
<p>For most of the ligand-based machine learning models, the hyperparameter space was too large for exhaustive searches using the full dataset. Therefore, we applied a grid search on a pre-defined set of hyperparameters in a smaller dataset and pruned those that performed poorly. We performed a single iteration of training on the first four folds of <bold>PriA-SSB AS</bold> to avoid over-fitting. The hyperparameters considered are listed in Appendix D.</p>
</sec>
<sec id="s2e2">
<label>2.5.2</label>
<title>Cross-Validation Stage</title>
<p>To identify which VS algorithms are likely to have the best performance in a prospective screen, we applied a traditional cross-validation training strategy on datasets <bold>PriA-SSB AS, PriA-SSB FP</bold>, and <bold>RMI-FANCM FP</bold> after reducing the hyperparameter combinations to consider. Selecting the best model is non-trivial. Ideally, the best model would have dominant performance on all evaluation metrics, but this is rarely observed with existing models. Each evaluation metric prioritizes different performance characteristics. Our cross-validation results illustrate which models consistently perform well over different metrics, the correspondence of metrics relative to a desired utility (<italic>n<sub>hits</sub></italic>), and how to choose models and evaluation metrics in order to successfully identify active compounds in a prospective screen.</p>
<p>Cross-validation is commonly used to avoid over-fitting when there are few training samples. We split the training data into 5 folds, 4 folds for training and 1 for testing. Models like RF and IRV that do not require a hold-out dataset for early stopping used 4 folds for training. Other models like the neural networks perform early-stopping based on a hold-out set, so we iteratively selected 1 of the 4 training data folds for this purpose. This led to a two-layer cross-validation with 5 &#x00D7; 4 &#x003D; 20 trained neural networks.</p>
</sec>
<sec id="s2e3">
<label>2.5.3</label>
<title>Prospective Screening Stage</title>
<p>Our prospective screen used a library of 25,279 new LC compounds that were not present in the training set. We used each VS model to prioritize 250 of these compounds that are most likely to be active. This emulates virtual screening on much larger compound libraries, in which only a small fraction of all computationally scored compounds can be tested experimentally. After finalizing the models&#x2019; predictions, we screened all 25,279 compounds in the wet lab and assigned actives based on a 35 &#x0025; inhibition threshold and structural filters (<bold>PriA-SSB prospective</bold>). Finally, we evaluated how many of the wet lab actives each VS method identified in its top 250 predictions, the number of distinct chemical clusters recovered, and the number of active compounds that were not in the top 250 predictions from any of the VS algorithms. The prospective screen allowed us to assess how well the cross-validation results generalized to new compounds and further verified our conclusions from the retrospective cross-validation tests.</p>
</sec>
</sec>
<sec id="s2f" sec-type="availability">
<label>2.6</label>
<title>Data and Software Availability</title>
<p>Code implementing our ligand-based virtual screening algorithms is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gitter-lab/pria_lifechem">https://github.com/gitter-lab/pria_lifechem</ext-link>. This GitHub repository also contains additional Jupyter notebooks to reproduce the visualizations and analyses. Version 0.1.0 of our software is archived on Zenodo (doi:10.5281/zenodo.1257674). Our PriA-SSB and RMI-FANCM HTS data will be made available on PubChem. A formatted version of this dataset for training virtual screening algorithms is available on Zenodo (doi:10.5281/zenodo.1257463).</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Results</title>
<sec id="s3a">
<label>3.1</label>
<title>Cross-Validation Results</title>
<p>In the cross-validation stage we assessed 35 models: 8 neural networks (STNN-C, STNN-R, MTNN-C, and LSTM), 8 random forests (RF), 5 influence relevance voter (IRV), and 14 from docking (Dock) or consensus docking (CD). When there are multiple versions of a model that use different hyperparameters, we distinguish them with alphabetic suffixes such as &#x201C;&#x005F;a&#x201D; and &#x201C;&#x005F;b&#x201D;. Appendix E describes the hyperparameters associated with these suffixes. We highlight the <bold>PriA-SSB AS</bold> dataset as a representative example, but the VS workflow is applicable for all tasks.</p>
<sec id="s3a1">
<label>3.1.1</label>
<title>Comparing Virtual Screening Algorithms</title>
<p>We tested all 35 models on three datasets, and the results for four evaluation metrics on the <bold>PriA-SSB AS</bold> dataset are shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Appendix F contains the results for <bold>PriA-SSB FP</bold> and <bold>RMI-FANCM FP</bold>. The <bold>PriA-SSB AS</bold> performance using AUC[ROC] was comparable for most models, where nearly all models except LSTM and the docking programs were above 0.8 AUC[ROC]. Random forest was the best model, reaching AUC[ROC] of approximately 0.9.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>The evaluation metric distributions on <bold>PriA-SSB AS</bold> on all models over the crossvalidation folds.</p></caption>
<graphic xlink:href="337956_fig2.tif"/>
</fig>
<p>Random forest was again the best method for the <bold>RMI-FANCM FP</bold> dataset for most of the evaluation metrics (Appendix F). On the <bold>PriA-SSB FP</bold> dataset, STNN-R achieved the highest scores over the majority of the metrics (Appendix F). The other types of VS models were effectively tied for most metrics (Appendix G).</p>
</sec>
<sec id="s3a2">
<label>3.1.2</label>
<title>Evaluation Metrics</title>
<p>Given a fixed evaluation metric, we could compare two models with a t-test to assess if one statistically outperforms the other. However, we needed to make such comparisons repeatedly between each pair of models and required a statistical test that accounts for multiple hypothesis testing. Due to unequal variances and sample sizes (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we used Dunnett&#x2019;s modified Tukey-Kramer test (DTK.<sup><xref ref-type="bibr" rid="c51">51</xref>,<xref ref-type="bibr" rid="c52">52</xref></sup> for pairwise comparison to assess whether the mean metric scores of two models were significantly different.</p>
<p>Using DTK results for <italic>each metric</italic>, we scored each model based on how many times it attained a statistically significantly better result than other models (Appendix G). For most metric-target pairs, many models have the same rank because DTK does not report a significant difference. Based on DTK alone, RF models consistently place in the top five ranks for each metric-target pair.</p>
<p>In a prospective screen, our goal is to maximize the number of active compounds identified by a VS algorithm given a fixed budget (number of predictions). We wanted to determine which of the evaluation metrics commonly used for VS best aligns with <italic>n<sub>hits</sub>;</italic> i.e. maximizing the metric leads to maximizing <italic>n<sub>hits</sub></italic>. We assume that <italic>n<sub>hits</sub></italic> is ultimately the desired utility to maximize. Thus, we compared the model ranking induced by each metric with the model ranking induced by <italic>n<sub>hits</sub></italic> at varying number of tests.</p>
<p>To score the evaluation metrics, we used Spearman&#x2019;s rank correlation coefficient based on the model rankings induced by the metric of concern versus <italic>n<sub>hits</sub></italic> at a specific <italic>n<sub>tests</sub></italic>. We then ranked the metrics based on their correlation with <italic>n<sub>hits</sub></italic>. The correlation coefficients and metric rankings can be found in Appendix H. The metric ranking varies depending on <italic>ntests</italic> and the target. Some metrics overtake one another as we increase or decrease <italic>n<sub>tests</sub></italic>. For <bold>PriA-SSB AS</bold>, NEF<italic><sub>R</sub></italic> consistently placed in the top ranking correlations when <italic>R</italic> coincided with <italic>ntests</italic>. This is evident when we focus on a single metric and see the top ranking metrics for <italic>n<sub>tests</sub></italic> &#x2208; [100,250,500,1000,2500]. Only for a large enough <italic>n<sub>tests</sub></italic> do metrics like AUC[ROC] that evaluate the complete ranked list become comparable. This suggests that if we know <italic>a priori</italic> how many new compounds we can afford to screen, then NEF<italic><sub>R</sub></italic> at a suitable <italic>R</italic> is a viable metric for choosing a VS algorithm during cross-validation in the hopes of maximizing <italic>n<sub>hits</sub></italic>.</p>
</sec>
<sec id="s3a3">
<label>3.1.3</label>
<title>Selecting the Best Model</title>
<p>Based on these results, we selected the VS screening models that are most likely to generalize to new compounds and identify actives in our experimental screen of 25,279 new compounds. We focus on PriA-SSB for the prospective screen using models trained on <bold>PriA-SSB AS</bold> because the assay was more readily available for us to generate data for the new compounds.</p>
<p><xref ref-type="table" rid="tbl3">Table 3</xref> compares model selection based on evaluation metric means alone versus the DTK&#x002B;Mean approach for multiple evaluation metrics on the three tasks. The complete model rankings for means only and DTK&#x002B;Means can be found in Appendix I. DTK&#x002B;Mean ranks models by statistical significance and uses the mean value only for tie-breaking. Both strategies selected the same models for a fixed evaluation metric, except for AUC[PR] on all three tasks and NEF<sub>1&#x0025;</sub> for <bold>RMI-FANCM FP</bold>. This is mainly due to DTK not detecting statistically significant differences among the models&#x2019; evaluation scores, so tie-breaking by means selected the same models as ranking by means. Recall that <bold>PriA-SSB</bold> FP has fewer actives than <bold>PriA-SSB AS</bold> and <bold>RMI-FANCM FP</bold> (<xref ref-type="table" rid="tbl1">Table 1</xref>). Similar models from random forest and STNN-C were selected for <bold>PriA-SSB AS</bold> and <bold>RMI-FANCM FP</bold>. However, <bold>PriA-SSB FP</bold> identified STNN-R models exclusively.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><p>Top-ranked models by means versus DTK&#x002B;Mean on the three tasks. Evaluation metric means were computed over all cross-validation folds. The prospective screening was only performed on PriA-SSB. Model names are mapped to their hyperparameter values in Appendix E.</p></caption>
<graphic xlink:href="337956_tbl3.tif"/>
</table-wrap>
<p>In our prospective screen, each model prioritizes 250 top-ranked compounds, approximately 1&#x0025; of the new LC library. In this setting where each model has a fixed budget for the predicted compounds, NEF<italic><sub>R</sub></italic> is a suitable metric. Therefore, we used NEF<sub>1&#x0025;</sub> with DTK&#x002B;Means to choose the best models from each class. The best-in-class models were RandomForest&#x005F;h, SingleClassification&#x005F;a, SingleRegression&#x005F;b, MultiClassification&#x005F;b, LSTM&#x005F;b, IRV&#x005F;d, and ConsensusDocking&#x005F;efr1&#x005F;opt, with RandomForest&#x005F;h being the strongest model overall (Appendix I).</p>
</sec>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Prospective Screening Results</title>
<p>After selecting the best model from each class based on cross-validation and the NEF<sub>1&#x0025;</sub> metric, we retrained the models on all 72,423 LC compounds to predict PriA-SSB inhibition using the same types of data shown in <xref ref-type="table" rid="tbl2">Table 2</xref>. This provided a single version of each model instead of one for each cross-validation fold. All models then ranked 25,279 new LC compounds that were provided blind, without activity labels. We selected the top 250 ranked new compounds from each model. Then, we experimentally screened all 25,279 new compounds to assess PriA-SSB &#x0025; inhibition and defined actives based on a 35&#x0025; inhibition and PAINS filters. The new binary dataset <bold>PriA-SSB prospective</bold> contained 62 actives.</p>
<p><xref ref-type="table" rid="tbl4">Table 4</xref> presents how many of the 62 actives were identified by each of the best-in-class virtual screening methods, along with the chemical structure similarity baseline. For comparison, randomly selecting 250 compounds from the <bold>PriA-SSB prospective</bold> dataset is expected to identify less than one active. Appendices J and K show the VS models&#x2019; <bold>PriA-SSB prospective</bold> performance for the other evaluation metrics.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><p>The number of active compounds in the top 250 predictions from the seven selected models and the chemical similarity baseline compared to the number of experimentally-identified actives. These selected models are the best in each algorithm category from cross-validation. The last two columns correspond to the number of distinct chemical clusters from similarity or maximum common substructure clustering that are represented among the 62 actives. Complete hits on all models are in Appendix L.</p></caption>
<graphic xlink:href="337956_tbl4.tif"/>
</table-wrap>
<p><xref ref-type="table" rid="tbl4">Table 4</xref> also lists the number of distinct chemical clusters identified by each method, with the goal of identifying as many diverse compounds as possible. The 62 experimental hits represent 32 SIM and 37 MCS clusters or chemical series. Commonly, virtual screening is followed by a medicinal chemistry effort that would be expected to identify other members of these clusters.</p>
<p>In general, the number of distinct chemical clusters captured in the top 250 predictions is correlated with the number of actives (<xref ref-type="table" rid="tbl4">Table 4</xref>), meaning that the methods selected structurally diverse hits. The best ligand-based approaches predicted at least one compound from half of the SIM clusters but a smaller fraction of the MCS clusters. RF found the most actives and the most distinct chemical clusters.</p>
<p>On the <bold>PriA-SSB prospective</bold> dataset, only the RF model recovered more active compounds in its top 250 predictions than the chemical similarity baseline. Cross-validation with NEF<sub>1&#x0025;</sub> as the metric successfully identified the best PriA-SSB model before the prospective screen. The similarity baseline included one active compound that was excluded from the top 250 compounds from RF (<xref ref-type="fig" rid="fig3">Figure 3</xref>), but RF recovered a different member from this active compound&#x2019;s SIM and MCS clusters (Appendix M). The STNN-R and MTNN-C models identified fewer total active compounds than the similarity baseline but more unique chemical clusters.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>An UpSet plot showing the overlap between the top 250 predictions from the selected VS models and the chemical similarity baseline on <bold>PriA-SSB prospective</bold>. The plot generalizes a Venn diagram by indicating the overlapping sets with dots on the bottom and the size of the overlaps with the bar graph.<sup><xref ref-type="bibr" rid="c53">53</xref></sup> Altogether, the combined predictions from the best-in-class VS methods found 49 of the 62 actives.</p></caption>
<graphic xlink:href="337956_fig3.tif"/>
</fig>
<p>The ligand-based methods recovered many of the same actives as the chemical similarity baseline, but they also found actives that were missed by the baseline (<xref ref-type="fig" rid="fig3">Figure 3</xref>). There was a group of nine active compounds that were identified by most ligand-based methods, including the baseline model. The best model, RF, identified two unique actives that were not detected by any other methods. STNN-R was not the top performer overall but found nine unique actives and three unique chemical clusters (Appendix M).</p>
<sec id="s3b1">
<label>3.2.1</label>
<title>Trained Models are Target-Specific</title>
<p>As a control, we assessed the performance of models trained on <bold>RMI-FANCM FP</bold> instead of <bold>PriA-SSB AS</bold> for making <bold>PriA-SSB prospective</bold> predictions on the new 25,279 compounds. As expected, the <bold>RMI-FANCM FP</bold> models perform poorly on <bold>PriA-SSB prospective</bold> (Appendix J), indicating that the best <bold>PriA-SSB AS</bold> models have learned compound properties that are specific to PriA-SSB.</p>
</sec>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Discussion</title>
<p>We followed a VS pipeline with the goal of maximizing the number of active compounds identified in a prospective screen with a limited number of predictions. From an initial pool of structure-based and ligand-based models, we pruned models in a hyperparameter search stage and conducted cross-validation with multiple evaluation metrics. We used DTK&#x002B;Means with the NEF<sub>1&#x0025;</sub> metric to select the best models based on the cross-validation results and evaluated their top 250 prospective predictions from a new library of 25,279 compounds. The single best model from our pool, which was RandomForest&#x005F;h for <bold>PriA-SSB AS</bold>, was also the top performing model on <bold>PriA-SSB prospective</bold>. Therefore, our overall pipeline successfully identified the best prospective model.</p>
<p>Metrics like AUC[ROC] can compare models in general, regardless of cost or other additional constraints.<sup><xref ref-type="bibr" rid="c46">46</xref></sup> However, for virtual screening in practice, one typically only experimentally tests a small fraction of all compounds in the test library. In this setting, metrics like EF that capture early enrichment are preferable. In our prospective screen, STNN-R had higher AUC[ROC] than the random forest (Appendix J), but the random forest found 11 more active compounds in its top 250 predictions (<xref ref-type="table" rid="tbl4">Table 4</xref>). Our study suggests that EF<italic><sub>R</sub></italic>, or its normalized version NEF<italic><sub>R</sub></italic>, are the preferred metrics for identifying the best target-specific virtual screening method that maximizes <italic>n<sub>hits</sub></italic> when there is a budget for experimental testing. Other metrics like AUC[ROC] or AUC[PR], which is more appropriate for problems where the inactive compounds far outnumber the actives,<sup><xref ref-type="bibr" rid="c50">50</xref></sup> may still be reasonable for benchmarking virtual screening methods on large existing datasets where the entire ranked list of compounds is evaluated.<sup><xref ref-type="bibr" rid="c33">33</xref></sup></p>
<p>Some recent studies.<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c54">54</xref></sup> reported that deep learning models substantially outperform traditional supervised learning approaches, including random forests. Our finding that a random forest model was the most accurate in both cross-validation and our prospective screen does not refute those results. Rather, it reinforces that the ideal virtual screening method can depend on the training data available, target attributes, and other factors. Therefore, careful target-specific cross-validation is important to optimize prospective performance. One cannot assume that deep learning models will be dominant for all targets and all virtual screening scenarios. We also recommend hyperparameter exploration for all models, including traditional supervised learning methods. For example, our best random forest model contained 8000 estimators, whereas a previous benchmark considered at most 50 estimators.<sup><xref ref-type="bibr" rid="c3">3</xref></sup></p>
<p>Ramsundar et al.<sup><xref ref-type="bibr" rid="c14">14</xref></sup> showed that performance improved in multi-task neural networks as they added more training compounds and tasks. Furthermore, the degree of improvement varied across the datasets and was moderately correlated with number of shared active compounds among the targets within a single dataset. Task-relatedness also affects the success of multi-task learning but is difficult to quantify.<sup><xref ref-type="bibr" rid="c55">55</xref>,<xref ref-type="bibr" rid="c56">56</xref></sup> We observed that <bold>PriA-SSB AS</bold>, <bold>PriA-SSB FP</bold>, and <bold>RMI-FANCM FP</bold> have no shared actives with any of the PCBA tasks, and multi-task neural networks were not substantially better than single-task neural networks in <bold>PriA-SSB AS</bold> cross-validation (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The MTNN-C model outperformed the STNN-C model in the prospective evaluation (<xref ref-type="table" rid="tbl4">Table 4</xref>), possibly because multi-task learning can help prevent overfitting,<sup><xref ref-type="bibr" rid="c57">57</xref></sup> but was still considerably worse than the random forest.</p>
<p>We focused on docking and well-established machine learning models instead of more recent deep learning models, such as graph-based neural networks.<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c58">58</xref>&#x2013;<xref ref-type="bibr" rid="c61">61</xref></sup> This is because our main goal was to investigate the virtual screening principles for choosing the best model for a specific task (<bold>PriA-SSB AS</bold>) in a practical setting instead of broadly benchmarking virtual screening algorithms. In addition, a recent benchmark showed that conventional methods outperformed graph-based methods on most biophysics datasets.<sup><xref ref-type="bibr" rid="c33">33</xref></sup></p>
<p>Consensus docking<sup><xref ref-type="bibr" rid="c44">44</xref></sup> failed to recover any actives in the <bold>PriA-SSB prospective</bold> dataset, even though some of the individual docking programs did. It should be noted that the individual docking and consensus methods do not make use of the initial HTS screening data like the machine learning methods do. A more direct comparison might be to re-train a custom consensus scoring function to include the initial HTS data, though this effort is out of scope for this study.</p>
<p>Specifically for the PriA-SSB protein-protein interaction, docking is also limited by the large, flat nature of the binding site. Many compounds that are inactive in the experimental screen have good scores and reasonable binding poses (per visual inspection) but fail to interrupt necessary specific interactions in the protein-protein interface. This will the limit overall performance by pushing true actives down the ranked list. Therefore, our docking results are not necessarily representative for other targets with other structural features, once again demonstrating the need for target-specific model selection during virtual screening.</p>
<p>The random forest model performed the best overall, but there were ten active compounds identified by the other methods that the random forest missed (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The single-task regression neural network recovered nine of those ten and three unique active compound clusters (Appendix M). In addition, this regression model performed the best on <bold>PriA-SSB FP</bold> during cross-validation (<xref ref-type="table" rid="tbl3">Table 3</xref>), possibly because there are fewer binary actives in this dataset. In future work, we will explore whether ensembling classification and regression models, potentially in combination with structure-based VS algorithms, can further improve accuracy.</p>
<p>We emphasize our prospective performance on the new LC library, which minimizes the biases that make evaluation with retrospective benchmarks challenging.<sup><xref ref-type="bibr" rid="c62">62</xref></sup> There are many sources of experimental error in HTS, and the active compounds in the prospective evaluation must still be interpreted conservatively. However, a VS algorithm that can prioritize compounds with high &#x0025; inhibition in primary and retest screens is valuable for further compound optimization even if not all of the actives confirm experimentally. Our study provides guidelines for selecting a target-specific VS model and complements other practical recommendations for VS pertaining to hit identification, validation, and filtering<sup><xref ref-type="bibr" rid="c63">63</xref></sup> as well as avoiding common pitfalls.<sup><xref ref-type="bibr" rid="c64">64</xref></sup> Having established that our best virtual screening model successfully prioritized new active compounds in the LC library, another future direction will be to test prospective performance on much larger, more diverse chemical libraries.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The authors acknowledge GPU hardware from NVIDIA; compute resources of the University of Wisconsin-Madison Center for High Throughput Computing; and funding from the Center for Predictive Computational Phenotyping NIH/NIAID U54 AI117924, the University of Wisconsin Carbone Cancer Center Support Grant NIH P30 CA014520, and the Morgridge Institute for Research. Additional support for this research was provided by the University of Wisconsin-Madison Office of the Vice Chancellor for Research and Graduate Education with funding from the Wisconsin Alumni Research Foundation. We are grateful for the assistance and feedback from Gene E. Ananiev, Pengcheng Wang, Haozhen Wu, and many members of the Center for High Throughput Computing and the Gitter lab.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>(1)</label><mixed-citation publication-type="journal"><string-name><surname>Cross</surname>, <given-names>J. B.</given-names></string-name>; <string-name><surname>Thompson</surname>, <given-names>D. C.</given-names></string-name>; <string-name><surname>Rai</surname>, <given-names>B. K.</given-names></string-name>; <string-name><surname>Baber</surname>, <given-names>J. C.</given-names></string-name>; <string-name><surname>Fan</surname>, <given-names>K. Y.</given-names></string-name>; <string-name><surname>Hu</surname>, <given-names>Y.</given-names></string-name>; <string-name><surname>Humblet</surname>, <given-names>C.</given-names></string-name> <article-title>Comparison of several molecular docking programs: pose prediction and virtual screening accuracy</article-title>. <source>Journal of chemical information and modeling</source> <year>2009</year>, <volume>49</volume>, <fpage>1455</fpage>&#x2013;<lpage>1474</lpage>.</mixed-citation></ref>
<ref id="c2"><label>(2)</label><mixed-citation publication-type="journal"><string-name><surname>Lionta</surname>, <given-names>E.</given-names></string-name>; <string-name><surname>Spyrou</surname>, <given-names>G.</given-names></string-name>; <string-name><surname>K Vassilatis</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Cournia</surname>, <given-names>Z.</given-names></string-name> <article-title>Structure-based virtual screening for drug discovery: principles, applications and recent advances</article-title>. <source>Current topics in medicinal chemistry</source> <year>2014</year>, <volume>14</volume>, <fpage>1923</fpage>&#x2013;<lpage>1938</lpage>.</mixed-citation></ref>
<ref id="c3"><label>(3)</label><mixed-citation publication-type="journal"><string-name><surname>Korotcov</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Tkachenko</surname>, <given-names>V.</given-names></string-name>; <string-name><surname>Russo</surname>, <given-names>D. P.</given-names></string-name>; <string-name><surname>Ekins</surname>, <given-names>S.</given-names></string-name> <article-title>Comparison of Deep Learning With Multiple Machine Learning Methods and Metrics Using Diverse Drug Discovery Data Sets</article-title>. <source>Molecular Pharmaceutics</source> <year>2017</year>, <volume>14</volume>, <fpage>4462</fpage>&#x2013;<lpage>4475</lpage>.</mixed-citation></ref>
<ref id="c4"><label>(4)</label><mixed-citation publication-type="journal"><string-name><surname>Tseng</surname>, <given-names>Y. J.</given-names></string-name>; <string-name><surname>Hopfinger</surname>, <given-names>A. J.</given-names></string-name>; <string-name><surname>Esposito</surname>, <given-names>E. X.</given-names></string-name> <article-title>The great descriptor melting pot: mixing descriptors for the common good of QSAR models</article-title>. <source>Journal of Computer-Aided Molecular Design</source> <year>2012</year>, <volume>26</volume>, <fpage>39</fpage>&#x2013;<lpage>43</lpage>.</mixed-citation></ref>
<ref id="c5"><label>(5)</label><mixed-citation publication-type="journal"><string-name><surname>Hawkins</surname>, <given-names>P. C.</given-names></string-name>; <string-name><surname>Skillman</surname>, <given-names>A. G.</given-names></string-name>; <string-name><surname>Nicholls</surname>, <given-names>A.</given-names></string-name> <article-title>Comparison of shape-matching and docking as virtual screening tools</article-title>. <source>Journal of medicinal chemistry</source> <year>2007</year>, <volume>50</volume>, <fpage>74</fpage>&#x2013;<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c6"><label>(6)</label><mixed-citation publication-type="journal"><string-name><surname>Kr&#x00FC;ger</surname>, <given-names>D. M.</given-names></string-name>; <string-name><surname>Evers</surname>, <given-names>A.</given-names></string-name> <article-title>Comparison of Structure-and Ligand-Based Virtual Screening Protocols Considering Hit List Complementarity and Enrichment Factors</article-title>. <source>ChemMedChem</source> <year>2010</year>, <volume>5</volume>, <fpage>148</fpage>&#x2013;<lpage>158</lpage>.</mixed-citation></ref>
<ref id="c7"><label>(7)</label><mixed-citation publication-type="journal"><string-name><surname>Venkatraman</surname>, <given-names>V.</given-names></string-name>; <string-name><surname>P&#x00E9;rez-Nueno</surname>, <given-names>V. I.</given-names></string-name>; <string-name><surname>Mavridis</surname>, <given-names>L.</given-names></string-name>; <string-name><surname>Ritchie</surname>, <given-names>D. W.</given-names></string-name> <article-title>Comprehensive comparison of ligand-based virtual screening tools against the DUD data set reveals limitations of current 3D methods</article-title>. <source>Journal of chemical information and modeling</source> <year>2010</year>, <volume>50</volume>, <fpage>2079</fpage>&#x2013;<lpage>2093</lpage>.</mixed-citation></ref>
<ref id="c8"><label>(8)</label><mixed-citation publication-type="journal"><string-name><surname>Mitchell</surname>, <given-names>J. B. O.</given-names></string-name> <article-title>Machine learning methods in chemoinformatics</article-title>. <source>Wiley Interdisciplinary Reviews. Computational Molecular Science</source> <year>2014</year>, <volume>4</volume>, <fpage>468</fpage>&#x2013;<lpage>481</lpage>.</mixed-citation></ref>
<ref id="c9"><label>(9)</label><mixed-citation publication-type="website"><collab>Merck, Merck Molecular Activity Challenge</collab>. <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/c/">https://www.kaggle.com/c/</ext-link> <source>MerckActivity</source> <year>2012</year>,</mixed-citation></ref>
<ref id="c10"><label>(10)</label><mixed-citation publication-type="journal"><string-name><surname>Dahl</surname>, <given-names>G. E.</given-names></string-name>; <string-name><surname>Jaitly</surname>, <given-names>N.</given-names></string-name>; <string-name><surname>Salakhutdinov</surname>, <given-names>R.</given-names></string-name> <article-title>Multi-task Neural Networks for QSAR Predictions</article-title>. <source>arXiv preprint arXiv:1406.1231</source> <year>2014</year>,</mixed-citation></ref>
<ref id="c11"><label>(11)</label><mixed-citation publication-type="journal"><string-name><surname>Ma</surname>, <given-names>J.</given-names></string-name>; <string-name><surname>Sheridan</surname>, <given-names>R. P.</given-names></string-name>; <string-name><surname>Liaw</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Dahl</surname>, <given-names>G. E.</given-names></string-name>; <string-name><surname>Svetnik</surname>, <given-names>V.</given-names></string-name> <article-title>Deep neural nets as a method for quantitative structure&#x2013;activity relationships</article-title>. <source>Journal of chemical information and modeling</source> <year>2015</year>, <volume>55</volume>, <fpage>263</fpage>&#x2013;<lpage>274</lpage>.</mixed-citation></ref>
<ref id="c12"><label>(12)</label><mixed-citation publication-type="journal"><string-name><surname>Mayr</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Klambauer</surname>, <given-names>G.</given-names></string-name>; <string-name><surname>Unterthiner</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Hochreiter</surname>, <given-names>S.</given-names></string-name> <article-title>DeepTox: toxicity prediction using deep learning</article-title>. <source>Frontiers in Environmental Science</source> <year>2016</year>, <volume>3</volume>, <fpage>80</fpage>.</mixed-citation></ref>
<ref id="c13"><label>(13)</label><mixed-citation publication-type="journal"><string-name><surname>Unterthiner</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Mayr</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Klambauer</surname>, <given-names>G.</given-names></string-name>; <string-name><surname>Steijaert</surname>, <given-names>M.</given-names></string-name>; <string-name><surname>Wegner</surname>, <given-names>J. K.</given-names></string-name>; <string-name><surname>Ceulemans</surname>, <given-names>H.</given-names></string-name>; <string-name><surname>Hochreiter</surname>, <given-names>S.</given-names></string-name> <article-title>Deep learning as an opportunity in virtual screening</article-title>. <source>Advances in neural information processing systems</source> <year>2014</year>, <volume>27</volume>.</mixed-citation></ref>
<ref id="c14"><label>(14)</label><mixed-citation publication-type="journal"><string-name><surname>Ramsundar</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Kearnes</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Riley</surname>, <given-names>P.</given-names></string-name>; <string-name><surname>Webster</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Konerding</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Pande</surname>, <given-names>V.</given-names></string-name> <article-title>Massively multitask networks for drug discovery</article-title>. <source>arXivpreprint arXiv:1502.02072</source> <year>2015</year>,</mixed-citation></ref>
<ref id="c15"><label>(15)</label><mixed-citation publication-type="journal"><string-name><surname>Ching</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> <article-title>Opportunities and obstacles for deep learning in biology and medicine</article-title>. <source>Journal of The Royal Society Interface</source> <year>2018</year>, <volume>15</volume>, <fpage>20170387</fpage>.</mixed-citation></ref>
<ref id="c16"><label>(16)</label><mixed-citation publication-type="journal"><string-name><surname>Voter</surname>, <given-names>A. F.</given-names></string-name>; <string-name><surname>Manthei</surname>, <given-names>K. A.</given-names></string-name>; <string-name><surname>Keck</surname>, <given-names>J. L.</given-names></string-name> <article-title>A high-throughput screening strategy to identify protein-protein interaction inhibitors that block the Fanconi Anemia DNA repair pathway</article-title>. <source>Journal of biomolecular screening</source> <year>2016</year>, <volume>21</volume>, <fpage>626</fpage>&#x2013;<lpage>633</lpage>.</mixed-citation></ref>
<ref id="c17"><label>(17)</label><mixed-citation publication-type="journal"><string-name><surname>Voter</surname>, <given-names>A. F.</given-names></string-name>; <string-name><surname>Killoran</surname>, <given-names>M. P.</given-names></string-name>; <string-name><surname>Ananiev</surname>, <given-names>G. E.</given-names></string-name>; <string-name><surname>Wildman</surname>, <given-names>S. A.</given-names></string-name>; <string-name><surname>Hoffmann</surname>, <given-names>F. M.</given-names></string-name>; <string-name><surname>Keck</surname>, <given-names>J. L.</given-names></string-name> <article-title>A High-Throughput Screening Strategy to Identify Inhibitors of SSB Protein&#x2013;Protein Interactions in an Academic Screening Facility</article-title>. <source>SLAS DISCOVERY: Advancing Life Sciences R &#x0026; D</source> <year>2017</year>, <fpage>94</fpage>&#x2013;<lpage>101</lpage>.</mixed-citation></ref>
<ref id="c18"><label>(18)</label><mixed-citation publication-type="journal"><string-name><surname>Nordmann</surname>, <given-names>P.</given-names></string-name>; <string-name><surname>Cuzon</surname>, <given-names>G.</given-names></string-name>; <string-name><surname>Naas</surname>, <given-names>T.</given-names></string-name> <article-title>The real threat of Klebsiella pneumoniae carbapenemase-producing bacteria</article-title>. <source>The Lancet infectious diseases</source> <year>2009</year>, <volume>9</volume>, <fpage>228</fpage>&#x2013;<lpage>236</lpage>.</mixed-citation></ref>
<ref id="c19"><label>(19)</label><mixed-citation publication-type="journal"><string-name><surname>Manthei</surname>, <given-names>K. A.</given-names></string-name>; <string-name><surname>Keck</surname>, <given-names>J. L.</given-names></string-name> <article-title>The BLM dissolvasome in DNA replication and repair</article-title>. <source>Cellular and molecular life sciences</source> <year>2013</year>, <volume>70</volume>, <fpage>4067</fpage>&#x2013;<lpage>4084</lpage>.</mixed-citation></ref>
<ref id="c20"><label>(20)</label><mixed-citation publication-type="journal"><string-name><surname>Baell</surname>, <given-names>J. B.</given-names></string-name>; <string-name><surname>Holloway</surname>, <given-names>G. A.</given-names></string-name> <article-title>New substructure filters for removal of pan assay interference compounds (PAINS) from screening libraries and for their exclusion in bioassays</article-title>. <source>Journal of medicinal chemistry</source> <year>2010</year>, <volume>53</volume>, <fpage>2719</fpage>&#x2013;<lpage>2740</lpage>.</mixed-citation></ref>
<ref id="c21"><label>(21)</label><mixed-citation publication-type="journal"><string-name><surname>Lagorce</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Sperandio</surname>, <given-names>O.</given-names></string-name>; <string-name><surname>Baell</surname>, <given-names>J. B.</given-names></string-name>; <string-name><surname>Miteva</surname>, <given-names>M. A.</given-names></string-name>; <string-name><surname>Villoutreix</surname>, <given-names>B. O.</given-names></string-name> <article-title>FAF-Drugs3: a web server for compound property calculation and chemical library design</article-title>. <source>Nucleic acids research</source> <year>2015</year>, <volume>43</volume>, <fpage>W200</fpage>&#x2013;<lpage>W207</lpage>.</mixed-citation></ref>
<ref id="c22"><label>(22)</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>; <string-name><surname>Bryant</surname>, <given-names>S. H.</given-names></string-name>; <string-name><surname>Cheng</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>; <string-name><surname>Gindulyte</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Shoemaker</surname>, <given-names>B. A.</given-names></string-name>; <string-name><surname>Thiessen</surname>, <given-names>P. A.</given-names></string-name>; <string-name><surname>He</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Zhang</surname>, <given-names>J.</given-names></string-name> <article-title>PubChem BioAssay: 2017 Update</article-title>. <source>Nucleic Acids Research</source> <year>2017</year>, <volume>45</volume>, <fpage>D955</fpage>&#x2013;<lpage>D963</lpage>.</mixed-citation></ref>
<ref id="c23"><label>(23)</label><mixed-citation publication-type="journal"><string-name><surname>Rogers</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Hahn</surname>, <given-names>M.</given-names></string-name> <article-title>Extended-connectivity fingerprints</article-title>. <source>Journal of chemical information and modeling</source> <year>2010</year>, <volume>50</volume>, <fpage>742</fpage>&#x2013;<lpage>754</lpage>.</mixed-citation></ref>
<ref id="c24"><label>(24)</label><mixed-citation publication-type="journal"><string-name><surname>Weininger</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Weininger</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Weininger</surname>, <given-names>J. L.</given-names></string-name> <article-title>SMILES. 2. Algorithm for generation of unique SMILES notation</article-title>. <source>Journal of Chemical Information and Computer Sciences</source> <year>1989</year>, <volume>29</volume>, <fpage>97</fpage>&#x2013;<lpage>101</lpage>.</mixed-citation></ref>
<ref id="c25"><label>(25)</label><mixed-citation publication-type="website"><collab>RDKit</collab>: <source>Open-source cheminformatics</source>. <ext-link ext-link-type="uri" xlink:href="http://www.rdkit.org">http://www.rdkit.org</ext-link></mixed-citation></ref>
<ref id="c26"><label>(26)</label><mixed-citation publication-type="website"><string-name><surname>Chollet</surname>, <given-names>F.</given-names></string-name> <source>Keras</source>. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link> <year>2015</year>,</mixed-citation></ref>
<ref id="c27"><label>(27)</label><mixed-citation publication-type="journal"><collab>The Theano Development Team</collab>, <etal>et al.</etal> <article-title>Theano: A Python framework for fast computation of mathematical expressions</article-title>. <source>arXiv preprint arXiv:1605.02688</source> <year>2016</year>,</mixed-citation></ref>
<ref id="c28"><label>(28)</label><mixed-citation publication-type="journal"><string-name><surname>Hochreiter</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Schmidhuber</surname>, <given-names>J.</given-names></string-name> <article-title>Long Short-Term Memory</article-title>. <source>Neural Comput</source>. <year>1997</year>, <volume>9</volume>, <fpage>1735</fpage>&#x2013;<lpage>1780</lpage>.</mixed-citation></ref>
<ref id="c29"><label>(29)</label><mixed-citation publication-type="journal"><string-name><surname>Jastrzebski</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Le&#x015B;niak</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Czarnecki</surname>, <given-names>W. M.</given-names></string-name> <article-title>Learning to SMILE (s)</article-title>. <source>arXiv preprint arXiv:1602.06289</source> <year>2016</year>,</mixed-citation></ref>
<ref id="c30"><label>(30)</label><mixed-citation publication-type="journal"><string-name><surname>Swamidass</surname>, <given-names>S. J.</given-names></string-name>; <string-name><surname>Azencott</surname>, <given-names>C.-A.</given-names></string-name>; <string-name><surname>Lin</surname>, <given-names>T.-W.</given-names></string-name>; <string-name><surname>Gramajo</surname>, <given-names>H.</given-names></string-name>; <string-name><surname>Tsai</surname>, <given-names>S.-C.</given-names></string-name>; <string-name><surname>Baldi</surname>, <given-names>P.</given-names></string-name> <article-title>Influence relevance voting: an accurate and interpretable virtual high throughput screening method</article-title>. <source>Journal of chemical information and modeling</source> <year>2009</year>, <volume>49</volume>, <fpage>756</fpage>&#x2013;<lpage>766</lpage>.</mixed-citation></ref>
<ref id="c31"><label>(31)</label><mixed-citation publication-type="journal"><string-name><surname>Lusci</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Fooshee</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Browning</surname>, <given-names>M.</given-names></string-name>; <string-name><surname>Swamidass</surname>, <given-names>J.</given-names></string-name>; <string-name><surname>Baldi</surname>, <given-names>P.</given-names></string-name> <article-title>Accurate and efficient target prediction using a potency-sensitive influence-relevance voter</article-title>. <source>Journal of cheminformatics</source> <year>2015</year>, <volume>7</volume>, <fpage>63</fpage>.</mixed-citation></ref>
<ref id="c32"><label>(32)</label><mixed-citation publication-type="journal"><string-name><surname>Ramsundar</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Liu</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Wu</surname>, <given-names>Z.</given-names></string-name>; <string-name><surname>Verras</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Tudor</surname>, <given-names>M.</given-names></string-name>; <string-name><surname>Sheridan</surname>, <given-names>R. P.</given-names></string-name>; <string-name><surname>Pande</surname>, <given-names>V.</given-names></string-name> <article-title>Is multitask deep learning practical for pharma?</article-title> <source>Journal of chemical information and modeling</source> <year>2017</year>, <volume>57</volume>, <fpage>2068</fpage>&#x2013;<lpage>2076</lpage>.</mixed-citation></ref>
<ref id="c33"><label>(33)</label><mixed-citation publication-type="journal"><string-name><surname>Wu</surname>, <given-names>Z.</given-names></string-name>; <string-name><surname>Ramsundar</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Feinberg</surname>, <given-names>E. N.</given-names></string-name>; <string-name><surname>Gomes</surname>, <given-names>J.</given-names></string-name>; <string-name><surname>Geniesse</surname>, <given-names>C.</given-names></string-name>; <string-name><surname>Pappu</surname>, <given-names>A. S.</given-names></string-name>; <string-name><surname>Leswing</surname>, <given-names>K.</given-names></string-name>; <string-name><surname>Pande</surname>, <given-names>V.</given-names></string-name> <article-title>MoleculeNet: a benchmark for molecular machine learning</article-title>. <source>Chemical Science</source> <year>2018</year>,</mixed-citation></ref>
<ref id="c34"><label>(34)</label><mixed-citation publication-type="journal"><string-name><surname>Pedregosa</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal> <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source> <year>2011</year>, <volume>12</volume>, <fpage>2825</fpage>&#x2013;<lpage>2830</lpage>.</mixed-citation></ref>
<ref id="c35"><label>(35)</label><mixed-citation publication-type="journal"><string-name><surname>Bhattacharyya</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>George</surname>, <given-names>N. P.</given-names></string-name>; <string-name><surname>Thurmes</surname>, <given-names>T. M.</given-names></string-name>; <string-name><surname>Zhou</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Jani</surname>, <given-names>N.</given-names></string-name>; <string-name><surname>Wessel</surname>, <given-names>S. R.</given-names></string-name>; <string-name><surname>Sandler</surname>, <given-names>S. J.</given-names></string-name>; <string-name><surname>Ha</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Keck</surname>, <given-names>J. L.</given-names></string-name> <article-title>Structural mechanisms of PriA-mediated DNA replication restart</article-title>. <source>Proceedings of the National Academy of Sciences</source> <year>2014</year>, <volume>111</volume>, <fpage>1373</fpage>&#x2013;<lpage>1378</lpage>.</mixed-citation></ref>
<ref id="c36"><label>(36)</label><mixed-citation publication-type="journal"><string-name><surname>Hawkins</surname>, <given-names>P. C. D.</given-names></string-name>; <string-name><surname>Skillman</surname>, <given-names>A. G.</given-names></string-name>; <string-name><surname>Warren</surname>, <given-names>G. L.</given-names></string-name>; <string-name><surname>Ellingson</surname>, <given-names>B. A.</given-names></string-name>; <string-name><surname>Stahl</surname>, <given-names>M. T.</given-names></string-name> <article-title>Conformer Generation with OMEGA: Algorithm and Validation Using High Quality Structures from the Protein Databank and Cambridge Structural Database</article-title>. <source>Journal of Chemical Information and Modeling</source> <year>2010</year>, <volume>50</volume>, <fpage>572</fpage>&#x2013;<lpage>584</lpage>.</mixed-citation></ref>
<ref id="c37"><label>(37)</label><mixed-citation publication-type="journal"><string-name><surname>Morris</surname>, <given-names>G. M.</given-names></string-name>; <string-name><surname>Huey</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Lindstrom</surname>, <given-names>W.</given-names></string-name>; <string-name><surname>Sanner</surname>, <given-names>M. F.</given-names></string-name>; <string-name><surname>Belew</surname>, <given-names>R. K.</given-names></string-name>; <string-name><surname>Goodsell</surname>, <given-names>D. S.</given-names></string-name>; <string-name><surname>Olson</surname>, <given-names>A. J.</given-names></string-name> <article-title>AutoDock4 and AutoDockTools4: Automated docking with selective receptor flexibility</article-title>. <source>Journal of Computational Chemistry</source> <year>2009</year>, <volume>30</volume>, <fpage>2785</fpage>&#x2013;<lpage>2791</lpage>.</mixed-citation></ref>
<ref id="c38"><label>(38)</label><mixed-citation publication-type="journal"><string-name><surname>Allen</surname>, <given-names>W. J.</given-names></string-name>; <string-name><surname>Balius</surname>, <given-names>T. E.</given-names></string-name>; <string-name><surname>Mukherjee</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Brozell</surname>, <given-names>S. R.</given-names></string-name>; <string-name><surname>Moustakas</surname>, <given-names>D. T.</given-names></string-name>; <string-name><surname>Lang</surname>, <given-names>P. T.</given-names></string-name>; <string-name><surname>Case</surname>, <given-names>D. A.</given-names></string-name>; <string-name><surname>Kuntz</surname>, <given-names>I. D.</given-names></string-name>; <string-name><surname>Rizzo</surname>, <given-names>R. C.</given-names></string-name> <article-title>DOCK 6: Impact of new features and current docking performance</article-title>. <source>Journal of Computational Chemistry</source> <year>2015</year>, <volume>36</volume>, <fpage>1132</fpage>&#x2013;<lpage>1156</lpage>.</mixed-citation></ref>
<ref id="c39"><label>(39)</label><mixed-citation publication-type="journal"><string-name><surname>McGann</surname>, <given-names>M.</given-names></string-name> <article-title>FRED and HYBRID docking performance on standardized datasets</article-title>. <source>Journal of Computer-Aided Molecular Design</source> <year>2012</year>, <volume>26</volume>, <fpage>897</fpage>&#x2013;<lpage>906</lpage>.</mixed-citation></ref>
<ref id="c40"><label>(40)</label><mixed-citation publication-type="journal"><string-name><surname>Korb</surname>, <given-names>O.</given-names></string-name>; <string-name><surname>St&#x00FC;tzle</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Exner</surname>, <given-names>T. E.</given-names></string-name> <article-title>Empirical Scoring Functions for Advanced Protein-Ligand Docking with PLANTS</article-title>. <source>Journal of Chemical Information and Modeling</source> <year>2009</year>, <volume>49</volume>, <fpage>84</fpage>&#x2013;<lpage>96</lpage>.</mixed-citation></ref>
<ref id="c41"><label>(41)</label><mixed-citation publication-type="journal"><string-name><surname>Ruiz-Carmona</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Alvarez-Garcia</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Foloppe</surname>, <given-names>N.</given-names></string-name>; <string-name><surname>Garmendia-Doval</surname>, <given-names>A. B.</given-names></string-name>; <string-name><surname>Juhos</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Schmidtke</surname>, <given-names>P.</given-names></string-name>; <string-name><surname>Barril</surname>, <given-names>X.</given-names></string-name>; <string-name><surname>Hubbard</surname>, <given-names>R. E.</given-names></string-name>; <string-name><surname>Morley</surname>, <given-names>S. D.</given-names></string-name> <article-title>rDock: A Fast, Versatile and Open Source Program for Docking Ligands to Proteins and Nucleic Acids</article-title>. <source>PLOS Computational Biology</source> <year>2014</year>, <volume>10</volume>, <fpage>e1003571</fpage>.</mixed-citation></ref>
<ref id="c42"><label>(42)</label><mixed-citation publication-type="journal"><string-name><surname>Koes</surname>, <given-names>D. R.</given-names></string-name>; <string-name><surname>Baumgartner</surname>, <given-names>M. P.</given-names></string-name>; <string-name><surname>Camacho</surname>, <given-names>C. J.</given-names></string-name> <article-title>Lessons learned in empirical scoring with smina from the CSAR 2011 benchmarking exercise</article-title>. <source>Journal of Chemical Information and Modeling</source> <year>2013</year>, <volume>53</volume>, <fpage>1893</fpage>&#x2013;<lpage>1904</lpage>.</mixed-citation></ref>
<ref id="c43"><label>(43)</label><mixed-citation publication-type="journal"><string-name><surname>Cleves</surname>, <given-names>A. E.</given-names></string-name>; <string-name><surname>Jain</surname>, <given-names>A. N.</given-names></string-name> <article-title>Knowledge-guided docking: accurate prospective prediction of bound configurations of novel ligands using Surflex-Dock</article-title>. <source>Journal of Computer-Aided Molecular Design</source> <year>2015</year>, <volume>29</volume>, <fpage>485</fpage>&#x2013;<lpage>509</lpage>.</mixed-citation></ref>
<ref id="c44"><label>(44)</label><mixed-citation publication-type="journal"><string-name><surname>Ericksen</surname>, <given-names>S. S.</given-names></string-name>; <string-name><surname>Wu</surname>, <given-names>H.</given-names></string-name>; <string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>; <string-name><surname>Michael</surname>, <given-names>L. A.</given-names></string-name>; <string-name><surname>Newton</surname>, <given-names>M. A.</given-names></string-name>; <string-name><surname>Hoffmann</surname>, <given-names>F. M.</given-names></string-name>; <string-name><surname>Wildman</surname>, <given-names>S. A.</given-names></string-name> <article-title>Machine learning consensus scoring improves performance across targets in structure-based virtual screening</article-title>. <source>Journal of Chemical Information and Modeling</source> <year>2017</year>, <volume>57</volume>, <fpage>1579</fpage>&#x2013;<lpage>1590</lpage>.</mixed-citation></ref>
<ref id="c45"><label>(45)</label><mixed-citation publication-type="journal"><string-name><surname>Mysinger</surname>, <given-names>M. M.</given-names></string-name>; <string-name><surname>Carchia</surname>, <given-names>M.</given-names></string-name>; <string-name><surname>Irwin</surname>, <given-names>J. J.</given-names></string-name>; <string-name><surname>Shoichet</surname>, <given-names>B. K.</given-names></string-name> <article-title>Directory of Useful Decoys, Enhanced (DUD-E): Better Ligands and Decoys for Better Benchmarking</article-title>. <source>Journal of Medicinal Chemistry</source> <year>2012</year>, <volume>55</volume>, <fpage>6582</fpage>&#x2013;<lpage>6594</lpage>.</mixed-citation></ref>
<ref id="c46"><label>(46)</label><mixed-citation publication-type="journal"><string-name><surname>Nicholls</surname>, <given-names>A.</given-names></string-name> <article-title>What do we know and when do we know it?</article-title> <source>Journal of Computer-Aided Molecular Design</source> <year>2008</year>, <volume>22</volume>, <fpage>239</fpage>&#x2013;<lpage>255</lpage>.</mixed-citation></ref>
<ref id="c47"><label>(47)</label><mixed-citation publication-type="journal"><string-name><surname>Truchon</surname>, <given-names>J.-F.</given-names></string-name>; <string-name><surname>Bayly</surname>, <given-names>C. I.</given-names></string-name> <article-title>Evaluating virtual screening methods: good and bad metrics for the &#x201C;early recognition&#x201D; problem</article-title>. <source>Journal of chemical information and modeling</source> <year>2007</year>, <volume>47</volume>, <fpage>488</fpage>&#x2013;<lpage>508</lpage>.</mixed-citation></ref>
<ref id="c48"><label>(48)</label><mixed-citation publication-type="journal"><string-name><surname>Swamidass</surname>, <given-names>S. J.</given-names></string-name>; <string-name><surname>Azencott</surname>, <given-names>C.-A.</given-names></string-name>; <string-name><surname>Daily</surname>, <given-names>K.</given-names></string-name>; <string-name><surname>Baldi</surname>, <given-names>P.</given-names></string-name> <article-title>A CROC stronger than ROC: measuring, visualizing and optimizing early retrieval</article-title>. <source>Bioinformatics</source> <year>2010</year>, <volume>26</volume>, <fpage>1348</fpage>&#x2013;<lpage>1356</lpage>.</mixed-citation></ref>
<ref id="c49"><label>(49)</label><mixed-citation publication-type="journal"><string-name><surname>Grau J</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Grosse</surname> <given-names>I</given-names></string-name> <article-title>PRROC: computing and visualizing precision-recall and receiver operating characteristic curves in R</article-title>. <source>Bioinformatics</source> <year>2015</year>, <volume>31</volume>, <fpage>2595</fpage>&#x2013;<lpage>2597</lpage>.</mixed-citation></ref>
<ref id="c50"><label>(50)</label><mixed-citation publication-type="confproc"><string-name><surname>Davis</surname>, <given-names>J.</given-names></string-name>; <string-name><surname>Goadrich</surname>, <given-names>M.</given-names></string-name> <article-title>The relationship between Precision-Recall and ROC curves</article-title>. <conf-name>Proceedings of the 23rd international conference on Machine learning</conf-name>. <year>2006</year>; pp <fpage>233</fpage>&#x2013;<lpage>240</lpage>.</mixed-citation></ref>
<ref id="c51"><label>(51)</label><mixed-citation publication-type="journal"><string-name><surname>Lau</surname>, <given-names>M.</given-names></string-name> <article-title>DTK: Dunnett-Tukey-Kramer Pairwise Multiple Comparison Test adjusted for unequal variances and unequal sample sizes</article-title>. <source>R package</source> <year>2013</year>, <volume>3</volume>.</mixed-citation></ref>
<ref id="c52"><label>(52)</label><mixed-citation publication-type="journal"><string-name><surname>Dunnett</surname>, <given-names>C. W.</given-names></string-name> <article-title>Pairwise Multiple Comparisons in the Unequal Variance Case</article-title>. <source>Journal of the American Statistical Association</source> <year>1980</year>, <volume>75</volume>, <fpage>796</fpage>&#x2013;<lpage>800</lpage>.</mixed-citation></ref>
<ref id="c53"><label>(53)</label><mixed-citation publication-type="journal"><string-name><surname>Lex</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Gehlenborg</surname>, <given-names>N.</given-names></string-name>; <string-name><surname>Strobelt</surname>, <given-names>H.</given-names></string-name>; <string-name><surname>Vuillemot</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Pfister</surname>, <given-names>H.</given-names></string-name> <article-title>UpSet: Visualization of Intersecting Sets</article-title>. <source>IEEE Transactions on Visualization and Computer Graphics</source> <year>2014</year>, <volume>20</volume>, <fpage>1983</fpage>&#x2013;<lpage>1992</lpage>.</mixed-citation></ref>
<ref id="c54"><label>(54)</label><mixed-citation publication-type="journal"><string-name><surname>Lenselink</surname>, <given-names>E. B.</given-names></string-name>; <string-name><surname>Dijke</surname>, <given-names>N. t.</given-names></string-name>; <string-name><surname>Bongers</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Papadatos</surname>, <given-names>G.</given-names></string-name>; <string-name><surname>Vlijmen</surname>, <given-names>H. W. T. v.</given-names></string-name>; <string-name><surname>Kowalczyk</surname>, <given-names>W.</given-names></string-name>; <string-name><surname>IJzerman</surname>, <given-names>A. P.</given-names></string-name>; <string-name><surname>Westen</surname>, <given-names>G. J. P. v.</given-names></string-name> <article-title>Beyond the hype: deep neural networks outperform established methods using a ChEMBL bioactivity benchmark set</article-title>. <source>Journal of Cheminformatics</source> <year>2017</year>, <volume>9</volume>, <fpage>45</fpage>.</mixed-citation></ref>
<ref id="c55"><label>(55)</label><mixed-citation publication-type="journal"><string-name><surname>Kearnes</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Goldman</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Pande</surname>, <given-names>V.</given-names></string-name> <article-title>Modeling industrial ADMET data with multitask networks</article-title>. <source>arXiv preprint arXiv:1606.08793</source> <year>2016</year>,</mixed-citation></ref>
<ref id="c56"><label>(56)</label><mixed-citation publication-type="journal"><string-name><surname>Altae-Tran</surname>, <given-names>H.</given-names></string-name>; <string-name><surname>Ramsundar</surname>, <given-names>B.</given-names></string-name>; <string-name><surname>Pappu</surname>, <given-names>A. S.</given-names></string-name>; <string-name><surname>Pande</surname>, <given-names>V.</given-names></string-name> <article-title>Low Data Drug Discovery with One-Shot Learning</article-title>. <source>ACS Central Science</source> <year>2017</year>, <volume>3</volume>, <fpage>283</fpage>&#x2013;<lpage>293</lpage>.</mixed-citation></ref>
<ref id="c57"><label>(57)</label><mixed-citation publication-type="journal"><string-name><surname>Ruder</surname>, <given-names>S.</given-names></string-name> <article-title>An Overview of Multi-Task Learning in Deep Neural Networks</article-title>. <source>arXiv preprint arXiv:1706.05098</source> <year>2017</year>, arXiv: 1706.05098.</mixed-citation></ref>
<ref id="c58"><label>(58)</label><mixed-citation publication-type="other"><string-name><surname>Duvenaud</surname>, <given-names>D. K.</given-names></string-name>; <string-name><surname>Maclaurin</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Iparraguirre</surname>, <given-names>J.</given-names></string-name>; <string-name><surname>Bombarell</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Hirzel</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Aspuru-Guzik</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Adams</surname>, <given-names>R. P.</given-names></string-name> <article-title>Convolutional networks on graphs for learning molecular fingerprints. Advances in neural information processing systems</article-title>. <year>2015</year>; pp <fpage>2224</fpage>&#x2013;<lpage>2232</lpage>.</mixed-citation></ref>
<ref id="c59"><label>(59)</label><mixed-citation publication-type="journal"><string-name><surname>Kearnes</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>McCloskey</surname>, <given-names>K.</given-names></string-name>; <string-name><surname>Berndl</surname>, <given-names>M.</given-names></string-name>; <string-name><surname>Pande</surname>, <given-names>V.</given-names></string-name>; <string-name><surname>Riley</surname>, <given-names>P.</given-names></string-name> <article-title>Molecular graph convolutions: moving beyond fingerprints</article-title>. <source>Journal of Computer-Aided Molecular Design</source> <year>2016</year>, <volume>30</volume>, <fpage>595</fpage>&#x2013;<lpage>608</lpage>.</mixed-citation></ref>
<ref id="c60"><label>(60)</label><mixed-citation publication-type="journal"><string-name><surname>Coley</surname>, <given-names>C. W.</given-names></string-name>; <string-name><surname>Barzilay</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Green</surname>, <given-names>W. H.</given-names></string-name>; <string-name><surname>Jaakkola</surname>, <given-names>T. S.</given-names></string-name>; <string-name><surname>Jensen</surname>, <given-names>K. F.</given-names></string-name> <article-title>Convolutional embedding of attributed molecular graphs for physical property prediction</article-title>. <source>Journal of chemical information and modeling</source> <year>2017</year>, <volume>57</volume>, <fpage>1757</fpage>&#x2013;<lpage>1772</lpage>.</mixed-citation></ref>
<ref id="c61"><label>(61)</label><mixed-citation publication-type="journal"><string-name><surname>Matlock</surname>, <given-names>M. K.</given-names></string-name>; <string-name><surname>Dang</surname>, <given-names>N. L.</given-names></string-name>; <string-name><surname>Swamidass</surname>, <given-names>S. J.</given-names></string-name> <article-title>Learning a Local-Variable Model of Aromatic and Conjugated Systems</article-title>. <source>ACS Central Science</source> <year>2018</year>, <volume>4</volume>, <fpage>52</fpage>&#x2013;<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c62"><label>(62)</label><mixed-citation publication-type="other"><string-name><surname>Wallach</surname>, <given-names>I.</given-names></string-name>; <string-name><surname>Heifets</surname>, <given-names>A.</given-names></string-name> <article-title>Most Ligand-Based Classification Benchmarks Reward Memorization Rather than Generalization</article-title>. <source>Journal of Chemical Information and Modeling</source> <year>2018</year>,</mixed-citation></ref>
<ref id="c63"><label>(63)</label><mixed-citation publication-type="journal"><string-name><surname>Zhu</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Cao</surname>, <given-names>S.</given-names></string-name>; <string-name><surname>Su</surname>, <given-names>P.-C.</given-names></string-name>; <string-name><surname>Patel</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Shah</surname>, <given-names>D.</given-names></string-name>; <string-name><surname>Chokshi</surname>, <given-names>H. B.</given-names></string-name>; <string-name><surname>Szukala</surname>, <given-names>R.</given-names></string-name>; <string-name><surname>Johnson</surname>, <given-names>M. E.</given-names></string-name>; <string-name><surname>Hevener</surname>, <given-names>K. E.</given-names></string-name> <article-title>Hit Identification and Optimization in Virtual Screening: Practical Recommendations Based on a Critical Literature Analysis</article-title>. <source>Journal of Medicinal Chemistry</source> <year>2013</year>, <volume>56</volume>, <fpage>6560</fpage>&#x2013;<lpage>6572</lpage>.</mixed-citation></ref>
<ref id="c64"><label>(64)</label><mixed-citation publication-type="journal"><string-name><surname>Scior</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Bender</surname>, <given-names>A.</given-names></string-name>; <string-name><surname>Tresadern</surname>, <given-names>G.</given-names></string-name>; <string-name><surname>Medina-Franco</surname>, <given-names>J. L.</given-names></string-name>; <string-name><surname>Mart&#x00ED;nez-Mayorga</surname>, <given-names>K.</given-names></string-name>; <string-name><surname>Langer</surname>, <given-names>T.</given-names></string-name>; <string-name><surname>Cuanalo-Contreras</surname>, <given-names>K.</given-names></string-name>; <string-name><surname>Agrafiotis</surname>, <given-names>D. K.</given-names></string-name> <article-title>Recognizing Pitfalls in Virtual Screening: A Critical Review</article-title>. <source>Journal of Chemical Information and Modeling</source> <year>2012</year>, <volume>52</volume>, <fpage>867</fpage>&#x2013;<lpage>881</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>