<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/059733</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A phenome-wide examination of neural and cognitive function</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Poldrack</surname><given-names>RA</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Congdon</surname><given-names>E</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Triplett</surname><given-names>W</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3321-7583</contrib-id>
<name><surname>Gorgolewski</surname><given-names>KJ</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Karlsgodt</surname><given-names>KH</given-names></name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0926-3531</contrib-id>
<name><surname>Mumford</surname><given-names>JA</given-names></name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Sabb</surname><given-names>FW</given-names></name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3586-6587</contrib-id>
<name><surname>Freimer</surname><given-names>NB</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>London</surname><given-names>ED</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Cannon</surname><given-names>TD</given-names></name>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5085-7852</contrib-id>
<name><surname>Bilder</surname><given-names>RM</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, Stanford University</institution></aff>
<aff id="a2"><label>2</label><institution>Department of Psychiatry and Biobehavioral Sciences, University of California</institution> Los Angeles</aff>
<aff id="a3"><label>3</label><institution>Department of Psychology, University of California</institution>, Los Angeles</aff>
<aff id="a4"><label>4</label><institution>Center for Healthy Minds, University of Wisconsin</institution>-Madison</aff>
<aff id="a5"><label>5</label><institution>University of Oregon</institution></aff>
<aff id="a6"><label>6</label><institution>Department of Psychology, Yale University</institution></aff>
<aff id="a7"><label>7</label><institution>Department of Psychiatry, Yale University</institution></aff>
</contrib-group>
<author-notes>
<corresp>Corresponding Author: R Poldrack <email>russpold@stanford.edu</email></corresp></author-notes>
<pub-date pub-type="epub"><year>2016</year></pub-date>
<elocation-id>059733</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>6</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>19</day>
<month>6</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2016</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="059733.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>This data descriptor outlines a shared neuroimaging dataset from the UCLA Consortium for Neuropsychiatric Phenomics, which focused on understanding the dimensional structure of memory and cognitive control (response inhibition) functions in both healthy individuals (138 subjects) and individuals with neuropsychiatric disorders including schizophrenia (58 subjects), bipolar disorder (49 subjects), and attention deficit/hyperactivity disorder (45 subjects). The dataset includes an extensive set of task-based fMRI assessments, resting fMRI, structural MRI, and high angular resolution diffusion MRI. The dataset is shared through the OpenfMRI project, and is formatted according to the Brain Imaging Data Structure (BIDS) standard.</p></abstract>
<counts>
<page-count count="19"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Background and summary</title>
<p>The Consortium for Neuropsychiatric Phenomics (CNP) was established on the principle that discovery of genetic mechanisms for complex mental disorders will ultimately demand integration of research on large numbers of <italic>phenotypes</italic> spanning multiple biological and behavioral scales, from genome to syndrome, and will require both novel informatics and data analytic strategies. The CNP focused on two phenotype domains &#x2013; memory/working memory and response inhibition &#x2013; because these neurocognitive domains have been examined across multiple levels of analysis and are relevant to multiple neuropsychiatric syndromes. To examine these domains the CNP collected interviews and rating scales, self-report measures, neurocognitive exams using both paper-pencil and computerized tests, and neuroimaging data comprising structural MRI (sMRI), high angular resolution diffusion imaging (HARDI), and functional MRI (fMRI) both at rest (rsfMRI) and during five different cognitive activation paradigms. The CNP was committed to the perspective that most phenotypes should be considered dimensional until evidence of categorical structure was clear, and for this reason focused most on assessing phenotypes across a broad range of healthy people rather than specific groups representing individuals with neuropsychiatric syndromes. The CNP sample additionally included smaller groups of people who had diagnoses of schizophrenia, bipolar disorder, and attention-deficit/hyperactivity disorder (following DSM-IV), to determine where these individuals&#x2019; scores would fall with respect to the distributions observed in healthy individuals. The CNP was one of 9 Interdisciplinary Research Consortia supported by the NIH Roadmap Initiative from 2007-2012. The CNP comprised 8 linked awards, including a Coordinating Center (UL1DE019580, UL1RR024911), five linked R01 awards (RL1MH083268, RL1MH083269, RL1DA024853, RL1MH083270, and RL1LM009833) and two center grant awards (PL1MH083271 and PL1NS062410). To date the neuroimaging data from the CNP study have been used in 6 publications <sup><xref ref-type="bibr" rid="c1">1</xref>&#x2013;<xref ref-type="bibr" rid="c6">6</xref></sup>, and another 53 publications are linked to CNP awards.</p>
<p>This Data Descriptor provides a description of the neuroimaging data and related data from the CNP, which have been shared via the OpenFMRI project (<ext-link ext-link-type="uri" xlink:href="http://openfmri.org">http://openfmri.org</ext-link>)<sup>78</sup>. The shared data are described according to the Brain Imaging Data Structure (BIDS: <ext-link ext-link-type="uri" xlink:href="http://bids.neuroimaging.io">http://bids.neuroimaging.io</ext-link>) (Gorgolewski et al, in press) which is a data organization format designed to facilitate the transfer, description, and storage of neuroimaging experiment data. BIDS provides a disciplined way to arrange the different data types that comprise a neuroimaging experiment.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Participants</title>
<p>Healthy adults, ages 21-50, were recruited by community advertisements from the Los Angeles area; adult ADHD, Bipolar and Schizophrenia participants were recruited using a patient-oriented strategy involving outreach to local clinics and online portals (separate from the methods used to recruit healthy volunteers). All candidates were screened by telephone and then in person. To be included individuals had to identify themselves in either one of the NIH ethnic and racial categories: White, not Hispanic or Latino; or Hispanic or Latino, of any racial group. Additionally they satisfied the following inclusion-exclusion criteria: primary language (as determined by verbal fluency tests in both languages) either English or Spanish; completed at least 8 years of formal education; no significant medical illness by self report; adequately cooperative to complete assessments; and visual acuity 20&#x002F;60 or better. Urinalysis was used to screen for drugs of abuse (cannabinoids, amphetamine, opioids, cocaine, benzodiazepines), and participants were excluded if results were positive. This healthy behavioral sample comprised 1101 individuals.</p>
<p>A subset of the healthy sample and patient sample took part in two separate fMRI sessions, which each included one-hour of behavioral testing and a one-hour scan on the same day. Eligible English-speaking participants between the ages of 21 and 40 were recruited from the parent study if they successfully completed all previous testing sessions, and they did not meet the following additional exclusion criteria: left-handedness, pregnancy, history of head injury with loss of consciousness or cognitive sequelae, or other contraindications to scanning (e.g., claustrophobia, metal in body).</p>
<p>After receiving a verbal explanation of the study, participants gave written informed consent following procedures approved by the Institutional Review Boards at UCLA and the Los Angeles County Department of Mental Health. All subjects underwent a semi-structured assessment with the Structured Clinical Interview for the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition (DSM-IV) (SCID-I; (First MB, 2004)), supplemented for ADHD diagnoses with the Adult ADHD Interview (a structured interview form derived from the Kiddie Schedule for Affective Disorders and Schizophrenia, Present and Lifetime Version (KSADS-PL) (Kaufman et al., 1997)), in order to enable a more detailed characterization of lifetime history of ADHD in adults.</p>
<p>The final sample included imaging data for healthy individuals from the community (138 subjects), as well as samples of individuals diagnosed with Schizophrenia (58), Bipolar Disorder (49), and ADHD (45).</p>
</sec>
<sec id="s2b">
<title>Behavioral assessment</title>
<p>Enrolled participants completed extensive neuropsychological testing; these data will be shared separately at a later date via the NIH Data Archive. The list of tests performed during the behavioral session is presented in <xref ref-type="table" rid="tblS1a">Table S1</xref>. Participants were debriefed and compensated for their time at the end of the final testing session.</p></sec>
<sec id="s2c">
<title>Neuroimaging assessment</title>
<p><italic>Imaging acquisition</italic>. MRI data were acquired on one of two 3T Siemens Trio scanners, located at the Ahmanson-Lovelace Brain Mapping Center (Siemens version syngo MR B15) and the Staglin Center for Cognitive Neuroscience (Siemens version syngo MR B17) at UCLA. Functional MRI data were collected using a T2&#x002A;-weighted echoplanar imaging (EPI) sequence with the following parameters: slice thickness &#x003D; 4 mm, 34 slices, TR &#x003D; 2 s, TE &#x003D; 30 ms, flip angle &#x003D; 90&#x00B0;, matrix 64 &#x00D7; 64, FOV &#x003D; 192 mm, oblique slice orientation. Additionally, a T2-weighted matched-bandwidth high-resolution anatomical scan (with the same slice prescription as the fMRI scan) and MPRAGE were collected. The parameters for the high-resolution scan were: 4mm slices, TR/TE&#x003D;5000/34 ms, 4 averages, matrix &#x003D; 128&#x00D7;128, 90 degree flip angle. The parameters for MPRAGE were the following: TR &#x003D; 1.9 s, TE &#x003D; 2.26 ms, FOV &#x003D; 250 mm, matrix &#x003D; 256 &#x00D7; 256, sagittal plane, slice thickness &#x003D; 1 mm, 176 slices. Diffusion weighted imaging (DWI) data were collected using an echo-planar sequence with parameters: 64 directions, 2mm slices, TR/TE&#x003D;9000&#x002F;93 ms, 1 average, 96&#x003D;96 matrix, 90 degree flip angle, axial slices, b&#x003D;1000 s/mm<sup>2</sup>.</p>
<p>Subjects participated in two scanning sessions (&#x0022;A&#x0022; and &#x0022;B&#x0022;) in a counterbalanced fashion. Session A included: localizer, MPRAGE, DWI, Matched Bandwidth Hires, Balloon Analog Risk Task, and Paired-associate Memory Task. Session B included: localizer, Matched Bandwidth Hires, Resting State, Breath Hold Task, Stop Signal Task, Spatial Capacity working memory task (SCAP), and Task Switching Task.</p>
<p><italic>Resting fMRI</italic>. The resting fMRI scan lasted 304 seconds. Participants were asked to remain relaxed and keep their eyes open; they were not presented any stimuli or asked to respond during the scan.</p>
<p><italic>Task fMRI</italic>. For each task described below, all participants received brief training on each task immediately before scanning. Each participant viewed the task stimuli through MRI-compatible goggles, responded with his or her right hand on an MR-compatible button box in the scanner, and performed one run of each task while in the scanner. The presentation and timing of all stimuli and response events were achieved using Matlab (Mathworks) and the Psychtoolbox (<ext-link ext-link-type="uri" xlink:href="https://www.psychtoolbox.org">www.psychtoolbox.org</ext-link>) on an Apple Powerbook. Code for all tasks is available at <ext-link ext-link-type="uri" xlink:href="https://poldracklab.stanford.edu/software">https://poldracklab.stanford.edu/software</ext-link>.</p>
<p><italic>Balloon Analog Risk Task</italic>. In this task (Lejuez et al., 2002), participants were allowed to pump a series of virtual green (experimental) and white (control) balloons. On each trial, participants chose to pump the balloon or cash out and collect their accumulated earnings for that round. For experimental balloons, after a trial in which the participant successfully pumped the balloon (meaning it did not result in an explosion), an image of a larger balloon was presented, the participant earned 5 points, and was able to pump again or cash out. After a trial in which the participant chose to cash out, the participant&#x2019;s accumulated earnings for that round were displayed and the task moved onto the next round. On an explosion trial (necessarily following a pump trial), an exploded balloon was presented, the participant received no points for that round, and the task moved onto the next round. In this version of the BART, balloons exploded randomly on a number drawn from a uniform distribution over numbers of pumps, with 12 maximum pumps possible before an explosion or end of a round. Thus, participants experienced the probability as non-stationary, as the likelihood of a loss event increased with each trial in a round and as no information was provided to subjects about the probability of explosion. Participants also responded to control balloons, which increased in size on successive trials, but which neither resulted in points nor exploded. For both balloons (green and white), the balloon would disappear from the screen once the participant responded, and each balloon trial was separated by a jittered delay. An outcome trial (following a cash-out trial or an explosion) was displayed for a fixed duration of 2 s. Each trial was separated by a blank screen that was presented for a variable duration (1-2 s, average 1.5 s); each round was separated by a blank screen that was presented for variable duration (1-12 s, average 4 s).</p>
<p>The task performed in the scanner was self-paced, but the task was programmed such that participants saw approximately 30 virtual balloons, with an approximate run time of 9 minutes. Each successful pump was worth 5 points, but participants did not collect their earnings at the end of the scan.</p>
<p><italic>Paired-associate Memory Task</italic>. In this task, two scans were performed to assess declarative memory encoding and retrieval, respectively. The first scan consisted of a block of 64 encoding trials. Forty of the encoding trials were &#x201C;memory&#x201D; trials and 24 were &#x201C;control&#x201D; trials. During memory trials, first, two words appeared for 1 s, one on each side of the screen. Then, line drawings of two objects that matched the words appeared above the words and they were presented together for 3 more seconds. One of the objects was drawn in black and white, and one object drawn using a single color (e.g. orange). For control trials, pairs of scrambled stimuli, one black and white and one colored, appeared for 2 s. The subject indicated by button press which side the colored object was on. Subjects were instructed to remember the objects and the relationship between the objects. The trial types were intermixed, and the ITI between trials was jittered. The encoding run, in total, was 8.07 minutes long.</p>
<p>During the retrieval scan there were 104 total trials: 24 control trials, 40 correct trials, and 40 incorrect trials. The retrieval task required the subjects to look at a pair of objects and rate their confidence in their memory of the pairing. There were 4 possible response options ranging from &#x0022;Sure correct&#x0022; to &#x0022;Sure incorrect&#x0022;, allowing the responses to be analyzed as a spectrum or binarized into yes/no type responses. During control trials, on one side of the screen was one of the four retrieval confidence response options &#x0022;sure correct&#x0022;, &#x0022;maybe correct&#x0022;, &#x0022;maybe incorrect&#x0022;, or &#x0022;sure incorrect&#x0022;. On the other side of the screen was &#x0022;xxxx&#x0022;. Subjects were asked to press the button (1-4) that corresponded to the response option displayed (for example, a response of 1 if &#x201C;sure correct&#x201D; appeared). In the 40 correct trials, items were shown paired as they had been at encoding. During the 40 incorrect trials items were shown paired differently than they were at encoding; some objects are the same, but were just paired incorrectly. The retrieval scan was 8.93 minutes long.</p>
<p><italic>Spatial Working Memory Task</italic>. During the spatial delayed response task (or, spatial capacity task &#x002D; SCAP), subjects were shown a target array of 1, 3, 5 or 7 yellow circles positioned pseudorandomly around a central fixation cross. After a delay, subjects were shown a single green circle and were required to indicate whether that circle was in the same position as one of the target circles had been. A relatively long stimulus presentation time of two seconds was used to allow subjects to fully encode the target array, minimizing a potential encoding bias on the basis of set size interaction. Likewise, decision or selection requirements were kept constant across set sizes to reduce possible effects of set size on response processes. In addition to load, delay period was manipulated, with delays of 1.5, 3 or 4.5 seconds. Trial events included a 2-sec target-array presentation, a 1.5, 3 or 4.5 sec delay period, and a 3-sec fixed response interval. A central fixation was visible throughout each of the 48 trials (12 per memory set size, with 4 at each delay length for each memory set). Half the trials were true-positive, and half were true-negative. Before starting the in-scanner task, subjects underwent a supervised instruction and training period outside of the scanner, and once in the scanner were again reminded of the instructions. (Glahn, 2003; Cannon, 2005)</p>
<p><italic>Stop Signal Task</italic>. Participants were instructed to respond quickly when a &#x201C;go&#x201D; stimulus was presented on the computer screen, except on the subset of trials where the &#x201C;go&#x201D; stimulus was paired with a &#x201C;stop&#x201D; signal (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Specifically, participants were shown a series of go stimuli (left-and right-wards pointing arrows), to which participants were told to respond with left and right button presses, respectively (Go trials). On a subset of trials (25&#x0025;), a stop-signal (a 500 Hz tone presented through headphones) was presented a short delay after the go stimulus appeared and lasted for 250 ms (Stop trials). Participants were instructed to respond as quickly and accurately as possible on all trials, but to withhold their response on Stop trials (on trials with the tone). They also were instructed that stopping and going were equally important.</p>
<p>On Stop trials, the delay of the onset of the stop-signal, or stop-signal delay (SSD), was varied, such that it was increased after the participant successfully inhibited in response to a stop-signal (making the next stop trial more difficult), and decreased after the participant failed to inhibit in response to a stop-signal (making the next stop trial less difficult). Each SSD increase or decrease was in 50-ms intervals. The SSD values were drawn from two interleaved staircases per block, resulting in 16 trials from each staircase for a total of 32 Stop trials per block. On the testing day, participants completed two experimental runs (one run outside of the scanner and one while inside of the scanner). In the first task run completed outside of the scanner, SSD values started at 250 and 350 ms for staircase 1 and 2, respectively. At the end of the behavioral run, the last SSD time from each staircase was then carried over to be the initial SSD for the scan run. This one-up/one-down tracking procedure ensured that subjects successfully inhibited on approximately 50&#x0025; of inhibition trials. Also as a result, difficulty level is individualized across subjects and both behavioral performance and numbers of successful stop trials are equated across subjects.</p>
<p>Each experiment run contained 128 trials, 96 of which were Go trials and 32 of which were Stop trials, each presented randomly. All trials were preceded by a 500 ms fixation cross in the center of the screen, then each trial began with the appearance of an arrow and ended after 1000 ms, followed by the null period. Jittered null events separated every trial (with a blank screen), with the duration of null events sampled from an exponential distribution (null events ranged from 0.5 to 4 s, with a mean of 1 s).</p>
<p><italic>Task-switching Task</italic>. In this task, participants were presented with a series of one of four possible stimuli and asked to respond to the stimulus based on the task cue presented prior to, and above, the image. The four stimuli included a red triangle, red circle, green triangle, and green circle. Participants switched between responding to the image&#x2019;s color (i.e., red or green) or the shape (i.e., triangle or circle). Cues presented included either &#x201C;SHAPE&#x201D; or &#x201C;S&#x201D; on trials where participants were expected to respond to the shape of the stimulus; cues presented included either &#x201C;COLOR&#x201D; or &#x201C;C&#x201D; on trials where participants were expected to respond to the color of the stimulus. On 33&#x0025; of trials the instructions switched, such that participants were instructed to switch from responding from shape to color, or vice versa. On 67&#x0025; of trials, the instructions remained the same but the cues changed. This task is designed to measure the changes in reaction time between trials requiring versus not requiring a switch in responding. Participants completed a total of 96 trials, for a total run time of 6 min 52 s.</p>
<p><italic>Breath Holding Task</italic>. In this task, participants were asked to alternate between holding their breath and breathing regularly while resting. Participants were presented with bars on the screen in order to pace breath holding. When the bar was green, they were asked to breathe regularly; when the bar was yellow, they were asked to prepare to hold their breath; and when the bar was red, they were asked to hold their breath for 13.5 seconds. This cycle was repeated eight times, for a total run time of 2 minutes and 46 seconds. Participants performed the BHT in the scanner while wearing a respiratory belt in order to measure breathing. The purpose of this task was to assess the contribution of respiratory rhythms to changes in the BOLD signal.</p>
<p><italic>Physiological recording</italic>. During the breath holding and resting fMRI scans, physiological data were collected using a BIOPAC MP150 with Pulse Oximeter and Respiration modules. Data were sampled at 1000 Hz and recorded using BIOPAC Acknowledge software.</p>
</sec>
</sec>
<sec id="s3">
<title>Data Records</title>
<p>The data set is hosted on OpenfMRI under the accession number ds000030. The files are organized in the Brain Imaging Data Structure (BIDS) version 1.0.0rc3 format, and provided in multiple gzip-compressed tar archives <sup><xref ref-type="bibr" rid="c8">8</xref></sup>. BIDS provides a consistent naming convention and folder structure that is amenable to automated processing.</p>
<p>At the top-level, machine-readable text files in javascript object notation (JSON) are provided describing each fMRI task. A demographics file (participants.tsv; tab-delimited format) contains the unique participant number, age group, diagnosis, and an indication of which scan data are present for each subject.</p>
<p>The neuroimaging data collected for each participant are organized in a <italic>sub-&#x003C;subject_id&#x003E;</italic> data folder. The data for each imaging series are further organized into subfolders reflecting their intended use or purpose:
<list list-type="bullet">
<list-item>
<p><bold>func</bold>: BOLD contrast fMRI image data (both task-based and resting state), fMRI task event files, physiological monitoring logs;</p>
</list-item>
<list-item>
<p><bold>anat:</bold> high resolution T1-weighted image data used for structural analysis, cortical parcellation, and co-registration to standard templates;</p>
</list-item>
<list-item>
<p><bold>dwi:</bold> Diffusion-weighted image data used for experimental white matter characterization methods such as Diffusion Tensor Imaging;</p>
</list-item>
<list-item><p><bold>beh:</bold> Stop Signal task training run collected outside of the MRI scanner.</p>
</list-item>
</list>
</p>
<p>Each of these folders contain the following data files that collectively represent a participant&#x2019;s study visit:
<list list-type="bullet">
<list-item>
<p><bold>func/sub-&#x003C;subject id&#x003E;_task-&#x003C;taskname&#x003E;_bold.nii.gz</bold>: fMRI time series image data collected from the MRI in NIfTI format and compressed with gzip;</p>
</list-item>
<list-item>
<p><bold>func/sub&#x003C;subject id&#x003E;_task-&#x003C;taskname&#x003E;_events.tsv</bold>: Tab-separated text file containing the timing of the events presented during the fMRI task and the responses given by the participant;</p>
</list-item>
<list-item>
<p><bold>func/sub-&#x003C;subject id&#x003E;_task-&#x003C;taskname&#x003E;_bold.json</bold>: a JSON-structured file containing the MRI scanner parameters used to collect the image data;</p>
</list-item>
<list-item>
<p><bold>func/sub-&#x003C;subject id&#x003E;_task&#x003C;taskname&#x003E;_physio.tsv.gz</bold>: A gzip-compressed tab-separated text file containing the output from physiological monitoring that occurred during the fMRI resting state and breath-holding fMRI experiments;</p>
</list-item>
<list-item>
<p><bold>dwi/sub-&#x003C;subject id&#x003E;_dwi.bval</bold>: Diffusion weighting (s/mm<sup>2</sup>) applied to each volume in the diffusion weighted image series;</p>
</list-item>
<list-item><p><bold>dwi/sub-&#x003C;subject id&#x003E;_dwi.bvec</bold>: Diffusion weighting gradient orientations applied to each volume in the diffusion weighted image series;</p></list-item>
<list-item>
<p><bold>dwi/sub-&#x003C;subject id&#x003E;_dwi.nii.gz</bold>: Diffusion image data in NIfTI format compressed with gzip;</p>
</list-item>
<list-item>
<p><bold>dwi/sub-&#x003C;subject id&#x003E;_dwi.json</bold>: Diffusion weighted imaging scan parameters and metadata in a JSON text file;</p>
</list-item>
<list-item>
<p><bold>anat/sub-&#x003C;subject id&#x003E;_T1w.nii.gz</bold>: High-resolution (1&#x00D7;1&#x00D7;1 mm resolution) Tl-weighted image data for structural/anatomical use;</p>
</list-item>
<list-item>
<p><bold>anat/sub-&#x003C;subject id&#x003E;_T1w.json</bold>: MR scanning parameters and metadata in a JSON text file.</p>
</list-item>
</list>
</p>
<p>The label <bold>&#x003C;taskname&#x003E;</bold> refers to data from one of the tasks performed during the visit:
<list list-type="bullet">
<list-item><p><bold>bart</bold>: Balloon analog risk task</p></list-item>
<list-item><p><bold>stopsignal</bold>: Stop signal task</p></list-item>
<list-item><p><bold>pamenc</bold>: Paired memory encoding task</p></list-item>
<list-item><p><bold>pamret</bold>: Paired memory retrieval task</p></list-item>
<list-item><p><bold>scap</bold>: Spatial working memory task</p></list-item>
<list-item><p><bold>taskswitch</bold>: Task switching task</p></list-item>
<list-item><p><bold>bht</bold>: Breath-holding task</p></list-item>
<list-item><p><bold>rest</bold>: Resting state (eyes open)</p></list-item>
</list>
</p>
</sec>
<sec id="s4">
<title>Technical Validation</title>
<p>Imaging files were converted from primary DICOM data to Neuroimaging Informatics Technology Initiative (NIfTI) version 1.1 format using the dcm2niix (<ext-link ext-link-type="uri" xlink:href="https://github.com/neurolabusc/dcm2niix">https://github.com/neurolabusc/dcm2niix</ext-link>) program. dcm2niix extracts the image pixel data and pertinent metadata parameters from the DICOM files to populate the NIfTI file header. For diffusion weighted images, dcm2niix also extracts the diffusion gradient strengths and orientations to separate files. The dcm2niix program output was saved for each conversion and inspected for errors. Additional metadata were extracted from the DICOM files using the gdcm library (<ext-link ext-link-type="uri" xlink:href="http://gdcm.sourceforge.net/wiki/index.php/Main_Page">http://gdcm.sourceforge.net/wiki/index.php/Main_Page</ext-link>) and converted to javascript object notation (JSON) format to accompany the respective image files.</p>
<p>All relevant metadata were combined and plotted over the timeframe of the study to reveal instances where individual scans were performed with MRI parameter settings that deviated from the standard protocol and to highlight scans with non-standard dimensions. There were very few deviations, and most were minor in nature that did not warrant data exclusion; however the table of parameters and plots are included with the data set as reference material.</p>
<p>After processing the source data, BOLD contrast (fMRI) and Tl-weighted anatomical imaging data were processed by the MRI Quality Control protocol (MRIQC <ext-link ext-link-type="uri" xlink:href="https://github.com/poldracklab/mriqc">https://github.com/poldracklab/mriqc</ext-link>). MRIQC computes several quality control metrics available in the published literature.</p>
<sec id="s4a">
<title>Anatomical T1w Scans:</title>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Distribution of selected QC measures for T1w anatomical scans included in dataset.</p></caption>
<graphic xlink:href="059733_fig1.tif"/>
</fig>
<p>All Tl-weighted images were skull-stripped <sup><xref ref-type="bibr" rid="c9">9</xref></sup> [AFNI 3dSkullStrip], corrected for intensity inhomogeneity due to B1 variations <sup><xref ref-type="bibr" rid="c10">10</xref></sup> [ANTS N4], and normalized to MNI-152 2 mm template space <sup><xref ref-type="bibr" rid="c11">11</xref></sup> [ANTS]. The background, gray matter, white matter, and cerebrospinal fluid were segmented <sup><xref ref-type="bibr" rid="c12">12</xref></sup> [FSL 5.0.8/FAST], and the resulting segmentations were used to compute the following quality control measures:</p>
<table-wrap id="utbl1" orientation="portrait" position="float">
<graphic xlink:href="059733_utbl1.tif"/>
</table-wrap>
<p>In addition to the quality metrics listed above, summary information about the mean and standard deviation of background, foreground, gray matter, white matter, CSF, and average inhomogeneity bias are provided for comparison across the subject population.</p>
</sec>
<sec id="s4b">
<title>BOLD/T2&#x002A;-weighted Functional Scans:</title>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Distribution of selected QC measures for BOLD contrast functional scans included in dataset.</p></caption>
<graphic xlink:href="059733_fig2.tif"/>
</fig>
<p>Each BOLD-contrast fMRI scan was corrected for head motion during the acquisition using AFNI <sup><xref ref-type="bibr" rid="c9">9</xref></sup>, a brain mask was computed to separate the brain from the skull and outside air <sup><xref ref-type="bibr" rid="c16">16</xref></sup>. Then, the following QC metrics were computed:</p>
<table-wrap id="utbl2a" orientation="portrait" position="float">
<graphic xlink:href="059733_utbl2a.tif"/>
</table-wrap>
<table-wrap id="utbl2b" orientation="portrait" position="float">
<graphic xlink:href="059733_utbl2b.tif"/>
</table-wrap>
<p>After the MRIQC was completed, each high-resolution T1-weighted anatomical scan was scrubbed of facial features using the mri_deface program<sup><xref ref-type="bibr" rid="c20">20</xref></sup>. Visual inspection of all outputs was performed to ensure that the facial features were properly removed to preserve subject privacy.</p></sec></sec>
<sec id="s5">
<title>fMRI Task Event and Physiological Monitoring Data</title>
<p>fMRI task and event onsets were extracted from the raw matlab log files using R-matlab and are provided as tabular text files. These event files contain the onset, duration, type of trial, reaction time, and task-specific details. The onset time entries in each event file were corrected for the scanner trigger delay to account for extra T1 saturation equalization pre-scans performed by the scanner. In some cases the trigger delay was not explicitly available from the source data. Plots of all event files are provided with the data set for reference.</p>
<p>Similarly, physiological recordings collected during resting state and breath-holding fMRI scans were converted from raw data (Acknowledge format, BioPac) using the Bioread python package (<ext-link ext-link-type="uri" xlink:href="https://github.com/njvack/bioread">https://github.com/njvack/bioread</ext-link>). The individual recording traces were saved as gzip-compressed tab-separated value files, and the raw data header information (Channel Name, Units, Sampling Rate) was extracted to accompanying JSON files. Plots of physiological traces are provided overlaid with breath-hold instruction timings (ready, hold, rest) for reference.</p>
</sec>
<sec id="s6">
<title>Diffusion-weighted Imaging</title>
<p>The diffusion-weighted data were corrected for eddy currents and head motion using the B0 image as the reference, and the motion parameters were saved for later analysis<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. The corrected volumes were then skull-stripped to remove the background and other non-brain scan regions<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. Diffusion tensor estimation was performed for each subject, and the mean fractional anisotropy (FA) and average diffusivity (AD) were computed for all brain voxels<sup><xref ref-type="bibr" rid="c21">21</xref></sup>. Quality assurance was performed using a semi-automated method, including the following steps: confirmed that the b-values and applied directions were the same as expected, calculated mean in-mask FA and average or mean diffusivity (AD, MD), calculated and plotted motion, created a standard deviation image based on regular and motion corrected files, and used regional maps to calculate the percentage of cropped voxels in the occipital lobe, frontal lobe, temporal lobes, cerebellum, and the most superior portion of the brain. Trained individuals then used the results of this script to evaluate scan quality. This included a visual inspection of the FA map, visual inspection of the color map to ensure tracts were coded correctly, a check for cropping in which if more than 10 percent of voxels in a region were cropped, the map was visually inspected to ensure that the cropped region did not encroach on a major tract (i.e., regions that would be included in the FSL DTI skeleton), and the raw data were watched as a movie. Data were flagged for coverage (0&#x003D;no cropping, 1&#x003D;minor cropping, 2&#x003D;severe unuseable cropping), motion (based on watching raw data as movie, and on motion plots), tensor direction flags (based on b-value and direction calculations, and on observation of the color map), artifact flags (including noise, striping, and the vibration artifact that affected many Siemens Trio systems during this time period). An overall quality score from 1&#x2013;4 was generated from these measures, in which 1&#x003D;excellent, 2&#x003D;good, 3&#x003D;fair (both 2 and 3 may be useable, but depending on analysis may want to consider the reason for the decreased score), and 4&#x003D;unuseable (all individuals with vibration artifacts are in this category, along with other irreconcilable problems), 5&#x003D;not evaluated. Ratings are included with the data download.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Results from the semi-automated DWI quality assessment, by subject group.</p></caption>
<graphic xlink:href="059733_fig3.tif"/>
</fig>
</sec>
<sec id="s7">
<title>Usage Notes</title>
<p>All data are made available under the Public Domain Dedication and License v1.0 (<ext-link ext-link-type="uri" xlink:href="http://www.opendatacommons.org/licenses/pddl71.0/">http://www.opendatacommons.org/licenses/pddl71.0/</ext-link>), which places no restrictions on the usage of the data. We expect that users of the data will follow the ODC Attribution-Sharealike Community Norms (<ext-link ext-link-type="uri" xlink:href="http://opendatacommons.org/norms/odc-by-sa/">http://opendatacommons.org/norms/odc-by-sa/</ext-link>), which state that any derivative works should be shared via an equally open license, and that the creators of this dataset should be credited by citation of the present data descriptor.</p>
<p>We ask that users with questions please use the NeuroStars Forum (<ext-link ext-link-type="uri" xlink:href="https://neurostars.org">https://neurostars.org</ext-link>) and attach the tags &#x0022;openfmri&#x0022; and &#x0022;ds000030&#x0022; in order to discuss and comment on this dataset.</p></sec>
<sec id="s8">
<title>Data Citations</title>
<p>R. A. Poldrack et al., <italic>UCLA Consortium for Neuropsychiatric Phenomics LA5c Study</italic>. <ext-link ext-link-type="uri" xlink:href="https://openfmri.org/dataset/ds000030/">https://openfmri.org/dataset/ds000030/</ext-link></p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by the Consortium for Neuropsychiatric Phenomics (NIH Roadmap for Medical Research grants UL1-DE019580, RL1MH083268, RL1MH083269, RL1DA024853, RL1MH083270, RL1LM009833, PL1MH083271, and PL1NS062410). Preparation of the data in the BIDS format was supported by a grant from the Laura and John Arnold Foundation. Thanks to many research assistants who helped with data collection: especially Angelica Bato and Eric Miller who were primarily charged with scanning procedures, and others who participated in recruitment, clinical assessment, cognitive assessment, translation, task programming, and assisting with scanning, including Hannah Al-Sodani; Oren Boxer; Xavier Cagigas; Rachel Casas; Alan Chang; Jennifer Erickson; Winifred Flach; Christina Fong; Chelsea Gilbert; Samantha Hemingway; David Kaufman; Milky Kohno; Rachel Lavian; Evan Lutkenhoff; Carla Orieta; Katy Preciado; Cesia Toledo; Shahaf Tuler; Jessica Valluzzi; Jonathan Yang, Anna Xu, Amira Ibrahim, Aron Jacobsen, Nathalie De Shetler, Borja Izaguirre, Tyler Morgan, and Joey Contreras</p></ack>
<sec>
<title>Author contributions</title>
<p>RAP: conception and design of study and data sharing plan, drafting of the article. EC: conception and design of study, acquisition and analysis of data, critical review and final approval of the version submitted. WT: curation, critical review and final approval of the version submitted. KJG: design of data sharing plan, critical review and final approval of the version submitted. KHK: conception and design of study, acquisition and analysis of data, critical review and final approval of the version submitted. JAM: conception and design of study, final approval of the version submitted. FWS: conception and design of study, final approval of the version submitted. NBF: conception and design of study, final approval of the version submitted. TDC: conception and design of study, final approval of the version submitted. RMB: conception and design of study and data sharing plan, critical review and final approval of the version submitted.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="confproc"><string-name><surname>Helfinstein</surname>, <given-names>S. M.</given-names></string-name> <etal>et al.</etal> <article-title>Predicting risky choices from brain activity patterns</article-title>. <conf-name>Proc. Natl. Acad. Sci</conf-name>. <conf-loc>U. S. A</conf-loc>. <volume>111</volume>, <fpage>2470</fpage>&#x2013;<lpage>2475</lpage> (<conf-date>2014</conf-date>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Congdon</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal> <article-title>Neural activation during response inhibition in adult attention-deficit/hyperactivity disorder: preliminary findings on the effects of medication and symptom severity</article-title>. <source>Psychiatry Res</source>. <volume>222</volume>, <fpage>17</fpage>&#x2013;<lpage>28</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Congdon</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal> <article-title>Differences in neural activation as a function of risk-taking task parameters</article-title>. <source>Front. Neurosci</source>. <volume>7</volume>, <fpage>173</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Montojo</surname>, <given-names>C. A.</given-names></string-name> <etal>et al.</etal> <article-title>Neural mechanisms of response inhibition and impulsivity in 22q11.2 deletion carriers and idiopathic attention deficit hyperactivity disorder</article-title>. <source>Neuroimage Clin</source> <volume>9</volume>, <fpage>310</fpage>&#x2013;<lpage>321</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Montojo</surname>, <given-names>C. A.</given-names></string-name> <etal>et al.</etal> <article-title>Neural substrates of inhibitory control deficits in 22q11.2 deletion syndrome</article-title>. <source>Cereb. Cortex</source> <volume>25</volume>, <fpage>1069</fpage>&#x2013;<lpage>1079</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Schreiner</surname>, <given-names>M. J.</given-names></string-name> <etal>et al.</etal> <article-title>Default mode network connectivity and reciprocal social behavior in 22q11.2 deletion syndrome</article-title>. <source>Soc. Cogn. Affect. Neurosci.</source> <volume>9</volume>, <fpage>1261</fpage>&#x2013;<lpage>1267</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <etal>et al.</etal> <article-title>Toward open sharing of task-based fMRI data: the OpenfMRI project</article-title>. <source>Front. Neuroinform</source>. <volume>7</volume>, <fpage>12</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="other"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal> <article-title>The Brain Imaging Data Structure: a standard for organizing and describing outputs of neuroimaging experiments</article-title>. <source>bioRxiv</source> <fpage>034561</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1101/034561</pub-id></mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name> <article-title>AFNI: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages</article-title>. <source>Comput. Biomed. Res.</source> <volume>29</volume>, <fpage>162</fpage>&#x2013;<lpage>173</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name> <etal>et al.</etal> <article-title>N4ITK: improved N3 bias correction</article-title>. <source>IEEE Trans. Med. Imaging</source> <volume>29</volume>, <fpage>1310</fpage>&#x2013;<lpage>1320</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Avants</surname>, <given-names>B. B.</given-names></string-name> <etal>et al.</etal> <article-title>A reproducible evaluation of ANTs similarity metric performance in brain image registration</article-title>. <source>Neuroimage</source> <volume>54</volume>, <fpage>2033</fpage>&#x2013;<lpage>2044</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name> <article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title>. <source>IEEE Trans. Med. Imaging</source> <volume>20</volume>, <fpage>45</fpage>&#x2013;<lpage>57</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Magnotta</surname>, <given-names>V. A.</given-names></string-name>, <string-name><surname>Friedman</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>FIRST BIRN</surname></string-name>. <article-title>Measurement of Signal-to-Noise and Contrast-to-Noise in the fBIRN Multicenter Imaging Study</article-title>. <source>J. Digit. Imaging</source> <volume>19</volume>, <fpage>140</fpage>&#x2013;<lpage>147</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Atkinson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hill</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Stoyle</surname>, <given-names>P. N.</given-names></string-name>, <string-name><surname>Summers</surname>, <given-names>P. E.</given-names></string-name> &#x0026; <string-name><surname>Keevil</surname>, <given-names>S. F.</given-names></string-name> <article-title>Automatic correction of motion artifacts in magnetic resonance images using an entropy focus criterion</article-title>. <source>IEEE Trans. Med. Imaging</source> <volume>16</volume>, <fpage>903</fpage>&#x2013;<lpage>910</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Mortamet</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal><article-title>Automatic quality assessment in structural brain magnetic resonance imaging</article-title>. <source>Magn. Reson. Med.</source> <volume>62</volume>, <fpage>365</fpage>&#x2013;<lpage>372</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name> <article-title>Fast robust automated brain extraction</article-title>. <source>Hum. Brain Mapp.</source> <volume>17</volume>, <fpage>143</fpage>&#x2013;<lpage>155</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Giannelli</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Diciotti</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Tessa</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Mascalchi</surname>, <given-names>M.</given-names></string-name> <article-title>Characterization of Nyquist ghost in EPI-fMRI acquisition sequences implemented on two clinical 1.5 T MR scanner systems: effect of readout bandwidth and echo spacing</article-title>. <source>J. Appl. Clin. Med. Phys.</source> <volume>11</volume>, <fpage>3237</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="other"><string-name><surname>Nichols</surname>, <given-names>T.</given-names></string-name> <source>Notes on creating a standardized version of DVARS</source>. (<year>2013</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bannister</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name> <article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>. <source>Neuroimage</source> <volume>17</volume>, <fpage>825</fpage>&#x2013;<lpage>841</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Bischoff-Grethe</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>A technique for the deidentification of structural brain MR images</article-title>. <source>Hum. Brain Mapp.</source> <volume>28</volume>, <fpage>892</fpage>&#x2013;<lpage>903</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Basser</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Mattiello</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>LeBihan</surname>, <given-names>D.</given-names></string-name> <article-title>MR diffusion tensor spectroscopy and imaging</article-title>. <source>Biophys. J.</source> <volume>66</volume>, <fpage>259</fpage>&#x2013;<lpage>267</lpage> (<year>1994</year>).</mixed-citation></ref>
</ref-list>
<sec id="s9" sec-type="supplementary-material">
<table-wrap id="tblS1a" orientation="portrait" position="float">
<label>Table S1.</label>
<caption><p>Behavioral session assessments.</p></caption>
<graphic xlink:href="059733_utblS1a.tif"/>
</table-wrap>
<table-wrap id="tblS1b" orientation="portrait" position="float">
<graphic xlink:href="059733_utblS1b.tif"/>
</table-wrap>
<table-wrap id="tblS1c" orientation="portrait" position="float">
<graphic xlink:href="059733_utblS1c.tif"/>
</table-wrap>
</sec>
</back>
</article>