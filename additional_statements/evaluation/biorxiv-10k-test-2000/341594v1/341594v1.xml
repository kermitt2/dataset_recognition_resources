<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/341594</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Thought experiment: Decoding cognitive processes from the fMRI data of one individual</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Wegrzyn</surname><given-names>Martin</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Aust</surname><given-names>Joana</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Barnstorf</surname><given-names>Larissa</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Gippert</surname><given-names>Magdalena</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Harms</surname><given-names>Mareike</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hautum</surname><given-names>Antonia</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Heidel</surname><given-names>Shanna</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Herold</surname><given-names>Friederike</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hommel</surname><given-names>Sarah M.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Knigge</surname><given-names>Anna-Katharina</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Neu</surname><given-names>Dominik</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Peters</surname><given-names>Diana</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Schaefer</surname><given-names>Marius</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Schneider</surname><given-names>Julia</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Vormbrock</surname><given-names>Ria</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Zimmer</surname><given-names>Sabrina M.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Woermann</surname><given-names>Friedrich G.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Labudda</surname><given-names>Kirsten</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, Bielefeld University</institution>, Bielefeld, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Mara Epilepsy Centre</institution>, Bielefeld, <country>Germany</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label><bold>Corresponding author</bold>: <email>martin.wegrzyn@uni-bielefeld.de</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>341594</elocation-id>
<history>
<date date-type="received">
<day>08</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>08</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>6</month>
<year>2018</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions>
<self-uri xlink:href="341594.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<p>Cognitive processes, such as the generation of language, can be mapped onto the brain using fMRI. These maps can in turn be used for decoding the respective processes from the brain activation patterns. Given individual variations in brain anatomy and organization, analyzes on the level of the single person are important to improve our understanding of how cognitive processes correspond to patterns of brain activity. They also allow to advance clinical applications of fMRI, because in the clinical setting making diagnoses for single cases is imperative. In the present study, we used mental imagery tasks to investigate language production, motor functions, visuo-spatial memory, face processing, and resting-state activity in a single person. Analysis methods were based on similarity metrics, including correlations between training and test data, as well as correlations with maps from the NeuroSynth meta-analysis. Four blinded teams made predictions regarding the neuropsychological domain (e.g. language) and the specific content (e.g. animal names) of single 30-second blocks. Results showed that the similarity metrics allowed to reach the highest degrees of accuracy when predicting the superordinate domain of a block. Overall, 23 of the 25 test blocks could be correctly predicted by three of the four teams. Excluding the unspecific rest condition, up to 10 out of 20 blocks could be successfully decoded regarding their specific content. The study showed how the information contained in a single fMRI session and in each of its single blocks can allow to draw inferences about the cognitive processes an individual engaged in. Simple methods like correlations between blocks of fMRI data can serve as highly reliable approaches for cognitive decoding. We discuss the implications of our results in the context of clinical fMRI applications, with a focus on how decoding can support functional localization.</p>
</abstract>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Paul Broca, whose work lay the foundations for the localization of cognitive functions in the brain, speculated that &#x201C;the large regions of the mind correspond to the large regions of the brain&#x201D; (<italic>&#x201C;les grandes r&#x00E9;gions de l&#x2019;esprit correspondent aux grandes r&#x00E9;gions du cerveau&#x201D;</italic> in the french original) (<xref ref-type="bibr" rid="c6">Broca, 1861</xref>). Today, it is well established that broad neuropsychological domains, such as language, memory or motor functions can be reliably mapped onto specific regions of the brain (<xref ref-type="bibr" rid="c40">Satterthwaite and Davatzikos, 2015</xref>). Functional magnetic resonance imaging (fMRI) is one noninvasive method allowing to localize brain functions with limited but nevertheless remarkable detail (<xref ref-type="bibr" rid="c25">Kanwisher, 2017</xref>). While this type of large-scale localization of functions can provide only a limited understanding of how mind and brain work, it has proven to be of direct practical use (<xref ref-type="bibr" rid="c7">Bunzl et al., 2010</xref>; <xref ref-type="bibr" rid="c43">Szaflarski et al., 2017</xref>). In the clinical context, fMRI plays an important role for planning surgery in patients with tumors or epilepsies, as it aids the understanding of which parts of the brain need to be spared in order to preserve sensory, motor or cognitive abilities (<xref ref-type="bibr" rid="c42">Stippich, 2015</xref>). To be useful for clinical diagnostics and prognostics, fMRI data must be interpretable on the level of the individual case (<xref ref-type="bibr" rid="c10">Dubois and Adolphs, 2016</xref>). Because in group studies idiosyncratic activity patterns can be obscured by averaging, the precise mapping of brain function in a single person has become a vanguard of fMRI research (<xref ref-type="bibr" rid="c28">Laumann et al., 2015</xref>; <xref ref-type="bibr" rid="c23">Huth et al., 2016</xref>; <xref ref-type="bibr" rid="c15">Gordon et al., 2017</xref>). These studies are important to deepen our understanding of how the brain works, because the functional organization of brains becomes more heterogenous on a finer anatomical scale (<xref ref-type="bibr" rid="c28">Laumann et al., 2015</xref>; <xref ref-type="bibr" rid="c39">Poldrack, 2017</xref>). Also, when looking at increasingly smaller &#x2018;regions of the mind&#x2019;, such as the neural correlates of specific words instead of language in general, averaging on the group level can obscure the fine spatial information which allows to differentiate these contents in the individual brain (<xref ref-type="bibr" rid="c23">Huth et al., 2016</xref>). Single participant studies can also provide valuable impulses for the use of fMRI as a clinical tool. This includes the possibility to assess how stable results are within a single participant, and how much data should be collected to provide a reliable description of the individual&#x2019;s functional brain organization (<xref ref-type="bibr" rid="c28">Laumann et al., 2015</xref>; <xref ref-type="bibr" rid="c15">Gordon et al., 2017</xref>). While the group average is a composite of many individuals, the activity map of the individual is likewise a composite of an underlying timecourse, consisting of many separate observations of brain activity while performing a task. Variability over the course of an fMRI session can be expected due to factors such as head movement, fatigue, increasing familiarity with the task and changes in cognitive strategies (<xref ref-type="bibr" rid="c30">McGonigle, 2012</xref>; <xref ref-type="bibr" rid="c16">Gorgolewski et al., 2013</xref>). The neuroradiologist&#x2019;s interpretation of a single patient&#x2019;s fMRI might therefore be substantially improved, if she knows how the patient&#x2019;s cognitive states changed over time and how this relates to changes in brain activity patterns. This is particularly important if the fMRI task does not allow to monitor overt behavior. For example, in a language production task, patients might be asked to produce words from categories such as &#x201C;fruits&#x201D; or &#x201C;animals&#x201D; in a predefined period of time (<xref ref-type="bibr" rid="c44">Woermann et al., 2003</xref>). Because overt articulation of words produces movement artifacts, the patients are asked to use only internal speech. Without behavioral output from the patient, interpretation of fMRI results is limited by the uncertainty about whether the task was performed in the expected manner. A possible solution might be the decoding of fMRI data, in order to learn what the patient was thinking at each point in time. Decoding refers to an inference from brain activity patterns to the cognitive processes that accompanied them (<xref ref-type="bibr" rid="c38">Poldrack, 2006</xref>; <xref ref-type="bibr" rid="c21">Haynes and Rees, 2006</xref>). In clinical practice, decoding has proven to be highly valuable for communicating with unresponsive patients (<xref ref-type="bibr" rid="c35">Owen et al., 2006</xref>; <xref ref-type="bibr" rid="c4">Boly et al., 2007</xref>; <xref ref-type="bibr" rid="c41">Sorger et al., 2012</xref>). However, decoding methods are usually not being used in presurgical planning, where fMRI is used to learn how cognitive processes can be mapped onto the brain (i.e. encoding instead of decoding; <xref ref-type="bibr" rid="c33">Naselaris et al. (2011)</xref>). When interpreting an activity map, decoding might nevertheless be useful to better understand how the patient performed the task: Comparing different observations within-patient might allow to assess the stability of task performance during the fMRI session, while comparisons with healthy controls allow to assess if the task was performed in a prototypical way (<xref ref-type="bibr" rid="c10">Dubois and Adolphs, 2016</xref>).</p>
<p>The present fMRI-study aimed at decoding the domains of language, motor functions, visuo-spatial memory, face processing and task-free resting in a single individual. Each of these task domains is relevant for presurgical planning and can be used clinically in the individual patient (language <xref ref-type="bibr" rid="c44">Woermann et al. (2003)</xref>; motor <xref ref-type="bibr" rid="c17">H&#x00E5;berg et al. (2004)</xref>; visuospatial <xref ref-type="bibr" rid="c24">Jokeit et al. (2001)</xref>; faces <xref ref-type="bibr" rid="c36">Parvizi et al. (2012)</xref>). We used four mental imagery tasks and one rest task, where the verbal instruction to engage one of the above mentioned functions was the only external input given to the participant, and the fMRI data was the only output the participant produced. In order to evaluate how well decoding works at the level of individual fMRI blocks, we first analyzed a set of training data to learn how predictions of each neuropsychological domain could be optimized using simple similarity metrics. Then, test blocks were decoded regarding their superordinate domains as well as their specific contents. The study was carried out as part of a graduate course in psychology at Bielefeld University, with four groups of students making predictions for the test data.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a"><label>2.1</label>
<title>Participant</title>
<p>Data was collected from one healthy, 25 years old, male psychology student. The participant gave written informed consent, including written informed consent to have his brain data published online. The study was approved by the ethics committee of Bielefeld University (ethics statement 2016-171).</p>
</sec>
<sec id="s2b"><label>2.2</label>
<title>Mental imagery instructions</title>
<p>For the four neuropsychological domains of language, sensory-motor skills, visuo-spatial memory and visual processing of faces, imagery instructions were adapted from the literature: For language, a semantic verbal fluency task was used, in which the participant had to generate as many words belonging to a certain superordinate class as possible (e.g. animals, fruits; <xref ref-type="bibr" rid="c44">Woermann et al. (2003)</xref>). To engage motor imagery, the participant was instructed to perform different sports (e.g. tennis, soccer; <xref ref-type="bibr" rid="c35">Owen et al. (2006)</xref>). To test visuo-spatial memory, the participant was instructed to imagine walking in his hometown to different familiar locations (e.g. school, church; <xref ref-type="bibr" rid="c24">Jokeit et al. (2001)</xref>). To engage face processing mechanisms, the participant was asked to imagine famous or familiar faces (e.g. actors, friends; <xref ref-type="bibr" rid="c34">O&#x2019;Craven and Kanwisher (2000)</xref>). During time periods of resting, the participant was told to engage in a state of relaxed wakefulness. For each task, we tried to derive predictions about the brain areas which should be active when engaging in the respective cognitive process, based on the literature. The predictions for each task are summarized in <xref ref-type="table" rid="tbl1">Table 1</xref>.
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>Table 1.</label>
<caption><p>Overview of tasks used in the paradigm.</p></caption><graphic xlink:href="341594_tbl1.tif"/></table-wrap></p>
</sec>
<sec id="s2c"><label>2.3</label>
<title>Study design</title>
<p>We acquired three runs of fMRI data, with 25 blocks per run, and a block length of 30 seconds. Within each run, there were five blocks per condition and the order of the five conditions was counterbalanced, so that they followed each other equally often. This was achieved using a simplified version of a serially balanced sequence (<xref ref-type="bibr" rid="c32">Nair, 1967</xref>). During the experiment, the participant lay in the MRI scanner with eyes closed. Instructions to start thinking about one of the four categories and the rest condition were given by short verbal cues which were agreed upon beforehand (e.g. &#x201C;language &#x2013; fruits&#x201D;). Audibility was ensured by using an acquisition protocol with 500ms pauses between volumes, during which the instructions were given. In addition to the three main runs, we added a one-minute run where the participant was asked to first rest for 30 seconds and then think a&#x2019;secret&#x2019; thought for 30 seconds, the content of which he would not tell anyone and which was supposed to be different from the contents of the main experiment. Thus, this &#x2018;secret&#x2019; run was added to explore the possibility of out-of-sample predictions of completely new thoughts, for which we would not have any training data.</p>
</sec>
<sec id="s2d"><label>2.4</label>
<title>Data acquisition</title>
<p>MRI data were collected using a 3T Siemens Verio scanner. A high-resolution MPRAGE structural scan was acquired with 192 sagittal slices (TR=1900 msec, TE=2.5 msec, 0.8mm slice thickness, 0.75&#x00D7;0.75 in-plane resolution), using a 32-channel head coil. Functional echo-planar images (EPI) were acquired with 21 axial slices oriented along the rostrum and splenium of the corpus callosum (slice thickness of 5 mm, in-plane resolution 2.4&#x00D7;2.4 mm), using a 12-channel head coil. To allow for audible instructions during scanning, a sparse temporal sampling strategy was used (TR=3000ms with 2500ms acquisition time and 500ms pause between acquisitions). Excluding two dummy scans, a total of 253 volumes were collected for each run.</p>
</sec>
<sec id="s2e"><label>2.5</label>
<title>Data preprocessing</title>
<p>Basic preprocessing was performed using SPM12. Functional images were motion corrected using the realign function. The structural image was co-registered to the mean image of the functional timeseries and then used to derive deformation maps using the segment function (<xref ref-type="bibr" rid="c3">Ashburner and Friston, 2005</xref>). The deformation fields were then applied to all images (structural and functional) to transform them into MNI standard space and upsample them to 2mm isomorphic voxel size. The full normalized fMRI timecourses are available on doi.org/10.6084/m9.figshare.5951563.v1. All further preprocessing steps were carried out using Nilearn 0.2.5 (<xref ref-type="bibr" rid="c1">Abraham et al., 2014</xref>) in Python 2.7. To generate an activity map for each of the 75 blocks, each voxel&#x2019;s timecourse was z-transformed to have mean zero and standard deviation one. Timecourses were detrended using a linear function and movement parameters were added as confounds. Then TRs were grouped into blocks using a simple boxcar design shifted by 2 TR (the expected shift in the hemodynamic response function) and averaged, to give one averaged image per block. These images were used for all further analyses and are available on NeuroVault (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/3467">https://neurovault.org/collections/3467</ext-link>).</p>
</sec>
<sec id="s2f"><label>2.6</label>
<title>Data analysis</title>
<p>The first two fMRI runs (50 blocks total, 10 blocks per condition) were used as a training set and the third fMRI run (25 blocks total, 5 blocks per condition) was used as the held-out test set. To ensure proper blinding of test data, the block order was randomly shuffled and the 25 blocks were then assigned letters from A to Y. The true labels of the blocks were only known by the first author (MW), who did not participate in making predictions for the test data. Emulating the &#x201C;common task framework&#x201D; (<xref ref-type="bibr" rid="c29">Liberman, 2006</xref>) 15 of the authors formed four groups, of which each had to submit their predictions regarding the domain (e.g. &#x201C;motor imagery&#x201D;) and specific content (e.g. &#x201C;tennis&#x201D;) for each block in written form. The authors making the predictions were all graduate students of psychology, enrolled in a project seminar at Bielefeld University. Only after all predictions were submitted were the true labels of the test blocks revealed. It was also then when the participant himself revealed what he had thought about during the &#x2018;secret&#x2019; block. The groups were allowed to analyze the training and test data in any way they deemed fit, but all used a combination of the following methods: (i) Visual inspection with dynamic varying of thresholds using a software such as Mricron or FSLView. (ii) Voxel-wise correlation of brain maps from the training and the test set, to find the blocks which are most similar to each other. (iii) Voxel-wise correlations of brain maps with maps from NeuroSynth (<xref ref-type="bibr" rid="c45">Yarkoni et al., 2011</xref>), to find the keywords from the NeuroSynth database whose posterior probability maps are most similar to the participant&#x2019;s activity patterns. The basic principles of these analyses are presented in the following sections of the manuscript. Full code is available online (<ext-link ext-link-type="uri" xlink:href="https://github.com/mwegrzyn/thoughtExperiment">https://github.com/mwegrzyn/thoughtExperiment</ext-link>).</p>
<sec id="s2f1">
<title>Similarity of blocks</title>
<p>Similarity of blocks. For similarity analyses, Pearson correlations between the voxels of two brain images were computed. This was done either by correlating the activity maps of two individual blocks with each other, or by correlating an individual block with an average of all independent blocks belonging to the same condition. During training, a nested cross-validation approach was established, where the individual blocks from one run were correlated with the averaged maps of the five conditions from the other run. Each block was then assigned to the condition of the other run&#x2019;s average map it correlated strongest with. This was done for all blocks to determine the proportion of correct predictions. To learn from the training data which features allowed for the highest accuracy in predicting the domain of a block, the mask used to extract the data and the amount of smoothing were varied: Different brain masks were defined by thresholding the mean z-score maps for each of the five conditions on different levels of z-values and using only the remaining above-threshold voxel with highest values for computing correlations. The size of the smoothing kernel was also varied in a step-wise manner. The best combination of features (amount of voxels included and size of smoothing kernel used) from the cross-validation of the training data could then be used to decode the test data.</p>
</sec>
<sec id="s2f2">
<title>Similarity with NeuroSynth maps</title>
<p>In addition to these within-participant correlations, each block was also correlated with 602 posterior probability maps derived from the NeuroSynth database (<xref ref-type="bibr" rid="c45">Yarkoni et al., 2011</xref>). From the 3169 maps provided with NeuroSynth 0.3.5, we first selected the 2000 maps with the most nonzero voxel. This allowed to exclude many maps for unspecific keywords such as &#x201C;design&#x201D; or &#x201C;neuronal&#x201D;, with which no specific activation patterns are associated. The selected maps were then clustered using K-Means, as implemented in Scikit-learn 0.17 (<xref ref-type="bibr" rid="c37">Pedregosa et al., 2011</xref>). K-Means clustering was performed starting with two clusters and then successively increasing the number of clusters to be identified. For solutions of nine or more clusters, groups of keywords representing language, auditory, spatial, motor, reward, emotion, default mode and visual processing emerged, plus additional large clusters of further unspecific keywords which were still present in the dataset (e.g. &#x201C;normalization&#x201D;, &#x201C;anatomy&#x201D;). To exclude these unspecific keywords, we eliminated the largest cluster of the nine cluster solution and re-ran the K-Means clustering on the remaining 602 maps. This clustering resulted in the same eight interpretable clusters found previously (<xref ref-type="fig" rid="fig1">Fig 1</xref>). To visualize the similarity between the clusters and the relationship of keywords within each cluster, we computed the Euclidean distances between all maps and projected the distances into two dimensions using multi-dimensional scaling (MDS; cf. <xref ref-type="bibr" rid="c27">Kriegeskorte et al. (2008)</xref>) as implemented in Scikit-learn. The resulting &#x2018;cognitive space&#x2019; showed a strong agreement between the clustering and MDS, with keywords from the same cluster being close together in space (<xref ref-type="fig" rid="fig1">Fig 1</xref>). This &#x2018;cognitive space&#x2019; was then used for decoding, by correlating our fMRI data with all NeuroSynth maps. The resulting correlations were then visualized in the 2D space, allowing to inspect not only which keywords correlated the strongest, but also if there were consistent correlations within each cluster. To be computationally feasible, a gray matter mask with 4&#x00D7;4&#x00D7;4mm resolution was used for computing correlations, reducing the number of voxel to be correlated from &#x007E;230,000 to &#x007E;19,000.
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Cognitive Space derived from the NeuroSynth database. Colors were assigned based on K-means clustering and distances in space were derived using multidimensional scaling (MDS). Note how both approaches give very similar results, in terms of similar colors being close together in space. There are some exceptions, i.e. BA 47 being in the default mode cluster but closer to the auditory-related keywords in MDS-space. There are clear gaps between many of the clusters, indicating that they might be categorically distinct. Regarding the arrangement of clusters, the emotion and reward clusters are close together, as well as the motor and spatial, and the language and auditory clusters. The keywords on the borders of the clusters often represent concepts shared by multiple domains, for example &#x201C;characters&#x201D; bridging the clusters of vision and language, &#x201C;visual motion&#x201D; close to vision and spatial processing, or &#x201C;avoidance&#x201D; related to emotion and reward processing. To allow for good readability, keywords in the figure had to be a certain distance from each other in the space to be plotted.</p></caption><graphic xlink:href="341594_fig1.tif"/></fig></p>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a"><label>3.1</label>
<title>Results for the training data</title>
<sec id="s3a1">
<title>Mean activity maps</title>
<p>A visualization of the average activity map for each condition is shown in <xref ref-type="fig" rid="fig2">Fig 2</xref> For the language task, a clear left-lateralized network of regions, including inferior frontal gyrus, superior temporal sulcus, left supplementary motor area (SMA) and left fusiform gyrus, emerged. For the motor imagination task, SMA and premotor areas, as well as superior parietal cortex were active. The visuo-spatial memory task gave rise to activity in parahippocampal gyrus, premotor cortex and posterior parietal cortex. The face imagery condition showed activity around the mid-fusiform sulcus in both hemispheres, but mainly activity in the posterior cingulate and medial frontal areas. For the rest condition, there was only weak activity in the precuneus, as compared to the other four conditions.
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Activity maps for the five conditions of the training data. For visualization purposes, t-maps for the comparison of each condition against the remaining four were generated (smoothed with an 8mm kernel and thresholded at t=3.31, corresponding to p&#x003C;0.001). Results were projected on an inflated surface of the participant&#x2019;s normalized structural scan, using PySurfer. Interactive unthresholded versions of these maps are available on NeuroVault (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/3467/">https://neurovault.org/collections/3467/</ext-link>).</p></caption><graphic xlink:href="341594_fig2.tif"/></fig></p>
</sec>
<sec id="s3a2">
<title>Feature selection for correlation analyses</title>
<p>For computation of similarity metrics, correlations of individual blocks from one run with the mean activity maps from the respective other run were used (i.e. blocks of run 1 correlated with the five mean activity maps from run 2, or the other way around). The decision to which condition a block belonged was then made by assigning the block to the condition it had the highest correlation with. Using this approach without voxel selection or smoothing, an accuracy of 72&#x0025; was reached (p&#x003C;10<sup>&#x2212;14</sup>; for a binomial test with chance at 20&#x0025;). Using feature selection (varying the voxels included and the smoothing kernel used), accuracies of up to 92&#x0025; (p&#x003C;10<sup>&#x2212;27</sup>) could be reached, using only the top 1-3&#x0025; of voxel from each condition and moderate or no smoothing (<xref ref-type="fig" rid="fig3">Fig 3</xref>).
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Accuracies for the predictions of training data, as a function of voxel selection and smoothing kernel. Highest accuracies (in dark red) were reached using only the top 1-3&#x0025; of voxel active for each condition (i.e. using the 99-97th percentile to threshold the data). The percentile cutoff was applied to each map of the five conditions individually and the maps were then combined (conjunction of maps). Therefore, given that overlap between maps was low, percentile 80 contained 71&#x0025; of whole-brain voxel and percentile 99 contained 5&#x0025; of the whole-brain voxel.</p></caption><graphic xlink:href="341594_fig3.tif"/></fig></p>
<p>The correlations of individual blocks from one run with the mean activity blocks from the respective other run, using the best feature combination, are shown in <xref ref-type="fig" rid="fig4">Fig 4</xref>. Of the 50 blocks, one motor block was mistaken for rest, another motor block was mistaken for a visuo-spatial memory block, and two visuo-spatial blocks were mistaken for motor blocks, corresponding to 46 out of 50, or 92&#x0025;, correct predictions.
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Correlation of single blocks (rows) of one run with the mean activity maps (columns) of the respective other run. Results are based on unsmoothed data using a 99th percentile cutoff to threshold the mean activity maps with which the individual blocks are correlated. For each block, the name of the condition (i.e. &#x201C;language&#x201D;), the number of the block in the experiment (i.e. &#x201C;002&#x201D; for the second block of the experiment) and the content (i.e. &#x201C;animals&#x201D;) are indicated in the row labels.</p></caption><graphic xlink:href="341594_fig4.tif"/></fig></p>
</sec>
<sec id="s3a3">
<title>Decoding using NeuroSynth data</title>
<p>To evaluate how completely independent data can be used to decode the five conditions, each mean activity map (averaged over both training runs) was correlated with the NeuroSynth data and the strength of the correlation visualized in MDS space (<xref ref-type="fig" rid="fig5">Fig 5</xref>). Four of the five conditions showed strongest correlations with keywords from the respective related cluster (language-&#x201D;reading&#x201D;, motor-&#x201D;motor&#x201D;, visuo-spatial - &#x201C;spatial&#x201D;, rest - &#x201C;theory [of] mind&#x201D;). The correlations of the face condition indicated that the cognitive processes our participant engaged in during this task had more to do with episodic and working memory than with object and face processing (cf. <xref ref-type="fig" rid="fig5">Fig 5</xref>).
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>NeuroSynth decoding of average activity map for each training condition (averaged over both training runs). Stronger correlations with a keyword are indicated by a bigger circle, bigger font size and less transparency of font. To improve readability, the correlations are min-max scaled, so that the largest correlation is always of the same pre-defined size. Furthermore, the sizes of the scaled correlations have been multiplied with an exponential function, so that large correlations appear larger and small correlations smaller than they actually are (sizes are more extreme that the underlying data). To further enhance readability, if two keywords were too close in space so they would overlap, only the higher correlating keyword was printed.</p></caption><graphic xlink:href="341594_fig5.tif"/></fig></p>
</sec>
</sec>
<sec id="s3b"><label>3.2</label>
<title>Results for the test set</title>
<sec id="s3b1">
<title>Activity maps for individual blocks</title>
<p><xref ref-type="fig" rid="fig6">Fig 6</xref> shows the activity maps for all 25 individual blocks of the held-out test data. Here, robust activity in the networks already identified in the average training data (<xref ref-type="fig" rid="fig2">Fig 2</xref>) can be seen on a block-by-block basis. With the exception of block #60 for the motor imagery task, block #57 for the rest condition and block #64 for faces, specific activity in at least one of the most important regions for each domain could be found (language: superior temporal areas; motor: superior parietal areas; visuo-spatial: parahippocampal gyrus; faces: mid-fusiform sulcus; rest: precuneus).
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Example views of the individual activity maps of the test set. Only one view per block is shown. Maps depict the average z-values of each block, smoothed with an 8mm kernel and individually thresholded at different levels to best visualize the typical activity patterns. Red-yellow colors indicate activations and blue-lightblue colors indicate deactivations, in relation to the voxel&#x2019;s grand mean over the whole timecourse. Unthresholded and interactively explorable maps of each block are available on NeuroVault (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/3467/">https://neurovault.org/collections/3467/</ext-link>). For each block, the name of the condition (i.e. &#x201C;language&#x201D;), the number of the block in the experiment (i.e. &#x201C;052&#x201D; for the second block of the test run, which comprises blocks 51-75) and the content (i.e. &#x201C;countries&#x201D;) is indicated above the brain map.</p></caption><graphic xlink:href="341594_fig6.tif"/></fig></p>
</sec>
<sec id="s3b2">
<title>Correlation analysis with winner-take-all decision rule</title>
<p>A correlation approach using the same parameters as for the training data (top 1&#x0025; of voxel, no smoothing), allowed to correctly label 24 of the 25 test blocks (96&#x0025; correct; p&#x003C;10<sup>&#x2212;15</sup>; cf. <xref ref-type="fig" rid="fig7">Fig 7</xref>). The only misclassification occurs for block #60, where the &#x201C;swimming&#x201D; block from the movements condition is misclassified as belonging to the rest condition.
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Correlation of single blocks (rows) of the test run with the mean activity maps (columns) of the two training runs. Results are based on unsmoothed data using a 99th percentile cutoff to threshold the mean activity maps with which the individual blocks are correlated. For each block, the name of the condition (i.e. &#x201C;language&#x201D;), the number of the block in the experiment (i.e. &#x201C;052&#x201D; for the second block of the test run, which comprises blocks 51-75) and the content (i.e. &#x201C;countries&#x201D;) is indicated in the row labels.</p></caption><graphic xlink:href="341594_fig7.tif"/></fig></p>
<p>In addition to the correlation with mean training data, each of the 25 test blocks was also correlated with each of the 50 individual training blocks (<xref ref-type="fig" rid="fig8">Fig 8</xref>). Here, an optimal outcome would be if each test block has its ten highest correlations with the corresponding ten training blocks of the same condition. The results showed that for 20 of the 25 test blocks, at least eight of the highest correlations were with the correct corresponding training blocks. Only the &#x201C;swimming&#x201D; block had less than half of the ten highest correlations with training blocks from its correct domain.
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Correlation of the 25 blocks of the test run (051-075, rows) with the single blocks of the two training runs (001-050, columns).</p></caption><graphic xlink:href="341594_fig8.tif"/></fig></p>
</sec>
<sec id="s3b3">
<title>Decoding using NeuroSynth data</title>
<p>When using the NeuroSynth data to decode each test block, 60&#x0025; of blocks were correctly decoded using the cluster of the keyword with the highest correlation (p&#x003C;0.0001). The best predictions were possible for the motor, spatial and rest domains, while language and faces showed more ambiguous correlation patterns (<xref ref-type="fig" rid="fig9">Fig 9</xref>).
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><p>NeuroSynth decoding of individual blocks of the test run. For each block, the name of the condition, the number of the block and its content are indicated above the respective image of the space. An asterisk in the title indicates that the block was correctly decoded by assigning it to the cluster of the NeuroSynth keyword it correlated strongest with. For visualization, stronger correlations with a keyword are indicated by a bigger circle, bigger font size and less transparency of font. To improve readability, only the keywords with the highest correlations are labeled.</p></caption><graphic xlink:href="341594_fig9.tif"/></fig></p>
</sec>
<sec id="s3b4">
<title>Predictions made by the four teams</title>
<p>Based on these sources of information (visual inspection; correlation with mean training data; correlation with individual training blocks; correlation with NeuroSynth maps) the four teams submitted their predictions (<xref ref-type="table" rid="tbl2">Table 2</xref>). Three of the four teams made 23 correct predictions (p&#x003C;10<sup>&#x2212;13</sup>), all making the same mistake of classifying the swimming block as rest. In addition, the teams made at least one additional mistake, and therefore one mistake more than the correlation analysis in <xref ref-type="fig" rid="fig7">Fig 7</xref>. One team which weighted the results of visual inspection more strongly in their results reached an accuracy of only 76&#x0025; (p&#x003C;10<sup>&#x2212;8</sup>).
<table-wrap id="tbl2" position="float" orientation="portrait">
<label>Table 2.</label>
<caption><p>Results of the predictions made for the held-out test data.</p></caption><graphic xlink:href="341594_tbl2.tif"/></table-wrap></p>
<p>Regarding the prediction of content, the rest blocks had to be excluded, as they had no content, leaving 20 blocks from four conditions. Making the conservative assumptions that one can predict all superordinate categories perfectly and that there are only 5 possible contents within each condition, guessing would be at 20&#x0025; and at least 40&#x0025; correct would be needed to reach above-chance (p&#x003C;0.05) accuracies. Only two of the four teams scored better than chance, with one team making 10 correct predictions out of 20 (p=0.003) and the other team 9 out of 20 (p=0.01; cf. <xref ref-type="table" rid="tbl2">Table 2</xref>). As all teams used a combination of all methods to guess the content, the results do not allow to infer the role each individual method played for reaching these accuracies. However, using only the automated procedure of selecting the content of the training block with the highest correlation (cf. <xref ref-type="fig" rid="fig8">Fig 8</xref>), only chance performance (5 out of 20) could be reached.</p>
</sec>
<sec id="s3b5">
<title>Prediction of the secret block</title>
<p>In addition to the main task, the teams also tried to decode the additional &#x2018;secret&#x2019; run. The activity maps for the resting block and secret block of this run are shown in <xref ref-type="fig" rid="fig10">Fig 10</xref>, together with the maps from the NeuroSynth decoding. Both the visual inspection and the NeuroSynth results show that the resting block did not give rise to default mode network activity, making it unlikely that decoding of the secret block could work. However, given that frontal areas seemed to be engaged during the secret block, the teams speculated that language or executive functions might be recruited. There was no clear lateralization to the left, making pure language production less probable. Also, the secret run was the first and only one for which the NeuroSynth analysis showed strong correlations with the keyword &#x201C;[Brodmann Area] 47&#x201D;, located in the lateral orbital part of the inferior frontal gyrus. Brodmann Area 47 has been shown to be involved in the perception and imagination of music (<xref ref-type="bibr" rid="c26">Koelsch et al., 2005</xref>; <xref ref-type="bibr" rid="c46">Zatorre and Halpern, 2005</xref>). When originally planning the study, one additional condition under consideration was auditory imagination, operationalized as theme songs from different movies. Probably aided by this prior knowledge, one group was able to indeed correctly guess that the participant had mentally imagined music (<xref ref-type="table" rid="tbl3">Table 3</xref>). As the participant later revealed, he had imagined the main theme from &#x201C;Star Wars&#x201D;.
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><p>Activity maps and NeuroSynth decoding for the secret run. Average activity maps are smoothed with an 8mm kernel and projected onto an inflated normalized brain of the participant using PySurfer. Unthresholded images are available on NeuroVault (rest block: <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/images/60514/">https://neurovault.org/images/60514/</ext-link>; secret block: <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/images/60530/">https://neurovault.org/images/60530/</ext-link>) Correlations with the NeuroSynth keywords are visualized using larger symbols and fontsizes for higher correlations.</p></caption><graphic xlink:href="341594_fig10.tif"/></fig>
<table-wrap id="tbl3" position="float" orientation="portrait">
<label>Table 3.</label>
<caption><p>Predictions for the secret block</p></caption><graphic xlink:href="341594_tbl3.tif"/></table-wrap></p>
</sec>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>We showed that decoding &#x201C;large regions of the mind&#x201D; (<xref ref-type="bibr" rid="c6">Broca, 1861</xref>), namely language, motor functions, visuo-spatial memory, face processing, and task-free resting is possible using individual 30-second blocks of fMRI data. As in previous studies (<xref ref-type="bibr" rid="c4">Boly et al., 2007</xref>; <xref ref-type="bibr" rid="c41">Sorger et al., 2012</xref>), we were able to reach almost perfect accuracies when deciding between these superordinate neuropsychological domains using training data from the same participant. This was confirmed by visual inspection of the data (<xref ref-type="fig" rid="fig6">Fig 6</xref>), which showed that activity patterns on single block level were highly robust. We were also able to show how single blocks of a person&#x2019;s fMRI data can be decoded, regarding their superordinate categories, using an independent database which maps activations of hundreds of keywords onto the brain (<xref ref-type="bibr" rid="c45">Yarkoni et al., 2011</xref>). This demonstrated the potential to decode a completely new observation of brain activity in a person, even when no training data were available and no feature selection had been performed. Our results also showed that it is possible to predict the contents within some of the domains with moderate accuracy. Predictions worked best for the language and motor domains, in line with previous work: The contents of our language task can be considered superordinate categories in their own right (i.e. animals and tools as animate and inanimate objects), and thus their differential activity patterns can be expected to differ on a relatively large anatomical scale (<xref ref-type="bibr" rid="c31">Mummery et al., 1998</xref>). The different sports used in the motor task activated different parts of body, and could potentially be identified based on the somatotopic organization of SMA and superior parietal cortex (<xref ref-type="bibr" rid="c12">Fontaine et al., 2002</xref>; <xref ref-type="bibr" rid="c2">Aflalo et al., 2015</xref>). Because predictions of content were not explicitly trained and were only at chance using the automatic methods, the interpretation of this part of the results is limited. On the level of the five superordinate domains, the activity patterns were broadly in line with our a priori predictions (cf. <xref ref-type="table" rid="tbl1">Table 1</xref>). However, the motor imagery task recruited predominantly superior parietal areas, which have previously been shown to be important for movement planning (<xref ref-type="bibr" rid="c2">Aflalo et al., 2015</xref>), but are not always active in imagery tasks (for example <xref ref-type="bibr" rid="c35">Owen et al. (2006)</xref>). This also reflects the issue that while mental imagery tasks are easy to setup and integrate into the clinical routine, they have some natural limits regarding the localization of functions. In the case of the motor imagery task, one usually cannot map the primary motor cortex, where the execution of actual movements would be represented. While SMA and superior parietal areas are certainly also important for carrying out movements (<xref ref-type="bibr" rid="c12">Fontaine et al., 2002</xref>; <xref ref-type="bibr" rid="c2">Aflalo et al., 2015</xref>), it would thus be a mistake to use motor imagery as the only functional localizer in this domain. Despite this limitation of our paradigm, it is also conceivable that activity maps based on imagining complex movements could be a useful complement to simple real movement tasks, such as finger tapping. This is especially true since the organization of primary motor areas can be well approximated from brain structure alone, while this is not the case for movement planning (<xref ref-type="bibr" rid="c2">Aflalo et al., 2015</xref>). In contrast to our prediction, the face imagery task predominantly recruited parts of the default mode network instead of the core face processing areas (<xref ref-type="bibr" rid="c20">Haxby et al., 2000</xref>). This might reflect a strong involvement of autobiographical memory recall when thinking of known faces (<xref ref-type="bibr" rid="c14">Gobbini and Haxby, 2007</xref>). Although unexpected, these patterns were very stable across blocks and sufficiently different from the resting activity to allow for perfect accuracies when predicting the face blocks. Finally, the superior temporal activity in the verbal fluency task did most likely not correspond to Wernicke&#x2019;s area, but to a more inferior cluster in the superior temporal sulcus, as shown in previous production tasks (e.g. <xref ref-type="bibr" rid="c5">Branco et al. (2016)</xref>). It is also rather atypical that the peak of activity in a language production task is in temporal and not in inferior frontal areas (<xref ref-type="bibr" rid="c44">Woermann et al., 2003</xref>). Apart from that, the language and visuo-spatial conditions produced activity patterns that were very close to what would be expected if the tasks would be actually carried out, which makes these paradigms especially useful for clinical applications (<xref ref-type="bibr" rid="c44">Woermann et al., 2003</xref>; <xref ref-type="bibr" rid="c24">Jokeit et al., 2001</xref>). Another limitation of the present mental imagery task concerns the question how well activity patterns are comparable between individuals. When using external stimulation, every participant receives the same low-level inputs, but between-participant variance is still sizable (<xref ref-type="bibr" rid="c19">Haxby et al., 2011</xref>). Therefore, when using self-generated and hence potentially idiosyncratic mental imagery, even larger variation between individuals should be expected. Given that we collected data from only one person, the generalization of our results is particularly limited. However, we were able to make reasonable predictions about our participant&#x2019;s cognitive processes using independent data from NeuroSynth. The NeuroSynth data represents a different metric (posterior probabilities; cf. <xref ref-type="bibr" rid="c45">Yarkoni et al. (2011)</xref>), from different participants who performed different tasks on different scanners and were analyzed using different software and statistical methods. That our data still converged rather well with these meta-analytical information provides tentative support that on the scale of general neuropsychological domains, consistency between individuals is very high, even if using mental imagery. Furthermore, because no kind of training was performed to optimize the performance of the NeuroSynth approach, it might serve as a demonstration of &#x2018;ad hoc&#x2019; decoding. This immediacy of application might make it especially appealing in the clinical context, where there might be no time to collect and analyze training data for each patient. A crucial question regarding how the present results can inform clinical applications, is how well the present results can generalize from healthy participants to patients: While the block-wise analyses worked very well with a cognitively unimpaired and highly motivated participant, cognitive deficits, medication and a general tendency for increased movement artifacts (<xref ref-type="bibr" rid="c9">Dijk et al., 2012</xref>) will all contribute to altered or weaker signal in patient populations. Being able to collect healthy normative samples (<xref ref-type="bibr" rid="c10">Dubois and Adolphs, 2016</xref>) is one of the major advantages of fMRI over other methods used in presurgical planning (i.e. intracrianal EEG, Wada-testing). However, this is moot if the clinical data of actual patients cannot be reasonably collected and analyzed in the first place. Therefore, future studies are needed to show if the signal yield necessary for block-wise analyses is attainable when examining presurgical patients. While we outlined some important limitations above, we believe that the current study provides some valuable impulses for the clinical application of task-fMRI, including its use in presurgical planning:</p>
<sec id="s4a">
<title>Analysis of fMRI data can benefit from splitting a data-set into smaller subsets</title>
<p>If the patient has consistently preformed the task as required, splitting the fMRI run into smaller parts (ideally blocks) can increase the neuroradiologist&#x2019;s confidence in the resulting activity map. If the activity patterns of the patient are highly inconsistent across the run, the neuroradiologist might be able to retain some diagnostic information by re-analysing those subsets of the data which are most indicative of task compliance. Splitting the data can also reveal if a patient&#x2019;s activity pattern is atypical but stable, as was the case for our face condition. Here, we saw that although the patterns were not as expected, they were highly similar across blocks. Such analyses might allow to better decide if an inconclusive looking activity pattern is due to noise or is a veridical representation of an unexpected cognitive strategy the patient engaged in.</p>
</sec>
<sec id="s4b">
<title>Pattern analysis methods do not have to be &#x2018;black-box&#x2019;</title>
<p>The pattern analyses in the present study were all based on the notion of minimizing the sums of squared differences between two observations. While these methods certainly do not take advantage of all the information contained in the data, they are highly versatile and robust (<xref ref-type="bibr" rid="c22">Hilborn and Mangel, 1997</xref>), and work well for fMRI data (<xref ref-type="bibr" rid="c18">Haxby, 2001</xref>). With the rise of artificial intelligence methods in medical imaging (<xref ref-type="bibr" rid="c11">Esteva et al., 2017</xref>), there is growing concern that the decisions made by algorithms might be excellent but the reasoning behind them will remain impenetrable to a human (<xref ref-type="bibr" rid="c8">Castelvecchi, 2016</xref>). Therefore, it could prove beneficial to accompany methods of high sophistication with more transparent (&#x2018;glass box&#x2019;) analyses like the present ones.</p>
</sec>
<sec id="s4c">
<title>Localization and decoding of functions is complementary</title>
<p>While presurgical diagnostics are usually only concerned with brain mapping, the main benefit of decoding might be to better understand what exactly is being mapped. For example, in a language task, an activity pattern encompassing Broca&#x2019;s area, SMA, Wernicke&#x2019;s area and visual word-form area (VWFA) would allow for a relatively safe interpretation of lateralization, depending on whether this network of activation is localized in the left or right hemisphere. If, on the other hand, the activity pattern for the language task resembled a default mode network, one would conclude that the task was not performed at all and not use the map to determine the degree of lateralization. Between these two extreme cases, a whole continuum of prototypical vs. improper task performance will occur in clinical practice. For example, a language production task will pose different demands on working memory or executive functions, depending on how difficult a patient finds the task overall, or for a specific category. Knowing how much an activity map reflects these processes, which might be represented in neighboring frontal areas, but more bilaterally than language, could influence how strong a conclusion about lateralization of language one is willing to draw. Therefore, the localization of functions (knowing where things are) could be aided by quantifying what cognitive demands the task poses for each patient (knowing what is being mapped). If it would be possible to decode the content of each block (e.g. producing names of animals vs. names of tools in a verbal fluency task), this would allow for a very close monitoring of the patient&#x2019;s covert behavior. Therefore, such types of decoding could be a valuable substitute for the lack of behavioral output which currently limits the applicability of mental imagery tasks.</p>
</sec>
</sec>
<sec id="s5">
<title>Conclusion</title>
<p>The present study showed how brief periods of self-generated thought can be decoded regarding the superordinate neuropsychological domains involved. The categories of language production, motor imagination, visuo-spatial navigation, face processing, and task-free resting were reliably differentiated using basic similarity metrics. This was possible using both training data from the same participant as well as independent meta-analytical data from other studies, which allow for immediate decoding without prior training. Capitalizing on the non-invasive nature of fMRI, we showed how exploratory approaches towards collecting and analyzing fMRI data can provide new impulses regarding its application in the individual case.</p>
</sec>
<sec id="s6">
<title>Additional Information</title>
<sec id="s6a">
<title>Copyright</title>
<p>(C)2018 Wegrzyn et al. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original authors are credited.</p>
</sec>
<sec id="s7" sec-type="availability">
<title>Data Availability</title>
<p>Functional MRI data are available on <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5951563.v1">https://doi.org/10.6084/m9.figshare.5951563.v1</ext-link>. Code to reproduce the results and figures, as well as to recreate this manuscript, can be found on github.com/mwegrzyn/thoughtExperiment.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Abraham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pedregosa</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Eickenberg</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Gervais</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Mueller</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kossaifi</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name> (<year>2014</year>). <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Frontiers in Neuroinformatics</source>, <fpage>8</fpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Aflalo</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kellis</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Klaes</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Shi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Pejsa</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Shanfield</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hayes-Jackson</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Aisen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Heck</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name> (<year>2015</year>). <article-title>Decoding motor imagery from the posterior parietal cortex of a tetraplegic human</article-title>. <source>Science</source>, <volume>348</volume>(<issue>6237</issue>):<fpage>906</fpage>&#x2013;<lpage>910</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Ashburner</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name> (<year>2005</year>). <article-title>Unified segmentation</article-title>. <source>NeuroImage</source>, <volume>26</volume>(<issue>3</issue>):<fpage>839</fpage>&#x2013;<lpage>851</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Boly</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Coleman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hampshire</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bor</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Moonen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Maquet</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pickard</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Laureys</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Owen</surname>, <given-names>A.</given-names></string-name> (<year>2007</year>). <article-title>When thoughts become action: An fMRI paradigm to study volitional brain activity in non-communicative brain injured patients</article-title>. <source>NeuroImage</source>, <volume>36</volume>(<issue>3</issue>):<fpage>979</fpage>&#x2013;<lpage>992</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Branco</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Seixas</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Deprez</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kovacs</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Peeters</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Castro</surname>, <given-names>S. L.</given-names></string-name>, and <string-name><surname>Sunaert</surname>, <given-names>S.</given-names></string-name> (<year>2016</year>). <article-title>Resting-state functional magnetic resonance imaging for language preoperative planning</article-title>. <source>Frontiers in Human Neuroscience</source>, <fpage>10</fpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="book"><string-name><surname>Broca</surname>, <given-names>P.</given-names></string-name> (<year>1861</year>). <chapter-title>Remarks on the seat of the faculty of articulated language, following an observation of aphemia (loss of speech); translation by christopher d. green</chapter-title>. In <source>Bulletin de la Soci&#x00E9;t&#x00E9; Anatomique</source>, <volume>6</volume>, <fpage>330</fpage>&#x2013;<lpage>357</lpage>. <publisher-name>Christopher D. Green</publisher-name>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="book"><string-name><surname>Bunzl</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hanson</surname>, <given-names>S. J.</given-names></string-name>, and <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2010</year>). <chapter-title>An exchange about localism</chapter-title>. In <source>Foundational Issues in Human Brain Mapping</source>, pages <fpage>49</fpage>&#x2013;<lpage>54</lpage>. <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Castelvecchi</surname>, <given-names>D.</given-names></string-name> (<year>2016</year>). <article-title>Can we open the black box of AI?</article-title> <source>Nature</source>, <volume>538</volume>(<issue>7623</issue>):<fpage>20</fpage>&#x2013;<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Dijk</surname>, <given-names>K. R. V.</given-names></string-name>, <string-name><surname>Sabuncu</surname>, <given-names>M. R.</given-names></string-name>, and <string-name><surname>Buckner</surname>, <given-names>R. L.</given-names></string-name> (<year>2012</year>). <article-title>The influence of head motion on intrinsic functional connectivity MRI</article-title>. <source>NeuroImage</source>, <volume>59</volume>(<issue>1</issue>):<fpage>431</fpage>&#x2013;<lpage>438</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Dubois</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Adolphs</surname>, <given-names>R.</given-names></string-name> (<year>2016</year>). <article-title>Building a science of individual differences from fMRI</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>20</volume>(<issue>6</issue>):<fpage>425</fpage>&#x2013;<lpage>443</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Esteva</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kuprel</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Novoa</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Ko</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Swetter</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Blau</surname>, <given-names>H. M.</given-names></string-name>, and <string-name><surname>Thrun</surname>, <given-names>S.</given-names></string-name> (<year>2017</year>). <article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>. <source>Nature</source>, <volume>542</volume>(<issue>7639</issue>):<fpage>115</fpage>&#x2013;<lpage>118</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Fontaine</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Capelle</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Duffau</surname>, <given-names>H.</given-names></string-name> (<year>2002</year>). <article-title>Somatotopy of the supplementary motor area: Evidence from correlation of the extent of surgical resection with the clinical patterns of deficit</article-title>. <source>Neurosurgery</source>, <volume>50</volume>(<issue>2</issue>):<fpage>297</fpage>&#x2013;<lpage>305</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="other"><string-name><surname>Fox</surname>, <given-names>M. D.</given-names></string-name> (<year>2010</year>). <chapter-title>Clinical applications of resting state functional connectivity</chapter-title>. <source>Frontiers in Systems Neuroscience</source>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Gobbini</surname>, <given-names>M. I.</given-names></string-name> and <string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name> (<year>2007</year>). <article-title>Neural systems for recognition of familiar faces</article-title>. <source>Neuropsychologia</source>, <volume>45</volume>(<issue>1</issue>):<fpage>32</fpage>&#x2013;<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Gordon</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name>, <string-name><surname>Gilmore</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Newbold</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Greene</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Berg</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Ortega</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hoyt-Drazen</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gratton</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hampton</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Coalson</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>McDermott</surname>, <given-names>K. B.</given-names></string-name>, <string-name><surname>Shimony</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>S. M.</given-names></string-name>, and <string-name><surname>Dosenbach</surname>, <given-names>N. U.</given-names></string-name> (<year>2017</year>). <article-title>Precision functional mapping of individual human brains</article-title>. <source>Neuron</source>, <volume>95</volume>(<issue>4</issue>):<fpage>791</fpage>&#x2013;<lpage>807.e7</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Storkey</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Bastin</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Whittle</surname>, <given-names>I.</given-names></string-name>, and <string-name><surname>Pernet</surname>, <given-names>C.</given-names></string-name> (<year>2013</year>). <article-title>Single subject fMRI test&#x2013;retest reliability metrics and confounding factors</article-title>. <source>NeuroImage</source>, <volume>69</volume>:<fpage>231</fpage>&#x2013;<lpage>243</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>H&#x00E5;berg</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kvistad</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Unsg&#x00E5;rd</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Haraldseth</surname>, <given-names>O.</given-names></string-name> (<year>2004</year>). <article-title>Preoperative blood oxygen level-dependent functional magnetic resonance imaging in patients with primary brain tumors: Clinical application and outcome</article-title>. <source>Neurosurgery</source>, <volume>54</volume>(<issue>4</issue>):<fpage>902</fpage>&#x2013;<lpage>915</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name> (<year>2001</year>). <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>. <source>Science</source>, <volume>293</volume>(<issue>5539</issue>):<fpage>2425</fpage>&#x2013;<lpage>2430</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name>, <string-name><surname>Guntupalli</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Connolly</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Halchenko</surname>, <given-names>Y. O.</given-names></string-name>, <string-name><surname>Conroy</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Gobbini</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Hanke</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Ramadge</surname>, <given-names>P. J.</given-names></string-name> (<year>2011</year>). <article-title>A common, high-dimensional model of the representational space in human ventral temporal cortex</article-title>. <source>Neuron</source>, <volume>72</volume>(<issue>2</issue>):<fpage>404</fpage>&#x2013;<lpage>416</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name>, <string-name><surname>Hoffman</surname>, <given-names>E. A.</given-names></string-name>, and <string-name><surname>Gobbini</surname>, <given-names>M.</given-names></string-name> (<year>2000</year>). <article-title>The distributed human neural system for face perception</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>4</volume>(<issue>6</issue>):<fpage>223</fpage>&#x2013;<lpage>233</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Haynes</surname>, <given-names>J.-D.</given-names></string-name> and <string-name><surname>Rees</surname>, <given-names>G.</given-names></string-name> (<year>2006</year>). <article-title>Decoding mental states from brain activity in humans</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>7</volume>(<issue>7</issue>):<fpage>523</fpage>&#x2013;<lpage>534</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="book"><string-name><surname>Hilborn</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Mangel</surname>, <given-names>M.</given-names></string-name> (<year>1997</year>). <source>The ecological detective. confronting models with data</source>. volume <volume>77</volume>. <publisher-name>Princeton University Press</publisher-name>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Huth</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>de Heer</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Theunissen</surname>, <given-names>F. E.</given-names></string-name>, and <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name> (<year>2016</year>). <article-title>Natural speech reveals the semantic maps that tile human cerebral cortex</article-title>. <source>Nature</source>, <volume>532</volume>(<issue>7600</issue>):<fpage>453</fpage>&#x2013;<lpage>458</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Jokeit</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Okujava</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Woermann</surname>, <given-names>F. G.</given-names></string-name> (<year>2001</year>). <article-title>Memory fMRI lateralizes temporal lobe epilepsy</article-title>. <source>Neurology</source>, <volume>57</volume>(<issue>10</issue>):<fpage>1786</fpage>&#x2013;<lpage>1793</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name> (<year>2017</year>). <article-title>The quest for the FFA and where it led</article-title>. <source>The Journal of Neuroscience</source>, <volume>37</volume>(<issue>5</issue>):<fpage>1056</fpage>&#x2013;<lpage>1061</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Koelsch</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Fritz</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Schulze</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Alsop</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Schlaug</surname>, <given-names>G.</given-names></string-name> (<year>2005</year>). <article-title>Adults and children processing music: An fMRI study</article-title>. <source>NeuroImage</source>, <volume>25</volume>(<issue>4</issue>):<fpage>1068</fpage>&#x2013;<lpage>1076</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ruff</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Bodurka</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Esteky</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Tanaka</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Bandettini</surname>, <given-names>P. A.</given-names></string-name> (<year>2008</year>). <article-title>Matching categorical object representations in inferior temporal cortex of man and monkey</article-title>. <source>Neuron</source>, <volume>60</volume>(<issue>6</issue>):<fpage>1126</fpage>&#x2013;<lpage>1141</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name>, <string-name><surname>Gordon</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Adeyemo</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Joo</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>M.-Y.</given-names></string-name>, <string-name><surname>Gilmore</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>McDermott</surname>, <given-names>K. B.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Dosenbach</surname>, <given-names>N. U.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, and <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name> (<year>2015</year>). <article-title>Functional system and areal organization of a highly sampled individual human brain</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>3</issue>):<fpage>657</fpage>&#x2013;<lpage>670</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="book"><string-name><surname>Liberman</surname>, <given-names>M.</given-names></string-name> (<year>2006</year>). <source>Reproducible research and the common task method. technical report</source>. <publisher-name>Simons Foundation Frontiers of Data Science Lecture</publisher-name>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>McGonigle</surname>, <given-names>D. J.</given-names></string-name> (<year>2012</year>). <article-title>Test&#x2013;retest reliability in fMRI: Or how i learned to stop worrying and love the variability</article-title>. <source>NeuroImage</source>, <volume>62</volume>(<issue>2</issue>):<fpage>1116</fpage>&#x2013;<lpage>1120</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Mummery</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Patterson</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hodges</surname>, <given-names>J. R.</given-names></string-name>, and <string-name><surname>Price</surname>, <given-names>C. J.</given-names></string-name> (<year>1998</year>). <article-title>Functional neuroanatomy of the semantic system: Divisible by what?</article-title> <source>Journal of Cognitive Neuroscience</source>, <volume>10</volume>(<issue>6</issue>):<fpage>766</fpage>&#x2013;<lpage>777</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Nair</surname>, <given-names>C. R.</given-names></string-name> (<year>1967</year>). <article-title>Sequences balanced for pairs of residual effects</article-title>. <source>Journal of the American Statistical Association</source>, <volume>62</volume>(<issue>317</issue>):<fpage>205</fpage>&#x2013;<lpage>225</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Nishimoto</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name> (<year>2011</year>). <article-title>Encoding and decoding in fMRI</article-title>. <source>NeuroImage</source>, <volume>56</volume>(<issue>2</issue>):<fpage>400</fpage>&#x2013;<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Craven</surname></string-name> and <string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name> (<year>2000</year>). <article-title>Mental imagery of faces and places activates corresponding stimulus-specific brain regions</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>12</volume>(<issue>6</issue>):<fpage>1013</fpage>&#x2013;<lpage>1023</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Owen</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Coleman</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Boly</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>M. H.</given-names></string-name>, <string-name><surname>Laureys</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Pickard</surname>, <given-names>J. D.</given-names></string-name> (<year>2006</year>). <article-title>Detecting awareness in the vegetative state</article-title>. <source>Science</source>, <volume>313</volume>(<issue>5792</issue>):<fpage>1402</fpage>&#x2013;<lpage>1402</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Parvizi</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jacques</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Foster</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Withoft</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Rangarajan</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Weiner</surname>, <given-names>K. S.</given-names></string-name>, and <string-name><surname>Grill-Spector</surname>, <given-names>K.</given-names></string-name> (<year>2012</year>). <article-title>Electrical stimulation of human fusiform face-selective regions distorts face perception</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>43</issue>):<fpage>14915</fpage>&#x2013;<lpage>14920</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Pedregosa</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Michel</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Grisel</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Blondel</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Prettenhofer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Weiss</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Dubourg</surname>, <given-names>V.</given-names></string-name>, <etal>et al.</etal> (<year>2011</year>). <article-title>Scikit-learn: Machine learning in python</article-title>. <source>Journal of machine learning research</source>, <volume>12</volume>(Oct):<fpage>2825</fpage>&#x2013;<lpage>2830</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R.</given-names></string-name> (<year>2006</year>). <article-title>Can cognitive processes be inferred from neuroimaging data?</article-title> <source>Trends in Cognitive Sciences</source>, <volume>10</volume>(<issue>2</issue>):<fpage>59</fpage>&#x2013;<lpage>63</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2017</year>). <article-title>Precision neuroscience: Dense sampling of individual brains</article-title>. <source>Neuron</source>, <volume>95</volume>(<issue>4</issue>):<fpage>727</fpage>&#x2013;<lpage>729</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Satterthwaite</surname>, <given-names>T. D.</given-names></string-name> and <string-name><surname>Davatzikos</surname>, <given-names>C.</given-names></string-name> (<year>2015</year>). <article-title>Towards an individualized delineation of functional neuroanatomy</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>3</issue>):<fpage>471</fpage>&#x2013;<lpage>473</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Sorger</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Reithler</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Dahmen</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Goebel</surname>, <given-names>R.</given-names></string-name> (<year>2012</year>). <article-title>A real-time fMRI-based spelling device immediately enabling robust motor-independent communication</article-title>. <source>Current Biology</source>, <volume>22</volume>(<issue>14</issue>):<fpage>1333</fpage>&#x2013;<lpage>1338</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="book"><string-name><surname>Stippich</surname>, <given-names>C.</given-names></string-name> (<year>2015</year>). <chapter-title>Introduction to presurgical functional MRI</chapter-title>. In <source>Clinical Functional MRI</source>, pages <fpage>1</fpage>&#x2013;<lpage>7</lpage>. <publisher-name>Springer Berlin Heidelberg</publisher-name>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Szaflarski</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Gloss</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Binder</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Gaillard</surname>, <given-names>W. D.</given-names></string-name>, <string-name><surname>Golby</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Holland</surname>, <given-names>S. K.</given-names></string-name>, <string-name><surname>Ojemann</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Spencer</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Swanson</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>French</surname>, <given-names>J. A.</given-names></string-name>, and <string-name><surname>Theodore</surname>, <given-names>W. H.</given-names></string-name> (<year>2017</year>). <article-title>Practice guideline summary: Use of fMRI in the presurgical evaluation of patients with epilepsy</article-title>. <source>Neurology</source>, <volume>88</volume>(<issue>4</issue>):<fpage>395</fpage>&#x2013;<lpage>402</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Woermann</surname>, <given-names>F. G.</given-names></string-name>, <string-name><surname>Jokeit</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Luerding</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Freitag</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Guertler</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Okujava</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wolf</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Tuxhorn</surname>, <given-names>I.</given-names></string-name>, and <string-name><surname>Ebner</surname>, <given-names>A.</given-names></string-name> (<year>2003</year>). <article-title>Language lateralization by wada test and fMRI in 100 patients with epilepsy</article-title>. <source>Neurology</source>, <volume>61</volume>(<issue>5</issue>):<fpage>699</fpage>&#x2013;<lpage>701</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Essen</surname>, <given-names>D. C. V.</given-names></string-name>, and <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name> (<year>2011</year>). <article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title>. <source>Nature Methods</source>, <volume>8</volume>(<issue>8</issue>):<fpage>665</fpage>&#x2013;<lpage>670</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Zatorre</surname>, <given-names>R. J.</given-names></string-name> and <string-name><surname>Halpern</surname>, <given-names>A. R.</given-names></string-name> (<year>2005</year>). <article-title>Mental concerts: Musical imagery and auditory cortex</article-title>. <source>Neuron</source>, <volume>47</volume>(<issue>1</issue>):<fpage>9</fpage>&#x2013;<lpage>12</lpage>.</mixed-citation></ref>
</ref-list></back>
</article>