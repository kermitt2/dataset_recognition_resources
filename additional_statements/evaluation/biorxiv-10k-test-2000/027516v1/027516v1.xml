<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/027516</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Mixed Effects Models to Find Differences in Multi-Subject Functional Connectivity</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Narayan</surname>
<given-names>Manjari</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Allen</surname>
<given-names>Genevera I.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1">
<label>1</label><institution>Department of Electrical and Computer Engineering,</institution>
</aff>
<aff id="a2">
<label>2</label><institution>Department of Statistics, Rice University, Houston, TX</institution>, <country>USA</country>
</aff>
<aff id="a3">
<label>3</label><institution>Jan and Dan Duncan Neurological Research Institute, Houston, TX</institution>, <country>USA</country>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor1">
<label>&#x002A;</label>Correspondence: Manjari Narayan Department of Electrical and Computer Engineering, Rice University, 6100 Main St, Houston, TX, 77005, USA, <email>manjari.narayan@gmail.com</email>
</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2015</year>
</pub-date>
<elocation-id>027516</elocation-id>
<history>
<date date-type="received">
<day>23</day>
<month>9</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>9</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2015, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2015</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="027516.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>Many complex brain disorders such as autism spectrum disorders exhibit a wide range of symptoms and disability. To understand how brain communication is impaired in such conditions, functional connectivity studies seek to understand individual differences in brain network structure in terms of covariates that measure symptom severity. In practice, however, functional connectivity is not observed but estimated from complex and noisy neural activity measurements. Imperfect subject network estimates can compromise subsequent efforts to detect covariate effects on network structure. We address this problem in the case of Gaussian graphical models of functional connectivity, by proposing novel two-level models that treat both subject level networks and population level covariate effects as unknown parameters. To account for imperfectly estimated subject level networks when fitting these models, we propose two related approaches R<sup>2</sup> &#x0026; R<sup>3</sup> based on resampling, random adaptive penalization and random effects test statistics. Simulation studies using realistic graph structures reveal that R<sup>2</sup> and R<sup>3</sup> have superior statistical power to detect covariate effects compared to existing approaches, particularly when the number of within subject observations is comparable to the size of subject networks. Using our novel models and methods to study parts of the ABIDE dataset, we find evidence of hypoconnectivity associated with symptom severity in Autism spectrum disorders, in frontoparietal and limbic systems as well as in anterior and posterior cingulate cortices.</p>
</abstract>
<counts>
<page-count count="32"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><label>1</label><title>INTRODUCTION</title>
<p>One of the goals of neuroimaging studies of intrinsic or &#x201C;resting state&#x201D; brain activity, is to discover specific and stable imaging based biomarkers or phenotypes of neuropsychiatric and neurological disorders. Typically, resting state studies seek to infer <italic>functional connectivity</italic> or functional relationships between distinct brain regions from observed neurophysiological activity. Advances in resting state studies using fMRI [<xref ref-type="bibr" rid="c20"><bold>Bullmore</bold>, 2012</xref>; <xref ref-type="bibr" rid="c64"><bold>Menon</bold>, 2011</xref>; <xref ref-type="bibr" rid="c29"><bold>Craddock et al.</bold>, 2013</xref>; <xref ref-type="bibr" rid="c84"><bold>Smith et al.</bold>, 2013</xref>] suggest that functional connectivity could yield neuroimaging biomarkers for diagnosis and personalized treatment for a wide range of disorders.</p>
<p>For instance, many studies have found differences either in individual functional connections or in overall patterns of connectivity in Autism Spectrum Disorders [<xref ref-type="bibr" rid="c89"><bold>Uddin</bold>, 2014</xref>; <xref ref-type="bibr" rid="c30"><bold>Di Martino et al.</bold>, 2014a</xref>], Alzheimer&#x2019;s [<xref ref-type="bibr" rid="c18"><bold>Buckner et al.</bold>, 2009</xref>; <xref ref-type="bibr" rid="c86"><bold>Tam et al.</bold>, 2014</xref>], Depression [<xref ref-type="bibr" rid="c87"><bold>Tao et al.</bold>, 2013</xref>; <xref ref-type="bibr" rid="c59"><bold>Lui et al.</bold>, 2014</xref>; <xref ref-type="bibr" rid="c45"><bold>Kaiser et al.</bold>, 2015</xref>] and others [<xref ref-type="bibr" rid="c61"><bold>Meda et al.</bold>, 2012</xref>; <xref ref-type="bibr" rid="c93"><bold>van den Heuvel et al.</bold>, 2013</xref>; <xref ref-type="bibr" rid="c69"><bold>Palaniyappan et al.</bold>, 2013</xref>]. However, simple group level differences between two distinct samples are challenging to interpret in many disorders. Autism, for example, is a diagnostic label that masks many diverse clinical symptoms [<xref ref-type="bibr" rid="c55"><bold>Lenroot and Yeung</bold>, 2013</xref>; <xref ref-type="bibr" rid="c44"><bold>Insel</bold>, 2014</xref>]. Thus, the biological relevance of group level differences in network structure between Autism and healthy populations is unclear for individual subjects. One solution to find more meaningful differences in network structure is to study whether behavioral and affective symptoms measured by cognitive scores are associated with variations in individual functional networks. This paper offers a novel and rigorous statistical framework to find and test such covariate effects on functional connectivity metrics, when functional connectivity is defined using Gaussian graphical models.</p>
<p>Functional connectivity refers to latent relationships that cannot be directly observed via any modality of functional neuroimaging. Instead, it must be estimated from observations of neurophysiological activity. In fMRI studies, we first observe changes in the BOLD response over time either across thousands of voxels or over hundreds of brain regions, defined anatomically or functionally. Then depending on the specific statistical definition for functional connectivity, we estimate a functional connectivity network per subject using within-subject BOLD observations. For example, in a pairwise correlation model of functional connectivity, if the mean time-series of two brain regions are correlated then they are functionally connected. Thus, one popular approach to estimate functional connectivity is to compute sample correlations between every pair of brain regions. An increasingly popular alternative is to use Gaussian graphical models (GGMs) based on partial correlations to define functional connectivity. Here, if two brain regions are partially correlated, that is if the mean time-series of two brain regions remain correlated after regressing out the time-series of other brain regions, then they are functionally connected. For multivariate normal data, a zero partial correlation between two brain regions is equivalent to independence between the activity of two brain regions conditional on the activity of all other intermediate brain regions. Thus, GGMs eliminate indirect connections between regions provided by pairwise correlations and are increasingly popular in neuroimaging [<xref ref-type="bibr" rid="c60"><bold>Marrelec et al</bold>., 2006</xref>; <xref ref-type="bibr" rid="c83"><bold>Smith et al</bold>., 2011</xref>; <xref ref-type="bibr" rid="c95"><bold>Varoquaux et al</bold>., 2012</xref>; <xref ref-type="bibr" rid="c29"><bold>Craddock et al</bold>., 2013</xref>]. Consequently, employing GGMs for functional connectivity enables us to discover network differences that implicate nodes and edges directly involved in producing clinical symptoms and provide stronger insights into network structures truly involved in the disease mechanism. For the rest of this paper, we define functional connectivity in terms of GGMs and discuss approaches to conducting inference on network metrics for such network models.</p>
<p>The functional connectivity of a single experimental unit or subject is rarely the final object of interest. Rather, most neuroimaging studies [<xref ref-type="bibr" rid="c22"><bold>Bullmore and Sporns</bold>, 2012</xref>; <xref ref-type="bibr" rid="c104"><bold>Zuo et al</bold>., 2012</xref>; <xref ref-type="bibr" rid="c20"><bold>Bullmore</bold>, 2012</xref>] are interested in identifying network biomarkers, or broader patterns of functional connectivity shared across individuals who belong to some distinct population or display some clinical phenotype. A popular approach [<xref ref-type="bibr" rid="c21"><bold>Bullmore and Sporns</bold>, 2009</xref>] to find such network biomarkers is through topological properties of network structure. Common properties or metrics either measure specialization of network components into functionally homogenous modules, or measure how influential brain regions integrate information across distinct network components. However, recall that functional connectivity in individual subjects is unknown and unobserved. Consequently, many multi-subject fcMRI studies first estimate functional connectivity for every subject and then assuming these subject networks are fixed and known, compute topological metrics of these networks using the Brain Connectivity Toolbox [<xref ref-type="bibr" rid="c74"><bold>Rubinov and Sporns</bold>, 2010</xref>]. Finally, they compare and contrast these estimated networks or estimated network metrics to infer group level network characteristics. Typical neuroimaging studies that seek to detect covariate effects on network structure [<xref ref-type="bibr" rid="c40"><bold>Hahamy et al</bold>., 2015</xref>; <xref ref-type="bibr" rid="c97"><bold>Warren et al</bold>., 2014</xref>] conduct a single level regression with network metrics as the response and cognitive scores as the covariate, and subsequently use standard F-tests for covariate testing. New methods to conduct such network inference either emphasize novel topological metrics [<xref ref-type="bibr" rid="c92"><bold>van den Heuvel and Sporns</bold>, 2011</xref>; <xref ref-type="bibr" rid="c5"><bold>Alexander-Bloch et al.</bold>, 2012</xref>] or novel approaches to study covariate effects for known networks for complex experimental designs with longitudinal observations or multiple experimental conditions [<xref ref-type="bibr" rid="c82"><bold>Simpson et al</bold>., 2013</xref>; <xref ref-type="bibr" rid="c48"><bold>Kim et al</bold>., 2014</xref>; <xref ref-type="bibr" rid="c37"><bold>Ginestet et al</bold>., 2014</xref>]. However, these existing approaches assume estimated functional networks are perfectly known quantities. In contrast, we seek to explicitly investigate the consequences of using estimated, and often imperfectly estimated, functional networks and their corresponding network metrics on subsequent inference for covariate effects.</p>
<p>Before considering the consequences of using estimated networks, one might ask the question why individual network estimates might be unreliable to begin with. Statistical theory informs us that estimated networks can be unreliable in two possible ways. First, high dimensional networks with a large number of nodes estimated from a limited number of fMRI observations in a session possess substantial sampling variability [<xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>., 2015</xref>; <xref ref-type="bibr" rid="c12"><bold>Bickel and Levina</bold>, 2008</xref>; <xref ref-type="bibr" rid="c73"><bold>Rothman et al</bold>., 2008</xref>; <xref ref-type="bibr" rid="c72"><bold>Ravikumar et al</bold>., 2011</xref>]. Second, when assuming sparsity in the network structure in the form of thresholded or penalized network estimates to overcome high dimensionality, we often obtain biased network estimates in the form of false positive or false negative edges [<xref ref-type="bibr" rid="c72"><bold>Ravikumar et al</bold>., 2011</xref>]. Such errors in estimating networks are particularly exacerbated [<xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>., 2015</xref>] when networks are well connected with modest degrees, as is the case in neuroimaging. Additionally, empirical evidence from neuroimaging studies also suggest that sample correlation based estimates of individual resting state networks are unreliable. For instance test re-test studies [<xref ref-type="bibr" rid="c81"><bold>Shehzad et al</bold>., 2009</xref>; <xref ref-type="bibr" rid="c94"><bold>Van Dijk et al.</bold>, 2010</xref>; <xref ref-type="bibr" rid="c14"><bold>Braun et al</bold>., 2012</xref>] that measure intersession agreement of estimated functional networks within the same subject find that sample intra-class correlations vary between .3 &#x2212; .7, indicating non-negligible within subject variability. While we expect many sources of variation contribute to such inter-session variability within a subject including natural variations due to differences in internal cognitive states, recent work by <xref ref-type="bibr" rid="c13"><bold>Birn et al</bold>. [2013]</xref>; <xref ref-type="bibr" rid="c39"><bold>Hacker et al</bold>. [2013]</xref>; <xref ref-type="bibr" rid="c53"><bold>Laumann et al</bold>. [2015]</xref> suggests that sampling variability due to limited fMRI measurements play a significant role. These studies find that increasing the length of typical fMRI sessions from 5-10 minutes to 25 minutes substantially improves inter-session agreement of functional networks. Given the accumulating theoretical and empirical evidence of these methodological limitations, we assume that obtaining perfect estimates of individual networks is unlikely in typical fMRI studies. Instead, we seek to highlight the importance of accounting for imperfect estimates of functional networks in subsequent inferential analyses.</p>
<p>Failure to account for errors in estimating statistical networks reduces both generalizability and reproducibility of functional connectivity studies. Statistical tests that compare functional networks but do not account for potentially unreliable network estimates lack either statistical power or type I error control or both. For instance, <xref ref-type="bibr" rid="c67"><bold>Narayan and Allen</bold> [2013]</xref>; <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref> investigate the impact of using estimated networks when testing for two-sample differences in edge presence or absence between groups. When individual subject graphical models cannot be estimated perfectly, <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref> show that standard two-sample test statistics are both biased and overoptimistic, resulting in poor statistical power and type I error control. In a similar spirit, this paper considers the impact of using estimated networks to detect relationships between any covariates and individual variations in functional connectivity.</p>
<p>The paper is organized as follows. In <xref ref-type="sec" rid="s2">Section 2</xref> we provide new statistical models that explicitly link subject level neurophysiological data to population level covariate effects for network metrics of interest and provide new statistical algorithms and test statistics using resampling and random penalization for testing covariate effects. While the models and methods we propose can detect covariate effects on many well behaved network metrics [<xref ref-type="bibr" rid="c6"><bold>Balachandran et al</bold>., 2013</xref>] at the edge level [<xref ref-type="bibr" rid="c88"><bold>Tomson et al</bold>., 2013</xref>], node level [<xref ref-type="bibr" rid="c18"><bold>Buckner et al</bold>., 2009</xref>; <xref ref-type="bibr" rid="c104"><bold>Zuo et al</bold>., 2012</xref>] and community level [<xref ref-type="bibr" rid="c88"><bold>Tomson et al</bold>., 2013</xref>; <xref ref-type="bibr" rid="c5"><bold>Alexander-Bloch et al.</bold>, 2012</xref>], we investigate the benefits of our methods to discover covariate effects on connection density. Using realistic simulations of graph structure for GGMs in <xref ref-type="sec" rid="s3">Section 3</xref>, we demonstrate our proposed resampling framework substantially improves statistical power over existing approaches, particularly for typical sample size regimes in fMRI studies. Finally, in <xref ref-type="sec" rid="s4">Section 4</xref> we demonstrate that our proposed methods can detect biologically relevant signals in a resting state fMRI dataset for Autism Spectrum Disorders.</p></sec>
<sec id="s2"><label>2</label><title>MODELS AND METHODS</title>
<p>We seek new methods to detect covariate effects when populations of functional networks are unknown. To achieve this, we first need statistical models that describe how each measurement of brain activity denoted by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline1.gif"/></alternatives></inline-formula> arises from unknown functional brain network with <italic>p</italic> nodes in the <italic>i</italic><sup>th</sup> subject and how individual variations in a population of brain networks are related to some population level mean <italic>&#x03BC;</italic>. Thus, our two-level models take the following form,
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="027516_eqn1.gif"/></alternatives></disp-formula> where <italic>u</italic>(&#x00B7;) denotes some function or network metric over the brain network. Suppose that we denote any network metric in the <italic>i</italic><sup>th</sup> subject as <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, then the population mean is given by <italic>E</italic>(<italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>) &#x003D; <italic>g</italic>(<italic>&#x03BC;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>) and population variance is given by Var(<italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>) &#x003D; <italic>v</italic><sup>2</sup>. We assume that the effect of covariates on the network metrics takes the following form of a general linear model [<xref ref-type="bibr" rid="c80"><bold>Searle et al</bold>., 2009</xref>]</p>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="027516_eqn2.gif"/></alternatives></disp-formula>
<p>Here <italic>g</italic>(<italic>&#x03BC;</italic>) is a link function either reduces to <italic>g</italic>(<italic>&#x03BC;</italic>) &#x003D; <italic>&#x03BC;</italic> in linear models, or takes other forms such as the logit functon for discrete valued data; <bold><italic>X</italic></bold> is the n <italic>x</italic> &#x00D7; (<italic>q</italic> &#x002B; 1) matrix of the intercept and <italic>q</italic> covariates of interest with corresponding coefficients <italic>&#x03B2;</italic> &#x003D; (<italic>&#x03B2;</italic><sub>0</sub>, <italic>&#x03B2;</italic><sub>1</sub><italic>,&#x2026; &#x03B2;<sub>q</sub></italic>) while <italic>Z</italic> is the <italic>n</italic> &#x00D7; <italic>r</italic> matrix of nuisance covariates and corresponding regression coefficients <italic>&#x03B3;</italic>. <italic>X<sub>i</sub></italic> and <italic>Z<sub>i</sub></italic> denote the <italic>q</italic> dimensional explanatory covariate and <italic>r</italic> dimensional nuisance covariate for the <italic>i<sup>th</sup></italic> subject, respectively.</p>
<p>In this paper, we seek to test the hypothesis that explanatory covariates have a statistically significant covariate effect on network metrics. Here <italic>&#x03B2;</italic><sub>&#x005C;0</sub> denotes the coefficients for explanatory covariates. Thus, the null <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline2.gif"/></alternatives></inline-formula> and alternative hypothesis <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline3.gif"/></alternatives></inline-formula> are</p>
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="027516_eqn3.gif"/></alternatives></disp-formula>
<p>This section is organized as follows &#x2014; In <xref ref-type="sec" rid="s2a">Section 2.1</xref>, we begin by discussing the specific instances of the two-level models in (1) using Gaussian graphical models of functional connectivity. We show that our models are general since they can be employed to test any population level covariate effect and are applicable to any metrics that can be modeled using a general linear model (2).</p>
<p>Standard statistical analyses in neuroimaging studies estimate each level of these two level models separately. Thus, such approaches first estimate functional connectivity networks by fitting subject level models. However, they assume individual subject networks and their metrics are known when they fit the population level model and conduct inference on covariate effects. In <xref ref-type="sec" rid="s2b">Section 2.2</xref> we discuss how such statistical procedures that assume functional connectivity networks are known lose statistical power to detect covariate effects. To address this problem, we introduce two related methods that utilize resampling, random adaptive penalization, and random effects that we call, R<sup>2</sup> and R<sup>3</sup> in <xref ref-type="sec" rid="s2c">Section 2.3</xref>. These methods ameliorate potential biases and sampling variability in estimated network metrics, thus improving statistical power to detect covariate effects.</p>
<sec id="s2a"><label>2.1</label><title>TWO LEVEL MODELS FOR COVARIATE EFFECTS</title>
<p>We begin by studying the subject level model in (1) in greater detail. Recall that the vector <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline4.gif"/></alternatives></inline-formula> denotes BOLD observations or average BOLD observations within <italic>p</italic> regions of interest, at the <italic>j<sup>th</sup></italic> time point for the <italic>i<sup>th</sup></italic> subject. We assume <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline5.gif"/></alternatives></inline-formula> has a multivariate normal distribution,
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="027516_eqn4.gif"/></alternatives></disp-formula> where &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> denotes the inverse covariance or precision matrix, <italic>j</italic> &#x003D; 1,&#x2026; <italic>t,</italic> and <italic>i</italic> &#x003D; 1,&#x2026; <italic>n</italic>. Although fMRI observations are autocorrelated across time and thus dependent [<xref ref-type="bibr" rid="c100"><bold>Worsley et al</bold>., 2002</xref>; <xref ref-type="bibr" rid="c99"><bold>Woolrich et al</bold>., 2001</xref>], we assume that these observations can be made approximately independent via appropriate whitening procedures discussed in our case study in <xref ref-type="sec" rid="s4">Section 4</xref>.</p>
<p>Let <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline6.gif"/></alternatives></inline-formula> denote a Gaussian graphical model that consists of vertices <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline7.gif"/></alternatives></inline-formula> and edges <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline8.gif"/></alternatives></inline-formula>. Here, the presence of an edge <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline9.gif"/></alternatives></inline-formula> implies that the random variables <italic>Y<sub>k</sub></italic> and <italic>Y<sub>l</sub></italic> at nodes/vertices <italic>k</italic> and <italic>l</italic> are statistically dependent conditional on all the other vertices <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline10.gif"/></alternatives></inline-formula>. For multivariate normal distributions, a non-zero value in the (<italic>k</italic>, <italic>l</italic>) entry of the inverse covariance matrix &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> is equivalent to the conditional independence relatinoships, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline11.gif"/></alternatives></inline-formula>. Thus, we define functional connectivity networks where edges indicate <italic>direct</italic> relationships between two brain regions using the non-zero entries of &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. For a more thorough introduction to graphical models, we refer the reader to <xref ref-type="bibr" rid="c54"><bold>Lauritzen</bold> [1996]</xref>.</p>
<p>A network metric is simply a function of the adjacency matrix <italic>u</italic>(<italic>A</italic>). The adjacency matrix of each individual subject network is given by the support of the inverse covariance matrix <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline12.gif"/></alternatives></inline-formula>. Network metrics that measure topological structure of networks are widely used in neuroimaging [<xref ref-type="bibr" rid="c21"><bold>Bullmore and Sporns</bold>, 2009</xref>; <xref ref-type="bibr" rid="c74"><bold>Rubinov and Sporns</bold>, 2010</xref>]. While any of these network metrics can be incorporated into our two level models, we have found that many metrics originally proposed when studying a determinstic network are not suitable for covariate testing in the presence of individual variations in a population of networks. Recently, <xref ref-type="bibr" rid="c6"><bold>Balachandran et al</bold>. [2013]</xref> suggests that several discontinuous network metrics which include betweenness centrality, clustering coefficients and potentially many others are not suitable for inference. Thus, this paper focuses on well behaved topological metrics, namely density based metrics. Formally, the density or number of connections in a network <italic>A</italic> is given by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline13.gif"/></alternatives></inline-formula>. However, rather than defining density over the whole graph, the density can be restricted to a subnetwork (subnetwork density) or over a single node (node density or degree) or simply at the edge level (edge presence). At the node level, density is a simple measure of influence or centrality of a single brain region of interest [<xref ref-type="bibr" rid="c74"><bold>Rubinov and Sporns</bold>, 2010</xref>; <xref ref-type="bibr" rid="c71"><bold>Power et al</bold>., 2013</xref>]. At the subnetwork level, density is popularly used [<xref ref-type="bibr" rid="c41"><bold>Honey et al</bold>., 2007</xref>; <xref ref-type="bibr" rid="c21"><bold>Bullmore and Sporns</bold>, 2009</xref>] to measure an excess or deficit of long range connections either within or between groups of brain regions with a distinct functional purpose. While we investigate node and subnetwork density in this paper, alternative network metrics amenable to inference include binary metrics such as edge presence [<xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>., 2015</xref>; <xref ref-type="bibr" rid="c61"><bold>Meda et al</bold>., 2012</xref>] or co-modularity relationships between nodes [<xref ref-type="bibr" rid="c88"><bold>Tomson et al</bold>., 2013</xref>; <xref ref-type="bibr" rid="c7"><bold>Bassett et al</bold>., 2013</xref>].</p></sec>
<sec id="s2a1"><label>2.1.1</label><title>Population Model for Network Metrics</title>
<p>As described earlier, given the subject level model and a network metric of interest, we use a general linear model in (2) to describe the deterministic relationship between the population mean for the network metrics and various covariates of interest. Each individual network metric is given by <italic>u</italic>(<italic>A</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>) that we henceforth denote as <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. Depending on whether a network metric is continuous or binary valued, this general linear model takes the form of linear or logistic-linear models.</p>
<p>However, we also require a probability model to describe how a random sample of individual network metrics deviate from the population mean. When the network metric <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> is continuous valued, the link function in (2) reduces to the identity <italic>g</italic>(<italic>&#x03BC;</italic>) &#x003D; <italic>&#x03BC;</italic>. For network metrics <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> such as global, subnetwork or node density, we use the following linear model with normal errors,</p>
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="027516_eqn5.gif"/></alternatives></disp-formula>
<p>For metrics such as edge presence and co-modularity that take discrete binary values &#x007B;0, 1&#x007D;, a widely used link function [<xref ref-type="bibr" rid="c2"><bold>Agresti</bold>, 2002</xref>; <xref ref-type="bibr" rid="c98"><bold>Williams</bold>, 1982</xref>] for the general linear model (2) is the logit function. The resulting linear-logistic model requires an additional Bernoulli parameter <italic>&#x03C0;<sub>i</sub></italic>, the probability that network metric <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> &#x003D; 1, to account for discrete binary errors.</p>
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="027516_eqn6.gif"/></alternatives></disp-formula>
<p>For the remainder of this paper, we consider normal models for node and subnetwork density.</p></sec>
<sec id="s2b"><label>2.2</label><title>MOTIVATION FOR NEW TEST STATISTICS</title>
<p>To understand why new statistical methods are necessary to fit our two-level models, consider the our covariate testing problem (3) for node and subnetwork density. Suppose the subject level networks in (4) and corresponding metrics are known precisely for each subject. In this case, we employ standard least squares estimation with corresponding F-tests for linear regression to test our null hypothesis for covariate effects (3).</p>
<p>In practice however, not only is the covariate effect <italic>&#x03B2;</italic> unknown, the underlying graphical model &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> and the network metrics <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> are also unknown and are all estimated from data. In <xref ref-type="fig" rid="fig1">Figures 1a</xref> and 1b we contrast the ideal scenario where the population of networks and corresponding network metrics are exactly known with the practical scenario where these network metrics are estimated from data. (See <xref ref-type="sec" rid="s3a">Section 3.1</xref> for details on how we simulate data.) Applying a standard linear regression to known network metrics reveals an oracle estimate of the covariate effect (blue line). In contrast, when the standard approach described is applied to estimated network metrics (orange line), the size of the covariate effect is substantially reduced. However, by employing the R<sup>3</sup> approach (green line) that we introduce in the next section, we account for errors in estimating networks, thereby improving statistical power.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title><italic>Motivation for new statistical framework R</italic><sup>3</sup>.</title>
<p>Here, we simulate covariate effects on the metric of interest, namely the degree centrality or node density (left) and subnetwork density (right) with (<italic>p</italic> &#x003D; 50, <italic>n</italic> &#x003D; 20, <italic>t</italic> &#x003D; 100). We illustrate covariate effects in the ideal scenario where network metrics are known perfectly in blue. Unfortunately, in functional connectivity networks, statistical errors in estimating graphical models are inevitable and these propogate to estimates of network metrics. As a result, when we estimate node and subnetwork density for each subject and conduct tests for covariate effects using standard F-tests, we fail to see a clear relationship between metrics and covariate of interest (orange) using linear regression. This loss of statistical power occurs when standard test statistics assume that estimates of density are correct. In contrast, when we account for errors in graph estimation and selection using R<sup>3</sup> test statistics (green), we have greater statistical power to detect covariate effects on density metrics. Algorithmic details of the R<sup>3</sup> approaches can be found in <xref ref-type="sec" rid="s2">section 2</xref>.</p></caption>
<graphic xlink:href="027516_fig1.tif"/>
</fig>
<p>Two issues arise when we estimate network metrics from data. First, instead of true network metrics, <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, our estimated network metrics, <italic>&#x0169;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, are a function of observations <bold><italic>Y</italic></bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. Thus, each estimate, <italic>&#x0169;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, possesses additional sampling variability. However, since we only acquire one network estimate per subject, standard least squares estimation cannot account for this additional variability. Additionally graph selection errors in network estimation potentially bias network metric estimates. Previously, <xref ref-type="bibr" rid="c62"><bold>Meinshausen and B&#x00FC;hlmann</bold> [2006]</xref>; <xref ref-type="bibr" rid="c72"><bold>Ravikumar et al</bold>. [2011]</xref>; <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref> show that in finite sample settings where the number of independent observations <italic>t</italic> within a subject is comparable to the number of nodes <italic>p</italic>, we expect false positive and false negative edges in network estimates. Such graph selection errors increase with the complexity of the network structure, governed by factors such as the level of sparsity, maximum node degree as well as the location of edges in the network. Since functional connectivity networks are moderately dense and well connected with small world structure [<xref ref-type="bibr" rid="c1"><bold>Achard et al</bold>., 2006</xref>], edges in these networks might be selected incorrectly. Observe that in <xref rid="fig1" ref-type="fig">Figures 1a</xref> and <xref rid="fig1" ref-type="fig">1b</xref>, we obtain larger estimates of node and subnetwork density for individual networks where true node or subnetwork densities are small and the reverse for truly large node or subnetwork densities. As a result, individual variation in estimated metrics no longer reflects the true effect of the covariate, resulting in loss of statistical power. For a detailed overview of how selection errors in estimating network structure propagate to group level inferences, we refer the reader to <xref ref-type="sec" rid="s2">Section 2</xref> of <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref>.</p>
<p>To overcome these obstacles, we use resampling to empirically obtain the sampling variability of estimated network metrics, <italic>&#x0169;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, and propopage this uncertainty using mixed effects test statistics for the covariate effect <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline14.gif"/></alternatives></inline-formula>. Moreover, by aggregating network statistics across resamples and optionally incorporating adaptive penalization techniques, we sufficiently improve network estimates and corresponding network metrics to obtain more accurate estimates of the covariate effects.</p></sec>
<sec id="s2c"><label>2.3</label><title>PROCEDURE FOR TESTING COVARIATE EFFECTS</title>
<p>In order to improve statistical power, we propose a resampling framework that integrates network estimation with inference for fixed covariate effects at the population level. We provide two related procedures to test covariate effects &#x2013; R<sup>2</sup> that employs resampling and random effects test statistics, and R<sup>3</sup> that employs resampling (RS), random adaptive penalization (RAP) and random effect test statistics (RE). Intuitively, our algorithm consists of first obtaining initial estimates of the sparsity levels in individual subject networks. Then, to estimate the sampling variability of each subject network empirically, we resample within subject observations and re-estimate the networks of each subject. Additionally, in the case of R<sup>3</sup> we simultaneously apply random adaptive penalties when re-estimating the networks. Network metrics are computed on each of the resampled networks, giving us multiple pseudo-replicates of network metrics per subject. Finally, we model these resampled network statistics using simple mixed effects models to derive test statistics for population level covariate effects. After performing our procedure, one can use well known parametric or non-parametric approaches to obtain p-values and correct for multiplicity of test statistics when necessary. Thus our procedure consists of three components, graph estimation and selection, resampling and RAP, and covariate testing via mixed effects models. We discuss each of these ingredients separately before putting them together in Algorithm 1.</p>
<sec id="s2c1"><label>2.3.1</label><title>Graphical Model Estimation</title>
<p>Many approaches such as sparse regularized regression [<xref ref-type="bibr" rid="c62"><bold>Meinshausen and B&#x00FC;hlmann</bold>, 2006</xref>], sparse penalized maximum likelihood (ML) or the graphical lasso [<xref ref-type="bibr" rid="c102"><bold>Yuan and Lin</bold>, 2007</xref>; <xref ref-type="bibr" rid="c35"><bold>Friedman et al</bold>., 2008</xref>] and others [<xref ref-type="bibr" rid="c24"><bold>Cai et al</bold>., 2011</xref>; <xref ref-type="bibr" rid="c103"><bold>Zhou et al</bold>., 2011</xref>] can be used to estimate &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> in our subject level model (4). We use the QuIC solver [<xref ref-type="bibr" rid="c42"><bold>Hsieh et al</bold>., 2011</xref>, <xref ref-type="bibr" rid="c43">2013</xref>] to fit a weighted graphical lasso to obtain estimates of &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. <disp-formula id="eqn7">
<alternatives><graphic xlink:href="027516_eqn7.gif"/></alternatives></disp-formula> where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline15.gif"/></alternatives></inline-formula> is the empirical sample covariance, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline16.gif"/></alternatives></inline-formula>, and o denotes the Hadamard dot product. The term <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline17.gif"/></alternatives></inline-formula> is the <italic>&#x2113;</italic><sub>1</sub> penalty on the off-diagonals entries. Since the sample correlation rather than covariance is commonly used in neuroimaging, we employ sample correlation matrix, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline18.gif"/></alternatives></inline-formula>. The two are equivalent when <bold><italic>Y</italic></bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> has been centered and scaled. Given any estimate of the inverse covariance matrix <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline19.gif"/></alternatives></inline-formula>, the estimated adjacency matrix for each subject is thus given by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline20.gif"/></alternatives></inline-formula> and network statistics can be computed accordingly. For our R<sup>3</sup> procedure, we employ a symmetric weight matrix of penalties <bold>&#x039B;</bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> obtained by randomly perturbing an initial penalty parameter <italic>&#x03BB;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. For our R<sup>2</sup> this weight matrix <bold>&#x039B;</bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> reduces to a scalar value <italic>&#x03BB;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> for all off-diagonal entries, giving us the standard graphical lasso. In order to estimate these initial penalty parameters <italic>&#x03BB;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, we employ StARS [<xref ref-type="bibr" rid="c58"><bold>Liu et al</bold>., 2010</xref>], a model selection criterion that is asymptotically guaranteed to contain the true network, and works well with neuroimaging data.</p></sec>
<sec id="s2c2"><label>2.3.2</label><title>Resampling and Random Adaptive Penalization</title>
<p>Since network estimates depend on the underlying observations <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline21.gif"/></alternatives></inline-formula>, we employ resampling techniques to estimate the sampling variability of <italic>&#x0169;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. Recall that estimates of a network metric, <italic>&#x0169;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, are a function of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline22.gif"/></alternatives></inline-formula>. Unfortunately, closed form finite sample distributions for sparse penalized estimates of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline23.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c10"><bold>Berk et al</bold>., 2013</xref>] as well as sampling distributions of network metrics [<xref ref-type="bibr" rid="c6"><bold>Balachandran et al</bold>., 2013</xref>] are still an emerging area of research. Our approach is to build an empirical distribution of network statistics, where we perturb the data by sampling <italic>m</italic> out of <italic>t</italic> observations with replacement (bootstrap) [<xref ref-type="bibr" rid="c33"><bold>Efron and Tibshirani</bold>, 1993</xref>] or without replacement (subsampling) [<xref ref-type="bibr" rid="c70"><bold>Politis et al</bold>., 1999</xref>] and re-estimate the network metrics per resample. By aggregating network statistics across resamples within each subject [<xref ref-type="bibr" rid="c15"><bold>Breiman</bold>, 1996a</xref>], we gain the additional benefit of variance reduction [<xref ref-type="bibr" rid="c19"><bold>B&#x00FC;hlmann and Yu</bold>, 2002</xref>] for individual subject metrics. Many variations of resampling techniques exist to handle dependencies [<xref ref-type="bibr" rid="c51"><bold>Lahiri</bold>, 2013</xref>] in spatio-temporal data. Since we assume approximately independent observations, from here on we use the standard <italic>t</italic> out of <italic>t</italic> bootstrap for resampling.</p>
<p>For our method, R<sup>2</sup>, that only involves resampling, we obtain a bootstrapped network estimate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline24.gif"/></alternatives></inline-formula>, and a corresponding network metric <italic>&#x0169;</italic><sup>&#x002A;(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup> in Step 1 of our algorithm 1 for each of <italic>B</italic> &#x003D; 100 resamples. For our alternative procedure, R<sup>3</sup>, however, we not only use resampling, but simultaneously perturb the initial regularization parameters <italic>&#x03BB;</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> for every resample. This amounts to solving a weighted graphical lasso to re-estimate the network, where the weights are given by random adaptive penalties. Our motivation to use R<sup>3</sup> is based on previous work in the context of two sample tests for edge differences. <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref> show that random penalization significantly improved power over pure resampling to detect differential edges when the networks were moderately dense. Given this result, we sought to investigate the benefits of random penalization for more general network metrics. Intuitively, we anticipate that density based metrics beyond the edge level are immune to some graph selection errors. For instance, when false negatives are compensated by an equal number of false positive edges within the same node or subnetwork, node or subnetwork density values remain unchanged. However, graph selection errors that do not cancel each other out result in a net increase or decrease in density, thus contributing to loss of power. In these scenarios, we expect R<sup>3</sup> to offer additional statistical power to test covariate effects.</p>
<p>Whereas general network metrics, require global properties of the network structure be preserved, the standard randomized graphical lasso [<xref ref-type="bibr" rid="c63"><bold>Meinshausen and Buhlmann</bold>, 2010</xref>] penalizes every edge randomly such that topological properties of the network could be easily destroyed within each resample. Thus, we seek to randomly perturb selected models in a manner less destructive to network structure. To achieve this, we adaptively penalize [<xref ref-type="bibr" rid="c103"><bold>Zhou et al</bold>., 2011</xref>] entries of &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>. Strongly present edges are more likely to be true edges and should thus be penalized less, whereas weak edges are more likely to be false and should be penalized more. As long as we have a good initial estimate of where the true edges in the network are, we can improve network estimates by adaptively re-estimating the network, while simultaneously using random penalties to account for potential biases in the initial estimates. In order to obtain a reliable initial estimate of network structure, we take advantage of the notion of stability as a measure of confidence popularized by <xref ref-type="bibr" rid="c16"><bold>Breiman</bold> [1996b]</xref>; <xref ref-type="bibr" rid="c63"><bold>Meinshausen and Buhlmann</bold> [2010]</xref>. Here the stability of an edge within a network across many resamples measures how strongly an is edge present in the network. When an edge belongs to the true network with high stability we randomly decrease the associated penalty by a constant <italic>&#x03BA;</italic>. Conversely, we randomly increase the penalty by <italic>&#x03BA;</italic> for an edge with low stability. Similar to <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref>, we fix the constant <italic>&#x03BA;</italic> to <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline25.gif"/></alternatives></inline-formula>. Here <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline26.gif"/></alternatives></inline-formula> is the regularization parameter that results in the all zero graph for a subject. We call this approach random adaptive penalization (RAP) and is similar in spirit to the adaptive random penalties employed by <xref ref-type="bibr" rid="c96"><bold>Wang et al</bold>. [2011]</xref> in the context of the lasso.</p>
<p>Since, random adaptive penalization depends on an initial estimate of the stability of every edge in the network, we take advantage of the basic resampling step in algorithm 1 to obtain a stability score matrix <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline27.gif"/></alternatives></inline-formula> for each subject. The entries of this matrix provide a proportion that takes values in the interval (0, 1). Once we have the stability scores, we consider an additional set of <italic>B</italic> &#x003D; 100 resamples to implement RAP. Thus in step 2 of algorithm 1, we form an matrix of random penalties <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline28.gif"/></alternatives></inline-formula> per resample <italic>b</italic>. For each edge (<italic>k</italic>, <italic>l</italic>) the corresponding adaptive penalty is determined by perturbing initial <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline29.gif"/></alternatives></inline-formula> by an amount <italic>&#x03BA;</italic> using a Bernoulli ranodm variable. The probability of success of each Bernoulli r.v is determined by the corresponding stability score for that edge.</p>
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="027516_eqn8.gif"/></alternatives></disp-formula>
<p>Putting these components together, R<sup>3</sup> consists of first running Step 1 of algorithm 1 to obtain stability scores and then using an additional <italic>B</italic> resamples based on random adaptive penalization, summarized in Step 2 of algorithm 1 to obtain <italic>nB</italic> resampled network metrics <italic>&#x0169;</italic><sup>(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup>. Note that in subsequent steps we omit the superscripts in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline30.gif"/></alternatives></inline-formula> for notational convenience.</p></sec>
<sec id="s2c3"><label>2.3.3</label><title>Test Statistics for Network Metrics</title>
<p>Both R<sup>2</sup> and R<sup>3</sup> yield a total of <italic>nB</italic> resampled network statistics that possess two levels of variability. If we applied single level regression techniques to test the covariate effect in (3), we would in effect assume that all the <italic>nB</italic> resampled statistics were independent. Test statistics that assume <italic>nB</italic> independent observations, despite the availability of only <italic>n</italic> independent clusters of size <italic>B</italic> are known to be overoptimistic [<xref ref-type="bibr" rid="c52"><bold>Laird and Ware</bold>, 1982</xref>; <bold>Liang and Zeger</bold>, <xref ref-type="bibr" rid="c57">1993</xref>]. To address this overoptimism, a more reasonable assumption is that resampled statistics between any two subjects are independent, whereas within subject resampling statistics are positively correlated. Just as we commonly employ mixed effects models to account for two levels of variation in repeated measures data, we employ similar two-level models to derive test statistics for resampled network metrics.</p>
<p>Let <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline31.gif"/></alternatives></inline-formula> denote the vector <italic>B</italic> &#x00D7; 1 vector of resampled statistics per subject &#x007B;<italic>&#x0169;</italic>&#x002A;<sup>(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup>&#x007D;. In the case of real valued density metrics, we use a linear mixed effects (LME) model for repeated measures [<xref ref-type="bibr" rid="c52"><bold>Laird and Ware</bold>, 1982</xref>] to account for the two levels of variability in resampled statistics.</p>
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="027516_eqn9.gif"/></alternatives></disp-formula>
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="027516_eqn10.gif"/></alternatives></disp-formula>
<p>Here <italic>a<sub>i</sub></italic> are <italic>i.i.d</italic> subject level random intercepts with variance Var(<italic>a<sub>i</sub></italic>) &#x003D; <italic>v</italic><sup>2</sup>, <italic>R<sub>i</sub></italic> &#x003D; 1<italic><sub>B</sub></italic><sub>&#x00D7;1</sub> is the random effect design matrix, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline32.gif"/></alternatives></inline-formula> is independent of <italic>a<sub>i</sub></italic> and captures within subject sampling variability with variance Var(<italic>e<sub>i</sub></italic>) &#x003D; <italic>&#x03D5;</italic><sup>&#x002A;2</sup>I<italic><sub>B</sub></italic> where I denotes the identity. From hereon, we ignore the intercept <italic>&#x03B2;</italic><sub>0</sub>, and assume that <italic>&#x03B2;</italic> denotes the (<italic>q</italic> &#x00D7; 1) vector of explanatory fixed effects.</p>
<p>Estimation and inference for linear mixed effect models are well covered in the neuroimaging literature in the context of functional activation studies and longitudinal designs [<xref ref-type="bibr" rid="c8"><bold>Beckmann et al</bold>., 2003</xref>; <xref ref-type="bibr" rid="c11"><bold>Bernal-Rusiel et al.</bold>, 2013</xref>]. We employ standard estimators and test statistics for linear mixed effects models including generalized least squares estimators for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline33.gif"/></alternatives></inline-formula> and corresponding ReML estimators of variance to obtain F-test statistics to test the null hypothesis regarding <italic>&#x03B2;</italic>, the covariate effects. A thorough review of mixed effects models can be found in <xref ref-type="bibr" rid="c3"><bold>Agresti</bold> [2015]</xref> and we also spell these out in more detail for our methods in supplementary materials.</p></sec></sec></sec>
<sec id="s3"><label>3</label><title>SIMULATION STUDY</title>
<p>In this section, we seek to evaluate our framework for testing covariate effects by conducting a rigorous power analysis using realistic fMRI network structures. We obtain realistic network structures for fMRI functional connectivity by using networks estimated from real data as the basis of our simulated networks. First, we synthetically create multivariate data according to our two-level models using realistic graph structures in <xref ref-type="sec" rid="s3a">Section 3.1</xref>. Since we know the true structure of graphical models and their network metrics we empirically measure statistical power and type-I error for all methods. Then, in <xref ref-type="sec" rid="s3b">Section 3.2</xref> we offer two key results. First, by employing simulations using two-level models of variability in (4) that reflect how functional networks are analyzed in practice, we provide a more realistic assessment of when we lose statistical power due to sample sizes (<italic>t</italic>, <italic>n</italic>) and covariate signal-to-noise (SNR) controlled by population variance <italic>v</italic><sup>2</sup>. Second, we show that both R<sup>2</sup> and R<sup>3</sup> mitigate the challenges discussed in <xref ref-type="sec" rid="s2b">Section 2.2</xref> and improve statistical power over standard test statistics under various sample sizes and covariate SNR regimes.</p>
<statement>
<label>Algorithm 1:</label>
<title>R<sup>2</sup> and R<sup>3</sup> Procedures for Testing Covariates Effects on Network Metrics</title>
<p><italic>Step 0:</italic> <bold>Initial Parameters</bold></p>
<p>Estimate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline34.gif"/></alternatives></inline-formula> using graphical model estimation and selection for each subject <italic>i</italic>.</p>
<p><italic>Step 1:</italic> <bold>Subject Level Resampling</bold>
<list list-type="alpha-lower">
<list-item><p>FOR <italic>b</italic> &#x003D; 1,&#x2026;, <italic>B</italic> in the <italic>i</italic><bold><italic><sup>th</sup></italic></bold> subject</p>
<list list-type="roman-lower">
<list-item><p>Bootstrap the data <bold><italic>Y</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup></bold> to get <bold><italic>Y</italic></bold><sup>&#x002A;(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup> and sample correlation matrix <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline35.gif"/></alternatives></inline-formula></p></list-item>
<list-item><p>Perform a standard graphical lasso <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline36.gif"/></alternatives></inline-formula> in (7)</p>
<p><bold>If R<sup>2</sup>:</bold></p></list-item>
<list-item><p>Compute network statistic <italic>&#x0169;</italic><sup>&#x002A;(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup> defined in 2.1</p>
<p>END</p></list-item>
</list></list-item>
<list-item><p>Estimate stability scores <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline37.gif"/></alternatives></inline-formula></p></list-item>
</list></p>
<p><italic>Step 2:</italic> <bold>Subject Level Resampling &#x0026; Random Adaptive Penalization (R<sup>3</sup> only)</bold>
<list list-type="alpha-lower">
<list-item><p>FOR <italic>b</italic> &#x003D; 1,&#x2026;, <italic>B</italic> in the <italic>i</italic><bold><italic><sup>th</sup></italic></bold> subject
<list list-type="roman-lower">
<list-item><p>Bootstrap the data <bold><italic>Y</italic></bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> to get <bold><italic>Y</italic></bold><sup>&#x002A;(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup> and sample correlation matrix <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline38.gif"/></alternatives></inline-formula></p></list-item>
<list-item><p>Using stability scores from Step 1(b), compute random adaptive penalties <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline39.gif"/></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="eqn1">Eq. (8)</xref></p></list-item>
<list-item><p>Using a weighted graphical lasso, estimate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline40.gif"/></alternatives></inline-formula> in (7)</p></list-item>
<list-item><p>Compute network statistic <italic>&#x0169;</italic><sup>&#x002A;(</sup><italic><sup>i</sup></italic>,<italic><sup>b</sup></italic><sup>)</sup> defined in 2.1</p>
<p>END</p></list-item>
</list></p></list-item>
</list></p>
<p><italic>Step 3:</italic> <bold>Population Level Inference for</bold> <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline41.gif"/></alternatives></inline-formula> <bold>using Random Effects</bold></p>
<p>Given either R<sup>2</sup> or R<sup>3</sup> based resampled network statistics <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline42.gif"/></alternatives></inline-formula>
<list list-type="alpha-lower">
<list-item><p>Estimate fixed covariate effects <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline43.gif"/></alternatives></inline-formula> using mixed effects models.</p></list-item>
<list-item><p>Compute mixed effects test statistic and p-values.</p></list-item>
</list></p></statement>
<sec id="s3a"><label>3.1</label><title>SIMULATION SETUP FOR SUBNETWORK AND REGIONAL DENSITY</title>
<p>We simulate multivariate data according to our two level models in <xref ref-type="sec" rid="s2a">Section 2.1</xref>. We know from previous work that the graph structure or location of non-zeros in the inverse covariance [<xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>., 2015</xref>] influences the difficulty of estimating individual subject networks accurately. Using a group level empirical inverse correlation matrix obtained from 90 healthy subjects in the Michigan sample of the ABIDE dataset, preprocessed in <xref ref-type="sec" rid="s4">Section 4</xref>, we threshold entries smaller than <italic>&#x03C4;</italic> &#x003D; |.25| to create a baseline network <italic>A</italic><sub>0</sub> that contributes to the intercept term <italic>&#x03B2;</italic><sub>0</sub> of our model (4). Then we create individual adjacency matrices and network metrics <italic>u</italic><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> according to the linear model (5). We create inverse correlation matrices &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> using the graph structure provided by <italic>A</italic><sub>o</sub> and ensure &#x0398;<sup>(</sup><italic><sup>i</sup></italic><sup>)</sup> is positive definite.</p>
<p>Our main focus in the simulation study is to conduct a rigorous power analysis for node density and subnetwork density under a range of sample sizes and population variability and demonstrate the benefits of using R<sup>3</sup> and R<sup>2</sup> over standard approaches. We obtain empirical estimates of statistical power by measuring the proportion of times we successfully reject <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline44.gif"/></alternatives></inline-formula> at level <italic>&#x03B1;</italic> &#x003D; .05, in the presence of a true covariate effect <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline45.gif"/></alternatives></inline-formula>, across 150 monte-carlo trials for a simulation scenario. Similarly, we obtain an empirical estimate of type I error by measuring the proportion of times we reject <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline46.gif"/></alternatives></inline-formula> at level <italic>&#x03B1;</italic> &#x003D; .05 in the presence of a null covariate effect of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline47.gif"/></alternatives></inline-formula>.</p>
<p>Although one could choose to vary a large number of parameters for these simulations, we focus on the parameters most important for a power analysis, sample sizes and population variance, (<italic>t</italic>, <italic>n</italic>, <italic>v</italic><sup>2</sup>), while fixing other parameters such as number of covariates to <italic>q</italic> &#x003D; 1, <italic>r</italic> &#x003D; 0 and number of nodes to <italic>p</italic> &#x003D; 50. We present power analyses of node density that vary <italic>t</italic> &#x003D; &#x007B;<italic>p</italic>, 2<italic>p</italic>, 4<italic>p</italic>&#x007D;,<italic>v</italic><sup>2</sup> &#x003D; &#x007B;.1, .25, .5&#x007D; and <italic>n</italic> &#x003D; &#x007B;5, 10,&#x2026; 95&#x007D; in <xref ref-type="fig" rid="fig2">Figure 2</xref> in a 3 &#x00D7; 3 panel. Here, we design the simulations by holding the intercept and covariate effect fixed at <italic>&#x03B2;</italic><sub>0</sub> &#x003D; 2, <italic>&#x03B2;</italic><sub>1</sub> &#x003D; 1. Each panel illustrates statistical power as a function of subject sample size <italic>n</italic> for a fixed value of (<italic>t</italic>, <italic>v</italic><sup>2</sup>). Panels vary <italic>t</italic> values from top to bottom and vary <italic>v</italic><sup>2</sup> values from left to right. Similarly, in <xref ref-type="fig" rid="fig3">Figure 3</xref> we present power analyses for subnetwork density where we hold the intercept and covariate fixed at <italic>&#x03B2;</italic><sub>0</sub> &#x003D; 5, <italic>&#x03B2;</italic><sub>1</sub> &#x003D; 2 and use subnetworks of size .1<italic>p</italic> &#x003D; 10 nodes. We use larger values for covariate effects to ensure that the number of edges in a subnetwork are realistically large for a subnetwork with 10 nodes. While the values of sample sizes (<italic>t</italic>, <italic>n</italic>) are the same as those in node density, we also increase <italic>v</italic><sup>2</sup> &#x003D; &#x007B;.4, 1, 2&#x007D;. This ensures that covariate signal to noise ratio <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline48.gif"/></alternatives></inline-formula> is similar for both metrics. Note that that the intercept values <italic>&#x03B2;</italic><sub>0</sub> in both power analyses were based on the average node degree in <italic>A</italic><sub>0</sub> or average subnetwork density for subnetworks of size 10 in <italic>A</italic><sub>0</sub>. For each power analysis, we have a corresponding simulation of type-I error, obtained by setting <italic>&#x03B2;</italic><sub>1</sub> &#x003D; 0 while keeping all other parameters equivalent. The full set of type-I error control results are presented in supplementary materials, and one representative simulation for each metric is presented in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title><italic>Statistical Power Analysis for Node Density.</italic></title>
<p>When node density varies with an explanatory covariate (<italic>q</italic> &#x003D; 1), statistical power to detect this covariate effect improves with subject sample size n but crucially depends on the number of independent fMRI samples <italic>t</italic> from a single session and relative size of the covariate effect, <italic>&#x03B2;</italic><sub>1</sub> &#x003D; 1, to population variance <italic>v</italic><sup>2</sup> (covariate SNR). When <italic>t</italic> &#x2248; <italic>p</italic>, estimates of node density are both highly variable and potentially biased. By accounting for these issues, R<sup>3</sup> and R<sup>2</sup> improve estimates of network metrics, thus exceeding 80&#x0025; power, whereas the standard F-test is substantially less powerful. Note that R<sup>3</sup> and R<sup>2</sup> are more powerful at smaller sample sizes compared to the standard approach. However, when fMRI samples become sufficiently large at <italic>t</italic> &#x2248; 4<italic>p</italic>, all methods become similarly powerful for detecting covariate effects of node density.</p></caption>
<graphic xlink:href="027516_fig2.tif"/>
</fig>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title><italic>Statistical Power for Subnetwork Density.</italic></title>
<p>When subnetwork density varies with an explanatory covariate (<italic>q</italic> &#x003D; 1), statistical power to detect this effect improves with subject sample size <italic>n</italic> but crucially depends on the number of independent fMRI samples <italic>t</italic> from a single session and the relative size of the covariate effect, <italic>&#x03B2;</italic><sub>1</sub> &#x003D; 2, to the population variance <italic>v</italic><sup>2</sup> (covariate SNR). For many values of (<italic>t</italic>, <italic>p</italic>) estimates of subnetwork density are both highly variable and potentially biased. By accounting for these issues, both R<sup>3</sup> and R<sup>2</sup> test statistics substantially improve statistical power across all regimes at smaller subject sample sizes, whereas the standard F-test is substantially less powerful. We note that covariate effects on subnetwork metrics are particularly hard to detect when <italic>t</italic> &#x2248; <italic>p</italic>, with statistical power often below 60&#x0025;.</p></caption>
<graphic xlink:href="027516_fig3.tif"/>
</fig>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title><italic>Statistical Type I Error Is Controlled for both Node and Subnetwork Density.</italic></title>
<p>These simulations evaluate the level of our tests; we report the estimated type-I error as a function of subject sample size <italic>n</italic>. The grey line represents the 5&#x0025; level of the test. Here, we provide a representative simulation for node and subnetwork density in the moderate SNR regime with (<italic>p</italic> &#x003D; 50, <italic>t</italic> &#x003D; 100) and <italic>v</italic><sup>2</sup> &#x003D; .25 for node density and <italic>v</italic><sup>2</sup> &#x003D; 1 for subnetwork density. All methods approximately control type I error across all scenarios studied for both metrics. The full panel of simulations that complement the power analyses in <xref ref-type="fig" rid="fig2">Fig 2</xref> and <xref ref-type="fig" rid="fig3">Fig 3</xref> are included in supplementary materials.</p></caption>
<graphic xlink:href="027516_fig4.tif"/>
</fig></sec>
<sec id="s3b"><label>3.2</label><title>SIMULATION RESULTS</title>
<p>Our methods, R<sup>3</sup> and R<sup>2</sup>, outperform standard methods in terms of statistical power, particularly when within subject observations are comparable to the dimension of the network, and subject networks are harder to estimate correctly. Recall from <xref ref-type="sec" rid="s2b">Section 2.2</xref> that we expect to lose statistical power when individual subject networks are difficult to estimate correctly, due to additional sampling variability and bias in network metrics. As expected, power analyses for both metrics in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref> reveal that statistical power deteriorates as observations <italic>t</italic> available for subject network estimation reduce. Moreover, this loss of statistical power cannot always be compensated by larger subject sample sizes <italic>n</italic>. For example, the best achievable statistical power at large subject samples of <italic>n</italic> &#x2248; 100 begins to deteriorate when <italic>t</italic> &#x003D; <italic>p</italic>. While, the best achievable statistical power often exceeds 90&#x0025; for node density when <italic>t</italic> &#x003E; <italic>p</italic>, it drops as low as 80&#x0025; for R<sup>3</sup> and R<sup>2</sup>. The standard approach in contrast drops below 60&#x0025; node density. In the case of subnetwork density, statistical power for R<sup>3</sup> and R<sup>2</sup> exceed 80&#x0025; when <italic>t</italic> &#x003D; 4<italic>p</italic>, this drops as low as 60&#x0025; at more modest sample sizes of <italic>t</italic> &#x003D; 2<italic>p</italic> and further down to 40&#x0025; at <italic>t</italic> &#x003D; <italic>p</italic>. The standard approach falls to below 40&#x0025; more quickly at <italic>t</italic> &#x003D; 2<italic>p</italic> and below 20&#x0025; when <italic>t</italic> &#x003D; <italic>p</italic>.</p>
<p>Just as with subject sample size, covariate signal to noise ratio or SNR has an almost negligible impact on statistical power, when observations for network estimation are large at <italic>t</italic> &#x003D; 4<italic>p</italic> and individual network estimation is easy. However, as <italic>t</italic> decreases, network estimation becomes harder and consequently, all methods become much more sensitive to SNR. For example, in regimes where <italic>t</italic> &#x003D; 2<italic>p</italic>, network estimation is moderately hard but detecting covariate effects is achievable at high SNR. However, we observe that all methods lose power as covariate SNR decreases. We also observe that loss of statistical power due to SNR is more pronounced at smaller subject sample sizes of <italic>n</italic> &#x003C; 60. Such a result is expected since sampling variability of covariate effect <italic>&#x03B2;</italic><sub>1</sub> is proportional to population variance <italic>v</italic><sup>2</sup> and decreases with larger subject sample sizes <italic>n</italic>.</p>
<p>We noted earlier in <xref ref-type="sec" rid="s2c">Section 2.3</xref> that we expect the benefits of R<sup>3</sup> over R<sup>2</sup> to be the greatest for finest scale metrics at the edge level which are most sensitive to graph selection errors and decrease as metrics measure density at more global levels. Whereas random penalization improves statistical power relative to R<sup>2</sup> for two-sample differences at the edge level <xref ref-type="bibr" rid="c68"><bold>Narayan et al</bold>. [2015]</xref>, they share similar statistical power for node and subnetwork density in most simulations presented here, with some marginal benefits for node density. R<sup>3</sup> offers greater benefits over R<sup>2</sup> at small sample sizes <italic>t</italic> for networks that are more sparse and where the stability of true edges over false edges can be improved via random penalties. Simulations that change the sparsity of networks are provided in supplementary materials.</p>
<p>Finally, in <xref ref-type="fig" rid="fig4">Figure 4</xref>, we provide evidence that type-I error is controlled by all methods for both node and subnetwork density. The full panel of simulations that complement <xref ref-type="fig" rid="fig2">Figures 2</xref> &#x0026; <xref ref-type="fig" rid="fig3">3</xref> are included in supplementary materials.</p>
<p>From these simulations we conclude that resampling based approaches are more efficient, i.e. they have higher statistical power for both node and subnetwork density at smaller subject sample sizes <italic>n</italic>, particularly for smaller <italic>t</italic> and lower covariate SNR. Another noFigure insight from these simulations is that given a fixed budget of fMRI session time, it is preferable to increase the number of within session observations <italic>t</italic> per subject for fewer number of subjects <italic>n</italic> in order to maximize statistical power. For studies where each fMRI session consists of observations comparable to the size of networks (<italic>t</italic>, <italic>p</italic> &#x2208; [100, 200]), as well as for studies that cannot recruit a large number of subjects, our methods, R<sup>3</sup> and R<sup>2</sup>, make better use of available data and improve statistical power compared to standard approaches to network analysis.</p></sec></sec>
<sec id="s4"><label>4</label><title>CASE STUDY</title>
<p>A number of recent studies on Autism Spectrum Disorders (ASD) have found differences in functional connectivity that were correlated with symptom severity as measured by Autism Diagnostic Interview (ADI) or Autism Diagnostic Observation Schedule (ADOS). However, the majority of these studies that link symptom severity to functional connectivity derive networks using pairwise correlations [<xref ref-type="bibr" rid="c91"><bold>Uddin et al</bold>., 2013b</xref>; <xref ref-type="bibr" rid="c85"><bold>Supekar et al</bold>., 2013</xref>]. An important shortcoming of studying differences in pairwise correlation networks is that we cannot distinguish whether the nodes and edges where differences are observed are directly or indirectly involved in the disease mechanism. In contrast, we employ two level models (1) based on GGMs, and thus study density metrics on networks consisting of direct functional connections. This approach enables scientists to infer that any network differences linked with behavioral deficits implicate nodes and edges directly involved in the disease mechanism. Guided by the successes of our simulation study, we employ R<sup>3</sup> to investigate the relationship between cognitive scores on node and subnetwork densities in Autism Spectrum Disorders. In particular, we conduct tests for covariate effects on the density or number of connections in brain regions and subnetworks that might be involved in regulating attention to salient events and hypothesized to be disrupted in ASD based on previous findings [<xref ref-type="bibr" rid="c89"><bold>Uddin</bold>, 2014</xref>].</p>
<sec id="s4a"><label>4.1</label><title>ABIDE DATA COLLECTION AND PREPROCESSING</title>
<p>We use resting state fMRI data collected from the Autism Brain Imaging Data Exchange (ABIDE) project [<xref ref-type="bibr" rid="c31"><bold>Di Martino et al.</bold>, 2014b</xref>] and preprocessed by the Preprocessed Connectomes Project (PCP) [<xref ref-type="bibr" rid="c28"><bold>Craddock and Bellec</bold>, 2015</xref>] using the configurable-pipeline for analysis of connectomes or (C-PAC) toolbox [<xref ref-type="bibr" rid="c27"><bold>Craddock</bold>, 2014</xref>; <xref ref-type="bibr" rid="c36"><bold>Giavasis</bold>, 2015</xref>]. In order to properly account for site effects, we choose to focus on two major sites with relatively large samples, UCLA and Michigan, resulting in 98 and 140 subjects per site. While both ADOS and ADI-R cognitive scores are available for these sites, we focus on ADOS scores obtained using the Gotham algorithm [<xref ref-type="bibr" rid="c38"><bold>Gotham et al</bold>., 2009</xref>], which is known to be comparable across different age groups.</p>
<p>The ABIDE data was acquired [<xref ref-type="bibr" rid="c31"><bold>Di Martino et al.</bold>, 2014b</xref>] using T2 weighted functional MRI images with scan parameters TR&#x003D; 2 at the Michigan site and TR&#x003D; 3 at the UCLA site. Subsequently, this data was minimally preprocessed using the C-PAC utility [<xref ref-type="bibr" rid="c36"><bold>Giavasis</bold>, 2015</xref>; <xref ref-type="bibr" rid="c28"><bold>Craddock and Bellec</bold>, 2015</xref>], including slice timing correction, motion realignment and motion correction using 24 motion parameters, and normalization of images to Montreal Neurological Institute (MNI) 152 stereotactic space at 3 &#x00D7; 3 &#x00D7; 3 mm<sup>3</sup> isotropic resolution. The pipeline was also conFigured to regress out nuisance signals from the fMRI time-series. The nuisance variables included were physiological confounds such as heart beat and respiration, tissue signals and low frequency drifts in the time-series. We did not regress out the global signal as this operation is known to introduce artifacts in the spatial covariance structure [<xref ref-type="bibr" rid="c66"><bold>Murphy et al</bold>., 2009</xref>]. Additionally, we did not apply band pass filtering as this would interfere with subsequent temporal whitening that we describe later in thisSection. Preprocessed data without bandpass filtering and global signal regression is available using the <italic>noglobalnofilt</italic> option in the PCP project. Finally, the spatial timeseries was parcellated into times-series &#x00D7; regions of interest using the Harvard-Oxford atlas distributed with FSL. Here we included <italic>p</italic> &#x003D; 110 regions of interest including 96 cortical regions and 14 subcortical regions. Regions corresponding to white matter, brain stem and cerebellum were excluded. The resulting time-series &#x00D7; regions data matrix for each individual subject is (<italic>t</italic> &#x003D; 116, <italic>p</italic> &#x003D; 110) for UCLA subjects and (<italic>t</italic> &#x003D; 300, <italic>p</italic> &#x003D; 110) for Michigan subjects. This preprocessed dataset has been archived in a public repository <monospace><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1533313">http://dx.doi.org/10.6084/m9.figshare.1533313</ext-link></monospace>.</p></sec>
<sec id="s4b"><label>4.2</label><title>PREVIOUSLY IMPLICATED SUBNETWORKS AND REGIONS</title>
<p>Distinct lines of evidence suggest the involvement of limbic, fronto-parietal, default mode and ventral attention regions in ASD. <xref ref-type="bibr" rid="c89"><bold>Uddin</bold> [2014]</xref> summarize the evidence in favor of a salience-network model to explain behavioral dysfunction in responding to external stimuli. According to this model, the salience network regions that span traditional limbic and ventral attention systems play a vital role in coordinating information between the default mode regions involved in attending to internal stimuli and the fronto-parietal regions involved in regulating attention to external stimuli. Together, these interactions enable appropriate behavioral responses to &#x201C;salient&#x201D; or important events in the external environment. <xref ref-type="bibr" rid="c90"><bold>Uddin et al</bold>. [2013a]</xref> conducted a network-based prediction study and found that connectivity features of the anterior cingulate cortex, and the anterior insula, predict an increase ADOS repetitive behavior scores. Similarly, another study by <xref ref-type="bibr" rid="c32"><bold>DiMartino et al</bold>. [2009]</xref> also implicates connectivity of anterior insula and anterior cingulate cortex to deficits in social responsiveness in Autism. <xref ref-type="bibr" rid="c26"><bold>Cherkassky et al</bold>. [2006]</xref>; <xref ref-type="bibr" rid="c65"><bold>Monk et al</bold>. [2009]</xref> implicate posterior cingulate connectivity within the default mode network in ASD. <xref ref-type="bibr" rid="c4"><bold>Alaerts et al</bold>. [2013]</xref> show that deficits in emotion recognition were correlated with network features in the right posterior superior temporal sulcus, a result also supported in the wider literature [<xref ref-type="bibr" rid="c91"><bold>Uddin et al</bold>., 2013b</xref>].</p>
<p>We also consider major findings from previous analyses of the ABIDE dataset that include the UCLA or Michigan subject samples. Whole brain voxelwise analysis by <xref ref-type="bibr" rid="c31"><bold>Di Martino et al.</bold> [2014b]</xref> revealed covariate effects associated with the mid insula, posterior insula, posterior cingulate cortex and thalamus. Group level two-sample tests of functional segregation and integration in seed based functional connectivity [<xref ref-type="bibr" rid="c75"><bold>Rudie et al</bold>., 2012a</xref>,b] reveal differences in the amygdyla, IFG right pars opercularis.</p>
<p>Based on our review of existing literature, we seek to detect covariate effects with respect to 23 hypotheses regarding the density of connections. Of these 23 hypotheses, 13 correspond to density of connections of nodes or brain regions with respect to the whole brain, and 10 correspond to the density within and between 4 large scale functional subnetworks. These regions are defined using the Harvard-Oxford atlas with large scale subnetworks provided by <xref ref-type="bibr" rid="c101"><bold>Yeo et al</bold>. [2011]</xref>. <xref ref-type="fig" rid="fig5">Figure 5</xref> illustrates the volumes associated with the 13 regions of interest. <xref ref-type="fig" rid="fig6">Figure 6</xref> illustrates the four large scale functional brain networks we consider, namely, the default mode, the frontoparietal, the limbic and the ventral attention networks as defined by <xref ref-type="bibr" rid="c101"><bold>Yeo et al</bold>. [2011]</xref>. By explicitly testing the density of long-range connections in brain regions and networks previously linked with ASD, we aim to identify network structures at the node and subnetwork level that are directly involved in behavioral deficits.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title><italic>Regions of Interest for Covariate Tests of Node Density.</italic></title>
<p>This figure illustrates the regions of interest based on the Harvard Oxford Atlas that we have chosen to test for covariate effects in <xref ref-type="table" rid="tbl2">Table 2</xref>. Several studies link the severity of autism spectrum disorders, measured by ADI or ADOS cognitive scores, with 9 cortical (<xref ref-type="fig" rid="fig5">Fig 5a</xref>) and 4 sub-cortical (<xref ref-type="fig" rid="fig5">Fig 5c</xref>) regions of interest, all within the default mode, limbic, frontoparietal and ventral attention networks. The full literature review is available in 4.2.</p></caption>
<graphic xlink:href="027516_fig5.tif"/>
</fig>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title><italic>Functional Subnetworks of Interest for Covariate Tests of Network Density.</italic></title>
<p>This figure illustrates the subnetworks we have chosen to test for covariate effects in <xref ref-type="table" rid="tbl1">Table 1</xref>. Using previous studies discussed in 4.2, we seek to test whether symptom severity is associated with individual differences in the density or number of connections within and between these sub-networks. Panels A-D illustrate subnetwork components of the full group level network in panel E. The network structure in Panel (A) shows links within the limbic subnetwork as well as between the limbic regions and all other brain regions. Similarly, each of the other panels emphasize connectivity of fronto-parietal (B), ventral attention (C) and default mode (D) regions, respectively, to the whole brain. For the purposes of illustration, this group level network is obtained using individually estimated graphical models from the procedure in <xref ref-type="sec" rid="s2c1">section 2.3.1</xref>. Nodes correspond to anatomical regions in the Harvard Oxford Atlas [<xref ref-type="bibr" rid="c34"><bold>Fischl et al</bold>., 2004</xref>]. The subnetworks correspond to resting state networks provided by <xref ref-type="bibr" rid="c101"><bold>Yeo et al</bold>. [2011]</xref>. We first threshold weak edges with stability scores less than .8 in individual subject networks and then obtain a group level network by aggregating edge presence across all subjects. Note that we use this group network exclusively for illustrative purposes and not for statistical inference. The color gradient for edges in group network in panel E corresponds to proportion of stable edges found across all subjects.</p></caption>
<graphic xlink:href="027516_fig6.tif"/>
</fig>
<sec id="s4b1"><label>4.2.1</label><title>Testing for covariate effects via R<sup>3</sup></title>
<p>We employ the linear model from (5) for node and subnetwork density to test the null hypothesis that ADOS covariates have no effect on density. For this analysis, we jointly consider two related explanatory covariates, the ADOS Social Affect (SA) and the ADOS Restricted, Repetitive Behavior (RRB) scores (<italic>q</italic> &#x003D; 2), while accounting for differences in clinical evaluation across sites, by incorporating site as a nuisance covariate (<italic>r</italic> &#x003D; 1). We eliminate subjects without ADOS cognitive scores, leaving us with <italic>n</italic> &#x003D; 100 autism subjects. Thus, the final data tensor for covariate tests contains either <italic>t</italic> &#x003D; 116 (UCLA) or <italic>t</italic> &#x003D; 300 (Michigan) time-points for <italic>p</italic> &#x003D; 110 brain regions in <italic>n</italic> &#x003D; 100 subjects.</p>
<p>Before applying R<sup>3</sup> from <xref ref-type="sec" rid="s2c">Section 2.3</xref> to the preprocessed ABIDE dataset, we need to ensure fMRI observations are approximately independent. By whitening temporal observations, we ensure that estimating individual subject networks is more efficient. We achieve this by first estimating the temporal precision matrix <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline49.gif"/></alternatives></inline-formula> using the banded regularization procedure of [<xref ref-type="bibr" rid="c12"><bold>Bickel and Levina</bold>, 2008</xref>] for autoregressive data and whitening the fMRI time-series of each subject <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline50.gif"/></alternatives></inline-formula>. To choose the number of lags, we conduct model selection via cross-validation [<xref ref-type="bibr" rid="c12"><bold>Bickel and Levina</bold>, 2008</xref>]. Given these whitened observations, we apply the R<sup>3</sup> procedure outlined in Algorithm 1. Since we have a total of 23 node density and subnetwork density hypotheses, we control the false discovery rate at the 5&#x0025; level using the Benjamini-Yekutieli procedure [<xref ref-type="bibr" rid="c9"><bold>Benjamini and Yekutieli,</bold> 2001</xref>].</p></sec></sec>
<sec id="s4c"><label>4.3</label><title>ABIDE DATA ANALYSIS: RESULTS</title>
<p><xref ref-type="table" rid="tbl1">Tables 1</xref> &#x0026; <xref ref-type="table" rid="tbl2">2</xref> show statistically significant covariate effects for 4 subnetwork hypotheses and 6 regions of interest. Notable findings amongst subnetwork hypotheses in <xref ref-type="table" rid="tbl1">Table 1</xref> are that an increase in behavioral deficits indicated by restricted and repetitive behavior scores (RRB) and social affect (SA) is associated with a decrease in connection densities within frontoparietal-based subnetworks. This includes connection densities within the frontoparietal subnetwork, between the frontoparietal to limbic subnetworks, between the frontoparietal to ventral attention subnetworks and between the default mode and limbic subnetworks. Individual regression coefficients and confidence intervals for RRB and SA suggest that of the two covariates, RRB scores particularly dominate the decrease in subnetwork density for two of these results, particularly the frontoparietal-limbic subnetwork. The most prominent results amongst region of interest hypotheses in <xref ref-type="table" rid="tbl2">Table 2</xref> suggest that ADOS symptom severity again is associated with hypoconnectivity in between the bilateral pairs of cingulate cortex, posterior (PCC) and anterior divisions (ACC); the right inferior frontal gyrus (IFG); and the thalamus to all other brain regions. While the regression coefficients for site effects are non-zero in both analyses, most confidence intervals either contain zero or are very close to zero and not statistically significant. The one exception amongst our prominent findings, the right ACC, shows statistically significant site effects. We also find site effects for two hypotheses where we did not detect ADOS effects, namely, the limbic to ventral attention subnetwork and right insula. However, these site effects are not statistically significant after correcting for multiplicity.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title><italic>Joint ADOS Covariate Effects on Subnetwork Density.</italic></title>
<p>We jointly test the effects of two ADOS covariates on subnetwork density while accounting for site effects as a nuisance covariate. Here, the most prominent findings suggest that a decrease in the numer of direct connections within frontoparietal subnetworks, and between frontoparietal to limbic, and frontoparietal to ventral attention subnetworks is linked with increased ADOS symptom severity. This result is consistent with the hypothesis that abnormalities within the salience network, comprising anterior cingulate cortex (a region within our frontoparietal network) and insula (a region within our ventral attention network), results in a failure to regulate between attention to external stimuli versus attention to internal thoughts. A total of four subnetworks, denoted by <sup>&#x002A;</sup>, survive corrections for multiplicity, using false discovery control over all 23 hypotheses tested at the 5&#x0025; level using Benjamini-Yekutieli. Although estimates of site effects were nonzero, individual confidence intervals for most site-effects were close to zero and were thus not statistically significant after corrections for multiplicity. Results are discussed further in <xref ref-type="sec" rid="s4c">Section 4.3</xref></p></caption>
<graphic xlink:href="027516_tbl1.tif"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title><italic>Joint ADOS Covariate Effects on Node Density.</italic></title>
<p>We jointly test the effects of two ADOS covariates on node density while accounting for site effects as a nuisance covariate. Notably, we find that a decrease in the number of direct connections between posterior cingulate cortex (PCC) and anterior cingulate cortex (ACC) with all other regions is linked with an increase in ADOS symptom severity. This result corroborates previous findings that ACC (a component of the salience network) and PCC connectivity might be directly involved behavioral deficits ASD. A total of six regions, denoted by &#x002A;, survive corrections for multiplicity, using false discovery control over all 23 hypotheses tested at the 5&#x0025; level using Benjamini-Yekutieli. Although estimates of site effects were non-zero, individual confidence intervals for most site-effects were close to zero and were thus not statistically significant after corrections for multiplicity. Results are discussed further in <xref ref-type="sec" rid="s4c">Section 4.3</xref></p></caption>
<graphic xlink:href="027516_tbl2.tif"/>
</table-wrap>
<p>Our analysis strongly implicates the frontoparietal-limbic subnetwork, and frontoparietal-ventral attention subnetworks, as well as posterior/anterior cingulate cortical connections with the rest of the brain, in behavioral deficits of ASD. Since we identify these regions and subnetworks using partial correlation measures of functional connectivity, our results provide strong evidence that these network components are directly involved in ASD. In particular, since the salience network [<xref ref-type="bibr" rid="c90"><bold>Uddin et al</bold>., 2013a</xref>; <xref ref-type="bibr" rid="c17"><bold>Buckner et al</bold>., 2013</xref>] is thought to comprise the ACC, which falls within our frontoparietal network, and insular regions that overlap limbic and ventral attention networks in our analysis, our subnetwork findings are consistent with the salience network explanation for behavioral deficits in autism. Additionally, our findings strongly implicate frontoparietal-limbic relationships. While our region of interest analysis found abnormalities in thalamar connectivity, a component of the limbic network, other limbic regions could also be directly involved in ASD and thus warrant further study.</p>
<p>Although, previous analyses based on the UCLA and UM ABIDE samples <xref ref-type="bibr" rid="c31"><bold>Di Martino et al.</bold> [2014b]</xref>; <xref ref-type="bibr" rid="c77"><bold>Rudie et al</bold>. [2012b]</xref> as well as those independent of these sites [<xref ref-type="bibr" rid="c91"><bold>Uddin et al</bold>., 2013b</xref>] link insular, amygdylar connectivity with autism symptoms, we did not detect strong effects for these regions. While this does not rule out their involvement via alternative network metrics, the absence of strong effects in our analysis suggests that the insular and amygdylar connections might be associated with behavioral deficits in autism only by indirect correlations with other regions of interest. Similarly, although we find abnormalities in the PCC, a region within the default mode network, and between the default-mode and the limbic regions, we failed to find abnormalities linking the default mode with frontoparietal or ventral attention networks. This suggests that previous findings involving the default mode network could have been the result of indirect pairwise correlations, possibly driven by PCC. Although we use novel functional connectivity models and methods to analyze the ABIDE dataset, some of our choices of a-priori hypotheses for this analysis, notably, the inclusion of IFG pars opercularis and the amygdyla for node density, were guided by alternative analyses of the ABIDE dataset [<xref ref-type="bibr" rid="c77"><bold>Rudie et al</bold>., 2012b</xref>; <xref ref-type="bibr" rid="c31"><bold>Di Martino et al.</bold>, 2014b</xref>]. Thus, we need further validation of the purported effects of ADOS on IFG pars opercularis density.</p>
<p>In addition to finding abnormalities in subnetworks and regions previously implicated in Autism, our results also offer some guidance on conflicting results in neuroimaging [<xref ref-type="bibr" rid="c76"><bold>Rudie and Dapretto</bold>, 2013</xref>]. We offer insights regarding whether behavioral deficits in ASD are primarily driven by hyperconnectivity, defined as abnormal increase in interactions between brain regions, or hypoconnectivity, defined as an abnormal decrease in interactions between brain regions. All our results, at both the subnetwork and node level, favor the hypoconnectivity hypothesis for behavioral deficits in autism. Specifically, we find that a reduction in directly involved long-range functional connections increases ADOS symptom severity. Assuming that the salience network model of autism dysfunction is correct, our results suggest that reduced interactions between the executive control network and the salience network might be responsible for ASD symptoms. A previous study found evidence of hyperconnectivity when counting the number of local voxelwise connections in <xref ref-type="bibr" rid="c47"><bold>Keown et al</bold>. [2013]</xref>. Our results do not contradict this finding since a network architecture of ASD could involve both reduced long range connections as well as increased density of local connections <xref ref-type="bibr" rid="c76"><bold>Rudie and Dapretto</bold> [2013]</xref>. Other results on hyperconnectivity [<xref ref-type="bibr" rid="c90"><bold>Uddin et al</bold>., 2013a</xref>; <xref ref-type="bibr" rid="c85"><bold>Supekar et al</bold>., 2013</xref>] do not explicitly employ degree or density of connections to measure hyper or hypo-conectivity but measure the strength of the mean pairwise correlation within and between regions and subnetworks. While the effect in <xref ref-type="bibr" rid="c85"><bold>Supekar et al</bold>. [2013]</xref> appears to be a large and robust finding, the model of connectivity employed in their analysis could be misleading since it includes both direct and indirect functional connections and does not explicitly measure the density of connections. While further studies are needed to resolve the questions raised by <xref ref-type="bibr" rid="c76"><bold>Rudie and Dapretto</bold> [2013]</xref> on this matter, we emphasize that using graphical models of functional connectivity that capture direct functional connections combined with explicit density metrics enables stronger scientific conclusions regarding network structure.</p></sec></sec>
<sec id="s5"><label>5</label><title>DISCUSSION</title>
<p>This paper investigates an understudied issue in neuroimaging &#x2013; the impact of (often imperfectly) estimated functional networks on subsequent population level inference to find differences across functional networks. Using an important class of network models for functional connectivity, Gaussian graphical models, we demonstrate that neglecting errors in estimated functional networks reduces statistical power to detect covariate effects for network metrics. While lack of statistical power due to small subject sizes is well documented in neuroimaging [<xref ref-type="bibr" rid="c23"><bold>Button et al</bold>., 2013</xref>], recent test re-test studies [<xref ref-type="bibr" rid="c13"><bold>Birn et al</bold>., 2013</xref>; <xref ref-type="bibr" rid="c53"><bold>Laumann et al</bold>., 2015</xref>] suggest that typical fMRI studies of 5-10 minutes are highly susceptible to lack of statistical power. This paper provides additional evidence that within subject sample size, t, is important for well powered studies. For typical studies where t is comparable to the number of nodes p, errors in estimating functional networks can be substantial and not accounted for by standard test statistics. We show that our methods to mitigate this problem, R<sup>2</sup> and R<sup>3</sup>, are always at least as powerful if not substantially more powerful than standard test statistics under a variety of sample sizes and covariate signal-to-noise regimes. Additionally, regardless of the methods employed, our power analyses suggest that in many scenarios, particularly for large networks, a more efficient use of a fixed experimental budget would be to collect more within subject measurements and fewer subject samples in order to maximize statistical power to detect covariate effects.</p>
<p>We employ our models and methods to detect covariate effects on the density of direct, long range functional connections in ASD, using the ABIDE dataset [<xref ref-type="bibr" rid="c31"><bold>Di Martino et al.</bold>, 2014b</xref>]. We particularly highlight the scientific merits of employing explicit density based metrics in graphical models of functional connectivity to gain insights into disease mechanisms at a macroscopic level. Our results in <xref ref-type="sec" rid="s4c">section 4.3</xref> suggest that hypoconnectivity, rather than hyperconnectivity of long range connections is associated with autism symptom severity. We find evidence if hypoconnectivity within frontoparietal subnetworks, between frontoparietal to limbic regions, between frontoparietal to ventral subnetworks, as well as between anterior and posterior cingulate cortices to the whole brain. These findings are consistent with the hypothesis that abnormalities in the salience network are involved in behavioral deficits of ASD.</p>
<p>While we focus on resting state functional connectivity in fMRI in this work, our concern regarding errors in estimating large functional networks is applicable to other imaging modalities including EEG/MEG studies. In fact, our two level models (1) and R<sup>3</sup> framework can be easily extended to functional network analyses based on partial coherence [<xref ref-type="bibr" rid="c78"><bold>Sato et al</bold>., 2009</xref>] networks or vector autoregressive models [<xref ref-type="bibr" rid="c50"><bold>Koenig et al</bold>., 2005</xref>; <xref ref-type="bibr" rid="c79"><bold>Schelter et al</bold>., 2006</xref>] that are popular in EEG/MEG studies. Additionally, our results are highly relevant to dynamic functional connectivity [<xref ref-type="bibr" rid="c25"><bold>Chang and Glover</bold>, 2010</xref>] analyses where studies estimate separate time-varying functional networks per subject using short sliding-windows of 30-60 seconds rather than 5-10 minutes. In such a high dimensional setting where <italic>t</italic> &#x003C;&#x003C; <italic>p</italic>, our power analyses in <xref ref-type="fig" rid="fig2">figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref> suggest that such dynamic network analyses will be highly underpowered and could benefit from our methods. Thus, extensions of the R<sup>3</sup> framework for dynamic connectivity analyses as well as other multivariate network models is a promising avenue of research. Other areas of investigation include inference for partial correlation strength and corresponding weighted network analysis, as well as including high dimensional covariates in our general linear model (2). Overall, this work reveals that accounting for imperfectly estimated functional networks dramatically improves statistical power to detect population level covariate effects, thus highlighting an important new direction for future research.</p></sec>
<sec id="s6"><label>6</label><title>DATA AND SOFTWARE</title>
<p>The preprocessed ABIDE dataset used in this paper will be made available at <monospace><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1533313">http://dx.doi.org/10.6084/m9.figshare.1533313</ext-link></monospace>. Software for reproducing our analysis will be provided at <monospace><ext-link ext-link-type="uri" xlink:href="https://bitbucket.org/gastats/monet">https://bitbucket.org/gastats/monet</ext-link></monospace>.</p></sec>
</body>
<back>
<ack><title>ACKNOWLEDGMENTS</title>
<p>The authors thank Steffie Tomson for helpful discussions and advice on preprocessing the ABIDE dataset.</p>
<p content-type="funding"><italic>Funding:</italic> M.N. and G.A. are supported by NSF DMS 1264058. M.N is supported an AWS (Amazon Web Services) research grant for computational resources.</p>
</ack>
<sec id="s7" sec-type="supplementary-material"><title>SUPPLEMENTARY MATERIALS</title>
<p>We include additional simulations and details of test statistics for our methods in the appendix.</p></sec>
<ref-list><title>REFERENCES</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Achard</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Salvador</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Whitcher</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Suckling</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name> (<year>2006</year>), <article-title>A resilient, low-frequency, small-world human brain functional network with highly connected association cortical hubs</article-title>, <source>J. Neurosci.</source>, <volume>26</volume>, <issue>1</issue>, <fpage>63</fpage>&#x2013;<lpage>72</lpage></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><string-name><surname>Agresti</surname>, <given-names>A.</given-names></string-name> (<year>2002</year>), <source>Categorical data analysis</source>, volume <volume>359</volume> (<publisher-name>John Wiley &#x0026; Sons</publisher-name>)</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="book"><string-name><surname>Agresti</surname>, <given-names>A.</given-names></string-name> (<year>2015</year>), <source>Foundations of Linear and Generalized Linear Models</source> (<publisher-name>John Wiley &#x0026; Sons</publisher-name>)</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="other"><string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Woolley</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Steyaert</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Swinnen</surname>, <given-names>S. P.</given-names></string-name>, and <string-name><surname>Wenderoth</surname>, <given-names>N.</given-names></string-name> (<year>2013</year>), <article-title>Underconnectivity of the superior temporal sulcus predicts emotion recognition deficits in autism</article-title>, <source>Social cognitive and affective neuroscience</source>, <fpage>nst156</fpage></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Alexander-Bloch</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lambiotte</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Giedd</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gogtay</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name> (<year>2012</year>), <article-title>The discovery of population differences in network community structure: New methods and applications to brain functional networks in schizophrenia</article-title>, <source>Neuroimage</source>, <volume>59</volume>, <issue>4</issue>, <fpage>3889</fpage>&#x2013;<lpage>3900</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage</pub-id>. 2011.11.035</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Balachandran</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Airoldi</surname>, <given-names>E.</given-names></string-name>, and <string-name><surname>Kolaczyk</surname>, <given-names>E.</given-names></string-name> (<year>2013</year>), <article-title>Inference of network summary statistics through network denoising</article-title>, <source>arXiv preprint arXiv</source>:<volume>1310</volume>.<fpage>0423</fpage></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bassett</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Porter</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Wymbs</surname>, <given-names>N. F.</given-names></string-name>, <string-name><surname>Grafton</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Carlson</surname>, <given-names>J. M.</given-names></string-name>, and <string-name><surname>Mucha</surname>, <given-names>P. J.</given-names></string-name> (<year>2013</year>), <article-title>Robust detection of dynamic community structure in networks</article-title>, <source>Chaos: An Interdisciplinary Journal of Nonlinear Science</source>, <volume>23</volume>, <issue>1</issue>, <fpage>013142</fpage>&#x2013;<lpage>013142</lpage></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name> (<year>2003</year>), <article-title>General multilevel linear modeling for group analysis in FMri</article-title>, <source>Neuroimage</source>, <volume>20</volume>, <issue>2</issue>, <fpage>1052</fpage>&#x2013;<lpage>1063</lpage></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Benjamini</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Yekutieli</surname>, <given-names>D.</given-names></string-name> (<year>2001</year>), <article-title>The control of the false discovery rate in multiple testing under dependency</article-title>, <source>Ann. Stat.</source>, <volume>29</volume>, <issue>4</issue>, <fpage>1165</fpage>&#x2013;<lpage>1188</lpage></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="other"><string-name><surname>Berk</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Buja</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Zhao</surname>, <given-names>L.</given-names></string-name> (<year>2013</year>), <article-title>Valid post-selection inference</article-title>, <source>Ann. Stat</source>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Bernal-Rusiel</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Greve</surname>, <given-names>D. N.</given-names></string-name>, <string-name><surname>Reuter</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Sabuncu</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Initiative</surname>, <given-names>A. D. N.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Statistical analysis of longitudinal neuroimage data with linear mixed effects models</article-title>, <source>Neuroimage</source>, <volume>66</volume>, <fpage>249</fpage>&#x2013;<lpage>260</lpage></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="other"><string-name><surname>Bickel</surname>, <given-names>P. J.</given-names></string-name>, and <string-name><surname>Levina</surname>, <given-names>E.</given-names></string-name> (<year>2008</year>), <article-title>Regularized estimation of large covariance matrices</article-title>, <source>Ann. Stat.</source>, <fpage>199</fpage>&#x2013;<lpage>227</lpage></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Birn</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Molloy</surname>, <given-names>E. K.</given-names></string-name>, <string-name><surname>Patriat</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Parker</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Meier</surname>, <given-names>T. B.</given-names></string-name>, <string-name><surname>Kirk</surname>, <given-names>G. R.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>The effect of scan length on the reliability of resting-state fmri connectivity estimates</article-title>, <source>Neuroimage</source>, <volume>83</volume>, <fpage>550</fpage>&#x2013;<lpage>558</lpage></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Braun</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Plichta</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Esslinger</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Sauer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Haddad</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Grimm</surname>, <given-names>O.</given-names></string-name>, <etal>et al.</etal> (<year>2012</year>), <article-title>Test-retest reliability of resting-state connectivity network characteristics using fmri and graph theoretical measures</article-title>, <source>Neuroimage</source>, <volume>59</volume>, <issue>2</issue>, <fpage>1404</fpage>&#x2013;<lpage>1412</lpage></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Breiman</surname>, <given-names>L.</given-names></string-name> (<year>1996a</year>), <article-title>Bagging predictors</article-title>, <source>Machine learning</source>, <volume>24</volume>, <issue>2</issue>, <fpage>123</fpage>&#x2013;<lpage>140</lpage></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Breiman</surname>, <given-names>L.</given-names></string-name> (<year>1996b</year>), <article-title>Heuristics of instability and stabilization in model selection</article-title>, <source>Ann. Stat.</source>, <volume>24</volume>, <issue>6</issue>, <fpage>2350</fpage>&#x2013;<lpage>2383</lpage></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Buckner</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Krienen</surname>, <given-names>F. M.</given-names></string-name>, and <string-name><surname>Yeo</surname>, <given-names>B. T.</given-names></string-name> (<year>2013</year>), <article-title>Opportunities and limitations of intrinsic functional connectivity MRI</article-title>, <source>Nat. Neurosci.</source>, <volume>16</volume>, <issue>7</issue>, <fpage>832</fpage>&#x2013;<lpage>837</lpage></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Buckner</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Sepulcre</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Talukdar</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Krienen</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hedden</surname>, <given-names>T.</given-names></string-name>, <etal>et al.</etal> (<year>2009</year>), <article-title>Cortical hubs revealed by intrinsic functional connectivity: mapping, assessment of stability, and relation to alzheimer&#x2019;s disease</article-title>, <source>J. Neurosci.</source>, <volume>29</volume>, <issue>6</issue>, <fpage>1860</fpage>&#x2013;<lpage>1873</lpage></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>B&#x00FC;hlmann</surname>, <given-names>P.</given-names></string-name> and <string-name><surname>Yu</surname>, <given-names>B.</given-names></string-name> (<year>2002</year>), <article-title>Analyzing bagging</article-title>, <source>Ann. Stat.</source>, <volume>30</volume>, <issue>4</issue>, <fpage>927</fpage>&#x2013;<lpage>961</lpage></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name> (<year>2012</year>), <article-title>Functional network endophenotypes of psychotic disorders</article-title>., <source>Biol. Psychiatry</source>, <volume>71</volume>, <issue>10</issue>, <fpage>844</fpage></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name> and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name> (<year>2009</year>), <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>, <source>Nat. Rev. Neurosci.</source>, <volume>10</volume>, <issue>3</issue>, <fpage>186</fpage>&#x2013;<lpage>198</lpage></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name> and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name> (<year>2012</year>), <article-title>The economy of brain network organization</article-title>, <source>Nat. Rev. Neurosci.</source>, <volume>13</volume>, <issue>5</issue>, <fpage>336</fpage>&#x2013;<lpage>349</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nrn3214</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Button</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Ioannidis</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Mokrysz</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Nosek</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Flint</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>E. S.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Power failure: why small sample size undermines the reliability of neuroscience</article-title>, <source>Nature Reviews Neuroscience</source>, <volume>14</volume>, <issue>5</issue>, <fpage>365</fpage>&#x2013;<lpage>376</lpage></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Cai</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Luo</surname>, <given-names>X.</given-names></string-name> (<year>2011</year>), <article-title>A constrained <italic>&#x2113;</italic><sub>1</sub> minimization approach to sparse precision matrix estimation</article-title>, <source>JASA</source>, <volume>106</volume>, <issue>494</issue>, <fpage>594</fpage>&#x2013;<lpage>607</lpage></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Chang</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Glover</surname>, <given-names>G. H.</given-names></string-name> (<year>2010</year>), <article-title>Time-frequency dynamics of resting-state brain connectivity measured with fmri</article-title>, <source>Neuroimage</source>, <volume>50</volume>, <issue>1</issue>, <fpage>81</fpage>&#x2013;<lpage>98</lpage></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Cherkassky</surname>, <given-names>V. L.</given-names></string-name>, <string-name><surname>Kana</surname>, <given-names>R. K.</given-names></string-name>, <string-name><surname>Keller</surname>, <given-names>T. A.</given-names></string-name>, and <string-name><surname>Just</surname>, <given-names>M. A.</given-names></string-name> (<year>2006</year>), <article-title>Functional connectivity in a baseline resting-state network in autism</article-title>, <source>Neuroreport</source>, <volume>17</volume>, <issue>16</issue>, <fpage>1687</fpage>&#x2013;<lpage>1690</lpage></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="other"><string-name><surname>Craddock</surname>, <given-names>C.</given-names></string-name> (<year>2014</year>), <article-title>Preprocessed connectomes project: Open sharing of preprocessed neuroimaging data and derivatives, in 61st Annual Meeting (AACAP)</article-title></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="other"><string-name><surname>Craddock</surname>, <given-names>R. C.</given-names></string-name>, and <string-name><surname>Bellec</surname>, <given-names>P.</given-names></string-name> (<year>2015</year>), Preprocessed connectomes project: Abide, <monospace><ext-link ext-link-type="uri" xlink:href="http://preprocessed-connectomes-project.github.io/abide/">http://preprocessed-connectomes-project.github.io/abide/</ext-link></monospace></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Craddock</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Jbabdi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.-G.</given-names></string-name>, <string-name><surname>Vogelstein</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Imaging human connectomes at the macroscale</article-title>, <source>Nat. Methods</source>, <volume>10</volume>, <issue>6</issue>, <fpage>524</fpage>&#x2013;<lpage>539</lpage></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fair</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Kelly</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Satterthwaite</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Thomason</surname>, <given-names>M. E.</given-names></string-name>, <etal>et al.</etal> (<year>2014a</year>), <article-title>Unraveling the miswired connectome: A developmental perspective</article-title>, <source>Neuron</source>, <volume>83</volume>, <issue>6</issue>, <fpage>1335</fpage>&#x2013;<lpage>1353</lpage></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.-G.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Denio</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, <etal>et al.</etal> (<year>2014b</year>), <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>, <source>Mol. Psychiatry</source>, <volume>19</volume>, <issue>6</issue>, <fpage>659</fpage>&#x2013;<lpage>667</lpage></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>DiMartino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Shehzad</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kelly</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Gee</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <etal>et al.</etal> (<year>2009</year>), <article-title>Relationship between cingulo-insular functional connectivity and autistic traits in neurotypical adults</article-title>, <source>The American journal of psychiatry</source>, <volume>166</volume>, <issue>8</issue>, <fpage>891</fpage>&#x2013;<lpage>899</lpage></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="book"><string-name><surname>Efron</surname>, <given-names>B.</given-names></string-name> and <string-name><surname>Tibshirani</surname>, <given-names>R. J.</given-names></string-name> (<year>1993</year>), <source>An Introduction to the Bootstrap</source> (<publisher-name>Chapman &#x0026; Hall</publisher-name>, <publisher-loc>London, U.K</publisher-loc>)</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>van der Kouwe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Destrieux</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Halgren</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>S&#x00E9;gonne</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Salat</surname>, <given-names>D. H.</given-names></string-name>, <etal>et al.</etal> (<year>2004</year>), <article-title>Automatically parcellating the human cerebral cortex</article-title>, <source>Cereb. Cortex</source>, <volume>14</volume>, <issue>1</issue>, <fpage>11</fpage>&#x2013;<lpage>22</lpage></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Friedman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hastie</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Tibshirani</surname>, <given-names>R. J.</given-names></string-name> (<year>2008</year>), <article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>, <source>Biostatistics</source>, <volume>9</volume>, <issue>3</issue>, <fpage>432</fpage>&#x2013;<lpage>441</lpage></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="other"><string-name><surname>Giavasis</surname>, <given-names>S.</given-names></string-name> (<year>2015</year>), <article-title>Configurable-pipeline for the analysis of connectomes version 0.3.8</article-title>, doi:<pub-id pub-id-type="doi">10.5281/ zenodo.14298</pub-id>,</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Ginestet</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>Fournel</surname>, <given-names>A. P.</given-names></string-name>, and <string-name><surname>Simmons</surname>, <given-names>A.</given-names></string-name> (<year>2014</year>), <article-title>Statistical network analysis for functional MRI: summary networks and group comparisons</article-title>, <source>Front. Comput. Neurosci.</source>, <volume>8</volume></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Gotham</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Pickles</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Lord</surname>, <given-names>C.</given-names></string-name> (<year>2009</year>), <article-title>Standardizing ados scores for a measure of severity in autism spectrum disorders</article-title>, <source>J. Autism Dev. Disord.</source>, <volume>39</volume>, <issue>5</issue>, <fpage>693</fpage>&#x2013;<lpage>705</lpage></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Hacker</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name>, <string-name><surname>Szrama</surname>, <given-names>N. P.</given-names></string-name>, <string-name><surname>Baldassarre</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Leuthardt</surname>, <given-names>E. C.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Resting state network estimation in individual subjects</article-title>, <source>Neuroimage</source>, <volume>82</volume>, <fpage>616</fpage>&#x2013;<lpage>633</lpage></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="other"><string-name><surname>Hahamy</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Behrmann</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Malach</surname>, <given-names>R.</given-names></string-name> (<year>2015</year>), <article-title>The idiosyncratic brain: distortion of spontaneous connectivity patterns in autism spectrum disorder</article-title>, <source>Nat. Neurosci</source>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Honey</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>K&#x00F6;tter</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Breakspear</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name> (<year>2007</year>), <article-title>Network structure of cerebral cortex shapes functional connectivity on multiple time scales</article-title>, <source>Proceedings of the National Academy of Sciences</source>, <volume>104</volume>, <issue>24</issue>, <fpage>10240</fpage>&#x2013;<lpage>10245</lpage></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Hsieh</surname>, <given-names>C.-J.</given-names></string-name>, <string-name><surname>Sustik</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>M&#x00E1;ty&#x00E1;s</surname> <given-names>A.</given-names></string-name> and <string-name><surname>Dhillon</surname></string-name>, and <string-name><surname>Ravikumar</surname>, <given-names>P.</given-names></string-name> (<year>2011</year>), <article-title>Sparse inverse covariance matrix estimation using quadratic approximation</article-title>, in <person-group person-group-type="editor"><string-name><given-names>J.</given-names> <surname>Shawe-Taylor</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Zemel</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bartlett</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Pereira</surname></string-name>, and <string-name><given-names>K.</given-names> <surname>Weinberger</surname></string-name></person-group>, eds., <source>Advances in Neural Information Processing Systems</source> <volume>24</volume>, <fpage>2330</fpage>&#x2013;<lpage>2338</lpage></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Hsieh</surname>, <given-names>C.-J.</given-names></string-name>, <string-name><surname>Sustik</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Dhillon</surname>, <given-names>I. S.</given-names></string-name>, <string-name><surname>Ravikumar</surname>, <given-names>P. K.</given-names></string-name>, and <string-name><surname>Poldrack</surname>, <given-names>R.</given-names></string-name> (<year>2013</year>), <source>Big &#x0026; quic: Sparse inverse covariance estimation for a million variables, in Advances in Neural Information Processing Systems</source> <issue>26</issue>, <fpage>3165</fpage>&#x2013;<lpage>3173</lpage></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Insel</surname>, <given-names>T. R.</given-names></string-name> (<year>2014</year>), <article-title>The nimh research domain criteria (rdoc) project: precision medicine for psychiatry</article-title>, <source>Am. J. Psychiatry</source>, <volume>171</volume>, <issue>4</issue>, <fpage>395</fpage>&#x2013;<lpage>397</lpage></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="other"><string-name><surname>Kaiser</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Andrews-Hanna</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, and <string-name><surname>Pizzagalli</surname>, <given-names>D. A.</given-names></string-name> (<year>2015</year>), <article-title>Large-scale network dysfunction in major depressive disorder a meta-analysis of resting-state functional connectivity</article-title>, <source>JAMA psychiatry</source></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="other"><string-name><surname>Kenward</surname>, <given-names>M. G.</given-names></string-name>, and <string-name><surname>Roger</surname>, <given-names>J. H.</given-names></string-name> (<year>1997</year>), <article-title>Small sample inference for fixed effects from restricted maximum likelihood</article-title>, <source>Biometrics</source>, <fpage>983</fpage>&#x2013;<lpage>997</lpage></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Keown</surname>, <given-names>C. L.</given-names></string-name>, <string-name><surname>Shih</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Nair</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Peterson</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mulvey</surname>, <given-names>M. E.</given-names></string-name>, and <string-name><surname>M&#x00FC;ller</surname>, <given-names>R.-A.</given-names></string-name> (<year>2013</year>), <article-title>Local functional overconnectivity in posterior brain regions is associated with symptom severity in autism spectrum disorders</article-title>, <source>Cell reports</source>, <volume>5</volume>, <issue>3</issue>, <fpage>567</fpage>&#x2013;<lpage>572</lpage></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wozniak</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Mueller</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Shen</surname>, <given-names>X.</given-names></string-name>, and <string-name><surname>Pan</surname>, <given-names>W.</given-names></string-name> (<year>2014</year>), <article-title>Comparison of statistical tests for group differences in brain functional networks</article-title>, <source>Neuroimage</source>, <volume>101</volume>, <fpage>681</fpage>&#x2013;<lpage>694</lpage></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Kleinman</surname>, <given-names>J. C.</given-names></string-name> (<year>1973</year>), <article-title>Proportions with extraneous variance: single and independent samples</article-title>, <source>JASA</source>, <volume>68</volume>, <issue>341</issue>, <fpage>46</fpage>&#x2013;<lpage>54</lpage></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Koenig</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Studer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hubl</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Melie</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Strik</surname>, <given-names>W.</given-names></string-name> (<year>2005</year>), <article-title>Brain connectivity at different time-scales measured with EEG</article-title>, <source>Phil. Trans. R. Soc. B</source>, <volume>360</volume>, <issue>1457</issue>, <fpage>1015</fpage>&#x2013;<lpage>1024</lpage>, doi:<pub-id pub-id-type="doi">10.1098/rstb.2005. 1649</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="other"><string-name><surname>Lahiri</surname>, <given-names>S. N.</given-names></string-name> (<year>2013</year>), <article-title>Resampling methods for dependent data (Springer Science &#x0026; Business Media)</article-title></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Laird</surname>, <given-names>N. M.</given-names></string-name>, and <string-name><surname>Ware</surname>, <given-names>J. H.</given-names></string-name> (<year>1982</year>), <article-title>Random-effects models for longitudinal data</article-title>, <source>Biometrics</source>, <volume>38</volume>, <issue>4</issue>, pp.<fpage>963</fpage>&#x2013;<lpage>974</lpage></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="other"><string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name>, <string-name><surname>Gordon</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Adeyemo</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Joo</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>M.-Y.</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>), <article-title>Functional system and areal organization of a highly sampled individual human brain</article-title>, <source>Neuron</source></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="book"><string-name><surname>Lauritzen</surname>, <given-names>S. L.</given-names></string-name> (<year>1996</year>), <source>Graphical models</source>, volume <volume>17</volume> (<publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>)</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="other"><string-name><surname>Lenroot</surname>, <given-names>R. K.</given-names></string-name>, and <string-name><surname>Yeung</surname>, <given-names>P. K.</given-names></string-name> (<year>2013</year>), <article-title>Heterogeneity within autism spectrum disorders: what have we learned from neuroimaging studies</article-title>?, <source>Front. Hum. Neurosci.</source>, <fpage>7</fpage></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Liang</surname>, <given-names>K.-Y.</given-names></string-name>, and <string-name><surname>Hanfelt</surname>, <given-names>J.</given-names></string-name> (<year>1994</year>), <article-title>On the use of the quasi-likelihood method in teratological experiments</article-title>., <source>Biometrics</source>, <volume>50</volume>, <issue>3</issue>, <fpage>872</fpage>&#x2013;<lpage>880</lpage></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Liang</surname>, <given-names>K.-Y.</given-names></string-name>, and <string-name><surname>Zeger</surname>, <given-names>S. L.</given-names></string-name> (<year>1993</year>), <article-title>Regression analysis for correlated data</article-title>, <source>Annual review of public health</source>, <volume>14</volume>, <issue>1</issue>, <fpage>43</fpage>&#x2013;<lpage>68</lpage></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="other"><string-name><surname>Liu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Roeder</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Wasserman</surname>, <given-names>L.</given-names></string-name> (<year>2010</year>), <article-title>Stability approach to regularization selection (stars) for high dimensional graphical models, in Advances in Neural Information Processing Systems</article-title></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="other"><string-name><surname>Lui</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Qiu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Kuang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Chan</surname>, <given-names>R. C.</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>), <article-title>Resting-state functional connectivity in treatment-resistant depression</article-title>, <source>Am. J. Psychiatry</source></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Marrelec</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Krainik</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Duffau</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>P&#x00E9;l&#x00E9;grini-Issac</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Leh&#x00E9;ricy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Doyon</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal> (<year>2006</year>), <article-title>Partial correlation for functional brain interactivity investigation in functional MRI</article-title>, <source>Neuroimage</source>, <volume>32</volume>, <issue>1</issue>, <fpage>228</fpage>&#x2013;<lpage>237</lpage></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Meda</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Gill</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Stevens</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Lorenzoni</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Glahn</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name>, <etal>et al.</etal> (<year>2012</year>), <article-title>Differences in resting-state functional magnetic resonance imaging functional network connectivity between schizophrenia and psychotic bipolar probands and their unaffected first-degree relatives</article-title>, <source>Biol. Psychiatry</source>, <volume>71</volume>, <issue>10</issue>, <fpage>881</fpage>&#x2013;<lpage>889</lpage></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Meinshausen</surname>, <given-names>N.</given-names></string-name> and <string-name><surname>B&#x00FC;hlmann</surname>, <given-names>P.</given-names></string-name> (<year>2006</year>), <article-title>High-dimensional graphs and variable selection with the lasso</article-title>, <source>Ann. Stat.</source>, <volume>34</volume>, <issue>3</issue>, <fpage>1436</fpage>&#x2013;<lpage>1462</lpage></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Meinshausen</surname>, <given-names>N.</given-names></string-name> and <string-name><surname>Buhlmann</surname>, <given-names>P.</given-names></string-name> (<year>2010</year>), <article-title>Stability selection</article-title>, <source>J. Roy. Statist. Soc. Ser. B Stat. Methodol.</source>, <volume>72</volume>, <issue>4</issue>, <fpage>417</fpage>&#x2013;<lpage>473</lpage></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Menon</surname>, <given-names>V.</given-names></string-name> (<year>2011</year>), <article-title>Large-scale brain networks and psychopathology: a unifying triple network model</article-title>, <source>Trends in cognitive sciences</source>, <volume>15</volume>, <issue>10</issue>, <fpage>483</fpage>&#x2013;<lpage>506</lpage></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Monk</surname>, <given-names>C. S.</given-names></string-name>, <string-name><surname>Peltier</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Wiggins</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Weng</surname>, <given-names>S.-J.</given-names></string-name>, <string-name><surname>Carrasco</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Risi</surname>, <given-names>S.</given-names></string-name>, <etal>et al.</etal> (<year>2009</year>), <article-title>Abnormalities of intrinsic functional connectivity in autism spectrum disorders</article-title>, <source>Neuroimage</source>, <volume>47</volume>, <issue>2</issue>, <fpage>764</fpage>&#x2013;<lpage>772</lpage></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Murphy</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Birn</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Handwerker</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>T. B.</given-names></string-name>, and <string-name><surname>Bandettini</surname>, <given-names>P. A.</given-names></string-name> (<year>2009</year>), <article-title>The impact of global signal regression on resting state correlations: are anti-correlated networks introduced?</article-title>, <source>Neuroimage</source>, <volume>44</volume>, <issue>3</issue>, <fpage>893</fpage>&#x2013;<lpage>905</lpage></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="other"><string-name><surname>Narayan</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Allen</surname>, <given-names>G. I.</given-names></string-name> (<year>2013</year>), <article-title>Randomized approach to differential inference in multi-subject functional connectivity, in Pattern Recognition in Neuroimaging (PRNI)</article-title>, <source>2013 International Workshop on (IEEE)</source>, <fpage>78</fpage>&#x2013;<lpage>81</lpage></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Narayan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Allen</surname>, <given-names>G. I.</given-names></string-name>, and <string-name><surname>Tomson</surname>, <given-names>S.</given-names></string-name> (<year>2015</year>), <article-title>Two sample inference for populations of graphical models with applications to functional brain connectivity</article-title>, <source>arXiv preprint arXiv</source>:<volume>1502</volume>.<fpage>03853</fpage></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Palaniyappan</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Simmonite</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>White</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Liddle</surname>, <given-names>E. B.</given-names></string-name>, and <string-name><surname>Liddle</surname>, <given-names>P. F.</given-names></string-name> (<year>2013</year>), <article-title>Neural primacy of the salience processing system in schizophrenia</article-title>, <source>Neuron</source>, <volume>79</volume>, <issue>4</issue>, <fpage>814</fpage>&#x2013;<lpage>828</lpage></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="other"><string-name><surname>Politis</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Romano</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Wolf</surname>, <given-names>M.</given-names></string-name> (<year>1999</year>), <article-title>Subsampling</article-title></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Lessov-Schlaggar</surname>, <given-names>C. N.</given-names></string-name>, and <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name> (<year>2013</year>), <article-title>Evidence for hubs in human functional brain networks</article-title>, <source>Neuron</source>, <volume>79</volume>, <issue>4</issue>, <fpage>798</fpage>&#x2013;<lpage>813</lpage></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Ravikumar</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Wainwright</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Raskutti</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Yu</surname>, <given-names>B.</given-names></string-name> (<year>2011</year>), <article-title>High-dimensional covariance estimation by minimizing <italic>&#x2113;</italic><sub>1</sub>-penalized log-determinant divergence</article-title>, <source>Electron. J. Stat.</source>, <volume>5</volume>, <fpage>935</fpage>&#x2013;<lpage>980</lpage></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Rothman</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Bickel</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Levina</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal> (<year>2008</year>), <article-title>Sparse permutation invariant covariance estimation</article-title>, <source>Electron. J. Stat.</source>, <volume>2</volume>, <fpage>494</fpage>&#x2013;<lpage>515</lpage></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Rubinov</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name> (<year>2010</year>), <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>, <source>Neuroimage</source>, <volume>52</volume>, <issue>3</issue>, <fpage>1059</fpage>&#x2013;<lpage>1069</lpage></mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="other"><string-name><surname>Rudie</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Beck-Pancer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hernandez</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Dennis</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Thompson</surname>, <given-names>P.</given-names></string-name>, <etal>et al.</etal> (<year>2012a</year>), <article-title>Altered functional and structural brain network organization in autism</article-title>, <source>NeuroImage: Clinical</source></mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Rudie</surname>, <given-names>J. D.</given-names></string-name>, and <string-name><surname>Dapretto</surname>, <given-names>M.</given-names></string-name> (<year>2013</year>), <article-title>Convergent evidence of brain overconnectivity in children with autism?</article-title>, <source>Cell reports</source>, <volume>5</volume>, <issue>3</issue>, <fpage>565</fpage>&#x2013;<lpage>566</lpage></mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><string-name><surname>Rudie</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Shehzad</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Hernandez</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Colich</surname>, <given-names>N. L.</given-names></string-name>, <string-name><surname>Bookheimer</surname>, <given-names>S. Y.</given-names></string-name>, <string-name><surname>Iacoboni</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> (<year>2012b</year>), <article-title>Reduced functional integration and segregation of distributed neural systems underlying social and emotional information processing in autism spectrum disorders</article-title>, <source>Cereb. Cortex</source>, <volume>22</volume>, <issue>5</issue>, <fpage>1025</fpage>&#x2013;<lpage>1037</lpage></mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Sato</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Takahashi</surname>, <given-names>D. Y.</given-names></string-name>, <string-name><surname>Arcuri</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Sameshima</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Morettin</surname>, <given-names>P. A.</given-names></string-name>, and <string-name><surname>Baccal&#x00E1;</surname>, <given-names>L. A.</given-names></string-name> (<year>2009</year>), <article-title>Frequency domain connectivity identification: An application of partial directed coherence in fmri</article-title>, <source>Hum. Brain Mapp.</source>, <volume>30</volume>, <issue>2</issue>, <fpage>452</fpage>&#x2013;<lpage>461</lpage>, doi:<pub-id pub-id-type="doi">10.1002/hbm.20513</pub-id></mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><string-name><surname>Schelter</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Winterhalder</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Eichler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Peifer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hellwig</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Guschlbauer</surname>, <given-names>B.</given-names></string-name>, <etal>et al.</etal> (<year>2006</year>), <article-title>Testing for directed influences among neural signals using partial directed coherence</article-title>, <source>J. Neurosci. Methods</source>, <volume>152</volume>, <issue>1&#x00C4;&#x00EC;2</issue>, <fpage>210</fpage>&#x2013;<lpage>219</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.jneumeth.2005.09.001</pub-id></mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="book"><string-name><surname>Searle</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Casella</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>McCulloch</surname>, <given-names>C. E.</given-names></string-name> (<year>2009</year>), <chapter-title>Variance components</chapter-title>, volume <volume>391</volume> (<publisher-name>Wiley-Interscience</publisher-name>)</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><string-name><surname>Shehzad</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kelly</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Reiss</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Gee</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Gotimer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <etal>et al.</etal> (<year>2009</year>), <article-title>The resting brain: unconstrained yet reliable</article-title>, <source>Cereb. Cortex</source>, <volume>19</volume>, <issue>10</issue>, <fpage>2209</fpage>&#x2013;<lpage>2229</lpage></mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><string-name><surname>Simpson</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Bowman</surname>, <given-names>F. D.</given-names></string-name>, <string-name><surname>Laurienti</surname>, <given-names>P. J.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Analyzing complex functional brain networks: fusing statistics and network science to understand the brain</article-title>, <source>Statistics Surveys</source>, <volume>7</volume>, <fpage>1</fpage>&#x2013;<lpage>36</lpage></mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Salimi-Khorshidi</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Webster</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name>, <etal>et al.</etal> (<year>2011</year>), <article-title>Network modelling methods for FMri</article-title>, <source>Neuroimage</source>, <volume>54</volume>, <issue>2</issue>, <fpage>875</fpage>&#x2013;<lpage>891</lpage></mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Vidaurre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Functional connectomics from resting-state fmri</article-title>, <source>Trends Cogn. Sci.</source>, <volume>17</volume>, <issue>12</issue>, <fpage>666</fpage>&#x2013;<lpage>682</lpage></mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><string-name><surname>Supekar</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <string-name><surname>Khouzam</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gaillard</surname>, <given-names>W. D.</given-names></string-name>, <string-name><surname>Kenworthy</surname>, <given-names>L. E.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Brain hyperconnectivity in children with autism and its links to social deficits</article-title>, <source>Cell reports</source>, <volume>5</volume>, <issue>3</issue>, <fpage>738</fpage>&#x2013;<lpage>747</lpage></mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><string-name><surname>Tam</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Orban</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Dansereau</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Belleville</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Benoit</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dagher</surname>, <given-names>A.</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>), <article-title>Connectome-wide analysis of differences between normal aging, mild cognitive impairment, and dementia of the alzheimer&#x2019;s type using resting-state FMri connectivity</article-title>, <source>Alzheimer&#x2019;s &#x0026; Dementia: The Journal of the Alzheimer&#x2019;s Association</source>, <volume>10</volume>, <issue>4</issue>, <fpage>P827</fpage>&#x2013;<lpage>P828</lpage></mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><string-name><surname>Tao</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ge</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kendrick</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Xue</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Z.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Depression uncouples brain hate circuit</article-title>, <source>Mol. Psychiatry</source>, <volume>18</volume>, <issue>1</issue>, <fpage>101</fpage>&#x2013;<lpage>111</lpage></mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><string-name><surname>Tomson</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Narayan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Allen</surname>, <given-names>G. I.</given-names></string-name>, and <string-name><surname>Eagleman</surname>, <given-names>D. M.</given-names></string-name> (<year>2013</year>), <article-title>Neural networks of colored sequence synesthesia</article-title>, <source>J. Neurosci.</source>, <volume>33</volume>, <issue>35</issue>, <fpage>14098</fpage>&#x2013;<lpage>14106</lpage></mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="other"><string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name> (<year>2014</year>), <article-title>Salience processing and insular cortical function and dysfunction</article-title>, <source>Nat. Rev. Neurosci</source>.</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <string-name><surname>Supekar</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Lynch</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Khouzam</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Feinstein</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal> (<year>2013a</year>), <article-title>Salience network-based classification and prediction of symptom severity in children with autism</article-title>, <source>JAMA psychiatry</source>, <volume>70</volume>, <issue>8</issue>, <fpage>869</fpage>&#x2013;<lpage>879</lpage></mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="other"><string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <string-name><surname>Supekar</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Menon</surname>, <given-names>V.</given-names></string-name> (<year>2013b</year>), <article-title>Reconceptualizing functional brain connectivity in autism from a developmental perspective</article-title>, <source>Front. Hum. Neurosci.</source>, <fpage>7</fpage></mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><string-name><surname>van den Heuvel</surname>, <given-names>M. P.</given-names></string-name>, and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name> (<year>2011</year>), <article-title>Rich-club organization of the human connectome</article-title>, <source>J. Neurosci.</source>, <volume>31</volume>, <issue>44</issue>, <fpage>15775</fpage>&#x2013;<lpage>15786</lpage></mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="other"><string-name><surname>van den Heuvel</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Collin</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Scheewe</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Mandl</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Cahn</surname>, <given-names>W.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>), <article-title>Abnormal rich club organization and functional brain dynamics in schizophrenia</article-title>, <source>JAMA Psychiatry</source>, <fpage>1</fpage>&#x2013;<lpage>10</lpage></mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><string-name><surname>Van Dijk</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Hedden</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Venkataraman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Evans</surname>, <given-names>K. C.</given-names></string-name>, <string-name><surname>Lazar</surname>, <given-names>S. W.</given-names></string-name>, and <string-name><surname>Buckner</surname>, <given-names>R. L.</given-names></string-name> (<year>2010</year>), <article-title>Intrinsic functional connectivity as a tool for human connectomics: theory, properties, and optimization</article-title>, <source>J. Neurophysiol.</source>, <volume>103</volume>, <issue>1</issue>, <fpage>297</fpage>&#x2013;<lpage>321</lpage></mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="other"><string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Poline</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name> (<year>2012</year>), <article-title>Markov models for fmri correlation structure: is brain functional connectivity small world, or decomposable into networks</article-title>?, <source>Journal of Physiology-Paris</source></mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nan</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Rosset</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Zhu</surname>, <given-names>J.</given-names></string-name> (<year>2011</year>), <article-title>Random lasso</article-title>, <source>Ann. Appl. Stat.</source>, <volume>5</volume>, <issue>1</issue>, <fpage>468</fpage></mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><string-name><surname>Warren</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Bruss</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Denburg</surname>, <given-names>N. L.</given-names></string-name>, <string-name><surname>Waldron</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>H.</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>), <article-title>Network measures predict neuropsychological outcome after brain injury</article-title>, <source>Proc. Natl. Acad. Sci. U.S.A.</source>, <volume>111</volume>, <issue>39</issue>, <fpage>14247</fpage>&#x2013;<lpage>14252</lpage></mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="other"><string-name><surname>Williams</surname>, <given-names>D. A.</given-names></string-name> (<year>1982</year>), <article-title>Extra-binomial variation in logistic linear models</article-title>, <source>Applied statistics</source>, <fpage>144</fpage>&#x2013;<lpage>148</lpage></mixed-citation></ref>
<ref id="c99"><mixed-citation publication-type="journal"><string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Ripley</surname>, <given-names>B. D.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name> (<year>2001</year>), <article-title>Temporal autocorrelation in univariate linear modeling of FMri data</article-title>, <source>Neuroimage</source>, <volume>14</volume>, <issue>6</issue>, <fpage>1370</fpage>&#x2013;<lpage>1386</lpage></mixed-citation></ref>
<ref id="c100"><mixed-citation publication-type="journal"><string-name><surname>Worsley</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Liao</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Aston</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Petre</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Morales</surname>, <given-names>F.</given-names></string-name>, <etal>et al.</etal> (<year>2002</year>), <article-title>A general statistical analysis for fmri data</article-title>, <source>Neuroimage</source>, <volume>15</volume>, <issue>1</issue>, <fpage>1</fpage>&#x2013;<lpage>15</lpage></mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="journal"><string-name><surname>Yeo</surname>, <given-names>B. T. T.</given-names></string-name>, <string-name><surname>Krienen</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Sepulcre</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sabuncu</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Lashkari</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hollinshead</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> (<year>2011</year>), <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>, <source>J. Neurophysiol.</source>, <volume>106</volume>, <issue>3</issue>, <fpage>1125</fpage>&#x2013;<lpage>1165</lpage></mixed-citation></ref>
<ref id="c102"><mixed-citation publication-type="journal"><string-name><surname>Yuan</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Lin</surname>, <given-names>Y.</given-names></string-name> (<year>2007</year>), <article-title>Model selection and estimation in the gaussian graphical model</article-title>, <source>Biometrika</source>, <volume>94</volume>, <issue>1</issue>, <fpage>19</fpage>&#x2013;<lpage>35</lpage></mixed-citation></ref>
<ref id="c103"><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>R&#x00FC;timann</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>B&#x00FC;hlmann</surname>, <given-names>P.</given-names></string-name> (<year>2011</year>), <article-title>High-dimensional covariance estimation based on Gaussian graphical models</article-title>, <source>JMLR</source>, <volume>12</volume>, <fpage>2975</fpage>&#x2013;<lpage>3026</lpage></mixed-citation></ref>
<ref id="c104"><mixed-citation publication-type="journal"><string-name><surname>Zuo</surname>, <given-names>X.-N.</given-names></string-name>, <string-name><surname>Ehmke</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Mennes</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Imperati</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name>, <etal>et al.</etal> (<year>2012</year>), <article-title>Network centrality in the human functional connectome</article-title>, <source>Cereb. Cortex</source>, <volume>22</volume>, <issue>8</issue>, <fpage>1862</fpage>&#x2013;<lpage>1875</lpage></mixed-citation></ref>
</ref-list>
<sec id="s7a"><label>A</label><title>SUPPLEMENTARY SIMULATIONS &#x0026; FIGURES</title>
<p>In this appendix, we provide supplementary simulations and figures to complement the power analyses and summary of type-I error control that appear in <xref ref-type="fig" rid="fig3">Figures 3</xref>,<xref ref-type="fig" rid="fig4">4</xref> &#x0026; <xref ref-type="fig" rid="fig5">5</xref> of our manuscript. The setup for the supplementary simulations follows the procedures outlined in <xref ref-type="sec" rid="s4a">Section 4.1</xref>. <xref ref-type="fig" rid="figA1">Figures A.1</xref> &#x0026; <xref rid="figA2" ref-type="fig">A.2</xref> provide a complete set of type-I error simulations for node and subnetwork density, respectively, and complement the power analyses found in <xref ref-type="fig" rid="fig3">Figures 3</xref> &#x0026; <xref ref-type="fig" rid="fig4">4</xref>. Additionally, we demonstrate the impact of sparsity on the ability of R<sup>3</sup>, R<sup>2</sup> and the standard method to detect covariate effects in <xref ref-type="fig" rid="figA3">Figure A.3</xref>. Here, we employ the node density metric in the medium SNR case (<italic>v</italic><sup>2</sup> &#x003D; .25) as a representative example, while holding all other parameters consistent with <xref ref-type="fig" rid="fig3">Figure 3</xref> of the manuscript constant with exception of baseline sparsity threshold <italic>&#x03C4;</italic>. While the simulations in our manuscript employed realistic networks obtained by setting all partial correlations whose absolute values were less than <italic>&#x03C4;</italic> &#x003D; .25 to zero, we varied this threshold to values &#x007B;.1, .4&#x007D; to obtain both denser and sparser baseline networks.</p>
<p>The supplementary simulations in <xref ref-type="fig" rid="figA1">Figures A.1</xref> &#x0026; <xref rid="figA2" ref-type="fig">A.2</xref> are consistent with <xref ref-type="fig" rid="fig5">Figure 5</xref> of our manuscript, and demonstrate that all methods approximately control type-I error at the 5&#x0025; level. In <xref ref-type="fig" rid="figA3">Figure A.3</xref>, as expected, statistical power decreases with smaller sample sizes, especially when <italic>t</italic> &#x2248; <italic>p</italic>. In the sparser baseline case, our methods, R<sup>3</sup> and R<sup>2</sup>, are able to achieve better statistical power to detect covariate effects over standard F-tests. In the sparser network case, it is easier to estimate subject networks even in low sample sizes of <italic>t</italic> &#x2248; <italic>p</italic>, and initial stability scores continue to discriminate between true and false edges more effectively than in denser network regimes. Since the benefits of adaptive estimation depend on initial network estimates, we observe that the random adaptive penalization component of R<sup>3</sup> improves the estimates of network metrics, thus achieving greater statistical power than R<sup>2</sup> in sparser network regimes with small sample sizes. However, when baseline networks become denser, particularly when <italic>&#x03C4;</italic> &#x003D; .10, the ability of all methods to detect covariate effects begin to fail as within subject sample sizes reduce to <italic>t</italic> &#x2248; <italic>p</italic>. Overall our supplementary simulations continue to highlight the importance of within subject sample size <italic>t</italic>, and the benefits of our methods, R<sup>3</sup> and R<sup>2</sup> over the standard approach at smaller sample sizes.</p>
<fig id="figA1" position="float" orientation="portrait" fig-type="figure">
<label>Figure A.1.</label>
<caption><title>Statistical Type I Error Control for Node Density.</title>
<p>These simulations evaluate the level of our tests; we report the estimated type-I error as a function of subject sample size <italic>n</italic>. The grey line represents the 5&#x0025; level of the test. Here, we provide a complete set of Type-1 error simulations to complement the power analysis in <xref ref-type="fig" rid="fig3">Figure 3</xref>. All methods approximately control type I error across all scenarios studied for node density.</p></caption>
<graphic xlink:href="027516_figA1.tif"/>
</fig>
<fig id="figA2" position="float" orientation="portrait" fig-type="figure">
<label>Figure A.2.</label>
<caption><title>Statistical Type I Error Control for Subnetwork Density.</title>
<p>These simulations evaluate the level of our tests; we report the estimated type-I error as a function of subject sample size <italic>n</italic>. The grey line represents the 5&#x0025; level of the test. Here, we provide a complete set of Type-1 error simulations to complement the power analysis in <xref ref-type="fig" rid="fig4">Figure 4</xref>. All methods approximately control type I error across all scenarios studied for subnetwork density.</p></caption>
<graphic xlink:href="027516_figA2.tif"/>
</fig>
<fig id="figA3" position="float" orientation="portrait" fig-type="figure">
<label>Figure A.3.</label>
<caption><title>Statistical Power Analysis with Varying Baseline Sparsity.</title>
<p>This figure complements the power analysis for node density in <xref ref-type="fig" rid="fig3">Figure 3</xref> of the manuscript for the medium SNR case (<italic>v</italic><sup>2</sup> &#x003D; .25), where the number of nodes is <italic>p</italic> &#x003D; 50. Whereas the baseline pseudo-real networks in <xref ref-type="fig" rid="fig3">Figure 3</xref> consist of edges whose absolute partial correlation strength was greater than <italic>&#x03C4;</italic> &#x003D; .25, here we consider simulations where the baseline density is decreased (<italic>&#x03C4;</italic> &#x003D; .40) as well as increased (<italic>&#x03C4;</italic> &#x003D; .10). Notice that for the sparse baseline network, our results broadly match those of <xref ref-type="fig" rid="fig3">Figure 3</xref>. When node density varies with an explanatory covariate (<italic>q</italic> &#x003D; 1), statistical power to detect this covariate effect improves with subject sample size <italic>n</italic> but crucially depends on the number of independent fMRI samples <italic>t</italic> from a single session. When networks are hard to estimate at limited within subject sample sizes <italic>t</italic> &#x2248; <italic>p</italic>, we expect estimates of node density to be both highly variable and potentially biased. However, as long as the baseline networks are sufficiently sparse, we can account for these errors via our methods R<sup>3</sup> and R<sup>2</sup>. In fact, R<sup>3</sup> achieves near perfect statistical power by adaptively improving the network metrics estimates of R<sup>2</sup>, thus improving statistical power over <italic>R</italic><sup>2</sup> and standard F-tests. In contrast, when baseline graphs are dense, and the sample sizes approach (<italic>t</italic> &#x2248; <italic>p</italic>), it becomes impossible to detect covariate effects. Thus, within subject sample sizes continue to be crucial for detecting covariate effects</p></caption>
<graphic xlink:href="027516_figA3.tif"/>
</fig></sec>
<sec id="s7b"><label>B</label><title>TEST STATISTICS FOR R<sup>3</sup> AND R<sup>2</sup></title>
<p>R<sup>3</sup> and R<sup>2</sup> model resampled network metrics using repeated measures mixed effects models to account for two levels of variation in continuous network metrics. In this appendix, we begin with some elementary estimators and test statistics for covariate effects in the linear mixed effect (LME) model defined in <xref ref-type="disp-formula" rid="eqn9">Eq. (9</xref>) &#x0026; <xref ref-type="disp-formula" rid="eqn10">(10)</xref> in <xref ref-type="sec" rid="s2c">Section 2.3</xref> of our manuscript. Additionally, in <xref ref-type="sec" rid="s7b2">Section B.2</xref> we provide alternatives to the LME models in <xref ref-type="sec" rid="s2c3">Section 2.3.3</xref> of our manuscript for two levels of binary valued resampled statistics. As in the case of LME models, we outline relevant correlated binomial models and corresponding estimators for covariate effects.</p>
<sec id="s7b1"><label>B.1</label><title>ESTIMATORS FOR REPEATED MEASURES LME</title>
<p>Many estimators <xref ref-type="bibr" rid="cS1"><bold>Agresti</bold> [2015]</xref> are available to estimate fixed effects for LME models, where the number of resamples within each subject is complete and balanced. We employ a generalization of ordinary least squares regression for correlated two-level data given by weighted least squares estimators (GLS) <xref ref-type="bibr" rid="cS1"><bold>Agresti</bold> [2015]</xref>. Ideally, in order to make the least square residuals independent we weight the residuals by the precision matrix, <italic>V<sub>i</sub></italic><sup>&#x2212;1</sup>, to obtain efficient estimates of <italic>&#x03B2;</italic>.</p>
<p>We redefine the earlier notation in <xref ref-type="sec" rid="s2a">Section 2.1</xref> for the population model to account for the availability of resampled network metrics. We denote the overall design matrix by <bold>W</bold> &#x003D; [<italic>W</italic><sub>1</sub> &#x2026; <italic>W<sub>n</sub></italic>]<sup>&#x22A4;</sup>. Here <italic>W<sub>i</sub></italic> is the <italic>B</italic> &#x00D7; (1 &#x002B; <italic>q</italic> &#x002B; <italic>r</italic>) subject level design matrix for the fixed effects, obtained by stacking centered and scaled explanatory and nuisance covariates [<italic>X<sub>i</sub> Z<sub>i</sub></italic>]. Let c denote a contrast vector to separate explanatory and nuisance covariates of interest such that <italic>c</italic> &#x003D; [0 1<sub>1&#x00D7;</sub><italic><sub>q</sub></italic> 0<sub>1&#x00D7;</sub><italic><sub>r</sub></italic>] and <italic>c</italic><sup>&#x22A4;</sup>[<italic>&#x03B2; &#x03B3;</italic>] &#x003D; <italic>&#x03B2;</italic><sub>&#x005C;0</sub>. We omit the subscript excluding the intercept when referring to <italic>&#x03B2;</italic><sub>&#x005C;0</sub> in this section. Here <italic>B</italic> denotes the number of resamples, <italic>n</italic> the number of subjects, <italic>q</italic> and <italic>r</italic> the number of explanatory and nuisance covariates, respectively.</p>
<p>Thus, the fixed effects estimate takes the form <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline51.gif"/></alternatives></inline-formula>. The corresponding partial Wald statistic for explanatory fixed effects is given by</p>
<disp-formula id="eqnB1">
<alternatives><graphic xlink:href="027516_eqnB1.gif"/></alternatives></disp-formula>
<p>Since our two level model in <xref ref-type="sec" rid="s2c3">Section 2.3.3</xref> is a random intercept model for repeated measures, <italic>V<sub>i</sub></italic><sup>&#x2212;1</sup> has compound symmetry structure and depends on two unknown parameters (<italic>v</italic><sup>2</sup>,<italic>&#x03D5;</italic><sup>2</sup>) that do not vary with subjects <italic>i</italic>. Consequently standard ANOVA and restricted maximum likelihood estimators for variance components, <italic>&#x03D5;</italic>, <italic>v</italic> coincide [<xref ref-type="bibr" rid="cS5"><bold>Searle et al</bold>., 2009</xref>], given by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline52.gif"/></alternatives></inline-formula> and<inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline53.gif"/></alternatives></inline-formula>. While Wald-type test statistics are asymptomtically <italic>&#x03C7;</italic><sup>2</sup> distributed, they are better approximated by scaled F-distributions at finite samples. Finite sample corrections and estimates of the degrees of freedom for these F-distributions, provided by <xref ref-type="bibr" rid="c46"><bold>Kenward and Roger</bold> [1997]</xref>, are widely adopted for inference in LME models to ensure better type-I error control. For more details on computational procedures and extensions to these models for more complex experimental designs, we refer the reader to <xref ref-type="bibr" rid="cS1"><bold>Agresti</bold> [2015]</xref>.</p></sec>
<sec id="s7b2"><label>B.2</label><title>MIXED EFFECTS MODELS FOR CORRELATED BINARY DATA</title>
<p>As in the case of continuous metrics, when R<sup>2</sup> and R<sup>3</sup> produce resampled binary network statistics per subject, our data possesses two levels of variability. Although such statistics can be summarized using proportions <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline54.gif"/></alternatives></inline-formula> per subject, we cannot model these correlated proportions using binomial distributions, as the binomial assumes all <italic>nB</italic> &#x00D7; 1 binary valued resampled statistics to be independent. In fact, we expect the resampled statistics within each subject to be positively correlated. To resolve this problem, following the well established literature [<xref ref-type="bibr" rid="cS4"><bold>Liang and Hanfelt</bold>, 1994</xref>; <xref ref-type="bibr" rid="cS1"><bold>Agresti</bold>, 2015</xref>], we consider two-level models for correlated binary data.</p>
<p>To understand binomial models for correlated data, consider the example of the probability of observing an edge as the network metric of interest. Recall, from <xref ref-type="disp-formula" rid="eqn6">Eq.(6)</xref> that we seek to conduct inference over the fixed effect <italic>&#x03B2;</italic> which describes the rate of change in the subject edge probability in a population logit <italic>&#x03C0;<sub>i</sub></italic> &#x003D; <italic>&#x03B7;<sub>i</sub></italic> &#x003D; <italic>X&#x03B2;</italic> &#x002B; <italic>Z&#x03B3;</italic> for a unit change in the covariate [<xref ref-type="bibr" rid="cS6"><bold>Williams</bold>, 1982</xref>]. However we only observe network metrics for a sample of subjects in the population. To account for this inter-subject sampling variability, we introduce a continuous latent random variable <italic>P<sub>i</sub></italic> that takes values in the interval [0,1]. Additionally, however, we do not observe individual subject edge probabilities <italic>P<sub>i</sub></italic> but rather observe binary network statistics per subject. Thus, conditional on a subject&#x2019;s true edge probability <italic>P<sub>i</sub></italic>, we assume that each resampled network statistic <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline55.gif"/></alternatives></inline-formula>is Bernoulli distributed, such that <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline56.gif"/></alternatives></inline-formula>. Together, this gives us the following model for the observed proportions <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline57.gif"/></alternatives></inline-formula></p>
<disp-formula id="eqnB2">
<alternatives><graphic xlink:href="027516_eqnB2.gif"/></alternatives></disp-formula>
<p>By employing this two-level model, we account for overdispersion in correlated resampled statistics in the form of the multiplicative correction term [1 &#x002B; <italic>&#x03D5;</italic>(<italic>B</italic> &#x2212; 1)]. Note that, while we can specify a fully parametric model for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline58.gif"/></alternatives></inline-formula> using beta or correlated binomial distributions, specifying the first and second moments is adequate [<xref ref-type="bibr" rid="cS6"><bold>Williams</bold>, 1982</xref>; <xref ref-type="bibr" rid="cS5"><bold>Searle et al</bold>., 2009</xref>] for the estimation and inference of fixed effects.</p>
<p>In the presence of balanced within subject resamples <italic>B</italic>, our two-level model (<xref ref-type="disp-formula" rid="eqnB2">B.2</xref>) is very similar to our single level logistic-linear model in (6) with the exception of the additional overdispersion factor (1 &#x002B; <italic>&#x03D5;</italic>(<italic>B</italic> &#x2212; 1)). Thus, standard iterative reweighted least squares estimation can be used to obtain estimates of fixed effects <italic>&#x03B2;</italic>, <italic>&#x03B3;</italic> and moment estimators for <italic>&#x03D5;</italic> [<xref ref-type="bibr" rid="c49"><bold>Kleinman</bold>, 1973</xref>; <xref ref-type="bibr" rid="cS6"><bold>Williams</bold>, 1982</xref>]. We proceed with inference for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline59.gif"/></alternatives></inline-formula>, using Wald type statistics in (<xref ref-type="disp-formula" rid="eqnB1">B.1</xref>), by ensuring that standard sample variance estimates for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="027516_inline60.gif"/></alternatives></inline-formula> incorporate the overdispersion factor. In the absence of balanced data, or for more complex experimental designs such as longitudinal imaging studies we recommend the maximum quasi-likelihood or generalized estimating equations [<xref ref-type="bibr" rid="cS4"><bold>Liang and Hanfelt</bold>, 1994</xref>] for correlated binary data.</p></sec></sec>
<ref-list><title>REFERENCES</title>
<ref id="cS1"><mixed-citation publication-type="book"><string-name><surname>Agresti</surname>, <given-names>A.</given-names></string-name> (<year>2015</year>), <chapter-title>Foundations of Linear and Generalized Linear Models</chapter-title> (<publisher-name>John Wiley &#x0026; Sons</publisher-name>)</mixed-citation></ref>
<ref id="cS2"><mixed-citation publication-type="other"><string-name><surname>Kenward</surname>, <given-names>M. G.</given-names></string-name>, and <string-name><surname>Roger</surname>, <given-names>J. H.</given-names></string-name> (<year>1997</year>), <article-title>Small sample inference for fixed effects from restricted maximum likelihood</article-title>, <source>Biometrics</source>, <fpage>983</fpage>&#x2013;<lpage>997</lpage></mixed-citation></ref>
<ref id="cS3"><mixed-citation publication-type="journal"><string-name><surname>Kleinman</surname>, <given-names>J. C.</given-names></string-name> (<year>1973</year>), <article-title>Proportions with extraneous variance: single and independent samples</article-title>, <source>JASA</source>, <volume>68</volume>, <issue>341</issue>, <fpage>46</fpage>&#x2013;<lpage>54</lpage></mixed-citation></ref>
<ref id="cS4"><mixed-citation publication-type="journal"><string-name><surname>Liang</surname>, <given-names>K.-Y.</given-names></string-name>, and <string-name><surname>Hanfelt</surname>, <given-names>J.</given-names></string-name> (<year>1994</year>), <article-title>On the use of the quasi-likelihood method in teratological experiments</article-title>., <source>Biometrics</source>, <volume>50</volume>, <issue>3</issue>, <fpage>872</fpage>&#x2013;<lpage>880</lpage></mixed-citation></ref>
<ref id="cS5"><mixed-citation publication-type="book"><string-name><surname>Searle</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Casella</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>McCulloch</surname>, <given-names>C. E.</given-names></string-name> (<year>2009</year>), <source>Variance components</source>, volume <volume>391</volume> (<publisher-loc>Wiley-Interscience</publisher-loc>)</mixed-citation></ref>
<ref id="cS6"><mixed-citation publication-type="other"><string-name><surname>Williams</surname>, <given-names>D. A.</given-names></string-name> (<year>1982</year>), <article-title>Extra-binomial variation in logistic linear models</article-title>, <source>Applied statistics</source>, <fpage>144</fpage>&#x2013;<lpage>148</lpage></mixed-citation></ref>
</ref-list>
</back>
</article>