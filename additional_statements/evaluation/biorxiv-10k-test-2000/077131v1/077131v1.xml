<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/077131</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Fixing the stimulus-as-fixed-effect fallacy in task fMRI</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Westfall</surname><given-names>Jacob</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Nichols</surname><given-names>Thomas E.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Yarkoni</surname><given-names>Tal</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, University of Texas at Austin</institution></aff>
<aff id="a2"><label>2</label><institution>Department of Statistics &#x0026; WMG, University of Warwick</institution>, Coventry, CV4 7AL</aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>&#x2020;</label><p>Contributed equally to this work</p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2016</year>
</pub-date>
<elocation-id>077131</elocation-id>
<history>
<date date-type="received"><day>23</day><month>9</month><year>2016</year></date>
<date date-type="accepted"><day>25</day><month>9</month><year>2016</year></date>
</history><permissions><copyright-statement>&#x00A9; 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2016</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="077131.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract><title>Abstract</title>
<p>Most fMRI experiments record the brain&#x2019;s responses to samples of stimulus materials (e.g., faces or words). Yet the statistical modeling approaches used in fMRI research universally fail to model stimulus variability in a manner that affords population generalization--meaning that researchers&#x2019; conclusions technically apply only to the precise stimuli used in each study, and cannot be generalized to new stimuli. A direct consequence of this <italic>stimulus-as-fixed-effect fallacy</italic> is that the majority of published fMRI studies have likely overstated the strength of the statistical evidence they report. Here we develop a Bayesian mixed model (the random stimulus model; RSM) that addresses this problem, and apply it to a range of fMRI datasets. Results demonstrate considerable inflation (50 - 200&#x0025; in most of the studied datasets) of test statistics obtained from standard &#x201C;summary statistics&#x201D;-based approaches relative to the corresponding RSM models. We demonstrate how RSMs can be used to improve parameter estimates, properly control false positive rates, and test novel research hypotheses about stimulus-level variability in human brain responses.</p>
</abstract>
<counts>
<page-count count="36"/>
</counts>
</article-meta>
</front>
<body>
<p>Consider two potential titles of a hypothetical neuroimaging paper: (1) &#x201C;Inferior frontal gyrus responds more strongly to the words &#x2018;chair,&#x2019; &#x2018;house,&#x2019; and &#x2018;tree&#x2019; than to &#x2018;run,&#x2019; &#x2018;pay,&#x2019; and &#x2018;speak&#x2019;&#x201D;; and (2) &#x201C;Inferior frontal gyrus responds more strongly to nouns than to verbs&#x0022;. These two titles may superficially appear to describe exactly the same set of findings, since categories like Noun and Verb are necessarily comprised entirely of individual exemplars like &#x2018;chair&#x2019; and &#x2018;speak&#x2019;. Yet there can be little doubt that most neuroimaging researchers forced to choose between the two titles above would opt for the latter--which makes a far more interesting scientific statement. After all, we typically do not care about individual words like &#x2018;chair&#x2019; except insofar as they exemplify broader populations of items that share similar properties. As the psycholinguist Edmund Coleman observed over 50 years ago, &#x201C;many studies of verbal behavior have little scientific point if their conclusions have to be restricted to the specific language materials that were used in the experiment&#x201D; (Coleman, 1964). The same is no doubt true of the stimuli used in modern neuroimaging studies.</p>
<p>Choosing between hypothetical titles like those above may seem purely a matter of preference--a researcher simply decides that she cares more about the underlying population than about the individual stimuli, and can then proceed to describe her results as such. But the conceptual move from stimulus-level to population-level inference is not automatically justified. It must be explicitly supported by appropriate statistical inference. In studies where a sample of participants respond to a sample of stimuli&#x2014;as is the case in a vast number of fMRI studies&#x2014;the correct analysis that allows generalization to both participant and stimulus populations involves fitting a mixed-effects model with crossed random effects of both participants and stimuli (<xref ref-type="bibr" rid="c1">Baayen, Davidson, &#x0026; Bates, 2008</xref>; <xref ref-type="bibr" rid="c18">Judd, Westfall, &#x0026; Kenny, 2012</xref>). This is not a hypothetical concern: in a review of 100 random task-based fMRI articles extracted from the Neurosynth database (see Methods for details), we found that 63/100 (95&#x0025; Jeffreys interval &#x003D; [53&#x0025;, 72&#x0025;]) used multiple stimuli in a context where generalization over stimuli was clearly indicated. Yet while virtually every fMRI study conducted over the past 15 years has modeled subject as a random factor (<xref ref-type="bibr" rid="c25">Penny, Holmes, &#x0026; Friston, 2003</xref>), we are aware of only two published fMRI studies that have discussed the problem of unmodeled stimulus-related variance from a methodological perspective (<xref ref-type="bibr" rid="c5">Bedny, Aguirre, &#x0026; Thompson-Schill, 2007</xref>; <xref ref-type="bibr" rid="c11">Donnet, Lavielle, &#x0026; Poline, 2006</xref>), and know of no primary fMRI studies that have modeled participants and stimuli as crossed random factors.</p>
<p>The consequences of this stimulus-as-fixed-effect fallacy, as it is called in psycholinguistics, are potentially devastating. Strictly speaking, the <italic>p</italic>-values (or other inferential statistics) reported in the entire fMRI literature to date are valid only for the exact stimuli used in each study. The conclusions cannot be generalized to a broader population of stimuli without risking inflated Type I error (cf. <xref ref-type="bibr" rid="c11">Donnet et al., 2006</xref>). Previous work in other domains (and replicated here) demonstrates that this inflation can be dramatic, with the Type 1 error rate frequently exceeding 50&#x0025; under realistic conditions (<xref ref-type="bibr" rid="c18">Judd et al., 2012</xref>; <xref ref-type="bibr" rid="c33">Wickens &#x0026; Keppel, 1983</xref>).</p>
<p>Here we develop a Bayesian mixed model (the random stimulus model; RSM) that directly estimates the degree of stimulus variability in fMRI data and properly adjusts the key parameter estimates to account for uncertainty due to stimulus sampling. We then apply this model to a variety of real fMRI datasets with diverse stimulus samples and experimental designs, comparing the results from the standard statistical model that ignores stimulus variability to the results from the corresponding RSM. Our findings suggest that an unknown but possibly large fraction of published fMRI findings are likely to be false positives driven by unmodeled stimulus-level variability. We demonstrate that the magnitude of the problem can be considerably ameliorated by employing large stimulus samples and/or presenting different subjects with different stimuli -- in fact, in the limiting case where every participant receives a completely unique stimulus set, the standard model is the statistically appropriate model. Finally, we show how the stimulus-level parameter estimates produced by RSMs can be used to generate and test novel research hypotheses, opening up a powerful new method for studying the neural substrates of cognition.</p>
<sec id="s1"><title>Results</title>
<sec id="s1a"><title>The Random Stimulus Model</title>
<p>Consider a hypothetical fMRI experiment in which participants view a total of 20 stimuli in a blocked design, half belonging to one stimulus category and half to another, and we are interested in the difference in neural response between these two categories (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). In analyzing the data under the standard model, the regressors for each condition, which give the shape of the predicted neural response, are obtained by convolving an activation sequence representing when stimuli in that condition were presented with a hemodynamic response function. The standard model posits that these stimulus-level activations are all identical in amplitude for a given category (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>)&#x2014;a dubious assumption in most fMRI studies. In the RSM, we relax this assumption and allow the stimulus-level activations to have distributions of amplitudes, with the parameters of these distributions to be estimated from the data (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Note that this approach is directly analogous to the way that virtually all existing fMRI packages already handle subject-level variability. That is, in addition to modeling subject as a random factor in order to account for uncertainty due to random subject sampling, we extend the same treatment to stimuli.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure"><label>Figure 1</label>
<caption><p>Idealized data from the standard model and the random stimulus model (RSM) for a hypothetical experiment. Stimuli belonging to one of two conditions (nouns in red, verbs in blue) are presented in alternating blocks, with the same stimuli presented in the same order to each participant. Both models incorporate subject-level variability in the magnitude of the category difference; for example, Participant 2 shows a small category difference while Participant 3 shows a large category difference. In the standard model, neural responses are assumed to be equal in magnitude for all stimuli in a category. The random stimulus model relaxes this assumption and estimates a separate response for each stimulus. For example, the noun &#x201C;desk&#x201D; elicits consistently high responses for all participants, while the noun &#x201C;spoon&#x201D; elicits consistently low responses for all participants.</p></caption>
<graphic xlink:href="077131_fig1.tif"/>
</fig>
<p>To validate our Bayesian estimation approach, we conducted extensive simulations in which we systematically varied sample sizes and stimulus variabilities, fitting both the standard model and the RSM to each dataset. The full details of these simulations are given in <xref ref-type="app" rid="app1">Appendix 1</xref>. The results confirmed that the test statistics from the RSM were attenuated under the same conditions as in previously studied behavioral models (<xref ref-type="bibr" rid="c18">Judd et al., 2012</xref>; <xref ref-type="bibr" rid="c32">Westfall, Kenny, &#x0026; Judd, 2014</xref>). Under the worst conditions we studied in simulation--namely, when the number of experimental stimuli is small and the degree of stimulus variance is large--the test statistic from the standard model was inflated over five-fold relative to the test statistic from the correct model. Put differently, when random stimulus effects are added to the standard model, the test statistics were reduced by over 80&#x0025; in the worst case we studied. (As a preview, in some of the real datasets we reanalyze below, the reduction is even more severe than this.) Importantly, only the RSM correctly estimated the variability in the average condition difference across simulated datasets; the standard errors from both the standard model and other simpler (but incorrect) approximations consistently underestimated the true variance of the condition differences across simulated datasets.</p>
</sec>
<sec id="s1b"><title>Does the amygdala preferentially respond to emotional faces?</title>
<p>To illustrate the scope and magnitude of the stimulus-as-fixed-effects fallacy in fMRI, we first focus our attention on one of the most well-established neuroimaging findings: the role of the amygdala in affective processing. The amygdala has been shown in hundreds of fMRI studies to increase activation in response to biologically salient stimuli--most notably faces--and to show a particular strong response to negative affect-provoking stimuli such as fearful or angry face expressions (<xref ref-type="bibr" rid="c7">Breiter et al., 1996</xref>; <xref ref-type="bibr" rid="c22">Morris et al., 1996</xref>). However, the number of stimuli used in studies demonstrating this effect is often small--in many cases, fewer than 10 stimuli per experimental condition. As we note above, this is precisely the situation in which inflated statistical significance is expected.</p>
<p>To quantify the effects of modeling stimulus as a random factor on the amygdala response to emotionally salient stimuli, we used data (n &#x003D; 111 subjects) from the Human Connectome Project (<xref ref-type="bibr" rid="c2">Barch et al., 2013</xref>; <xref ref-type="bibr" rid="c31">Van Essen et al., 2013</xref>). In the HCP Emotion Processing Task--adapted from an earlier task used by Hariri and colleagues (<xref ref-type="bibr" rid="c16">Hariri et al., 2002</xref>)--participants view blocks of either faces (20 in total) or geometric shapes (3 in total), and make an unrelated perceptual matching judgment. The face stimuli have either fearful or angry facial expressions (10 per condition). We first analyzed the data using the standard model, where subjects (but not stimuli) were modeled as random effects. For each contrast of interest, we define a test statistic <italic>z</italic>&#x003D;&#x03BC;/&#x03C3;, where &#x03BC; and &#x03C3; are the mean and standard deviation, respectively, of the posterior samples for the associated parameter estimate (cf. <xref ref-type="bibr" rid="c20">Kruschke, 2013</xref>). Consistent with previous reports on this dataset (<xref ref-type="bibr" rid="c2">Barch et al., 2013</xref>) and the broader literature, when analyzing the data under the standard model, we found a robust increase in amygdala activation for face stimuli relative to shape stimuli (z&#x003D;26), and a smaller but still notable increase for angry faces relative to fearful faces (z&#x003D;3.3). These results are illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref> (top).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure"><label>Figure 2</label>
<caption><p>Posterior samples of the regression coefficients associated with each stimulus category, indicating the predicted magnitude of average amygdala response in response to each category, under both the standard model and the random stimulus model. Under the standard model, there is clear separation of the estimated amygdala responses toward all three stimulus categories, with anger faces evoking a somewhat stronger response than fear faces, and both face stimuli evoking a much stronger response than the simple shape stimuli. Under the random stimulus model, the means of the regression coefficients are about the same, but they are estimated with far more uncertainty. The result is that while the face vs. shape contrast is still clearly discernible, the anger vs. fear contrast is no longer distinguishable from sampling/measurement error.</p></caption>
<graphic xlink:href="077131_fig2.tif"/>
</fig>
<p>As noted above, the analysis under the standard model fails to account for the uncertainty inherent in the fact that the effect of stimulus category is based on a small and highly variable stimulus sample. When we modeled the data correctly, using the RSM, we found that the test statistic for the face vs. shape contrast was reduced by 89&#x0025; (from z&#x003D;26 to z&#x003D;2.8) compared to the standard model, and the test statistic for the anger vs. fear contrast was reduced by 78&#x0025; (from z&#x003D;3.3 to z&#x003D;0.7). In the former case, the effect remained intact (but would have failed to do so in a smaller sample more typical of the modal fMRI study, and would not have survived multiple comparisons correction even at the current sample size). In the latter case, the remaining effect was negligible, providing essentially no basis for concluding that the amygdala responds differentially to angry versus fearful faces. These results are illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref> (bottom). Thus, simply accounting for natural variability in the sampled stimuli was sufficient to turn a seemingly robust and possibly scientifically intriguing finding into an unremarkable result that probably does not merit further consideration. The striking effect of explicitly modeling stimulus as a random effect is further illustrated in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure"><label>Figure 3</label>
<caption><p>Magnitude of amygdala response predicted by the standard model (panel A) and the RSM (panel B), represented as subject &#x00D7; stimulus matrices, where each row (111 in total) represents a unique subject and each column (23 in total) represents a unique stimulus. Each entry of the matrix gives a (posterior mean) regression coefficient corresponding to the model&#x2019;s prediction for that subject&#x2019;s amygdala response toward that stimulus. Notice that the standard model assumes that a subject has the same amygdala response toward all stimuli in a given category---in other words, it assumes no random stimulus variability. While this may not be an entirely unreasonable assumption for the three relatively impoverished shape stimuli (a circle and two ovals), it is a patently absurd assumption for the faces, as a cursory visual inspection of the stimuli makes clear (panel E). When we add random stimulus effects to the standard model--resulting in the RSM--we find that random stimulus variability (evident in the within-category variance of the column means) is in fact one of the chief sources of variation in the data. The images in panel E are sorted within each emotion condition by their posterior sample means (panels C and D), which are printed below the stimulus labels.</p></caption>
<graphic xlink:href="077131_fig3.tif"/>
</fig>
</sec>
<sec id="s1c"><title>Whole-brain analysis reveals differential stimulus sensitivity</title>
<p>Next, we extended the analysis to the rest of the brain, fitting the same RSM in 100 different regions-of-interest (ROIs; we used an ROI rather than voxel-wise approach due to the computational demands of the RSM). As <xref ref-type="fig" rid="fig4">Figure 4</xref> illustrates, the impact of modeling stimulus as a random factor were no less dramatic than in the amygdala for most brain regions. For the two test statistics (i.e., face vs. shape contrast and anger vs. fear contrast), the median ratios of the standard model z-statistic over the RSM z-statistic were 3.3 and 5.96, respectively, indicating reductions of 70&#x0025; and 83&#x0025; when random stimulus effects were added. When thresholding brain activity at even a relatively liberal threshold of z&#x003D;3, only 2 out of 100 regions (compared to 59 out of 100 in the classical analysis) remained statistically significant, and <italic>no</italic> region showed a significant difference between angry and fearful faces (as compared to 27 regions in the classical analysis).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure"><label>Figure 4</label>
<caption><p>Whole-brain results for 5 contrasts from 4 different datasets when modeled with either a standard approach or a RSM. Each row displays results for a different dataset and/or contrast (see main text for details). Left column: scatter plot displaying the relationship between ROI-level test statistics from the standard model (y-axis) and RSM (x-axis). Each point represents a single ROI from a 100-region whole-brain clustering. Middle and right columns: axial slices displaying ROI-level test statistics (z statistics, defined as in the main text) from the standard and RSM analyses, respectively. Maps are thresholded at |z| &#x003E; 3.3 -- comparable to using p &#x003C; .001, uncorrected, in a traditional frequentist analysis -- in order to illustrate the significant drop in test statistics in most datasets when including random stimulus effects.</p></caption>
<graphic xlink:href="077131_fig4.tif"/>
</fig>
<p>Intriguingly, the fusiform face area (FFA; <xref ref-type="bibr" rid="c19">Kanwisher, McDermott, &#x0026; Chun, 1997</xref>)--which showed the most robust face-related increase in the standard model (z&#x003D;31)--failed to show a significant difference between faces and shapes in the RSM. This counterintuitive result can be understood by considering the large amount of stimulus-level variability in FFA responses to faces (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Since the face vs. shape test statistic in the RSM depends on the ratio between the between-condition and within-condition (i.e., stimulus-level) variances, a brain region that is extremely sensitive to different stimuli of the same modality may counterintuitively fail to show a consistent difference between faces and shapes precisely <italic>because</italic> it is extremely sensitive (but differentially so) to individual faces.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure"><label>Figure 5</label>
<caption><p>Model-estimated stimulus variability (standard deviation of the random stimulus effects) for the three stimulus categories in the HCP Emotion Processing Task, separately for each ROI. ROIs with greater estimated stimulus variability showed greater sensitivity to idiosyncratic stimulus differences within each stimulus category.</p></caption>
<graphic xlink:href="077131_fig5.tif"/>
</fig>
<p>Although the resulting reduction in the test statistic may come as an unpleasant surprise, there is an important silver lining: the ability to quantify the variance in brain activity specifically related to individual stimuli provides a powerful tool for identifying brain regions sensitive to different classes of stimuli. To illustrate, <xref ref-type="fig" rid="fig5">Figure 5</xref> displays the stimulus-level variability captured by the model in each brain region. Not surprisingly, stimulus-related variability was greatest in visual cortical regions; however, a number of other brain regions also showed considerable stimulus sensitivity in response to faces, including motor cortex, anterior insula (particularly for anger faces), and portions of anterior PFC. As one might intuitively expect, the variability in responses to the 3 simple geometric shapes was muted in comparison to the response to faces.</p>
</sec>
<sec id="s1d"><title>Generalization to other datasets</title>
<p>To ensure that the HCP Emotion Task was not an outlier, and that our conclusions apply more generally, we repeated our random stimulus analyses on several other datasets. We fit RSM models to two other HCP functional tasks -- the Social Cognition Task and the Working Memory Task -- as well as a non-HCP emotion processing dataset (<xref ref-type="bibr" rid="c9">Chang, Gianaros, Manuck, Krishnan, &#x0026; Wager, 2015</xref>). These tasks differed widely in experimental design, stimulus modality (video clips, images, and audio narratives), number of stimuli (10 in the social cognition task, 96 in the WM task), and putative psychological processes. Nevertheless, when contrasting the RSM with the classical model, test statistics for critical comparisons were reduced considerably in all datasets (the median reductions across all 100 ROIs ranged from 12&#x0025; to 83&#x0025; in the datasets we examined; see <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig6">6</xref>). In general, the rank-order stability of regions was high across the two analyses in terms of the test statistics (mean <italic>r</italic>&#x003D;.77). Thus, the global pattern of activity across the whole brain was--at least in the tested datasets--relatively conserved in the RSM, and the drop in test statistics largely reflected the increased variance of the fixed-effect estimates of the experimental conditions (cf. <xref ref-type="fig" rid="fig2">Fig. 2</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure"><label>Figure 6</label>
<caption><p>Whole-brain results for 3 datasets modeled with either a standard approach or a RSM. The interpretation is the same as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></caption>
<graphic xlink:href="077131_fig6.tif"/>
</fig>
</sec>
<sec id="s1e"><title>The critical role of stimulus sample size</title>
<p>Why were the critical test statistics from the RSM model so small compared to the standard analysis, despite the relatively large participant samples used in these analyses? The likely culprits here are the relatively small stimulus sets used in these experiments. As far as the RSM is concerned, the stimuli used in a study are just as important as the human subjects---both ultimately represent sources of random variation in the data that we would like to generalize over when estimating brain responses to different experimental conditions. Most researchers would question the wisdom of conducting an fMRI study that compared, say, 5 highly variable subjects in one condition to 5 highly variable subjects in another condition, yet many researchers routinely make essentially the same mistake when sampling stimuli. The problem is exacerbated in many cases (including in many of the present datasets) when stimuli are presented in exactly the same order to all participants---an approach that conflates order effects with stimulus effects, necessarily inflating the variance seemingly accounted for by the latter.</p>
<p>The important silver lining to this otherwise grim analysis is that test statistic inflation in the classical model is related in predictable ways to stimulus sample size (<xref ref-type="bibr" rid="c18">Judd et al., 2012</xref>; <xref ref-type="bibr" rid="c33">Wickens &#x0026; Keppel, 1983</xref>). Thus, it should be possible to minimize the gap between the standard model and the RSM by increasing the number of stimuli in one&#x2019;s experiment. To test this prediction empirically, we used two additional datasets. First, we applied the RSM to the HCP language task, which included a Math condition in which participants provided forced-choice answers to auditorily presented mental arithmetic problems. In contrast to the other HCP tasks, stimuli in the Math condition are adaptively chosen from a large set of over 7,000 candidate mental arithmetic problems based on each participant&#x2019;s in-task performance. We consequently predicted that RSM estimates should be very close to standard model estimates for this experimental condition. This prediction was confirmed (<xref ref-type="fig" rid="fig6">Figure 6B</xref>): test statistics from the two models were very similar across the brain when comparing the Math condition to the implicit resting baseline (mean |z|&#x003D;8.47 vs. 8.12; 4&#x0025; reduction). This consistency across models contrasted sharply with the large reduction observed for the Language condition (mean |z|&#x003D;4.83 vs. 2.67; 45&#x0025; reduction), which presented the same 6 stimuli to nearly all subjects. As a consequence of the loss of precision in the Language condition, test statistics for the Math vs. Language contrast also showed a considerable decline (mean |z|&#x003D;13.75 vs. 5.96; 57&#x0025; reduction). <xref ref-type="fig" rid="fig6">Figure 6C</xref> displays estimates from the standard model and RSM for a sample region (V5/MT in visual cortex), clearly illustrating the selective increase in uncertainty in the story condition.</p>
<p>Second, we analyzed an unpublished emotion regulation dataset (<xref ref-type="bibr" rid="c10">Cohen, 2009</xref>) publicly available from the OpenfMRI.org repository (<xref ref-type="bibr" rid="c26">Poldrack &#x0026; Gorgolewski, 2015</xref>), in which 11 participants passively viewed either negative or neutral pictures. Importantly, each participant viewed 60 different stimuli (from a total set of 120). Theoretically, this &#x201C;partially-crossed&#x201D; design should considerably reduce the discrepancy between the RSM and classical model (<xref ref-type="bibr" rid="c32">Westfall et al., 2014</xref>), and this is precisely what we found: test statistics from the two models were very similar across the brain when comparing passive viewing of neutral vs. negative images (<xref ref-type="fig" rid="fig6">Fig. 6A</xref>; mean |z|&#x003D;2.77 vs. 2.30 for standard model vs. RSM, respectively; median ratio&#x003D;1.18). These results confirm that there is indeed a predictable and robust relationship between the stimulus sampling scheme used in an fMRI experiment and the degree of test statistic inflation one can expect to observe when using the standard (incorrect) model.</p>
</sec>
<sec id="s2"><title>Stimulus-level parameter estimates as a tool for exploration</title>
<p>While the primary reason to include random stimulus effects in one&#x2019;s model is to ensure that statistical inferences can be safely generalized to new stimuli, an important secondary benefit is that this approach facilitates data exploration and hypothesis generation. The inclusion of a separate parameter for each stimulus allows one to estimate the unique pattern of whole-brain activation associated with each stimulus. Inspection of these estimates may help identify novel features of the data or design that can be subsequently tested formally.</p>
<p>To illustrate, consider the parameter estimates displayed for individual faces in <xref ref-type="fig" rid="fig3">Figure 3E</xref>. Qualitatively, there appears to be a potential trend for black faces to elicit larger amygdala responses than white faces. To formally test this hypothesis, we obtained race judgments of the 20 faces from 3 lab members blind to our hypothesis and with no knowledge of the parameter estimates. When the RSM model was recomputed with an additional fixed effect coding stimulus race, the resulting posterior estimate was suggestive of a weak race effect (z&#x003D;1.55; the other parameter estimates were all virtually unchanged). Of course, this particular analysis is circular, since the hypothesis was generated and tested using the same data. The important point, however, is that even this cursory visual inspection of the stimulus-level estimates was sufficient to suggest a scientifically interesting hypothesis that could be readily tested using independent data. Indeed, a number of previous studies (<xref ref-type="bibr" rid="c21">Lieberman, Hariri, Jarcho, Eisenberger, &#x0026; Bookheimer, 2005</xref>) have reported race-related amygdala activation patterns consistent with our conjecture (though none included random stimulus effects, and hence the existing evidence for race effects in the amygdala is itself very likely overstated).</p>
</sec>
</sec>
<sec id="s3"><title>Discussion</title>
<p>We have shown that the universal failure of fMRI studies to include random stimulus effects in statistical models can have a substantial, and almost invariably deleterious, effect on reported results. At root, the problem lies in a mismatch between researcher intent and statistical implementation: neuroimaging researchers intend for their statistical conclusions to generalize across populations of stimuli similar, but not identical to, the ones they tested; however, conventional statistical procedures only allow conclusions to be drawn with respect to the exact stimuli used in each study. Our literature survey suggests that the ramifications of this discrepancy between intent and praxis are likely to be very large: in a survey of 100 articles, we found that use of a RSM was clearly indicated in over 60&#x0025; of cases. This is a conservative lower bound of the true extent of the problem, as many of the remaining studies could not have used a RSM due to otherwise avoidable limitations of their experimental design (e.g., using only a single stimulus per condition). Given that the RSM test statistics we obtained were frequently reduced by 50&#x0025; or more relative to those obtained using a standard analysis, one implication of our findings is that a large fraction of the results reported in the fMRI literature are likely to be severely inflated. Moreover, when the true mean stimulus effect is zero, variation in stimuli will generally exert some non-zero influence on brain activity (as was evident in all of the datasets we tested), which in turn will inflate Type I error. In simulations that we describe in detail in <xref ref-type="app" rid="app1">Appendix 1</xref>, we found that the Type 1 error rate for the standard model in the presence of unmodeled stimulus variability, using a nominal decision threshold of <italic>&#x03B1;</italic> &#x003D; &#x002E;001, ranged from about .01 to about .4, depending on the sample sizes and the level of stimulus variability. At a threshold of <italic>&#x03B1;</italic> &#x003D; &#x002E;05 --as would be common in many hypothesis-driven ROI-level tests--the Type 1 error rate was as high as .65, still under relatively conservative assumptions (e.g., a maximum participant sample size of 64 and a minimum stimulus sample size of 16).</p>
<p>We are aware two previous papers that have discussed the issue of random stimulus variability in fMRI (<xref ref-type="bibr" rid="c5">Bedny et al., 2007</xref>; <xref ref-type="bibr" rid="c11">Donnet et al., 2006</xref>). While conceptually similar, these two papers take different approaches than the one described here, and it is worth noting the differences. <xref ref-type="bibr" rid="c11">Donnet et al. (2006)</xref> describe a model with random stimulus effects that are different for every subject, so that the corresponding variance component is more akin to a subject-by-stimulus interaction variance component than to the stimulus variance components incorporated in our models. They also do not discuss inference on the fixed effects of activation magnitude. <xref ref-type="bibr" rid="c5">Bedny et al. (2007)</xref> do discuss inference on the fixed effects, but they focus primarily on conducting a separate subject-wise analysis (i.e., what we have called the standard model, which ignores stimulus variance) and stimulus-wise analysis (i.e., the conceptual complement of the subject-wise analysis, which includes stimulus variance but ignores participant variance). This approach is common in psycholinguistics, and it is certainly a step up from running only the standard or subject-wise model, but it is not equivalent to the full, correct model with crossed random effects of participants and stimuli. In particular, it does not succeed in maintaining the nominal Type 1 error rate (<xref ref-type="bibr" rid="c28">Raaijmakers, 2003</xref>; <xref ref-type="bibr" rid="c29">Raaijmakers, Schrijnemakers, &#x0026; Gremmen, 1999</xref>).</p>
<p>What can researchers do to address the stimulus-as-fixed-effect fallacy? Broadly speaking, there are two possible strategies. The best practice approach to address the issue is to explicitly include random effects in one&#x2019;s model for every factor a researcher intends to generalize over. In the present study, we used MCMC sampling to fit our mixed-effects models; however, other approaches (based on maximum likelihood estimation, variational inference, etc.) are also available (<xref ref-type="bibr" rid="c4">Bates, Douglas, Martin, Ben, &#x0026; Steve, 2015</xref>). The primary downside of an estimation-based solution is that it is computationally intensive and may be technically demanding. At present, no major fMRI analysis package supports RSMs of the kind we employ here, limiting the ability of most researchers to produce correct inferences. While we have open-sourced the <italic>nipymc</italic> Python package we used to fit the models reported here (<ext-link ext-link-type="uri" xlink:href="http://github.com/PsychoinformaticsLab/nipymc">http://github.com/PsychoinformaticsLab/nipymc</ext-link>), this should be viewed as a provisional (and not particularly scalable) solution until more robust and widely-used packages such as FSL, SPM, or AFNI introduce support for random stimulus effects.</p>
<p>Alternatively, a less effective but much simpler approach to the problem is to use as large a stimulus sample as is practically feasible. In previous work, we have shown that the number of stimuli can impose a hard cap on statistical power in the RSM: when stimulus samples are very small, it may be impossible to obtain statistically significant estimates of the fixed effects, no matter how many thousands of subjects one samples (<xref ref-type="bibr" rid="c32">Westfall et al., 2014</xref>). This is evident in the present findings, where test statistics from fMRI experiments with only a few stimuli (such as the HCP Emotion and Social Cognition tasks) showed precipitous drops in the RSM, whereas those generated by designs with many stimuli are often negligible (e.g., <xref ref-type="fig" rid="fig6">Figure 6</xref>). The primary (and significant) downside of a stimulus-maximizing heuristic is that it is only a heuristic--there is no guarantee that the resulting test statistic will closely approximate the one that would have been obtained through the explicit inclusion of random stimulus effects. In particular, if the degree of random stimulus variability is large, then a huge number of stimuli may be required before the two sets of test statistics closely converge. Nevertheless, in the absence of analysis tools capable of correctly modeling multi-stimulus designs, we strongly encourage researchers to always include as many stimuli as possible in their designs. Importantly, unlike increases in participant sample size, adding stimuli rarely incurs any additional cost. Researchers can usually easily increase the number of stimuli by either (a) eschewing repeated presentation of a few stimuli in favor of single presentation of many different stimuli, or (b) using a &#x201C;partially crossed&#x201D; design where each participant responds to a different subset of stimuli (<xref ref-type="bibr" rid="c32">Westfall et al., 2014</xref>). These approaches allow one to enjoy the statistical power benefits of a large stimulus sample without increasing data collection requirements.</p>
</sec>
<sec id="s4"><title>Methods</title>
<sec id="s4a"><title>fMRI Datasets</title>
<p>All analyses used publicly available data obtained from one of three sources. The HCP analyses used task fMRI data from the Human Connectome Project&#x2019;s &#x201C;100 unrelated subject&#x201D; release, accessible via the online Connectome Workbench (<ext-link ext-link-type="uri" xlink:href="http://www.humanconnectome.org">http://www.humanconnectome.org</ext-link>). These data were provided [in part] by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University. All HCP analyses used the preprocessed data release. No further processing of the time series was performed prior to region-based averaging and mixed-effects modeling (see below). Methods have been previously described in detail in (<xref ref-type="bibr" rid="c14">Glasser et al., 2013</xref>).</p>
<p>The emotion regulation dataset was obtained from OpenfMRI, and is publicly available; its accession number is ds000009. Note that although the full dataset includes n&#x003D;24 subjects, only 11 subjects had preprocessed data available. We therefore conducted analyses with the convenience n&#x003D;11 sample, since subject sample size was irrelevant for our purposes. Experimental design and preprocessing procedures for this dataset have been previously described in <xref ref-type="bibr" rid="c10">Cohen (2009)</xref>.</p>
<p>The IAPS dataset previously used in <xref ref-type="bibr" rid="c9">Chang et al. (2015)</xref> was obtained from the NeuroVault whole-brain image repository (<xref ref-type="bibr" rid="c15">Gorgolewski et al., 2015</xref>). Images were downloaded via the NeuroVault API from the corresponding image collection (<ext-link ext-link-type="uri" xlink:href="http://neurovault.org/collections/503/">http://neurovault.org/collections/503/</ext-link>). The dataset contains 30 trial-level estimates for each of 172 participants (30 images in total). On each trial, participants passively viewed either a negative or a neutral IAPS image (15 of each). All methods have been previously described in <xref ref-type="bibr" rid="c9">Chang et al. (2015)</xref>.</p>
</sec>
<sec id="s4b"><title>Statistical modeling</title>
<sec id="s4b1"><title>The standard model</title>
<p>Consider a hypothetical fMRI experiment in which participants view 20 stimuli, half belonging to one stimulus category and half to another (as in <xref ref-type="fig" rid="fig1">Figure 1</xref>), and we are interested in the difference in neural response between these two categories. Let <italic>Y</italic><sub><italic>it</italic></sub> be the neural response of the <italic>i</italic>th subject at the <italic>t</italic>th time point in a particular voxel or region of interest (ROI), with all preprocessing already carried out and with each participant&#x2019;s data separately standardized. The standard statistical model used to analyze such data is
<disp-formula><alternatives><graphic xlink:href="077131_ueqn1.gif"/></alternatives></disp-formula>
where <italic>X</italic><sub>1</sub> and <italic>X</italic><sub>2</sub> are the regressors representing the predicted neural responses toward the two categories of stimuli; <italic>&#x03B2;</italic><sub>0</sub> is the fixed intercept; <italic>&#x03B2;</italic><sub>1</sub> and <italic>&#x03B2;</italic><sub>2</sub> are the fixed effects of the two neural regressors; <italic>p</italic><sub>1</sub> and <italic>p</italic><sub>2</sub> are normally distributed participant effects of the neural regressors, representing stable subject-to-subject variability in the degree of neural response toward both stimulus types; and the <italic>e</italic> terms are normally distributed, observation-level errors with an AR(2) covariance structure. The regressors <italic>X</italic><sub>1</sub> and <italic>X</italic><sub>2</sub> are formed by summing over the predicted neural responses toward the individual stimuli comprising each stimulus category,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn2.gif"/></alternatives></disp-formula>
where <italic>x</italic><sub><italic>ijt</italic></sub> is the predicted neural response of the <italic>i</italic>th participant for the <italic>j</italic>th stimulus at time <italic>t</italic>. These predicted neural responses are based on convolving a stimulus presentation sequence with a hemodynamic response function (<xref ref-type="bibr" rid="c27">Poldrack, Mumford, &#x0026; Nichols, 2011</xref>).</p>
</sec>
<sec id="s4b2"><title>Random Stimulus Model (RSM)</title>
<p>The standard model posits that the stimulus-level regressors are all identical in amplitude, differing only in their presentation times (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>)&#x2014;a dubious assumption in most fMRI studies. In the RSM, we relax this assumption and allow the stimulus-level regressors to have distributions of amplitudes that are to be estimated from the data (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>); these amplitudes are common over subjects, but vary randomly per stimuli. To achieve this, we add a set of terms <italic>s</italic><sub><italic>j</italic></sub><italic>x</italic><sub><italic>ijt</italic></sub> to the model, where the <italic>s</italic><sub><italic>j</italic></sub> are normally distributed stimulus effects, representing stable stimulus-to-stimulus variability in the strength of the neural response. The resulting model is
<disp-formula><alternatives><graphic xlink:href="077131_ueqn3.gif"/></alternatives></disp-formula></p>
<p>This model cannot be fit using standard mixed modeling statistical packages, such as lme4 in R or SAS PROC MIXED, because these packages assume that each row of the dataset is associated with one and only one level of each random factor (i.e., a single participant and a single stimulus)<xref ref-type="fn" rid="fn1"><sup>1</sup></xref>. However, for the RSM, the measurements at each time point are influenced not by a single random stimulus effect (<italic>s</italic><sub><italic>j</italic></sub>), but rather by <italic>all</italic> of the random stimulus effects (&#x2211;<sub><italic>j</italic></sub><italic>s</italic><sub><italic>j</italic></sub>). Despite this complication, it is relatively straightforward to fit the RSM as a Bayesian model using a probabilistic programming framework such as BUGS, JAGS, or Stan. For the models in this paper, we used the PyMC3 Python package (<xref ref-type="bibr" rid="c24">Patil, Huard, &#x0026; Fonnesbeck, 2010</xref>; <xref ref-type="bibr" rid="c30">Salvatier, Wiecki, &#x0026; Fonnesbeck, 2015</xref>), which is built on the Theano deep learning package (<xref ref-type="bibr" rid="c3">Bastien et al., 2012</xref>; <xref ref-type="bibr" rid="c6">Bergstra et al., 2010</xref>) and implements the state-of-the-art No U-Turn MCMC Sampler (<xref ref-type="bibr" rid="c17">Hoffman &#x0026; Gelman, 2014</xref>). An alpha version of our <italic>NiPyMC</italic> analysis package is available online (github.com/PsychoinformaticsLab/nipymc). In <xref ref-type="app" rid="app1">Appendix 1</xref> we give the full statistical details of the specific models we estimated in our reanalyses, including the precise distributional assumptions and the variations of the basic model that we applied to each individual dataset.</p>
<p>We note that there are various specification options that could be applied to the standard model and RSM described here and in <xref ref-type="app" rid="app1">Appendix 1</xref>--for example, different choices of HRF, autocorrelation parameters, motion correction, image realignment, and so on. While such options can certainly impact overall data quality and test statistics (cf. <xref ref-type="bibr" rid="c8">Carp, 2012</xref>) they are extremely unlikely to affect the central conclusions supported by the present results. To exert a non-negligible impact on our results, these specification options would need to have very different impacts on the standard model and RSM (otherwise the extensions would simply lead to the test statistics from both models increasing or decreasing more or less in unison, leaving their relative differences essentially unchanged). We are aware of no a priori reasons to expect this to be the case for any of the methodological procedures employed with any frequency in the literature, and reiterate that comparably large decreases in test statistics have been repeatedly observed in other domains of psychology when including random stimulus effects (<xref ref-type="bibr" rid="c18">Judd et al., 2012</xref>; <xref ref-type="bibr" rid="c34">Wolsiefer, Westfall, &#x0026; Judd, 2016</xref>).</p>
</sec>
</sec>
<sec id="s4c"><title>Simulations</title>
<p>We conducted an extensive series of simulations in order to validate and to better understand the properties of our proposed RSM. Our first goal was to verify that the RSM could adequately recover true parameter values. Our second goal was to identify the conditions under which using a RSM produces the greatest attenuation of test statistics compared to the standard model. In orthogonal, ANOVA-like designs where the appropriate RSM can be fit in standard mixed modeling software, it can be shown that the test statistic for the standard model that ignores stimulus variability will be inflated by a factor of roughly <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="077131_inline1.gif"/></alternatives></inline-formula>, where <italic>n</italic> is the number of participants, <italic>m</italic> is the number of stimuli, and <italic>E</italic>, <italic>P</italic>, and <italic>S</italic> are, respectively, the error variance, participant variance, and stimulus variance (the exact expression depends on the experimental design). While we cannot safely assume that the more complicated fMRI RSM will follow a similar inflation factor, this does give us several hypotheses about the qualitative conditions under which we should expect the worst inflation in fMRI data. Specifically, the degree of inflation should increase with participant sample size, decrease with stimulus sample size, and increase with stimulus variability. In <xref ref-type="app" rid="app1">Appendix 1</xref> we describe the results of our simulations in detail. Here we summarize the basic structure of the simulations and their results.</p>
<p>In each run of the simulation, we generated data according to the RSM for a block-design experiment involving participants responding to stimuli nested in two stimulus categories. The test of interest in these simulated experiments is the difference in the fixed regression coefficients for the two stimulus categories (i.e., whether there is greater activation for one stimulus category than for the other). We varied three primary factors in our simulations: the participant sample size (<italic>n</italic>&#x003D;16, 32, or 64), the stimulus sample size (<italic>m</italic>&#x003D;16, 32, or 64), and the degree of random stimulus variability (zero, moderate, or high). Note that when the random stimulus effects have zero variance, the RSM is statistically equivalent to the standard model.</p>
<p>We included this condition in order to investigate the performance of the RSM when the standard model is the correct model. For each simulated experiment, we fit four statistical models: the standard model, the RSM, the standard SPM-style &#x201C;summary statistics&#x201D; model, and a fourth model that we call the Fixed Stimulus Model, which we describe in <xref ref-type="app" rid="app1">Appendix 1</xref>. Here we focus on comparing the performance of the standard model and RSM (though, in practice, the three non-RSM models all display essentially indistinguishable behavior across all simulations).</p>
<p>When the true data generating process contained zero stimulus variability, the standard model and RSM yielded very similar test statistics for the stimulus category difference, for all participant and stimulus sample sizes. The exception was that when the stimulus sample size was small (<italic>m</italic>&#x003D;16), the test statistics from the RSM were slightly attenuated (by about 18&#x0025;) compared to the standard model test statistics. However, this attenuation disappeared with increasing stimulus sample size, so that at <italic>m</italic>&#x003D;32 and <italic>m</italic>&#x003D;64, the test statistics from the two models were essentially identical, as should be the case given the lack of true stimulus variability. This provides evidence that the reduced test statistics observed in our reanalyses of real datasets (most of which were based on a sample of 100 participants) are not simply the result of the RSM always yielding lower test statistics. Instead, the RSM tends to yield lower test statistics when they should in fact be lower, namely, when there is random stimulus variability in the data that is ignored by the standard model.</p>
<p>When the true data generating process contained moderate stimulus variability, the RSM yielded consistently lower test statistics than the standard model. This reduction was exacerbated when the stimulus sample size was small (<italic>m</italic>&#x003D;16) and attenuated somewhat when the stimulus sample size was large (<italic>m</italic>&#x003D;64). The opposite pattern held for the participant sample size: the reduction in the RSM test statistic was largest when the participant sample size was large (<italic>n</italic>&#x003D;64) and smallest when the participant sample size was small (<italic>n</italic>&#x003D;16). These patterns are consistent with what has been observed in previous behavioral work (<xref ref-type="bibr" rid="c18">Judd et al., 2012</xref>). In the best case (<italic>n</italic>&#x003D;16 and <italic>m</italic>&#x003D;64) the RSM test statistics were still reduced by an average of 17&#x0025; compared to the standard model test statistics. In the worst case (<italic>n</italic>&#x003D;64 and <italic>m</italic>&#x003D;16), the RSM test statistics were reduced by an average of 67&#x0025;. Finally, when the true data generating process contained high stimulus variability, the same qualitative patterns held, but the reduction in test statistics was even greater, ranging from 41&#x0025; in the best case to 81&#x0025; in the worst case.</p>
</sec>
<sec id="s4d"><title>Literature review</title>
<p>For our survey of the literature using task-based fMRI, we randomly selected published papers listed in the Neurosynth database -- skipping over studies that used resting-state fMRI -- and coded each study on a small set of criteria until we had reached exactly 100 experiments. Four of the papers we sampled described two experiments, one paper described three experiments, and the rest described a single experiment, so that the 100 experiments we sampled came from 94 unique papers. We coded each experiment for (a) whether the stimuli were crossed with participants or nested in participants, (b) the type of stimuli used, (c) the total number of stimuli, (d) the number of stimulus categories, and (e) whether the study was eligible to have applied a RSM to the data obtained from the study. Generally speaking, experiments were deemed eligible to have applied a RSM if (i) the experiment used more stimuli than stimulus categories (so that the individual stimulus effects are statistically identifiable), and (ii) the sampled stimuli could not be considered to fully exhaust the population of stimuli over which generalization was intended. In the handful of cases where it was not totally clear from the text whether a RSM could have been applied, we decided to err on the conservative side and deem the study ineligible. A spreadsheet with the detailed study-level results of our survey can be found at github.com/PsychoinformaticsLab/nipymc. We ultimately found that 63/100 of the experiments (95&#x0025; Jeffreys interval&#x003D;[53&#x0025;, 72&#x0025;]) were eligible to have applied a RSM, and thus the published test statistics for these experiments are likely inflated relative to the more appropriate RSM test statistics.</p>
</sec>
</sec>
</body>
<back>
<ack><title>Acknowledgements</title>
<p>This work was supported by National Institutes of Health Grant R01MH096906.</p>
</ack>
<app-group>
<app id="app1"><title>Appendix 1</title>
<sec><title>Statistical models</title>
<p>As mentioned in the main text, we implemented the Random Stimulus Model (RSM) as a Bayesian model, primarily in order to circumvent certain limitations in standard statistical software for fitting linear mixed models. In order to facilitate comparisons between the RSM and the standard model applied in most research papers, we also implemented the standard model as a Bayesian model, so that the two models differed only in their inclusion of random stimulus effects. Here we give the full Bayesian mixed models that we used for all 6 datasets we reanalyzed. Each model contains a set of stimulus-level regressors <italic>x</italic><sub><italic>ijt</italic></sub> that, as in the main text, represent the predicted neural response of the <italic>i</italic>th subject toward the <italic>jth</italic> stimulus at the <italic>t</italic>th time point. These regressors were constructed by convolving a stimulus presentation sequence, indicating when a stimulus was being presented, with a double-gamma hemodynamic response function (HRF) with parameters fixed at the default values used in the SPM package.</p>
<p>For each task, the model was applied separately to 100 regions-of-interest (ROIs) defined via meta-analytic k-means clustering of over 11,000 studies in the Neurosynth dataset (<ext-link ext-link-type="uri" xlink:href="http://neurosynth.org">http://neurosynth.org</ext-link>; details are reported in a forthcoming publication). The 100-ROI whole-brain cluster map is available from the project GitHub repository (<ext-link ext-link-type="uri" xlink:href="http://github.com/PsychoinformaticsLab/nipymc">http://github.com/PsychoinformaticsLab/nipymc</ext-link>). Note that this mask was used purely for convenience, and the results reported here should not depend in any way on the the choice of ROIs (as can be seen from the near ubiquitous drop in test statistics across all ROIs in <xref ref-type="fig" rid="fig4">Fig. 4</xref>).</p>
<sec><title>HCP Emotion model</title>
<p>The full Bayesian mixed model for <italic>Y</italic><sub><italic>it</italic></sub>, representing the neural response within a particular ROI (separately standardized for each subject) for the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus in the <italic>k</italic>th experimental condition at the <italic>t</italic>th time point, is
<disp-formula><alternatives><graphic xlink:href="077131_ueqn4.gif"/></alternatives></disp-formula>
where HalfCauchy was chosen as the default, weakly informative prior for the standard deviation (<xref ref-type="bibr" rid="c12">Gelman, 2006</xref>), and the mean is
<disp-formula><alternatives><graphic xlink:href="077131_ueqn5.gif"/></alternatives></disp-formula>
Where <italic>&#x03B1;</italic><sub>1</sub> and <italic>&#x03B1;</italic><sub>2</sub> are fixed effects accounting for autoregressive order-2 variation; <italic>&#x03B2;</italic><sub>0</sub> and <italic>&#x03B2;</italic><sub>k</sub> are fixed effects of the intercept and condition <italic>k</italic>, respectively; <italic>p</italic><sub><italic>ki</italic></sub> are the random subject effects, the disturbance from <italic>&#x03B2;</italic><sub><italic>k</italic></sub> for subject <italic>i</italic>, condition <italic>k</italic>; <sup><italic>s</italic><sub><italic>j</italic></sub></sup> are the random stimulus effect for stimulus <italic>j</italic>. The autoregressive fixed effects have Cauchy priors and the remaining fixed effects have Normal priors,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn6.gif"/></alternatives></disp-formula></p>
<p>The random subject effects are Normal with the same HalfCauchy prior
<disp-formula><alternatives><graphic xlink:href="077131_ueqn7.gif"/></alternatives></disp-formula></p>
<p>The stimuli random effects likewise have the same type Normal/HalfCauchy priors; for shape stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn8.gif"/></alternatives></disp-formula></p>
<p>For anger face stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn9.gif"/></alternatives></disp-formula></p>
<p>For fear face stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn10.gif"/></alternatives></disp-formula></p>
<p>The two contrasts of interest in this model are the Face vs. Shape contrast, (<italic>&#x03B2;</italic><sub>2</sub> &#x002B; <italic>&#x03B2;</italic><sub>3</sub>/2 &#x2212; <italic>&#x03B2;</italic><sub>1</sub>), and the Anger vs. Fear contrast, <italic>&#x03B2;</italic><sub>2</sub> &#x2212; <italic>&#x03B2;</italic><sub>3</sub>.</p>
</sec>
<sec><title>HCP Working Memory model</title>
<p>The full Bayesian mixed model for <italic>Y</italic><sub><italic>it</italic></sub> -- representing the neural response within a particular ROI (separately standardized for each subject) for the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus in the <italic>k</italic>th stimulus category under the <italic>l</italic>th N-back condition at the <italic>t</italic>th time point -- has a similar form as above:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn11.gif"/></alternatives></disp-formula></p>
<p>For this model, the stimuli are as follows; for body stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn12.gif"/></alternatives></disp-formula></p>
<p>For place stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn13.gif"/></alternatives></disp-formula></p>
<p>For face stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn14.gif"/></alternatives></disp-formula></p>
<p>For tool stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn15.gif"/></alternatives></disp-formula></p>
<p>The regressors <italic>X</italic><sub>1<italic>it</italic></sub> to <italic>X</italic><sub>4<italic>it</italic></sub> were constructed in the usual way (by convolution with a double-gamma HRF) and then orthogonalized with respect to <italic>N</italic><sub>1<italic>it</italic></sub> and <italic>N</italic><sub>2<italic>it</italic></sub>, which were the regressors of interest. Each in the series of 24 trials consists of both 1- and 2-back stimuli. <italic>N</italic><sub>1<italic>it</italic></sub> and <italic>N</italic><sub>2<italic>it</italic></sub> represent the predicted neural responses for the 0-back and 2-back trials, respectively, of the N-back task used in the HCP Working Memory data. Note that both the participants and the stimuli were crossed with the two N-back conditions, i.e., all subjects made responses in both conditions and all stimuli received responses under both the conditions. The contrast of interest in this model is the difference in response between the 0-back and 2-back conditions, <italic>&#x03B3;</italic><sub>1</sub> &#x2212; <italic>&#x03B3;</italic><sub>2</sub>.</p>
</sec>
<sec><title>HCP Social Cognition model</title>
<p>The full Bayesian mixed model for <italic>Y</italic><sub><italic>it</italic></sub>, representing the neural response within a particular ROI (separately standardized for each subject) for the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus in the <italic>k</italic>th experimental condition at the <italic>t</italic>th time point, has the form:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn16.gif"/></alternatives></disp-formula></p>
<p>The stimuli are as follows; for the random stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn17.gif"/></alternatives></disp-formula></p>
<p>For the mental stimuli:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn18.gif"/></alternatives></disp-formula></p>
<p>The contrast of interest in this model is the random vs. mental contrast, <italic>&#x03B2;</italic><sub>1</sub>&#x2212;<italic>&#x03B2;</italic><sub>2</sub>.</p>
</sec>
<sec><title><xref ref-type="bibr" rid="c9">Chang et al. (2015)</xref> model</title>
<p>For this dataset we used a slightly simplified, approximate version of the full RSM, quite similar to what <xref ref-type="bibr" rid="c13">Gelman &#x0026; Hill (2007)</xref> refer to as a &#x201C;no-pooling model.&#x201D; The basic idea is that rather than directly modeling all of the neural data for all subjects for a particular ROI at once, one first fits separate subject-level models that simply contain a separate fixed regressor for each stimulus. Since the participants and stimuli are fully crossed in this dataset, this produces <italic>n</italic> &#x00D7; <italic>m</italic> estimated regression coefficients, where <italic>n</italic> is the number of subjects and <italic>m</italic> is the number of stimuli. These estimated regression coefficients are then propagated upward to serve as the data in a higher-level RSM that includes crossed random participant and stimulus effects. This model is only an approximate version of the full RSM, as it ignores the varying degrees of uncertainty in the stimulus-level coefficients estimated at the first level (due in particular to factors such as differences in how often the stimuli were presented and how collinear the stimulus-level regressors were for each subject). We used this approximate method because this is the form in which the data were made available on the public NeuroVault repository (NeuroVault.org; <xref ref-type="bibr" rid="c15">Gorgolewski et al., 2015</xref>). However, it is worth noting that two practical advantages of this simplified model are that (i) it can be estimated relatively quickly and efficiently compared to the full RSM, and (ii) it can be fit using standard mixed modeling software such as R&#x2019;s lme4 package or SAS PROC MIXED, since the higher-level model is just a straightforward crossed random effects model with one and only one stimulus effect associated with each data point.</p>
<p>For the statistical details of the first-level model, which was applied separately to each subject&#x2019;s neural data, see <xref ref-type="bibr" rid="c9">Chang et al. (2015)</xref>. From these first-level models one obtains <italic>n</italic> &#x00D7; <italic>m</italic> coefficients <italic>b</italic><sub><italic>ij</italic></sub>, representing the estimated regression coefficient for the neural response of the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus. After standardizing the coefficients separately for each subject, the 2nd level model is then, as before, the Normal/HalfCauchy observation model
<disp-formula><alternatives><graphic xlink:href="077131_ueqn19.gif"/></alternatives></disp-formula>
with mean given by
<disp-formula><alternatives><graphic xlink:href="077131_ueqn20.gif"/></alternatives></disp-formula>
where now <italic>&#x03B2;</italic><sub>0</sub> is the mean response to all stimuli, <italic>s</italic><sub><italic>j</italic></sub> is the random stimulus effect, <italic>&#x03B2;</italic><sub>1</sub> is the fixed effect of valence, <italic>p</italic><sub><italic>i</italic></sub> is the random subject effect of valence, and <italic>X</italic><sub><italic>ij</italic></sub> is a dummy variable indicating whether the <italic>j</italic>th stimulus photograph was negative or neutral in valence. The fixed variables have wide Normal priors,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn21.gif"/></alternatives></disp-formula>,</p>
<p>And the random effects have the Normal/HalfCauchy priors as before:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn22.gif"/></alternatives></disp-formula></p>
</sec>
<sec><title>OpenfMRI Emotion Regulation model</title>
<p>The full Bayesian mixed model for <italic>Y</italic><sub><italic>it</italic></sub>, representing the neural response within a particular ROI (separately standardized for each subject) for the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus in the <italic>k</italic>th experimental condition at the <italic>t</italic>th time point, takes the form of the time-series models above:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn23.gif"/></alternatives></disp-formula>,</p>
<p>For the Negative/Suppress stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn24.gif"/></alternatives></disp-formula></p>
<p>For the Negative/Attend stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn25.gif"/></alternatives></disp-formula></p>
<p>For the Neutral/Attend stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn26.gif"/></alternatives></disp-formula></p>
<p>Note that all of the negative stimuli (<italic>j</italic>&#x003D;1,&#x2026;, 80) are observed in both the Suppress and Attend conditions, while the neutral stimuli (<italic>j</italic>&#x003D;81,&#x2026;, 120) are observed only in the Attend condition, so that there are a total of 200 stimulus effects (80&#x002B;80&#x002B;40) for the 120 stimuli. The two contrasts of interest in this model are the Negative vs. Neutral contrast, (<italic>&#x03B2;</italic><sub>1</sub> &#x002B; <italic>&#x03B2;</italic><sub>2</sub>)/2 &#x2212; <italic>&#x03B2;</italic><sub>3</sub>, and the Suppress vs. Attend contrast, <italic>&#x03B2;</italic><sub>1</sub> &#x2212; (<italic>&#x03B2;</italic><sub>2</sub> &#x002B; <italic>&#x03B2;</italic><sub>3</sub>)/2. Although we report only the Negative vs. Neutral results in the main text for the sake of brevity, the results for the Suppress vs. Attend contrast were nearly identical in terms of the impact of the RSM on test statistics; test statistics in the RSM were reduced by about 14&#x0025; on average compared to those from the standard model.</p>
</sec>
<sec><title>HCP Language model</title>
<p>This dataset consisted of subjects&#x2019; responses toward 6 stories and 831 math problems (drawn from a much larger potential set of over 7,000 unique stimuli). These math problems were generally presented a very small number of times each--most appeared only once in the dataset, and many appeared only twice. Due to the intensive computation that would have been required to estimating models with 831 extra parameters (most of which were either not identifiable or only weakly identifiable), we decided to group all of the math stimuli with fewer than 3 responses into a single &#x201C;dummy&#x201D; stimulus, resulting in a new total of 272 math stimuli. The full Bayesian mixed model for <italic>Y</italic><sub><italic>it</italic></sub>, representing the neural response within a particular ROI (separately standardized for each subject) for the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus in the <italic>k</italic>th experimental condition at the <italic>t</italic>th time point, takes the same form as the previous model:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn27.gif"/></alternatives></disp-formula></p>
<p>For the story stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn28.gif"/></alternatives></disp-formula></p>
<p>For the math stimuli,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn29.gif"/></alternatives></disp-formula></p>
<p>The contrast of interest in this model is the Story vs. Math contrast, <italic>&#x03B2;</italic><sub>1</sub> &#x2212; <italic>&#x03B2;</italic><sub>2</sub>.</p>
</sec>
</sec>
<sec><title>Simulation</title>
<p>We simulated experiments in which <italic>n</italic> participants respond one time each to <italic>m</italic> stimuli that belong to one of two stimulus categories, and the contrast of interest is the difference in neural activation between the two categories. The simulated experiments used a block design with the stimuli presented in alternating blocks of 8, with the order of the stimulus category presentations (i.e., whether the sequence began with category A or category B) counterbalanced across participants. Each experimental run consisted of an initial stimulus presented for 1 second, then a 2-second inter-stimulus interval (ISI), then another stimulus presented for 1 second, then another 2-second ISI, and so on until all stimuli had been presented once. The stimulus regressors <italic>x</italic><sub><italic>ijt</italic></sub> and <italic>X</italic><sub><italic>kit</italic></sub> were formed in the same way as described in the previous &#x201C;Statistical models&#x201D; section.</p>
<p>The data <italic>Y</italic><sub><italic>it</italic></sub>, representing the neural response within a particular voxel or ROI for the <italic>i</italic>th subject toward the <italic>j</italic>th stimulus in the <italic>k</italic>th experimental condition at the <italic>t</italic>th time point, were generated according to the model
<disp-formula><alternatives><graphic xlink:href="077131_ueqn30.gif"/></alternatives></disp-formula>.
where the mean is given by
<disp-formula><alternatives><graphic xlink:href="077131_ueqn31.gif"/></alternatives></disp-formula>.</p>
<p>The autocorrelation parameters were set equal to
<disp-formula><alternatives><graphic xlink:href="077131_ueqn32.gif"/></alternatives></disp-formula>
and the fixed means for the two stimulus categories were set equal to
<disp-formula><alternatives><graphic xlink:href="077131_ueqn33.gif"/></alternatives></disp-formula>.</p>
<p>The random participant effects <italic>p</italic><sub><italic>ki</italic></sub> and the random stimulus effects <italic>s</italic>)<italic>j</italic> were distributed as
<disp-formula><alternatives><graphic xlink:href="077131_ueqn34.gif"/></alternatives></disp-formula>.</p>
<p>In our simulations we varied the number of participants <italic>n</italic> &#x2208; {16, 32,64}; the number of stimuli <italic>m</italic> &#x2208; {16, 32,64}; and the standard deviation of the random stimulus effects &#x03C3;<sub>Stim</sub> &#x2208; {0, 1, 2}. We ran 500 iterations of the simulation within each of these parameter combinations. In each iteration of the simulation we fit 4 statistical models to the simulated dataset, which we describe next.</p>
<sec><title>SPM model</title>
<p>The first model that we fit to each simulated dataset is perhaps the most widely used statistical model in neuroimaging, serving as the default model in the SPM software package. In practice it is implemented in a two-stage procedure. In the first stage, one fits separate regression models to the data from each participant, where the model for the <italic>i</italic>th participant is
<disp-formula><alternatives><graphic xlink:href="077131_ueqn35.gif"/></alternatives></disp-formula></p>
<p>In the second stage, one computes the difference <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="077131_inline2.gif"/></alternatives></inline-formula> for each participant and then performs a one-sample t-test on these differences. This model can be seen as an approximation to a mixed-effects model with random participant effects -- what we refer to below as the No Stimulus Model (NSM) and in the main text as the standard model -- valid to the extent that the intrasubject variances are all equal. We include the results of this model in our simulations simply to show that it yields practically equivalent results to the NSM model that we focus on in the main text, despite their slight differences in assumptions. In the main text we focus on comparing the Random Stimulus Model (RSM) to the NSM, rather than the SPM model, because it is a cleaner comparison, since the RSM and NSM are identical except for their inclusion of random stimulus effects.</p>
</sec>
<sec><title>Fixed stimulus model (FSM)</title>
<p>The second model that we fit is similar in structure to the RSM, except the stimuli are treated as fixed effects rather than random effects. In other words, a separate fixed regression coefficient is estimated for each individual stimulus regressor. This model has been described by (<xref ref-type="bibr" rid="c23">Mumford, Turner, Ashby, &#x0026; Poldrack, 2012</xref>), who referred to it as the &#x201C;Least Squares -- All&#x201D; model. Specifically, the FSM that we estimated in each iteration is
<disp-formula><alternatives><graphic xlink:href="077131_ueqn36.gif"/></alternatives></disp-formula></p>
<p>Note that the random stimulus effects <italic>s</italic><sub><italic>j</italic></sub> are replaced with fixed effects <italic>&#x03B2;</italic><sub><italic>j</italic></sub>, which also requires that the category fixed effects <italic>&#x03B2;</italic><sub>1</sub> and <italic>&#x03B2;</italic><sub>2</sub> are removed from the model, since they would be perfectly collinear with the fixed stimulus effects. The contrast between the two stimulus categories is computed as the mean of the <italic>&#x03B2;</italic><sub><italic>j</italic></sub> in stimulus category B minus the mean of the <italic>&#x03B2;</italic><sub><italic>j</italic></sub> in stimulus category A.</p>
</sec>
<sec><title>No stimulus model (NSM)</title>
<p>This is the model that we referred to in the main text as the &#x201C;standard model.&#x201D; Unlike the FSM and RSM, the NSM does not include any stimulus effects at all, hence the name we use here. Specifically, the NSM that we estimated in each iteration is:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn37.gif"/></alternatives></disp-formula></p>
<p>The contrast between the stimulus categories was computed as <italic>&#x03B2;</italic><sub>2</sub> &#x2212; <italic>&#x03B2;</italic><sub>1</sub>.</p>
</sec>
<sec><title>Random stimulus model (RSM)</title>
<p>The RSM that we estimated in each iteration is:
<disp-formula><alternatives><graphic xlink:href="077131_ueqn38.gif"/></alternatives></disp-formula></p>
<p>For stimulus category A,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn39.gif"/></alternatives></disp-formula></p>
<p>For stimulus category B,
<disp-formula><alternatives><graphic xlink:href="077131_ueqn40.gif"/></alternatives></disp-formula></p>
<p>The contrast between the stimulus categories was computed as <italic>&#x03B2;</italic><sub>2</sub> &#x2212; <italic>&#x03B2;</italic><sub>1</sub>.</p>
</sec>
<sec><title>False positive rates under the SPM model</title>
<p>We first present the results for the false positive rates (i.e., Type 1 error rates) of the SPM model in a separate simulation identical to the main simulation, but with <italic>&#x03B2;</italic><sub>1</sub>&#x003D;<italic>&#x03B2;</italic><sub>2</sub>&#x003D;1, so that the null hypothesis of no difference in the fixed category means is true. These error rates are based on running 500 iterations for each parameter combination, and they are computed for several levels of <italic>&#x03B1;</italic>, the decision threshold. Test levels of <italic>&#x03B1;</italic>&#x003D; 0.05, 0.01, 0.005 and 0.001 are considered, which have nominal Monte Carlo 95&#x0025; confidence intervals of &#x00B1; 0.019, &#x00B1; 0.009, &#x00B1; 0.006, and &#x00B1; 0.003, respectively.</p>
<table-wrap id="utbl1" orientation="portrait" position="float">
<graphic xlink:href="077131_utbl1.tif"/>
</table-wrap>
<table-wrap id="utbl2" orientation="portrait" position="float">
<graphic xlink:href="077131_utbl2.tif"/>
</table-wrap>
</sec>
<sec><title>Inflation of test statistics</title>
<p>The plots below show the simulated test statistics for the contrast between the two stimulus categories for all four models in each parameter combination. The points in each panel give the mean test statistic across 500 simulation runs, and the error bars span plus-or-minus one standard deviation of the test statistics across the 500 simulation runs. It is worth noting that the parameter estimates we obtained for all three of the Bayesian models described above were not discernibly affected by the particular choice of priors. While we initially experimented with more informative priors (e.g., modeling stimulus or subject variances as &#x007E; HalfCauchy(1), the insensitivity of the posterior estimates to the choice of prior ultimately led us to opt for the relatively weak, or uninformative, priors detailed above. The interpretation of these simulation results is given in the Methods section in the main text. The full simulation results for all parameters of all models under all parameter combinations can be found at <ext-link ext-link-type="uri" xlink:href="http://github.com/PsychoinformaticsLab/nipymc">http://github.com/PsychoinformaticsLab/nipymc</ext-link>.</p>
<fig id="ufig1" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="077131_ufig1.tif"/>
</fig>
<fig id="ufig2" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="077131_ufig2.tif"/>
</fig>
<fig id="ufig3" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="077131_ufig3.tif"/>
</fig>
</sec>
</sec>
</app>
</app-group>
<ref-list><title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Baayen</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Davidson</surname>, <given-names>D. J.</given-names></string-name>, &#x0026; <string-name><surname>Bates</surname>, <given-names>D. M.</given-names></string-name> (<year>2008</year>). <article-title>Mixed-effects modeling with crossed random effects for subjects and items</article-title>. <source>Journal of Memory and Language</source>, <volume>59</volume>(<issue>4</issue>), <fpage>390</fpage>&#x2013;<lpage>412</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Harms</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Corbetta</surname>, <given-names>M.</given-names></string-name>,&#x2026; <collab>WU-Minn HCP Consortium</collab>. (<year>2013</year>). <article-title>Function in the human connectome: task-fMRI and individual differences in behavior</article-title>. <source>NeuroImage</source>, <volume>80</volume>, <fpage>169</fpage>&#x2013;<lpage>189</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Bastien</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Lamblin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pascanu</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Bergstra</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Goodfellow</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Bergeron</surname>, <given-names>A.</given-names></string-name>,&#x2026; <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> (<year>2012</year>, November 23). <article-title>Theano: new features and speed improvements</article-title>. <source>arXiv [cs.SC]</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1211.5590">http://arxiv.org/abs/1211.5590</ext-link></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Bates</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Douglas</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ben</surname>, <given-names>B.</given-names></string-name>, &#x0026; <string-name><surname>Steve</surname>, <given-names>W.</given-names></string-name> (<year>2015</year>). <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>Journal of Statistical Software</source>, <volume>67</volume>(<issue>1</issue>). <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.18637/jss.v067.i01">http://doi.org/10.18637/jss.v067.i01</ext-link></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bedny</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Aguirre</surname>, <given-names>G. K.</given-names></string-name>, &#x0026; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L.</given-names></string-name> (<year>2007</year>). <article-title>Item analysis in functional magnetic resonance imaging</article-title>. <source>NeuroImage</source>, <volume>35</volume>(<issue>3</issue>), <fpage>1093</fpage>&#x2013;<lpage>1102</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="book"><string-name><surname>Bergstra</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Breuleux</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Bastien</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Lamblin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pascanu</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Desjardins</surname>, <given-names>G.</given-names></string-name>,&#x2026; <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> (<year>2010</year>). <chapter-title>Theano: a CPU and GPU math expression compiler</chapter-title>. In <source>Proceedings of the Python for scientific computing conference (SciPy)</source> (Vol. <volume>4</volume>, p. <fpage>3</fpage>). <publisher-loc>Austin, TX</publisher-loc>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Breiter</surname>, <given-names>H. C.</given-names></string-name>, <string-name><surname>Etcoff</surname>, <given-names>N. L.</given-names></string-name>, <string-name><surname>Whalen</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Kennedy</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Rauch</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Buckner</surname>, <given-names>R. L.</given-names></string-name>,&#x2026; <string-name><surname>Rosen</surname>, <given-names>B. R.</given-names></string-name> (<year>1996</year>). <article-title>Response and habituation of the human amygdala during visual processing of facial expression</article-title>. <source>Neuron</source>, <volume>17</volume>(<issue>5</issue>), <fpage>875</fpage>&#x2013;<lpage>887</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Carp</surname>, <given-names>J.</given-names></string-name> (<year>2012</year>). <article-title>On the plurality of (methodological) worlds: Estimating the analytic flexibility of fmri experiments</article-title>. <source>Frontiers in Neuroscience</source>, (OCT). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/23087605">http://www.ncbi.nlm.nih.gov/pubmed/23087605</ext-link></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Chang</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Gianaros</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Manuck</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Krishnan</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name> (<year>2015</year>). <article-title>A Sensitive and Specific Neural Signature for Picture-Induced Negative Affect</article-title>. <source>PLoS Biology</source>, <volume>13</volume>(<issue>6</issue>), <fpage>e1002180</fpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname>, <given-names>J. R.</given-names></string-name> (<year>2009</year>). <source>The development and generality of self-control</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://gradworks.umi.com/34/01/3401764.html">http://gradworks.umi.com/34/01/3401764.html</ext-link></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Donnet</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lavielle</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Poline</surname>, <given-names>J.-B.</given-names></string-name> (<year>2006</year>). <article-title>Are fMRI event-related response constant in time? A model selection answer</article-title>. <source>NeuroImage</source>, <volume>31</volume>(<issue>3</issue>), <fpage>1169</fpage>&#x2013;<lpage>1176</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name> (<year>2006</year>). <article-title>Prior distributions for variance parameters in hierarchical models (Comment on Article by Browne and Draper)</article-title>. <source>Bayesian Analysis</source>, <volume>1</volume>(<issue>3</issue>), <fpage>515</fpage>&#x2013;<lpage>534</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Hill</surname>, <given-names>J.</given-names></string-name> (<year>2007</year>). <source>Data Analysis Using Regression and Multilevel/Hierarchical Models</source>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Sotiropoulos</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Coalson</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Andersson</surname>, <given-names>J. L.</given-names></string-name>,&#x2026; <collab>WU-Minn HCP Consortium</collab>. (<year>2013</year>). <article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title>. <source>NeuroImage</source>, <volume>80</volume>, <fpage>105</fpage>&#x2013;<lpage>124</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rivera</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Schwarz</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Maumet</surname>, <given-names>C.</given-names></string-name>,&#x2026; <string-name><surname>Margulies</surname>, <given-names>D. S.</given-names></string-name> (<year>2015</year>). <article-title>NeuroVault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>9</volume>, 8.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Hariri</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Mattay</surname>, <given-names>V. S.</given-names></string-name>, <string-name><surname>Tessitore</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kolachana</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Fera</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Goldman</surname>, <given-names>D.</given-names></string-name>,&#x2026; <string-name><surname>Weinberger</surname>, <given-names>D. R.</given-names></string-name> (<year>2002</year>). <article-title>Serotonin transporter genetic variation and the response of the human amygdala</article-title>. <source>Science</source>, <volume>297</volume>(<issue>5580</issue>), <fpage>400</fpage>&#x2013;<lpage>403</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Hoffman</surname>, <given-names>M. D.</given-names></string-name>, &#x0026; <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name> (<year>2014</year>). <article-title>The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo</article-title>. <source>Journal of Machine Learning Research: JMLR</source>, <volume>15</volume>, 30.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Judd</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Westfall</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Kenny</surname>, <given-names>D. A.</given-names></string-name> (<year>2012</year>). <article-title>Treating stimuli as a random factor in social psychology: A new and comprehensive solution to a pervasive but largely ignored problem</article-title>. <source>J. Pers. Soc. Psychol.</source> <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1037/a0028347">http://doi.org/10.1037/a0028347</ext-link></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>McDermott</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Chun</surname>, <given-names>M. M.</given-names></string-name> (<year>1997</year>). <article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title>. <source>Journal of Neuroscience</source>, <volume>17</volume>(<issue>11</issue>), <fpage>4302</fpage>&#x2013;<lpage>4311</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Kruschke</surname>, <given-names>J. K.</given-names></string-name> (<year>2013</year>). <article-title>Bayesian estimation supersedes the t test</article-title>. <source>Journal of Experimental Psychology. General</source>, <volume>142</volume>(<issue>2</issue>), <fpage>573</fpage>&#x2013;<lpage>603</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Lieberman</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Hariri</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jarcho</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Eisenberger</surname>, <given-names>N. I.</given-names></string-name>, &#x0026; <string-name><surname>Bookheimer</surname>, <given-names>S. Y.</given-names></string-name> (<year>2005</year>). <article-title>An fMRI investigation of race-related amygdala activity in African-American and Caucasian-American individuals</article-title>. <source>Nature Neuroscience</source>, <volume>8</volume>(<issue>6</issue>), <fpage>720</fpage>&#x2013;<lpage>722</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Morris</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Frith</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Perrett</surname>, <given-names>D. I.</given-names></string-name>, <string-name><surname>Rowland</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Young</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Calder</surname>, <given-names>A. J.</given-names></string-name>, &#x0026; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>1996</year>). <article-title>A differential neural response in the human amygdala to fearful and happy facial expressions</article-title>. <source>Nature</source>, <volume>383</volume>(<issue>6603</issue>), <fpage>812</fpage>&#x2013;<lpage>815</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>B. O.</given-names></string-name>, <string-name><surname>Ashby</surname>, <given-names>F. G.</given-names></string-name>, &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2012</year>). <article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title>. <source>NeuroImage</source>, <volume>59</volume>(<issue>3</issue>), <fpage>2636</fpage>&#x2013;<lpage>2643</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Patil</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Huard</surname>, <given-names>D.</given-names></string-name>, &#x0026; <string-name><surname>Fonnesbeck</surname>, <given-names>C. J.</given-names></string-name> (<year>2010</year>). <article-title>PyMC: Bayesian Stochastic Modelling in Python</article-title>. <source>Journal of Statistical Software</source>, <volume>35</volume>(<issue>4</issue>), <fpage>1</fpage>&#x2013;<lpage>81</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Penny</surname>, <given-names>W. D.</given-names></string-name>, <string-name><surname>Holmes</surname>, <given-names>A. P.</given-names></string-name>, &#x0026; <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name> (<year>2003</year>). <article-title>Random effects analysis</article-title>. <source>Human Brain Function</source>, <volume>2</volume>, <fpage>843</fpage>&#x2013;<lpage>850</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, &#x0026; <string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> (<year>2015</year>). <article-title>OpenfMRI: Open sharing of task fMRI data</article-title>. <source>NeuroImage</source>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1016/j.neuroimage.2015.05.073">http://doi.org/10.1016/j.neuroimage.2015.05.073</ext-link></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="book"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, &#x0026; <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name> (<year>2011</year>). <source>Handbook of Functional MRI Data Analysis</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Raaijmakers</surname>, <given-names>J. G. W.</given-names></string-name> (<year>2003</year>). <article-title>A further look at the &#x201C;language-as-fixed-effect fallacy</article-title>.&#x201D; <source>Canadian Journal of Experimental Psychology&#x003D;Revue Canadienne de Psychologie Experimentale</source>, <volume>57</volume>(<issue>3</issue>), <fpage>141</fpage>&#x2013;<lpage>151</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Raaijmakers</surname>, <given-names>J. G. W.</given-names></string-name>, <string-name><surname>Schrijnemakers</surname>, <given-names>J. M. C.</given-names></string-name>, &#x0026; <string-name><surname>Gremmen</surname>, <given-names>F.</given-names></string-name> (<year>1999</year>). <article-title>How to Deal with &#x201C;The Language-as-Fixed-Effect Fallacy&#x201D;: Common Misconceptions and Alternative Solutions</article-title>. <source>Journal of Memory and Language</source>, <volume>41</volume>(<issue>3</issue>), <fpage>416</fpage>&#x2013;<lpage>426</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Salvatier</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wiecki</surname>, <given-names>T.</given-names></string-name>, &#x0026; <string-name><surname>Fonnesbeck</surname>, <given-names>C.</given-names></string-name> (<year>2015</year>, July 29). <article-title>Probabilistic Programming in Python using PyMC</article-title>. <source>arXiv [stat.CO]</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1507.08050">http://arxiv.org/abs/1507.08050</ext-link></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, &#x0026; <collab>WU-Minn HCP Consortium</collab>. (<year>2013</year>). <article-title>The WU-Minn Human Connectome Project: an overview</article-title>. <source>NeuroImage</source>, <volume>80</volume>, <fpage>62</fpage>&#x2013;<lpage>79</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Westfall</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kenny</surname>, <given-names>D. A.</given-names></string-name>, &#x0026; <string-name><surname>Judd</surname>, <given-names>C. M.</given-names></string-name> (<year>2014</year>). <article-title>Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli</article-title>. <source>Journal of Experimental Psychology. General</source>, <volume>143</volume>(<issue>5</issue>), <fpage>2020</fpage>&#x2013;<lpage>2045</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Wickens</surname>, <given-names>T. D.</given-names></string-name>, &#x0026; <string-name><surname>Keppel</surname>, <given-names>G.</given-names></string-name> (<year>1983</year>). <article-title>On the choice of design and of test statistic in the analysis of experiments with sampled materials</article-title>. <source>Journal of Verbal Learning and Verbal Behavior</source>, <volume>22</volume>(<issue>3</issue>), <fpage>296</fpage>&#x2013;<lpage>309</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Wolsiefer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Westfall</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Judd</surname>, <given-names>C. M.</given-names></string-name> (<year>2016</year>). <article-title>Modeling stimulus variation in three common implicit attitude tasks</article-title>. <source>Behavior Research Methods</source>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.3758/s13428-016-0779-0">http://doi.org/10.3758/s13428-016-0779-0</ext-link></mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn1"><label><sup>1</sup></label><p>While the full model as written here cannot be estimated in standard software due to the limitations we mentioned, it is possible to use standard software to fit a slightly simplified, approximate version of this model, quite similar to what (<xref ref-type="bibr" rid="c13">Gelman &#x0026; Hill, 2007</xref>) refer to as a &#x201C;no-pooling model.&#x201D; As we discuss in <xref ref-type="app" rid="app1">Appendix 1</xref>, we did apply this approximate model to one of our reanalyzed datasets, the (<xref ref-type="bibr" rid="c9">Chang, Gianaros, Manuck, Krishnan, &#x0026; Wager, 2015</xref>) data.</p></fn>
</fn-group>
</back>
</article>
