<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/284562</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A probabilistic interpretation of PID controllers using active inference</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6086-4711</contrib-id>
<name><surname>Baltieri</surname><given-names>Manuel</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8551-9121</contrib-id>
<name><surname>Buckley</surname><given-names>Christopher L.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Evolutionary and Adaptive Systems Group, Department of Informatics, University of Sussex</institution>, Brighton, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>Sussex Neuroscience, University of Sussex</institution>, Brighton, <country>UK</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author; email: <email>m.baltieri@sussex.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>284562</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>18</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>19</day>
<month>3</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="284562.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>In the past few decades, probabilistic interpretations of brain functions have become widespread in cognitive science and neuroscience. The Bayesian brain hypothesis, predictive coding, the free energy principle and active inference are increasingly popular theories of cognitive functions that claim to unify understandings of life and cognition within general mathematical frameworks derived from information theory, statistical physics and machine learning. Furthermore, it has been argued that one such proposal, active inference, combines both information and control theory and has its roots in cybernetics studies of the brain. The connections between information and control theory have been discussed since the 1950&#x2019;s by scientists like Shannon and Kalman and have recently risen to prominence in modern stochastic optimal control theory. How-ever, the implications of the confluence of these two theoretical frame-works for the biological sciences have been slow to emerge. Here we argue that if the active inference proposal is to be taken as a general process theory for biological systems, we need to consider how existing control theoretical approaches to biological systems relate to it. In this work we will focus on PID (Proportional-Integral-Derivative) controllers, one of the most common types of regulators employed in engineering and more recently used to explain behaviour in biological systems, e.g. chemotaxis in bacteria and amoebae or robust adaptation in biochemical networks. Using active inference, we derive a probabilistic interpretation of PID controllers, showing how they can fit a more general theory of life and cognition under the principle of (variational) free energy minimisation once we use only simple linear generative models.</p>
</abstract>
<counts>
<page-count count="12"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Probabilistic approaches to the study of living systems and cognition are becoming increasingly popular in the natural sciences. In particular for the brain sciences, theories inspired the Bayesian brain hypothesis such as predictive coding, the free energy principle and active inference have been used to explain mechanism of the brain and cognition including perception, action and higher order functions [<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c32" ref-type="bibr">32</xref>, <xref rid="c30" ref-type="bibr">30</xref>, <xref rid="c21" ref-type="bibr">21</xref>, <xref rid="c11" ref-type="bibr">11</xref>, <xref rid="c27" ref-type="bibr">27</xref>, <xref rid="c7" ref-type="bibr">7</xref>, <xref rid="c8" ref-type="bibr">8</xref>].</p>
<p>According to these theories, brains, and biological systems more in general, should be thought of as Bayesian inference machines, gathering and representing information from the environment into generative models [<xref rid="c21" ref-type="bibr">21</xref>, <xref rid="c11" ref-type="bibr">11</xref>, <xref rid="c27" ref-type="bibr">27</xref>]. Such systems in fact appear to estimate the latent causes of their sensory input in a process consistent with a Bayesian inference scheme. In particular it has been suggested that perceptual process can be accounted for in terms of predictive coding models whereby feedforward prediction errors and feedback predictions are combined within a generative model to infer the hidden causes of sensory data [<xref rid="c32" ref-type="bibr">32</xref>]. More recent theories have extended this proposal to account also for motor control and behaviour [<xref rid="c25" ref-type="bibr">25</xref>, <xref rid="c18" ref-type="bibr">18</xref>]. On this view, behaviour is cast as a process of acting on the world to make sensory data better fit existing predictions. This latter process usually falls under the name of <italic>active inference</italic>.</p>
<p>Modelling approaches inspired by control theory are nowadays established methodologies for instance in psychology [<xref rid="c31" ref-type="bibr">31</xref>, <xref rid="c9" ref-type="bibr">9</xref>], and are increasingly popular in fields such as biology [<xref rid="c40" ref-type="bibr">40</xref>, <xref rid="c39" ref-type="bibr">39</xref>, <xref rid="c1" ref-type="bibr">1</xref>]. Typically inspired by classical control theory and dynamical system theory, they emphasise regulation and concepts such as set-point control and negative feedback for the study of different aspects of living systems, an approach first introduced with cybernetics [<xref rid="c3" ref-type="bibr">3</xref>, <xref rid="c37" ref-type="bibr">37</xref>]. In particular, methods such as PID (Proportional-Integral-Derivative) control have been widely used as they represent a very simple methodology with properties that guarantee robustness to perturbations and noise [<xref rid="c40" ref-type="bibr">40</xref>, <xref rid="c39" ref-type="bibr">39</xref>, <xref rid="c1" ref-type="bibr">1</xref>, <xref rid="c33" ref-type="bibr">33</xref>].</p>
<p>The relationship between information/probability theory and control theory has long been recognised, with the first intuitions (as far as the authors are aware) emerging from work by Shannon [<xref rid="c35" ref-type="bibr">35</xref>] and Kalman [<xref rid="c29" ref-type="bibr">29</xref>]. A unifying view of these two theoretical frameworks is nowadays proposed for instance in stochastic optimal control [<xref rid="c36" ref-type="bibr">36</xref>] and active inference [<xref rid="c19" ref-type="bibr">19</xref>, <xref rid="c34" ref-type="bibr">34</xref>]. How these ideas can be used to combine traditional concepts of control more commonly applied in biology with frameworks like active inference is still however unclear. Here, to address this, we develop an information theoretic interpretation of PID controllers, a very popular control strategy that works with little prior knowledge of the process to regulate. Starting from ideas proposed by the free energy principle, we will show that simple linear generative models only approximating the true dynamics of the environment can implement PID control as a process of active inference.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>The free energy principle</title>
<p>The free energy principle (FEP) was initially introduced by Karl Friston [<xref rid="c21" ref-type="bibr">21</xref>] and later elaborated in a series of papers [<xref rid="c17" ref-type="bibr">17</xref>, <xref rid="c18" ref-type="bibr">18</xref>, <xref rid="c23" ref-type="bibr">23</xref>]. The FEP is proposed as a unifying theory for biological sciences with roots in information theory, thermo-dynamics and statistical mechanics. Work on the FEP has so far covered computational neuroscience [<xref rid="c15" ref-type="bibr">15</xref>, <xref rid="c16" ref-type="bibr">16</xref>], and behavioural/cognitive neuroscience studies [<xref rid="c25" ref-type="bibr">25</xref>, <xref rid="c22" ref-type="bibr">22</xref>]. Furthermore, connections have been implied with theories of biological self-organisation, information theory (e.g. infomax principle), optimal control, cybernetics and economics (e.g. utility theory) among others [<xref rid="c18" ref-type="bibr">18</xref>, <xref rid="c19" ref-type="bibr">19</xref>, <xref rid="c20" ref-type="bibr">20</xref>, <xref rid="c34" ref-type="bibr">34</xref>]. According to the FEP, a living system system exists only in a limited set of states over time, e.g. a fish can&#x2019;t survive for long out of water. Biological creatures can thus be seen as systems that minimise the surprisal (or suprise) of their sensory observations to maintain their existence, e.g. a fish&#x2019; observations should be limited to states in the water. Since this surprisal is not directly accessible by an agent [<xref rid="c21" ref-type="bibr">21</xref>], variational free energy is proposed as a proxy that can be minimised in its place, acting as an upper bound for such quantity.</p>
<p>In this study we will focus on hypotheses and theories linked to the FEP regarding perception and action in agents, in particular predictive coding and active inference. Predictive coding [<xref rid="c32" ref-type="bibr">32</xref>] models of information processing in the brain are a special case of the FEP [<xref rid="c18" ref-type="bibr">18</xref>] and prescribe a way in which top-down and bottom-up information flows could be combined in the cortex following a formulation based on generative models. Top-down processes provide predictions about sensory input while bottom-up activity carries prediction errors representing the difference between real and predicted sensations. These errors are then used to train a generative model to produce better predictions. The minimisation of prediction errors achieved by changing the model to better represent an agent&#x2019;s sensations corresponds, on this view, to perception.</p>
<p>One of the main contributions of the FEP is however the extension of predictive coding models to include accounts of action otherwise missing. The introduction of <italic>active inference</italic> [<xref rid="c24" ref-type="bibr">24</xref>, <xref rid="c25" ref-type="bibr">25</xref>] represents in fact a way to unify perception and action in a cohesive mathematical framework where differences between the two processes almost vanish.</p>
<sec id="s2a">
<label>2.1</label>
<title>Active inference and control</title>
<p>Active inference provides a second way in which prediction errors, or free energy, can be minimised. While perceptual inference suppresses prediction errors only by updating a generative model [<xref rid="c17" ref-type="bibr">17</xref>, <xref rid="c25" ref-type="bibr">25</xref>], active inference suppresses error also by directly acting on the environment and changing sensory input to better accord with existing predictions. If a generative model encodes information about desired/favourable states for an agent, then this process constitutes a way by which an agent can change its environment to better meet its needs. Thus, under the FEP, these two processes of error suppression allow an agent to both perceive and control the surrounding environment.</p>
<p>Most agent-based models implementing ideas of the FEP and active inference assume that agents have a deep understanding of their environment and its dynamics in the form of an accurate and detailed generative model. For instance, in [<xref rid="c24" ref-type="bibr">24</xref>, <xref rid="c25" ref-type="bibr">25</xref>] the generative model of the agent explicitly mirrors the <italic>generative process</italic> of the environment, i.e. the dynamics of the world the agent interacts with. In recent work we have argued that this needs not be the case [<xref rid="c6" ref-type="bibr">6</xref>], especially if we consider simple living systems with limited resources. We intuitively don&#x2019;t expect an ant to explicitly model the environment where it forages, performing complex simulations of the environment in its brain (cf. the concept of Umwelt [<xref rid="c10" ref-type="bibr">10</xref>]). This idea is however common in other authors&#x2019; work [<xref rid="c27" ref-type="bibr">27</xref>]. According to this perspective, cognition and perception are processes of inference to the best explanation, encoding an accurate set of parameters and variables of the environment with agents seen as mainly building sophisticated models of their worlds used then for action and behaviour. One implicit assumption is that <italic>all</italic> the information available to an agent should be encoded (e.g. an ant modelling the entire environment). This assumption is however not reasonable in dynamic and complex environments: when variables and parameters change rapidly, accurate online inference and learning are implausible [<xref rid="c2" ref-type="bibr">2</xref>]. A possible alternative introduces action-oriented representations entailing a more parsimonious approach where only task-relevant information is encoded [<xref rid="c12" ref-type="bibr">12</xref>, <xref rid="c13" ref-type="bibr">13</xref>]. On this view, agents only model environmental properties that are necessary for their behaviour and their goals.</p>
<p>In this work we present an example of such parsimonious, action-oriented probabilistic representations described in [<xref rid="c12" ref-type="bibr">12</xref>, <xref rid="c13" ref-type="bibr">13</xref>], connecting them to methods from classic control theory. We will focus in particular on Proportional-Integral-Derivative (PID) control, both extensively used in industry [<xref rid="c5" ref-type="bibr">5</xref>] and more recently emerging as a model of robust feedback mechanisms in biology, implemented for instance in bacteria [<xref rid="c40" ref-type="bibr">40</xref>], amoeba [<xref rid="c39" ref-type="bibr">39</xref>] and gene networks [<xref rid="c1" ref-type="bibr">1</xref>], and in psychology [<xref rid="c33" ref-type="bibr">33</xref>]. The popularity of PID controllers in engineering is mostly due to the fact that one needs only very little knowledge of the process to regulate. In active inference we will show that this corresponds to linear generative models that only approximate general properties of the world dynamics. Specifically, our model will describe linear dynamics for a single hidden state and a linear mapping from the hidden state to an observed variable, representing knowledge of the world that is potentially far removed from the real complexity behind observations and their hidden causes.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>PID control</title>
<p>Proportional-Integral-Derivative (PID) control is one of the simplest set-point controllers, whereby a desired state (i.e. set-point, reference) represents the final goal of the regulation process, e.g. to maintain a room temperature of 23&#x00B0; C. PID controllers are based on closed-loop strategies with a negative feedback mechanism that tracks the real state of the environment. The difference between such state and the target value (e.g. 23<italic>&#x00B0;</italic> C temperature) produces a prediction error whose minimisation drives the controller, e.g. if the temperature is too high, it decreases it and if too low, it raises it. In mathematical terms:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="284562v1_eqn1.gif"/></alternatives>
</disp-formula>
where <italic>e</italic>(<italic>t</italic>) is the error, <italic>y</italic><sub><italic>r</italic></sub> is the <italic>reference</italic> or set-point (e.g. desired temperature) and <italic>y</italic>(<italic>t</italic>) is the observed variable (e.g. the actual room temperature).</p>
<p>This mechanism is however unstable in very common conditions, in particular when a steady-state offset is added (e.g. a sudden and unpredictable change in external conditions affecting the room temperature which are not under our control), or when fluctuations need to be repressed (e.g. too many oscillations in the temperature on the trajectory to the desired state may be undesirable). PID controllers deal with both of these problems by augmenting the more standard negative feedback architecture, here called <italic>proportional</italic> or <italic>P term</italic>, with an <italic>integral</italic> or <italic>I</italic> and a <italic>derivative</italic> or <italic>D term</italic>, see <xref rid="fig1" ref-type="fig">Fig. 1</xref>. The integral term accumulates the prediction error over time in order to cancel out errors due to steady-state input, while the minimisation of the derivative of the prediction error leads to a decrease in the amplitude of fluctuations. The general form of the control signal <italic>u</italic>(<italic>t</italic>) generated by a PID controller is usually described by:</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1.</label>
<caption><p>A PID controller. The prediction error <italic>e</italic>(<italic>t</italic>) is given by the difference between a reference (desired) signal <italic>r</italic>(<italic>t</italic>) or <italic>y</italic><sub><italic>r</italic></sub> in our formulation, and the output <italic>y</italic>(<italic>t</italic>) of a process. The different terms, one proportional to the error (P term), one integrating the error over time (I term) and one differentiating it over time (D term), drive the control signal <italic>u</italic>(<italic>t</italic>). Image by Arturo Urquizo - <ext-link ext-link-type="uri" xlink:href="http://commons.wikimedia.org/wiki/File:PID.svg">http://commons.wikimedia.org/wiki/File:PID.svg</ext-link>, CC BY-SA 3.0, <ext-link ext-link-type="uri" xlink:href="https://commons.wikimedia.org/w/index.php?curid=17633925">https://commons.wikimedia.org/w/index.php?curid=17633925</ext-link></p></caption>
<graphic xlink:href="284562v1_fig1.tif"/>
</fig>
<p><disp-formula id="eqn2">
<alternatives><graphic xlink:href="284562v1_eqn2.gif"/></alternatives>
</disp-formula>
where <italic>e</italic>(<italic>t</italic>) is again the prediction error and <italic>k</italic><sub><italic>p</italic></sub>, <italic>k</italic><sub><italic>i</italic></sub>, <italic>k</italic><sub><italic>d</italic></sub> are the so called proportional, integral and derivative gains respectively, a set of parameters used to tune the relative strength of the P, I and D terms of the controller.</p>
<p>The popularity of PID controllers is largely due to: 1) their robustness in the presence of uncertainty, i.e. step disturbances and more in general noise, given by their filtering properties (I term), and 2) an only approximate model of the dynamics of the process to regulate, based on a linearisation around the target state. While this might look incompatible with work in active inference formulations suggesting a link to optimal control strategies with perfect models of process/environment, we argued previously that this needs not be the case [<xref rid="c6" ref-type="bibr">6</xref>]. One of the main strengths of active inference lies, according to us, in its general formulation and in generative models that do not have to mirror the dynamics of the environment, perhaps due to limitations or constraints of a system (e.g. an ant incapable of encoding the entire map of the world).</p>
</sec>
<sec id="s4">
<label>4</label>
<title>PID control as active inference</title>
<p>In this work we will not provide a complete derivation of the active inference scheme, referring to previous treatments [<xref rid="c26" ref-type="bibr">26</xref>, <xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>] for more details. Here we will begin from the Laplace encoded variational free energy for a univariate case:
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="284562v1_eqn3.gif"/></alternatives>
</disp-formula>
where <italic>&#x03C1;</italic> represents the observed sensory input of an agent and <italic>&#x00B5;</italic><sub><italic>x</italic></sub> the sufficient statistics, here just the mean, encoding the expectation of some hidden state <italic>x</italic> in the environment. The constants within the free energy will not be discussed here since they play no role in the minimisation scheme we present.</p>
<p>As previously shown [<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>], to minimise <xref ref-type="disp-formula" rid="eqn3">equation (3)</xref> we need to specify the agent&#x2019;s generative density <italic>P</italic> (<italic>&#x03C1;, &#x00B5;</italic><sub><italic>x</italic></sub>) = <italic>P</italic> (<italic>&#x03C1;</italic>&#x007C;<italic>&#x00B5;</italic><sub><italic>x</italic></sub>)<italic>P</italic> (<italic>&#x00B5;</italic><sub><italic>x</italic></sub>) introducing a likelihood <italic>P</italic> (<italic>&#x03C1;</italic>&#x007C;<italic>&#x00B5;</italic><sub><italic>x</italic></sub>) and a prior <italic>P</italic> (<italic>&#x00B5;</italic><sub><italic>x</italic></sub>) in terms of an agent&#x2019;s beliefs <italic>&#x00B5;</italic><sub><italic>x</italic></sub>. These probabilities can be specified by a generative model in the form of a state space model. In particular, to get the integral, proportional and derivative terms of a PID controller, we will use a <italic>generalised</italic> linear state space model of order 2 [<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>]:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="284562v1_eqn4.gif"/></alternatives>
</disp-formula>
where <italic>&#x03C1;</italic> is the observation of the proprioceptive signal and <italic>x</italic> is the estimated hidden state, <italic>&#x03B7;</italic> encodes a desired state (e.g. desired temperature) represented mathematically as an exogenous or external input (or as a prior from higher layers in hierarchical models [<xref rid="c16" ref-type="bibr">16</xref>]) and <italic>z, w</italic> are zero-mean Gaussian random variables. As we shall see later, <italic>&#x03B7;</italic> is equivalent to <italic>y</italic><sub><italic>r</italic></sub> in <xref ref-type="disp-formula" rid="eqn1">equation (1)</xref>. However, unlike more standard PID schemes, <italic>&#x03B7;</italic> is here specified as a function of time using generalised coordinates of motion (explained below). At the end, this derivation will collapse to a more standard set-point scheme when <italic>&#x03B7;</italic> = <italic>y</italic><sub><italic>r</italic></sub> and <italic>&#x03B7;&#x2032;</italic> = <italic>&#x03B7;&#x2032;&#x2032;</italic> = 0. The prime (e.g. <italic>&#x03C1;&#x2032;, &#x03C1;&#x2032;&#x2032;</italic>) indicates the order of generalised coordinate of motion of each variable [<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>]. Generalised coordinates of motion are introduced to represent non-Markovian continuous stochastic processes [<xref rid="c28" ref-type="bibr">28</xref>], in our case <italic>z, w</italic>. One could think of them as quantities conveying information about &#x201C;velocity&#x201D; (e.g. <italic>&#x03C1;&#x2032;</italic>), &#x201C;acceleration&#x201D; (e.g. <italic>&#x03C1;&#x2032;&#x2032;</italic>), etc. for each of the variables. Following the notation previously introduced in [<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>], we then define:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="284562v1_eqn5.gif"/></alternatives>
</disp-formula>
where the tilde sign (e.g.<inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline1.gif"/></alternatives></inline-formula>) summarises the generalised state, a variable and its higher orders, into a more compact description (e.g. <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline2.gif"/></alternatives></inline-formula>).</p>
<p>With the assumption that random variables <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline2a.gif"/></alternatives></inline-formula> are normally distributed (making the likelihood <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline3.gif"/></alternatives></inline-formula> and the prior <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline3a.gif"/></alternatives></inline-formula> of Gaussian form), the variational free energy reduces to:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="284562v1_eqn6.gif"/></alternatives>
</disp-formula>
where we used the means <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline6.gif"/></alternatives></inline-formula> of the estimated hidden states rather than the states <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline7.gif"/></alternatives></inline-formula> themselves since <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline8.gif"/></alternatives></inline-formula> are the only sufficient statistics required for the minimisation of free energy under the assumption of optimal (co)variances of the recognition density (see [<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>]). <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline9.gif"/></alternatives></inline-formula> are the precision parameters (inverse variances) of <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline10.gif"/></alternatives></inline-formula> respectively. Following [<xref rid="c26" ref-type="bibr">26</xref>, <xref rid="c16" ref-type="bibr">16</xref>], the optimisation of the Laplace encoded free energy can be performed via a standard gradient descent procedure:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="284562v1_eqn7.gif"/></alternatives>
</disp-formula>
where the two equations prescribe perception and action processes respectively. The first equation includes an extra term <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline11.gif"/></alternatives></inline-formula> that represents the &#x201C;mode of the path&#x201D; in the minimisation of variables in generalised coordinates of motion [<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c8" ref-type="bibr">8</xref>], with <italic>D</italic> as a differential operator with respect to time, i.e. <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline12.gif"/></alternatives></inline-formula>. More intuitively, since we are now minimising the components of a generalised state representing a trajectory rather than a static variable, variables are in a moving framework of reference where the minimisation is achieved for <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline13.gif"/></alternatives></inline-formula> rather than <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline14.gif"/></alternatives></inline-formula>. In the second equation, an assumption of active inference is that actions <italic>a</italic> only affect sensory input <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline15.gif"/></alternatives></inline-formula> and furthermore that this mapping is then known to an agent as a reflex mechanism, see [<xref rid="c25" ref-type="bibr">25</xref>] for discussion. By applying the gradient descent described in <xref ref-type="disp-formula" rid="eqn7">equation (7)</xref> to our free energy function in <xref ref-type="disp-formula" rid="eqn6">equation (6)</xref>, we obtain the following update equations for perception:
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="284562v1_eqn8.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline16.gif"/></alternatives></inline-formula> since we truncated our generalised state-space model to order 2 (i.e. anything beyond that is zero-mean Gaussian noise), and for action respectively:
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="284562v1_eqn9.gif"/></alternatives>
</disp-formula>
The mapping of these equations to a PID control scheme becomes more clear once a few simplifying assumptions are taken. First we assume that the agent has strong priors (desires) on the causes of its proprioceptive observations. Intuitively, these strong priors will be used to define actions that change the observations to better fit the agent&#x2019;s desires. This is implemented in the weighting mechanism of prediction errors by precision parameters in <xref ref-type="disp-formula" rid="eqn6">equation (6)</xref>; see also [<xref rid="c25" ref-type="bibr">25</xref>, <xref rid="c6" ref-type="bibr">6</xref>] for similar discussions on the role of precision parameters for behaviour. Here we want to weight prediction errors on the expected causes, <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline17.gif"/></alternatives></inline-formula>, more than the ones on observations, <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline18.gif"/></alternatives></inline-formula>. We achieve this by enhancing top-down predictions of our agent, increasing precisions <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline19.gif"/></alternatives></inline-formula> and effectively biasing the gradient descent procedure towards minimising these errors. Perception can then be approximated as:
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="284562v1_eqn10.gif"/></alternatives>
</disp-formula>
which at steady state sets the expected hidden states <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline20.gif"/></alternatives></inline-formula> to the priors <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline21.gif"/></alternatives></inline-formula>. With fixed strong priors, to minimise free energy an agent will necessarily have to modify its sensory input <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline22.gif"/></alternatives></inline-formula> to better match expectations <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline23.gif"/></alternatives></inline-formula> reflecting priors (i.e. desires) <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline24.gif"/></alternatives></inline-formula>. Effectively, the agent &#x201C;imposes&#x201D; its desires on the world, driving actions that will minimise the prediction errors arising at the proprioceptive sensory layers. In essence, an active inference agent implements set-point regulation by acting to make its sensations accord with its strong priors/desires. After these assumptions, action can be written as:
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="284562v1_eqn11.gif"/></alternatives>
</disp-formula>
where we assumed <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline25.gif"/></alternatives></inline-formula>, but still need to specify partial derivatives <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline26.gif"/></alternatives></inline-formula>. As discussed previously [<xref rid="c25" ref-type="bibr">25</xref>], this step also highlights the fundamental differences between the FEP and the more traditional forward/inverse models formulation of control problems [<xref rid="c38" ref-type="bibr">38</xref>]. While these derivatives define a form of inverse model, unlike more traditional approaches this does not involve a mapping between actions and hidden states <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline27.gif"/></alternatives></inline-formula> but is cast in terms of sensory data <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline28.gif"/></alternatives></inline-formula> directly. It is claimed that this provides an easier implementation for such an inverse model [<xref rid="c19" ref-type="bibr">19</xref>], one that is grounded in an extrinsic frame of reference (i.e. the real world, <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline29.gif"/></alternatives></inline-formula>) rather than in a intrinsic one in terms of hidden states <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline30.gif"/></alternatives></inline-formula>. To achieve PID-like control, we finally assume that the agent encodes linear relationships between its actions (controls) and their effects on sensory input across all generalised coordinates of motion:
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="284562v1_eqn12.gif"/></alternatives>
</disp-formula>
This reflects a very simple reflex-arc-like mechanism that is triggered any time a proprioceptive prediction is made. Intuitively, positive actions increase the values of the sensed variables <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline31.gif"/></alternatives></inline-formula>, while negative actions decrease them. There is however an apparent inconsistency here that we need to dissolve: the proprioceptive input <italic>&#x03C1;</italic> and its higher order states <italic>&#x03C1;&#x2032;, &#x03C1;&#x2032;&#x2032;</italic> are <italic>all</italic> linearly dependent on actions <italic>a</italic> as represented by the inverse model in <xref ref-type="disp-formula" rid="eqn12">equation (12)</xref>. While an action may not change position, velocity and acceleration of a variable in the same way, the goal of an agent <bold>is not</bold> to perfectly represent its physical reality but just to encode sensorimotor properties that allow it to achieve its goals. In the same way, PID controllers are effective but only approximate solutions for control in most cases [<xref rid="c4" ref-type="bibr">4</xref>]. This allows us to understand the encoding of an inverse model from the perspective of an agent rather than assuming a perfect, objective mapping from sensations to actions that reflects exactly how actions affect sensory input [<xref rid="c25" ref-type="bibr">25</xref>]. This also points at possible investigations of generative/inverse models in simpler living systems where accurate internal models are not needed, and where strategies like PID control are implemented [<xref rid="c40" ref-type="bibr">40</xref>, <xref rid="c39" ref-type="bibr">39</xref>, <xref rid="c1" ref-type="bibr">1</xref>]. By combining <xref ref-type="disp-formula" rid="eqn11">equation (11)</xref> and <xref ref-type="disp-formula" rid="eqn12">equation (12)</xref>, action can then be simplified to:
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="284562v1_eqn13.gif"/></alternatives>
</disp-formula>
consistent with the so-called &#x201C;velocity form&#x201D; or &#x201C;velocity algorithm&#x201D; of a PID controller [<xref rid="c4" ref-type="bibr">4</xref>]. For comparison, the velocity form of <xref ref-type="disp-formula" rid="eqn2">equation (2)</xref> is:
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="284562v1_eqn14.gif"/></alternatives>
</disp-formula>
where we removed the explicit dependence on time <italic>t</italic>. Velocity forms are used in control problems where, for instance, integration is provided by an external mechanism outside the controller [<xref rid="c4" ref-type="bibr">4</xref>, <xref rid="c5" ref-type="bibr">5</xref>]. This algorithm is often described using discrete systems to avoid the definition of the derivative of random variables, often assumed to be white noise (i.e. Markov processes). In the continuous case, if the variable <italic>y</italic> is a Markov process, its time derivative is in fact not well defined. For this form to exist in continuous systems, <italic>y</italic> must be a smooth process. This effectively drops the Markov assumption of white noise and implements the same definition of analytic (i.e. differentiable) noise and related generalised coordinates of motion we described earlier. The presence of extra prediction errors beyond the traditional negative feedback (proportional term) can in this light be seen as a natural consequence of considering non-Markov processes.</p>
<p>To ensure that the active inference implementation effectively approximates the velocity form of PID control we then need to clarify the relationship between generalised coordinates of motion in <xref ref-type="disp-formula" rid="eqn13">equation (13)</xref> and the differential operators <italic>d/dt, d</italic><sup>2</sup><italic>/dt</italic><sup>2</sup> in <xref ref-type="disp-formula" rid="eqn14">equation (14)</xref>. As pointed out in previous work [<xref rid="c26" ref-type="bibr">26</xref>, <xref rid="c8" ref-type="bibr">8</xref>], the two of them are equal at the minimum of the free energy landscape when the gradient descent has reached its steady state. To simplify our formulation and show this more directly, we could consider the case for <italic>&#x03B7;&#x2032;</italic> = <italic>&#x03B7;&#x2032;&#x2032;</italic> = 0, defining the more standard set-point control where the desired trajectory collapses to a single target point. In the velocity form, this is equivalent to the case where <italic>y</italic><sub><italic>r</italic></sub> is a constant and <italic>dy</italic><sub><italic>r</italic></sub><italic>/dt</italic> = <italic>d</italic><sup>2</sup><italic>y</italic><sub><italic>r</italic></sub><italic>/dt</italic><sup>2</sup> = 0.</p>
</sec>
<sec id="s5">
<label>5</label>
<title>Conclusion</title>
<p>PID controllers are robust controllers used as a model of regulation for noisy and non-stationary processes in different disciplines, from engineering to biology and psychology. They however do not guarantee optimality, so a straightforward interpretation of this control strategy in terms of optimal control is missing. Active inference is often described as an extension of optimal control theory with deep connections to Bayesian inference [<xref rid="c19" ref-type="bibr">19</xref>]. While active inference has been proposed as a general mathematical theory of life and cognition according to the minimisation of variational free energy [<xref rid="c18" ref-type="bibr">18</xref>], methods such as PID control are still widely adopted as models of biological systems [<xref rid="c40" ref-type="bibr">40</xref>, <xref rid="c39" ref-type="bibr">39</xref>, <xref rid="c1" ref-type="bibr">1</xref>]. In this work we proposed a way to connect these two perspectives showing how PID controllers can be seen as a special case of active inference once simplified (i.e. linear) generative models are introduced.</p>
<p>Following our previous work [<xref rid="c6" ref-type="bibr">6</xref>], we defined a generative model that only approximates the agent&#x2019;s environment and showed how under a set of assumptions including analytic (i.e. non-Markovian, differentiable) Gaussian noise and linear dynamics, this model recapitulates PID control. A crucial component of our formulation is the presence of low precision parameters on proprioceptive prediction errors of our free energy function or equivalently, beliefs about high variance of proprioceptive signals. These low precisions play two roles during the minimisation of free energy: (1) they implement control signals as predictions of proprioceptive input influenced by strong priors (i.e. desires) rather than by observations, see <xref ref-type="disp-formula" rid="eqn11">equation (11)</xref> and [<xref rid="c25" ref-type="bibr">25</xref>, <xref rid="c6" ref-type="bibr">6</xref>], and (2) they reflect a belief into the presence of large exogenous fluctuations (low precision = high variance) as part of the observed proprioceptive input. This last point can be seen as the well known property of the Integral term [<xref rid="c5" ref-type="bibr">5</xref>] of PID controllers, dealing with unexpected external input (i.e. large exogenous fluctuations). The inverse model represented by derivatives <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline32.gif"/></alternatives></inline-formula> encodes then how actions <italic>a</italic> approximately affect observed proprioceptive sensations <inline-formula><alternatives><inline-graphic xlink:href="284562v1_inline33.gif"/></alternatives></inline-formula>, with an agent implementing a sensorimotor mapping that does not match the real dynamics of actions applied to the environment. The generative model we proposed can in general be applied to different tasks, in the same way PID control is used in different problems without specific knowledge of the system to regulate.</p>
<p>In future work we will explore the implications of PID control as active inference for the understanding of biological systems. In particular we suggest that given our formalisation it is trivial to generalise the set-point definition of PID controllers, based on point attractors, to trajectories (e.g. a reference temperature changing during the day with pre-specified properties such as the speed of change, etc.) using generalised coordinates of motion [<xref rid="c26" ref-type="bibr">26</xref>, <xref rid="c8" ref-type="bibr">8</xref>]. We may also be able to provide a principled, Bayes-optimal algorithm for the optimisation of the gains of a PID controller, <italic>k</italic><sub><italic>i</italic></sub>, <italic>k</italic><sub><italic>p</italic></sub>, <italic>k</italic><sub><italic>d</italic></sub> (i.e. precision parameters in our free energy formulation, <italic>&#x03C0;</italic><sub><italic>w</italic></sub>, <italic>&#x03C0;</italic><sub><italic>w</italic></sub><italic>&#x2032;, &#x03C0;</italic><sub><italic>w</italic></sub><italic>&#x2032;&#x2032;</italic>), for which only heuristic methods exist at the moment [<xref rid="c4" ref-type="bibr">4</xref>].</p>
</sec>
</body>
<back>
<ref-list>
<title>Bibliography</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Ang</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Bagh</surname></string-name>, <string-name><given-names>B. P.</given-names> <surname>Ingalls</surname></string-name>, and <string-name><given-names>D. R.</given-names> <surname>McMillen</surname></string-name>. <article-title>Considerations for using integral feedback control to construct a perfectly adapting synthetic gene network</article-title>. <source>Journal of theoretical biology</source>, <volume>266</volume>(<issue>4</issue>):<fpage>723</fpage>&#x2013;<lpage>738</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>W.</given-names> <surname>Ashby</surname></string-name>. <article-title>Requisite variety and its implications for the control of complex systems</article-title>. <source>Cybernetica</source>, <volume>1</volume>:<fpage>83</fpage>&#x2013;<lpage>99</lpage>, <year>1958</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="other"><string-name><given-names>W. R.</given-names> <surname>Ashby</surname></string-name>. <source>An introduction to cybernetics</source>. <year>1957</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="other"><string-name><given-names>K. J.</given-names> <surname>Astrom</surname></string-name>. <article-title>Pid controllers: theory, design and tuning</article-title>. <source>Instrument society of America</source>, <year>1995</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="book"><string-name><given-names>K. J.</given-names> <surname>Astrom</surname></string-name> and <string-name><given-names>R. M.</given-names> <surname>Murray</surname></string-name>. <source>Feedback systems: an introduction for scientists and engineers</source>. <publisher-name>Princeton university press</publisher-name>, <year>2010</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="other"><string-name><given-names>M.</given-names> <surname>Baltieri</surname></string-name> and <string-name><given-names>C. L.</given-names> <surname>Buckley</surname></string-name>. <article-title>An active inference implementation of phototaxis</article-title>. In <source>Proc. Eur. Conf. on Artificial Life</source>, pages <fpage>36</fpage>&#x2013;<lpage>43</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="other"><string-name><given-names>R.</given-names> <surname>Bogacz</surname></string-name>. <article-title>A tutorial on the free-energy framework for modelling perception and learning</article-title>. <source>Journal of Mathematical Psychology</source>, <year>2015</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="other"><string-name><given-names>C. L.</given-names> <surname>Buckley</surname></string-name>, <string-name><given-names>C. S.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>S.</given-names> <surname>McGregor</surname></string-name>, and <string-name><given-names>A. K.</given-names> <surname>Seth</surname></string-name>. <article-title>The free energy principle for action and perception: A mathematical review</article-title>. <source>Journal of Mathematical Psychology</source>, <year>2017</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="book"><string-name><given-names>C. S.</given-names> <surname>Carver</surname></string-name> and <string-name><given-names>M. F.</given-names> <surname>Scheier</surname></string-name>. <source>Attention and self-regulation: A control-theory approach to human behavior</source>. <publisher-name>Springer Science &#x0026; Business Media</publisher-name>, <year>1981</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="book"><string-name><given-names>A.</given-names> <surname>Clark</surname></string-name>. <source>Being there: Putting brain, body, and world together again</source>. <publisher-name>MIT press</publisher-name>, <year>1998</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Clark</surname></string-name>. <article-title>Whatever next? predictive brains, situated agents, and the future of cognitive science</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>36</volume>(<issue>03</issue>):<fpage>181</fpage>&#x2013;<lpage>204</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Clark</surname></string-name>. <article-title>Radical predictive processing</article-title>. <source>The Southern Journal of Philosophy</source>, <volume>53</volume>(<issue>S1</issue>):<fpage>3</fpage>&#x2013;<lpage>27</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="book"><string-name><given-names>A.</given-names> <surname>Clark</surname></string-name>. <source>Surfing Uncertainty: Prediction, Action, and the Embodied Mind</source>. <publisher-name>Oxford University Press</publisher-name>, <year>2015</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, <string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Neal</surname></string-name>, and <string-name><given-names>R. S.</given-names> <surname>Zemel</surname></string-name>. <article-title>The helmholtz machine</article-title>. <source>Neural computation</source>, <volume>7</volume>(<issue>5</issue>):<fpage>889</fpage>&#x2013;<lpage>904</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>. <article-title>A theory of cortical responses</article-title>. <source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source>, <volume>360</volume>(<issue>1456</issue>):<fpage>815</fpage>&#x2013;<lpage>836</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>. <article-title>Hierarchical models in the brain</article-title>. <source>PLoS Computational Biology</source>, <volume>4</volume>(<issue>11</issue>), <year>2008</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>. <article-title>The free-energy principle: a rough guide to the brain?</article-title> <source>Trends in Cognitive Sciences</source>, <volume>13</volume>(<issue>7</issue>):<fpage>293</fpage>&#x2013;<lpage>301</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>. <article-title>The free-energy principle: a unified brain theory?</article-title> <source>Nature reviews. Neuroscience</source>, <volume>11</volume>(<issue>2</issue>):<fpage>127</fpage>&#x2013;<lpage>138</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>. <article-title>What is optimal about motor control?</article-title> <source>Neuron</source>, <volume>72</volume>(<issue>3</issue>):<fpage>488</fpage>&#x2013;<lpage>498</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>. <article-title>Life as we know it</article-title>. <source>Journal of the Royal Society Interface</source>, <volume>10</volume>(<issue>86</issue>):<fpage>20130475</fpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Kilner</surname></string-name>, and <string-name><given-names>L.</given-names> <surname>Harrison</surname></string-name>. <article-title>A free energy principle for the brain</article-title>. <source>Journal of Physiology-Paris</source>, <volume>100</volume>(<issue>1</issue>):<fpage>70</fpage>&#x2013;<lpage>87</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Mattout</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Kilner</surname></string-name>. <article-title>Action understanding and active inference</article-title>. <source>Biological Cybernetics</source>, <volume>104</volume>(<issue>1-2</issue>):<fpage>137</fpage>&#x2013;<lpage>160</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="other"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Rigoli</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Ognibene</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Mathys</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Fitzgerald</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Pezzulo</surname></string-name>. <article-title>Active inference and epistemic value</article-title>. <source>Cognitive neuroscience</source>, pages <fpage>1</fpage>&#x2013;<lpage>28</lpage>, <month>mar</month> <year>2015</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Daunizeau</surname></string-name>, and <string-name><given-names>S. J.</given-names> <surname>Kiebel</surname></string-name>. <article-title>Reinforcement learning or active inference?</article-title> <source>PloS one</source>, <volume>4</volume>(<issue>7</issue>):<fpage>e6421</fpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Daunizeau</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Kilner</surname></string-name>, and <string-name><given-names>S. J.</given-names> <surname>Kiebel</surname></string-name>. <article-title>Action and behavior: A free-energy formulation</article-title>. <source>Biological Cybernetics</source>, <volume>102</volume>(<issue>3</issue>):<fpage>227</fpage>&#x2013;<lpage>260</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Trujillo-Barreto</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Daunizeau</surname></string-name>. <article-title>DEM: A variational treatment of dynamic systems</article-title>. <source>NeuroImage</source>, <volume>41</volume>(<issue>3</issue>):<fpage>849</fpage>&#x2013;<lpage>885</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="book"><string-name><given-names>J.</given-names> <surname>Hohwy</surname></string-name>. <source>The predictive mind</source>. <publisher-name>OUP Oxford</publisher-name>, <year>2013</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="other"><string-name><given-names>A.</given-names> <surname>Jazwinski</surname></string-name>. <source>Stochastic processes and filtering theory</source>. <year>1970</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>R. E.</given-names> <surname>Kalman</surname></string-name> <etal>et al.</etal> <article-title>Contributions to the theory of optimal control</article-title>. <source>Bol. Soc. Mat. Mexicana</source>, <volume>5</volume>(<issue>2</issue>):<fpage>102</fpage>&#x2013;<lpage>119</lpage>, <year>1960</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>D. C.</given-names> <surname>Knill</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Pouget</surname></string-name>. <article-title>The bayesian brain: the role of uncertainty in neural coding and computation</article-title>. <source>TRENDS in Neurosciences</source>, <volume>27</volume>(<issue>12</issue>):<fpage>712</fpage>&#x2013;<lpage>719</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="other"><string-name><given-names>W. T.</given-names> <surname>Powers</surname></string-name>. <source>Behavior: The control of perception. Aldine Chicago</source>, <year>1973</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>R. P.</given-names> <surname>Rao</surname></string-name> and <string-name><given-names>D. H.</given-names> <surname>Ballard</surname></string-name>. <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nature neuroscience</source>, <volume>2</volume>(<issue>1</issue>):<fpage>79</fpage>&#x2013;<lpage>87</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="other"><string-name><given-names>H.</given-names> <surname>Ritz</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Nassar</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Shenhav</surname></string-name>. <article-title>A control theoretic model of adaptive behavior in dynamic environments</article-title>. <source>bioRxiv</source>, page <fpage>204271</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="other"><string-name><given-names>A. K.</given-names> <surname>Seth</surname></string-name>. <source>The cybernetic bayesian brain. In Open MIND. Open MIND. Frankfurt am Main: MIND Group</source>, <year>2014</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>C. E.</given-names> <surname>Shannon</surname></string-name>. <article-title>Coding theorems for a discrete source with a fidelity criterion</article-title>. <source>IRE Nat. Conv. Rec</source>, <volume>4</volume>(<issue>142-163</issue>):<fpage>1</fpage>, <year>1959</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="other"><string-name><given-names>E.</given-names> <surname>Todorov</surname></string-name>. <article-title>General duality between optimal control and estimation. In</article-title> <source>Decision and Control, 2008. CDC 2008. 47th IEEE Conference on</source>, pages <fpage>4286</fpage>&#x2013;<lpage>4292</lpage>. IEEE, <year>2008</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Wiener</surname></string-name>. <source>Cybernetics or Control and Communication in the Animal and the Machine</source>, volume <volume>25</volume>. <year>1961</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>D. M.</given-names> <surname>Wolpert</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Kawato</surname></string-name>. <article-title>Multiple paired forward and inverse models for motor control</article-title>. <source>Neural networks</source>, <volume>11</volume>(<issue>7-8</issue>):<fpage>1317</fpage>&#x2013;<lpage>1329</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Yang</surname></string-name> and <string-name><given-names>P. A.</given-names> <surname>Iglesias</surname></string-name>. <article-title>Positive feedback may cause the biphasic response observed in the chemoattractant-induced response of dictyostelium cells</article-title>. <source>Systems &#x0026; control letters</source>, <volume>55</volume>(<issue>4</issue>):<fpage>329</fpage>&#x2013;<lpage>337</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>T.-M.</given-names> <surname>Yi</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Huang</surname></string-name>, <string-name><given-names>M. I.</given-names> <surname>Simon</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Doyle</surname></string-name>. <article-title>Robust perfect adaptation in bacterial chemotaxis through integral feedback control</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>97</volume>(<issue>9</issue>):<fpage>4649</fpage>&#x2013;<lpage>4653</lpage>, <year>2000</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>