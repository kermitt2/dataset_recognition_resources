<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/205328</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Scaling read aligners to hundreds of threads on general-purpose processors</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2437-1976</contrib-id>
<name><surname>Langmead</surname><given-names>Ben</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wilks</surname><given-names>Christopher</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Antonescu</surname><given-names>Valentin</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Charles</surname><given-names>Rone</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Computer Science, Johns Hopkins University</institution></aff>
<aff id="a2"><label>2</label><institution>Center for Computational Biology, Johns Hopkins University</institution></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Correspondence to: <email>langmea@cs.jhu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub"><year>2017</year></pub-date>
<elocation-id>205328</elocation-id>
<history>
<date date-type="received">
<day>23</day>
<month>10</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>23</day>
<month>10</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>10</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="205328.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>General-purpose processors can now contain many dozens of processor cores and support hundreds of simultaneous threads of execution. To make best use of these threads, genomics software must contend with new and subtle computer architecture issues. We discuss some of these and propose methods for improving thread scaling in tools that analyze each read independently, such as read aligners. We implement these methods in new versions of Bowtie, Bowtie 2 and HISAT. We greatly improve thread scaling in many scenarios, including on the recent Intel Xeon Phi architecture. We also highlight how bottlenecks are exacerbated by variable-record-length file formats like FASTQ and suggest changes that enable superior scaling.</p>
</abstract>
<counts>
<page-count count="22"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>General-purpose processors are now capable of running hundreds of threads of execution simul-taneously in parallel. Intel&#x2019;s Xeon Phi &#x201C;Knight&#x2019;s Landing&#x201D; architecture supports 256&#x2013;288 simul-taneous threads across 64&#x2013;72 physical processor cores [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>]. With severe physical limits on clock speed [<xref ref-type="bibr" rid="c3">3</xref>], future architectures will likely support more simultaneous threads rather than faster individual cores [<xref ref-type="bibr" rid="c4">4</xref>]. In fact, clock speed on many-core Xeon Phi processors (1.3-1.5 Ghz) is about half that of the 10-core processors driving compute-intensive servers available from Amazon Web Services [<xref ref-type="bibr" rid="c5">5</xref>]. While specialized (e.g. graphics) processors have been highly multithreaded for some time, this only recently became true for the general-purpose processors that can boot standard op-erating systems and that typically power servers and desktops.</p>
<p>With these advances come new computer-architecture considerations for programmers. Simply adding multi-threading to a software tool does not guarantee it will use threads well. In fact, it is distressingly common for a software tool&#x2019;s overall throughput to <italic>decrease</italic> with when thread count grows large enough [<xref ref-type="bibr" rid="c6">6</xref>]. So whereas past efforts in computational genomics software for general-purpose processors have focused on speed on a fixed (and usually small) number of threads, it will be important for future efforts to examine scaling to much higher thread counts.</p>
<p>Here we tackle the problem of scaling read aligners to hundreds of threads on general-purpose processors. We concentrate on the Bowtie [<xref ref-type="bibr" rid="c7">7</xref>], Bowtie 2 [<xref ref-type="bibr" rid="c8">8</xref>] and HISAT [<xref ref-type="bibr" rid="c9">9</xref>] tools because they are widely used and representative of a wider group of <italic>embarrassingly parallel</italic> tools, where the computation is readily separable into independent tasks, one per sequencing read. That is, the alignment of one read does not depend on the alignment of any other. <sup><xref ref-type="fn" rid="fn1">1</xref></sup> Many other sequencing analysis tools are also embarrassingly parallel, including tools for error correction [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>], quality assessment and trimming [<xref ref-type="bibr" rid="c12">12</xref>], and taxonomic assignment [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>]. This is true whether the input data consists of short (e.g. Illumina) reads or longer (e.g. nanopore) reads.</p>
<p>We propose strategies that scale to hundreds of threads better than alternative approaches like multiprocessing (several possibly-multithreaded processes running simultaneously) and the pipelined approach taken by BWA-MEM [<xref ref-type="bibr" rid="c15">15</xref>]. We also explore how the FASTQ file format [<xref ref-type="bibr" rid="c16">16</xref>], its unpredictable record boundaries in particular, can impede thread scaling. We suggest a way to change FASTQ files and similar formats that enable further improvements in thread scaling while maintaining essentially the same compressed file size.</p>
<p><bold>Synchronization and locking</bold> For embarrassingly parallel genomics tools, threads typically proceed by repeatedly (a) obtaining the next read from the input file, (b) aligning the read, and (c) writing the resulting alignment to the output file. Threads&#x2019; interactions with input and output files must be synchronized. That is, some portions of code must be protected to allow only one thread to execute at a time. <xref ref-type="fig" rid="fig1">Figure 1</xref> illustrates threads operating in parallel while periodically reading input in a synchronized fashion. Failure to properly synchronize can lead to software crashes and corrupt data. Synchronization is achieved with locks. There are various lock types, which incur different types and amounts of overhead. We confirm here that for many-core architectures with non-uniform memory access (NUMA), choice of lock type has a major impact on thread scaling [<xref ref-type="bibr" rid="c17">17</xref>]. We explore several lock types, demonstrate their relative merits, and propose the queueing lock from the Thread Building Blocks (TBB) library [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>] as a choice that scales well to hundreds of threads.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Four threads running simultaneously in an embarrassingly parallel setting. Time progresses from top to bottom. Gray boxes show time spent waiting to enter the critical section. Black boxes show time spent in the critical section, which can be occupied by at most one thread at a time. At time t1 (dashed line), thread 1 is executing the critical section and all the other threads are running. At time t2, thread 1 is still in the critical section and threads 2 and 3 are waiting to enter. At time t3, thread 2 occupies the critical section and thread 4 is waiting.</p></caption>
<graphic xlink:href="205328_fig1.tif"/>
</fig>
<p><bold>Multithreading versus multiprocessing</bold> Our focus is on making the best use of many threads in a single process. But another strategy is to run multiple simultaneous processes, possibly with many threads each. For example, a user with several FASTQ files might align all the files using Bowtie 2 with the <monospace>- p 100</monospace> argument, causing Bowtie 2 to use 100 simultaneous threads of execution. Alternately, the user might divide the input into 10 batches and run 10 simultaneous Bowtie 2 processes using <monospace>- p 10</monospace>. In both cases, 100 threads run in parallel. In the latter case, threads are spread across many simultaneous processes.</p>
<p>A trade-off exists between multithreading (MT) and multiprocessing (MP) approaches. MP can suffer from <italic>load imbalance</italic>: when the input is divided into batches, some batches take longer to align than others. This negatively impacts scaling since the overall job does not complete until the longest-running batch completes.</p>
<p>Imbalance can be mitigated by <italic>dynamic</italic> load balancing. Such a scheme might divide the input into many batches, more than there are processes. The load balancer then launches the processes and continually feed each process new input batches upon completion of the previous batch, until all batches are processed. As batch count increases, per-batch running times tend to average out, reducing the disparity among per-process running times. This incurs overhead; the dynamic load balancer must split the inputs, launch and feed the processes, and finally combine outputs.</p>
<p>Another disadvantage of MP is that many data structures, such as the genome index, are copied across processes, leading to a higher memory footprint compared to MT. Since the genome index us identical from process to process, this is a wasteful use of memory and cache space. It can also exceed available memory for aligners with larger data structures, such as GEM [<xref ref-type="bibr" rid="c20">20</xref>] and SNAP [<xref ref-type="bibr" rid="c21">21</xref>], as shown previously [<xref ref-type="bibr" rid="c6">6</xref>]. This can be mitigated using the memory mapping or shared-memory approaches already implemented in Bowtie, Bowtie 2 and HISAT.</p>
<p>The MP strategy also has a major advantage: by allowing each processes to deal only with its own private input and output files, the level of thread contention is reduced in each process. That is, a single process has fewer threads to synchronize. There are also NUMA-related reasons why running multiple processes can aid thread scaling, e.g. by allowing each process to have a copy of the genome index that is local to its home NUMA node [<xref ref-type="bibr" rid="c6">6</xref>].</p>
<p>Here we focus on improving MT thread scaling since an efficient MT scaling strategy effec-tively combines the advantages of MT and MP approaches. MT inherently achieves dynamic load balancing without requiring extra software beyond the aligner itself. It also achieves a low memory footprint (no duplicated data structures) without the need for memory mapping or similar mechanism. It is also applicable regardless of how many input files the user starts with, a signif-icant advantage since users typically start with a single input file and desire a single output file. This also makes MT approaches more amenable to streaming contexts, where inputs arrive and outputs leave via individual data streams such as operating-system pipes or socket connections.</p>
<p><bold>Related work</bold> Two prior studies [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>], examined Bowtie 2 thread scaling with synchroniza-tion and Non-Uniform Memory Access (NUMA) as primary concerns. By adapting Bowtie 2 to the FastFlow [<xref ref-type="bibr" rid="c24">24</xref>] parallel framework and by making effective use of (a) thread pinning and (b) in-terleaving of memory pages across NUMA sockets, the modifications improved Bowtie 2&#x2019;s thread scaling. Our suggestions for improving thread scaling are complementary to these proposals.</p>
<p>Herzeel et al [<xref ref-type="bibr" rid="c25">25</xref>] re-parallelized sections of the BWA code using the Cilk [<xref ref-type="bibr" rid="c26">26</xref>] programming language. They noted a 2-fold improvement in multi-threaded speedup, highlighting the impor-tance of NUMA and load balance issues. Lenis and Senar examined performance of four read aligners, including Bowtie 2 and BWA-MEM on NUMA architectures [<xref ref-type="bibr" rid="c6">6</xref>] without modifications, and noted that a multiprocessing approach that replicated the index data structure across NUMA nodes performed the best. Our goal is to achieve similar improvements with a purely multi-threaded approach on modern hardware.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Methods</title>
<sec id="s2a">
<label>2.1</label>
<title>Lock types</title>
<p>We begin by examining how lock types affect thread scaling. Different lock types are appropriate for different situations. A <italic>spinlock</italic> uses a loop to repeatedly check if a lock is held. As soon as a check indicates the lock is free, ownership is transferred to the inquiring thread. The check and the transfer can happen simultaneously using an atomic operation [<xref ref-type="bibr" rid="c27">27</xref>]. In practice, a spinlock that fails to obtain a lock in a prescribed time interval will simply go to sleep, allowing the operating system (OS) to revive it when the lock becomes free. This avoids <italic>starvation</italic>, where the lock-holding thread is slow to finish its work (and release the lock) because other threads are using the processor to probe the very same lock.</p>
<p>Spinlocks are <italic>optimistic</italic>: they work best when the lock can be obtained quickly. On the other hand, another common lock type is a <italic>standard lock</italic>, which the thread to sleep immediately, allowing the OS to revive it when the lock is free. While pausing and reviving a thread incurs overhead, a standard lock cannot starve other threads. Thus, a standard lock is <italic>pessimistic</italic>, working best when the lock is unlikely to be available soon.</p>
<p>We might suppose that when active thread count is less than or equal to the number of physical cores &#x2014; a typical situation when a user has dedicated access to a computer and desires speed &#x2014; starvation is not an issue and spinlocks are ideal. However, this supposition fails on modern many-core systems for reasons relevant to our choice of lock type. One concern is that modern architectures have many cores and caches connected in a NUMA architecture. That is, there is a single addressable memory space visible to all threads, but it is physically divided into partitions that might be attached to separate cores in a multi-socket system, as for the 2-socket Broadwell system used in our evaluations, or both the partitions and the cores might be connected via an interconnection network, as on the Xeon Phi. Either way, thread scaling is impacted in at least two ways: (a) threads running on different cores but accessing the same memory location will incur different access latencies depending on the distance to the memory, and (b) when several threads read and write the same memory location simultaneously, the system&#x2019;s <italic>cache coherence protocol</italic> must step in to ensure all threads have a coherent view of memory. In short, thread scaling is harmed when the added threads must access distant memories or when they compete for the same memory locations as existing threads. This is a general issue but it affects locking in specific ways that we return to this when discussing the queueing lock.</p>
<p>Another issue arises when threads can co-exist on the same physical processor. On Xeon Phi, up to four threads can run simultaneously on one processor, competing for its resources like its arithmetic units and cache. A thread operating by itself on a processor moves at one speed, but slows when joined by a second thread, slows still further when joined by third, etc. Thus, increas-ing thread count incurs a mild but increasing starvation penalty even when free thread &#x201C;slots&#x201D; remain. This puts optimistic locks at a disadvantage, since their spinning behavior can needlessly starve productive threads on the same processor.</p>
<p>In past versions, Bowtie, Bowtie 2 and HISAT used a spinlock from the <monospace>TinyThread&#x002B;&#x002B;</monospace> [<xref ref-type="bibr" rid="c28">28</xref>] library. Observing that this scaled poorly (see Results), we extended the three tools to use the open source Intel Thread Building Blocks (TBB) library [<xref ref-type="bibr" rid="c18">18</xref>]. TBB provides various lock types [<xref ref-type="bibr" rid="c29">29</xref>], including a queuing lock [<xref ref-type="bibr" rid="c30">30</xref>] particularly appropriate for NUMA systems like the Knight&#x2019;s Landing and Broadwell systems used here. TBB also provides scalable replacements for standard heap memory allocation functions (e.g. <monospace>malloc/free, new/delete</monospace>). This aids thread scaling, since memory allocations require synchronization.</p>
<p>The TBB queuing lock implements an MCS lock [<xref ref-type="bibr" rid="c30">30</xref>], which uses an in-memory queue to or-ganize waiting threads. Like a spinlock, a waiting thread repeatedly probes a variable in memory to learn when it has obtained the lock. Unlike a spinlock, each waiting thread probes a separate queue entry, each entry occupying a separate cache line. This greatly reduces overhead. To elaborate, consider that an atomic operation (e.g. atomic compare-and-swap) might modify a variable in memory, depending on the condition. Consequently, it is treated as a memory write by the cache coherence infrastructure. A write modifies a cache line, causing cache coherence messages to travel between caches for threads that recently accessed the line. When this happens in a loop, new messages are generated each iteration. When many threads spin simultaneously, messages multiply, eventually reaching a point where the messages flood the system bus and starve other threads, including lock holder. This is called <italic>cache-line</italic> or <italic>hotspot</italic> contention [<xref ref-type="bibr" rid="c30">30</xref>] and it is a major concern on many-core and NUMA systems [<xref ref-type="bibr" rid="c17">17</xref>]. The queuing lock reduces contention in two ways. First, since each thread spins on a variable in a thread-specific cache line, the loop condition can be a simple memory read rather than an atomic operation. This reduces cache coherence messaging. Second, while a memory write is still needed to hand the lock from one thread to another, only two threads are involved in the hand-off, reducing the coherence messages exchanged.</p>
<p>We adapted the three tools to use four lock types: the (original) <monospace>TinyThread&#x002B;&#x002B;</monospace> lock, standard TBB lock, TBB spinlock, and TBB queuing lock. On the Linux systems we used for evaluation, the standard TBB lock works by calling <monospace>pthread_mutex_unlock</monospace>, which in turn uses the Linux <monospace>futex</monospace> (fast mutex) strategy. This strategy first attempts to obtain the lock using a fast atomic operation then, if unsuccessful (i.e. if the lock is held by another thread), places it on a queue of paused threads until the lock is released.</p>
<p>The lock type is selected at compile time via preprocessing macros. These extensions are avail-able as of the Bowtie v1.1.2, Bowtie 2 v2.2.9 and HISAT v0.1.6-beta software versions. Supplementary Note 1 gives build instructions for the exact software versions tested here.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Parsing strategies</title>
<p>We also examined how threads coordinate when reading input (e.g. FASTQ reads [<xref ref-type="bibr" rid="c16">16</xref>]) or writing output (SAM [<xref ref-type="bibr" rid="c31">31</xref>] alignments). These interactions are synchronized, i.e. protected by locks. The name <italic>critical section</italic> is given to a portion of the software that only one thread may execute at a time. The critical section for handling input is called the <italic>input critical section</italic> and is protected by the <italic>input lock</italic>. Likewise for the <italic>output critical section</italic> and the <italic>output lock</italic>.</p>
<p>We hypothesized that to improve thread scaling we should restructure the input and output critical sections. Our first goal was to reduce the time spent in the critical section by deferring as much computation until after the critical section as possible. Our second goal was to reduce the total number of times the critical section was entered. This reduces overhead incurred by locking and unlocking upon entering and exiting.</p>
<p>The original strategy (O-parsing) both reads and parses a sequencing read in the critical section (CS). We developed three variants on this approach (<xref ref-type="table" rid="tbl1">Table 1</xref>). In deferred (D) parsing, the CS reads a single input record into a buffer. After the CS, the buffer is parsed into the sequencing read data object. Batch deferred (B) parsing is like D-parsing but handles batches of N reads at a time. The B-parsing critical section has a loop that iterates <italic>N</italic> times, reading each record into a separate buffer. After the CS, another loop parses each buffer into a sequencing read object. This reduces by a factor of <italic>N</italic> the total number of times the CS is entered. A similar change is made to the output CS: alignment records are written to the output stream in batches of <italic>N</italic> reads.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Pseudocode for four synchronized parsing strategies. Red code is inside the critical section (CS). Original (O) parsing both reads and parses in the CS. Deferred parsing (D) uses the CS to read the next record into a buffer, counting four newlines to find the record boundary, but defers parsing until after the CS. Batch deferred parsing (B) is like (D) but reads <italic>N</italic> reads at a time. Block deferred parsing (L) reads a fixed-sized chunk of data (<italic>B</italic> bytes), assuming that no record spans a <italic>B</italic>-byte boundary. While the assumption for (L) is violated in practice for formats like FASTQ, it suggests a strategy for making formats more amenable to multithreaded parsing.</p></caption>
<graphic xlink:href="205328_tbl1.tif"/>
</table-wrap>
<p>Blocked deferred (L) parsing reads a chunk of exactly <italic>B</italic> input bytes into a buffer, assuming that (a) no read spans a <italic>B</italic>-byte boundary in the input file, such that no <italic>B</italic>-byte chunk contains a partial input record, and (b) the number of reads (N) per <italic>B</italic>-byte chunk is the same for all chunks (except perhaps the last) and known ahead of time. These assumptions do not hold for real FASTQ files, but we can easily modify a FASTQ file to comply. We accomplish this by appending extra space characters to every <italic>N</italic>th read until the following read begins at an <italic>B</italic>-byte boundary (<xref ref-type="fig" rid="fig2">Figure 2</xref>). (Trailing spaces are later removed by the aligner.) This has the effect both of enforcing the L-parsing assumptions and of making it easier to parse paired-end files in a synchronized manner, since a <italic>B</italic>-sized block taken from the same offset in both files will be guaranteed to contain <italic>N</italic> matching ends. As with B-parsing, the L-parsing output critical section writes alignments in batches of <italic>B</italic> reads at a time.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Converting a standard pair of FASTQ files (a) to blocked FASTQ files (b), where the number of bytes (<italic>B</italic>) and number of input read per block (<italic>N</italic>) are 64 and 2 respectively. Numbers left of vertical lines indicate byte offsets for FASTQ lines, assuming newline characters (not shown) are one byte. For (b), padding spaces are represented by solid blue rectangles. The first 64 bytes of each file are colored blue and subsequent bytes are colored red. Note that the two ends differ in length; end 1 is 10 bases long and end 2 is 9 bases long. This necessitates differing amounts of padding in the two FASTQ files. But after padding, we are guaranteed that corresponding 64-byte blocks from the files contain <italic>N</italic> corresponding reads.</p></caption>
<graphic xlink:href="205328_fig2.tif"/>
</fig>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Other aligner modifications</title>
<p>We also modified the aligners to minimize the incidence of heap memory allocations wherever possible. This is because heap memory allocations also require synchronization, thus negatively impacting thread scaling. We also modified each of Bowtie, Bowtie 2 and HISAT to cause each thread to report how much wall-clock time it spends aligning reads, with microsecond accuracy.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Multiprocessing</title>
<p>While our focus is on single-process multithreaded (MT) approaches, multiprocessing (MP) is another avenue for improving thread scaling. For this reason, our comparisons include an MP-based &#x201C;baseline&#x201D; strategy. The MP baseline is measured for every thread count <italic>T</italic> that is multiple of 16 by running <italic>T</italic>/16 processes, each with 16 threads. For MP experiments involving Bowtie, Bowtie 2 or HISAT, we use memory mapping (<monospace>- -mm</monospace> option) to limit overall memory footprint.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Results</title>
<p><bold>Configurations &#x0026; jobs</bold> We evaluate various read aligners and synchronization schemes by running each &#x201C;configuration&#x201D; (combination of aligner and synchronization scheme) using the same input data. For each configuration, we perform a series of alignment <italic>jobs</italic> varying the number of input reads and the number of simultaneous threads of execution in direct proportion, thus keeping the number of reads per thread constant. In each case we align to an index of the GRCh38 human genome reference assembly [<xref ref-type="bibr" rid="c32">32</xref>]. We measure wall-clock running time of each job, omitting time required for one-time setup tasks such as index loading since these influence thread scaling only slightly when aligning large datasets. The number of reads per thread (Supplementary Table 1) was chosen for each configuration and system so that most jobs take 1 minute or longer. Any job taking longer than 20 minutes was aborted and omitted from the results. The Linux <monospace>top</monospace> utility was run in the background to periodically measure system load, processor utilization and memory footprint.</p>
<p>We evaluate Bowtie [<xref ref-type="bibr" rid="c7">7</xref>], Bowtie 2 [<xref ref-type="bibr" rid="c8">8</xref>] and HISAT [<xref ref-type="bibr" rid="c9">9</xref>] because they are widely used. We include a comparison to BWA-MEM [<xref ref-type="bibr" rid="c15">15</xref>] for the same reason. While we did not modify the newer HISAT2 [<xref ref-type="bibr" rid="c33">33</xref>], we expect the same modifications to benefit that software as well. We ran HISAT with the <monospace>--no-spliced-alignment --no-temp-splicesite</monospace> options to disable gathering of splice-site evidence because our input reads were from DNA sequencing experiments.</p>
<p>All software used to run the experiments and produce the figures and tables are located at <ext-link ext-link-type="uri" xlink:href="https://github.com/BenLangmead/bowtie-scaling">https://github.com/BenLangmead/bowtie-scaling</ext-link>.</p>
<p><bold>Reads</bold> We obtained sequencing reads from accessions ERR194147 (Platinum Genomes Project [<xref ref-type="bibr" rid="c34">34</xref>]), SRR069520 (1000 Genomes Project [<xref ref-type="bibr" rid="c35">35</xref>]) and SRR3947551 (a low coverage whole genome sequencing project [<xref ref-type="bibr" rid="c36">36</xref>]). All reads are 100 &#x00D7; 100 nt (paired-end) from the Illumina HiSeq 2000 instrument. We downloaded the reads in FASTQ format, selected a random subset of 100M from each of the 3 accessions, then randomized the order of the resulting set of 300M reads to avoid clustering of reads with similar properties. These constitute the <italic>human_100_300M</italic> input read set. Bowtie is designed to align shorter reads, so we also created set <italic>human_50_300M</italic> consisting of the <italic>human_100_300M</italic> reads truncated to 50 nt at the 3&#x2019; end. Unpaired alignment experiments use just the first-end FASTQ files. Download links for reads are in Supplementary Note 2.</p>
<p><bold>Evaluation systems</bold> Each job was run on two servers. The first (<italic>Broadwell</italic>) is a dual-socket sys-tem with two Intel Xeon E7-4830 v4 2.00GHz CPUs and 1 TB of DDR4 memory. Both CPUs have 28 physical processor cores, enabling up to 112 threads of execution since each core supports 2 simultaneous &#x201C;hyperthreaded&#x201D; threads. The system runs CentOS 6.8 Linux, kernel v2.6.32, and is located at the Maryland Advanced Research Computing Center (MARCC). The second system (KNL) is an Intel Xeon Phi 7250 (Knight&#x2019;s Landing) system with 96GB DDR4 memory (as well as a 16GB high-speed MCDRAM). The system has 68 physical processor cores, enabling up to 272 threads of execution, 4 per core. This system runs Red Hat Enterprise Linux 7, kernel v3.10.0, and is located in the Stampede 2 cluster at the Texas Advanced Compute Center (TACC) accessible via the XSEDE network.</p>
<sec id="s3a">
<label>3.1</label>
<title>Varying lock type</title>
<p>As discussed in Methods, we extended Bowtie, Bowtie 2 and HISAT to use one of four lock types: a <monospace>TinyThread&#x002B;&#x002B;</monospace> spinlock, TBB standard lock, TBB spinlock, or TBB queueing lock. We tested each in a pure multithreading (MT) context; for each run, we launched a single aligner process configured via the <monospace>- p</monospace> option to use the desired number of simultaneous threads, <italic>T</italic>. At multiples of 16, we also compared to a multiprocessing (MP) baseline that launched <italic>T</italic>/16 simultaneous processes, each using 16 threads. The MP baseline uses the TBB queueing lock.</p>
<p>When plotting results, we arranged thread count on the horizontal axis and maximum per-thread wall-clock time (i.e. time required to align all reads) on the vertical axis. Because we vary the number of input reads in direct proportion to thread count, a flat horizontal line would indicate perfect scaling. Because we omit runs with a running time of over 20 minutes, lines for poorly-scaling configurations can &#x201C;fall off&#x201D; the top of the plot.</p>
<p><xref ref-type="fig" rid="fig3">Figure 3</xref> shows how thread count affects running time for unpaired alignment. Supplementary Figure 1 shows the same for paired-end alignment. We observe that the MP baseline generally outperformed all multithreading modes (MT). We also see the choice of lock type can have a major impact on scaling, seen clearly for the Broadwell&#x002B;HISAT configurations. While no lock type performed best in all cases, the TBB queueing lock tended to eventually outperform the other MT configurations at high thread count. This is clearest for HISAT and Bowtie. There were also cases where the TBB standard lock or spinlock outperformed the queueing lock at high thread counts. This is clearest for Broadwell&#x002B;Bowtie, where the TBB spinlock performed best even at the highest thread counts, and for KNL&#x002B;Bowtie 2, where the standard lock outperformed.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Comparison of 4 lock types and multiprocessing baseline. Reads are unpaired. Results are shown for three aligners (rows) and two systems (columns). Jobs that ran for over 20 minutes are omitted. Squares indicate the point on each line yielding maximal total alignment throughput. These points are summarized in <xref ref-type="table" rid="tbl2">Table 2</xref>.</p></caption>
<graphic xlink:href="205328_fig3.tif"/>
</fig>
<p><xref ref-type="table" rid="tbl2">Table 2</xref> shows peak throughputs (also represented by squares in <xref ref-type="fig" rid="fig3">Figure 3</xref>) for each lock type and the MP baseline. For 6 out of 12 combinations of aligner, test system and paired-end status, the queueing lock has the second-highest peak throughput after the MP baseline. In the remaining six, queueing lock throughput is close to (never &#x003E; 10&#x0025; lower than) the best MT configuration.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>Peak throughputs for four lock types. For each row, maximal peak throughput (K reads/sec) and number of threads (Threads) that achieved peak throughput are reported. For each combination of aligner, paired-end status and test system, the best and second-best through-puts are highlighted in red and orange respectively.</p></caption>
<graphic xlink:href="205328_tbl2.tif"/>
</table-wrap>
<p>In some cases, the queueing lock took a steep turn upwards at the highest thread counts, e.g. for Broadwell&#x002B;Bowtie and Broadwell&#x002B;Bowtie 2. This contrasts with the TBB standard lock, which also tended to rise at higher thread counts, but more slowly, almost linearly. This is likely due to starvation; at high thread counts, threads share cores (up to 2 threads per cores on Broadwell, 4 on KNL), so optimistic lock types like the queueing lock will tend to spin fruitlessly on contended locks, starving other threads, including the lock holder. The problem is not shared by the (pessimistic) standard lock, which avoids starvation and so deteriorates more slowly.</p>
<p>It is not surprising that even the best-scaling configuration &#x2014; the MP baseline &#x2014; had an up-ward trend in running time. Increasing thread count increases contention for shared resources, slowing the threads on average. For example, higher thread count leads to greater contention for shared memory, e.g. L1 and L2 caches, translation look-aside buffer, and computational hardware, e.g. arithmetic and vector processing units. This was more pronounced on the KNL system where up to 4 threads can share a processor.</p>
<p>Divergence between the lock-type scaling behaviors was lower for Bowtie 2 than for the other tools. This is likely because Bowtie 2 requires more time to align a single read. This spreads locking attempts out over time and thereby reduces contention. Thus, Bowtie 2&#x2019;s lower divergence is consistent with the theory that differences come primarily from contention overhead.</p>
<p>In summary: while the MP baseline outperformed all MT configurations, the TBB queueing lock often scaled best, with the TBB spin and standard locks doing well or better in some situations. We use the queueing lock in subsequent Bowtie, Bowtie 2 and HISAT experiments.</p>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Varying parsing method</title>
<p>The gap between MP baseline and MT methods spurred us to examine the highly contended input and output locks. We hypothesized the gap was due to a combination of (a) the length of time spent in these critical section, and (b) the overhead of locking and unlocking before and after these critical section. We tried to close the gap using the strategies discussed in Methods: deferred parsing (D), batch parsing (B). B-parsing used a batch size of 32 in all experiments.</p>
<p><xref ref-type="fig" rid="fig4">Figure 4</xref> shows running time versus thread count for unpaired alignment using each parsing strategy. Supplementary Figure 2 shows the same for paired-end alignment. A clear ordering exists among the strategies: B-parsing outperformed D-parsing, which outperformed O-parsing. This was true in every scenario tested. B-parsing scaled well enough to be competitive with the MP baseline in multiple scenarios, e.g. for Bowtie 2, for Broadwell&#x002B;Bowtie, and for all paired-end scenarios apart from KNL&#x002B;HISAT.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Comparison of 3 parsing strategies and multiprocessing baseline. Reads are unpaired. Jobs that ran for over 20 minutes are omitted. Squares indicate the point on each line yielding maximal total alignment throughput and these points are summarized in <xref ref-type="table" rid="tbl3">Table 3</xref>.</p></caption>
<graphic xlink:href="205328_fig4.tif"/>
</fig>
<p><xref ref-type="table" rid="tbl3">Table 3</xref> shows peak throughputs (also represented by squares in <xref ref-type="fig" rid="fig4">Figure 4</xref>) for each lock type and the MP baseline. B-parsing had either the highest or second-highest peak throughput in all scenarios except paired-end KNL&#x002B;Bowtie, where it performed slightly worse than D-parsing. The MP baseline had the highest peak throughput in 6 of 12 scenarios. Importantly, there was still a wide gap between the MP baseline and the second-best throughput (achieved by B-parsing) in a few scenarios, including KNL&#x002B;HISAT and unpaired KNL&#x002B;Bowtie.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><p>Peak throughputs for three parsing strategies. For each of combination of aligner, paired-end status and test machine, the best and second-best throughputs are highlighted in red and orange respectively. In all cases the TBB queueing lock type is used.</p></caption>
<graphic xlink:href="205328_tbl3.tif"/>
</table-wrap>
<p>As with the lock type investigation, we find that divergence between the parsing strategies was lower for Bowtie 2 than for the other tools. Again, this is likely because Bowtie 2 spends more time on aligning each read compared to the other tools, reducing contention.</p>
</sec>
<sec id="s3c">
<label>3.3</label>
<title>Final evaluation</title>
<p>Finally we compared B-parsing to L-parsing, i.e. block deferred parsing. Because L-parsing&#x2019;s critical section is the most streamlined, we hypothesized that it would outperform B-parsing. But recall that L-parsing requires the input to be padded, requiring an initial pass over the input reads that might itself become the throughput bottleneck depending on the scenario. We return to the important question of L-parsing practicality in the Discussion section below.</p>
<p>To test block parsing (L) we created new input sets with appropriate padding (example in <xref ref-type="fig" rid="fig2">Figure 2</xref>). Specifically, we created a new input set called <italic>human_100_block_300M</italic> with the same reads as <italic>human_100_300M</italic> but with the FASTQ for both ends padded to achieve 12 KB blocks (<italic>B</italic> &#x003D; 12288) and 44 reads per block (<italic>N</italic> &#x003D; 44). Similarly, we created an input set called <italic>human_50_block_300M</italic> with the reads from <italic>human_50_300M</italic> padded to achieve 12 KB blocks (<italic>B</italic> &#x003D; 12288) and 70 reads per block (<italic>N</italic> &#x003D; 70). N and B are provided to the read aligner via command-line options (<monospace>--block-bytes</monospace> and <monospace>--reads-per-block</monospace>) added for these experiments.</p>
<p>In the case of Bowtie 2, we also compared to BWA-MEM v0.7.16a [<xref ref-type="bibr" rid="c15">15</xref>] with default argu-ments. BWA-MEM uses a pipelined strategy. Two master threads run simultaneously, each cycling through three steps: (a) parsing a batch of input reads, (b) aligning the batch, and (c) writing the output alignments for the batch. The two master threads cannot be in the aligning step at the same time, creating a degree of interleaving; one thread can be aligning while the other is writing output or reading input. This synchronization is enforced by a pthreads [<xref ref-type="bibr" rid="c37">37</xref>] lock and condition variable. When a master thread enters the alignment step, it spawns T alignment threads with <italic>T</italic> specified via the <monospace>- t</monospace> option. A work stealing mechanism enables dynamic load balancing among alignment threads, with synchronization facilitated by atomic operations. Batch size is determined by multiplying a constant number of input bases (10 million) by <italic>T</italic>. We note that (a) these are relatively large batches compared to Bowtie 2, which uses a batch size of 32 reads for B-parsing and of either 44 or 70 reads for L-parsing depending on read length, and (b) that, while the batch size is independent of thread count for Bowtie 2, it grows linearly with thread count in BWA-MEM.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><p>Peak throughputs for three parsing strategies. For each of combination of aligner, paired-end status and test machine, the best and second-best throughputs are highlighted in red and orange respectively. In all cases the TBB queueing lock type is used.</p></caption>
<graphic xlink:href="205328_tbl4.tif"/>
</table-wrap>
<p>For our BWA-MEM experiments, we used the same number of input reads as for the Bowtie 2 experiments (Supplementary Table 1). We also corrected an issue in the BWA-MEM code that caused failures for thread counts over 214, a limit we exceed on KNL (Supplementary Note 3).</p>
<p><xref ref-type="fig" rid="fig5">Figure 5</xref> shows the comparison for unpaired alignment and Supplementary Figure 3 shows the same for paired-end alignment. <xref ref-type="table" rid="tbl4">Table 4</xref> gives the maximal peak throughput for each configuration. While L- and B-parsing scaled similarly at low thread counts, L-parsing maintained excellent scaling through higher thread counts in all configurations. B-parsing scaled substantially worse than L-parsing for HISAT and for unpaired Bowtie.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Comparison of BWA-MEM, the multiprocessing baseline, and the 2 most advantageous multithreading configurations tested. Unpaired alignment was performed. Jobs that ran for over 20 minutes are omitted. Squares indicate the run for each configuration that yields the greatest overall alignment throughput. These points are summarized in <xref ref-type="table" rid="tbl4">Table 4</xref>.</p></caption>
<graphic xlink:href="205328_fig5.tif"/>
</fig>
<p>Remarkably, L-parsing scaled better than the MP baseline in most cases. Additionally, L-parsing had the highest peak throughput (<xref ref-type="table" rid="tbl4">Table 4</xref>) in 11 out of the 12 scenarios. Thus, L-parsing is the only approach we have found that consistently scales better than the MP baseline.</p>
<p>While BWA-MEM scales well, both the B-parsing and L-parsing Bowtie 2 configurations scaled better. This is particularly true on the KNL system and is also supported by the peak throughputs (<xref ref-type="table" rid="tbl4">Table 4</xref>), where B-parsing achieved 28&#x2013;44&#x0025; higher throughput and L-parsing achieved 32&#x2013;49&#x0025; higher throughput than BWA-MEM across the four scenarios. BWA-MEM&#x2019;s larger input chunk size, together with the fact that chunk size scales linearly with thread count, caused BWA-MEM&#x2019;s memory footprint to grow much faster than Bowtie 2&#x2019;s (Supplementary Figure 4).</p>
</sec></sec>
<sec id="s4">
<label>4</label>
<title>Discussion</title>
<p>General-purpose processors now support hundreds of simultaneous threads of execution and fu-ture architectures will likely continue the trend of squeezing more relatively slow threads onto a single chip. Genomics software must adapt to high thread counts, slow individual threads, and system architectures that more closely resemble small computer clusters &#x2014; complete with inter-connection network and distributed storage &#x2014; than simpler processors of the past.</p>
<p>We addressed how lock types, design of critical sections, NUMA, starvation and other issues can impact thread scaling on two Intel systems, including one based on the many-core Knight&#x2019;s Landing architecture. We greatly improved thread scaling for three commonly used alignment tools: Bowtie, Bowtie 2 and HISAT. We measured the effect of each candidate improvement, and also showed that the improvements to Bowtie 2 allow it to scale more favorably than BWA-MEM with respect to both time and peak memory footprint. The TBB queueing lock and the B-parsing method are the default as of Bowtie v1.2.0 and Bowtie 2 v2.3.0.</p>
<p>Bowtie and HISAT align reads more quickly than Bowtie 2 or BWA-MEM (<xref ref-type="table" rid="tbl4">Table 4</xref>), making their locks more contended and thread scaling more difficult. This is reinforced by how little L-parsing improved Bowtie 2&#x2019;s scaling, compared to how much it improved scaling for Bowtie and HISAT. So while we improved a range of tools in this study, greater gains may be possible by adapting these methods to even faster tools, such as pseudoaligners [<xref ref-type="bibr" rid="c38">38</xref>], quasi-mappers [<xref ref-type="bibr" rid="c39">39</xref>] and tools that analyze reads based on <italic>k</italic>-mer content [<xref ref-type="bibr" rid="c14">14</xref>].</p>
<p>Despite the gains shows here, there is further room for improvement. For example, the best-scaling MT method that works with standard unpadded sequencing reads is B-parsing, which is why B-parsing is now the default strategy (coupled with the TBB queueing lock) in Bowtie and Bowtie 2. But the MP baseline outperformed B-parsing in some scenarios, and L-parsing outperformed it in all scenarios. We are still seeking MT methods that scale as well as the MP baseline or L-parsing but that also work with unpadded inputs.</p>
<p>To improve MT scaling further, it will be important to investigate more lock types. The queue-ing (MCS [<xref ref-type="bibr" rid="c30">30</xref>]) lock scaled best at high thread counts, likely because of reduced cache-coherence communication. But other lock types could improve on this in two ways. First: like the spinlock, the queueing lock is optimistic. But at high thread counts, locks become more contended and pes-simism is more appropriate. It will be important to investigate lock types that adapt their degree of optimism in inverse proportion to the lock contention, e.g. the hierarchical backoff lock [<xref ref-type="bibr" rid="c40">40</xref>]. Secondly, while the queueing lock successfully reduces cache-coherence communication, other locks go further in this regard. The cohort lock [<xref ref-type="bibr" rid="c41">41</xref>], for example, further reduces communication by maximizing the chance that consecutive holders of the lock are physically proximate (i.e. on the same NUMA node), avoiding expensive longer-distance communication.</p>
<p>We argued that genomics file formats, notably FASTQ and FASTA, presented obstacles to fur-ther thread scaling improvements. Because records do not have a predictable length, boundaries between records must be identified in a synchronized manner, i.e. inside a critical section. By adapting FASTQ to have predictable record boundaries and combining that with our L-parsing strategy, we achieve the best scaling of any method evaluated here, including the MP baseline.</p>
<p>The padding needed for L-parsing is easy to add and works regardless of the reads&#x2019; paired-end status or length (including mixed lengths within a file and/or between paired ends), as long as the block size <italic>B</italic> is large enough to accommodate the longest read. This suggests a strategy of pre-padding FASTQ files before feeding them to L-parsing aligners. But this might simply move the synchronization bottleneck into the padding software. Software that adds padding must detect (and manipulate) record boundaries, similarly to the D-parsing and B-parsing critical sections. As we established, that makes it difficult to scale to a large number of threads. If the padding software and the downstream read alignment software are connected in a pipeline, the aligner can only be fed at the rate at which padding is added. It may still be worth the cost, though, if we expect the same input file to be re-used across multiple L-parsing alignment jobs. This effectively amortizes the computational cost of the padding over many downstream analyses, each benefiting from L-parsing&#x2019;s superior thread scaling.</p>
<p>Compression is also a key issue for future work. Because the padding added for L-parsing is repetitive (strings of space characters), compression can greatly reduce the padding&#x2019;s added cost. For instance, the padding added to our input sets increased uncompressed FASTQ file size by 9&#x2013;14&#x0025;, but the compressed FASTQ file size increased just 1.0&#x2013;1.5&#x0025; (Supplementary Table 2). More generally, it is common to store sequencing reads in a compressed form, then decompress &#x2014; e.g. with <monospace>gzip</monospace> or the <monospace>libz</monospace> library &#x2014; prior to read alignment. But if decompression must be performed either upstream of the read aligner or in the aligner&#x2019;s input critical section, decompression is liable to become a new thread-scaling bottleneck. A possible workaround is similar to the idea behind D-parsing: instead of both reading and decompressing in the critical section, decompression could be deferred until after the critical section. A question for future work is whether compressed inputs can be used to reduce the space overhead of padding while still providing thread scaling similar to what we achieved here with L-parsing and uncompressed inputs.</p>
</sec>
</body>
<back>
<ack>
<label>5</label>
<title>Acknowledgments</title>
<p>We are grateful to many individuals at Intel, and the Intel Parallel Computing Center program, for their technical and administrative assistance, including John Oneill, Ram Ramanujam, Kevin O&#x2019;leary, Lisa Smith and Brian Napier. This work used the Extreme Science and Engineering Dis-covery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1548562.</p></ack>
<sec sec-type="funding">
<label>6</label>
<title>Funding</title>
<p>BL, VA and CW were partly supported by an Intel Parallel Computing Center grant to BL. BL, CW and RC were supported by National Institutes of Health/National Institute of General Medical Sciences grant R01GM118568 to BL. Experiments on the KNL system used the XSEDE Stampede 2 resource at the Texas Advanced Computing Center (TACC), which we accessed using allocation TG-CIE170020 to BL.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="confproc"><string-name><surname>Avinash</surname> <given-names>Sodani</given-names></string-name>. &#x201C;<article-title>Knights landing (KNL): 2nd Generation Intel&#x00AE; Xeon Phi processor</article-title>&#x201D;. In: <conf-name>Hot Chips 27 Symposium (HCS), 2015 IEEE</conf-name>. <conf-sponsor>IEEE</conf-sponsor>. <year>2015</year>, pp. <fpage>1</fpage>&#x2013;<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="book"><string-name><surname>James</surname> <given-names>Jeffers</given-names></string-name>, <string-name><surname>James</surname> <given-names>Reinders</given-names></string-name>, and <string-name><surname>Avinash</surname> <given-names>Sodani</given-names></string-name>. <chapter-title>Intel Xeon Phi Processor High Performance Programming: Knights Landing Edition</chapter-title>. <publisher-name>Morgan Kaufmann</publisher-name>, <year>2016</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>M</given-names> <surname>Mitchell Waldrop</surname></string-name>. &#x201C;<article-title>The chips are down for Moore&#x2019;s law</article-title>&#x201D;. In: <source>Nature News</source> <volume>530</volume>.<issue>7589</issue> (<year>2016</year>), p. <fpage>144</fpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Pedro</given-names> <surname>Valero-Lara</surname></string-name>, <string-name><given-names>Abel</given-names> <surname>Paz-Gallardo</surname></string-name>, <string-name><given-names>Manuel</given-names> <surname>Prieto-Mat&#x00ED;as</surname></string-name>, <string-name><given-names>Alfredo</given-names> <surname>Pinelli</surname></string-name>, <string-name><given-names>Erich L</given-names> <surname>Foster</surname></string-name>, and <string-name><given-names>Johan</given-names> <surname>Jansson</surname></string-name>. &#x201C;<article-title>Multicore and Manycore: Hybrid Computing Architectures</article-title>&#x201D;. In: <source>Innovative Research and Applications in Next-Generation High Performance Computing</source> (<year>2016</year>), p. <fpage>107</fpage>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="website"><string-name><given-names>Jeff</given-names> <surname>Barr</surname></string-name>. <source>New Compute-Optimized EC2 Instances</source>. <ext-link ext-link-type="uri" xlink:href="https://aws.amazon.com/blogs/aws/new-c4-instances/">https://aws.amazon.com/blogs/aws/new-c4-instances/</ext-link>. [Online; accessed <date-in-citation content-type="access-date">2017-10-20</date-in-citation>]. <year>2014</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>Josefina</given-names> <surname>Lenis</surname></string-name> and <string-name><given-names>Miquel</given-names> <surname>Angel Senar</surname></string-name>. &#x201C;<article-title>A performance comparison of data and memory allocation strategies for sequence aligners on NUMA architectures</article-title>&#x201D;. In: <source>Cluster Computing</source> <volume>20</volume>.<issue>3</issue> (<year>2017</year>), pp. <fpage>1909</fpage>&#x2013;<lpage>1924</lpage>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><surname>Ben</surname> <given-names>Langmead</given-names></string-name>, <string-name><given-names>Cole</given-names> <surname>Trapnell</surname></string-name>, <string-name><given-names>Mihai</given-names> <surname>Pop</surname></string-name>, and <string-name><given-names>Steven L</given-names> <surname>Salzberg</surname></string-name>. &#x201C;<article-title>Ultrafast and memory-efficient alignment of short DNA sequences to the human genome</article-title>&#x201D;. In: <source>Genome biology</source> <volume>10</volume>.<issue>3</issue> (<year>2009</year>), p. <fpage>1</fpage>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><surname>Ben</surname> <given-names>Langmead</given-names></string-name> and <string-name><given-names>Steven L</given-names> <surname>Salzberg</surname></string-name>. &#x201C;<article-title>Fast gapped-read alignment with Bowtie 2</article-title>&#x201D;. In: <source>Nature methods</source> <volume>9</volume>.<issue>4</issue> (<year>2012</year>), pp. <fpage>357</fpage>&#x2013;<lpage>359</lpage>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Daehwan</given-names> <surname>Kim</surname></string-name>, <string-name><surname>Ben</surname> <given-names>Langmead</given-names></string-name>, and <string-name><given-names>Steven L</given-names> <surname>Salzberg</surname></string-name>. &#x201C;<article-title>HISAT: a fast spliced aligner with low memory requirements</article-title>&#x201D;. In: <source>Nature methods</source> <volume>12</volume>.<issue>4</issue> (<year>2015</year>), pp. <fpage>357</fpage>&#x2013;<lpage>360</lpage>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>David R</given-names> <surname>Kelley</surname></string-name>, <string-name><given-names>Michael C</given-names> <surname>Schatz</surname></string-name>, <string-name><given-names>Steven L</given-names> <surname>Salzberg</surname></string-name>, <etal>et al.</etal> &#x201C;<article-title>Quake: quality-aware detection and correction of sequencing errors</article-title>&#x201D;. In: <source>Genome Biol</source> <volume>11</volume>.<issue>11</issue> (<year>2010</year>), <fpage>R116</fpage>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>Song</given-names></string-name>, <string-name><surname>Liliana</surname> <given-names>Florea</given-names></string-name>, and <string-name><surname>Ben</surname> <given-names>Langmead</given-names></string-name>. &#x201C;<article-title>Lighter: fast and memory-efficient sequencing error correction without counting</article-title>&#x201D;. In: <source>Genome Biol</source> <volume>15</volume> (<year>2014</year>), p. <fpage>509</fpage>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Anthony M</given-names> <surname>Bolger</surname></string-name>, <string-name><surname>Marc</surname> <given-names>Lohse</given-names></string-name>, and <string-name><surname>Bjoern</surname> <given-names>Usadel</given-names></string-name>. &#x201C;<article-title>Trimmomatic: a flexible trimmer for Illumina sequence data</article-title>&#x201D;. In: <source>Bioinformatics</source> (<year>2014</year>), <fpage>btu170</fpage>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><surname>Nicola</surname> <given-names>Segata</given-names></string-name>, <string-name><given-names>Levi</given-names> <surname>Waldron</surname></string-name>, <string-name><surname>Annalisa</surname> <given-names>Ballarini</given-names></string-name>, <string-name><given-names>Vagheesh</given-names> <surname>Narasimhan</surname></string-name>, <string-name><given-names>Olivier</given-names> <surname>Jousson</surname></string-name>, and <string-name><given-names>Curtis</given-names> <surname>Huttenhower</surname></string-name>. &#x201C;<article-title>Metagenomic microbial community profiling using unique clade-specific marker genes</article-title>&#x201D;. In: <source>Nature methods</source> <volume>9</volume>.<issue>8</issue> (<year>2012</year>), pp. <fpage>811</fpage>&#x2013;<lpage>814</lpage>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Derrick E</given-names> <surname>Wood</surname></string-name> and <string-name><given-names>Steven L</given-names> <surname>Salzberg</surname></string-name>. &#x201C;<article-title>Kraken: ultrafast metagenomic sequence classification using exact alignments</article-title>&#x201D;. In: <source>Genome Biol</source> <volume>15</volume>.<issue>3</issue> (<year>2014</year>), <fpage>R46</fpage>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="other"><string-name><given-names>Heng</given-names> <surname>Li</surname></string-name>. &#x201C;<article-title>Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM</article-title>&#x201D;. In: <source>arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1303.3997</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>P. J.</given-names> <surname>Cock</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Fields</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Goto</surname></string-name>, <string-name><given-names>M. L.</given-names> <surname>Heuer</surname></string-name>, and <string-name><given-names>P. M.</given-names> <surname>Rice</surname></string-name>. &#x201C;<article-title>The Sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</article-title>&#x201D;. In: <source>Nucleic Acids Res</source>. <volume>38</volume>.<issue>6</issue> (Apr. <year>2010</year>), pp. <fpage>1767</fpage>&#x2013;<lpage>1771</lpage>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>Davidlohr</given-names> <surname>Bueso</surname></string-name>. &#x201C;<article-title>Scalability techniques for practical synchronization primitives</article-title>&#x201D;. In: <source>Queue</source> <volume>12</volume>.<issue>11</issue> (<year>2014</year>), p. <fpage>40</fpage>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="book"><string-name><given-names>James</given-names> <surname>Reinders</surname></string-name>. <source>Intel threading building blocks: outfitting C&#x002B;&#x002B; for multi-core processor parallelism</source>. &#x201C; <publisher-name>O&#x2019;Reilly Media, Inc</publisher-name>.&#x201D;, <year>2007</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="confproc"><string-name><given-names>Thomas</given-names> <surname>Willhalm</surname></string-name> and <string-name><given-names>Nicolae</given-names> <surname>Popovici</surname></string-name>. &#x201C;<article-title>Putting intel<sup>&#x00AE;</sup> threading building blocks to work</article-title>&#x201D;. In: <conf-name>Proceedings of the 1st international workshop on Multicore software engineering</conf-name>. <conf-sponsor>ACM</conf-sponsor>. <year>2008</year>, pp. <fpage>3</fpage>&#x2013;<lpage>4</lpage>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>Santiago</given-names> <surname>Marco-Sola</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Sammeth</surname></string-name>, <string-name><given-names>Roderic</given-names> <surname>Guig&#x00F3;</surname></string-name>, and <string-name><given-names>Paolo</given-names> <surname>Ribeca</surname></string-name>. &#x201C;<article-title>The GEM mapper: fast, accurate and versatile alignment by filtration</article-title>&#x201D;. In: <source>Nature methods</source> <volume>9</volume>.<issue>12</issue> (<year>2012</year>), pp. <fpage>1185</fpage>&#x2013;<lpage>1188</lpage>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="other"><string-name><given-names>Matei</given-names> <surname>Zaharia</surname></string-name>, <string-name><given-names>William J</given-names> <surname>Bolosky</surname></string-name>, <string-name><given-names>Kristal</given-names> <surname>Curtis</surname></string-name>, <string-name><given-names>Armando</given-names> <surname>Fox</surname></string-name>, <string-name><given-names>David</given-names> <surname>Patterson</surname></string-name>, <string-name><given-names>Scott</given-names> <surname>Shenker</surname></string-name>, <string-name><given-names>Ion</given-names> <surname>Stoica</surname></string-name>, <string-name><given-names>Richard M</given-names> <surname>Karp</surname></string-name>, and <string-name><given-names>Taylor</given-names> <surname>Sittler</surname></string-name>. &#x201C;<article-title>Faster and more accurate sequence alignment with SNAP</article-title>&#x201D;. In: <source>arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1111.5572</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="confproc"><string-name><given-names>Claudia</given-names> <surname>Misale</surname></string-name>. &#x201C;<article-title>Accelerating Bowtie2 with a lock-less concurrency approach and memory affinity</article-title>&#x201D;. In: <conf-name>Parallel, Distributed and Network-Based Processing (PDP), 2014 22nd Euromicro International Conference</conf-name> on. <conf-sponsor>IEEE</conf-sponsor>. <year>2014</year>, pp. <fpage>578</fpage>&#x2013;<lpage>585</lpage>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>Claudia</given-names> <surname>Misale</surname></string-name>, <string-name><given-names>Giulio</given-names> <surname>Ferrero</surname></string-name>, <string-name><given-names>Massimo</given-names> <surname>Torquati</surname></string-name>, and <string-name><given-names>Marco</given-names> <surname>Aldinucci</surname></string-name>. &#x201C;<article-title>Sequence alignment tools: one parallel pattern to rule them all?</article-title>&#x201D; In: <source>BioMed research international</source> <volume>2014</volume> (<year>2014</year>).</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Marco</given-names> <surname>Aldinucci</surname></string-name>, <string-name><given-names>Marco</given-names> <surname>Danelutto</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Kilpatrick</surname></string-name>, and <string-name><given-names>Massimo</given-names> <surname>Torquati</surname></string-name>. &#x201C;<article-title>Fastflow: high-level and efficient streaming on multi-core</article-title>&#x201D;. In: <source>Programming multi-core and many-core com-puting systems, parallel and distributed computing</source> (<year>2014</year>).</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="book"><string-name><given-names>Charlotte</given-names> <surname>Herzeel</surname></string-name>, <string-name><given-names>Thomas J</given-names> <surname>Ashby</surname></string-name>, <string-name><given-names>Pascal</given-names> <surname>Costanza</surname></string-name>, and <string-name><given-names>Wolfgang</given-names> <surname>De Meuter</surname></string-name>. &#x201C;<chapter-title>Resolving Load Balancing Issues in BWA on NUMA multicore architectures</chapter-title>&#x201D;. In: <source>Parallel Processing and Applied Mathematics</source>. <publisher-name>Springer</publisher-name>, <year>2014</year>, pp. <fpage>227</fpage>&#x2013;<lpage>236</lpage>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="book"><string-name><given-names>Robert D</given-names> <surname>Blumofe</surname></string-name>, <string-name><given-names>Christopher F</given-names> <surname>Joerg</surname></string-name>, <string-name><given-names>Bradley C</given-names> <surname>Kuszmaul</surname></string-name>, <string-name><given-names>Charles E</given-names> <surname>Leiserson</surname></string-name>, <string-name><given-names>Keith H</given-names> <surname>Randall</surname></string-name>, and <string-name><given-names>Yuli</given-names> <surname>Zhou</surname></string-name>. <source>Cilk: An efficient multithreaded runtime system</source>. Vol. <volume>30</volume>. <issue>8</issue>. <publisher-name>ACM</publisher-name>, <year>1995</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>Thomas E.</given-names> <surname>Anderson</surname></string-name>. &#x201C;<article-title>The performance of spin lock alternatives for shared-money multi-processors</article-title>&#x201D;. In: <source>IEEE Transactions on Parallel and Distributed Systems</source> <volume>1</volume>.<issue>1</issue> (<year>1990</year>), pp. <fpage>6</fpage>&#x2013;<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="website"><collab>TinyThread&#x002B;&#x002B; team</collab>. <source>TinyThread&#x002B;&#x002B; portable threads</source>. <ext-link ext-link-type="uri" xlink:href="http://tinythreadpp.bitsnbites.eu">http://tinythreadpp.bitsnbites.eu</ext-link>. [Online; accessed <date-in-citation content-type="access-date">2017-10-4</date-in-citation>]. <volume>2012</volume>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="website"><article-title>Intel</article-title>. <source>Intel Thread Building Blocks Developer Guide: Mutex Flavors</source>. <ext-link ext-link-type="uri" xlink:href="https://software.intel.com/en-us/node/506086">https://software.intel.com/en-us/node/506086</ext-link>. Online; Accessed on <date-in-citation content-type="access-date">2016-07-27</date-in-citation>. <volume>2016</volume>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>John M</given-names> <surname>Mellor-Crummey</surname></string-name> and <string-name><given-names>Michael L</given-names> <surname>Scott</surname></string-name>. &#x201C;<article-title>Synchronization without contention</article-title>&#x201D;. In: <source>ACM SIGPLAN Notices</source> <volume>26</volume>.<issue>4</issue> (<year>1991</year>), pp. <fpage>269</fpage>&#x2013;<lpage>278</lpage>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>H.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Handsaker</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Wysoker</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Fennell</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Ruan</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Homer</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Marth</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Abecasis</surname></string-name>, and <string-name><given-names>R.</given-names> <surname>Durbin</surname></string-name>. &#x201C;<article-title>The Sequence Alignment/Map format and SAMtools</article-title>&#x201D;. In: <source>Bioinformatics</source> <volume>25</volume>.<issue>16</issue> (Aug. <year>2009</year>), pp. <fpage>2078</fpage>&#x2013;<lpage>2079</lpage>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>Deanna M</given-names> <surname>Church</surname></string-name>, <string-name><given-names>Valerie A</given-names> <surname>Schneider</surname></string-name>, <string-name><given-names>Karyn</given-names> <surname>Meltz Steinberg</surname></string-name>, <string-name><given-names>Michael C</given-names> <surname>Schatz</surname></string-name>, <string-name><given-names>Aaron R</given-names> <surname>Quinlan</surname></string-name>, <string-name><surname>Chen-Shan</surname> <given-names>Chin</given-names></string-name>, <string-name><surname>Paul</surname> <given-names>A Kitts</given-names></string-name>, <string-name><given-names>Bronwen</given-names> <surname>Aken</surname></string-name>, <string-name><given-names>Gabor T</given-names> <surname>Marth</surname></string-name>, <string-name><given-names>Michael M</given-names> <surname>Hoff-man</surname></string-name>, <etal>et al.</etal> &#x201C;<article-title>Extending reference assembly models</article-title>&#x201D;. In: <source>Genome biology</source> <volume>16</volume>.<issue>1</issue> (<year>2015</year>), p. <fpage>13</fpage>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="website"><string-name><given-names>Daehwan</given-names> <surname>Kim</surname></string-name>. <source>HISAT2: graph-based alignment of next generation sequencing reads to a population of genomes</source>. <ext-link ext-link-type="uri" xlink:href="http://ccb.jhu.edu/software/hisat2/index.shtml">http://ccb.jhu.edu/software/hisat2/index.shtml</ext-link>. [Online; accessed <date-in-citation content-type="access-date">2017-10-4</date-in-citation>]. <volume>2017</volume>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>M. A.</given-names> <surname>Eberle</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Fritzilas</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Krusche</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Kallberg</surname></string-name>, <string-name><given-names>B. L.</given-names> <surname>Moore</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Bekritsky</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Iqbal</surname></string-name>, <string-name><given-names>H. Y.</given-names> <surname>Chuang</surname></string-name>, <string-name><given-names>S. J.</given-names> <surname>Humphray</surname></string-name>, <string-name><given-names>A. L.</given-names> <surname>Halpern</surname></string-name>, <etal>et al.</etal> &#x201C;<article-title>A reference data set of 5.4 million phased human variants validated by genetic inheritance from sequencing a three-generation 17-member pedigree</article-title>&#x201D;. In: <source>Genome Res</source>. <volume>27</volume>.<issue>1</issue> (Jan. <year>2017</year>]), pp. <fpage>157</fpage>&#x2013;<lpage>164</lpage>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Auton</surname></string-name>, <string-name><given-names>L. D.</given-names> <surname>Brooks</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Durbin</surname></string-name>, <string-name><given-names>E. P.</given-names> <surname>Garrison</surname></string-name>, <string-name><given-names>H. M.</given-names> <surname>Kang</surname></string-name>, <string-name><given-names>J. O.</given-names> <surname>Korbel</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Marchini</surname></string-name>, <string-name><given-names>S.</given-names> <surname>McCarthy</surname></string-name>, <string-name><given-names>G. A.</given-names> <surname>McVean</surname></string-name>, <string-name><given-names>G. R.</given-names> <surname>Abecasis</surname></string-name>, <etal>et al.</etal> &#x201C;<article-title>A global reference for human genetic variation</article-title>&#x201D;. In: <source>Nature</source> <volume>526</volume>.<issue>7571</issue> (Oct. <year>2015</year>), pp. <fpage>68</fpage>&#x2013;<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Rustagi</surname></string-name>. <string-name><given-names>A.</given-names> <surname>Zhou</surname></string-name>, <string-name><given-names>W. S.</given-names> <surname>Watkins</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Gedvilaite</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Ramesh</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Muzny</surname></string-name>, <string-name><given-names>R. A.</given-names> <surname>Gibbs</surname></string-name>, <string-name><given-names>L. B.</given-names> <surname>Jorde</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Yu</surname></string-name>, <etal>et al.</etal> &#x201C;<article-title>Extremely low-coverage whole genome sequencing in South Asians captures population genomics information</article-title>&#x201D;. In: <source>BMC Genomics</source> <volume>18</volume>.<issue>1</issue> (May <year>2017</year>), p. <fpage>396</fpage>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="book"><string-name><given-names>Bradford</given-names> <surname>Nichols</surname></string-name>, <string-name><given-names>Dick</given-names> <surname>Buttlar</surname></string-name>, and <string-name><given-names>Jacqueline</given-names> <surname>Farrell</surname></string-name>. <chapter-title>Pthreads programming: A POSIX standard for better multiprocessing</chapter-title>. &#x0022; <publisher-name>O&#x2019;Reilly Media, Inc</publisher-name>.&#x0022;, <year>1996</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>NL</given-names> <surname>Bray</surname></string-name>, <string-name><given-names>H</given-names> <surname>Pimentel</surname></string-name>, <string-name><given-names>P</given-names> <surname>Melsted</surname></string-name>, and <string-name><given-names>L</given-names> <surname>Pachter</surname></string-name>. &#x201C;<article-title>Near-optimal probabilistic RNA-seq quantification</article-title>.&#x201D; In: <source>Nature biotechnology</source> <volume>34</volume>.<issue>5</issue> (<year>2016</year>), p. <fpage>525</fpage>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>Avi</given-names> <surname>Srivastava</surname></string-name>, <string-name><given-names>Hirak</given-names> <surname>Sarkar</surname></string-name>, <string-name><given-names>Nitish</given-names> <surname>Gupta</surname></string-name>, and <string-name><given-names>Rob</given-names> <surname>Patro</surname></string-name>. &#x201C;<article-title>RapMap: a rapid, sensitive and accurate tool for mapping RNA-seq reads to transcriptomes</article-title>&#x201D;. In: <source>Bioinformatics</source> <volume>32</volume>.<issue>12</issue> (<year>2016</year>), pp. <fpage>i192</fpage>&#x2013;<lpage>i200</lpage>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="confproc"><string-name><given-names>Zoran</given-names> <surname>Radovic</surname></string-name> and <string-name><given-names>Erik</given-names> <surname>Hagersten</surname></string-name>. &#x201C;<article-title>Hierarchical backoff locks for nonuniform communi-cation architectures</article-title>&#x201D;. In: <collab>High-Performance Computer Architecture, 2003. HPCA-9 2003</collab>. <conf-name>Proceedings. The Ninth International Symposium</conf-name> on. <conf-sponsor>IEEE</conf-sponsor>. <year>2003</year>, pp. <fpage>241</fpage>&#x2013;<lpage>252</lpage>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Dice</surname></string-name>, <string-name><given-names>Virendra J</given-names> <surname>Marathe</surname></string-name>, and <string-name><given-names>Nir</given-names> <surname>Shavit</surname></string-name>. &#x201C;<article-title>Lock cohorting: A general technique for designing NUMA locks</article-title>&#x201D;. In: <source>ACM Transactions on Parallel Computing</source> <volume>1</volume>.<issue>2</issue> (<year>2015</year>), p. <fpage>13</fpage>.</mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn1"><label><sup>1</sup></label><p>There can be minor exceptions to this principle. For instance, HISAT uses alignments from a preliminary batch of reads to detect putative junctions that are then used to inform spliced alignment of subsequent reads.</p></fn>
</fn-group>
</back>
</article>