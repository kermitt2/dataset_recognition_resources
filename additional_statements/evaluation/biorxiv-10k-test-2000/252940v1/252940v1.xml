<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/252940</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Large-scale two-photon imaging revealed super-sparse population codes in V1 superficial layer of awake monkeys</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0294-3259</contrib-id>
<name>
<surname>Tang</surname>
<given-names>Shiming</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2248-8951</contrib-id>
<name>
<surname>Zhang</surname>
<given-names>Yimeng</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Zhihao</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Ming</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Fang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jiang</surname>
<given-names>Hongfei</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Lee</surname>
<given-names>Tai Sing</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Peking University School of Life Sciences and Peking-Tsinghua Center for Life Sciences</institution>, <country>China</country>;</aff>
<aff id="a2"><label>2</label><institution>IDG/McGovern Institute for Brain Research at Peking University</institution>, <country>China</country>;</aff>
<aff id="a3"><label>3</label><institution>Key Laboratory of Machine Perception (Ministry of Education), Peking University</institution>, Beijing 100871, P. R. <country>China</country>;</aff>
<aff id="a4"><label>4</label><institution>Center for the Neural Basis of Cognition and Computer Science Department, Carnegie Mellon University</institution>, Pittsburgh, Pennsylvania, <country>United States</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>To whom correspondence should be addressed (<email>tangshm@pku.edu.cn</email> and <email>tai@cnbc.cmu.edu</email>)
</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>252940</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>24</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>1</month>
<year>2018</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="252940.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Efficient coding has been proposed as a general principle for the sensory systems. The efficient coding hypothesis predicts that neuronal population responses should be sparse, but limited by the measurement techniques, the precise estimates of the population sparseness of visual cortical neurons are still uncertain. Here, we employed large-scale two-photon calcium imaging to examine the neuronal population activities in V1 superficial layers of awake macaques in response to a large set of natural images. We found that only 0.5&#x0025; of these neurons on average responded strongly to any given natural image with response strength above half of their individual peak responses, which is more than tenfold sparse over those reported by early studies. We further showed that these sparse population activities contain sufficient information for discriminating images with high accuracy. This study provided the first accurate measure of sparseness in V1 neuronal population responses, which support super-sparse neural codes in primates.</p>
</abstract>
<counts>
<page-count count="27"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Sparse coding is an important organizing principle in the sensory system (<xref ref-type="bibr" rid="c2">Barlow, 1981</xref>; <xref ref-type="bibr" rid="c11">Olshausen and Field, 1996</xref>). The efficient coding hypothesis predicts that neuronal population responses should be sparse, though the optimal level of sparseness depends on many factors. Most of the experimental evidences in support of sparse coding is based on the sparseness of an individual neuron&#x2019;s responses to natural images, measured using single-unit recording techniques (<xref ref-type="bibr" rid="c6">Haider et al., 2010</xref>; <xref ref-type="bibr" rid="c8">Hromadka et al., 2008</xref>; <xref ref-type="bibr" rid="c18">Rust and DiCarlo, 2012</xref>; <xref ref-type="bibr" rid="c20">Vinje and Gallant, 2000</xref>). One direct measurement of population sparseness was provided by a two-photon imaging (GCaMP6f) study on rodents (<xref ref-type="bibr" rid="c5">Froudarakis et al., 2014</xref>). The absolute level of estimated sparseness depends on multiple factors. However, the saturation (above 60-80Hz) in GCaMP6 signal can affect the estimate of sparseness (<xref ref-type="bibr" rid="c3">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="c5">Froudarakis et al., 2014</xref>). Thus, the precise measurement of population sparseness of neuronal response, particularly in primates, remains lacking.</p>
<p>In this study, we provided the first measurement of population sparseness of primate V1, by using two-photon calcium imaging on a large population of neurons at single cell resolution. We used calcium indicator GCaMP5 derived from AAVs (<xref ref-type="bibr" rid="c1">Akerboom et al., 2012</xref>), which we have shown earlier to exhibit linear behavior across a much wider range of firing rates (10 Hz to 150 Hz) (<xref ref-type="bibr" rid="c10">Li et al., 2017</xref>). This allows us to measure more accurately the response sparseness of almost an entire population of densely packed neurons in superficial layers 2/3 of V1 in an 850 &#x03BC;m &#x00D7; 850 &#x03BC;m field of view - the scale of about 1-2 hypercolumn.</p>
</sec>
<sec id="s2">
<title>Results and discussion</title>
<p>We employed two-photon imaging with GCaMP5 to measure the neuronal population responses (about 1000 neurons per monkey) in V1 layers 2/3 of two awake macaques to 2,250 natural images. The neurons&#x2019; calcium signals in response to visual stimuli were recorded while the monkey performed a fixation task. During each fixation trial, a blank screen was presented for one second, followed by a visual stimulus for another one second. The ROI of an activated cell was identified when the brightness of a compact region (&#x003E;25 pixels) exceeded 3 stds (standard deviations) in each single differential image. The ratio of fluorescence change (&#x0394;<italic>F/F0</italic>) of these ROIs was calculated for each activated cell. <italic>&#x0394;F &#x003D; F&#x2010; F0</italic>, where <italic>F0</italic> is the baseline activity during the blank screen prior stimulus onset in each trial and <italic>F</italic> is fluorescence activity in the ROI during stimulus presentation in the trial. A neuropil-correction was performed with an index of 0.7 (<xref ref-type="bibr" rid="c3">Chen et al., 2013</xref>).</p>
<p>The receptive fields (RFs) of the neurons were first localized using oriented gratings and bars presented in different positions. The RF centers of imaged neurons were located between 3<sup>o</sup> and 5<sup>o</sup> in eccentricity. In each trial, a stimulus of size 4<sup>o</sup> &#x00D7; 4<sup>o</sup> randomly drawn from a set of 2,250 natural image stimuli (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="figS1">Figure 1-Figure supplements 1c</xref>) was presented. The entire set of stimuli was repeated for three times. These natural images evoked robust visual responses in the imaged neurons (<xref ref-type="fig" rid="fig1">Figure 1a,b</xref>, Figure 1-Figure supplements 1c and 2).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1</label>
<caption><p>Sparse neuronal responses of V1 layer 2/3 neurons to natural scenes. (a and b) Ca images of the neuronal population response to two different natural images as shown in the insets. Typically, only a few neurons, among the nearly 1000 neurons measured (1,225 neurons for Monkey A or 982 neurons for Monkey B), responded strongly to a single patch of natural scenes. (c) The overall neuronal population responses to all 2,250 natural images. Eachcellwascolor-codedaccording tothe response intensity toits optimal stimulus respectively. (d and e) The distributions of neuronal population responses to the two natural images respectively. Abscissa indicates the 1,225 neurons that showed significant response to natural images, in ranked order according to their responses to each image. Ordinate indicates &#x0394;<italic>F/F0</italic>. Cells 653 and 949 are colored red respectively. (f and g) The distribution of the sharpness measures of population response distribution in terms of half-height width across the natural stimuli tested for the two monkeys. Less than 0.5&#x0025; of the cells responded above half of their individual peak response to any given natural image. (h and i) The response of one example cell (cell 653) to the entire set of natural scene stimuli, exhibiting high stimulus specificity. (j and k) Another example cell (cell 949) also shows high stimulus specificity. (l and m) The distributions of stimulus specificity of neurons, in terms of half-height width of the stimulus tuning curves. Each cell would typically respond strongly to less than 0.5&#x0025; of the natural images in our test set.</p></caption>
<graphic xlink:href="252940_fig1.tif"/>
</fig>
<p>We examined the neuronal population responses to the natural image set. We found that out of the 1,225 neurons in monkey A and 982 in monkey B, only a few neurons from each monkey strongly responded to each image patch (<xref ref-type="fig" rid="fig1">Figure 1a,b</xref>), though a large number of imaged neurons could be activated by the whole stimulus set (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). The rank-ordered distributions of the population responses were always sharply peaked (<xref ref-type="fig" rid="fig1">Figure 1d,e</xref>). On average, the half-height bandwidths of population response distributions were 0.49&#x0025; (6.0/1,225) and 0.42&#x0025; (4.1/982) for monkey A and B respectively (<xref ref-type="fig" rid="fig1">Figure 1f,g</xref>). In other words, only about 0.5&#x0025; of the cells responded substantially, each with activity level above half of its observed peak response, indicating a very high degree of sparseness in population responses (<bold><italic>see Methods</italic></bold>).</p>
<p>We also examined each neuron&#x2019;s stimulus specificity, or its life-time sparseness. We found most cells responded substantially only to a small number of images in the whole stimulus set (<xref ref-type="fig" rid="fig1">Figure 1h,j</xref>). Interestingly, the preferred images for individual neuron often shared common features. For example, neuron 653 of monkey A was most excited when its receptive field (0.8<sup>o</sup> in diameter) covered the lower rim of the cat&#x2019;s eye (indicated by the red dashed line in the inset in <xref ref-type="fig" rid="fig1">Figure 1i</xref>). The neuron&#x2019;s preference for the specific curve feature was further confirmed by a subsequent experiment testing the neurons&#x2019; selectivity to many artificial patterns (<xref ref-type="fig" rid="fig1">Figure 1i</xref>; see also <xref ref-type="bibr" rid="c19">Tang et al., 2017</xref>). Similarly, neuron 949 of Monkey A was found to be selective to an opposite curvature embedded in its preferred natural stimulus set (<xref ref-type="fig" rid="fig1">Figure 1k</xref>). These observations are consistent with earlier observations that V1 neurons might be selective to more complex patterns (<xref ref-type="bibr" rid="c7">Hedg&#x00E9; and Van Essen, 2007</xref>; <xref ref-type="bibr" rid="c19">Tang et al., 2017</xref>), which would result in highly sparse population responses. The average half-height stimulus bandwidths in stimulus tuning were 0.49&#x0025; (11/2,250) and 0.41&#x0025; (9.3/2,250) for monkeys A and B (<xref ref-type="fig" rid="fig1">Figure 1l,m</xref>) respectively. This high degree of stimulus specificity or life-time sparseness goes hand in hand with the high degree of measured population sparseness.</p>
<p>To understand how much information was carried in the sparse ensemble of population activities, we evaluated how well the sparse neural responses allow a decoder to discriminate the 2,250 stimuli (<xref ref-type="bibr" rid="c15">Quiroga RQ and Panzeri, 2009</xref>; <xref ref-type="bibr" rid="c5">Froudarakis et al., 2014</xref>). When the entire population activities were included, the decoding accuracies were 54&#x0025; for monkey A and 38&#x0025; for monkey B, whereas the chance accuracy was only 0.04&#x0025; (<xref ref-type="fig" rid="fig2">Figure 2a,b</xref>). In the following, we refer to these decoding accuracies as &#x201C;achievable decoding accuracies&#x201D; for subsequent comparison.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2</label>
<caption><p>Performance on the image decoding task using strong and weak neural responses. Y axes show the cross-validated decoding accuracy on the 2250-way image classification task, and X axes show the percentage of top responses included (red curves) and excluded (blue curves). Dash lines are the referential &#x201C;achievable decoding accuracies&#x201D; using all the neural responses. Gray vertical lines highlight the decoding accuracies including or excluding the top 0.5&#x0025; responses.</p></caption>
<graphic xlink:href="252940_fig2.tif"/>
</fig>
<p>To examine how much information the downstream neurons could derive from the strongest 0.5&#x0025; responses, we set all the responses below the top 0.5&#x0025; to 0 and used only the top 0.5&#x0025; strong responses to perform decoding (top only). Remarkably, a decoding accuracy of 28&#x0025; could be achieved for monkey A and 21&#x0025; for monkey B, which were about 50&#x0025; of achievable decoding accuracies for both monkeys.</p>
<p>We also studied how well the decoding could do when the top 0.5&#x0025; sparse responses were excluded by setting them to 0 (top excluded). We found by excluding the top 0.5&#x0025; top responses, over 50&#x0025; of the achievable accuracy was lost for each monkey. Thus, we showed that these strong and sparse responses convey both the necessary and sufficient information to downstream neurons for decoding the images with high accuracy.</p>
<p>The decoding accuracies under different percentages of the top responses included (red curve) or excluded (blue curve) revealed that most of the achievable decoding accuracy was contributed by the top 5&#x0025; of the strong responses in this 2,250-way decoding task (<xref ref-type="fig" rid="fig2">Fig. 2</xref>).</p>
<p>Thus, our study provided the first direct measurement of sparseness of large-scale neuronal population responses in V1 superficial layer of awake macaque monkeys, using large-scale two-photon imaging. We found that a very small ensemble of neurons in V1 superficial layer would be active concurrently in response to any given natural image. Using decoding analysis, we showed that these small ensembles of neural responses provide necessary and sufficient information for downstream neurons for image discrimination.</p>
<p>Earlier studies inferred population sparseness based on measurement of life-time sparseness. We showed that population sparseness measure was indeed comparable to life-time sparseness measure. However, the level of sparsity we observed (0.5&#x0025; at half height) was considerably higher than earlier life-time sparseness estimates based on single unit recording in macaque (<xref ref-type="bibr" rid="c18">Rust and DiCarlo, 2012</xref>). Studies on rodents yielded a considerable range of estimates on response sparseness which varied with measuring techniques (<xref ref-type="bibr" rid="c6">Haider et al., 2010</xref>; Hrimadka et al., 2008; <xref ref-type="bibr" rid="c5">Froudarakis et al., 2014</xref>). The single-unit study using the cell-attached technique might be the most accurate (<xref ref-type="bibr" rid="c8">Hromadka et al., 2008</xref>), which showed that neurons were mostly silent in the awake auditory cortex, and inferred that less than 5&#x0025; of the neurons would be strongly active (above 20 Hz) at each given instance. This sparse measure is actually consistent with our data (bandwidth at about 25&#x0025; height maximum), which confirmed that most of early study on neuronal sparseness with traditional extracellular recording were debatable from technical angle. From our observation, there were densely packed neurons with small cell bodies in the superficial layers of V1. It will be hard to get well isolated and long-term stable single-unit signals with extracellular recording method. Our study have eliminated the bias in neuron sampling and probed the neurons with large set of natural stimuli, thus provide a direct sparseness measurement of V1 neurons in primates at both a population and single-cell level.</p>
<p>The high level of sparsenes showever is consistent with two recent interesting conjectures in theoretical neuroscience. First, based on metabolic reasons and the cost of spiking, it has been conjectured that fewer than 1&#x0025; of the neurons should be substantially active concurrently in any brain area (<bold><italic>Lennin, 2003</italic></bold>). Second, and more importantly, theoretical sparse coding studies have suggested that because the number of V1 neurons is at least 200 times more abundant than its thalamic input, V1 neurons could be quite specialized in their feature tuning and highly sparse in their population responses (<xref ref-type="bibr" rid="c12">Olshausen, 2013</xref>; <xref ref-type="bibr" rid="c16">Rehn and Sommer, 2007</xref>), as we have observed using two-photon imaging techniques in the V1 superficial layer (<xref ref-type="bibr" rid="c19">Tang et al. 2017</xref>). The observed high degree of sparseness and complexity of V1 superficial-layer neurons have consequential implications on our understanding of efficient coding in the brain.</p>
</sec>
<sec id="s3">
<title>Materials and methods</title>
<p>All experimental protocols were approved by the Peking University Animal Care and Use Committee.</p>
<sec id="s3a">
<title>Subjects</title>
<p>The study used four adult rhesus monkeys (A and B), 4&#x2013;5 years of age and weighing 5&#x2013;7 kg. Two sequential surgeries were performed on each animal under general anesthesia and strictly sterile conditions. In the first surgery, a 16-mm hole was drilled in the skull over V1. The dura was opened to explore the cortex, into which 50-100 nl AAV1.hSynap.GCaMP5G.WPRE.SV40 (AV-1-PV2478, titer 2.37e13 (GC/ml), Penn Vector Core) was pressure-injected at a depth of &#x223C;500 &#x03BC;m. After AAV injection, the dura was sutured, the skull cap was placed back, and the scalp was sutured. Then the animal was returned to its cage for recovery. Antibiotic (Ceftriaxone sodium, Youcare Pharmaceutical Group Co. Ltd., China) was administered for one week. After 45 days, a second surgery was performed, in which three head-posts were implanted on each animal&#x2019;s skull, two on the forehead and one on the back of the head. A T-shaped steel frame was connected to these head-posts for head stabilization during imaging. The skull and dura were later on opened again to explore the cortex. A glass cover-slip (diameter 8 mm and thickness 0.17 mm) was glued to a titanium ring, and then gently pushed down onto the cortical surface. A ring-shape GORE membrane (20 mm in outer diameter) was inserted under the dura. The titanium ring was glued to the dura and skull with dental acrylic to form an imaging chamber. The whole chamber (formed by thick dental acrylic) was covered by a steel shell to prevent breakage of the cover-slip when the animal was returned to the home cage.</p>
</sec>
<sec id="s3b">
<title>Behavioral task</title>
<p>During imaging, each monkey was seated in a primate chair with head restraint and performed a fixation task, which involved fixating on a small white spot (0.1&#x00B0;) within a window of 1&#x00B0; for over 2 seconds to obtain a juice reward. Eye position was monitored with an infrared eye-tracking system (ISCAN, Inc.) at 120 Hz.</p>
</sec>
<sec id="s3c">
<title>Visual stimuli</title>
<p>Visual stimuli were generated using the ViSaGe system (Cambridge Research Systems) and displayed on a 17&#x201D; LCD monitor (Acer V173, 80Hz refresh rate) positioned 45 cm from the animal&#x2019;s eyes. Each stimulus was presented for 1 second after a 1 second blank within a fixation period of 2 seconds. We estimated the RF sizes and positions of the imaged neurons with small drifting gratings and bars presented at different locations. The RFs were estimated to be 0.2&#x00B0; to 0.8&#x00B0; in size with RF locations between 3 to 5 degrees in eccentricity for both monkeys.</p>
<p>Drifting and oriented gratings were tested to examine the visual responses of imaged neurons. Small patches (0.8&#x00B0; in diameter) of gratings with 100&#x0025; contrast square waves were presented to the center of RFs of imaged cells, with 2 spatial frequencies (4.0 and 8.0 cyc/deg) at 2 temporal frequencies (1 and 2 Hz), 6 orientations, and 2 directions (30&#x00B0; apart).</p>
<p>A natural stimulus set (NS) of 2,250 4&#x00B0; &#x00D7; 4&#x00B0; stimulus patches extracted from different natural scene photos was used to examine the neuronal responses to natural stimuli. The order of the stimuli was randomized in each session. These stimuli were tested on monkeys A and B, each with at least three repetitions.</p>
</sec>
<sec id="s3d">
<title>Eye movement control</title>
<p>We analyzed the distribution of eye-positions during stimulus ON periods. The monkeys&#x2019; fixation during stimulus presentation (from 1 to 2 second in the graph) was quite stable and accurate. The distribution of eye positions during stimulus presentation, with standard deviations less than 0.05&#x00B0;, which was significantly smaller than the typical receptive field sizes of neurons at 3-5 degree eccentricities (range from 0.2 to 0.8 degrees). To examine whether the eye movement had significant contribution to the distribution of neuronal population responses, we compared the standard divisions (stds) of eye position in different neuronal population response cases. We considered three classes of population responses: (1) weak response (&#x0394;<italic>F/F0</italic> &#x003C; 0.5), (2) sparse strong response (one or two cells responded), (3) dense response (more than ten cells responded). We found no statistically significant differences in the distribution of eye position data in these three classes (<xref ref-type="bibr" rid="c19">Tang et al., 2017</xref>), which indicated the observed effects are not caused by movement differences. The ROC and decoding analysis (Figure 1-Figure supplement 2), demonstrating the reliability of the neural responses across trials, confirm that the sparse population responses were evoked by stimuli repeatedly, not by random eye-movement jitters.</p>
</sec>
<sec id="s3e">
<title>Two-photon imaging</title>
<p>After a recovery period of 10 days from the second surgery, the animals were trained to maintain eye-fixation. Two-photon imaging was performed using a Prairie Ultima IV (In Vivo) two-photon microscope (Bruker Nano, Inc., FMBU, formerly Prairie Technologies) and a Ti: Sapphire laser (Mai Tai eHP, Spectra Physics). The wavelength of the laser was set at 1000 nm. With a 16&#x00D7; objective (0.8-N.A., Nikon), an area of 850&#x03BC;m &#x00D7; 850&#x03BC;m was imaged. A standard slow galvo scanner was used to obtain static images of cells with high resolution (1024 &#x00D7; 1024). The fast and resonant scan (up to 32 frames per second) was used to obtain images of neuron activity. The images were recorded at 8 frames per second by averaging each 4 frames. The infected cells up to 700 &#x03BC;m in depth could be imaged. We mainly focused at the layer at 160 &#x03BC;m to 180 &#x03BC;m depth which contained a high density of infected cells.</p>
</sec>
<sec id="s3f">
<title>Imaging data analysis</title>
<p>All data analyses were performed using customized Matlab software (The MathWorks, Natick, MA). The images from each session were first realigned to a template image (the average image of 1000 frames) using a normalized cross-correlation-based translation algorithm, to correct the X-Y offset of images caused by the motion between the objective and the cortex.</p>
<p>The cell density was high in superficial V1, and many cell bodies were quite dim at rest. It was difficult to identify these cells directly by eye or by algorithm based on the morphology from their static images. Hence, we identified ROIs for cell bodies based on their responses. The differential images (average frame of the stimulus ON period subtracting that of stimulus OFF period for each stimulus condition) were first filtered using low-pass and high-pass Gaussian filters (5 pixels and 50 pixels, 2 orders respectively). Notably, these two filters were only used for ROI identifications. In all further analyses, we used the raw data without any filtering. Connected subsets of pixels (&#x003E;25 pixels) with average pixel value greater than 3 standard deviations (std) in these differential images were identified as active neurons (ROIs). Note that this 3 std empirical value was used only for deciding the ROIs of activated cells and was not used as a cutoff threshold for measuring neuronal responses. We found that a higher std would allow the detection and selection of the ROIs of cell bodies more accurately but would miss some weakly responding cells, and a lower std threshold may include more cells but would have a greater chance of including some false ROIs that cannot be matched to any cell bodies. The ratio of fluorescence change <italic>(&#x0394;F/FO)</italic> of these ROIs was calculated for each activated cell. <bold><italic>&#x0394;</italic></bold><italic>F &#x003D; F&#x2010; F0,</italic> where <italic>F0</italic> is the baseline activity during the blank screen prior stimulus onset in each trial and <italic>F</italic> is fluorescence activity in the ROI during stimulus presentation in the trial. A neuropil-correction was performed with an index of 0.7 <italic>(<bold><xref ref-type="bibr" rid="c3">Chen et al., 2013</xref></bold>)</italic></p>
</sec>
<sec id="s3g">
<title>Sparseness measure</title>
<p>The sparseness measure is used to quantify the peakedness of response distribution. The sparseness measures based on the cosine distance between the response vector and the all-one vector (<xref ref-type="bibr" rid="c17">Rolls and Tovee, 1995</xref>; <xref ref-type="bibr" rid="c20">Vinje and Gallant, 2000</xref>) are popular for quantifying sparseness of responses based on spiking data. These measures however are very sensitive to slight changes in baseline level. These changes will cause a problem in our estimate of calcium signal-based sparseness which were not sensitive to spiking activities below 10 Hz (<xref ref-type="bibr" rid="c10">Li et al., 2017</xref>). In addition, a number of image filtering and corrections applied will also lead to an uncertain baseline in image data, which cannot even be recovered by de-convolution techniques. Thus the absolute sparseness with the Rolls-Tovee/Vinje-Gallant measure varied considerably from one study to another</p>
<p>An original motivation of sparseness measure is to characterize the peakedness of the distribution of neuronal population responses or the stimulus tuning curve (<bold><italic>Willmore et al., 2011</italic></bold>). In accord with this intuition, the half-height bandwidth of a tuning curve is also a simple and intuitive measure for the sparseness of neuronal responses and has been used in other studies (<xref ref-type="bibr" rid="c18">Rust and DiCarlo, 2012</xref>). This measure is not sensitive to low level activities or baseline fluctuations in imaging.</p>
</sec>
<sec id="s3h">
<title>Stability and reliability of the neuronal measurements</title>
<p>For each single neuron, we examined whether the sparse strong responses (&#x0394;<italic>F/F0</italic> &#x003E; 50&#x0025; max) observed across the 2,250 stimuli were reliable across trials by performing the following ROC analysis (<xref ref-type="bibr" rid="c14">Quiroga et al., 2005</xref>): we set all the stimuli that produced mean responses greater than 50&#x0025; of the observed maximum mean peak of the cell to be in the ON class, and all other stimuli to be in the OFF class. We computed the ROC for classifying the ON class against the OFF class based on the response of each single trial. If the responses above the half-maximum are stable across all trials, then the AUC (the area under the ROC curve) would be close to 1.0 as the ON and OFF classes are readily discriminable. The null hypothesis is that sparse strong responses are spurious single trial epileptic responses, thus not repeatable across trials. To test this hypothesis, we shuffled all the responses against the stimulus labels, and recomputed the mean responses for all the stimuli across the trials. We performed 1000 shuffles. We found that most of the shuffled cases have much lower average peak responses because of the mismatch of the rigorous sparse responses across trials, suggesting the reliability of the sparse responses in the original data. To make an even stricter and more fair comparison with the original data on ROC terms, for each shuffle, we recomputed the maximum responses, and used the half of this mean maximum as threshold to sort the stimuli into ON and OFF classes and repeated the ROC analysis to obtain the AUC for this shuffle. The probability of the null hypothesis is the percentage of the time that the AUCs of the 1000 shuffles reach the AUC of the original data. With this ROC analysis, we found &#x003E; 96&#x0025; neurons with the probability of the null hypothesis p&#x003C;0.01 (Figure 1-Figure supplements 2).</p>
</sec>
<sec id="s3i">
<title>Decoding Analysis</title>
<p>We used a nearest centroid classifier to discriminate the 2,250 images based on the population responses in each trial. Since each image was tested 3 times, the nearest centroid classifier was trained based on two trials for all images and tested on the hold-out trials. We repeated the procedure for each trial, performing 3-fold cross-validations.</p>
<p>For each monkey, we constructed neural response matrices (with dimension 2250 &#x00D7; 1225 for monkey A, and 2250 &#x00D7; 982 for monkey B) for three trials X<sup>(1)</sup>, X<sup>(2)</sup>, and X<sup>(3)</sup>, that store the neural responses to all images in each trial as rows in that matrix. We trained and tested nearest-centroid classifiers via a three-fold cross-validation procedure across trials in a 2250-way image decoding task. Specifically, for trial t, during training, we computed the centroids of the other two trials C<sup>(t)</sup> (if t=1, C<sup>(1)</sup>&#x003D; (X<sup>(2)</sup> &#x002B; X<sup>(3)</sup>)/2, if t=2, C<sup>(2)</sup>&#x003D; (X<sup>(1)</sup> &#x002B; X<sup>(3)</sup>)/2, etc.) and stored C<sup>(t)</sup> in the classifier; during testing, given some row k of X<sup>(t)</sup>, which is the population neural response vector to image k in trial t, the (trained) classifier computed the Euclidean distances between row k of X<sup>(t)</sup> and every row of C<sup>(t)</sup>. The model outputted the index (1,2,&#x2026;,2249,2250) of the row in C<sup>(t)</sup> that gives the smallest distance. The correct output is k and all other outputs are incorrect. The average decoding accuracy for this trial is defined as the percentage of correct outputs over all rows of X<sup>(t)</sup>. We repeated the above procedure for each trial and reported the average of three (average) decoding accuracies.</p>
<p>In our experiments, we first set the X<sup>(t)</sup>&#x2019;s defined above to be the original recorded neural responses and computed the decoding accuracies for both monkeys. We refer to the accuracies obtained from original neural data as &#x201C;achievable decoding accuracies&#x201D;. Later, to evaluate the amount of information in the strong sparse portions of the neural data, we set X<sup>(t)</sup>&#x2019;s to be thresholded versions of the original data. We tried two classes of thresholding methods: &#x201C;top only&#x201D; (red in <xref ref-type="fig" rid="fig2">Figure 2</xref>) and &#x201C;top excluded&#x201D; (blue in <xref ref-type="fig" rid="fig2">Figure 2</xref>). In &#x201C;top only&#x201D;, we only kept the largest p&#x0025; of the responses across images and trials in the thresholded version and made the smaller (100 - p)&#x0025; of the responses to be zero. In &#x201C;top excluded&#x201D;, which is complementary to &#x201C;top only&#x201D;, we set the largest p&#x0025; of the responses to be zero and kept the smaller (100-p)&#x0025; of the responses. For both &#x201C;top only&#x201D; and &#x201C;top excluded&#x201D;, we evaluated decoding accuracies at the following percentages (p&#x2019;s) (crosses in <xref ref-type="fig" rid="fig2">Figure 2</xref>): 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, and 99.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>ACKNOWLEDGMENTS</title>
<p>We are grateful to many colleagues for their insightful discussion and generous help on this paper. We thank Wenbiao Gan for the early provision of AAV-GCaMP5; and Peking University Laboratory Animal Center for excellent animal care. We acknowledge the Janelia Farm program for providing the GCaMP5-G construct, specifically Loren L. Looger, Jasper Akerboom, Douglas S. Kim, and the Genetically Encoded Calcium Indicator (GECI) project at Janelia Farm Research Campus Howard Hughes Medical Institute. This work was supported by the National Natural Science Foundation of China No. 31730109, the National Science Foundation of China Outstanding Young Researcher Award 30525016, a project 985 grant of Peking University, grants from the National Basic Research Program of China (2017YFA0105201), Beijing Municipal Commission of Science and Technology under contract No. Z151100000915070, NIH 1R01EY022247 and NSF CISE 1320651 and IARPA D16PC00007 of the U.S.A.</p>
</ack>
<sec>
<title>AUTHOR CONTRIBUTIONS</title> <p>S.T. conceived the project and designed the experiments. S.T. performed experiments with assistance from M.L., F.L., and H.J. on preparations. S.T. and T.L. analyzed the data and wrote the paper. Y.Z and Z. L. performed the decoding analysis.</p>
</sec>
<sec>
<title>COMPETING FINANCIAL INTERESTS</title>
<p>The authors declare no competing financial interests.</p>
</sec>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Akerboom</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>TW</given-names></string-name>, <string-name><surname>Wardill</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Tian</surname> <given-names>L</given-names></string-name>, <string-name><surname>Marvin</surname> <given-names>JS</given-names></string-name>, and <string-name><surname>Mutlu</surname> <given-names>S.</given-names></string-name> <year>2012</year>. <article-title>Optimization of a GCaMP calcium indicator for neural activity imaging</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>(<issue>40</issue>): <fpage>13819</fpage>&#x2013;<lpage>13840</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Barlow</surname> <given-names>HB</given-names></string-name>. <year>1981</year>. <article-title>&#x201C;Theferrier lecture, 1980. Critical limiting factors in the design of the eye and visual cortex,&#x201D;</article-title> <source>Proceedings of the Royal Society of London Series</source> <volume>B212</volume>: <fpage>1</fpage>&#x2013;<lpage>34</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>TW</given-names></string-name>, <string-name><surname>Wardill</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Sun</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Pulver</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Renninger</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Baohan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Schreiter</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Kerr</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Orger</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Jayaraman</surname> <given-names>V</given-names></string-name> <etal>et al.</etal> <year>2013</year>. <article-title>Ultra sensitive fluorescent proteins for imaging neuronal activity</article-title>. <source>Nature</source> <volume>499</volume>: <fpage>295</fpage>&#x2013;<lpage>300</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Denk</surname> <given-names>W</given-names></string-name>, <string-name><surname>Strickler</surname> <given-names>JH</given-names></string-name> and <string-name><surname>Webb</surname> <given-names>WWW</given-names></string-name>. <year>1990</year>. <article-title>Two-photon laser scanning fluorescence microscopy</article-title>. <source>Science</source> <volume>248</volume>: <fpage>73</fpage>&#x2013;<lpage>76</lpage> (1990).</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Froudarakis</surname> <given-names>E</given-names></string-name>, <string-name><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Cotton</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Sinz</surname> <given-names>FH</given-names></string-name>, <string-name><surname>Yatsenko</surname> <given-names>D</given-names></string-name>, <string-name><surname>Saggau</surname> <given-names>P</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M</given-names></string-name> and <string-name><surname>Tolias</surname> <given-names>AS</given-names></string-name>. <year>2014</year>. <article-title>Population code in mouse V1 facilitates read-out of natural scenes through increased sparseness</article-title>. <source>Nature Neuroscience.</source> <volume>17</volume>(<issue>6</issue>): <fpage>851</fpage>&#x2013;<lpage>857</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Haider</surname> <given-names>B</given-names></string-name>, <string-name><surname>Krause</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Duque</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Touryan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Mazer</surname> <given-names>JA</given-names></string-name>, and <string-name><surname>McCormick</surname> <given-names>DA</given-names></string-name>. <year>2010</year>. <article-title>Synaptic and network mechanisms of sparse and reliable visual cortical activity during nonclassical receptive field stimulation</article-title>. <source>Neuron.</source> <volume>65</volume>: <fpage>107</fpage>&#x2013;<lpage>121</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Hedg&#x00E9;</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>VanEssen</surname>, <given-names>D.C.</given-names></string-name> <year>2007</year>. <article-title>A comparative study of shape representation in macaque visual areas V2 and V4</article-title>. <source>Cereb.Cor.</source> <volume>17</volume>: <fpage>1100</fpage>&#x2013;<lpage>1116</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Hromadka</surname> <given-names>T</given-names></string-name>, <string-name><surname>DeWeese</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Zador</surname> <given-names>AM</given-names></string-name>. <year>2008</year>. <article-title>Sparse representation of sounds in the unanesthetized auditory cortex</article-title>. <source>PLoS Biology</source>. <volume>6</volume>(<issue>1</issue>): <fpage>0124</fpage>&#x2013;<lpage>0137</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Lennie</surname> <given-names>P.</given-names></string-name> <year>2003</year>. <article-title>The cost of cortical computation</article-title>. <source>Current Biology</source> <volume>13</volume>: <fpage>493</fpage>&#x2013;<lpage>497</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>M</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>F</given-names></string-name>, <string-name><surname>Jiang</surname> <given-names>H</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>TS</given-names></string-name>, &#x0026; <string-name><surname>Tang</surname> <given-names>S.</given-names></string-name> <year>2017</year>. <article-title>Long-term two-photon imaging in awake macaque monkey</article-title>. <source>Neuron</source>, <volume>93</volume>: <fpage>1049</fpage>&#x2013;<lpage>1057</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Olshausen</surname> <given-names>BA</given-names></string-name> and <string-name><surname>Field</surname> <given-names>DJJ</given-names></string-name>. <year>1996</year>. <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>(<issue>6583</issue>): <fpage>607</fpage>&#x2013;<lpage>609</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Olshausen</surname> <given-names>BA</given-names></string-name>. <year>2013</year>. <article-title>Highly overcomplete sparse coding</article-title>. <source>Proceed of SPIE</source> <volume>8651</volume>: <fpage>86510S</fpage>&#x2013;<lpage>4</lpage></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Olshausen</surname> <given-names>BA</given-names></string-name> and <string-name><surname>Field</surname> <given-names>DJ</given-names></string-name>. <year>2005</year>. <article-title>How close we are to understanding V1</article-title>? <source>Neural Computation</source> <volume>17</volume>(<issue>8</issue>), <fpage>1665</fpage>&#x2013;<lpage>1699</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Quiroga</surname> <given-names>RQ</given-names></string-name>, <string-name><surname>Reddy</surname> <given-names>L</given-names></string-name>, <string-name><surname>Kreiman</surname> <given-names>G</given-names></string-name>, <string-name><surname>Koch</surname> <given-names>C</given-names></string-name> &#x0026; <string-name><surname>Fried</surname> <given-names>I.</given-names></string-name> <year>2005</year>. <article-title>Invariant visual representation by single neurons in the human brain</article-title>. <source>Nature</source> <volume>435</volume>(<issue>7045</issue>): <fpage>1102</fpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Quiroga</surname> <given-names>RQ</given-names></string-name>, <string-name><surname>Panzeri</surname> <given-names>S.</given-names></string-name> <year>2009</year>. <article-title>Extracting information from neuronal populations: information theory and decoding approaches</article-title>. <source>Nature Reviews Neuroscience</source> <volume>10</volume>(<issue>3</issue>):<fpage>173</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Rehn</surname> <given-names>M</given-names></string-name> and <string-name><surname>Sommer</surname> <given-names>ET</given-names></string-name>. <year>2007</year>. <article-title>A network that uses few active neurons to code visual input predicts the diverse shapes of cortical receptive fields</article-title>. <source>J. Comp Neuroscience</source> <volume>22</volume>(<issue>2</issue>): <fpage>135</fpage>&#x2013;<lpage>146</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Rolls</surname> <given-names>ET</given-names></string-name> and <string-name><surname>Tovee</surname> <given-names>MJ</given-names></string-name>. <year>1995</year>. <article-title>Sparseness of the neuronal representation of stimuli in the primate temporal visual cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>73.2</volume>: <fpage>713</fpage>&#x2013;<lpage>726</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Rust</surname> <given-names>NC</given-names></string-name> and <string-name><surname>DiCarlo</surname> <given-names>JJJ</given-names></string-name>. <year>2012</year>. <article-title>Balanced increases in selectivity and tolerance produce constant sparseness along the ventral visual stream</article-title>. <source>The Journal of Neuroscience</source> <volume>32</volume> (<issue>30</issue>): <fpage>10170</fpage> &#x2013;<lpage>10182</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Tang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Li</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Xu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>F</given-names></string-name>, <string-name><surname>Teo</surname> <given-names>B</given-names></string-name> and <string-name><surname>Jiang</surname> <given-names>H.</given-names></string-name> <year>2017</year>. <article-title>Large-scale two-photon imaging revealed complex pattern selectivity of V1 superficial layer neurons in macaque</article-title>. <source>Current Biology</source>. DOI: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2017.11.039">http://dx.doi.org/10.1016/j.cub.2017.11.039</ext-link></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Vinje</surname> <given-names>WE</given-names></string-name> and <string-name><surname>Gallant</surname> <given-names>JL</given-names></string-name>. <year>2000</year>. <article-title>Sparse Coding and Decorrelation in Primary Visual Cortex During Natural Vision</article-title>. <source>Science</source> <volume>287</volume>: <fpage>1273</fpage>&#x2013;<lpage>1276</lpage>.</mixed-citation></ref>
</ref-list>
<sec sec-type="supplementary-materials">
<fig id="figS1" position="float" fig-type="figure">
<label>Figure 1 - Figure supplement 1.</label>
<caption><p>Two-photon calcium imaging in awake macaque monitoring the neuronal activity in V1 layer 2/3 evoked by natural stimuli. (a and b) Two-photon images of neurons expressing GCaMP5 at zoom 1X, 2X respectively. (c) Natural stimuli evoked robust neural activity probed by calcium indicator GCaMP5.</p></caption>
<graphic xlink:href="252940_figS1.tif"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure 1 - Figure supplement 2.</label>
<caption><p>Reliability analysis of neuronal responses. (a) The tuning curve of neuron &#x00E6;653&#x2019;s responses (averaged across trials) to the 2250 stimuli. (b) The tuning curve computed from one random shuffle across all trials. (c) The ROC of original trials (red curve) against those of 99 shuffled trials (gray). The AUC of the original data is 0.999. The AUC of the example in (b), colored in blue, is 0.68. (d) The distribution of the AUC&#x2019;s of all 1000 shuffled cases. The probability, that the shuffled AUC can reach the raw data&#x2019;s AUC, is less than 0.001 (p &#x003C; 0.001) for neuron &#x00E6;653.</p></caption>
<graphic xlink:href="252940_figS2.tif"/>
</fig>
</sec>
</back>
</article>
