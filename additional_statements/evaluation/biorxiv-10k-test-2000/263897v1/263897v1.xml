<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/263897</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Confirmatory Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Validation and Topic-driven Ranking for Biomedical Hypothesis Generation Systems</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5073-0122</contrib-id>
<name>
<surname>Sybrandt</surname>
<given-names>Justin</given-names>
</name>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6284-7408</contrib-id>
<name>
<surname>Safro</surname>
<given-names>Ilya</given-names>
</name>
</contrib>
</contrib-group>
<author-notes>
<fn><p><email>jsybran@clemson.edu</email>, <email>isafro@clemson.edu</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>263897</elocation-id>
<history>
<date date-type="received">
<day>11</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>11</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>2</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="263897.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Literature underpins research, providing the foundation for new ideas. But as the pace of science accelerates, many researchers struggle to stay current. To expedite their searches, some scientists leverage hypothesis generation (HG) systems, which can automatically inspect published papers to uncover novel implicit connections. With no foreseeable end to the driving pace of research, we expect these systems will become crucial for productive scientists, and later form the basis of intelligent automated discovery systems. Yet, many resort to expert analysis to validate such systems. This process is slow, hard to reproduce, and takes time away from other researchers. Therefore, we present a novel method to validate HG systems, which both scales to large validation sets and does not require expert input. We also introduce a number of new metrics to automatically identify plausible generated hypotheses. Through the study of published, highly cited, and noise predicates, we devise a validation challenge, which allows us to evaluate the performance of a HG system. Using an in-progress system, MOLIERE, as a case-study, we show the utility of our validation and ranking methods. So that others may reproduce our results, we provide our code, validation data, and results at <ext-link ext-link-type="uri" xlink:href="http://bit.ly/2EtVshN">bit.ly/2EtVshN</ext-link>.</p>
</abstract>
<counts>
<page-count count="15"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Literature underpins research and provides the groundwork upon which scientists construct new ideas. But while the foundation of published knowledge grows [<xref ref-type="bibr" rid="c24">24</xref>], so does the difficulty in surveying it. Currently the National Library of Medicine adds about 2,300 papers a day to MEDLINE [<xref ref-type="bibr" rid="c30">30</xref>], and this is likely to increase given that scientific output doubles every nine years [<xref ref-type="bibr" rid="c50">50</xref>]. Working in the modern deluge of information, researchers can miss valuable connections.</p>
<p><italic>Undiscovered public knowledge</italic> is the information no one explicitly knows, but has already been implicitly published [<xref ref-type="bibr" rid="c46">46</xref>]. For instance, in 1986 no one knew that fish oil was a treatment for Raynaud&#x2019;s Syndrome [<xref ref-type="bibr" rid="c45">45</xref>]. Instead, we knew separately that fish oil decreases a number of factors, and that those same factors worsen Raynaud&#x2019;s Syndrome. Arrowsmith, the software which uncovered this finding, was the first <italic>hypothesis generation system</italic> (HG) [<xref ref-type="bibr" rid="c39">39</xref>].</p>
<p>The importance of these systems rises alongside the pace of scientific output; an abundance of literature implies an abundance of implicit connections. Yet, while many projects focus on new ways to find potential discoveries [<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c42">42</xref>], few have a way to rigorously verify the quality of the connections posed by their system [<xref ref-type="bibr" rid="c7">7</xref>].</p>
<p>HG systems are hard to verify because they attempt to uncover novel information, a challenging task even for human researchers. To understand whether a potential connection is novel, these systems must model novelty itself. While there are verifiable models for novelty in specific contexts, each is trained to detect patterns similar to those present in a training set, which is conducive to traditional cross-validation [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c23">23</xref>]. Some examples include using non-negative matrix factorization [<xref ref-type="bibr" rid="c25">25</xref>] to uncover protein-protein interactions [<xref ref-type="bibr" rid="c12">12</xref>], or to discover mutational cancer signatures [<xref ref-type="bibr" rid="c3">3</xref>]. In other domains, groups are using Bayesian surprise [<xref ref-type="bibr" rid="c20">20</xref>] to identify interesting topological features [<xref ref-type="bibr" rid="c33">33</xref>] or unexpected measurements for the purpose of uncertainty quantification [<xref ref-type="bibr" rid="c4">4</xref>]. In contrast to all of the above, HG systems strive to detect patterns <italic>absent</italic> from training data (but not necessarily outliers), and in doing so inspire new inquiry.</p>
<p>Without a viable alternative, the HG community primarily turns to expert analysis in order to validate the output of these systems [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c2">2</xref>]. Many methods also require an expert&#x2019;s input to rank their potential connections [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c46">46</xref>]. But, getting expert input is time consuming, introduces bias, and cannot scale.</p>
<p><bold>Our contribution:</bold> We propose a novel method to thoroughly validate HG systems without expert input. Any system that provides a ranking criteria along with its generated hypotheses can leverage this validation method. In addition, we present a number of new ranking strategies that apply to any HG system that produces topic models. We implement each ranking strategy within our in-progress system, MOLIERE [<xref ref-type="bibr" rid="c49">49</xref>], in order to compare their performance with respect to our validation method. Although our work focuses on biomedical research, the methods we discuss easily generalize to HG in any domain.</p>
<p>Our methodology leverages predicates, or subject-verb-object statements, found within the MEDLINE dataset of over 27 million scientific abstracts. For simplicity and reproducibility we use the Semantic Medical Database (SemMedDB) [<xref ref-type="bibr" rid="c22">22</xref>], which defines predicates using identifiers provided by the Universal Medical Language System (UMLS) [<xref ref-type="bibr" rid="c1">1</xref>]. We identify the first publication date of each unique predicate in order to find new connections published each year. Because these connections all come from titles and abstracts of MEDLINE papers, we note that before a predicate&#x2019;s first publication, our system is unaware of any direct connection between its subject and object. Yet, a newly introduced predicate in a title or abstract represents a fruitful connection [<xref ref-type="bibr" rid="c8">8</xref>], the sort we would like a HG system to predict.</p>
<p>To begin our mass validation effort, that to the best of our knowledge has not been performed by other general-purpose HG systems, we select a &#x201C;cut date,&#x201D; which determines the set of publications provided to our system. We define the set of predicates that first occur after the cut date as the &#x201C;published&#x201D; set, and we subset it to identify predicates that first occurred in &#x201C;highly-cited&#x201D; papers. Next we generate a set of &#x201C;noise&#x201D; predicates that are randomly constructed and have never been published. We then run queries for predicates in all three sets using our HG system, which allows us to understand our ability to recover important connections. From there we rank our results and plot Receiver Operating Characteristic (ROC) curves [<xref ref-type="bibr" rid="c14">14</xref>] in order to estimate the overall performance of our system.</p>
<p>We find that by training a polynomial combination of multiple ranking metrics, MOLIERE is able to distinguish published and noise predicates with an ROC area of 0.834, and is able to distinguish highly cited predicates from noise with an ROC area of 0.874. This result is especially significant given that the main validation methods available, to both our system and other similar systems (see survey in [<xref ref-type="bibr" rid="c49">49</xref>]), were expert analysis and replicating the results of others [<xref ref-type="bibr" rid="c7">7</xref>].</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Background</title>
<p>HG systems attempt to extract novel ideas from existing research. In this section, we begin by providing an overview on these systems and continue to explain how we leverage two complimentary techniques for understanding large text corpora: Topic Modeling [<xref ref-type="bibr" rid="c6">6</xref>] and Word Embedding [<xref ref-type="bibr" rid="c29">29</xref>]. The former identifies fuzzy clusters of terms, which allow us to glimpse the main domains of discourse across a document set. The latter embeds terms into a real-valued vector space, which allows us to convey semantic relationships using various distance metrics.</p>
<sec id="s2a">
<label>2.1</label>
<title>Extracting Information from Hypothesis Generation Systems</title>
<p>Swanson and Smalheiser created the first HG system Arrowsmith [<xref ref-type="bibr" rid="c39">39</xref>], and in doing so outlined the ABC model for discovery [<xref ref-type="bibr" rid="c48">48</xref>]. Although this approach has limitations [<xref ref-type="bibr" rid="c36">36</xref>], its conventions and intuitions remain in modern approaches [<xref ref-type="bibr" rid="c42">42</xref>].</p>
<p>In the ABC model, users run queries by specifying two keywords <italic>a</italic> and <italic>c</italic>. The goal of a HG system is to discover some entity <italic>b</italic> such that there are known relationships &#x201C;<italic>a</italic> &#x2192; <italic>b</italic>&#x201D; and &#x201C;<italic>b</italic> &#x2192; <italic>c</italic>,&#x201D; which allow us to imply the relationship between <italic>a</italic> and <italic>c</italic>. Because many connections may require more than one element <italic>b</italic> to describe, researchers apply other techniques, such as topic models in our case, to describe these connections.</p>
<p>We center this work around our in-progress system, MOLIERE [<xref ref-type="bibr" rid="c49">49</xref>]. Once a user queries <italic>a</italic> and <italic>c</italic>, our system identifies a relevant region within our multi-layered knowledge network, which consists of papers, terms, phrases, and various types of links. We extract abstracts from this region and create a sub-corpus upon which we generate a topic model. This topic model describes groups of related terms, which we treat as a hypothesis. Until now, like other systems, we left the analysis of MOLIERE&#x2019;s output to experts, but through the methods described in <xref ref-type="sec" rid="s4">Section 4</xref> we perform this analysis automatically.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Word and Phrase Embedding</title>
<p>The method of finding dense vector representations of words is often referred to as &#x201C;<monospace>word2vec</monospace>&#x201D;. In reality, this umbrella term references two different algorithms, the Continuous BOW (CBOW) method and the Skip-Gram method [<xref ref-type="bibr" rid="c29">29</xref>] Both rely on shallow neural networks in order to learn vectors through word-usage patterns.</p>
<p>MOLIERE uses <monospace>FastText</monospace> [<xref ref-type="bibr" rid="c21">21</xref>], a similar tool under the <monospace>word2vec</monospace> umbrella, to find high quality embeddings of medical entities. By preprocessing our text with the automatic phrase mining technique <monospace>ToPMine</monospace> [<xref ref-type="bibr" rid="c9">9</xref>], we improve these embeddings while finding multi-word medical terms such as &#x201C;lung cancer&#x201D; or &#x201C;benign tumor.&#x201D; We see in <xref ref-type="fig" rid="fig1">Figure 1</xref> that <monospace>FastText</monospace> clusters similar biological terms, an observation we leverage to validate our HG system and derive a number of metrics.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>The above diagram shows a 2-D representation of the embeddings for over 8 thousand UMLS keywords within MOLIERE. We used singular value decomposition to reduce the dimensionality of these vectors from 500 to 2.</p></caption>
<graphic xlink:href="263897_fig1.tif"/>
</fig>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Topic Models</title>
<p>Latent Dirichlet Allocation (LDA) [<xref ref-type="bibr" rid="c6">6</xref>], the classical topic modeling method, groups keywords based on their document co-occurrence rates in order to describe the key &#x201C;topics&#x201D; of discourse. A topic is simply a probability distribution over a vocabulary, and each document from the input corpus is assumed to be a &#x201C;mixture&#x201D; of these topics. For instance, a topic model derived from New York Times articles would likely find one topic containing words such as &#x201C;computer,&#x201D; &#x201C;website,&#x201D; and &#x201C;Internet,&#x201D; while another topic may contains words such as &#x201C;money,&#x201D; &#x201C;market,&#x201D; and &#x201C;stock.&#x201D;</p>
<p>In the medical domain, we use topic models to understand trends across scientific literature. We look for groupings of entities such as genes, drugs, and diseases, which we then analyze to find novel connections. MOLIERE uses a parallel technique, PLDA&#x002B; [<xref ref-type="bibr" rid="c28">28</xref>] to quickly find topics from documents related to <italic>a</italic> and <italic>c</italic>. Because we pre-process MEDLINE articles with ToPMine, our resulting topic models include both words and phrases, which results in more meaningful topics.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Combing LDA and Word2Vec</title>
<p>There exists a symmetry between topic models and word embeddings [<xref ref-type="bibr" rid="c15">15</xref>]. The hidden layer of either CBOW or Skip-Gram captures semantic categories present in an input corpus. Each word in the vocabulary, when projected into the hidden layer, is represented as a mixture of hidden features &#x2014; the same way we can view a word&#x2019;s probability across a topic model.</p>
<p>A topic model is a weighted point cloud, where the embedding of each word is weighted by its probably within a given topic. Therefore, we can also represent the topic as a weighted centroid. In the following section we leverage both representations in order to mathematically describe the similarity between <italic>a</italic>, <italic>c</italic>, and each topic.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Validation Challenge</title>
<p>In order to unyoke automatic HG from expert analysis, we propose a challenge that any system can attempt, provided it can rank its proposed connections. A successful system ought to rank published connections higher than those we randomly created. So, we train a system given historical information, and create the &#x201C;published,&#x201D; &#x201C;highly-cited,&#x201D; and &#x201C;noise&#x201D; query sets. We pose these connections to an HG system, and rank its outputs to plot ROC curves, which determine whether published predicates are preferred to noise. Through the area under these ROC curves, a HG system demonstrates its quality at a large scale without expert analysis.</p>
<p>Our challenge starts with the Semantic Medical Database (SemMedDB) [<xref ref-type="bibr" rid="c22">22</xref>] that contains predicates extracted from MEDLINE defined on the set of UMLS terms [<xref ref-type="bibr" rid="c30">30</xref>]. For instance, predicate &#x201C;C1619966 TREATS C0041296&#x201D; represents a discovered fact &#x201C;abatacept treats tuberculosis&#x201D;. Because our system does not account for word order or verb, we look for distinct unordered word-pairs <italic>a&#x2013;c</italic> instead. Using the metadata associated with each predicate, we note the date each unordered pair was first published. In <xref ref-type="sec" rid="s7">Section 7</xref> we discuss how we may improve our system to include this unused information.</p>
<p>From there, we select a &#x201C;cut year.&#x201D; For this challenge, we create our knowledge network [<xref ref-type="bibr" rid="c49">49</xref>] using only information published before the cut year. We then identify the set of SemMedDB unordered pairs <italic>a&#x2013;c</italic> first published after the cut year provided <italic>a</italic> and <italic>c</italic> both occur in that year&#x2019;s UMLS release. This &#x201C;published set&#x201D; of pairs represent new connections between existing entities, from the perspective of our HG system. We select 2010 as the cut year for our study in order to create a published set of over 1 million pairs.</p>
<p>Also, we create a set of &#x201C;highly-cited&#x201D; pairs by filtering the published set by citation count. We use data from SemMedDB, MEDLINE, and Semantic Scholar to create a set of 1,448 pairs from the published set that first occurred in a paper cited over 100 times. We intuit that this set is closer to the number of landmark discoveries since the cut-date, given that the published set is large and likely contains incidental or incorrect connections.</p>
<p>To provide negative examples, we generate a &#x201C;noise set&#x201D; of pairs by sampling the cut-year&#x2019;s UMLS release, storing the pair only if it does not occur in SemMedDB. These pairs represent nonsensical connections between UMLS elements. Although it is possible that we may stumble across novel findings within the noise set, we assume this will occur infrequently enough to not effect our results.</p>
<p>We run <italic>a&#x2013;c</italic> queries from each set through MOLIERE and create two ranked lists: published vs. noise (PvN) and highly-cited vs. noise (HCvN). After ranking each set, we generate ROC curves [<xref ref-type="bibr" rid="c14">14</xref>], which allow us to judge the quality of our HG system. If more published predicates occur earlier in the ranking than noise, the ROC area will be close to 1, otherwise it will be closer to 0.5.</p>
</sec>
<sec id="s4">
<label>4</label>
<title>Ranking Methods for Topic Model Driven Hypotheses</title>
<p>In order to rise to the challenge stated above, we advanced MOLIERE [<xref ref-type="bibr" rid="c49">49</xref>] to produce a numeric ranking that accompanies its resulting hypotheses. As described above, we use this ranking to calculate ROC curves and evaluate our system&#x2019;s performance.</p>
<p>Another extremely important use case of ranking is related to massive query runs in hypothesis generation systems. Typically, biomedical researchers are interested in investigating connections of one-to-many types. For example, one disease can be queried versus all genes in order to establish what genes are related to it or one specific drug ingredient is verified versus all side effects. In practice, a researcher may be interested to run <italic>a &#x2013; c<sub>i</sub></italic> queries for tens of thousands <italic>c<sub>i</sub></italic>&#x2019;s. In such cases, ranking the hypotheses becomes vitally important.</p>
<p>In the following sections we present a number of promising approaches for ranking the topic model results from MOLIERE queries. The key intuition underpinning these metrics is depicted in <xref ref-type="fig" rid="fig2">Figure 2</xref>. That is, related objects are grouped together in vector space, so if <italic>a</italic> and <italic>c</italic> are related by a third entity <italic>b</italic>, we hypothesize <italic>b</italic>&#x2019;s vector <italic>&#x03F5;</italic>(<italic>b</italic>) ought to be similar to both <italic>&#x03F5;</italic>(<italic>a</italic>) and <italic>&#x03F5;</italic>(<italic>c</italic>). Because MOLIERE returns a topic model, rather than some single <italic>b</italic>, we quantify the potential relationship between <italic>a</italic> and <italic>c</italic> through their relationship to the topic model using the following metrics.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>The above depicts two queries, <italic>a&#x2013;c</italic><sub>1</sub> and <italic>a&#x2013;c</italic><sub>2</sub>, where <italic>a&#x2013;c</italic><sub>1</sub> is a published connection and <italic>a&#x2013;c</italic><sub>2</sub> is a noise connection. We see topics for each query represented as diamonds via Centr(<italic>T<sub>i</sub></italic>). Although both queries lead to topics which are similar to <italic>a</italic>, <italic>c</italic><sub>1</sub>, or <italic>c</italic><sub>2</sub>, we find that the the presence of some topic which is similar to <italic>both</italic> objects of interest may indicate the published connection.</p></caption>
<graphic xlink:href="263897_fig2.tif"/>
</fig>
<sec id="s4a">
<label>4.1</label>
<title>Similarity Between Query Words</title>
<p>As a baseline, we first consider two similarity metrics that do not include topic information: cosine similarity (CS<sc>IM</sc>) and Euclidean distance (<italic>L</italic><sub>2</sub>), namely,
<disp-formula id="ueqn1"><alternatives><graphic xlink:href="263897_ueqn1.gif"/></alternatives></disp-formula>
where <italic>a</italic> and <italic>c</italic> are the two objects of interest, and <italic>&#x03F5;</italic>(<italic>x</italic>) is an embedding function (see <xref ref-type="sec" rid="s2b">Section 2.2</xref>). Note, when calculating ROC curves for the <italic>L</italic><sub>2</sub> metric, we will sort in reverse, meaning smaller distances ought to indicate published predicates.</p>
<p>These metrics indicate whether <italic>a</italic> and <italic>c</italic> share the same cluster with respect to the embedding space. Our observation is that this can be a good indication that <italic>a</italic> and <italic>c</italic> are of the same kind, or are conceptually related. This cluster intuition is shared by others studying similar embedding spaces [<xref ref-type="bibr" rid="c52">52</xref>].</p>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Topic Model Correlation</title>
<p>The next metric attempts to uncover whether a and c are mutually similar to the generated topic model. This metric starts by creating vectors <italic>v</italic>(<italic>a,T</italic>) and <italic>v</italic>(<italic>c,T</italic>) which express each object&#x2019;s similarity to topic model <inline-formula><alternatives><inline-graphic xlink:href="263897_inline1.gif"/></alternatives></inline-formula> derived from an <italic>a &#x2013; c</italic> query. We do so by calculating the weighted cosine similarity T<sc>OPIC</sc>S<sc>IM</sc>(<italic>x</italic>, <italic>T</italic><sub><italic>i</italic></sub>) between each topic <italic>T<sub>i</sub></italic> and each object <italic>x</italic> &#x2208; {<italic>a, c</italic>}, namely,
<disp-formula id="ueqn2"><alternatives><graphic xlink:href="263897_ueqn2.gif"/></alternatives></disp-formula>
where a probability distribution over terms in <italic>T<sub>i</sub></italic> is represented as word-probability pairs (<italic>w, p</italic>). This metric results in a value in the interval [-1, 1] to represent the weighted similarity of <italic>x</italic> with <italic>T<sub>i</sub></italic>. The final similarity vectors <italic>v</italic>(<italic>a,T</italic>) and <italic>v</italic>(<italic>c,T</italic>) in &#x211D;<sup><italic>k</italic></sup> are defined as
<disp-formula id="ueqn3"><alternatives><graphic xlink:href="263897_ueqn3.gif"/></alternatives></disp-formula></p>
<p>Finally, we can see how well <italic>T</italic> correlates with both <italic>a</italic> and <italic>c</italic> by taking yet another cosine similarity
<disp-formula id="ueqn4"><alternatives><graphic xlink:href="263897_ueqn4.gif"/></alternatives></disp-formula></p>
<p>If T<sc>OPIC</sc>C<sc>ORR</sc>(<italic>a, c, T</italic>) is close to 1, then topics that are similar or dissimilar to <italic>a</italic> are also similar or dissimilar to <italic>c</italic>. This is supported by many experimental observations that if some explanation of the <italic>a&#x2013;c</italic> connection exists within <italic>T</italic>, then we anticipate that many <italic>T<sub>i</sub></italic> &#x2208; <italic>T</italic> would share these similarity relationships.</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Similarity of Best Topic Centroid</title>
<p>While the above metric attempts to find a trend within the entire topic model <italic>T</italic>, this metric attempts to find just a single topic <italic>T<sub>i</sub></italic> &#x2208; <italic>T</italic> that is likely to explain the <italic>a &#x2013; c</italic> connection. This metric is most similar to that depicted in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Each <italic>T<sub>i</sub></italic> is represented in the embedding space by taking a weighted centroid over its word probability distribution. We then rate each topic by averaging its similarity with both queried words. The score for the overall hypothesis is simply the highest score among the topics.</p>
<p>We define the centroid of <italic>T<sub>i</sub></italic> as
<disp-formula id="ueqn5"><alternatives><graphic xlink:href="263897_ueqn5.gif"/></alternatives></disp-formula>
and then compare it to both <italic>a</italic> and <italic>c</italic> through cosine similarity and euclidean distance. When comparing with CS<sc>IM</sc>, we highly rank <italic>T<sub>i</sub></italic>s with centroids located within the arc between <italic>&#x03F5;</italic>(<italic>a</italic>) and <italic>&#x03F5;</italic>(<italic>c</italic>). Because our embedding space identifies dimensions that help distinguish different types of objects, and because we trained a 500-dimensional embedding space, cosine similarity intuitively finds topics that share similar characteristics to both objects of interests. We define the best centroid similarity for CS<sc>IM</sc> as
<disp-formula id="ueqn6"><alternatives><graphic xlink:href="263897_ueqn6.gif"/></alternatives></disp-formula>
What we lose in the cosine similarity formulation is that clusters within our embedding space may be separate with respect to Euclidean distance but not cosine similarity. In order to evaluate the effect of this observation, we also formulate the best centroid metric with <italic>L</italic><sub>2</sub> distance. In this formulation we look for topics who occur as close to the midpoint between <italic>&#x03F5;</italic>(<italic>a</italic>) and <italic>&#x03F5;</italic>(<italic>c</italic>) as possible. We express this score as a ratio between that distance and the radius of the sphere with diameter from <italic>&#x03F5;</italic>(<italic>a</italic>) to <italic>&#x03F5;</italic>(<italic>c</italic>). In order to keep this metric in a similar range to the others, we limit its range to [0, 1], namely, for the midpoint <italic>m</italic> = (<italic>&#x03F5;</italic>(<italic>a</italic>) &#x002B; <italic>&#x03F5;</italic>(<italic>c</italic>))/2,
<disp-formula id="ueqn7"><alternatives><graphic xlink:href="263897_ueqn7.gif"/></alternatives></disp-formula>
</p>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Cosine Similarly of Best Topic Per Word</title>
<p>In a similar effort to the above centroid-based metric, we attempt to find topics which are related to <italic>a</italic> and <italic>c</italic>, but this time on a per-word (or phrase) basis using T<sc>OPIC</sc>S<sc>IM</sc>(<italic>x</italic>, <italic>T<sub>i</sub></italic>) from <xref ref-type="sec" rid="s4b">Section 4.2</xref>. Now instead of looking across the entire topic model, we attempt to identify a single topic which is similar to both objects of interest. We do so by rating each topic by the lower of its two similarities, meaning the best topic overall will be similar to both query words.
<disp-formula id="ueqn8"><alternatives><graphic xlink:href="263897_ueqn8.gif"/></alternatives></disp-formula>
</p>
</sec>
<sec id="s4e">
<label>4.5</label>
<title>Network of Topic Centroids</title>
<p>A majority of the above metrics all rely on a single topic to describe the potential connection between <italic>a</italic> and <italic>c</italic>, but as Smalheizer points out in [<xref ref-type="bibr" rid="c37">37</xref>], a hypothesis may be best described as a &#x201C;story&#x201D; &#x2014; a series of topics in our case. To model semantic connections between topics, we induce a nearest-neighbors network <italic>N</italic> from the set of vectors <italic>V</italic> = <italic>&#x03F5;</italic>(<italic>a</italic>) &#x222A; <italic>&#x03F5;</italic>(<italic>b</italic>) &#x222A; {C<sc>ENTR</sc>(<italic>T<sub>i</sub></italic>)}<sub><italic>T</italic><sub><italic>i</italic></sub>&#x03F5;<italic>T</italic></sub> which form the set of nodes for <italic>N</italic>. In this case, we set the number of neighbors per node to the smallest value (that may be different for each query) such that there exists a path from <italic>a</italic> to <italic>c</italic>. Using this topic network, we attempt to model the semantic differences between published and noise predicates using network analytic metrics.</p>
<p>We depict two such networks in <xref ref-type="fig" rid="fig3">Figure 3</xref>, and observe that the connectivity between <italic>a</italic> and <italic>c</italic> from a published predicate is substantially stronger and more structured. In order to quantify this observed difference, we measure the average betweenness and eigenvector centrality [<xref ref-type="bibr" rid="c31">31</xref>] of nodes along a shortest path from <italic>a</italic> to <italic>c</italic> (denoted by <italic>a</italic> &#x007E; <italic>c</italic>) within <italic>N</italic> to reflect possible information flow between <italic>T<sub>i</sub></italic> &#x2208; <italic>T</italic>. This shortest path represents the series of links between key concepts present within our dataset that one might use to explain the relationship between <italic>a</italic> and <italic>c</italic>. We expect the connection linking <italic>a</italic> and <italic>c</italic> to be stronger if that path is more central to the topic network. Below we define metrics to quantify the differences in these topic networks. Such network analytic metrics are widely applied in semantic knowledge networks [<xref ref-type="bibr" rid="c41">41</xref>].
<list id="L1" list-type="bullet">
<list-item><p>T<sc>OPIC</sc>W<sc>ALK</sc>L<sc>ENGTH</sc>(<italic>a</italic>, <italic>c</italic>, <italic>T</italic>): Length of shortest path <italic>a</italic> &#x007E; <italic>c</italic></p></list-item>
<list-item><p>T<sc>OPIC</sc>W<sc>ALK</sc>B<sc>TWN</sc>(<italic>a</italic>, <italic>c</italic>, <italic>T</italic>): Avg. betweenness centrality of <italic>a</italic> &#x007E; <italic>c</italic></p></list-item>
<list-item><p>T<sc>OPIC</sc>W<sc>ALK</sc>E<sc>IGEN</sc>(<italic>a</italic>, <italic>c</italic>, <italic>T</italic>): Avg. eigenvalue centrality of <italic>a</italic> &#x007E; <italic>c</italic></p></list-item>
<list-item><p>T<sc>OPIC</sc>N<sc>ET</sc>CC<sc>OEF</sc>(<italic>a</italic>, <italic>c</italic>, <italic>T</italic>): Clustering coefficient of <italic>N</italic></p></list-item>
<list-item><p>T<sc>OPIC</sc>N<sc>ET</sc>M<sc>OD</sc>(<italic>a</italic>, <italic>c</italic>, <italic>T</italic>): Modularity of <italic>N</italic>.</p></list-item>
</list>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Above depicts two topic networks as described in <xref ref-type="sec" rid="s4e">Section 4.5</xref>. In this visualization, longer edges correspond to dissimilar neighbors. In red are objects <italic>a</italic> and <italic>c</italic>, which we queried to create these topics models. We observe that the connectivity between <italic>a</italic> and <italic>c</italic> from the published predicate is much higher than in the noisy example.</p></caption>
<graphic xlink:href="263897_fig3.tif"/>
</fig></p>
</sec>
<sec id="s4f">
<label>4.6</label>
<title>Combination of Multiple Metrics</title>
<p>Each of the above methods are based on different assumptions regarding topic model or embedding space properties exhibited by published connections. To leverage each metric&#x2019;s strengths, we combined the top performing ones from each category into the following P<sc>OLY</sc>M<sc>ULTIPLE</sc> method. We explored polynomial combinations in the form of <inline-formula><alternatives><inline-graphic xlink:href="263897_inline2.gif"/></alternatives></inline-formula> for ranges of <italic>&#x03B1;<sub>i</sub></italic> &#x2208; [&#x2212;1,1] and <italic>&#x03B2;<sub>i</sub></italic> &#x2208; [1, 3] after scaling each <italic>x<sub>i</sub></italic> to the [0,1] interval. Through a blackbox optimization technique, we searched over one-million parameter combinations, and present the best values <xref ref-type="table" rid="tbl1">Table 1</xref>. Omitted metrics were optimized with corresponding <italic>&#x03B1;<sub>i</sub></italic> &#x2260; 0.</p>
<disp-formula id="ueqn9"><alternatives><graphic xlink:href="263897_ueqn9.gif"/></alternatives></disp-formula>
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>Table 1:</label>
<caption><p>Best hyperparameters obtained via blackbox optimization for the PolyMultiple method. Note, each parameter was scaled to the [0, 1] interval before its input into the overall polynomial.</p></caption>
<graphic xlink:href="263897_tbl1.tif"/>
</table-wrap>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Results and Lessons Learned</title>
<p>As described in <xref ref-type="sec" rid="s3">Section 3</xref>, our goal is to distinguish publishable connections from noise. We run MOLIERE to generate topic models related to published, noise, and highly cited pairs. Using this information, we plot ROC curves in <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>, and summarize the results in <xref ref-type="table" rid="tbl2">Table 2</xref>. These plots represent an analysis of 8,638 published vs. noise (PvN) pairs and 2,896 highly-cited vs. noise (HCvN) pairs (half of each set are noise). Although external factors limited the scale of our validation in both cases, we found that the resulting ROC areas are consistent for data sets of at least a few thousand pairs and different samplings.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>The above ROC curves show the ability for each of our proposed methods to distinguish the MOLIERE results of published pairs from noise. We use our system to generate hypotheses regarding 8,638 pairs, half from each set, on publicly available data released prior to 2,015. We only show the best performing metrics from <xref ref-type="sec" rid="s4e">Section 4.5</xref> for clarity.</p></caption>
<graphic xlink:href="263897_fig4.tif"/>
</fig>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>The above ROC curves show the ability for each of our proposed methods to distinguish the MOLIERE results of highly-cited pairs from noise. We identify 1,448 pairs who first occur in papers with over 100 citations published after our cut date. To plot the above ROC curve, we also select an random subset of equal size from the noise pairs.</p></caption>
<graphic xlink:href="263897_fig5.tif"/>
</fig>
<table-wrap id="tbl2" position="float" orientation="portrait">
<label>Table 2:</label>
<caption><p>The above summarizes all ROC area results for all considered metrics on the set of published vs. noise pairs (PvN) and highly-cited vs. noise pairs (HCvN). Note, we report areas in the range [0.5,1], so metrics marked with a (&#x002A;) have been sorted in reverse order for the ROC calculations. This indicates that a higher score along a starred metric indicates a noise pair.</p></caption>
<graphic xlink:href="263897_tbl2.tif"/>
</table-wrap>
<p><bold>Topic Model Correlation</bold> metric (see <xref ref-type="sec" rid="s4b">Section 4.2</xref>) is a poorly performing metric with an ROC area of 0.609 (PvN) and 0.496 (HCvN). The core issue of this method is its sensitivity to the number of topics generated, and given that we generate 100 topics per pair, we likely drive down performance through topics which are unrelated to the query. Surprisingly, this metric is less able to distinguish highly-cited pairs, which we suppose is because highly-cited connections often bridge very distant concepts [<xref ref-type="bibr" rid="c35">35</xref>] and likely results in more noisy topic models. Additionally, we may be able to limit this noise by tuning the number of topics returned from a query, as described in <xref ref-type="sec" rid="s7">Section 7</xref>.</p>
<p><bold><italic>L</italic><sub>2</sub>-based metrics</bold> exhibit even more surprising results. B<sc>EST</sc>C<sc>ENTR</sc>L<sub>2</sub> performs poorly, with an ROC area of 0.578 (PvN) and 0.587 (HCvN), while the much simpler <italic>L</italic><sub>2</sub> metric is exceptional, scoring a 0.783 (PvN) and 0.809 (HCvN). We note that if two words are related, they are more likely to be closer together in our vector space. We evaluate topic centroids based on their closeness to the midpoint between <italic>a</italic> and <italic>c</italic>, normalized by the distance between them, so if that distance is small, the radius from the midpoint is small as well. Therefore, it would seem that the distance between <italic>a</italic> and <italic>c</italic> is a better connection indication, and that the result of the centroid measurement is worse if this distance is small.</p>
<p><bold>CSim-based metrics</bold> are more straight-forward. The simple CS<sc>IM</sc>metric scores a 0.709 (PvN) and 0.703 (HCvN), which is interestingly consistent given that the <italic>L</italic><sub>2</sub> metric increases in ROC area given highly-cited pairs. The B<sc>EST</sc>T<sc>OPIC</sc>P<sc>ER</sc>W<sc>ORD</sc> metric only scores a 0.686 (PvN), but increases substantially to 0.731 (HCvN). The topic centroid method BESTCENTROIDCSIM is the best cosine-based metric with an ROC area of 0.719 (PvN) and 0.742 (HCvN). This result is evidence that our initial hypothesis described in <xref ref-type="fig" rid="fig2">Figure 2</xref> holds given cosine similarity, but as stated above, does not hold for euclidean distance.</p>
<p><bold>Topic network</bold> metrics are all outperformed by simple <italic>L</italic><sub>2</sub>, but we see interesting properties from their results that also help users to interpret generated hypotheses. For instance, we see that T<sc>OPIC</sc>W<sc>ALK</sc>B<sc>ETWEENESS</sc> is a negative indicator while T<sc>OPIC</sc>W<sc>ALK</sc>E<sc>IGEN</sc> is positive. Looking at the example in <xref ref-type="fig" rid="fig3">Figure 3</xref> we see that <italic>a</italic> and <italic>c</italic> are both far from the center of the network, connected to the rest of the topics through a very small number of high-betweenness nodes. In contrast, we see that in the network created from a published pair, the path from <italic>a</italic> to <italic>c</italic> is more central. We also see a denser clustering for the noise pair network, which is echoed by the fact that T<sc>OPIC</sc>N<sc>ET</sc>CC<sc>OEF</sc> and T<sc>OPIC</sc>N<sc>ET</sc>M<sc>ODULATIRY</sc> are both negative indicators. Lastly, we see that T<sc>OPIC</sc>W<sc>ALK</sc>L<sc>ENGTH</sc> performs the best out of these network approaches, likely because it is most similar to the simple <italic>L</italic><sub>2</sub> or CS<sc>IM</sc> metrics.</p>
<p><bold>Combination of metrics,</bold> P<sc>OLY</sc>M<sc>ULTIPLE</sc>, significantly outperforms all others with ROC areas of 0.834 (PvN) and 0.874 (HCvN). This is unsurprising because each other metric makes a different assumption about what sort of topic or vector configuration best indicates a published pair. When each is combined, we see not only better performance, but their relative importances. Looking into <xref ref-type="table" rid="tbl1">Table 1</xref> we see that the two <italic>L</italic><sub>2</sub>-based metrics are most important, followed by the topic network methods, and finally by T<sc>OPIC</sc>W<sc>ALK</sc>C<sc>ORR</sc> and B<sc>EST</sc>T<sc>OPIC</sc>P<sc>ERWORD</sc>. Unsurprisingly, the coefficient signs correlate directly with whether each metric is a positive or negative indication as summarized in <xref ref-type="table" rid="tbl2">Table 2</xref>. Additionally, the ordering of importance roughly follows the same ordering as the ROC areas.</p>
</sec>
<sec id="s6">
<label>6</label>
<title>Related Work and Proposed Validation</title>
<p>The HG community struggles to validate its systems in a number of ways. Yetisgen-Yildiz and Pratt, in their chapter &#x201C;Evaluation of Literature-Based Discovery Systems,&#x201D; outline four such methods (M1-M4) [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c55">55</xref>].</p>
<p><bold>M1: Replicate Swanson&#x2019;s Experiments.</bold> Swanson, during his development of ARROWSMITH [<xref ref-type="bibr" rid="c39">39</xref>], worked alongside medical researchers to uncover a number of new connections. These connections include the link between Raynaud&#x2019;s Disease and Fish Oil [<xref ref-type="bibr" rid="c45">45</xref>], the link between Alzheimer&#x2019;s Disease and Estrogen [<xref ref-type="bibr" rid="c38">38</xref>] and the link between Migraine and Magnesium [<xref ref-type="bibr" rid="c47">47</xref>]. As discussed in [<xref ref-type="bibr" rid="c55">55</xref>], a number of projects have centered their validation effort around Swanson&#x2019;s results [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. These efforts always rediscover a number of findings using information before Swanson&#x2019;s discovery date, and occasionally apply additional metrics such as precision and recall in order to quantify their results [<xref ref-type="bibr" rid="c14">14</xref>].</p>
<p>While limiting discussion to Swanson&#x2019;s discoveries reduces the domain of discovery drastically, at its core this method builds confidence in a new system through its ability to find known connections. We expand on this idea by validating automatically and on a massive scale, freeing our discourse from a single researcher&#x2019;s findings.</p>
<p><bold>M2: Statistical Evaluation.</bold> Hristovski et al. validate their system by studying a number of relationships and note their confidence and support with respect to the MEDLINE document set [<xref ref-type="bibr" rid="c18">18</xref>]. Then, they can generate potential relationships for the set of new connections added to UMLS [<xref ref-type="bibr" rid="c1">1</xref>] or OMIM [<xref ref-type="bibr" rid="c13">13</xref>]. By limiting their method to association rules, Hristovski et al. note that they can validate their system by predicting UMLS connections using data available prior to their publications. Therefore, this method is the similar to our own, but we notice that restricting discussion to only UMLS gene-disease connections results in a much smaller set than the predicate information present with SemMedDB.</p>
<p>Pratt et al. provide additional statistical validation for their system LitLinker [<xref ref-type="bibr" rid="c32">32</xref>]. This method also calculates precision and recall, but this time focusing on their <italic>B</italic>-set of returned results. Their system, like ARROWSMITH [<xref ref-type="bibr" rid="c39">39</xref>], returns a set of intermediate terms which may connect two queried entities. Pratt et al. run LitLinker for a number of diseases on which they establish a set of &#x201C;gold standard&#x201D; terms. Their method is validated based on its ability to list those gold-standard terms within its resulting <italic>B-sets. This approach requires careful selection of a (typically small) set of gold-standard terms, and is limited to &#x201C;ABC&#x201D; systems like ARROWSMITH, which are designed to identify term lists</italic> [<xref ref-type="bibr" rid="c36">36</xref>].</p>
<p><bold>M3: Incorporating Expert Opinion.</bold> This ranges from comparisons between system output and expert output, such as the analysis done on the Manjal system [<xref ref-type="bibr" rid="c44">44</xref>], to incorporating expert opinion into gold-standard terms for LitLinker [<xref ref-type="bibr" rid="c32">32</xref>], to running actual experiments on potential results by Wren et al. [<xref ref-type="bibr" rid="c54">54</xref>]. Expert opinion is at the heart of many recent systems [<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c2">2</xref>], including the previous version of our own. This process is both time consuming and risks introducing significant bias into the validation.</p>
<p>Spangler incorporates expert knowledge in a more sophisticated manner through the use of visualizations [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>]. This approach centers around visual networks and ontologies produced automatically, which allows experts to see potential new connections as they relate to previously established information. This view is shared by systems such as DiseaseConnect [<xref ref-type="bibr" rid="c27">27</xref>] which generates sub-networks of ONIM and GWAS related to specific queries. Although these visualizations allow users to quickly understand query results, they do not lend themselves to a numeric and massive evaluation of system performance.</p>
<p>BioCreative is a set of challenges focused on assessing biomedical text mining, is the largest endeavor of its kind, to the best of our knowledge [<xref ref-type="bibr" rid="c17">17</xref>]. Each challenge centers around a specific task, such as mining chemical-protein interactions, algorithmically identifying medical terms, and constructing causal networks from raw text. Although these challenges are both useful and important, their tasks fall under the umbrella of <italic>information retrieval</italic> because they compare expert analysis with software results given the same text.</p>
<p><bold>M4: Publishing in the Medical Domain.</bold> This method is exceptionally rare and expensive. The idea is to take prevalent potential findings and pose them to the medical research community for another group to attempt. Swanson and Smalheiser use this technique, which solidifies many of their most prevalent findings, but we are not aware of any other group to attempt this.</p>
<p>An alternative to this idea is taken by Soldatova and Rzhetsky wherein a &#x201C;robot scientist&#x201D; automatically runs experiments posed by their HG system [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c34">34</xref>]. This system uses logical statements to represent their hypotheses, so new ideas can be posed through a series of implications. Going further, their system even identifies statements that would be the most valuable if proven true [<xref ref-type="bibr" rid="c35">35</xref>]. <italic>But, the scope of experiments that a robot scientists can undertake is limited; in their initial paper, the robot researcher is limited to small-scale yeast experiments. Additionally, many groups cannot afford the space and expense that an automated lab requires.</italic></p>
</sec>
<sec id="s7">
<label>7</label>
<title>Deployment Challenges and Open Problems</title>
<p><bold>Challenge Size.</bold> Our proposed validation challenge involves ranking millions of published and noise query pairs. But, in <xref ref-type="sec" rid="s5">Section 5</xref> we show our results on a randomly sampled subset of our overall challenge set. This was necessary due to performance limitations of MOLIERE, a system which initially required a substantial amount of time and memory to process even a single hypothesis. To compute these results, we ran 100 instances of MOLIERE, each on a 16 core, 64 GB RAM machine connected to a ZFS storage system. Unfortunately, performance limitations within ZFS created a bottleneck that both limited our results and drastically reduced cluster performance overall. So, our results represent a set of predicates that we evaluated in a limited time period.</p>
<p><bold>System Optimizations.</bold> While performing a keyword search, most network-centered systems are either I/O or memory bound simply because they must load and traverse large networks. In the case of MOLIERE, we initially spent hours trying to find shortest paths or nearby abstracts. But, we found a way to leverage our embedding space and our parallel file system in order to drastically improve query performance.</p>
<p>In brief, one can discover a relevant knowledge-network region by inducing a subnetwork on the set of keywords found within the hyperellipse focused between <italic>a</italic> and <italic>c</italic>. This increases performance because, given a parallel file system, creating an edge list for that subnetwork is a massively parallel task of order <italic>O</italic>(<italic>n/p</italic>). Additionally, when finding a path from <italic>a</italic> to <italic>c</italic> in that subnetwork, we can leverage the embeddings again to replace our shortest-path algorithm with <italic>A</italic>&#x002A;. We note that if such a path does not exist within our subnetwork, one can always increase the hyperellipse constant in order to broaden the subnetwork.</p>
<p>The overall effect of our optimizations reduced the wall-clock runtime of a single query from about 12 hours to about 5-7 minutes. Additionally, we reduced the memory requirement for a single query from over 400GB to under 16GB. Moreover, because the quality of our system&#x2019;ss results is tunable through the hyperellipse constant, we note that our results presented here are nearly identical to our previous software.</p>
<p><bold>Highly Cited Predicates.</bold> Identifying highly sighted predicates requires that we synthesize information across multiple data sources. Although SemMedDB contains MEDLINE references for each predicate, neither contains citation information. For this, we turn to Semantic Scholar because not only do they track citations of medical papers, but they allow a free bulk download of metadata information (many other potential sources either provide a very limited API or none at all). In order to match Semantic Scholar data to MEDLINE citation, it is enough to match titles. This process allows us to get citation information for many MEDLINE documents, which in turn allow us to select predicates who&#x2019;s first occurrence was in highly cited papers.</p>
<p>We explored a number of thresholds for what constitutes &#x201C;highly cited&#x201D; and selected 100 because it was a round number that provided a sizable number of selected predicates. Because paper citations approximately follow a power-law distribution, any change would have drastically changed the size of this set. We note that the set of selected predicates was also limited by the quality of data in Semantic Scholar, and that the number of citations identified this was appeared to be substantially lower than that reported by other methods. Nevertheless, because our available citation count is a lower bound of the real value, we are assured that our &#x201C;highly cited&#x201D; set is actually well cited. According to our observations the least cited paper was cited more than 400 times in Google Scholar.</p>
<p><bold>Quality of Predicates.</bold> Through our above methods we learned that careful ranking methods can distinguish between published and noise predicates, but there is a potential inadequacy in this method. Likely, there exist a number of predicates within our published set which despite occurring in an abstract, are untrue. Additionally, it is possible that a noise predicate may be discovered to be true in the future. If our system ranks the published predicate which is untrue below the noise predicate which is, we worsen our system&#x2019;s ROC area. This same phenomena is addressed by Yetisgen-Yildiz and Pratt when they discuss the challenges present in validating literature-based discovery systems [<xref ref-type="bibr" rid="c55">55</xref>] &#x2014; if a HG systems goal is to identify novel findings, then it <italic>should</italic> find different connections than human researchers.</p>
<p>We show through our results that despite an uncertain validation set, there are clearly core differences between publishable results and noise, which are evident at scale. Although there may be some false positives or negatives, we see through our meaningful ROC curves that they are far outnumbered by more standard predicates.</p>
<p><bold>Automatic Question Posting.</bold> Going forward we wish to study highly ranked noise predicates for the purpose of automatic question posing. This would mean that our system would search through its set of entities, run queries, and report the most promising potential new connections. In order to do this effectively we need to gain an understanding of how we can intelligently search local regions of our knowledge network and how to define locality for this task.</p>
<p><bold>Comparison with ABC Systems.</bold> Additionally, we would like to explore how our ranking methods apply to traditional ABC systems. Although there are clear limitations to these systems [<xref ref-type="bibr" rid="c36">36</xref>], many of the original systems such as ARROWSMITH follow the pattern. These systems typically output a list of target terms and linking terms, which could be thought of as a topic. If we were to take a pretrained embedding space, and treated a set of target terms like a topic, we could likely use our methods from <xref ref-type="sec" rid="s4">Section 4</xref> to validate any ABC system.</p>
<p><bold>Verb Prediction.</bold> We noticed, while processing SemMedDB predicates, that we can improve MOLIERE if we utilize verbs. SemMedDB provides a handful of verb types, such as &#x201C;TREATS,&#x201D; &#x201C;CAUSES,&#x201D; or &#x201C;INTERACTS_WITH,&#x201D; that suggest a concrete relationship between the subject and object of a sentence. MOLIERE currently outputs a topic model that can be interpreted using our new metrics, but does not directly state what sort of connection may exist between <italic>a</italic> and <italic>c</italic>. So, we want to see if we can accurately predict these verb types given only topic model information.</p>
<p><bold>Interpretability of hypotheses</bold> remains one of the major problems in HG systems. Although topic-driven HG partially resolve this issue by producing a readable output, we still observe many topic models <italic>T</italic> (i.e., hypotheses) whose <italic>T<sub>i</sub></italic> &#x2208; <italic>T</italic> are not intuitively connected with each other. While the proposed ranking is definitely helpful for understanding <italic>T</italic>, it still does not fully resolve the interpretability problem. One of our current research directions to tackle it is using text summarization techniques.</p>
</sec>
<sec id="s8">
<label>8</label>
<title>Conclusion</title>
<p>When we rely on experts to pose questions or perform experiments for the sake of validation, we drastically reduce the productivity of all involved. This is compounded by the need for software systems to rapidly iterate over time, gaining features and trying new methods to produce results. That work flow cannot afford the time of experts. Although we are not the first to identify the need for large-scale validation, we do propose a validation method which is impartial, does not need expert opinion, and operates at large scale. Furthermore, by selecting different cut years, we can even continue with our validation scheme long into the future, without manually selecting discoveries.</p>
<p>Additionally, our validation challenge can be taken by any system, not just an ABC system, so long as that system can rank its results. As we show in <xref ref-type="sec" rid="s4">Section 4</xref>, even topic-driven systems can be adapted to produce such a ranking. Our validation methodology even extends across domains, as long as one can extract predicates. Overall, we see an immense need for validation which allows us to meaningfully compare performance across HG systems, or across scientific domains, and we are unaware of any other methodology for doing so.</p>
<p>To aid the biomedical HG community, we provide our code, query sets, and training data on-line at <ext-link ext-link-type="uri" xlink:href="http://bit.ly/2EtVshN">bit.ly/2EtVshN</ext-link>. With these resources, anyone could replicate our results using MOLIERE, or incorporate our ranking methods or validation framework into their own HG system.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="other"><comment>Umls reference manual</comment>, <year>2009</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>V.</given-names> <surname>Abedi</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Zand</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Yeasin</surname></string-name>, and <string-name><given-names>F. E.</given-names> <surname>Faisal</surname></string-name>. <article-title>An automated framework for hypotheses generation using literature</article-title>. <source>BioData Mining</source>, <volume>5</volume>(<issue>1</issue>):<fpage>13</fpage>, Aug <year>2012</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>L. B.</given-names> <surname>Alexandrov</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Nik-Zainal</surname></string-name>, <string-name><given-names>D. C.</given-names> <surname>Wedge</surname></string-name>, <string-name><given-names>S. A.</given-names> <surname>Aparicio</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Behjati</surname></string-name>, <string-name><given-names>A. V.</given-names> <surname>Biankin</surname></string-name>, <string-name><given-names>G. R.</given-names> <surname>Bignell</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Bolli</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Borg</surname></string-name>, <string-name><given-names>A.-L.</given-names> <surname>B&#x00F8;rresen-Dale</surname></string-name>, <etal>et al.</etal> <article-title>Signatures of mutational processes in human cancer</article-title>. <source>Nature</source>, <volume>500</volume>(<issue>7463</issue>):<fpage>415</fpage>&#x2013;<lpage>421</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="book"><string-name><given-names>N.</given-names> <surname>Bencomo</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Belaggoun</surname></string-name>. <chapter-title>A world full of surprises: Bayesian theory of surprise to quantify degrees of uncertainty</chapter-title>. In <source>Companion Proceedings of the 36th International Conference on Software Engineering</source>, pages <fpage>460</fpage>&#x2013;<lpage>463</lpage>. <publisher-name>ACM</publisher-name>, <year>2014</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Blake</surname></string-name> and <string-name><given-names>W.</given-names> <surname>Pratt</surname></string-name>. <article-title>Automatically identifying candidate treatments from existing medical literature</article-title>. In <source>AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases</source>, pages <fpage>9</fpage>&#x2013;<lpage>13</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>D. M.</given-names> <surname>Blei</surname></string-name>, <string-name><given-names>A. Y.</given-names> <surname>Ng</surname></string-name>, and <string-name><given-names>M. I.</given-names> <surname>Jordan</surname></string-name>. <article-title>Latent dirichlet allocation</article-title>. <source>Journal of machine Learning research</source>, <volume>3</volume>(<issue>Jan</issue>):<fpage>993</fpage>&#x2013;<lpage>1022</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="book"><string-name><given-names>P.</given-names> <surname>Bruza</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Weeber</surname></string-name>. <source>Literature-based discovery</source>. <publisher-name>Springer Science &#x0026; Business Media</publisher-name>, <year>2008</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>M. B.</given-names> <surname>Dos Santos</surname></string-name>. <article-title>The textual organization of research paper abstracts in applied linguistics</article-title>. <source>Text-Interdisciplinary Journal for the Study of Discourse</source>, <volume>16</volume>(<issue>4</issue>):<fpage>481</fpage>&#x2013;<lpage>500</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>El-Kishky</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Song</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>C. R.</given-names> <surname>Voss</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Han</surname></string-name>. <article-title>Scalable topical phrase mining from text corpora</article-title>. <source>Proceedings of the VLDB Endowment</source>, <volume>8</volume>(<issue>3</issue>):<fpage>305</fpage>&#x2013;<lpage>316</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Friedman</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Kra</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Yu</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Krauthammer</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Rzhetsky</surname></string-name>. <article-title>Genies: a natural-language processing system for the extraction of molecular pathways from journal articles</article-title>. <source>Bioinformatics</source>, <volume>17</volume>(<issue>suppl 1</issue>):<fpage>S74</fpage>&#x2013;<lpage>S82</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="other"><string-name><given-names>M. D.</given-names> <surname>Gordon</surname></string-name> and <string-name><given-names>S.</given-names> <surname>Dumais</surname></string-name>. <article-title>Using latent semantic indexing for literature based discovery</article-title>. <year>1998</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Greene</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Cagney</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Krogan</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>Cunningham</surname></string-name>. <article-title>Ensemble non-negative matrix factorization methods for clustering protein-protein interactions</article-title>. <source>Bioinformatics</source>, <volume>24</volume>(<issue>15</issue>):<fpage>1722</fpage>&#x2013;<lpage>1728</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Hamosh</surname></string-name>, <string-name><given-names>A. F.</given-names> <surname>Scott</surname></string-name>, <string-name><given-names>J. S.</given-names> <surname>Amberger</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Bocchini</surname></string-name>, and <string-name><given-names>V. A.</given-names> <surname>Mckusick</surname></string-name>. <article-title>Online mendelian inheritance in man (omim), a knowledgebase of human genes and genetic disorders</article-title>. <source>Nucleic acids research</source>, <volume>33</volume>(<issue>Database issue</issue>), <year>2005</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="other"><string-name><given-names>J.</given-names> <surname>Han</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Pei</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Kamber</surname></string-name>. <article-title>Data mining: concepts and techniques</article-title>. <source>Elsevier</source>, <year>2011</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="book"><string-name><given-names>J.</given-names> <surname>He</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Hu</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Berg-Kirkpatrick</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Huang</surname></string-name>, and <string-name><given-names>E. P.</given-names> <surname>Xing</surname></string-name>. <chapter-title>Efficient correlated topic modeling with topic embedding</chapter-title>. In <source>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>, pages <fpage>225</fpage>&#x2013;<lpage>233</lpage>. <publisher-name>ACM</publisher-name>, <year>2017</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>G. E.</given-names> <surname>Heo</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Lee</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Song</surname></string-name>. <article-title>Inferring undiscovered public knowledge by using text mining-driven graph model</article-title>. In <source>Proceedings of the ACM 8th International Workshop on Data and Text Mining in Bioinformatics</source>, pages <fpage>37</fpage>&#x2013;<lpage>37</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Hirschman</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Yeh</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Blaschke</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Valencia</surname></string-name>. <article-title>Overview of biocreative: critical assessment of information extraction for biology</article-title>. <source>BMC Bioinformatics</source>, <volume>6</volume>(<issue>1</issue>):<fpage>S1</fpage>, May <year>2005</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Hristovski</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Peterlin</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Mitchell</surname></string-name>, and <string-name><given-names>S. M.</given-names> <surname>Humphrey</surname></string-name>. <article-title>Using literature-based discovery to identify disease candidate genes</article-title>. <source>International journal of medical informatics</source>, <volume>74</volume>(<issue>2</issue>):<fpage>289</fpage>&#x2013;<lpage>298</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="book"><string-name><given-names>X.</given-names> <surname>Hu</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Yoo</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Zhang</surname></string-name>, and <string-name><given-names>X.</given-names> <surname>Xu</surname></string-name>. <chapter-title>A semantic-based approach for mining undiscovered public knowledge from biomedical literature</chapter-title>. In <source>Granular Computing, 2005 IEEE International Conference on</source>, volume <volume>1</volume>, pages <fpage>22</fpage>&#x2013;<lpage>27</lpage>. <publisher-name>IEEE</publisher-name>, <year>2005</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Itti</surname></string-name> and <string-name><given-names>P. F.</given-names> <surname>Baldi</surname></string-name>. <article-title>Bayesian surprise attracts human attention</article-title>. In <source>Advances in neural information processing systems</source>, pages <fpage>547</fpage>&#x2013;<lpage>554</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="other"><string-name><given-names>A.</given-names> <surname>Joulin</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Grave</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bojanowski</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Douze</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Jegou</surname></string-name>, and <string-name><given-names>T.</given-names> <surname>Mikolov</surname></string-name>. <article-title>Fasttext.zip: Compressing text classification models</article-title>. arXiv preprint arXiv:<pub-id pub-id-type="arxiv">1612.03651</pub-id>, <year>2016</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>H.</given-names> <surname>Kilicoglu</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Shin</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fiszman</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rosemblat</surname></string-name>, and <string-name><given-names>T. C.</given-names> <surname>Rindflesch</surname></string-name>. <article-title>Semmeddb: a pubmed-scale repository of biomedical semantic predications</article-title>. <source>Bioinformatics</source>, <volume>28</volume>(<issue>23</issue>):<fpage>3158</fpage>&#x2013;<lpage>3160</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="book"><string-name><given-names>R.</given-names> <surname>Kohavi</surname></string-name> <etal>et al.</etal> <chapter-title>A study of cross-validation and bootstrap for accuracy estimation and model selection</chapter-title>. In <source>Ijcai</source>, volume <volume>14</volume>, pages <fpage>1137</fpage>&#x2013;<lpage>1145</lpage>. <publisher-loc>Stanford, CA</publisher-loc>, <year>1995</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>P. O.</given-names> <surname>Larsen</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Von Ins</surname></string-name>. <article-title>The rate of growth in scientific publication and the decline in coverage provided by science citation index</article-title>. <source>Scientometrics</source>, <volume>84</volume>(<issue>3</issue>):<fpage>575</fpage>&#x2013;<lpage>603</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="other"><string-name><given-names>D. D.</given-names> <surname>Lee</surname></string-name> and <string-name><given-names>H. S.</given-names> <surname>Seung</surname></string-name>. <article-title>Algorithms for non-negative matrix factorization</article-title>. In <source>Advances in neural information processing systems</source>, pages <fpage>556</fpage>&#x2013;<lpage>562</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>R. K.</given-names> <surname>Lindsay</surname></string-name> and <string-name><given-names>M. D.</given-names> <surname>Gordon</surname></string-name>. <article-title>Literature-based discovery by lexical statistics</article-title>. <source>Journal of the Association for Information Science and Technology</source>, <volume>50</volume>(<issue>7</issue>):<fpage>574</fpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>C.-C.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Y.-T.</given-names> <surname>Tseng</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>C.-Y.</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Mayzus</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Rzhetsky</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Sun</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Waterman</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>P. M.</given-names> <surname>Chaudhary</surname></string-name>, <etal>et al.</etal> <article-title>Diseaseconnect: a comprehensive web server for mechanism-based disease-disease connections</article-title>. <source>Nucleic acids research</source>, <volume>42</volume>(<issue>W1</issue>):<fpage>W137</fpage>&#x2013;<lpage>W146</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>Z.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>E. Y.</given-names> <surname>Chang</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Sun</surname></string-name>. <article-title>Plda&#x002B;: Parallel latent dirichlet allocation with data placement and pipeline processing</article-title>. <source>ACM Transactions on Intelligent Systems and Technology (TIST)</source>, <volume>2</volume>(<issue>3</issue>):<fpage>26</fpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="other"><string-name><given-names>T.</given-names> <surname>Mikolov</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Corrado</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Dean</surname></string-name>. <article-title>Efficient estimation of word representations in vector space</article-title>. arXiv:<pub-id pub-id-type="arxiv">1301.3781</pub-id>, <year>2013</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="website"><collab>NCBI Resource Coordinators</collab>. <comment>PubMed. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/">https://www.ncbi.nlm.nih.gov/pubmed/</ext-link></comment>, <year>2017</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="book"><string-name><given-names>M.</given-names> <surname>Newman</surname></string-name>. <source>Networks: an introduction</source>. <publisher-name>Oxford university press</publisher-name>, <year>2010</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="book"><string-name><given-names>W.</given-names> <surname>Pratt</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Yetisgen-Yildiz</surname></string-name>. <chapter-title>Litlinker: capturing connections across the biomedical literature</chapter-title>. In <source>Proceedings of the 2nd international conference on Knowledge capture</source>, pages <fpage>105</fpage>&#x2013;<lpage>112</lpage>. <publisher-name>ACM</publisher-name>, <year>2003</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="book"><string-name><given-names>A.</given-names> <surname>Ranganathan</surname></string-name> and <string-name><given-names>F.</given-names> <surname>Dellaert</surname></string-name>. <chapter-title>Bayesian surprise and landmark detection</chapter-title>. In <source>Robotics and Automatnon</source>, <year>2009</year>. <comment>ICRA&#x2019;09. IEEE International Conference on</comment>, pages <fpage>2017</fpage>&#x2013;<lpage>2023</lpage>. <publisher-name>IEEE</publisher-name>, <comment>2009</comment>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="other"><string-name><given-names>A.</given-names> <surname>Rzhetsky</surname></string-name>. <article-title>The big mechanism program: Changing how science is done</article-title>. <year>2016</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Rzhetsky</surname></string-name>, <string-name><given-names>J. G.</given-names> <surname>Foster</surname></string-name>, <string-name><given-names>I. T.</given-names> <surname>Foster</surname></string-name>, and <string-name><given-names>J. A.</given-names> <surname>Evans</surname></string-name>. <article-title>Choosing experiments to accelerate collective discovery</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>112</volume>(<issue>47</issue>):<fpage>14569</fpage>&#x2013;<lpage>14574</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>N. R.</given-names> <surname>Smalheiser</surname></string-name>. <article-title>Literature-based discovery: Beyond the abcs</article-title>. <source>Journal of the Association for Information Science and Technology</source>, <volume>63</volume>(<issue>2</issue>):<fpage>218</fpage>&#x2013;<lpage>224</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>N. R.</given-names> <surname>Smalheiser</surname></string-name>. <article-title>Rediscovering don swanson: The past, present and future of literature-based discovery</article-title>. <source>Journal of Data and Information Science</source>, <volume>2</volume>(<issue>4</issue>):<fpage>43</fpage>&#x2013;<lpage>64</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>N. R.</given-names> <surname>Smalheiser</surname></string-name> and <string-name><given-names>D. R.</given-names> <surname>Swanson</surname></string-name>. <article-title>Linking estrogen to alzheimer&#x2019;s disease an informatics approach</article-title>. <source>Neurology</source>, <volume>47</volume>(<issue>3</issue>):<fpage>809</fpage>&#x2013;<lpage>810</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>N. R.</given-names> <surname>Smalheiser</surname></string-name> and <string-name><given-names>D. R.</given-names> <surname>Swanson</surname></string-name>. <article-title>Using arrowsmith: a computer-assisted approach to formulating and assessing scientific hypotheses</article-title>. <source>Computer methods and programs in biomedicine</source>, <volume>57</volume>(<issue>3</issue>):<fpage>149</fpage>&#x2013;<lpage>153</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>L. N.</given-names> <surname>Soldatova</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Rzhetsky</surname></string-name>. <article-title>Representation of research hypotheses</article-title>. <source>Journal of biomedical semantics</source>, <volume>2</volume>(<issue>2</issue>):<fpage>S9</fpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="book"><string-name><given-names>J. F.</given-names> <surname>Sowa</surname></string-name>. <source>Principles of semantic networks: Explorations in the representation of knowledge</source>. <publisher-loc>Morgan Kaufmann</publisher-loc>, <year>2014</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="book"><string-name><given-names>S.</given-names> <surname>Spangler</surname></string-name>. <source>Accelerating Discovery: Mining Unstructured Information for Hypothesis Generation</source>, volume <volume>37</volume>. <publisher-name>CRC Press</publisher-name>, <year>2015</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="book"><string-name><given-names>S.</given-names> <surname>Spangler</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Wilkins</surname></string-name>, <string-name><given-names>B. J.</given-names> <surname>Bachman</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Nagarajan</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Dayaram</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Haas</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Regenbogen</surname></string-name>, <string-name><given-names>C. R.</given-names> <surname>Pickering</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Comer</surname></string-name>, <string-name><given-names>J. N.</given-names> <surname>Myers</surname></string-name>, <etal>et al.</etal> <chapter-title>Automated hypothesis generation based on mining scientific literature</chapter-title>. In <source>Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</source>, pages <fpage>1877</fpage>&#x2013;<lpage>1886</lpage>. <publisher-name>ACM</publisher-name>, <year>2014</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Srinivasan</surname></string-name>. <article-title>Text mining: generating hypotheses from medline</article-title>. <source>Journal of the American Society for Information Science and Technology</source>, <volume>55</volume>(<issue>5</issue>):<fpage>396</fpage>&#x2013;<lpage>413</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>D. R.</given-names> <surname>Swanson</surname></string-name>. <article-title>Fish oil, raynaud&#x2019;s syndrome, and undiscovered public knowledge</article-title>. <source>Perspectives in biology and medicine</source>, <volume>30</volume>(<issue>1</issue>):<fpage>7</fpage>&#x2013;<lpage>18</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>D. R.</given-names> <surname>Swanson</surname></string-name>. <article-title>Undiscovered public knowledge</article-title>. <source>The Library Quarterly</source>, <volume>56</volume>(<issue>2</issue>):<fpage>103</fpage>&#x2013;<lpage>118</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>D. R.</given-names> <surname>Swanson</surname></string-name>. <article-title>Migraine and magnesium: eleven neglected connections</article-title>. <source>Perspectives in biology and medicine</source>, <volume>31</volume>(<issue>4</issue>):<fpage>526</fpage>&#x2013;<lpage>557</lpage>, <year>1988</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><given-names>D. R.</given-names> <surname>Swanson</surname></string-name> and <string-name><given-names>N. R.</given-names> <surname>Smalheiser</surname></string-name>. <article-title>An interactive system for finding complementary literatures: A stimulus to scientific discovery</article-title>. <source>Artif. Intell.</source>, <volume>91</volume>(<issue>2</issue>):<fpage>183</fpage>&#x2013;<lpage>203</lpage>, <comment>Apr.</comment> <year>1997</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="book"><string-name><given-names>J.</given-names> <surname>Sybrandt</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Shtutman</surname></string-name>, and <string-name><given-names>I.</given-names> <surname>Safro</surname></string-name>. <chapter-title>Moliere: Automatic biomedical hypothesis generation system</chapter-title>. In <source>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD&#x2019;17</source>, pages <fpage>1633</fpage>&#x2013;<lpage>1642</lpage>, <publisher-loc>New York, NY, USA</publisher-loc>, <year>2017</year>. <publisher-name>ACM</publisher-name>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="other"><string-name><given-names>R.</given-names> <surname>Van Noorden</surname></string-name>. <article-title>Global scientific output doubles every nine years</article-title>. <source>Nature News Blog</source>, <year>2014</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><string-name><given-names>H.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Ding</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Dong</surname></string-name>, <string-name><given-names>B.</given-names> <surname>He</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Qiu</surname></string-name>, and <string-name><given-names>D. J.</given-names> <surname>Wild</surname></string-name>. <article-title>Finding complex biological relationships in recent pubmed articles using biolda</article-title>. <source>PloS one</source>, <volume>6</volume>(<issue>3</issue>):<fpage>e17243</fpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Tian</surname></string-name>, <string-name><given-names>C.-L.</given-names> <surname>Liu</surname></string-name>, and <string-name><given-names>H.</given-names> <surname>Hao</surname></string-name>. <article-title>Semantic expansion using word embedding clustering and convolutional neural network for improving short text classification</article-title>. <source>Neurocomputing</source>, <volume>174</volume>:<fpage>806</fpage>&#x2013;<lpage>814</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Weeber</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Klein</surname></string-name>, <string-name><given-names>L.</given-names> <surname>de Jong-van den Berg</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Vos</surname></string-name>, <etal>et al.</etal> <article-title>Using concepts in literature-based discovery: Simulating swanson&#x2019;s raynaud-fish oil and migraine-magnesium discoveries</article-title>. <source>Journal of the Association for Information Science and Technology</source>, <volume>52</volume>(<issue>7</issue>):<fpage>548</fpage>&#x2013;<lpage>557</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>J. D.</given-names> <surname>Wren</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Bekeredjian</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Stewart</surname></string-name>, <string-name><given-names>R. V.</given-names> <surname>Shohet</surname></string-name>, and <string-name><given-names>H. R.</given-names> <surname>Garner</surname></string-name>. <article-title>Knowledge discovery by automated identification and ranking of implicit relationships</article-title>. <source>Bioinformatics</source>, <volume>20</volume>(<issue>3</issue>):<fpage>389</fpage>&#x2013;<lpage>398</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="book"><string-name><given-names>M.</given-names> <surname>Yetisgen-Yildiz</surname></string-name> and <string-name><given-names>W.</given-names> <surname>Pratt</surname></string-name>. <chapter-title>Evaluation of literature-based discovery systems</chapter-title>. In <source>Literature-based discovery</source>, pages <fpage>101</fpage>&#x2013;<lpage>113</lpage>. <publisher-name>Springer</publisher-name>, <year>2008</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>