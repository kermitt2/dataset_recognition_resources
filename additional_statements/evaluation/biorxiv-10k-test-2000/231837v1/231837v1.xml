<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/231837</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Animal Behavior and Cognition</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Remembrance of Inferences Past</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Dasgupta</surname><given-names>Ishita</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Schulz</surname><given-names>Eric</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Goodman</surname><given-names>Noah D.</given-names></name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Gershman</surname><given-names>Samuel J.</given-names></name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Physics and Center for Brain Science, Harvard University</institution>, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Psychology, Harvard University</institution>, Cambridge, Massachusetts, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Department of Psychology, Stanford University</institution>, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Department of Psychology and Center for Brain Science, Harvard University</institution>, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Correspondence concerning this article should be addressed to Ishita Dasgupta, Department of Physics and Center for Brain Science, Harvard University, 52 Oxford Street, Room 295.08, Cambridge, MA 02138, United States. E-mail: <email>idasgupta@physics.harvard.edu</email>.</corresp>
<fn id="n1"><p>A preliminary version of this work was previously reported in Dasgupta, Schulz, Goodman, and Gershman (2017).</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date><elocation-id>231837</elocation-id>
<history>
<date date-type="received">
<day>09</day>
<month>12</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>09</day>
<month>12</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>12</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="231837.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract><title>Abstract</title>
<p>Bayesian models of cognition assume that people compute probability distributions over hypotheses. However, the required computations are frequently intractable or prohibitively expensive. Since people often encounter many closely related distributions, selective reuse of computations (amortized inference) is a computationally efficient use of the brain&#x2019;s limited resources. We present three experiments that provide evidence for amortization in human probabilistic reasoning. When sequentially answering two related queries about natural scenes, participants&#x2019; responses to the second query systematically depend on the structure of the first query. This influence is sensitive to the content of the queries, only appearing when the queries are related. Using a cognitive load manipulation, we find evidence that people amortize summary statistics of previous inferences, rather than storing the entire distribution. These findings support the view that the brain trades off accuracy and computational cost, to make efficient use of its limited cognitive resources to approximate probabilistic inference.</p>
</abstract>
<counts>
<page-count count="41"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><title>Remembrance of Inferences Past</title>
<p><italic>&#x201C;Cognition is recognition.&#x201D;</italic></p>
<p><xref ref-type="bibr" rid="c22">Hofstadter (1995)</xref></p>
</sec>
<sec id="s2"><title>Introduction</title>
<p>Many theories of probabilistic reasoning assume that human brains are equipped with a general-purpose inference engine that can be used to answer arbitrary queries for a wide variety of probabilistic models (<xref ref-type="bibr" rid="c16">Griffiths, Vul, &#x0026; Sanborn, 2012</xref>; <xref ref-type="bibr" rid="c35">Oaksford &#x0026; Chater, 2007</xref>). For example, given a joint distribution over objects in a scene, the inference engine can be queried with arbitrary conditional distributions, such as:
<list list-type="bullet">
<list-item><p>What is the probability of a microwave given that I&#x2019;ve observed a sink?</p></list-item>
<list-item><p>What is the probability of a toaster given that I&#x2019;ve observed a sink and a microwave?</p></list-item>
<list-item><p>What is the probability of a toaster and a microwave given that I&#x2019;ve observed a sink?</p></list-item>
</list>
The nature of the inference engine that answers such queries is still an open research question, though many theories posit some form of approximate inference using Monte Carlo sampling (e.g., <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>; <xref ref-type="bibr" rid="c7">Denison, Bonawitz, Gopnik, &#x0026; Griffiths, 2013</xref>; <xref ref-type="bibr" rid="c14">Gershman, Vul, &#x0026; Tenenbaum, 2012</xref>; <xref ref-type="bibr" rid="c41">Sanborn &#x0026; Chater, 2016</xref>; <xref ref-type="bibr" rid="c46">Thaker, Tenenbaum, &#x0026; Gershman, 2017</xref>; <xref ref-type="bibr" rid="c51">Ullman, Goodman, &#x0026; Tenenbaum, 2012</xref>; <xref ref-type="bibr" rid="c52">Vul, Goodman, Griffiths, &#x0026; Tenenbaum, 2014</xref>).</p>
<p>The flexibility and power of such a general-purpose inference engine trades off against its computational efficiency: by treating each query distribution independently, an inference engine forgoes the opportunity to reuse computations across queries. Every time a distribution is queried, past computations are ignored and answers are produced anew&#x2014;the inference engine is memoryless, a property that makes it statistically accurate but inefficient in environments with overlapping queries. Continuing the scene inference example, answering the third query should be easily computable once the first two queries have been computed. Mathematically, the answer can be expressed as:
<disp-formula id="eqn1"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_eqn1.gif"/></alternatives></disp-formula>
Even though this is a trivial example, standard inference engines do not exploit these kinds of regularities because they are memoryless&#x2014;they have no access to traces of past computations.</p>
<p>An inference engine may gain efficiency by incurring some amount of bias due to reuse of past computations&#x2014;a strategy we will refer to as <italic>amortized inference</italic> (<xref ref-type="bibr" rid="c12">Gershman &#x0026; Goodman, 2014</xref>; <xref ref-type="bibr" rid="c44">Stuhlm&#x00FC;ller, Taylor, &#x0026; Goodman, 2013</xref>). For example, if the inference engine stores its answers to the &#x201C;toaster&#x201D; and &#x201C;microwave&#x201D; queries, then it can efficiently compute the answer to the &#x201C;toaster or microwave&#x201D; query without rerunning inference from scratch. More generally, the posterior can be approximated as a parametrized function, or <italic>recognition model,</italic> that maps data in a bottom-up fashion to a distribution over hypotheses, with the parameters trained to minimize the divergence between the approximate and true posterior. <xref ref-type="fn" rid="fn1">1</xref> By sharing the same recognition model across multiple queries, the recognition model can support rapid inference, but is susceptible to &#x201C;interference&#x201D; across different queries.</p>
<p>Amortization has a long history in machine learning; the <italic>locus classicus</italic> is the Helmholtz machine (<xref ref-type="bibr" rid="c6">Dayan, Hinton, Neal, &#x0026; Zemel, 1995</xref>; <xref ref-type="bibr" rid="c21">Hinton, Dayan, Frey, &#x0026; Neal, 1995</xref>), which uses samples from the generative model to train a recognition model. More recent extensions and applications of this approach (e.g., <xref ref-type="bibr" rid="c26">Kingma &#x0026; Welling, 2013</xref>; <xref ref-type="bibr" rid="c37">Paige &#x0026; Wood, 2016</xref>; <xref ref-type="bibr" rid="c38">Rezende, Mohamed, &#x0026; Wierstra, 2014</xref>; <xref ref-type="bibr" rid="c39">Ritchie, Thomas, Hanrahan, &#x0026; Goodman, 2016</xref>) have ushered in a new era of scalable Bayesian computation in machine learning. We propose that amortization is also employed by the brain (see <xref ref-type="bibr" rid="c55">Yildirim, Kulkarni, Freiwald, &#x0026; Tenenbaum, 2015</xref>, for a related proposal), flexibly reusing past inferences in order to efficiently answer new but related queries. The key behavioral prediction of amortized inference is that people will show correlations in their judgments across related queries.</p>
<p>We report 3 experiments that test this prediction using a variant of the probabilistic reasoning task previously studied by <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, and Gershman (2017)</xref>. In this task, participants answer queries about objects in scenes, much like in the examples given above. Crucially, the hypothesis space is combinatorial because participants have to answer questions about sets of objects (e.g., &#x201C;All objects starting with the letter S&#x201D;). This renders exact inference intractable: the hypothesis space cannot be efficiently enumerated. In our previous work (<xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>), we argued that people approximate inference in this domain using a form of Monte Carlo sampling. Although this algorithm is asymptotically exact, only a small number of samples can be generated due to cognitive limitations, thereby revealing systematic cognitive biases such as anchoring and adjustment, subadditivity, and superadditivity (see also <xref ref-type="bibr" rid="c29">Lieder, Griffiths, Huys, &#x0026; Goodman, 2017a</xref>, <xref ref-type="bibr" rid="c30">2017b</xref>; <xref ref-type="bibr" rid="c52">Vul et al., 2014</xref>).</p>
<p>We show that the same algorithm can be generalized to reuse inferential computations in a manner consistent with human behavior. First we describe how amortization might be used by the mind. We consider two crucial questions about how this might be implemented: what parts of previous calculations do people reuse &#x2014;all previous memories or summaries of the calculations&#x2014; and when do they choose to reuse their amortized calculations. Next we test these questions empirically. In Experiment 1, we demonstrate that people do use amortization by showing that there is a lingering influence of one query on participants&#x2019; answers to a second, related query. In Experiment 2, we explore what is reused, and find that people use summary statistics of their previously generated hypotheses, rather than the hypotheses themselves. Finally, in Experiment 3, we show that people are more likely to reuse previous computations when those computations are most likely to be relevant: when a second cue is similar to a previously evaluated one.</p>
</sec>
<sec id="s3"><title>Hypothesis generation and amortization</title>
<p>Before describing the experiments, we provide an overview of our theoretical framework. First, we describe how Monte Carlo sampling can be used to approximate Bayesian inference, and summarize the psychological evidence for such an approximation. We then introduce amortized inference as a generalization of this framework.</p>
<sec id="s3a"><title>Monte Carlo sampling</title>
<p>Bayes&#x2019; rule stipulates that the posterior distribution is obtained as a normalized product of the likelihood <italic>P(d\h)</italic> and the prior <italic>P(h):</italic>
<disp-formula id="eqn2"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_eqn2.gif"/></alternatives></disp-formula>
where H is the hypothesis space. Unfortunately, Bayes&#x2019; rule is computationally intractable for all but the smallest hypothesis spaces, because the denominator requires summing over all possible hypotheses. This intractability is especially prevalent in combinatorial space, where hypothesis spaces are exponentially large. In the scene inference example, &#x1D4D7; = h<sub>1</sub> &#x00D7; h<sub>2</sub> &#x00D7;&#x2026;<italic>h<sub>K</sub></italic> is the product space of latent objects, so if there are <italic>K</italic> latent objects and <italic>M</italic> possible objects, &#x007C;&#x1D4D7;&#x007C; = <italic>M<sub>K</sub></italic>. If we imagine there are <italic>M =</italic> 1000 kinds of objects, then it only takes <italic>K</italic> = 26 latent objects for the number of hypotheses to exceed the number of atoms in the universe.</p>
<p>Monte Carlo methods approximate probability distributions with samples <italic>&#x03B8; = &#x007B;h<sub>1</sub>,&#x2026;,h<sub>N</sub></italic>&#x007D; from the posterior distribution over the hypothesis space. We can understand Monte Carlo methods as producing a recognition model <italic>Q<sub>&#x03B8;</sub>(h&#x007C;d)</italic> parametrized by <italic>&#x03B8;</italic> (see <xref ref-type="bibr" rid="c40">Saeedi, Kulkarni, Mansinghka, &#x0026; Gershman, 2017</xref>, for a systematic treatment). In the idealized case, each hypothesis is sampled from <italic>P(h&#x007C;d).</italic> The approximation is then given by:
<disp-formula id="eqn3"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_eqn3.gif"/></alternatives></disp-formula>
where I&#x005B;&#x00B7;&#x005D; = 1 if its argument is true (and 0 otherwise). The accuracy of this approximation improves with <italic>N</italic>, but from a decision-theoretic perspective even small <italic>N</italic> may be serviceable (<xref ref-type="bibr" rid="c13">Gershman, Horvitz, &#x0026; Tenenbaum, 2015</xref>; <xref ref-type="bibr" rid="c29">Lieder et al., 2017a</xref>; <xref ref-type="bibr" rid="c52">Vul et al., 2014</xref>).</p>
<p>The key challenge in applying Monte Carlo methods is that generally we do not have access to samples from the posterior. Most practical methods are based on sampling from a more convenient distribution, weighting or selecting the samples in a way that preserves the asymptotic correctness of the approximation (<xref ref-type="bibr" rid="c32">MacKay, 2003</xref>). We focus on Markov chain Monte Carlo (MCMC) methods, the most widely used class of approximations, which are based on simulating a Markov chain whose stationary distribution is the posterior. In other words, if one samples from the Markov chain for long enough, eventually <italic>h</italic> will be sampled with frequency proportional to its posterior probability.</p>
<p>A number of findings suggest that MCMC is a psychologically plausible inference algorithm. Many implementations use a form of local stochastic search, proposing and then accepting or rejecting hypotheses. For example, the classic Metropolis-Hastings algorithm first samples a new hypothesis <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_inline1.gif"/></alternatives></inline-formula> from a proposal distribution <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_inline2.gif"/></alternatives></inline-formula> and then accepts this proposal with probability
<disp-formula id="eqn4"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_eqn4.gif"/></alternatives></disp-formula>
Intuitively, this Markov chain will tend to move from lower to higher probability hypotheses, but will also sometimes &#x201C;explore&#x201D; low probability hypotheses. In order to ensure that a relatively high proportion of proposals are accepted, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_inline3.gif"/></alternatives></inline-formula> is usually constructed to sample proposals from a local region around <italic>h<sub>n</sub>.</italic> This combination of locality and stochasticity leads to a characteristic pattern of small inferential steps punctuated by occasional leaps, much like the processes of conceptual discovery in childhood (<xref ref-type="bibr" rid="c51">Ullman et al., 2012</xref>) and creative insight in adulthood (<xref ref-type="bibr" rid="c45">Suchow, Bourgin, &#x0026; Griffiths, 2017</xref>). Even low-level visual phenomena like perceptual multistability can be described in these terms (<xref ref-type="bibr" rid="c14">Gershman et al., 2012</xref>; <xref ref-type="bibr" rid="c34">Moreno-Bote, Knill, &#x0026; Pouget, 2011</xref>).</p>
<p>Another implication of MCMC, under the assumption that a small number of hypotheses are sampled, is that inferences will tend to show anchoring effects (i.e., a systematic bias towards the initial hypotheses in the Markov chain). Lieder and colleagues have shown how this idea can account for a wide variety of anchoring effects observed in human cognition (<xref ref-type="bibr" rid="c28">Lieder, Griffiths, &#x0026; Goodman, 2012</xref>; <xref ref-type="bibr" rid="c30">Lieder et al., 2017b</xref>). For example, priming someone with an arbitrary number (e.g., the last 4 digits of their social security number) will bias a subsequent judgment (e.g., about the birth date of Gandhi), because the arbitrary number influences the initialization of the Markov chain.</p>
<p>In previous research (<xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>), we have shown that MCMC can account for many other probabilistic reasoning &#x201C;fallacies,&#x201D; suggesting that they arise not from a fundamental misunderstanding of probability, but rather from the inevitable need to approximate inference with limited cognitive resources. We explored this idea using the scene inference task introduced in the previous section. The task facing subjects in our experiments was to judge the probability of a particular set of latent objects (the hypothesis, h) in a scene conditional on observing one object (the cue, d). By manipulating the framing of the query, we showed that subjects gave different answers to formally equivalent queries. In particular, by partially unpacking the queried object set (where fully unpacking an object set means to present it explicitly as a union of each of its member objects) into a small set of exemplars and a &#x201C;catch-all&#x201D; hypothesis (e.g., &#x201C;what is the probability that there is a chair, a computer, or any other object beginning with C?&#x201D;), we found that subjects judged the probability to be higher when the unpacked exemplars were typical (a &#x201C;subadditivity&#x201D; effect; cf. <xref ref-type="bibr" rid="c50">Tversky &#x0026; Koehler, 1994</xref>) and lower when the unpacked exemplars were atypical (a &#x201C;superadditivity&#x201D; effect; cf. <xref ref-type="bibr" rid="c42">Sloman, Rottenstreich, Wisniewski, Hadjichristidis, &#x0026; Fox, 2004</xref>) compared to when the query is presented without any unpacking.</p>
<p>To provide a concrete example, in the presence of the cue &#x201C;table,&#x201D; the typically unpacked query &#x201C;what is the probability that there is also a chair, a computer, or any other object beginning with C?&#x201D; generates higher probability estimates relative to the packed query &#x201C;what is the probability that there is another object beginning with C?&#x201D;, whereas the atypically unpacked query &#x201C;what is the probability that there is also a cow, a canoe, or any other object beginning with C?&#x201D; generates lower probability estimates compared to the packed query.</p>
<p>We were able to account for these effects using MCMC under the assumption that the unpacked exemplars initialize the Markov chain that generates the sample set. Because the initialization of the Markov chain transiently determines its future trajectory, initializing with typical examples causes the chain to tarry in the high probability region of the queried object set, thereby increasing its judged probability (subadditivity). In contrast, initializing with atypical examples causes the chain to get more easily derailed into regions outside the queried object set. This decreases the judged probability of the queried object set (superadditivity). The strength of these effects theoretically diminishes with the number of samples, as the chain approaches its stationary distribution. Accordingly, experimental manipulations that putatively reduce the number of samples, such as response deadlines and cognitive load, moderate this effect (<xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>). The experiments reported in this paper build on these findings, using subadditivity and superadditivity in the scene inference paradigm to detect behavioral signatures of amortized inference.</p>
</sec>
<sec id="s3b"><title>Amortized inference</title>
<p>As defined in the previous section, Monte Carlo sampling is memoryless, approximating <italic>P(h&#x007C;d)</italic> without reference to other conditional distributions that have been computed in the past; all the hypothesis samples are specific to a particular query, and thus there can be no cumulative improvement in approximation accuracy across multiple queries. However, a moment&#x2019;s reflection suggests that people are capable of such improvement. Every time you look out your window, you see a slightly different scene, but it would be wasteful to recompute a posterior over objects from scratch each time; if you did, you would be no faster at recognizing and locating objects the millionth time compared to the first time. Indeed, experimental research has found considerable speed-ups in object recognition and visual search when statistical regularities can be exploited (<xref ref-type="bibr" rid="c36">Oliva &#x0026; Torralba, 2007</xref>).</p>
<p>Amortized inference is a generalization of the standard memoryless framework. We will formulate it in the most general possible terms, and later explore more specific variants.</p>
<p><xref ref-type="fig" rid="fig1">Figure 1</xref> illustrates the basic idea. In the standard, memoryless framework, an inference engine inverts a generative model <italic>P(d,h)</italic> over hypothesis <italic>h</italic> and data <italic>d</italic> to compute a recognition model <italic>Q<sub>&#x03B8;</sub></italic>(h&#x007C;d) parametrized by &#x03B8;. For example, Monte Carlo methods use a set of samples to parametrize the recognition model. Importantly, the answer to each query is approximated using a different set of parameters (e.g., independent samples)&#x2014;<italic>Q<sub>&#x03B8;1</sub></italic> (h&#x007C;d<sub>1</sub>), <italic>Q<sub>&#x03B8;2</sub></italic> (h&#x007C;d<sub>2</sub>), etc. In the amortized framework, parameters are shared across queries. The parameters are selected to accurately approximate not just a single query, but a <italic>distribution</italic> of queries. If cognitive resources are unbounded, then the optimal solution is to parametrize each query separately, thereby recovering the memoryless framework. Under bounded resources, a finite number of parameters must be shared between multiple queries, leading to memory effects: the answer to one query affects the answer to other, similar queries.</p>
<fig id="fig1" position="float"><label>Figure 1.</label>
<caption><title>Theory schematic. (Left) Standard, memoryless framework in which a recognition model <italic>Q<sub>&#x03B8;</sub>(h&#x007C;d)</italic> approximates the posterior over hypothesis <italic>h</italic> given data <italic>d.</italic> The recognition model is parametrized by <italic>&#x03B8;</italic> (e.g., a set of samples in the case of Monte Carlo methods). Memoryless inference builds a separate recognition model for each query. (Right) Amortized framework, in which the recognition model shares parameters across queries. After each new query, the recognition model updates the shared parameters. In this way, the model &#x201C;learns to infer.&#x201D;</title></caption>
<graphic xlink:href="231837_fig1.tif"/>
</fig>
<p>While reuse increases computational efficiency, it can cause errors in two ways. First, if amortization is deployed not only when two queries are identical but also when they are similar, then answers will be biased due to blurring together of the distributions. This is analogous to interference effects in memory. Second, the answer to the first query might itself have been inaccurate or biased, so its reuse will propagate that inaccuracy to the second query&#x2019;s answer. Our experiments focus on the second type of error. Specifically, we will investigate how the over- or underestimation of unpacked probabilities resulting from approximate inference for one query will continue to influence responses to a second query.</p>
</sec>
<sec id="s3c"><title>Two amortization strategies</title>
<p>In our experiments, we ask participants to sequentially answer pairs of queries (denoted <italic>Ql</italic> and <italic>Q2</italic>). In Experiment 2, both queries are conditioned on the same cue object <italic>(d),</italic> but with varying query object sets <italic>(h)</italic>. That is, both questions are querying the same probability distribution over objects, but eliciting the probabilities of different objects in each case. So in theory, all samples taken to answer query 1, can be reused to answer query 2 (they are both samples from the same distribution). This <italic>sample reuse</italic> strategy allows all computations carried out for query 1 to be reused to answer query 2. However, it is expensive, because each sample must be stored in memory. A less memory-intensive solution is to store and reuse summary statistics of the generated samples, rather than the samples themselves. This <italic>summary reuse</italic> strategy offers greater efficiency but less flexibility. Several more sophisticated amortization schemes have been developed in the machine learning literature (e.g., <xref ref-type="bibr" rid="c37">Paige &#x0026; Wood, 2016</xref>; <xref ref-type="bibr" rid="c38">Rezende et al., 2014</xref>; <xref ref-type="bibr" rid="c44">Stuhlm&#x00FC;ller et al., 2013</xref>), but we focus on sample and summary reuse because they make clear experimental predictions, which we elaborate below.</p>
<p>In the context of our experiments, summary reuse is only applicable to problems where the answer to <italic>Q2</italic> can be expressed as the composition of the answer to <italic>Q1</italic> and another (putatively simpler) computation. In Experiment 2, <italic>Q2</italic> queries a hypothesis space that is the union of the hypothesis space queried in <italic>Q1</italic> and a disjoint hypothesis space. For example if <italic>Q1</italic> is &#x201C;What is the probability that there is an object starting with a C in the scene?&#x201D;, <italic>Q2</italic> could be &#x201C;What is the probability that there is an object starting with a C or an R in the scene?&#x201D;. In this case, samples generated in response to <italic>Q1</italic> are summarized by a single number (&#x201C;the probability of an object starting with C&#x201D;), new samples are generated in response to a simpler query (&#x201C;the probability of an object starting with R&#x201D;), and these two numbers are then composed (in this case added) to give the final estimate for <italic>Q2</italic> (&#x201C;the probability of an object starting with C or R&#x201D;). This is possible because both queries are functions of the same probability distribution over latent objects.</p>
<p>These strategies are simplifications of what the brain is likely doing. Re-using all the samples exactly is unreasonably resource intensive, and re-using only the exact statistic in the few places that the second query can be expressed as a composition of the first query and a simpler computation is unreasonably inflexible. We do not claim that either extreme is plausible, but &#x2014;to a first approximation&#x2014; they capture the key ideas motivating our theoretical framework, and more importantly, they make testable predictions which can be used to assess which extreme pulls more weight in controlled experiments.</p>
<p>In particular, sample-based and summary-based amortization strategies make different predictions about how subadditivity and superadditivity change as a function of the sample size (<xref ref-type="fig" rid="fig2">Figure 2</xref>, details of these implementations can be found in the Appendix). For sample-based amortization, as the sample size for <italic>Q1</italic> grows, the effect for <italic>Q2</italic> asymptotically <italic>diminishes</italic> and eventually vanishes as the effect of biased initialization in <italic>Q1</italic> washes out. However, initially increasing the sample size for <italic>Q1</italic> also <italic>amplifies</italic> the effects for <italic>Q2</italic> under a sample-based scheme, because this leads to more biased <italic>Q1</italic> samples being available for reuse. The amplification effect dominates up to a sample size of around 230 (estimate for the number of samples taken for inference in this domain, reported in <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>). This effect can be counteracted by increasing the sample size for <italic>Q2</italic>. These are unbiased samples, since <italic>Q2</italic> is always presented as a packed query. More such samples will push the effect down by drowning out the bias with additional unbiased samples.</p>
<fig id="fig2" position="float"><label>Figure 2.</label>
<caption><title>Simulation of subadditivity and superadditivity effects under sample-based (top) and summary-based (bottom) amortization strategies. In all panels, the y-axis represents the unstandardized effect size for <italic>Q2</italic>. Left panels show the effects of changing the sample size for <italic>Q1</italic>; right panels show the effects of changing the sample size for <italic>Q2.</italic> When sample size for one query is changed, sample size for the other query is held fixed at 230 (the sample size estimated by <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>).</title></caption>
<graphic xlink:href="231837_fig2.tif"/>
</fig>
<p>Under a summary-based strategy, increasing the sample size for <italic>Q1</italic> will only <italic>diminish</italic> the effects for <italic>Q2</italic>, because the bias from <italic>Q1</italic> is strongest when the chain is close to its starting point. The effect of early, biased samples on the summary statistic disappears with more samples. We see also that changing the number of samples for <italic>Q2</italic> does not influence the effect size because the initialization of the chain for <italic>Q2</italic> is not influenced by the samples or summary statistic from the answer to <italic>Q1</italic>. Under the summary-based strategy, the subadditivity and superadditivity effects for <italic>Q2</italic> derive entirely from the same effects for <italic>Q1</italic>, which themselves are driven by the initialization (see <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>).</p>
<p>We test the different predictions of these strategies by placing people under cognitive load during either <italic>Q1</italic> or <italic>Q2</italic> in Experiment 2, a manipulation that is expected to reduce the number of produced samples (<xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>; <xref ref-type="bibr" rid="c46">Thaker et al., 2017</xref>). In this way, we can sample different parts of the curves shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p>
</sec>
<sec id="s3d"><title>Adaptive amortization</title>
<p>Amortization is not always useful. As we have already mentioned, it can introduce systematic bias into probabilistic judgments. This is especially true if samples or summary statistics are transferred between two dissimilar distributions. This raises the question: are human amortization algorithms adaptive? This question is taken up empirically in Experiment 3. Here we discuss some of the theoretical issues.</p>
<p>Truly adaptive amortization requires a method to assess similarities between queries. Imagine as an example the situation in which there is a &#x201C;chair&#x201D; in the scene and you have to evaluate the probability of any object starting with a &#x201C;P&#x201D;. If afterwards you are told that there is a &#x201C;book&#x201D; in another scene, and the task is again to evaluate the probability of any object starting with a &#x201C;P&#x201D;, it could be a viable strategy to reuse at least some of the previous computations. However, in order to do so efficiently, you would have to know how similar a chair is to a book, i.e. if they occur with a similar set of other objects on average. One way to quantify this similarity is by assessing the induced posterior over all objects conditioned on either &#x201C;book&#x201D; or &#x201C;chair&#x201D;, and then comparing the two resulting distributions directly. Cues that are more similar should co-occur with other objects in similar proportions.</p>
<p>To assess the similarity of two distributions over objects induced by two different cues, we will need a formal similarity measure. One frequently used measure of similarity between two probability distribution is the Kullback-Leibler (KL) divergence. For two discrete probability distributions <italic>Q</italic> and <italic>P</italic>, the KL divergence between <italic>P</italic> and <italic>Q</italic> is defined as
<disp-formula id="eqn5"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_eqn5.gif"/></alternatives></disp-formula>
The KL divergence is minimized to 0 when <italic>Q</italic> and <italic>P</italic> are identical. We will use this measure in Experiment 3 to select queries that are either similar or dissimilar, in order to examine whether our participants only exhibit signatures of amortization when the queries are similar.<xref ref-type="fn" rid="fn2">2</xref> Note, however, that the exact calculation of these divergences cannot be part of the algorithmic machinery used by humans to assess similarity, since it presupposes access to the posterior being approximated. Our experiments do not yet provide insight into how humans might achieve tractable adaptive amortization, a problem we leave to future research.</p>
</sec>
</sec>
<sec id="s4"><title>Experiment 1</title>
<p>In Experiment 1, we seek initial confirmation of our central hypothesis: human inference is not memoryless. To detect these &#x201C;remembrances of inferences past&#x201D;, we ask participants to answer pairs of queries sequentially. The first query is manipulated (by packing or unpacking the queried hypothesis) in such a way that subadditive or superadditive probability judgments can be elicited (<xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>). Crucially, the second query is always presented in packed form, so any differences across the experimental conditions in answers to the second query can only be attributed to the lingering effects of the first query.</p>
<sec id="s4a"><title>Participants</title>
<p>84 participants (53 males, mean age=32.61, SD=8.79) were recruited via Amazon&#x2019;s Mechanical Turk and received &#x0024;0.50 for their participation plus an additional bonus of &#x0024;0.10 for every on-time response.</p>
</sec>
<sec id="s4b"><title>Procedure</title>
<p>Participants were asked to imagine playing a game in which their friend sees a photo and then mentions one particular object present in the photo (the cued object). The participant is then queried about the probability that another class of objects (e.g., &#x201C;objects beginning with the letter B&#x201D;) is also present in the photo.</p>
<p>Each participant completed 6 trials, where the stimuli on every trial corresponded to the rows in <xref ref-type="table" rid="tbl1">Table 1</xref>. On each trial, participants first answered <italic>Q1</italic> given the cued object (for example, &#x201C;I see a lamb in this photo. What is the probability that I also see a window, a wardrobe, a wine rack, or any other object starting with a W?&#x201D;), using a slider bar to report the conditional probability using values between 0 (not at all likely) to 100 (very likely, see also <xref ref-type="fig" rid="fig3">Figure 3</xref>). The <italic>Q1</italic> framing (typical-unpacked, atypical-unpacked or packed) was chosen randomly. Participants then completed the same procedure for <italic>Q2</italic> (immediately after <italic>Q1</italic>), conditional on the same cued object. The framing for <italic>Q2</italic> was always packed and <italic>Q2</italic> was always presented as a conjunction (for example, &#x201C;What is the probability I see an object starting with a W or F?&#x201D;), where the order of the letters was determined at random.</p>
<fig id="fig3" position="float"><label>Figure 3.</label>
<caption><title>Experimental setup. Participants were asked to estimate the conditional probability using a slider bar within a 20-second time limit.</title></caption>
<graphic xlink:href="231837_fig3.tif"/>
</fig>
<table-wrap id="tbl1" position="float"><label>Table 1</label>
<caption><title>Experimental stimuli and queries for Experiment 1.</title></caption>
<graphic xlink:href="231837_tbl1.tif"/>
</table-wrap>
</sec>
<sec id="s4c"><title>Results</title>
<p>Six participants were excluded from the following analysis, four of which failed to respond on time in more than half of the questions, and two of which entered the same response throughout.</p>
<p>Consistent with our previous studies (<xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>), we found both subadditivity and superadditivity effects for <italic>Q1</italic>, depending on the unpacking: probability judgments were higher for unpacked-typical queries than for packed queries (a subadditivity effect; 59.35 vs. 49.67; <italic>t(77)</italic> = 4.03,<italic>p</italic> &#x003C; 0.001) and lower for unpacked-atypical than for packed queries (a superadditivity effect; 31.42 vs. 49.67; <italic>t(77)</italic> = &#x2014;6.44,<italic>p</italic> &#x003C; 0.001).</p>
<p>Next we calculated the difference between each participant&#x2019;s response to every query and the mean packed response to the same queried object. This difference was then entered as a dependent variable into a linear mixed effects regression with random effects for both participants and queried objects as well as a fixed effect for the condition. The resulting estimates revealed both a significant subadditivity (difference = 12.60 &#x00B1; 1.25, t(610.49) = 10.083, <italic>p</italic> &#x003C; 0.0001) and superadditivity (difference = &#x2014;15.69 &#x00B1; 1.32, t(615.46) = &#x2014;11.89, <italic>p</italic> &#x003C; 0.0001) effect.</p>
<p>Additionally, we found evidence that participants reused calculations from <italic>Q1</italic> for <italic>Q2</italic>: even though all <italic>Q2</italic> queries were presented in the same format (as packed), the estimates for that query differed depending on how <italic>Q1</italic> was presented. In particular, estimates for <italic>Q2</italic> were lower when <italic>Q1</italic> was unpacked to atypical exemplars (46.38 vs 56.83; t(77) = 5.08, <italic>p</italic> &#x003C; 0.001), demonstrating a superadditivity effect that carried over from one query to the next. We did not find an analogous carry-over effect for subadditivity (58.47 vs. 56.83; t(77) = 0.72, <italic>p</italic> = 0.4), possibly due to the subadditivity effect &#x201C;washing out&#x201D; more quickly (i.e. with fewer samples) than superadditivity, as has been observed in this domain before (see <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>).</p>
<p>We calculated the difference between each participant&#x2019;s response for every <italic>Q2</italic> and the mean response for the same object averaged over all responses to <italic>Q2</italic> conditional on <italic>Q1</italic> being packed. The resulting difference was again entered as the dependent variable into a linear mixed effects regression with both participants and cued object as random effects as well as condition as a fixed effect. The resulting estimates showed both a significant subadditivity (difference = 4.39 &#x00B1; 1.14, &#x00A3;(606.40) = 3.83, <italic>p</italic> &#x003C; 0.001) and superadditivity (difference = -7.86 &#x00B1; 1.21, &#x00A3;(610.41) = -6.50, <italic>p</italic> &#x003C; 0.0001) effect.</p>
<p>We calculated each participant&#x2019;s mean response to all packed hypotheses for <italic>Q2</italic> over all trials as a baseline measure and then assessed the difference between each condition&#x2019;s mean response and this mean packed response. This resulted in a measure of an average effect size for the <italic>Q2</italic> responses (how much each participant under- or overestimates different hypotheses as compared to an average packed hypothesis). Results of this calculation are shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p>
<fig id="fig4" position="float"><label>Figure 4.</label>
<caption><title>Experiment 1: Differences between <italic>Q2</italic> responses for each condition and an average packed baseline. A negative relative mean estimate indicates a superadditivity and a positive relative mean estimate a subadditivity effect. Error bars represent the standard error of the mean.</title></caption>
<graphic xlink:href="231837_fig4.tif"/>
</fig>
<p>The superadditivity effect was significantly greater than 0 (&#x00A3;(77) = 5.07, <italic>p</italic> &#x003C; 0.001). However, the subadditivity effect did not differ significantly from 0 (&#x00A3;(77) = &#x2014;0.42, <italic>p</italic> &#x003E; 0.6; see also <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>).</p>
<p>Next, we explored whether responses to <italic>Q1</italic> predicted trial-by-trial variation in responses to <italic>Q2</italic>. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows the difference between participants&#x2019; estimates for <italic>Q1</italic> and the true underlying probability of the query (as derived by letting our MCMC model run until convergence) plotted against the same difference for <italic>Q2</italic>. If participants do indeed reuse computations, then how much their estimates deviate from the underlying truth for <italic>Q1</italic> should be predictive for the deviance of their estimates for <italic>Q2</italic>.</p>
<fig id="fig5" position="float"><label>Figure 5.</label>
<caption><title>Trial-by-trial analyses of Experiment 1. Difference between <italic>Q1</italic> responses and true probability (as assessed by our MCMC model) plotted against the same quantity for <italic>Q2</italic>. Lines show the least-squares fit with standard error bands.</title></caption>
<graphic xlink:href="231837_fig5.tif"/>
</fig>
<p>We found significant positive correlations between the two queries in all conditions when aggregating across participants (average correlation: <italic>r</italic> = 0.67, <italic>p</italic> &#x003C; 0.01). The same conclusion can be drawn from analyzing correlations within participants and then testing the average correlation against 0 (<italic>r</italic> = 0.55, <italic>p</italic> &#x003C; 0.01). Moreover, the within-participant effect size (the response difference between the unpacked conditions and the packed condition) for <italic>Q1</italic> was correlated with responses to <italic>Q2</italic> for both atypical (<italic>r</italic> = 0.35, <italic>p</italic> &#x003C; 0.01) and typical (<italic>r</italic> = 0.21, <italic>p</italic> &#x003C; 0.05) unpacking conditions. This means that participants who showed greater subadditivity or superadditivity for <italic>Q1</italic> also showed correspondingly greater effects for <italic>Q2</italic>.</p>
</sec>
<sec id="s4d"><title>Discussion</title>
<p>Experiment 1 established a memory effect in probabilistic inference: answers to a query are influenced by answers to a previous query, thereby providing evidence for amortization. In particular, both a sub- and a superadditivity effect induced at <italic>Q1</italic> carried over to <italic>Q2</italic>, and participants showing stronger effects sizes for both sub- and superadditivity for <italic>Q1</italic> also showed greater effects for <italic>Q2</italic>.</p>
</sec>
</sec>
<sec id="s5"><title>Experiment 2</title>
<p>Our next experiment sought to discriminate between sample-based and summary-based amortization strategies. We follow the logic of the simulations shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, manipulating cognitive load at <italic>Q1</italic> and <italic>Q2</italic> in order to exogenously control the number of samples (see <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>; <xref ref-type="bibr" rid="c46">Thaker et al., 2017</xref>, for a similar approach).</p>
<p>In addition to cognitive load, we manipulate the &#x201C;overlap&#x201D; of <italic>Q1</italic> with <italic>Q2</italic>, by creating a new set of &#x201C;no overlap&#x201D; queries with no overlap between the hypothesis spaces of the query pairs. We predicted that we would only see a memory effect for queries with overlapping pairs. This manipulation allows us to rule out an alternative trivial explanation of our results: numerical anchoring (high answers to the first query lead to high answers to the second query). If the apparent memory effect was just due to anchoring, we would expect to see the effect regardless of query overlap, contrary to our predictions.</p>
<sec id="s5a"><title>Participants</title>
<p>80 participants (53 males, mean age=32.96, SD=11.56) were recruited from Amazon Mechanical Turk and received &#x0024;0.50 as a basic participation fee and an additional bonus of &#x0024;0.10 for every on time response as well as &#x0024;0.10 for every correctly classified digit during cognitive load trials.</p>
</sec>
<sec id="s5b"><title>Procedure</title>
<p>The procedure in Experiment 2 was largely the same as in Experiment 1, with the following differences. To probe if the memory effects arise from reuse or from numerical anchoring, we added several <italic><italic>Q2</italic></italic> queries to the list shown in <xref ref-type="table" rid="tbl1">Table 1</xref>. These <italic><italic>Q2</italic></italic> queries have no overlap with the queried hypothesis for <italic>Q1</italic> (for example, &#x2018;T or R&#x2019; instead of &#x2018;C or R&#x2019; in the trial shown in the first row in <xref ref-type="table" rid="tbl1">Table 1</xref>). In other words, these queries could not be decomposed such that the biased samples from <italic>Q1</italic> be reflected in the answer to <italic>Q2</italic>, so the sub- and super-additive effects would not be seen to carry over to <italic>Q2</italic> were reuse to occur. We refer to these queries as &#x201C;no overlap&#x201D;, in contrast to the other &#x201C;partial overlap&#x201D; queries in which one of the letters overlapped with the previously queried letter. Half of the queries had no overlap and half had partial overlap, randomly interspersed. The stimuli used in Experiment 2 are shown in <xref ref-type="table" rid="tbl2">Table 2</xref>.</p>
<table-wrap id="tbl2" position="float"><label>Table 2</label>
<caption><title>Experimental stimuli and queries for Experiment 2.</title></caption>
<graphic xlink:href="231837_tbl2.tif"/>
</table-wrap>
<p>To probe if the memory effect arises from reuse of generated samples (sample-based amortization) or reuse of summaries (summary-based amortization), we also manipulated cognitive load: on half of the trials, the cognitive load manipulation occurred at <italic>Q1</italic> and on half at <italic>Q2</italic>. A sequence of 3 different digits was presented prior to the query, where each of the digits remained on the screen for 1 second and then vanished. After their response to the query, participants were asked to make a same/different judgment about a probe sequence. Half of the probes were old and half were new.</p>
<p>We hypothesized that partial overlap would lead to a stronger amortization effects, whereas no overlap would lead to weaker effects. Furthermore, if participants are utilizing sample-based amortization, then cognitive load during <italic>Q2</italic> should increase the amortization effect: if more samples are generated during <italic>Q1</italic> (which are the samples that contain the subor superadditivity biases) and these samples are concatenated with fewer unbiased samples during <italic>Q2</italic>, then the combined samples will be dominated by biased samples from <italic>Q1</italic> and therefore show stronger effects. Vice versa, if participants are utilizing summary-based amortization, then cognitive load during <italic>Q1</italic> should increase the amortization effect: if less samples are generated during <italic>Q1</italic>, then a summary of those samples will inherit a stronger sub- or superadditivity effect such that the overall amortization effect will be stronger if the two summaries are combined (assuming that the summaries are combined with equal or close-to equal weights).</p>
</sec>
<sec id="s5c"><title>Results</title>
<p>Analyzing only the queries with partial overlap (averaging across load conditions), we found that probability judgments for <italic>Q1</italic> were higher for unpacked-typical compared to packed conditions (a subadditivity effect; t(79) = 4.38, <italic>p</italic> &#x003C; 0.001) and lower for unpacked-atypical compared to packed (a superadditivity effect; t(79) = &#x2014;4.94, <italic>p</italic> &#x003C; 0.001). These same effects occurred for <italic>Q2</italic> (unpacked-typical vs. packed: t(79) = 2.44, <italic>p</italic> &#x003C; 0.01; unpacked-atypical vs. packed: t(79) = &#x2014;1.93, <italic>p</italic> &#x003C; 0.05).</p>
<p>We again calculated the difference between each participant&#x2019;s response to every query during <italic>Q1</italic> and the overall mean response for the same query object in the packed condition. This difference was then used as the dependent variable in a linear mixed-effects regression model with participants and queried object as random effects and condition as fixed effect. The resulting estimates showed both a significant subadditivity (difference = 13.64 &#x00B1; 1.57, t(396.95) = 8.70, <italic>p</italic> &#x003C; 0.0001) and superadditivity (-14.90 &#x00B1; 1.56, t(395.48) = -9.55, <italic>p</italic> &#x003C; 0.0001) effect. Afterwards, we repeated the same analysis for responses to <italic>Q2</italic> (as in Experiment 1). This analysis again showed significant indicators of amortization as both the subadditivity (difference = 5.37 &#x00B1; 1.34, t(398.01) = 4.02, <italic>p</italic> &#x003C; 0.001) and the superadditivity effect (difference = -4.92 &#x00B1; 1.336461, t(398.01) = -3.69, <italic>p</italic> &#x003C; 0.001) were still present during <italic>Q2</italic>.</p>
<p>Next, we assessed how the memory effect was modulated by cognitive load and overlap (<xref ref-type="fig" rid="fig6">Figure 6</xref>). When cognitive load occurred during <italic>Q2</italic> and there was no overlap, none of the conditions produced an effect significantly different from 0 (all <italic>p</italic> &#x003E; 0.5). When cognitive load occurred during <italic>Q2</italic> and there was partial overlap, only typically unpacked hypotheses produced an effect significantly greater than 0 (&#x00A3;(38) = 2.14, <italic>p</italic> &#x003C; 0.05). When cognitive load occurred during <italic>Q1</italic> and there was no overlap, we found again no evidence for the conditions to differ from 0 (all <italic>p</italic> &#x003E; 0.05). Crucially, if cognitive load occurred during <italic>Q1</italic> and there was partial overlap, both conditions showed the expected subadditive (&#x00A3;(38) = 4.18, <italic>p</italic> &#x003C; 0.05) and superadditive (&#x00A3;(46) = &#x2014;1.89, <italic>p</italic> &#x003C; 0.05) effects. Moreover, calculating the average effect size of amortization for the different quadrants of <xref ref-type="fig" rid="fig6">Figure 6</xref>, the partial overlap-cognitive load at <italic>Q1</italic> condition produced the highest overall effect (d = 0.8), followed by the partial overlap-cognitive load at <italic>Q2</italic> condition (d = 0.56) and the no overlap-cognitive load at <italic>Q1</italic> condition (d = 0.42). The no overlap-cognitive load at <italic>Q2</italic> condition did not produce an effect greater than 0. Partial overlap trials were also more strongly correlated with responses during <italic>Q1</italic> than trials with no overlap (0.41 vs 0.15, &#x00A3;(157) = &#x2014;2.28, <italic>p</italic> &#x003C; 0.05).</p>
<fig id="fig6" position="float"><label>Figure 6.</label>
<caption><title>Experiment 2: Differences between <italic>Q2</italic> responses for each condition and an average packed baseline. A negative relative mean estimate indicates a superadditivity and a positive relative mean estimate a subadditivity effect. Error bars represent the standard error of the mean.</title></caption>
<graphic xlink:href="231837_fig6.tif"/>
</fig>
<p>Next, we calculated the difference between all responses to <italic>Q2</italic> and the mean responses to <italic>Q2</italic> over queried objects provided that <italic>Q1</italic> was packed. This difference was enter into a linear mixed-effects regression that contained overlap, cognitive load, and the presentation format of <italic>Q1</italic> as fixed effects and participants and the queried objects as random effects. We then assessed the interaction between cognitive load and the sub- and superadditivity conditions while controlling for overlap. The resulting estimates showed that there was a significant subadditivity (difference = 5.25 &#x00B1; 2.12, &#x00A3;(417.08) = 2.48 <italic>p</italic> &#x003C; 0.05) but no superadditivity (difference = &#x2014;3.19 &#x00B1; 2.17, &#x00A3;(419.23) = &#x2014;1.47, <italic>p</italic> = 0.17) effect when cognitive load was applied during <italic>Q2</italic>. Importantly, both the subadditivity (difference = 5.83 &#x00B1; 2.25, &#x00A3;(418.91) = 2.59, <italic>p</italic> &#x003C; 0.05) and the superadditivity (difference = &#x2014;6.86 &#x00B1; 2.21, &#x00A3;(419.80) = &#x2014;3.102, <italic>p</italic> &#x003C; 0.01) effect were present when cognitive load was applied during <italic>Q1</italic>. This finding points towards a larger amortization effect in the presence of cognitive load on <italic>Q1</italic>, thus supporting a summary-based over a sampled-based amortization scheme.</p>
<p>Further, on trials with cognitive load at <italic>Q2</italic>, participants were on average more likely to answer the probe correctly for partial overlap trials compared to no overlap trials (t(36) = 3.16, <italic>p</italic> &#x003C; 0.05). This is another signature of amortization: participants are expected to have more resources to spare for the memory task at <italic>Q2</italic> if the computations they executed for <italic>Q1</italic> are reusable in answering <italic>Q2</italic>. This also indicates that these results cannot be explained by simply initializing the chain for <italic>Q2</italic> where the chain for <italic>Q1</italic> ended, which would not have affected the required computations.</p>
<p>Interestingly, there was no evidence for a significant difference between participants&#x2019; responses to <italic>Q2</italic> under cognitive load in Experiment 2 as compared to participants&#x2019; responses to <italic>Q2</italic> in Experiment 1 when no cognitive load during both <italic>Q1</italic> or <italic>Q2</italic> was applied in Experiment 1 (t(314) = &#x2014;1.44, <italic>p</italic> = 0.15).</p>
<p>Finally, we assessed how much the difference between responses for <italic>Q1</italic> and the true underlying probabilities were predictive of the difference between responses for <italic>Q2</italic> and the true underlying probabilities (<xref ref-type="fig" rid="fig7">Figure 7</xref>). There was a strong correlation between responses to <italic>Q1</italic> and <italic>Q2</italic> over all conditions (r = 0.41, <italic>p</italic> &#x003C; 0.001), for the packed (r = 0.44, <italic>p</italic> &#x003C; 0.001), the typically unpacked (r = 0.36, <italic>p</italic> &#x003C; 0.01), as well as the atypically unpacked condition (r = 0.40, <italic>p</italic> &#x003C; 0.01). Moreover, the differences of <italic>Q1</italic> and <italic>Q2</italic> responses from the true answer were also highly correlated within participants (mean <italic>r</italic> = 0.31, <italic>p</italic> &#x003C; 0.01) and participants who showed stronger subadditivity or superadditivity effects for <italic>Q1</italic> also showed stronger effects for <italic>Q2</italic> overall (r = 0.31, <italic>p</italic> &#x003C; 0.001), for the superadditive (r = 0.3, <italic>p</italic> &#x003C; 0.001), and for the subadditive condition (r = 0.29, <italic>p</italic> &#x003C; 0.001). This replicates the effects of amortization found in Experiment 1.</p>
<fig id="fig7" position="float"><label>Figure 7.</label>
<caption><title>Trial-by-trial analyses of Experiment 2. Relationship between difference between <italic>Q1</italic> responses and true probability (as assessed by our MCMC model) and <italic>Q2</italic> responses and true probability. Lines show the least-squares fit with standard error bands.</title></caption>
<graphic xlink:href="231837_fig7.tif"/>
</fig>
</sec>
<sec id="s5d"><title>Discussion</title>
<p>Experiment 2 extended the findings of Experiment 1, suggesting constraints on the underlying amortization strategy. Participants exhibited an intricate pattern of sensitivity to cognitive load and query overlap. Based on our simulations (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we argue that the effect of cognitive load at <italic>Q1</italic> on <italic>Q2</italic> responses is more consistent with summary-based amortization than with sample-based amortization. Summary-based amortization is less flexible than sample-based amortization, but trades this inference limitation for an increase in memory efficiency, and is thus consistent with the idea that humans adopt cost-efficient resource-rational inference strategies (<xref ref-type="bibr" rid="c13">Gershman et al., 2015</xref>; <xref ref-type="bibr" rid="c15">Griffiths, Lieder, &#x0026; Goodman, 2015</xref>; <xref ref-type="bibr" rid="c29">Lieder et al., 2017a</xref>). Further supporting this idea is our finding that performance on the secondary task was better in the partial overlap conditions, indicating that more resources are available when computations can be amortized.</p>
<p>Our design allowed us to rule out a numerical anchoring effect, whereby participants would give high answers to the second query if they gave high answers to the first query. This effect should be invariant to the extent of overlap of the queried hypothesis spaces, but contrary to the anchoring hypothesis, the memory effect was stronger in the high overlap condition.</p>
</sec>
</sec>
<sec id="s6"><title>Experiment 3</title>
<p>In this experiment we try to further probe the strategic nature of amortization. So far, all generated hypotheses have been reusable, since both queries probe the same probability distribution, conditioned on the same cue object. By changing the cue object between <italic>Q1</italic> and <italic>Q2</italic> and manipulating the similarity between the cues, we can control how reusable the computations are. Note that this is in contrast to the notion of &#x201C;overlap&#x201D; in Experiment 2 where all the samples from <italic>Q1</italic> are always &#x201C;reusable&#x201D; in <italic>Q2</italic> since both query the same probability distribution, but in the no overlap conditions, the queried hypotheses spaces do not overlap resulting in the biased samples from <italic>Q1</italic> not being reflected in <italic>Q2</italic> judgments. The notion of reusability now allows us to test whether or not reuse always occurs, or if it occurs preferentially when it is more applicable (i.e., under high similarity between cues).</p>
<sec id="s6a"><title>Participants</title>
<p>100 participants (41 females, mean age=35.74, SD=11.69) were recruited from Amazon Mechanical Turk and received &#x0024;0.50 as a basic participation fee and an additional bonus of &#x0024;0.10 for every on time response.</p>
</sec>
<sec id="s6b"><title>Procedure</title>
<p>The procedure was similar to Experiments 1 and 2. The only difference was that participants were shown a new cue word for <italic>Q2</italic>, asking them to judge the probability of objects starting with the same letter as the letter from <italic>Q1</italic> with no conjunction of letters (i.e., same query space, full overlap). The query for <italic>Q2</italic> was always packed, as in previous experiments. The new cue words for <italic>Q2</italic> were generated to either have posterior with a low (similar cues) or a high (dissimilar cues) KL divergence from the <italic>Q1</italic> posterior. The range of KL divergences fell between 0 and 9; all similar cue words had conditional distributions with KL divergence of less than 0.1, and all dissimilar cue-words had a KL divergence of greater than 8.5. The exact KL divergences are reported in <xref ref-type="table" rid="tbl3">Table 3</xref>.</p>
<table-wrap id="tbl3" position="float"><label>Table 3</label>
<caption><title>Experimental stimuli and queries for Experiment 3. Kullback-Leibler (KL) divergence between the posteriors for Q1 and Q2 are shown in parentheses.</title></caption>
<graphic xlink:href="231837_tbl3.tif"/>
</table-wrap>
</sec>
<sec id="s6c"><title>Results</title>
<p>Seven participants did not respond on time to more than a half of all queries and were therefore excluded from the following analysis.</p>
<p>We again found that probability judgments for <italic>Q1</italic> in the typically unpacked queries were higher than in the unpacked condition (subadditivity effect: t(92) = 4.67, <italic>p</italic> &#x003C; 0.001) and that probability judgments in the atypically unpacked condition were lower than in the unpacked condition (superadditivity effect: t(92) = 3.25, <italic>p</italic> &#x003C; 0.01).</p>
<p>Analyzing the probability judgments for <italic>Q2</italic>, we found a significant subadditivity effect ((t(92) = 2.28, <italic>p</italic> &#x003C; 0.05) but not a significant superadditivity effect (56.06 vs. 55.31; t(92) = 0.07,p = 0.94).</p>
<p>As before, we calculated the difference between each participant&#x2019;s response to every query during <italic>Q1</italic> and the overall mean response for the same query object in the packed condition. This difference was entered as the dependent variable into a linear mixed-effects regression model with participants and queried object as random effects and condition as fixed effect. The resulting estimates showed both a significant subadditivity (difference = 14.39 &#x00B1; 1.97, t(189.84) = 7.31, <italic>p</italic> &#x003C; 0.0001) and superadditivity (&#x2014;13.72 &#x00B1; 1.98, t(190.18) = &#x2014;6.941, <italic>p</italic> &#x003C; 0.0001) effect. Repeating this analysis for responses to <italic>Q2</italic> revealed a significant amortization effect for the the subadditivity (difference = 5.21 &#x00B1; 1.90, t(191) = 2.74, <italic>p</italic> &#x003C; 0.05) but not for the superadditivity condition (difference = &#x2014;2.49 &#x00B1; 1.91, t(191.52) = &#x2014;1.303 <italic>p</italic> = 0.19).</p>
<fig id="fig8" position="float"><label>Figure 8.</label>
<caption><title>Experiment 3: Differences between <italic>Q2</italic> responses for each condition and an average packed baseline. A negative relative mean estimate indicates a superadditivity and a positive relative mean estimate a subadditivity effect. Error bars represent the standard error of the mean.</title></caption>
<graphic xlink:href="231837_fig8.tif"/>
</fig>
<p>For the dissimilar cues, we did not find statistical evidence for an effect of subadditivity (&#x00A3;(49) = 1.31, <italic>p</italic> = 0.19) or superaditivity(&#x00A3;(47) = &#x2014;0.27, <italic>p</italic> = 0.79). However, for the similar cues at <italic>Q2</italic>, the effect for the typically unpacked condition was significantly different from 0 (subadditivity effect: &#x00A3;(47) = 3.30, <italic>p</italic> &#x003C; 0.01), whereas there was again no superadditivity effect (&#x00A3;(48) = 0.54, <italic>p</italic> = 0.59). The difference between the size of the subadditivity effect was marginally bigger for the similar cues as compared to the dissimilar cues (&#x00A3;(36) = 1.83, <italic>p</italic> = 0.06) and the overall effect size of the similar cues was <italic>d</italic> = 0.17, whereas the effect size for the dissimilar cues was <italic>d</italic> = 0.11.</p>
<p>The difference between judgments and the true probabilities was correlated between <italic>Q1</italic> and <italic>Q2</italic> (r = 0.34, <italic>p</italic> &#x003C; 0.001), for the packed (r = 0.43, <italic>p</italic> &#x003C; 0.001), the typically unpacked (r = 0.43, <italic>p</italic> &#x003C; 0.001), but not the atypically unpacked condition (r = 0.20, <italic>p</italic> = 0.3); see <xref ref-type="fig" rid="fig9">Figure 9</xref>. Participants who showed higher subadditivity or superadditivity effects for <italic>Q1</italic> also showed higher effects for <italic>Q2</italic> overall (r = 0.29, <italic>p</italic> &#x003C; 0.001), for the typically unpacked condition (r = 0.39, <italic>p</italic> &#x003C; 0.001), but not for the atypically unpacked condition (r = 0.11, <italic>p</italic> = 0.29).</p>
<fig id="fig9" position="float"><label>Figure 9.</label>
<caption><title>Trial-by-trial analyses of Experiment 3. Relationship between difference between <italic>Q1</italic> responses and true probability (as assessed by our MCMC model) and <italic>Q2</italic> responses and true probability. Lines show the least-squares fit with standard error bands.</title></caption>
<graphic xlink:href="231837_fig9.tif"/>
</fig>
</sec>
<sec id="s6d"><title>Discussion</title>
<p>Experiment 3 assessed the strategic nature of amortization by manipulating the similarity between cues, which presumably affected the degree to which amortization is useful. We found a stronger subadditivity effect for similar cues compared to dissimilar cues, indicating that reuse is at least partially sensitive to similarity.</p>
<p>An unexpected finding was that while the superadditivity effect in aytpically-unpacked <italic>Q1</italic> was significant, neither the memory-based superadditivity effect (in <italic>Q2</italic>) nor correlations across the queries for atypically-unpacked <italic>Q1</italic> were significant. This indicates that the answers to the atypically-unpacked <italic>Q1</italic> are not detectably being reused in <italic>Q2</italic> in this experiment. However, in Experiments 1 and 2, the atypically-unpacked answers seem to be reused (as indicated by a robust memory-based superadditivity effect, and correlations across the queries) <italic>when the cue object remains the same</italic>. This may be because the extent of rational reuse here (where the cues change) is smaller than in previous experiments (where the cues remained the same) and therefore harder to detect. Another possible explanation for this difference in Experiment 3 is that changing the cue object engages a sort of reset, and allows people to ignore low-probability/bad samples such as the ones occurring in the atypically-unpacked condition, and therefore dismiss the stored answers to atypically-unpacked <italic>Q1</italic>. Further research is needed to investigate this possibility.</p>
</sec>
</sec>
<sec id="s7"><title>General Discussion</title>
<p>We tested a model of amortized hypothesis generation across 3 experiments and found that participants not only exhibited subadditive and superadditive probability judgments in the same paradigm (replicating <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, &#x0026; Gershman, 2017</xref>), but also carried over these effects to subsequent queries&#x2014;a memory effect on inference. Experiment 2 demonstrated that this memory effect is some function of the hypotheses generated in the first query and made some inroads into trying to understand this function. We found that the effect is stronger when cognitive load is applied to the first query, suggesting that the memory effect is driven by a form of summary-based amortization, whereby a summary statistic of the first query is computed from the samples and then reused to answer subsequent queries, provided they can be expressed in terms of previous computations. Summary-based amortization gives up some flexibility (compared to reusing the raw samples generated by past inferences), in order to gain memory-efficiency. Experiment 3 demonstrated that the memory effect selectively occurs when the queries are similar, indicating that reuse is deployed specifically when it is likely to be useful.</p>
<p>Building on earlier results (<xref ref-type="bibr" rid="c12">Gershman &#x0026; Goodman, 2014</xref>), our findings support the existence of a sophisticated inference engine that adaptively exploits past computations. While reuse can introduce error, this error may be a natural consequence of a resource-bounded system that optimally balances accuracy and efficiency (<xref ref-type="bibr" rid="c13">Gershman et al., 2015</xref>; <xref ref-type="bibr" rid="c15">Griffiths et al., 2015</xref>; <xref ref-type="bibr" rid="c28">Lieder et al., 2012</xref>; <xref ref-type="bibr" rid="c52">Vul et al., 2014</xref>). The incorporation of reuse into a Monte Carlo sampling framework allows the inference engine to preserve asymptotic exactness while improving efficiency in the finite-sample regime.</p>
<sec id="s7a"><title>Related work</title>
<p>This work fits into a larger nexus of ideas exploring the role of memory in inductive reasoning. Heit, Hayes and colleagues have carried out a number of studies that make this link explicit (<xref ref-type="bibr" rid="c17">Hawkins, Hayes, &#x0026; Heit, 2016</xref>; <xref ref-type="bibr" rid="c18">Hayes, Fritz, &#x0026; Heit, 2013</xref>; <xref ref-type="bibr" rid="c19">Hayes &#x0026; Heit, 2013</xref>; <xref ref-type="bibr" rid="c20">Heit &#x0026; Hayes, 2011</xref>). For example, <xref ref-type="bibr" rid="c20">Heit and Hayes (2011)</xref> developed a task in which participants studied a set of exemplars (large dogs that all possess &#x201C;beta cells&#x201D;) and then on a test set of exemplars (consisting of large and small dogs) made either property induction judgments (&#x201C;does this dog have beta cells?&#x201D;) or recognition memory judgments (&#x201C;did this dog appear in the study phase?&#x201D;). The key finding was that property induction and recognition memory judgments were strongly correlated across items, supporting the hypothesis that both judgments rely on a shared exemplar similarity computation: test exemplars are judged to be more familiar, and have the same latent properties, to the degree that they are similar to past exemplars. Heit and Hayes showed that both judgments could be captured by the same exemplar model, but with a broader generalization gradient for induction.</p>
<p>Another example of memory effects on inference is the observation that making a binary decision about a noisy stimulus (whether dots are moving to the left or right of a reference) influences a subsequent continuous judgment about motion direction (<xref ref-type="bibr" rid="c23">Jazayeri &#x0026; Movshon, 2007</xref>). Stocker and colleagues (<xref ref-type="bibr" rid="c31">Luu &#x0026; Stocker, 2016</xref>; <xref ref-type="bibr" rid="c43">Stocker &#x0026; Simoncelli, 2008</xref>) refer to this as &#x201C;conditioned perception&#x201D;&#x2019; or &#x201C;self-consistent inference&#x201D; because it appears as though observers are conditioning on their decision as they make a choice. <xref ref-type="bibr" rid="c11">Fleming and Daw (2017)</xref> have pushed this idea further, arguing that observers condition on their own confidence about the decision. Self-consistent inferences may reflect rational conditioning on choice or confidence information when a memory trace of the stimulus is unavailable or unreliable.</p>
<p>An intriguing explanation of order effects has been reported by Wang and colleagues (<xref ref-type="bibr" rid="c53">Wang &#x0026; Busemeyer, 2013</xref>; <xref ref-type="bibr" rid="c54">Wang, Solloway, Shiffrin, &#x0026; Busemeyer, 2014</xref>). The key idea, derived from a quantum probability model of cognition (see also <xref ref-type="bibr" rid="c49">Trueblood &#x0026; Busemeyer, 2011</xref>), is that answering a question will cause the corresponding mental state to linger and thus &#x201C;superpose&#x201D; with the mental state evoked by a second question. This superposition gives rise to a particular symmetry in the pattern of judgments when question order is manipulated, known as the <italic>quantum question order equality</italic> (see <xref ref-type="bibr" rid="c53">Wang &#x0026; Busemeyer, 2013</xref>, for details). Our amortization framework does not intrinsically make this prediction, but nor does it necessarily exclude it. Rather, we prefer to think about superposition states as arising from computational principles governing a computation-flexibility trade-off. Roughly speaking, states superpose in our framework because the inference engine is reusing information from past queries.</p>
<p>Recently, <xref ref-type="bibr" rid="c1">Costello and Watts (2018)</xref> pointed out that the quantum question order equality could arise from rational probabilistic reasoning corrupted by correlated noise. In particular, answers to a probabilistic query will be corrupted by samples retrieved recently to answer another probabilistic query (similar to the concept of &#x201C;overgeneralization&#x201D; in probabilistic estimation, as developed in <xref ref-type="bibr" rid="c33">Marchiori, Di Guida, &#x0026; Erev, 2015</xref>). <xref ref-type="bibr" rid="c1">Costello and Watts (2018)</xref> view this as a kind of priming effect. Alternatively, correlated noise would arise in the amortized inference framework due to stochastic reuse. Thus, amortization might provide a complementary rational analysis for the &#x201C;probability theory plus noise&#x201D; model proposed by <xref ref-type="bibr" rid="c1">Costello and Watts (2018)</xref>.</p>
<p>Most closely related to the present paper is the work of Dougherty and colleagues (<xref ref-type="bibr" rid="c8">Dougherty, Gettys, &#x0026; Ogden, 1999</xref>; <xref ref-type="bibr" rid="c9">Dougherty &#x0026; Hunter, 2003b</xref>, <xref ref-type="bibr" rid="c10">2003a</xref>; <xref ref-type="bibr" rid="c47">Thomas, Dougherty, Sprenger, &#x0026; Harbison, 2008</xref>; <xref ref-type="bibr" rid="c48">Thomas, Dougherty, &#x0026; Buttaccio, 2014</xref>), who have pursued the idea that probability judgments depend on the generation of hypotheses from memory. In particular, they argue that subadditivity arises from the failure to generate hypotheses, much like the account offered by <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, and Gershman (2017)</xref>, and that this failure is exacerbated by cognitive load or low working memory capacity. The key difference from our account is the particular way in which memories are used to generate hypotheses. For combinatorial hypothesis spaces like the scene inference task used here and by <xref ref-type="bibr" rid="c2">Dasgupta, Schulz, and Gershman (2017)</xref>, one cannot assume that all the relevant hypotheses are already stored in memory; rather, these must be generated on the fly&#x2014;a function we ascribe to MCMC sampling. The present paper asserts a more direct role for memory within a sampling framework, by controlling the trade-off between computation and flexibility.</p>
<p>This trade-off mirrors a similar tension in reinforcement learning, where the goal is to estimate long-term reward (<xref ref-type="bibr" rid="c4">Daw, Gershman, Seymour, Dayan, &#x0026; Dolan, 2011</xref>; <xref ref-type="bibr" rid="c5">Daw, Niv, &#x0026; Dayan, 2005</xref>; <xref ref-type="bibr" rid="c27">Kool, Gershman, &#x0026; Cushman, 2017</xref>). &#x201C;Model-based&#x201D; algorithms estimate long-term reward by applying tree search or dynamic programming to a probabilistic model of the environment. This is flexible, but computationally expensive. &#x201C;Model-free&#x201D; algorithms avoid this cost by directly estimated long-term rewards by interacting with the environment, storing these estimates in a look-up table or function approximator. This is computationally cheap but inflexible. In other words, model-free algorithms trade time for space, much in the same way that amortized inference uses memory to reduce the cost of approximate inference. Analogous to our proposed summary-based amortization strategy, recent work has suggested that model-free value estimates can be incorporated into model-based tree search algorithms (<xref ref-type="bibr" rid="c25">Keramati, Smittenaar, Dolan, &#x0026; Dayan, 2016</xref>), thus occupying a middle ground in the time-space trade-off.</p>
</sec>
<sec id="s7b"><title>Future directions</title>
<p>Our work has focused on fairly simple forms of amortization. There exists a much larger space of more sophisticated amortization strategies developed in the machine learning literature (e.g., <xref ref-type="bibr" rid="c38">Rezende et al., 2014</xref>; <xref ref-type="bibr" rid="c44">Stuhlm&#x00FC;ller et al., 2013</xref>) that we have not yet explored. Finding behaviorally distinguishable versions of these algorithms is an interesting challenge. These versions could take the form of reuse in much more abstract ways, such as developing strategies and heuristics, instead of just local reuse in a sequence of queries. We believe that further examining established effects of heuristics and biases through the lens of computational rationality will continue to produce interesting insights into principles of cognition.</p>
<p>More broadly, we are still lacking a comprehensive, mechanistic theory of amortized inference. What objective function is being optimized by amortization? How are the computational trade-offs managed algorithmically? What are the contributions of different memory mechanisms (episodic, semantic, procedural, etc.)? Answering these questions will require a more general theoretical treatment than the one offered here. Nonetheless, our experiments provide important constraints on any such theory.</p>
</sec>
<sec id="s7c"><title>Acknowledgments</title>
<p>We thank Kevin Smith for helpful comments and discussions. This material is based upon work supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF-1231216. E.S. was supported by a postdoctoral fellowship from the Harvard Data Science Initiative.</p>
</sec>
</sec>
</body>
<back>
<app-group>
<app id="app1"><label>Appendix</label><title>Two Re-use Schemes</title>
<p>The two schemes for re-use described in <xref ref-type="fig" rid="fig2">Figure 2</xref>, <italic>summary-based</italic> and <italic>sample-based</italic> amortization, are described below in greater detail.</p>
<p>In <italic>sample-based amortization</italic>, we simply add samples generated in response to one query (<italic>Q1</italic>) to the sample set for another query (<italic>Q2</italic>). So if <italic>N<sub>1</sub></italic> samples were generated in response to <italic>Q1</italic>, and <italic>N<sub>2</sub></italic> new samples are generated in response to <italic>Q2</italic>, in the absence of amortization, the responses to the two queries <italic>Q1</italic> and <italic>Q2</italic> would be generated as follows:</p>
<disp-formula id="ueqn1"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_ueqn1.gif"/></alternatives></disp-formula>
<p>Under the sample-based amortization scheme, the response to <italic>Q2</italic> is given by a calculation carried out over all N &#x002B; N2 equally weighted samples.</p>
<disp-formula id="ueqn2"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_ueqn2.gif"/></alternatives></disp-formula>
<p>Under this scheme, all the computations carried out for <italic>Q1</italic> are available for flexible reuse in the computation for <italic>Q2</italic>.</p>
<p>In <italic>summary-based amortization,</italic> we reuse a summary statistic computed from <italic>Q1</italic>. This strategy is only applicable to problems where the answer to <italic>Q2</italic> can be expressed as the composition of the answer to <italic>Q1</italic>, and an additional simpler computation. For example if <italic>Q1</italic> is &#x201C;What is the probability that there is an object starting with a C in the scene?&#x201D;, <italic>Q2</italic> could be &#x201C;What is the probability that there is an object starting with a C or an R in the scene?&#x201D;. In this case, the N samples generated in response to <italic>Q1</italic> are summarized into one probability (&#x201C;the probability of an object starting with C&#x201D;), <italic>N2</italic> new samples are generated in response to a simpler query (&#x201C;the probability of an object starting with R&#x201D;), and these two numbers are then composed (in this case simply added) to give the final estimate for <italic>Q2</italic> (&#x201C;the probability of an object starting with C or R&#x201D;).</p>
<disp-formula id="ueqn3"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="231837_ueqn3.gif"/></alternatives></disp-formula>
<p>Under this scheme, only the final product of the computation carried out for <italic>Q1</italic> is reused in the calculations for <italic>Q2</italic>.</p>
</app>
</app-group>
<ref-list><title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Costello</surname>, <given-names>F. J.</given-names></string-name>, &#x0026; <string-name><surname>Watts</surname>, <given-names>P.</given-names></string-name> (<year>2018</year>). <article-title>Invariants in probabilistic reasoning</article-title>. <source>Cognitive Psychology</source>, <volume>100</volume>, <fpage>1</fpage>-<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Dasgupta</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> (<year>2017</year>). Where do hypotheses come from? <source>Cognitive Psychology</source>, <volume>96</volume>, <fpage>1</fpage>-<lpage>25</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Dasgupta</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name>, &#x0026; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> (<year>2017</year>). <article-title>Amortized hypothesis generation</article-title>. In <source>Proceedings of the 39th annual meeting of the cognitive science society</source>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Seymour</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &#x0026; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>2011</year>). <article-title>Model-based influences on humans&#x2019; choices and striatal prediction errors</article-title>. <source>Neuron</source>, <volume>69</volume>, <fpage>1204</fpage>-<lpage>1215</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name>, &#x0026; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2005</year>). <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nature Neuroscience</source>, <volume>8</volume>, <fpage>1704</fpage>-<lpage>1711</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Hinton</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Neal</surname>, <given-names>R. M.</given-names></string-name>, &#x0026; <string-name><surname>Zemel</surname>, <given-names>R. S.</given-names></string-name> (<year>1995</year>). <article-title>The helmholtz machine</article-title>. <source>Neural Computation</source>, <volume>7</volume>, <fpage>889</fpage>-<lpage>904</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Denison</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bonawitz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Gopnik</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name> (<year>2013</year>). <article-title>Rational variability in children&#x00E2;&#x0102;&#x017A;s causal inferences: The sampling hypothesis</article-title>. <source>Cognition</source>, <volume>126</volume>, <fpage>285</fpage>-<lpage>300</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Dougherty</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Gettys</surname>, <given-names>C. F.</given-names></string-name>, &#x0026; <string-name><surname>Ogden</surname>, <given-names>E. E.</given-names></string-name> (<year>1999</year>). <article-title>MINERVA-DM: A memory processes model for judgments of likelihood</article-title>. <source>Psychological Review</source>, <volume>106</volume>, <fpage>180</fpage>-<lpage>209</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Dougherty</surname>, <given-names>M. R.</given-names></string-name>, &#x0026; <string-name><surname>Hunter</surname>, <given-names>J.</given-names></string-name> (<year>2003b</year>). <article-title>Probability judgment and subadditivity: The role of working memory capacity and constraining retrieval</article-title>. <source>Memory &#x0026; Cognition</source>, <volume>31</volume>, <fpage>968</fpage>-<lpage>982</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Dougherty</surname>, <given-names>M. R.</given-names></string-name>, &#x0026; <string-name><surname>Hunter</surname>, <given-names>J. E.</given-names></string-name> (<year>2003a</year>). <article-title>Hypothesis generation, probability judgment, and individual differences in working memory capacity</article-title>. <source>Acta Psychologica</source>, <volume>113</volume>, <fpage>263</fpage>-<lpage>282</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Fleming</surname>, <given-names>S. M.</given-names></string-name>, &#x0026; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name> (<year>2017</year>). <article-title>Self-evaluation of decision-making: A general bayesian framework for metacognitive computation</article-title>. <source>Psychological Review</source>, <volume>124</volume>, <fpage>91</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2014</year>). <article-title>Amortized inference in probabilistic reasoning</article-title>. In <source>Proceedings of the 36th Annual Conference of the Cognitive Science Society</source> (pp. <fpage>517</fpage>-<lpage>522</lpage>).</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Horvitz</surname>, <given-names>E. J.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2015</year>). <article-title>Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</article-title>. <source>Science</source>, <volume>349</volume>, <fpage>273</fpage>-<lpage>278</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Vul</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2012</year>). <article-title>Multistability and perceptual inference</article-title>. <source>Neural Computation</source>, <volume>24</volume>, <fpage>1</fpage>-<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Lieder</surname>, <given-names>F.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2015</year>). <article-title>Rational use of cognitive resources: Levels of analysis between the computational and the algorithmic</article-title>. <source>Topics in Cognitive Science</source>, <volume>7</volume>, <fpage>217</fpage>-<lpage>229</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Vul</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Sanborn</surname>, <given-names>A. N.</given-names></string-name> (<year>2012</year>). <article-title>Bridging levels of analysis for probabilistic models of cognition</article-title>. <source>Current Directions in Psychological Science</source>, <volume>21</volume>, <fpage>263</fpage>-<lpage>268</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Hawkins</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Hayes</surname>, <given-names>B. K.</given-names></string-name>, &#x0026; <string-name><surname>Heit</surname>, <given-names>E.</given-names></string-name> (<year>2016</year>). <article-title>A dynamic model of reasoning and memory</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>145</volume>, <fpage>155</fpage>-<lpage>180</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Hayes</surname>, <given-names>B. K.</given-names></string-name>, <string-name><surname>Fritz</surname>, <given-names>K.</given-names></string-name>, &#x0026; <string-name><surname>Heit</surname>, <given-names>E.</given-names></string-name> (<year>2013</year>). <article-title>The relationship between memory and inductive reasoning: Does it develop?</article-title> <source>Developmental Psychology</source>, <volume>49</volume>, <fpage>848</fpage>-<lpage>860</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Hayes</surname>, <given-names>B. K.</given-names></string-name>, &#x0026; <string-name><surname>Heit</surname>, <given-names>E.</given-names></string-name> (<year>2013</year>). <article-title>How similar are recognition memory and inductive reasoning?</article-title> <source>Memory &#x0026; Cognition</source>, <volume>41</volume>, <fpage>781</fpage>-<lpage>795</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Heit</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Hayes</surname>, <given-names>B. K.</given-names></string-name> (<year>2011</year>). <article-title>Predicting reasoning from memory</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>140</volume>, <fpage>76</fpage>-<lpage>101</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Hinton</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Frey</surname>, <given-names>B. J.</given-names></string-name>, &#x0026; <string-name><surname>Neal</surname>, <given-names>R. M.</given-names></string-name> (<year>1995</year>). <article-title>The &#x201C;wake-sleep&#x201D; algorithm for unsupervised neural networks</article-title>. <source>Science</source>, <volume>268</volume>, <fpage>1158</fpage>-<lpage>1160</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Hofstadter</surname>, <given-names>D. R.</given-names></string-name> (<year>1995</year>). <source>Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought</source>. <comment>Basic Books</comment>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Jazayeri</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name> (<year>2007</year>). <article-title>A new perceptual illusion reveals mechanisms of sensory decoding</article-title>. <source>Nature</source>, <volume>446</volume>, <fpage>912</fpage>-<lpage>915</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Jordan</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Ghahramani</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Jaakkola</surname>, <given-names>T. S.</given-names></string-name>, &#x0026; <string-name><surname>Saul</surname>, <given-names>L. K.</given-names></string-name> (<year>1999</year>). <article-title>An introduction to variational methods for graphical models</article-title>. <source>Machine Learning</source>, <volume>37</volume>, <fpage>183</fpage>-<lpage>233</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Keramati</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Smittenaar</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &#x0026; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2016</year>). <article-title>Adaptive integration of habits into depth-limited planning defines a habitual-goal-directed spectrum</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>113</volume>, <fpage>12868</fpage>-<lpage>12873</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name>, &#x0026; <string-name><surname>Welling</surname>, <given-names>M.</given-names></string-name> (<year>2013</year>). <article-title>Auto-encoding variational bayes</article-title>. The 2nd <source>International Conference on Learning Representations (ICLR)</source>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Kool</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, &#x0026; <string-name><surname>Cushman</surname>, <given-names>F. A.</given-names></string-name> (<year>2017</year>). <article-title>Cost-benefit arbitration between multiple reinforcement-learning systems</article-title>. <source>Psychological Science</source>, <volume>28</volume>, <fpage>1321</fpage>-<lpage>1333</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Lieder</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2012</year>). <article-title>Burn-in, bias, and the rationality of anchoring</article-title>. In <source>Advances in Neural Information Processing Systems</source> (pp. <fpage>2690</fpage>-<lpage>2798</lpage>).</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Lieder</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Huys</surname>, <given-names>Q. J.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2017a</year>). <article-title>The anchoring bias reflects rational use of cognitive resources</article-title>. <source>Psychonomic Bulletin &#x0026; Review</source>, <fpage>1</fpage>-<lpage>28</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Lieder</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Huys</surname>, <given-names>Q. J. M.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2017b</year>). <article-title>Empirical evidence for resource-rational anchoring and adjustment</article-title>. <source>Psychonomic Bulletin &#x0026; Review</source>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="other"><string-name><surname>Luu</surname>, <given-names>L.</given-names></string-name>, &#x0026; <string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name> (<year>2016</year>). <article-title>Choice-dependent perceptual biases</article-title>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="book"><string-name><surname>MacKay</surname>, <given-names>D. J.</given-names></string-name> (<year>2003</year>). <source>Information theory, inference and learning algorithms</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Marchiori</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Di Guida</surname>, <given-names>S.</given-names></string-name>, &#x0026; <string-name><surname>Erev</surname>, <given-names>I.</given-names></string-name> (<year>2015</year>). <article-title>Noisy retrieval models of over-and undersensitivity to rare events</article-title>. <source>Decision</source>, <volume>2</volume>, <fpage>82</fpage>-<lpage>106</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Moreno-Bote</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Knill</surname>, <given-names>D. C.</given-names></string-name>, &#x0026; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name> (<year>2011</year>). <article-title>Bayesian sampling in visual perception</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>108</volume>, <fpage>12491</fpage>-<lpage>12496</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="book"><string-name><surname>Oaksford</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Chater</surname>, <given-names>N.</given-names></string-name> (<year>2007</year>). <source>Bayesian rationality: The probabilistic approach to human reasoning</source>. <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Oliva</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Torralba</surname>, <given-names>A.</given-names></string-name> (<year>2007</year>). <article-title>The role of context in object recognition</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>11</volume>, <fpage>520</fpage>-<lpage>527</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Paige</surname>, <given-names>B.</given-names></string-name>, &#x0026; <string-name><surname>Wood</surname>, <given-names>F.</given-names></string-name> (<year>2016</year>). <article-title>Inference networks for Sequential Monte Carlo in graphical models</article-title>. In <source>Proceedings of the 33rd international conference on machine learning</source> (Vol. <volume>48</volume>).</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Rezende</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Mohamed</surname>, <given-names>S.</given-names></string-name>, &#x0026; <string-name><surname>Wierstra</surname>, <given-names>D.</given-names></string-name> (<year>2014</year>). <article-title>Stochastic backpropagation and approximate inference in deep generative models</article-title>. In <source>Proceedings of the 31st international conference on machine learning</source> (pp. <fpage>1278</fpage>-<lpage>1286</lpage>).</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Ritchie</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Thomas</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hanrahan</surname>, <given-names>P.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N.</given-names></string-name> (<year>2016</year>). <article-title>Neurally-guided procedural models: Amortized inference for procedural graphics programs using neural networks</article-title>. In <source>Advances in neural information processing systems</source> (pp. <fpage>622</fpage>-<lpage>630</lpage>).</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Saeedi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kulkarni</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Mansinghka</surname>, <given-names>V.</given-names></string-name>, &#x0026; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> (<year>2017</year>). <article-title>Variational particle approximations</article-title>. <source>Journal of Machine Learning Research</source>, <volume>18</volume>, <fpage>1</fpage>-<lpage>29</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Sanborn</surname>, <given-names>A. N.</given-names></string-name>, &#x0026; <string-name><surname>Chater</surname>, <given-names>N.</given-names></string-name> (<year>2016</year>). <article-title>Bayesian brains without probabilities</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>20</volume>, <fpage>883</fpage>-<lpage>893</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Sloman</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rottenstreich</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wisniewski</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hadjichristidis</surname>, <given-names>C.</given-names></string-name>, &#x0026; <string-name><surname>Fox</surname>, <given-names>C. R.</given-names></string-name> (<year>2004</year>). <article-title>Typical versus atypical unpacking and superadditive probability judgment</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>30</volume>, <fpage>573</fpage>-<lpage>582</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name>, &#x0026; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name> (<year>2008</year>). <article-title>A bayesian model of conditioned perception</article-title>. In <source>Advances in neural information processing systems</source> (pp. <fpage>1409</fpage>-<lpage>1416</lpage>).</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Stuhlm&#x00FC;ller</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Taylor</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2013</year>). <article-title>Learning stochastic inverses</article-title>. In <source>Advances in Neural Information Processing Systems</source> (pp. <fpage>3048</fpage>-<lpage>3056</lpage>).</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Suchow</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Bourgin</surname>, <given-names>D. D.</given-names></string-name>, &#x0026; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name> (<year>2017</year>). <article-title>Evolution in mind: Evolutionary dynamics, cognitive processes, and Bayesian inference</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>, <fpage>522</fpage>-<lpage>530</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Thaker</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &#x0026; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> (<year>2017</year>). <article-title>Online learning of symbolic concepts</article-title>. <source>Journal of Mathematical Psychology</source>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Thomas</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Dougherty</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sprenger</surname>, <given-names>A. M.</given-names></string-name>, &#x0026; <string-name><surname>Harbison</surname>, <given-names>J. I.</given-names></string-name> (<year>2008</year>). <article-title>Diagnostic hypothesis generation and human judgment</article-title>. <source>Psychological Review</source>, <volume>115</volume>, <fpage>155</fpage>-<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Thomas</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Dougherty</surname>, <given-names>M. R.</given-names></string-name>, &#x0026; <string-name><surname>Buttaccio</surname>, <given-names>D. R.</given-names></string-name> (<year>2014</year>). <article-title>Memory constraints on hypothesis generation and decision making</article-title>. <source>Current Directions in Psychological Science</source>, <volume>23</volume>, <fpage>264</fpage>-<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Trueblood</surname>, <given-names>J. S.</given-names></string-name>, &#x0026; <string-name><surname>Busemeyer</surname>, <given-names>J. R.</given-names></string-name> (<year>2011</year>). <article-title>A quantum probability account of order effects in inference</article-title>. <source>Cognitive science</source>, <volume>35</volume>, <fpage>1518</fpage>-<lpage>1552</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Tversky</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Koehler</surname>, <given-names>D. J.</given-names></string-name> (<year>1994</year>). <article-title>Support theory: a nonextensional representation of subjective probability</article-title>. <source>Psychological Review</source>, <volume>101</volume>, <fpage>547</fpage>-<lpage>567</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Ullman</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2012</year>). <article-title>Theory learning as stochastic search in the language of thought</article-title>. <source>Cognitive Development</source>, <volume>27</volume>, <fpage>455</fpage>-<lpage>480</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Vul</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2014</year>). <article-title>One and done? optimal decisions from very few samples</article-title>. <source>Cognitive Science</source>, <volume>38</volume>, <fpage>599</fpage>-<lpage>637</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Z.</given-names></string-name>, &#x0026; <string-name><surname>Busemeyer</surname>, <given-names>J. R.</given-names></string-name> (<year>2013</year>). <article-title>A quantum question order model supported by empirical tests of an a priori and precise prediction</article-title>. <source>Topics in Cognitive Science</source>, <volume>5</volume>, <fpage>689</fpage>-<lpage>710</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Solloway</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Shiffrin</surname>, <given-names>R. M.</given-names></string-name>, &#x0026; <string-name><surname>Busemeyer</surname>, <given-names>J. R.</given-names></string-name> (<year>2014</year>). <article-title>Context effects produced by question orders reveal quantum nature of human judgments</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>111</volume>, <fpage>9431</fpage>-<lpage>9436</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Yildirim</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Kulkarni</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Freiwald</surname>, <given-names>W. A.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2015</year>). <article-title>Efficient and robust analysis-by-synthesis in vision: A computational framework, behavioral tests, and modeling neuronal representations</article-title>. In <source>Proceedings of the 37th annual conference of the cognitive science society</source>.</mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn1"><label>1</label><p>More formally, this is known as variational inference (<xref ref-type="bibr" rid="c24">Jordan, Ghahramani, Jaakkola, &#x0026; Saul, 1999</xref>), where the divergence is typically the Kullback-Leibler divergence between the approximate and true posterior. Although this divergence cannot be minimized directly (since it requires knowledge of the true posterior), an upper bound can be tractably optimized for some classes of approximations.</p></fn>
<fn id="fn2"><label>2</label><p>Our findings do not strongly depend on the use of the KL divergence measure and all of our qualitative effects remained unchanged when we applied a symmetric distance measure such as the Jensen-Shannon divergence.</p></fn>
</fn-group>
</back>
</article>