<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/339648</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Detection of task-relevant and task-irrelevant motion sequences: application to motor adaptation in goal-directed and whole-body movements</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Furuki</surname>
<given-names>Daisuke</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2252-7826</contrib-id>
<name>
<surname>Takiyama</surname>
<given-names>Ken</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Electrical and Electronic Engineering, Tokyo University of Agriculture and Technology</institution>, Koganei-shi, Tokyo 184-8588, <country>Japan</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1">Correspondence should be addressed to K.T. (<email>t.j.ken.takiyama@gmail.com</email>).</corresp>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>339648</elocation-id>
<history>
<date date-type="received">
<day>05</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>05</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>05</day>
<month>6</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="339648.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Motor variability is inevitable in our body movements and has been discussed from various perspectives in motor neuroscience and biomechanics; it can originate from the variability of neural activities, reflect a large degree of freedom inherent in our body movements, decrease muscle fatigue, and facilitate motor learning. How to evaluate this motor variability is thus a fundamental question in motor neuroscience and biomechanics. Previous methods quantified (at least) two striking features of motor variability: a smaller variability in the task-relevant dimension than in the task-irrelevant dimension and a lowdimensional structure that have often been referred to as synergy or the principal component. However, these previous methods were not only unsuitable for quantifying these features simultaneously but also applicable in only limited conditions (e.g., one method cannot consider motion sequence and another method cannot consider how each motion is relevant to performance). Here, we propose a flexible and straightforward machine learning technique that can quantify task-relevant variability, task-irrelevant variability, and the relevance of each principal component to task performance while considering motion sequence and the relevance of each motion sequence to task performance in a data-driven manner. We validate our method by constructing a novel experimental setting to investigate goal-directed and whole-body movements. Further, our setting enables us to induce motor adaptation by using perturbation and evaluate the modulation of task-relevant and task-irrelevant variabilities through motor adaptation. Our method enables to identify a novel property of motor variability: the modulation of those variabilities is different depending on perturbation schedule. A constant perturbation increases task-relevant variability, and a gradually imposed perturbation increases task-irrelevant variability.</p>
</abstract>
<counts>
<page-count count="27"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In our daily life, we can repeatedly achieve desired movements, such as grasping a cup, throwing a ball, and playing piano. To achieve the desired movements, our motor system needs to resolve at least two difficulties inherent in our body motion [<xref ref-type="bibr" rid="c1">1</xref>]. One difficulty is movement variability. Due to the variability inherent in various stages such as acquiring sensory information [<xref ref-type="bibr" rid="c2">2</xref>], the neural activities of motor planning [<xref ref-type="bibr" rid="c3">3</xref>], or the muscle activities during motor execution [<xref ref-type="bibr" rid="c4">4</xref>], even sophisticated athletes and musicians can not repeat a given movement. Our motor systems somehow overcome these variabilities to achieve the desired movements [<xref ref-type="bibr" rid="c5">5</xref>]. Another difficulty is a large degree of freedom (DoF) inherent in our motor system [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c6">6</xref>]. The number of joints, muscles, and neurons are more than necessary to achieve the desired movements, resulting in that an infinite number of joint configurations, muscle activities, and neural activities that can result in the desired movement [<xref ref-type="bibr" rid="c7">7</xref>&#x2013;<xref ref-type="bibr" rid="c10">10</xref>]. Our motor systems somehow resolve these difficulties (i.e., variability and a large DoF) and generate the desired movements.</p>
<p>Although it remains unclear how we overcome movement variability, a possible answer is the decomposition of motor variability into task-relevant and task-irrelevant variabilities. We compensate for a portion of the motor variability that is relevant to achieve desired movements (i.e., task-relevant variability) [<xref ref-type="bibr" rid="c11">11</xref>&#x2013;<xref ref-type="bibr" rid="c15">15</xref>]; simultaneously, we do not significantly compensate for a portion of the variability that is irrelevant to achieve the desired movements (i.e., task-irrelevant variability). The compensation of taskrelevant variability can be observed in movement kinematics [<xref ref-type="bibr" rid="c11">11</xref>&#x2013;<xref ref-type="bibr" rid="c14">14</xref>], muscle activities [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>], and neural activities [<xref ref-type="bibr" rid="c15">15</xref>]. This striking feature of our motor variability enables us to achieve a desired movement under the existence of movement variability.</p>
<p>Several studies have developed the techniques to evaluate task-relevant and task-irrelevant variabilities. The uncontrolled manifold (UCM) evaluates the task-relevant and task-irrelevant variabilities (mainly) in joint angles and angular velocities. The method focuses on the kinematic parameters relevant to task achievement, such as hip joint position in stand-and-sit motion [<xref ref-type="bibr" rid="c11">11</xref>] or hand position in arm-reaching movements [<xref ref-type="bibr" rid="c18">18</xref>]. The Jacobian matrix, the derivatives of the kinematic parameters concerning joint angles or angular velocities, enables us to define null space around the joint angles or angular velocities averaged across trials. The variability along the null space can be defined as task-irrelevant variability. Previous studies have revealed that the task-relevant variability of joint angles and angular velocities is less than the task-irrelevant variability. Notably, the UCM focuses on forward kinematics that map joint angles and angular velocities onto joint positions and velocities in the external coordinate. In contrast, tolerance, noise, and covariation analysis (TNC) [<xref ref-type="bibr" rid="c13">13</xref>] and goal-equivalent manifold analysis (GEM) [<xref ref-type="bibr" rid="c14">14</xref>] focus on task functions that define the relationship between kinematic parameters and task performance. For example, a thrown dart or ball can be modeled as a parabola. When the release position and velocity in the vertical axis are p and v, respectively, the maximum height of the released dart or ball can be written as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline1.gif"/></alternatives></inline-formula>, where <italic>g</italic> is gravitational acceleration. When controlling <italic>h</italic> is a task, the relation among <italic>h, p</italic>, and <italic>v</italic> can be task function. For example, with a slight value <italic>d</italic> (i.e., <italic>d</italic><sup>2</sup> &#x2243; 0), a slight change in the release position <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline2.gif"/></alternatives></inline-formula> and release velocity <italic>v</italic> &#x2013; <italic>d</italic> does not cause any change in <italic>h</italic>, allowing the variability along these slight changes to be regarded as task-irrelevant variability. TNC and GEM evaluate the task-relevant and task-irrelevant variabilities based on the task functions.</p>
<p>These techniques have pros and cons. The UCM enables us to evaluate motion sequence, but it does not consider task function. The framework is thus not always suitable for the situation in which kinematic parameters are nonlinearly relevant to task achievements, as is the case with the quadratic function of v in the parabolic mentioned above. Because forward kinematics are nonlinear functions of joint angles and angular velocities, the UCM requires local linear approximation around representative joint angles or angular velocities based on the Jacobian matrix. Due to linear approximation, the UCM assumes the variability around the kinematics averaged across all trials. This approximation results in difficulty considering the motor variability when the averaged kinematics change, as with the kinematics before, during, and after motor learning (although it is possible to discuss these situations separately [<xref ref-type="bibr" rid="c18">18</xref>]). GEM also considers the local linear approximation of nonlinear task functions, resulting in the method considering variability around the task parameters averaged across all trials. Although GEM can deal with task function, it is difficult to apply to motion sequence in several cases. For example, to consider a motion sequence, the framework needs to define how the dart or ball position and velocity 100 msec before release are relevant to maximum height in the example mentioned above. TNC enables simultaneous discussion of the motor variability before, during, and after motor learning because the framework captures the entire variability in a nonparametric manner without local linear approximation; however, TNC is not always suitable for considering motion sequence based for reasons similar to those facing GEM: it requires explicit definition of task function. In total, each method has pros and cons, resulting in no single framework that can simultaneously evaluate task-relevant and task-irrelevant variabilities when the averaged kinematics or task parameters change while considering both motion sequence and task function.</p>
<p>Motor variability has another striking feature: the variability is embedded in low-dimensional space that is referred to as synergy [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c19">19</xref>&#x2013;<xref ref-type="bibr" rid="c22">22</xref>]. It is suggested that to overcome a larger DoF, our motor system controls not all the DoFs but only those in low-dimensional space. Synergy has been (mainly) discussed for kinematics data [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c22">22</xref>&#x2013;<xref ref-type="bibr" rid="c24">24</xref>] and EMG data [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. In both kinematics and EMG, low-dimensional space that can capture a high portion of motor variability has been found. Several methods have been developed to extract the synergy, such as principal component analysis (PCA) [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c22">22</xref>], nonnegative matrix factorization [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c25">25</xref>] or spatial-temporal decomposition of EMG data [<xref ref-type="bibr" rid="c19">19</xref>].</p>
<p>Motor variability thus has at least two characteristics: compensation of task-relevant variability and low-dimensional structure. Most of the techniques, however, deal with only one of these aspects. It is difficult to detect the low-dimensional structure of motor variability by the methods that evaluate task-relevant and task-irrelevant variabilities. Similarly, it is difficult to evaluate task-relevant and task-irrelevant variabilities by the techniques that extract the low-dimensional structure of motor variability. In other words, the 1st principal component, the dimension that can explain the most significant portion of variability among all dimensions, is not always the factor most relevant or irrelevant to task performance. Although the UCM had been used to extract synergy [<xref ref-type="bibr" rid="c26">26</xref>], the primary advantage of the UCM is not the extraction of low-dimensional structure but the evaluation of task-relevant and task-irrelevant variabilities. Although a few studies have focused on linear discrimination analysis (LDA) to discuss task-relevant low-dimensional space [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>], LDA enables only discrimination, i.e., success or failure of the movement [<xref ref-type="bibr" rid="c29">29</xref>], in contrast to TNC and GEM, which can account for motor performance based on continuous performance values. In summary, few methods simultaneously quantify the two striking features of movement variability.</p>
<p>Here, we propose a flexible and straightforward machine learning technique that can evaluate movement variability by unifying the advantages of previous techniques; our framework can evaluate not only task-relevant and task-irrelevant variabilities even when the averaged kinematics or task parameters change (e.g., before, during, and after motor learning) while considering motion sequence and task function but also how each synergy is relevant to task performance by extending the PCA. The current study relied on ridge regression [<xref ref-type="bibr" rid="c30">30</xref>], a linear regression technique that is robust to measurement noise, has a definite relation to the PCA and can evaluate how the motion of each body part at each time point is relevant to task performance in a data-driven manner [<xref ref-type="bibr" rid="c31">31</xref>]. Our technique can thus enable us to determine the task functions in a data-driven manner without any explicit function such as the parabola. First, we construct a novel experimental paradigm to discuss the relation of a motion sequence to task performance based on goal-directed and whole-body movements. We further discuss motor adaptation in the current experimental setting. Second, we formalize the dissociation of motion sequence data into task-relevant components and task-irrelevant components by extending a ridge regression. We validate the decomposition based on our experimental data. Third, we clarify the relation between ridge regression and the PCA, a popular method to extract motor variability in low-dimensional space. In particular, we analytically reveal how each principal component is relevant to performance in the ridge regression. We also validate the analytical calculations based on our experimental data. Finally, we apply our method to motion sequence data in whole-body and goal-directed movements before and after motor adaptation. Because our method enables us to discuss the modulation of movement variability before and after motor adaptation, we discuss the dependence of the modulation on perturbation schedule.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Goal-directed whole-body movements and motor adaptation</title>
<p>The current study focuses on goal-directed and whole-body movements in which subjects manage to achieve a desired movement by controlling a large DoFs. We focus on a simplified version of whole-body movements: a vertical jump while crossing arms in front of the trunk (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>). This goal-directed whole-body movement enabled us to focus on lower limb motions and assess task-relevant variability, task-irrelevant variability, and the low-dimensional spaces in which a high portion of the motor variability was embedded. We proposed a machine learning technique to simultaneously evaluate these features of variability while considering motion sequence and the relevance of each motion to jumping height.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Summary of our experimental settings. <bold>A</bold>: Participants were instructed to perform a vertical jump at the timing of the third beep. Three beeps sounded at one-second intervals. We measured and analyzed joint angles at toe, ankle, and knee in the sagittal plane. The jumping height was measured based on the position of the marker attached to the back in the y-axis. <bold>B</bold>: Task instruction and feedback information in each trial. A computer monitor was located in front of the participants (1.5 meters ahead, 1.7 meters above the floor). One second before the first beep, target height (indicated by black bar and texts [e.g., 50&#x0025; max]), baseline height (indicated by black bar), and initial position (indicated by blue cursor located on the baseline height) were displayed. When the target height was 60&#x0025;, the black bar and text were displayed at the position of the higher black dotted bar. When the target height was 40&#x0025;, the black bar and text were displayed at the position of the lower black dotted bar. These black dotted bars were used only for the explanation and were not visible throughout the experiments. In the practice trials, the blue cursor was displayed during trials to continuously indicate the position of the marker attached to the back in the y-axis. These trials enabled the participants to become accustomed to the experimental setting. In baseline and learning trials, the blue cursor was displayed at the beginning and end of each trial. At the beginning of each trial, the blue cursor was displayed at the baseline height. At the end of each trial, the cursor was displayed depending on the actual jumping height. When the jumping height was close to the target height, the participants heard a coin-getting sound. During the experiments, the subjects were provided with the current trial number and the number of successful trials where they could hear change rattling. <bold>C</bold>: The sequence of the experiments. Participants performed a vertical jump with maximum effort for two trials. These jumping heights were used to determine the target height. Participants experienced 20 practice trials, 50 baseline trials, and a number of learning trials specific to each experiment. <bold>D</bold>: Averaged jumping height of each participant in the baseline trials in experiment 1. The jumping height depended on the target height (1-way ANOVA, p &#x003D; 2.2597&#x00D7;10<sup>&#x2212;21</sup>), indicating that the participants could perform the goal-directed movement.</p></caption>
<graphic xlink:href="339648_fig1.tif"/>
</fig>
<p>Subjects stood in a fixed position and were instructed to look at a computer monitor located in front of them and perform a sub-maximum vertical jump according to a target height (40, 45, 50, 55, or 60&#x0025; of the maximum jumping height of each subject, <xref ref-type="fig" rid="fig1">Fig. 1B</xref>). Three beeps sounded, and the subjects needed to perform the jump at the timing of the third beep. The interval between each beep was one second. At the beginning of each trial (i.e., one second before the first beep), the target height was indicated by a black bar displayed on a computer monitor. At the end of the <italic>t</italic>th trial, the actual jumping height <italic>h<sub>t</sub></italic> (the y-position of the marker attached to the back) was displayed as a blue cursor on the monitor, where <italic>t</italic> &#x003D; 1,&#x2026;,<italic>T</italic> and <italic>T</italic> was the number of trials to be analyzed. By manipulating the displayed jumping height (we called this manipulation as a perturbation <italic>p<sub>t</sub></italic>), it was possible to induce sensory prediction error between the predicted and actual jumping heights. This perturbation paradigm was similar to a protocol of motor gain adaptation as reported mainly in saccade and arm-reaching movements [<xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c33">33</xref>]. We expected subjects to modify their motion sequences to minimize the sensory prediction error.</p>
<p>First, we determined whether the subjects could perform goal-directed whole-body movements in our experimental setting. In 50 baseline trials in experiment 1 (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>), the target height pseudorandomly changed in each trial. There were significant differences in jumping height depending on target height (<xref ref-type="fig" rid="fig1">Fig. 1D</xref>, 1-way ANOVA, p &#x003D; 2.2597&#x00D7;10<sup>&#x2212;21</sup>). The subjects could thus perform goal-directed vertical jump depending on target height.</p>
<p>Second, we determined whether the subjects showed motor adaptation in the experimental setting. In 96 learning trials in experiment 1 (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>), the subjects experienced perturbations once in every five trials; the perturbation was pseudorandomly set to <italic>p<sub>t</sub></italic> &#x003D; 0.05 or <italic>p<sub>t</sub></italic> &#x003D; &#x2212;0.05 in every five trials and <italic>p<sub>t</sub></italic> &#x003D; 0 in other trials (<xref ref-type="fig" rid="fig2">Figs. 2A and B</xref>). We observed the modification of jumping height after each perturbation (<xref ref-type="fig" rid="fig2">Fig. 2C</xref>, paired t-test, <italic>p</italic> &#x003D; 0.0026 for motor adaptation when <italic>p<sub>t</sub></italic> &#x003D; 0.05; and <italic>p</italic> &#x003D; 0.0014 for motor adaptation when <italic>p<sub>t</sub></italic> &#x003D; &#x2014;0.05). Motor adaptation could thus be observed in the goal-directed vertical jump.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Diagram and results of experiment 1. <bold>A</bold>: Target height in baseline and learning trials. Cyan and magenta circles indicated the trials with perturbations. <bold>B</bold>: Perturbation sequence. The cyan circle indicates the trials with p&#x003D;0.05, and the magenta circle indicates those with <italic>p</italic> &#x003D; &#x2212;0.05. The perturbations were pseudorandomly imposed once in five trials. <bold>C</bold>: Adaptation effect. The vertical line indicates the modification of the jumping height after the perturbation was imposed. Magenta dots indicate the averaged difference in each subject corresponding to the perturbation <italic>p</italic> &#x003D; &#x2212;0.05, and cyan dots indicate the averaged difference in each subject corresponding to the perturbation <italic>p</italic> &#x003D; 0.05.</p></caption>
<graphic xlink:href="339648_fig2.tif"/>
</fig>
</sec>
<sec id="s2b">
<title>Validation of ridge regression and decomposition into task-relevant and task-irrelevant components</title>
<p>The current study focuses on the evaluation of motor variability, especially task-relevant variability, task-irrelevant variability, and the relevance of low-dimensional structures to task performance, by extending ridge regression (the details of ridge regression were provided in Methods). Ridge regression is a linear regression technique that is robust against observation noise, is applicable to data with multicollinearity, and enables predictions of output data y (i.e., jumping height) based on input data <bold><italic>X</italic></bold> &#x003D; (<italic>X</italic><sub>1</sub>,&#x2026;, <italic>X<sub>D</sub></italic>) (i.e., motion sequence). The regression thus enables the prediction of jumping height as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline3.gif"/></alternatives></inline-formula>, where <italic>h</italic> is predicted jumping height and <bold><italic>w</italic></bold> &#x003D; (<italic>w</italic><sub>1</sub>,&#x2026;,<italic>w<sub>D</sub></italic>)<sup><italic>T</italic></sup> is weight coefficients to predict jumping height, where (<italic>a</italic><sub>1</sub>,&#x2026;)<sup><italic>T</italic></sup> denotes the transpose of the vector. When the absolute value of <italic>w<sub>i</sub></italic> is a large value, <italic>X<sub>i</sub></italic> can be considered to be relevant to task performance. In contrast, when <italic>w<sub>i</sub></italic> is close to 0, <italic>X<sub>i</sub></italic> can be considered to be irrelevant to task performance. We needed to validate the ridge regression in the current experimental setting before evaluating variability. Notably, we have already validated the efficiency of ridge regression to predict performance not only in jumping movements but also in throwing movements [<xref ref-type="bibr" rid="c31">31</xref>].</p>
<p>Ridge regression requires selecting input data because a careful selection of input data is indispensable to discussing the linear relation between input and output data. Prediction power is a sophisticated measure for selecting input data while avoiding overfitting [<xref ref-type="bibr" rid="c29">29</xref>]. The current study focuses on prediction error between actual and predicted jumping height using 10-fold cross validation. We compared the following three types of input data (see Methods for details). The first candidate is joint angles &#x007B;<italic>q<sub>i</sub></italic>&#x007D; and angular velocities <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline4.gif"/></alternatives></inline-formula>, where &#x007B;<italic>a<sub>i</sub></italic>&#x007D; &#x003D; (<italic>a</italic><sub>1</sub>,<italic>a</italic><sub>2</sub>,<italic>a</italic><sub>3</sub>) and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline5.gif"/></alternatives></inline-formula> denotes the derivative of <italic>q<sub>i</sub></italic> concerning time (the definitions of each <italic>q<sub>i</sub></italic> are given in <xref ref-type="fig" rid="fig1">Fig. 1A</xref>). The second candidate is the functions of <italic>q<sub>i</sub></italic> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline6.gif"/></alternatives></inline-formula>, which describe the position and velocity of hip joint in the y-axis and are relevant to jumping height: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline7.gif"/></alternatives></inline-formula>. The third candidate is the functions describing the jumping height based on parabolic approximation: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline8.gif"/></alternatives></inline-formula>, where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline9.gif"/></alternatives></inline-formula>. By comparing these three candidates, we found that the third candidate showed the lowest prediction error (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>). In particular, the third candidate, with seven time frames before release, yielded the lowest prediction error. In the following, we refer to the third candidate with seven time frames as the motion sequence. If the prediction error equals 1, the method cannot predict the output data. In contrast, if the prediction error equals 0, the method can predict the output data with 100&#x0025; accuracy. As shown in <xref ref-type="fig" rid="fig3">Fig. 3A</xref>, the third candidate with seven time frames resulted in a prediction error of less than 0.2, indicating that the ridge regression enables prediction of jumping height with a greater than 80&#x0025; accuracy in the current setting. Because the parabolic approximation of jumping height (<inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline10.gif"/></alternatives></inline-formula>, the detailed definition is given in the Introduction) enables prediction of the jumping height with a 76&#x0025; accuracy (purple line in <xref ref-type="fig" rid="fig3">Fig. 3A</xref>), the ridge regression enables prediction of jumping height with higher accuracy than the approximation. The reasons the ridge regression shows higher prediction power are its robustness against observation noise and consideration of the motion sequence rather than the representative motion data at a single time frame (i.e., the position and velocity of the hip joint only at the time of release). The ridge regression thus enables the discussion of the linear relation between the motion sequence and jumping height with appropriate precision.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Validation of the ridge regression and the concept of our method. <bold>A</bold>: Predictive power of the ridge regression using three kinds of input data. Horizontal and vertical axes indicate the time bin length used for the ridge regression and squared prediction error, respectively. If the ridge regression could not make a prediction, the prediction error equaled 1. If the ridge regression could predict the output data perfectly, the prediction error equaled 0. These results indicate that the ridge regression enables the prediction of output data with a greater than 80&#x0025; accuracy. <bold>B</bold>: An example of decomposing input data into task-relevant and task-irrelevant components. In this case, we assumed that the task 1 required <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> to be 2 (green line), task 2 required <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> to be 0 (green line), and task 3 required <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> to be &#x2212;2 (green line). Green, red, and blue dots indicate the typical input data for tasks 1, 2, and 3, respectively. In the ridge regression, these tasks can be achieved with <italic>w</italic><sub>1</sub> &#x003D; 1 and <italic>w</italic><sub>2</sub> &#x003D; &#x2013;1, i.e., <italic>y</italic> &#x003D; <italic>w</italic><sub>1</sub> <italic>X</italic><sub>1</sub> &#x002B; <italic>w</italic><sub>2</sub><italic>X</italic><sub>2</sub> &#x003D; <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> should be determined differently in each task. In the right panel, these input data were decomposed into a task-relevant (black dotted line) component <italic>X</italic><sub>rel</sub> &#x003D; <italic>Xww<sup>T</sup></italic>/|<italic>w</italic>|<sup>2</sup> and a task-irrelevant component <italic>X</italic><sub>irr</sub> &#x003D; <italic>X</italic> &#x2013; <italic>X</italic><sub>rel</sub> (solid black line). <italic>X</italic><sub>rel</sub> was separated depending on the task, and <italic>X</italic><sub>irr</sub> was not separated, which indicates that the decomposition enables the discussion of the task-relevant and task-irrelevant components.</p></caption>
<graphic xlink:href="339648_fig3.tif"/>
</fig>
<p>Based on the ridge regression, the current study decomposes the motion sequence <bold><italic>X</italic></bold> into a task relevant <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline11.gif"/></alternatives></inline-formula>, where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline12.gif"/></alternatives></inline-formula> is the squared norm of <bold><italic>w</italic></bold>, and a task-irrelevant components <bold><italic>X</italic></bold><sub>irr</sub> &#x003D; <bold><italic>X</italic></bold> &#x2013; <bold><italic>X</italic></bold><sub>rel</sub> (see Methods for details). <xref ref-type="fig" rid="fig3">Figs. 3B</xref> and <xref ref-type="fig" rid="fig3">3C</xref> demonstrate typical examples of the decomposition when <bold><italic>X</italic></bold> includes only 2 elements and constrains the task by setting <italic>y</italic> &#x003D; <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> (i.e., <italic>w</italic><sub>1</sub> &#x003D; 1 and <italic>w</italic><sub>2</sub> &#x003D; &#x2212;1) to some certain values (e.g., <italic>y</italic> &#x003D; 2, 0, &#x2212;2 in the simulated task 1, 2, 3, respectively). Because the constrained task was one dimensional and input data were two dimensional, an infinite number of <bold><italic>X</italic></bold> values resulted in an identical <italic>y</italic> value. In this case, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline13.gif"/></alternatives></inline-formula> and <bold><italic>X</italic></bold><sub>irr</sub> &#x003D; <bold><italic>X</italic></bold> &#x2013; <bold><italic>X</italic></bold><sub>rel</sub>. The simulated data points on the dotted line in <xref ref-type="fig" rid="fig3">Fig. 3C</xref> indicated <bold><italic>X</italic></bold><sub>rel</sub>. On the dotted line, the data points can be clearly separated into three parts corresponding to the simulated tasks 1, 2, and 3. In contrast, on the solid line, <bold><italic>X</italic></bold><sub>irr</sub> is not separated based on task. In our experimental setting with goal-directed vertical jump, <bold><italic>X</italic></bold>, <bold><italic>X</italic></bold><sub>rel</sub>, and <bold><italic>X</italic></bold><sub>irr</sub> included 63 elements in each trials (3(dim) &#x00D7;7(time frames) for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline14.gif"/></alternatives></inline-formula>. The current study calculated the variability (variance) of each element of <bold><italic>X</italic></bold><sub>rel</sub> and <bold><italic>X</italic></bold><sub>irr</sub> in focused trials. The representative values of the variability, task-relevant variability Var<sub>rel</sub> and task-irrelevant variability Var<sub>irr</sub>, were calculated by averaging the variability across all the elements.</p>
</sec>
<sec id="s2c">
<title>Variability in task-relevant and task-irrelevant space</title>
<p>We calculated the task-relevant and task-irrelevant variabilities in a goal-directed vertical jump based on both the ridge regression and the decomposition of input data into task-relevant and task-irrelevant dimensions. We found that the task-relevant variability was smaller than the task-irrelevant variability in all participants (N &#x003D; 13, red dots in <xref ref-type="fig" rid="fig4">Fig. 4A</xref>). Because previous methods, such as the UCM (blue crosses) and GEM (green crosses), found similar task-relevant and task-irrelevant variabilities, our method enabled the extraction of lower task-relevant variability and higher task-irrelevant variability. Because the normalization procedures of our method and previous methods differ (see Methods), there was a slight difference in the calculated variabilities. Our methods can quantify task-relevant and task-irrelevant variabilities by considering the motion sequence and the relevance of the sequence to the task. Our method does not require any explicit task function, such as the parabolic approximation of jumping height, but it determines the relevance of the motion sequence to the task in a data-driven manner. Further, our method is robust against observation noise due to the ridge regression.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Validation of our method and comparison to previous methods. <bold>A</bold>: Evaluation of taskrelevant and task-irrelevant variabilities. Red dots indicate those variabilities evaluated by our method in each subject (N &#x003D; 13). Blue and green crosses indicate the variabilities evaluated by the UCM and GEM, respectively. Our method uses a different normalization method from those of the UCM and GEM. <bold>B</bold>: Correlation between predicted and actual jumping height. The red line and the shaded area indicate the mean and standard error of the mean (s.e.m.) of the correlation in ridge regression (N &#x003D; 13), respectively. The blue line and shaded area indicate the mean and s.e.m. of the correlation in PCA (N &#x003D; 13), respectively. Horizontal and vertical axes indicate the explained variance or the corresponding number of principal components and the correlation, respectively. <bold>C</bold>: Explained variance and the correlation between the predicted and actual jumping height of each principal component. The red line and the shaded area indicate the mean and s.e.m. of the correlation (N &#x003D; 13), respectively. The blue line and the shaded area indicate mean and s.e.m. of the variance explained (N &#x003D; 13), respectively. <bold>D</bold>: Variance explained and the correlation between the predicted and actual jumping height of each principal component in a typical subject. The red and blue lines indicate the correlation and the variance explained, respectively. <bold>E</bold>: The PC number that is most relevant to predicting jumping height. Horizontal and vertical axes indicate the subject number and the most relevant PC number, respectively.</p></caption>
<graphic xlink:href="339648_fig4.tif"/>
</fig>
</sec>
<sec id="s2d">
<title>Relevance of each principal component to task performance</title>
<p>Movement variability shows not only less task-relevant variability than task-irrelevant variability but also a low-dimensional structure. The current study compares our method to PCA, a conventional method to extract low-dimensional structure. We decomposed the motion sequence <bold><italic>X</italic></bold> into principal components (PCs, i.e., eigenvectors) and calculated the correlation of each PC to jumping height (see Methods for detail). When the motion sequence was decomposed using a larger number of principal components, the decomposed sequence showed a higher correlation to jumping height (<xref ref-type="fig" rid="fig4">Fig. 4B</xref>). If averaged across all participants, the 1st PC could explain approximately 40&#x0025; of the movement variability (blue line in <xref ref-type="fig" rid="fig4">Fig. 4C</xref>). Corresponding to the explained movement variability, the 1st PC showed the highest correlation to jumping height (red line in <xref ref-type="fig" rid="fig4">Fig. 4C</xref>) if averaged across all participants. In a typical subject, however, the 2nd rather than the 1st PC showed the highest correlation to jumping height (red line in <xref ref-type="fig" rid="fig4">Fig. 4D</xref>). This typical subject was not an exception; <xref ref-type="fig" rid="fig4">Fig. 4E</xref> shows the PC number with the highest correlation to jumping height. In 6 out of 13 subjects, the 1st PC showed the highest correlation to performance. In 5 out of 13 subjects, the 2nd PC showed the highest correlation, and the 3rd PC showed the highest in 2 out of 13 subjects. These results indicate that the explained movement variability did not correspond to the relevance to task performance.</p>
<p>Ridge regression enabled the prediction of jumping height with higher accuracy than PCA (red line in <xref ref-type="fig" rid="fig4">Fig. 4B</xref>) because the ridge regression weights each PC based on both the explained movement variability and the task relevance. In PCA (or equivalently singular value decomposition (SVD)), the motion sequence at the tth trial is decomposed as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline15.gif"/></alternatives></inline-formula>, where <italic>N</italic> is the number of PCs, &#x03BB;<sub><italic>i</italic></sub> is the <italic>i</italic>th eigenvalue corresponding to the ith PC <bold><italic>v</italic></bold><sub><italic>i</italic></sub>, and <italic>u<sub>i,t</sub></italic> indicated how the ith PC appeared at the trial. The correlation of the <italic>i</italic>th PC to task performance was thus calculated based on <italic>u<sub>i,t</sub></italic>, and it did not reflect the relevance of the ith PC to task performance. In contrast, the ridge regression enables the prediction of task performance as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline16.gif"/></alternatives></inline-formula>, where <italic>f</italic>(&#x03BB;<sub><italic>i</italic></sub>) is a sigmoidal function of &#x03BB;<sub><italic>i</italic></sub> and Corr(<italic>u<sub>i,t</sub>, y<sub>t</sub></italic>) is the correlation between the contribution of the <italic>i</italic>th PC at the tth trial <italic>u<sub>i</sub>,<sub>t</sub></italic> and observed jumping height <italic>y<sub>t</sub></italic> (see Methods for details). The ridge regression thus enables the prediction of performance by weighting each PC based on both explained movement variability and task relevance. In other words, our method enables the consideration of the low-dimensional structure of movement variability by weighting each PC suitable for predicting task performance.</p>
</sec>
<sec id="s2e">
<title>Influence of motor adaptation on variability in task-relevant and task-irrelevant dimension</title>
<p>An advantage of our method is its linearity, which enables the simultaneous comparison of the taskrelevant and task-irrelevant variabilities among the conditions where mean kinematics or task parameters change (e.g., before, during, and after motor learning). It was previously unclear how task-relevant and task-irrelevant variabilities are modulated by motor adaptation. The modulation of these variabilities has been investigated for arm-reaching movements and motor adaptation to a constant perturbation [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c34">34</xref>]. Although there are some differences between adaptation to a constant perturbation and that to a gradually imposed perturbation, e.g., retention rate or awareness [<xref ref-type="bibr" rid="c35">35</xref>], the means by which those variabilities are modulated in the two types of adaptations have not been investigated. Further, it was previously unclear whether such modulation of variability could be observed in whole-body movements. Our method without linear approximation enabled the discussion of how task-relevant and task-irrelevant variabilities are modulated before and after motor adaptation in whole-body movements. We thus applied our method to motor adaptation in response to constant and gradually imposed perturbations.</p>
<p>In experiment 2 (two days for each subject), subjects experienced gradually increased or decreased perturbations. Each subject underwent ten learning trials without any perturbation. The perturbation gradually increased or decreased for ten trials and was set to 0.05 or &#x2212;0.05 for ten trials (<xref ref-type="fig" rid="fig5">Figs. 5A, B</xref>). In a total of 30 trials, the target height was set to 50&#x0025; of the subject&#x2019; s maximum jumping height. Subjects who experienced a <italic>p<sub>t</sub></italic> &#x003E; 0 on the first day experienced a <italic>p<sub>t</sub></italic> &#x003C; 0 on the 2nd day and vice versa. The order of perturbation was counterbalanced across subjects. The subjects could adapt to the gradually increased or decreased perturbations (<xref ref-type="fig" rid="fig5">Fig. 5C</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Diagram and results of experiments 2 and 3. <bold>A,D</bold>: Target height in baseline and learning trials. Blue and red circles indicate the trials with perturbations. <bold>B,E</bold>: Perturbation sequence. Subjects joined experiment 2 for two days and experienced two different perturbations (either <italic>p</italic> &#x003E; 0 or <italic>p</italic> &#x003C; 0). The order of perturbation was counterbalanced across subjects. In experiment 3, subjects experienced both positive and negative perturbations within one day. Although panel E shows the case when a negative perturbation followed a positive one, the order of the perturbation was counterbalanced across subjects. <bold>C,F</bold>: Learning curves. The thin solid lines indicate the learning curves of each subject. The bold solid line indicates the learning curve averaged across all subjects.</p></caption>
<graphic xlink:href="339648_fig5.tif"/>
</fig>
<p>In experiment 3, the subjects experienced constant perturbations. Each subject underwent five learning trials without any perturbation. The perturbation was set to 0.05 or &#x2212;0.05 for 15 trials, 0 for ten trials for washout and &#x2212;0.05 or 0.05 for 15 trials (<xref ref-type="fig" rid="fig5">Figs. 5D, E</xref>). Subjects who experienced a pt&#x003D;0.05 on the 6th-20th trials experienced a <italic>p<sub>t</sub></italic> &#x003D; &#x2212;0.05 on the 31st-45th trials and vice versa. The order of perturbation was counterbalanced across subjects. In a total of 45 trials, the target height was set to 50&#x0025; of the subject&#x2019; s maximum jumping height. In both experiments 2 and 3, the subjects adapted to the perturbations (<xref ref-type="fig" rid="fig5">Fig. 5F</xref>).</p>
<p>We calculated the task-relevant and task-irrelevant variabilities before and after adaptation in experiments 2 and 3 (<xref ref-type="fig" rid="fig6">Figs. 6A and B</xref>). For task-relevant variability, there was no significant difference before and after the adaptation to gradually increasing or decreasing perturbations (blue dots in <xref ref-type="fig" rid="fig6">Fig. 6A</xref>, N &#x003D; 13, Wilcoxon signed rank test, p &#x003D; 0.1272). In contrast, in adapting to a constant perturbation, there was a significant difference in task-relevant variability before and after adaptation (red dots in <xref ref-type="fig" rid="fig6">Fig. 6A</xref>, N &#x003D; 13, Wilcoxon signed rank test, p &#x003D; 0.0105). For task-irrelevant variability, there was a significant difference before and after adaptation to gradually increasing or decreasing perturbations (blue dots in <xref ref-type="fig" rid="fig6">Fig. 6B</xref>, N &#x003D; 13, Wilcoxon signed rank test, p &#x003D; 0.0215). In contrast, in adapting to a constant perturbation, there was no significant difference in task-irrelevant variability before and after adaptation (red dots in <xref ref-type="fig" rid="fig6">Fig. 6B</xref>, N &#x003D; 13, Wilcoxon signed rank test, p &#x003D; 0.5417). These results could be interpreted based on a simple and two-dimensional case similar to that shown in <xref ref-type="fig" rid="fig3">Figs. 3B and C</xref> (<xref ref-type="fig" rid="fig6">Figs. 6C, D</xref>). In adapting to perturbations, the subjects needed to modify their output (i.e., jumping height) by determining an appropriate input (i.e., motion sequence). In adapting to gradually increasing or decreasing perturbations, the task-irrelevant variability increased, while the task-relevant variability was not modulated (<xref ref-type="fig" rid="fig6">Fig. 6C</xref>). In adapting to a constant perturbation, the task-relevant variability increased, while the task-irrelevant variability was not be modulated (<xref ref-type="fig" rid="fig6">Fig. 6D</xref>). In summary, the modulation of task-relevant and task-irrelevant variabilities depends on the schedule of perturbation.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Application of our method to the results of experiments 2 and 3. <bold>A</bold>: Task-relevant variabilities of each subject (N &#x003D; 13) before and after adaptation to perturbation in experiments 2 and 3. The blue and red dots indicate the variability of each subject in experiments 2 and 3, respectively. The blue and red lines indicate the modulation of the variability due to adaptation. The blue and red bars indicate the averaged variability across all subjects. There was a significant difference between the variabilities before the adaptation and those after the adaptation in experiment 3 (Wilcoxon signed rank test, p &#x003D; 0.0105). <bold>B</bold>: Task-irrelevant variabilities of each subject (N &#x003D; 13) before and after adaptation to perturbation in experiments 2 and 3. There was a significant difference between the variabilities before the adaptation and those after the adaptation in experiment 2 (Wilcoxon signed rank test, p &#x003D; 0.0215). <bold>C,D</bold>: Interpretation of our results based on a simple example. We assume that the task before adaptation required <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> to be 2 and that the task after adaptation required <italic>X</italic><sub>1</sub> &#x2013; <italic>X</italic><sub>2</sub> to be &#x2212;2. Panel C indicates an interpretation of our results in experiment 2. In the experiment, task-irrelevant variabilities increased after adaptation, and task-relevant variabilities remained unchanged. Panel D indicates an interpretation of our results from experiment 3. In the experiment, task-relevant variabilities increased after adaptation, and task-irrelevant variabilities remained unchanged.</p></caption>
<graphic xlink:href="339648_fig6.tif"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We proposed a flexible and straightforward machine learning technique that quantified task-relevant variability, task-irrelevant variability, and the relevance of each principal component to task performance in a noise-robust manner while considering motion sequence and how each motion sequence was relevant to task performance (<xref ref-type="fig" rid="fig3">Figs. 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>). Our method can find the relevance of each motion sequence to performance (i.e., task function) in a data-driven manner; our method does not require any explicit task function, such as the parabolic approximation of jumping height. Further, our method does not require any linear approximation, which enables the simultaneous consideration of the variabilities when the kinematics or task parameters averaged across trials change (e.g., before, during, and after adaptation). By applying our method to the motion sequence before and after motor adaptation, we found that the perturbation schedules affected the modulation of movement variability in motor adaptation (<xref ref-type="fig" rid="fig6">Figs. 6A</xref> and <xref ref-type="fig" rid="fig6">6B</xref>). These advantages enable the methods to be flexibly applied to a wide range of goal-directed movements.</p>
<p>Another advantage of our method is the ability to select appropriate input based on predictive power (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>). The predictive power also enables the selection of an appropriate coordinate to define task performance. Although we considered one-dimensional performance in the current study (i.e., jumping height), more than two-dimensional performance requires the definition of an appropriate coordinate [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c37">37</xref>]. Predictive power also plays an important role in selecting the appropriate coordinate [<xref ref-type="bibr" rid="c31">31</xref>].</p>
<p>Our method yields a state-space model for motor adaptation during whole-body movements. The state-space model was previously proposed as a model of motor adaptation mainly in arm-reaching movements [<xref ref-type="bibr" rid="c38">38</xref>&#x2013;<xref ref-type="bibr" rid="c45">45</xref>]. In the current study, the modification of jumping height at the <italic>t</italic>th trial, <italic>h<sub>t</sub></italic> &#x2013; <italic>h</italic><sub><italic>t</italic>&#x2212;1</sub>, was significantly correlated with the error, <italic>e</italic><sub><italic>t</italic>&#x2212;1</sub>, caused by perturbation and motor noise (in experiment 1, the correlation between <italic>h<sub>t</sub></italic> &#x2013; <italic>h</italic><sub><italic>t</italic>&#x2212;1</sub> and <italic>e</italic><sub><italic>t</italic>&#x2212;1</sub> averaged across all participants was 0.5118 and <italic>p</italic> &#x003C; 0.01 for all the participants). The state-space model of jumping height can thus be written as <italic>h<sub>t</sub></italic> &#x003D; <italic>h</italic><sub><italic>t</italic>&#x2212;1</sub> &#x002B; <italic>&#x03B7;e</italic><sub><italic>t</italic>&#x2212;1</sub>, where <italic>&#x03B7;</italic>(&#x003E; 0) is the learning rate. The jumping height ht was predicted well by <italic>h<sub>t</sub></italic> &#x2243; <bold><italic>X</italic></bold><sub><italic>t</italic></sub><bold><italic>w</italic></bold> &#x003D; <bold><italic>X</italic></bold><sub>rel,t</sub>,<bold><italic>w</italic></bold>, which enabled us to approximately rewrite the state-space model as <bold><italic>X</italic></bold><sub>rel,t</sub><bold><italic>w</italic></bold> &#x003D; <bold><italic>X</italic></bold><sub>rel,t&#x2212;1</sub><bold><italic>w</italic></bold> &#x002B; <italic>&#x03B7;e</italic><sub><italic>t</italic>&#x2212;1</sub>. The model indicated that the jumping height was modified via modifying the motion sequence in the dimension along <bold><italic>w</italic></bold>.</p>
<p>We relied on a simple linear regression (i.e., ridge regression). It is possible to use a more complicated machine learning technique, such as a mixture model [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c46">46</xref>&#x2013;<xref ref-type="bibr" rid="c48">48</xref>], sparse regression technique [<xref ref-type="bibr" rid="c49">49</xref>], or nonlinear regression technique [<xref ref-type="bibr" rid="c50">50</xref>]. We have shown that a nonlinear regression technique, such as Gaussian process regression, is not effective in predicting performance based on motion data [<xref ref-type="bibr" rid="c31">31</xref>], likely because the number of data is limited. Although sparse regression, nonlinear regression, or a mixture model can show better predictive performance if the number of the data is high enough in general, it is difficult to find certain relations between the principal components and estimated parameters via those methods. Ridge regression enables the determination of not only task-relevant and task-irrelevant variabilities but also the relevance of each PC to performance.</p>
<p>To our knowledge, only a few studies have investigated how variability is modulated through motor adaptation [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c34">34</xref>]. A previous study clarified that the variability is modulated after motor adaptation by utilizing a constant force field [<xref ref-type="bibr" rid="c34">34</xref>]. To our knowledge, it was not clarified whether the perturbation schedule affected the modulation. The current study suggests that the perturbation schedule affects the modulation of variability (<xref ref-type="fig" rid="fig6">Figs. 6A and B</xref>). Because the variability can facilitate exploration [<xref ref-type="bibr" rid="c34">34</xref>], the current study also suggests that constant perturbations facilitate exploration in task-relevant space and that gradually applied perturbations affect the exploration less than constant perturbations. In contrast, a gradually applied perturbation can facilitate exploration in task-irrelevant space, and constant perturbations affect the exploration less than the gradually applied perturbations.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Thirteen healthy volunteers (aged 18-22 years, two females) participated in all of our experiments. On the first day, the participants underwent 10 practice trials and 160 baseline trials with pseudorandomly changing targets (40&#x0025;, 45&#x0025;, 50&#x0025;, 55&#x0025;, or 60&#x0025; of the maximum jump height) and became accustomed to the experimental setting. At the second, third, fourth, and fifth days (not consecutive), they joined experiments 1, 2, and 3. They joined experiment 2 for two days. All participants were informed of the experimental procedures and their confirmation with the Declaration of Helsinki, and all participants provided written informed consent before the initiation of the experiments. All procedures were approved by the ethics committee of the Tokyo University of Agriculture and Technology.</p>
<p>Data acquisition and processing. Jumping motions were recorded at 120 Hz using six cameras (Optitrack Flex 13, NaturalPoint Inc., Corvallis, Oregon). Markers were attached to the back (TV10), right hip joint (Femur greater Trochanter), right knee (Femur Lateral Epicondyle and Femur Medial Epicondyle), right foot (Fibula Apex of Lateral Malleolus and Tibia Apex of Medial Malleolus), and right toe (Head of 2nd Metatarsus) of the participants. Marker position data were filtered using a 12th-order, 10 Hz zero-phase Butterworth filter using MATLAB 2016a. Joint angles between the right toe and foot (<italic>q</italic><sub>1</sub>), right foot and shank (<italic>q</italic><sub>2</sub>), and right thigh and shank (<italic>q</italic><sub>3</sub>) were calculated in the sagittal plane (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>). Because the current study focused on a vertical jump while crossing arms in front of the trunk, it was possible to focus only on lower limb motions. Throughout the current study, we focused on the three-link model of the lower limbs in the sagittal plane.</p>
<p>Release timing was detected based on the moment at which the vertical toe position exceeded 10&#x0025; of the maximum height in each trial. The predictive power was calculated using various time bin lengths including the release timing (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>). When the time bin length was seven, the seventh time frame corresponded to the release timing, the sixth time frame corresponded to one time frame before the release timing, and the other time frames followed accordingly.</p>
</sec>
<sec id="s4b">
<title>Experimental setup</title>
<p>At the beginning of each trial, the subjects were instructed to stand at a fixed position. In each trial, subjects listened to three beeps separated by one-second intervals; the first beep indicated the start of each trial, and the subjects were required to jump at the timing of the third beep.</p>
<p>We measured the position of the marker attached to the subject&#x2019; s back using MATLAB at 30 Hz. In front of the subject (1.5 meters ahead, 1.7 meters above the floor), there was a monitor to with a blue cursor that indicated the height of the marker attached to subject&#x2019; s back and a black bar that indicated target height (<xref ref-type="fig" rid="fig1">Fig. 1B</xref>). Those cursors and bars were displayed one second before the first beep sounded. The blue marker could move only in the vertical axis because the current study focused on the vertical height of the jumping motion. The marker position at time <italic>t</italic> in the y-axis (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>), <italic>y<sub>t</sub></italic>, was displayed on the monitor after being normalized for each subject as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline17.gif"/></alternatives></inline-formula>, where <italic>&#x0177;<sub>t</sub></italic>, where <italic>&#x0177;<sub>t</sub></italic> is the marker position without normalization, <italic>y<sub>0</sub></italic> indicates the initial marker position at each trial, and <italic>y</italic><sub>max</sub> indicates the jumping height with maximum effort in each subject (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>). For the two trials that required the subjects to jump with maximum effort, there was no cursor feedback. One second before the first beep, <italic>y<sub>t</sub></italic> &#x003D; 0, the blue circle was displayed on the black baseline on the monitor. Additionally, the target height <italic>d</italic> was indicated by a black line. Before the baseline trials, the subjects underwent ten practice trials. In those trials, the marker position in each time frame was displayed on the monitor and <italic>d</italic> was pseudorandomly chosen from 0.40, 0.45, 0.50, 0.55, or 0.60 (each value was randomly chosen only once in every five trials). This method enabled the subjects to become acquainted with the experimental setting by confirming the motion trajectory of the marker attached to their back. In baseline trials, the marker position was displayed only at the start and end of each trial. One second before the first beep, the cursor was displayed on baseline position, and a black line was corresponding to <italic>d</italic> was displayed as pseudorandomly chosen from 0.40, 0.45, 0.50, 0.55, or 0.60. At the end of each trial, the cursor was displayed at the maximum value of <italic>y<sub>t</sub></italic> within each trial, which indicated jumping height (<xref ref-type="fig" rid="fig1">Fig. 1B</xref>). When the subjects achieved a jumping motion that was close to the target height (|<italic>d</italic> &#x2013; <italic>y<sub>t</sub></italic>| &#x003C; 0.02), they heard a coin-getting sound to indicate that the jumping motion was successful. After the baseline trials, the subjects underwent 96 learning trials in experiment 1, 30 trials in experiment 2 (the same set of practice and main trials was imposed for two days), and 45 trials in experiment 3.</p>
<p>We utilized a perturbation paradigm to investigate how subjects modify their jumping motion via experiencing sensory prediction errors. For trials with perturbation <italic>p<sub>t</sub></italic>, the position of the cursor was displayed at <italic>y<sub>t</sub></italic> &#x002B; <italic>p<sub>t</sub></italic>. The subjects needed to modify their jumping motion to achiever a lower (when <italic>p</italic> &#x003E; 0) or higher jumping height (when <italic>p</italic> &#x003C; 0). When the displayed jumping height was close to the target height (|<italic>d</italic> &#x2013; (<italic>y<sub>t</sub></italic> &#x002B; <italic>p<sub>t</sub></italic>)| &#x003C; 0.02), the subjects heard a coin-getting sound to indicate that the jumping motion was successful.</p>
</sec>
<sec id="s4c">
<title>Decomposition into task-relevant and task-irrelevant components</title>
<p>The current study relied on linear regression to determine the relation between input data <bold><italic>X</italic></bold> &#x2208; R<sup><italic>T&#x00D7;D</italic></sup> and output data <italic>d</italic> &#x2208; R<sup><italic>T</italic>&#x00D7;1</sup> following <italic>y</italic> &#x003D; <bold><italic>Xw</italic></bold>, where <bold><italic>y</italic></bold> &#x2208; R<sup><italic>T</italic>&#x00D7;1</sup> is the predicted output data and <bold><italic>w</italic></bold> &#x2208; R<sup><italic>D&#x00D7;1</italic></sup> is the best linear coefficients to predict the output data. Although we relied on a ridge regression to estimate <bold><italic>w</italic></bold> (see below), the following decomposition of input data into the task-relevant and task-irrelevant components could be applied to any linear regression technique.</p>
<p>The best linear coefficients <bold><italic>w</italic></bold> enabled not only the prediction of output data (jumping height) but also the dissociation of input data into a task-relevant component <bold><italic>X</italic></bold><sub>rel</sub> and task-irrelevant component <bold><italic>X</italic></bold><sub>irr</sub>. By minimizing the cost function
<disp-formula id="eqn1">
<alternatives>
<graphic xlink:href="339648_eqn1.gif"/>
</alternatives>
</disp-formula>
under the constraint <bold><italic>X</italic></bold> &#x2260; <bold><italic>X</italic></bold><sub>rel</sub> (avoidance of a self-evident answer), <bold><italic>X</italic></bold><sub>rel</sub> can be written as
<disp-formula id="eqn2">
<alternatives>
<graphic xlink:href="339648_eqn2.gif"/>
</alternatives>
</disp-formula>
where (<bold><italic>ww</italic></bold><sup><italic>T</italic></sup>)<sup>&#x2020;</sup> is a pseudo-inverse of <bold><italic>ww</italic></bold><sup><italic>T</italic></sup> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline18.gif"/></alternatives></inline-formula>. The equality <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline19.gif"/></alternatives></inline-formula> holds when <bold><italic>w</italic></bold> &#x2208; R<sup><italic>D</italic>&#x00D7;1</sup>. Under the decomposition <bold><italic>X</italic></bold> &#x003D; <bold><italic>X</italic></bold><sub>rel</sub> &#x002B; <bold><italic>X</italic></bold><sub>irr</sub>, <bold><italic>X</italic></bold><sub>irr</sub> can be written as
<disp-formula id="eqn3">
<alternatives>
<graphic xlink:href="339648_eqn3.gif"/>
</alternatives>
</disp-formula>
where <bold><italic>I</italic></bold> &#x2208; R<sup><italic>D&#x00D7;D</italic></sup> is an identity matrix.</p>
<p>Under the condition <bold><italic>X</italic></bold> &#x003D; <bold><italic>X</italic></bold><sub>rel</sub> &#x002B; <bold><italic>X</italic></bold><sub>irr</sub>, the variance of the ith component of <bold><italic>X</italic></bold>, <italic>X<sub>i</sub></italic>, can be calculated as
<disp-formula id="eqn4">
<alternatives>
<graphic xlink:href="339648_eqn4.gif"/>
</alternatives>
</disp-formula>
where <italic>X<sub>i,t</sub></italic> is <italic>X<sub>i</sub></italic> at the <italic>t</italic>th trial, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline20.gif"/></alternatives></inline-formula> is the ith component of <bold><italic>X</italic></bold><sup>rel</sup> at the <italic>t</italic>th trial, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline21.gif"/></alternatives></inline-formula> is the <italic>i</italic>th component of <bold><italic>X</italic></bold><sup>irr</sup> at the <italic>t</italic>th trial, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline22.gif"/></alternatives></inline-formula> is the covariance between <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline23.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline24.gif"/></alternatives></inline-formula>. Notably, in the current experimental setting, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline25.gif"/></alternatives></inline-formula> in the analyzed trials was close to 0. We thus considered only <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline26.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline27.gif"/></alternatives></inline-formula>.</p>
</sec>
<sec id="s4d">
<title>Ridge regression</title>
<p>The ridge regression enabled us to determine the best one-dimensional linear space <bold><italic>w</italic></bold> &#x2208; R<sup><italic>D&#x00D7;1</italic></sup> in the input data <bold><italic>X</italic></bold> &#x2208; R<sup><italic>T&#x00D7;D</italic></sup> to predict the output data <bold><italic>y</italic></bold> &#x2208; R<sup><italic>T</italic>&#x00D7;1</sup> by minimizing the cost function:
<disp-formula id="eqn5">
<alternatives>
<graphic xlink:href="339648_eqn5.gif"/>
</alternatives>
</disp-formula></p>
<p>The first term on the right-hand side indicates the fitting error, the second term indicates the regularization of <bold><italic>w</italic></bold>, and &#x03BB; is a regularization parameter. The current study determined &#x03BB; to minimize the prediction error based on a 10-fold cross validation, which enabled us to avoid overfitting [<xref ref-type="bibr" rid="c29">29</xref>]. Overfitting, which can appear without any regularization, leads to the selection of a model that is more complicated than the true one. Minimization of the cost function concerning <bold><italic>w</italic></bold> leads to the optimal value for <bold><italic>w</italic></bold>:
<disp-formula id="eqn6">
<alternatives>
<graphic xlink:href="339648_eqn6.gif"/>
</alternatives>
</disp-formula>
where <bold><italic>I</italic></bold> was an identity matrix.</p>
<p>The ridge regression enabled the estimation of an appropriate <bold><italic>w</italic></bold> based on the normalized <italic>y</italic> and <bold><italic>X</italic></bold>, i.e., the mean and standard deviation of <bold><italic>y</italic></bold> and <bold><italic>X</italic></bold> should be normalized to be 0 and 1, respectively; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline28.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline29.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline30.gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline31.gif"/></alternatives></inline-formula>. All the results in the current study depended on the normalized data. Without normalization, <italic>w<sub>i</sub></italic> is estimated to be large when <bold><italic>X</italic></bold><sub><italic>i,t</italic></sub> shows small fluctuations and vice versa, although regularization with parameter &#x03BB; was imposed equally to all the <italic>w<sub>i</sub></italic>; therefore, normalization, especially in <bold><italic>X</italic></bold>, is indispensable for estimating appropriate <bold><italic>w</italic></bold>. Notably, the normalization did not affect interpretation at all because it was possible to restore the original unnormalized data by adding the original mean <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline32.gif"/></alternatives></inline-formula> and multiplying the original standard deviation <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline33.gif"/></alternatives></inline-formula>. To satisfy <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline34.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline35.gif"/></alternatives></inline-formula>, where <bold><italic>w</italic></bold> corresponds to unnormalized data, should be divided by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline36.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline37.gif"/></alternatives></inline-formula> should be subtracted. In total, the normalization is indispensable for estimating an appropriate <bold><italic>w</italic></bold>; however, it did not affect the results at all.</p>
<p>The ridge regression showed high prediction power under the existence of measurement noise in <bold><italic>X</italic></bold>. Under the existence of measurement Gaussian noise <bold><italic>&#x03BE;</italic></bold> with a mean of 0, the standard deviation is <italic>&#x03C3;</italic>, covariance is 0, and the cost function averaged across all the possible noise can be written as
<disp-formula id="eqn7">
<alternatives>
<graphic xlink:href="339648_eqn7.gif"/>
</alternatives>
</disp-formula></p>
<p>The equivalence between <xref ref-type="disp-formula" rid="eqn5">equations (5)</xref> and <xref ref-type="disp-formula" rid="eqn7">(7)</xref> indicates that the ridge regression enabled the selection of the best <bold><italic>w</italic></bold> to predict <bold><italic>y</italic></bold> under the existence of measurement noise while avoiding overfitting.</p>
</sec>
<sec id="s4e">
<title>Parabolic representation of jumping height, three candidates of input data, the UCM and GEM</title>
<p>The vertical position of the marker attached to the subject&#x2019; s back determined the jumping height in the current study. We expected that the jumping height could be predicted well based on the position <italic>p</italic> and velocity <italic>v</italic> of the marker at the release timing as follows
<disp-formula id="eqn8">
<alternatives>
<graphic xlink:href="339648_eqn8.gif"/>
</alternatives>
</disp-formula>
where <italic>g</italic> &#x2243; 9.8(<italic>m/s</italic><sup>2</sup>). In the current setting, the markers attached to the subject&#x2019; s back and hip joint showed similar velocities (i.e., the joint angle between the hip joint and back equaled close to 90&#x00B0; at the release timing); it was thus possible to predict the jumping height based on the position and velocity of the marker attached to the hip joint and the release timing, although there was a constant bias between the position of the markers attached to the back and hip. In other words, the position and velocity of the hip joint were factors relevant to task performance in the current study. In the joint angle representation, p and v were written as follows:
<disp-formula id="eqn9">
<alternatives>
<graphic xlink:href="339648_eqn9.gif"/>
</alternatives>
</disp-formula>
and
<disp-formula id="eqn10">
<alternatives>
<graphic xlink:href="339648_eqn10.gif"/>
</alternatives>
</disp-formula></p>
<p>In the UCM (blue crosses in <xref ref-type="fig" rid="fig4">Fig. 4A</xref>), we calculated the task-relevant and task-irrelevant variabilities based on <xref ref-type="disp-formula" rid="eqn9">equations (9)</xref> and <xref ref-type="disp-formula" rid="eqn10">(10)</xref>.</p>
<p>Using the <xref ref-type="disp-formula" rid="eqn9">equations (9)</xref> and <xref ref-type="disp-formula" rid="eqn10">(10)</xref>, the predicted jumping height <italic>h<sub>t</sub></italic> can be written as
<disp-formula id="eqn11">
<alternatives>
<graphic xlink:href="339648_eqn11.gif"/>
</alternatives>
</disp-formula></p>
<p>The first candidate input data for the ridge regression were the joint angles and angular velocities (blue line in <xref ref-type="fig" rid="fig3">Fig. 3A</xref>). The second candidate data were the functions in the forward kinematics of the position and velocity of the hip joint (<xref ref-type="disp-formula" rid="eqn9">equations (9)</xref> and <xref ref-type="disp-formula" rid="eqn10">(10)</xref>, red line in <xref ref-type="fig" rid="fig3">Fig. 3A</xref>). The third candidate data were the functions that appeared in <xref ref-type="disp-formula" rid="eqn11">equation (11)</xref> (orange line in <xref ref-type="fig" rid="fig3">Fig. 3A</xref>). In GEM (blue crosses in <xref ref-type="fig" rid="fig4">Fig. 4A</xref>), we calculated the task-relevant and task-irrelevant variabilities based on <xref ref-type="disp-formula" rid="eqn11">equation (11)</xref>.</p>
</sec>
<sec id="s4f">
<title>Relation between ridge regression and principal component analysis</title>
<p>It was possible to analytically determine the relation between the ridge regression and principal component analysis (PCA) by decomposing <bold><italic>X</italic></bold> using singular value decomposition (SVD), <bold><italic>X</italic></bold> &#x003D; <bold><italic>UDV</italic></bold><sup><italic>T</italic></sup>, where <bold><italic>U</italic></bold> &#x2208; R<sup><italic>T&#x00D7;T</italic></sup> is an orthogonal matrix, <bold><italic>D</italic></bold> &#x2208; R<sup><italic>T&#x00D7;D</italic></sup> includes the square root of the <italic>i</italic>th eigenvalue of <bold><italic>X</italic></bold><sup><italic>T</italic></sup><bold><italic>X</italic></bold> at (<italic>i, i</italic>) element and <italic>D<sub>i,j</sub></italic> &#x003D; 0 when <italic>i</italic> &#x2260; <italic>j</italic>, and <bold><italic>V</italic></bold> &#x2208; R<sup><italic>D&#x00D7;D</italic></sup> is an orthogonal matrix. Using the SVD and <xref ref-type="disp-formula" rid="eqn6">equation (6)</xref>, the predicted output <italic>h<sub>t</sub></italic> can be written as
<disp-formula id="eqn12">
<alternatives>
<graphic xlink:href="339648_eqn12.gif"/>
</alternatives>
</disp-formula>
where min(<italic>T, D</italic>) determines the rank of <bold><italic>X</italic></bold>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline38.gif"/></alternatives></inline-formula> is an eigenvalue of <bold><italic>X</italic></bold><sup><italic>T</italic></sup><bold><italic>X</italic></bold>, Corr(&#x00B7;, &#x00B7;) indicates the correlation between two vectors, <bold><italic>v</italic></bold><sub><italic>i</italic></sub> is the eigenvector of <bold><italic>X</italic></bold><sup><italic>T</italic></sup><bold><italic>X</italic></bold> corresponding to <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline39.gif"/></alternatives></inline-formula>, and <italic>u<sub>i,t</sub></italic> is the (<italic>i,t</italic>) component of <bold><italic>U</italic></bold>. On the other hand, PCA enables the decomposition of <bold><italic>X</italic></bold><sub><italic>t</italic></sub> as
<disp-formula id="eqn13">
<alternatives>
<graphic xlink:href="339648_eqn13.gif"/>
</alternatives>
</disp-formula></p>
<p>This equation indicates that the motion data can be decomposed into eigenvectors (principal components) with weight &#x03BB;<sub><italic>i</italic></sub><italic>u<sub>i,t</sub></italic>. By comparing <xref ref-type="disp-formula" rid="eqn12">equations (12)</xref> and <xref ref-type="disp-formula" rid="eqn13">(13)</xref>, the ridge regression enables the prediction of output data by weighting based on the ith eigenvector with weight <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline40.gif"/></alternatives></inline-formula> (notably, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline41.gif"/></alternatives></inline-formula> was a monotonic function concerning &#x03BB;<sub><italic>i</italic></sub>). An important difference between PCA and the ridge regression is whether the task relevance of the ith eigenvector, Corr(<bold><italic>Xv</italic></bold><sub><italic>i</italic></sub>, <bold><italic>y</italic></bold>), should be considered. Although PCA relies only on the eigenvalue, the ridge regression considers both (nonlinearly transformed) eigenvalue and task relevance. The ridge regression could thus be considered an extended version of PCA to determine how each principal component is relevant to the task.</p>
<p>In PCA, we found the relation between the explained variance and prediction power to be as follows: at a <italic>s</italic>&#x0025; explained variance, we determine the number of principal components based on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline42.gif"/></alternatives></inline-formula> (i.e., the minimum number of principal components that exceed <italic>s</italic>&#x0025; explained variance). After determining <italic>n<sub>s</sub></italic>, motion data can be reconstructed as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline43.gif"/></alternatives></inline-formula>. We then multiply <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline44.gif"/></alternatives></inline-formula> by the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline45.gif"/></alternatives></inline-formula> from the right-hand side, resulting in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline46.gif"/></alternatives></inline-formula>. Finally, we calculate the correlation between observed jumping height <italic>h<sub>t</sub></italic> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="339648_inline47.gif"/></alternatives></inline-formula> in <xref ref-type="fig" rid="fig4">Figs. 4C-4E</xref>.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgement</title>
<p>This work was supported by a Grant-in-Aid for Young Scientists (18K17894). We thank D. Nozaki and S. Hagio for their helpful comments.</p>
</ack>
<sec sec-type="supplementary-material">
<title>Additional Information</title>
<p>Competing financial interests: The authors declare no competing financial interests.</p>
</sec>
<sec>
<title>Author contributions</title>
<p>D.F. and K.T. designed and performed the experiments. D.F. and K.T. performed the analyses and wrote the manuscript.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="book"><string-name><surname>Bernstein</surname>, <given-names>N. A.</given-names></string-name> <source>The co-ordination and regulation of movements</source>. <publisher-name>Pergamon</publisher-name>, <publisher-loc>London</publisher-loc> (<year>1967</year>).</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><surname>Faisal</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Selen</surname>, <given-names>L. P. J.</given-names></string-name> &#x0026; <string-name><surname>Wolpert</surname>, <given-names>D. M.</given-names></string-name> <article-title>Noise in the nervous system</article-title>. <source>Nature Neuroscience</source> <volume>9</volume>, <fpage>292</fpage>&#x2013;<lpage>303</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><surname>Churchland</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Afshar</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name> <article-title>A Central Source of Movement Variability</article-title>. <source>Neuron</source> <volume>52</volume>, <fpage>1085</fpage>&#x2013;<lpage>1096</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><surname>Jones</surname>, <given-names>K. E.</given-names></string-name>, <string-name><surname>Hamilton</surname>, <given-names>A. F.</given-names></string-name> &#x0026; <string-name><surname>Wolpert</surname>, <given-names>D. M.</given-names></string-name> <article-title>Sources of signal-dependent noise during isometric force production</article-title>. <source>Journal of Neurophysiology</source> <volume>88</volume>, <fpage>1533</fpage>&#x2013;<lpage>1544</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><surname>Dhawale</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>M. A.</given-names></string-name> &#x0026; <string-name><surname>Olveczky</surname>, <given-names>B. P.</given-names></string-name> <article-title>The Role of Variability in Motor Learning</article-title>. <source>Annual Review of Neuroscience</source> <volume>40</volume>, <fpage>479</fpage>&#x2013;<lpage>498</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><surname>Bizzi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Mussa-Ivaldi</surname>, <given-names>F. A.</given-names></string-name> &#x0026; <string-name><surname>Giszter</surname>, <given-names>S.</given-names></string-name> <article-title>Computations underlying the execution of movement: a biological perspective</article-title>. <source>Science</source> <volume>253</volume>, <fpage>287</fpage>&#x2013;<lpage>291</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><surname>Gribble</surname>, <given-names>P. L.</given-names></string-name>, <string-name><surname>Mullin</surname>, <given-names>L. I.</given-names></string-name>, <string-name><surname>Cothros</surname>, <given-names>N.</given-names></string-name> &#x0026; <string-name><surname>Mattar</surname>, <given-names>A.</given-names></string-name> <article-title>Role of cocontraction in arm movement accuracy</article-title>. <source>Journal of Neurophysiology</source> <volume>89</volume>, <fpage>2396</fpage>&#x2013;<lpage>2405</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><surname>Latash</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Scholz</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Sch&#x00f6;ner</surname>, <given-names>G.</given-names></string-name> <article-title>Motor control strategies revealed in the structure of motor variability</article-title>. <source>Exercise and sport sciences reviews</source> <volume>30</volume>, <fpage>26</fpage>&#x2013;<lpage>31</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><surname>Rokni</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Richardson</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>Bizzi</surname>, <given-names>E.</given-names></string-name> &#x0026; <string-name><surname>Seung</surname>, <given-names>H. S.</given-names></string-name> <article-title>Motor Learning with Unstable Neural Representations</article-title>. <source>Neuron</source> <volume>54</volume>, <fpage>653</fpage>&#x2013;<lpage>666</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Okada</surname>, <given-names>M.</given-names></string-name> <article-title>Maximization of Learning Speed in the Motor Cortex Due to Neuronal Redundancy</article-title>. <source>PLoS Computational Biology</source> <volume>8</volume>, <fpage>e1002348</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><surname>Scholz</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Sch&#x00f6; ner</surname>, <given-names>G.</given-names></string-name> <article-title>The uncontrolled manifold concept: identifying control variables for a functional task</article-title>. <source>Experimental Brain Research</source> <volume>126</volume>, <fpage>289</fpage>&#x2013;<lpage>306</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><surname>Todorov</surname>, <given-names>E.</given-names></string-name> &#x0026; <string-name><surname>Jordan</surname>, <given-names>M. I.</given-names></string-name> <article-title>Optimal feedback control as a theory of motor coordination</article-title>. <source>Nature Neuroscience</source> <volume>5</volume>, <fpage>1226</fpage>&#x2013;<lpage>1235</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><surname>M&#x00fc;ller</surname>, <given-names>H.</given-names></string-name> &#x0026; <string-name><surname>Sternad</surname>, <given-names>D</given-names></string-name>. <article-title>A randomization method for the calculation of covariation in multiple nonlinear relations: illustrated with the example of goal-directed movements</article-title>. <source>Biological Cybernetics</source> <volume>89</volume>, <fpage>22</fpage>&#x2013;<lpage>33</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><surname>Cusumano</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Cesari</surname>, <given-names>P.</given-names></string-name> <article-title>Body-goal variability mapping in an aiming task</article-title>. <source>Biological Cybernetics</source> <volume>94</volume>, <fpage>367</fpage>&#x2013;<lpage>379</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="other"><string-name><surname>Kaufman</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>S. I.</given-names></string-name> &#x0026; <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name> <article-title>Cortical activity in the null space: permitting preparation without movement</article-title>. <source>Nature Neuroscience</source> <fpage>1</fpage>&#x2013;<lpage>12</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><surname>Krishnamoorthy</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Latash</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Scholz</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Zatsiorsky</surname>, <given-names>V. M.</given-names></string-name> <article-title>Muscle synergies during shifts of the center of pressure by standing persons</article-title>. <source>Experimental Brain Research</source> <volume>152</volume>, <fpage>281</fpage>&#x2013;<lpage>292</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><surname>Valero-Cuevas</surname>, <given-names>F. J.</given-names></string-name>, <string-name><surname>Venkadesan</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Todorov</surname>, <given-names>E.</given-names></string-name> <article-title>Structured Variability of Muscle Activations Supports the Minimal Intervention Principle of Motor Control</article-title>. <source>Journal of Neurophysiology</source> <volume>102</volume>, <fpage>59</fpage>&#x2013;<lpage>68</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><surname>Yang</surname>, <given-names>J.-F.</given-names></string-name>, <string-name><surname>Scholz</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Latash</surname>, <given-names>M. L.</given-names></string-name> <article-title>The role of kinematic redundancy in adaptation of reaching</article-title>. <source>Experimental Brain Research</source> <volume>176</volume>, <fpage>54</fpage>&#x2013;<lpage>69</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><surname>d&#x2019;Avella</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Saltiel</surname>, <given-names>P.</given-names></string-name> &#x0026; <string-name><surname>Bizzi</surname>, <given-names>E.</given-names></string-name> <article-title>Combinations of muscle synergies in the construction of a natural motor behavior</article-title>. <source>Nature Neuroscience</source> <volume>6</volume>, <fpage>300</fpage>&#x2013;<lpage>308</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><surname>Ivanenko</surname>, <given-names>Y. P.</given-names></string-name>, <string-name><surname>Cappellini</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Dominici</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Poppele</surname>, <given-names>R. E.</given-names></string-name> &#x0026; <string-name><surname>Lacquaniti</surname>, <given-names>F.</given-names></string-name> <article-title>Modular control of limb movements during human locomotion</article-title>. <source>The Journal of Neuroscience</source> <volume>27</volume>, <fpage>11149</fpage>&#x2013;<lpage>11161</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><surname>Hagio</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Kouzaki</surname>, <given-names>M.</given-names></string-name> <article-title>The exible recruitment of muscle synergies depends on the required force-generating capability</article-title>. <source>Journal of Neurophysiology</source> <volume>112</volume>, <fpage>316</fpage>&#x2013;<lpage>327</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><surname>Furuya</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Tominaga</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Miyazaki</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Altenm&#x00fc;ller</surname>, <given-names>E</given-names></string-name>. <article-title>Losing dexterity: patterns of impaired coordination of nger movements in musician&#x2019;s dystonia</article-title>. <source>Scientific Reports</source> <volume>5</volume>, <fpage>13360</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><surname>Lacquaniti</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Maioli</surname>, <given-names>C.</given-names></string-name> <article-title>Independent control of limb position and contact forces in cat posture</article-title>. <source>Journal of Neurophysiology</source> <volume>72</volume>, <fpage>1476</fpage>&#x2013;<lpage>1495</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><surname>Dominici</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal> <article-title>Locomotor Primitives in Newborn Babies and Their Development</article-title>. <source>Science</source> <volume>334</volume>, <fpage>997</fpage>&#x2013;<lpage>999</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>D. D.</given-names></string-name> &#x0026; <string-name><surname>Seung</surname>, <given-names>H. S.</given-names></string-name> <article-title>Learning the parts of objects by non-negative matrix factorization</article-title>. <source>Nature</source> <volume>401</volume>, <fpage>788</fpage>&#x2013;<lpage>791</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><surname>Latash</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Scholz</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Sch&#x00f6;ner</surname>, <given-names>G</given-names></string-name>. <article-title>Motor control strategies revealed in the structure of motor variability</article-title>. <source>Exercise and sport sciences reviews</source> <volume>30</volume>, <fpage>26</fpage>&#x2013;<lpage>31</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><surname>Santello</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Soechting</surname>, <given-names>J. F.</given-names></string-name> <article-title>Gradual molding of the hand to object contours</article-title>. <source>Journal of Neuro-physiology</source> <volume>79</volume>, <fpage>1307</fpage>&#x2013;<lpage>1320</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><surname>Delis</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Berret</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Pozzo</surname>, <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Panzeri</surname>, <given-names>S.</given-names></string-name> <article-title>Quantitative evaluation of muscle synergy models: a single-trial task decoding approach</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>7</volume> (<year>2013</year>).</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="book"><string-name><surname>Bishop</surname>, <given-names>C. M.</given-names></string-name> <source>Pattern Recognition and Machine Learning</source> (<publisher-name>Springer Verlag</publisher-name>, <year>2006</year>).</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="other"><string-name><surname>Hoerl</surname>, <given-names>A. E.</given-names></string-name> &#x0026; <string-name><surname>Kennard</surname>, <given-names>R. W.</given-names></string-name> <article-title>Ridge regression: Biased estimation for nonorthogonal problems</article-title>. <source>Technometrics</source> (<year>1970</year>).</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><surname>Furuki</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name> <article-title>Detecting the relevance to performance of whole-body movements</article-title>. <source>Scientific Reports</source> <volume>7</volume>, <fpage>15659</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><surname>Krakauer</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Pine</surname>, <given-names>Z. M.</given-names></string-name>, <string-name><surname>Ghilardi</surname>, <given-names>M. F.</given-names></string-name> &#x0026; <string-name><surname>Ghez</surname>, <given-names>C.</given-names></string-name> <article-title>Learning of visuomotor transformations for vectorial planning of reaching trajectories</article-title>. <source>The Journal of Neuroscience</source> <volume>20</volume>, <fpage>8916</fpage>&#x2013;<lpage>8924</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><surname>Cotti</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> <article-title>Adaptation of reactive and voluntary saccades: different patterns of adaptation revealed in the antisaccade task</article-title>. <source>The Journal of Physiology</source> <volume>587</volume>, <fpage>127</fpage>&#x2013;<lpage>138</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="other"><string-name><surname>Wu</surname>, <given-names>H. G.</given-names></string-name>, <string-name><surname>Miyamoto</surname>, <given-names>Y. R.</given-names></string-name>, <string-name><surname>Castro</surname>, <given-names>L. N. G.</given-names></string-name>, <string-name><surname>lveczky</surname>, <given-names>B. P. O.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>M. A.</given-names></string-name> <article-title>Temporal structure of motor variability is dynamically regulated and predicts motor learning ability</article-title>. <source>Nature Neuroscience</source> <fpage>1</fpage>&#x2013;<lpage>13</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><surname>Kagerer</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Contreras-Vidal</surname>, <given-names>J. L.</given-names></string-name> &#x0026; <string-name><surname>Stelmach</surname>, <given-names>G. E.</given-names></string-name> <article-title>Adaptation to gradual as compared with sudden visuo-motor distortions</article-title>. <source>Experimental Brain Research</source> <volume>115</volume>, <fpage>557</fpage>&#x2013;<lpage>561</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="other"><string-name><surname>Sternad</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>S.-W.</given-names></string-name>, <string-name><surname>Mueller</surname>, <given-names>H.</given-names></string-name> &#x0026; <string-name><surname>Hogan</surname>, <given-names>N.</given-names></string-name> <article-title>Coordinate Dependence of Variability Analysis</article-title>. <source>PLoS Computational Biology</source> <fpage>6</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><surname>Shinya</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Pitching form determines probabilistic structure of errors in pitch location</article-title>. <source>Journal of sports sciences</source> <volume>35</volume>, <fpage>2142</fpage>&#x2013;<lpage>2147</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><surname>Thoroughman</surname>, <given-names>K. A.</given-names></string-name> &#x0026; <string-name><surname>Shadmehr</surname>, <given-names>R.</given-names></string-name> <article-title>Learning of action through adaptive combination of motor primitives</article-title>. <source>Nature</source> <volume>407</volume>, <fpage>742</fpage>&#x2013;<lpage>747</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><surname>Scheidt</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Dingwell</surname>, <given-names>J. B.</given-names></string-name> &#x0026; <string-name><surname>Mussa-Ivaldi</surname>, <given-names>F. A.</given-names></string-name> <article-title>Learning to move amid uncertainty</article-title>. <source>Journal of Neurophysiology</source> <volume>86</volume>, <fpage>971</fpage>&#x2013;<lpage>985</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><surname>Donchin</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Francis</surname>, <given-names>J. T.</given-names></string-name> &#x0026; <string-name><surname>Shadmehr</surname>, <given-names>R.</given-names></string-name> <article-title>Quantifying generalization from trial-by-trial behavior of adaptive systems that learn with basis functions: theory and experiments in human motor control</article-title>. <source>The Journal of Neuroscience</source> <volume>23</volume>, <fpage>9032</fpage>&#x2013;<lpage>9045</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Ghazizadeh</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Shadmehr</surname>, <given-names>R.</given-names></string-name> <article-title>Interacting adaptive processes with different timescales underlie short-term motor learning</article-title>. <source>PLoS Biology</source> <volume>4</volume>, <fpage>e179</fpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hirashima</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Nozaki</surname>, <given-names>D.</given-names></string-name> <article-title>Prospective errors determine motor learning</article-title>. <source>Nature Communications</source> <volume>6</volume>, <fpage>5925</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name> <article-title>Context-dependent memory decay is evidence of effort minimization in motor learning: a computational study</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>9</volume>, <fpage>1</fpage>&#x2013;<lpage>10</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="other"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Sakai</surname>, <given-names>Y.</given-names></string-name> <article-title>Balanced motor primitive can explain generalization of motor learning effects between unimanual and bimanual movements</article-title>. <source>Scientic Reports</source> <fpage>1</fpage>&#x2013;<lpage>10</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Sakai</surname>, <given-names>Y.</given-names></string-name> <article-title>A balanced motor primitive framework can simultaneously explain motor learning in unimanual and bimanual movements</article-title>. <source>Neural Networks</source> <volume>86</volume>, <fpage>80</fpage>&#x2013;<lpage>89</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Katahira</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Okada</surname>, <given-names>M.</given-names></string-name> <article-title>Exact inference in discontinuous firing rate estimation using belief propagation</article-title>. <source>Journal of the Physical Society of Japan</source> <volume>78</volume>, <fpage>4003</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Okada</surname>, <given-names>M.</given-names></string-name> <article-title>Detection of hidden structures in nonstationary spike trains</article-title>. <source>Neural Computation</source> <volume>23</volume>, <fpage>1205</fpage>&#x2013;<lpage>1233</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><surname>Naruse</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Takiyama</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Okada</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Umehara</surname>, <given-names>H.</given-names></string-name> <article-title>Statistical method for detecting phase shifts in alpha rhythm from human electroencephalogram data</article-title>. <source>Physical review. E, Statistical, nonlinear, and soft matter physics</source> <volume>87</volume>, <fpage>042708</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="other"><string-name><surname>Tibshirani</surname>, <given-names>R.</given-names></string-name> <article-title>Regression shrinkage and selection via the lasso</article-title>. <source>Journal of the Royal Statistical Society Series B</source> (<year>1996</year>).</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="book"><string-name><surname>Rasmussen</surname>, <given-names>C. E.</given-names></string-name> &#x0026; <string-name><surname>Williams</surname>, <given-names>C. K. I.</given-names></string-name> <source>Gaussian Processes for Machine Learning</source> (<publisher-name>MIT Press</publisher-name>, <year>2006</year>).</mixed-citation></ref>
</ref-list>
</back>
</article>