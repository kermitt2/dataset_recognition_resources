<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/162552</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>pyABC: distributed, likelihood-free inference</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Klinger</surname>
<given-names>Emmanuel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rickert</surname>
<given-names>Dennis</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hasenauer</surname>
<given-names>Jan</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Connectomics</institution>, Max Planck Institute for Brain Research, 60438 Frankfurt, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Institute of Computational Biology</institution>, Helmholtz Zentrum M&#x00FC;nchen - German Research Center for Environmental Health, 85764 Neuherberg, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Center for Mathematics</institution>, Technische Universit&#x00E4;t M&#x00FC;nchen, 85748 Garching, <country>Germany</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>1</label><p><email>emmanuel.klinger@brain.mpg.de</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>162552</elocation-id>
<history>
<date date-type="received">
<day>17</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>17</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>17</day>
<month>7</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="162552.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Summary</title>
<p>Likelihood-free methods are often required for inference in systems biology. While Approximate Bayesian Computation (ABC) provides a theoretical solution, its practical application has often been challenging due to its high computational demands. To scale likelihood-free inference to computationally demanding stochastic models we developed pyABC: a distributed and scalable ABC-Sequential Monte Carlo (ABC-SMC) framework. It implements computation-minimizing and scalable, runtime-minimizing parallelization strategies for multi-core and distributed environments scaling to thousands of cores. The framework is accessible to non-expert users and also enables advanced users to experiment with and to custom implement many options of ABC-SMC schemes, such as acceptance threshold schedules, transition kernels and distance functions without alteration of pyABC&#x2019;s source code. pyABC includes a web interface to visualize ongoing and 1nished ABC-SMC runs and exposes an API for data querying and post-processing.</p>
<sec sec-type="availability">
<title>Availability and Implementation</title>
<p>pyABC is written in Python 3 and is released under the GPLv3 license. The source code is hosted on <ext-link ext-link-type="uri" xlink:href="https://github.com/neuralyzer/pyabc">https://github.com/neuralyzer/pyabc</ext-link> and the documentation on <ext-link ext-link-type="uri" xlink:href="http://pyabc.readthedocs.io">http://pyabc.readthedocs.io</ext-link>. It can be installed from the Python Package Index (PyPI).</p>
</sec>
</abstract>
<counts>
<page-count count="5"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>The development of predictive models of biological processes requires the estimation of parameters from experimental data. For model classes such as ordinary differential equations, tailored approaches exploiting speci1c model properties have been developed to solve these inverse problems (<xref ref-type="bibr" rid="c6">Raue et al. 2015</xref>). However, this has not been possible for many other relevant model classes such as stochastic models of intracellular processes or multi-scale models of biological tissues. These models are often so involved and problem-speci1c that they have to be considered as black-boxes (<xref ref-type="bibr" rid="c2">Jagiella et al. 2017</xref>). Black-box models can be simulated but their internal structure cannot be exploited. To parameterize these models, likelihood-free methods, such as ABC-SMC schemes (<xref ref-type="bibr" rid="c7">Sisson et al. 2007</xref>; <xref ref-type="bibr" rid="c8">Toni et al. 2009</xref>), have been developed. ABC-SMC schemes use numerical simulations of the model to infer its parameters. Although some ABC-SMC frameworks for Python exist, these frameworks either lack customization options like (adaptive) acceptance threshold schedules or transition kernels, (<xref ref-type="bibr" rid="c4">Kangasr&#x00E4;&#x00E4;si&#x00F6; et al. 2016</xref>), do not implement scalable parallelization strategies (<xref ref-type="bibr" rid="c3">Jennings and Madigan 2017</xref>), only parallelize across the cores of a single machine (<xref ref-type="bibr" rid="c1">Ishida et al. 2015</xref>), or only leverage GPUs but not distributed infrastructure (<xref ref-type="bibr" rid="c5">Liepe et al. 2010</xref>). To address these shortcomings we developed pyABC.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Features</title>
<sec id="s2a">
<label>2.1</label>
<title>Usage</title>
<p>Parameter estimation and model selection for simulator-based, black-box models using several different parallelization strategies is implemented in the pyABC framework. The framework&#x2019;s features include
<list list-type="bullet">
<list-item><p>multi-core and distributed execution,</p></list-item>
<list-item><p>computation-minimizing and scalable, runtime-minimizing parallelization,</p></list-item>
<list-item><p>adaptive, local transition kernels and acceptance threshold schedules,</p></list-item>
<list-item><p>web based visualizations of posterior parameter distributions, acceptance thresholds, con1guration options and more,</p></list-item>
<list-item><p>early stopping of model simulations, and</p></list-item>
<list-item><p>a variety of con1guration and custom extension options without alterations of pyABC&#x2019;s source code.</p></list-item>
</list></p>
<p>pyABC can be combined with any user-de1ned computational model, distance function and parameter prior. Models can be de1ned as functions mapping the model parameters onto simulated data. This ensures a high degree of 2exibility and allows the internal usage of, e.g., the Systems Biology Markup Language (SBML) or GPUs. Custom- and scipy.stats-distributions are supported as priors. Post-processing and analysis is supported via the included API which provides pandas data frames, or by directly querying the underlying relational database.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Multi-core and distributed execution</title>
<p>Single-machine multi-core execution and multi-machine distributed execution in cloud and cluster environments is featured by pyABC. A variety of distributed execution engines is supported, such as ad hoc clusters (e.g., the Dask distributed cluster and the IPython parallel cluster), bare grid-submission systems (e.g., SGE and UGE), and Redis based, low-latency setups. Furthermore, two parallelization strategies for the sampling of particles in the individual populations are provided:</p>
<list list-type="bullet">
<list-item><p><italic>Static Scheduling (STAT):</italic> For each particle, one task is started on the available infrastructure. Within each task, proposal parameters are sampled and model simulations are run until exactly one simulation&#x2019;s parameter is accepted (<xref rid="fig1" ref-type="fig">Fig. 1a,b</xref>). Denoting by n the number of desired particles, then even for infrastructures with more than n cores, only n cores are employed. The tasks are queued, if n is larger than the number of cores and are executed as slots become available. STAT aims to minimize the total amount of computation.</p></list-item>
<list-item><p><italic>Dynamic Scheduling (DYN):</italic> Parameter sampling and model simulation is continuously performed on all available hardware until n particles are accepted (<xref rid="fig1" ref-type="fig">Fig. 1c,d</xref>). All running simulations are then waited for to complete, yielding m &#x2265; n accepted particles. The n accepted particles started first are included in the next population while the remaining m&#x2013;n accepted particles are discarded (to prevent bias towards parameters with shorter simulation times). DYN provides a scalable parallelization strategy aiming to minimize the total runtime.</p></list-item>
</list>
<p>For STAT, the degree of parallelism is limited to the population size n and decreases as particles are accepted (<xref rid="fig1" ref-type="fig">Fig. 1a</xref>), whereas DYN uses all available cores until n particles are accepted (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>). Moreover, DYN scales further if the number of available cores is larger than the population size (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>). When communication time is negligible compared to model simulation time, DYN is faster than STAT (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>), however, STAT performs less computation overall (<xref rid="fig1" ref-type="fig">Fig. 1f</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Parameter inference and scalability of pyABC&#x2019;s parallelization strategies. (a-d) Static Scheduling (STAT) and Dynamic Scheduling (DYN) for 5 particles and 8 cores. The core usage (a, c) and the total number of accepted particles (b, d) are depicted over runtime. The color-coding indicates whether a sample satis1es the acceptance threshold and is included in the next population, satis1es the acceptance threshold but is discarded (i.e. not included in the next population) or does not satisfy the acceptance threshold and is rejected. In (c), the 1fth accepted sample (light-blue) is not included in the next population. (e) Mean relative runtime and (f) mean relative total amount of computation of STAT compared to DYN for exponentially distributed simulation times disregarding potential communication overhead.</title></caption>
<graphic xlink:href="162552_fig1.tif"/>
</fig>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Configuration, customization and extension</title>
<p>The pyABC package is modular and extensible facilitating to experiment with and to develop new ABC-SMC schemes. Following the documented API, transition kernels, (adaptive) acceptance threshold schedules, distance functions, summary statistics and other options can be customized and con1gured. Model simulation and distance calculation can be combined to interrupt the simulation and reject it early to reduce the runtime, e.g., if the distance is a cumulative sum as it is commonly the case for time series simulations. The framework can be run on new parallel environments providing corresponding custom map functions or implementations of the concurrent.futures.Executor interface. All customizations are possible without modifying pyABC&#x2019;s source code.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Conclusion</title>
<p>pyABC addresses the need for distributed, likelihood-free inference for computationally demanding models. While pyABC&#x2019;s less scalable STAT strategy is also implemented elsewhere (<xref ref-type="bibr" rid="c3">Jennings and Madigan 2017</xref>), the runtime optimized, more scalable DYN strategy is, to the authors&#x2019; knowledge, not available in any other Python ABC-SMC package. The 2exibility and extensibility of pyABC render it applicable to a broad range of problem classes and infrastructures. We expect it to be used in many 1elds, including the emergent 1eld of multi-scale modeling.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ishida</surname>, <given-names>E. E. O.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>). &#x201C;<article-title>cosmoabc: likelihood-free inference via population Monte Carlo approximate Bayesian computation</article-title>&#x201D;. <source>Astron. Comput</source>. <volume>13</volume>, <fpage>1</fpage>&#x2013;<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Jagiella</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal> (<year>2017</year>). &#x201C;<article-title>Parallelization and high-performance computing enables automated statistical inference of multi-scale models</article-title>&#x201D;. <source>Cell Syst</source>. <volume>4</volume>, <fpage>194</fpage>&#x2013;<lpage>206</lpage>.e9.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Jennings</surname>, <given-names>E.</given-names></string-name> and <string-name><given-names>M.</given-names> <surname>Madigan</surname></string-name> (<year>2017</year>). <article-title>&#x201C;astroABC: an approximate Bayesian computation sequential Monte Carlo sampler for cosmological parameter estimation&#x201D;</article-title>. <source>Astron. Comput</source>. <volume>19</volume>, <fpage>16</fpage>&#x2013;<lpage>22</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Kangas&#x00E4;&#x00E4;asi&#x00F6;</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> (<year>2016</year>). &#x201C;<article-title>ELFI: engine for likelihood-free inference</article-title>&#x201D;. <source>NIPS 2016 Workshop on Advances in Approximate Bayesian Inference</source>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Liepe</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> (<year>2010</year>). &#x201C;<article-title>ABC-SysBio - Approximate Bayesian computation in Python with GPU support</article-title>&#x201D;. <source>Bioinformatics</source> <volume>26</volume>, <fpage>1797</fpage>&#x2013;<lpage>1799</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Raue</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>). &#x201C;<article-title>Data2Dynamics: a modeling environment tailored to parameter estimation in dynamical systems</article-title>&#x201D;. <source>Bioinformatics</source> <volume>31</volume>, <fpage>3558</fpage>&#x2013;<lpage>3560</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Sisson</surname>, <given-names>S. A.</given-names></string-name> <etal>et al.</etal> (<year>2007</year>). &#x201C;<article-title>Sequential Monte Carlo without likelihoods</article-title>&#x201D;. <source>P. Natl. Acad. Sci. USA</source> <volume>104</volume>, <fpage>1760</fpage>&#x2013;<lpage>1765</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Toni</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> (<year>2009</year>). &#x201C;<article-title>Approximate Bayesian computation scheme for parameter inference and model selection in dynamical systems</article-title>&#x201D;. <source>J. R. Soc. Interface</source> <volume>6</volume>, <fpage>187</fpage>&#x2013;<lpage>202</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>