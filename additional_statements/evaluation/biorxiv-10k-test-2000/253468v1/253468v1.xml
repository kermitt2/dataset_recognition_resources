<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/253468</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Idiosyncratic, retinotopic bias in face identification modulated by familiarity</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7931-5272</contrib-id>
<name><surname>di Oleggio Castello</surname> <given-names>Matteo Visconti</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Taylor</surname> <given-names>Morgan</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3164-2340</contrib-id>
<name><surname>Cavanagh</surname> <given-names>Patrick</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6727-7934</contrib-id>
<name><surname>Gobbini</surname> <given-names>M. Ida</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1">
<label>1</label><institution>Department of Psychological &#x0026; Brain Sciences, Dartmouth College</institution>, Hanover NH, 03755, <country>USA</country></aff>
<aff id="a2">
<label>2</label><institution>Department of Psychology Glendon College Toronto ON</institution>, M4N 3M6 <country>Canada</country></aff>
<aff id="a3">
<label>3</label><institution>Dipartimento di Medicina Specialistica, Diagnostica, e Sperimentale, University of Bologna</institution>, 40100 Bologna, <country>Italy</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>corresponding authors: M. Ida Gobbini, <email>maria.i.gobbini@dartmouth.edu</email>, <email>mariaida.gobbini@unibo.it</email> Matteo Visconti di Oleggio Castello, <email>mvdoc.gr@dartmouth.edu</email>, 6207 Moore Hall, Dartmouth College, Hanover, NH 03755, USA</corresp>
<fn><p><bold>Conflict of interest:</bold> The authors declare no competing financial interests.</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>253468</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>24</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>25</day>
<month>1</month>
<year>2018</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions>
<self-uri xlink:href="253468.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>The perception of gender and age of unfamiliar faces is reported to vary idiosyncratically across retinal locations such that, for example, the same androgynous face may appear to be male at one location but female at another. Here we test spatial heterogeneity for the recognition of the <italic>identity</italic> of personally familiar faces. We found idiosyncratic biases that were stable within subjects and that varied more across locations for low as compared to high familiar faces. These data suggest that like face gender and age, face identity is processed, in part, by independent populations of neurons monitoring restricted spatial regions and that the recognition responses vary for the same face across these different locations. Moreover, repeated exposure to the same face in different portions of the visual field due to repeated and varied social interactions appears to lead to adjustment of these independent face recognition neurons so that the same familiar face is eventually more likely to elicit the same recognition response across widely separated regions.</p>
<sec>
<title>Significance statement</title>
<p>In this work we tested spatial heterogeneity for the recognition of personally familiar faces. We found retinotopic biases that varied more across locations for low as compared to highly familiar faces. The retinotopic biases were idiosyncratic and stable within subjects. Our data suggest that, like face gender and age, face identity is processed by independent populations of neurons monitoring restricted spatial regions and that recognition may vary for the same face at these different locations. Unlike previous findings, our data show how the effect of learning modifies the representation of face identity in retinotopically-organized visual cortex. This new perspective has broader implications for understanding how learning optimizes visual processes for socially salient stimuli.</p>
</sec>
</abstract>
<counts>
<page-count count="29"/>
</counts>
</article-meta>
<ack>
<title>Acknowledgments</title>
<p>We would like to thank the Marten&#x2019;s Family Fund for its support.</p>
</ack>
</front>
<body>
<sec id="s2">
<title>Introduction</title>
<p>We spend most of our days interacting with acquaintances, family and close friends. Because of these repeated and protracted interactions, the representation of personally familiar faces is rich and complex, as reflected by stronger and more widespread neural activation in the distributed face processing network, as compared to responses to unfamiliar faces (<xref rid="c16" ref-type="bibr">Gobbini and Haxby, 2007</xref>; <xref rid="c25" ref-type="bibr">Taylor et al., 2009</xref>; <xref rid="c14" ref-type="bibr">Gobbini, 2010</xref>; <xref rid="c21" ref-type="bibr">Natu and O&#x2019;Toole, 2011</xref>; <xref rid="c5" ref-type="bibr">Bobes et al., 2013</xref>; <xref rid="c24" ref-type="bibr">Sugiura, 2014</xref>; <xref rid="c22" ref-type="bibr">Ramon and Gobbini, 2017</xref>; <xref rid="c28" ref-type="bibr">Visconti di Oleggio Castello et al., 2017a</xref>). Differences in representations of familiar as compared to unfamiliar faces is also reflected in faster detection of familiar faces and more robust recognition (<xref rid="c6" ref-type="bibr">Burton et al., 1999</xref>; <xref rid="c15" ref-type="bibr">Gobbini et al., 2013</xref>; <xref rid="c23" ref-type="bibr">Ramon et al., 2015</xref>; <xref rid="c26" ref-type="bibr">Visconti di Oleggio Castello and Gobbini, 2015</xref>; <xref rid="c29" ref-type="bibr">Visconti di Oleggio Castello et al., 2017b</xref>). Thus, despite the subjective feeling of expertise with faces in general (<xref rid="c9" ref-type="bibr">Diamond and Carey, 1986</xref>), our visual system seems to be optimized for the processing of familiar faces. The mechanisms underlying the prioritized processing of familiar faces are still a matter of investigation (<xref rid="c18" ref-type="bibr">Guntupalli and Gobbini, 2017</xref>; <xref rid="c22" ref-type="bibr">Ramon and Gobbini, 2017</xref>; <xref rid="c31" ref-type="bibr">Young and Burton, 2017</xref>).</p>
<p>The advantage for familiar faces could originate at different stages of the visual processing stream. In a study measuring saccadic reaction time, correct and reliable saccades to familiar faces were recorded as fast as 180 ms when unfamiliar faces were distractors (<xref rid="c26" ref-type="bibr">Visconti di Oleggio Castello and Gobbini, 2015</xref>). At such short latencies it is unlikely that a viewpoint-invariant representation of an individual face&#x2019;s identity drives the saccadic response. To account for facilitated, rapid detection of familiarity, we have previously hypothesized that personally familiar faces may be recognized quickly based on diagnostic, idiosyncratic features, which become highly learned through extensive personal interactions (<xref rid="c26" ref-type="bibr">Visconti di Oleggio Castello and Gobbini, 2015</xref>; <xref rid="c29" ref-type="bibr">Visconti di Oleggio Castello et al., 2017b</xref>). In a study of perception of gaze direction and head angle, changes in eye gaze were detected around 100ms faster in familiar than in unfamiliar faces (<xref rid="c26" ref-type="bibr">Visconti di Oleggio Castello and Gobbini, 2015</xref>). These data provide support for the hypothesis that facial features that are diagnostic for identity are processed more efficiently for familiar as compared to unfamiliar faces. Detection of these features may occur early in the visual hierarchy, allowing an initial, fast differential processing for personally familiar faces.</p>
<p>Processes occurring at early stages of the visual system can show idiosyncratic retinotopic biases (<xref rid="c17" ref-type="bibr">Greenwood et al., 2017</xref>). <xref rid="c1" ref-type="bibr">Afraz et al. (2010</xref>) reported retinotopic biases for perceiving face gender and age that vary depending on stimulus location in the visual field and were specific to each subject. These results suggest that neurons in higher-order face areas have restricted receptive fields or, equivalently, that diagnostic facial features for gender and age are encoded in retinotopic visual cortices. Here we reasoned that diagnostic visual features that play a role in visual processes for individuating faces may show idiosyncratic retinotopic biases and that these biases may be tuned by repeated interactions with personally familiar faces. Such biases may affect recognition of the identities presented in different parts of the visual field and may be modulated by the familiarity of those identities.</p>
<p>We tested this hypothesis by presenting participants with morphed stimuli of personally familiar individuals that were briefly shown at different retinal locations. In two separate experiments we found that participants showed idiosyncratic biases for specific identities in different visual field locations, and these biases were stable on retesting after weeks. Importantly, the range of the retinal biases was inversely correlated with the reported familiarity of each target identity, suggesting that prolonged personal interactions with the target individuals reduced retinal biases. These findings provide additional support for the hypothesis that asymmetries in the processing of personally familiar faces can arise at stages of the visual processing hierarchy where there is still retinotopic coding.</p>
</sec>
<sec id="s3">
<title>Materials and Methods</title>
<sec id="s3a">
<title>Stimuli</title>
<p>Pictures of the faces of individuals who were personally familiar to the participants (graduate students in the same department) were taken in a photo studio room with the same lighting condition and the same camera. Images of two individuals were used for Experiment 1, and images of three individuals were used for Experiment 2. All individuals portrayed in the stimuli signed written informed consent to use their pictures for research and in publications.</p>
<p>The images were converted to grayscale, resized and centered so that the eyes were aligned in the same position for the three identities, and the background was manually removed. These operations were performed using ImageMagick and Adobe Photoshop CS4. The resulting images were matched in luminance (average pixel intensity) using the SHINE toolbox (function <italic>lumMatch</italic>) (<xref rid="c30" ref-type="bibr">Willenbockel et al., 2010</xref>) after applying an oval mask, so that only pixels belonging to the face were modified. The luminance-matched images were then used to create morph continua (between two identities in Experiment 1, see <xref rid="fig2" ref-type="fig">Figure 2</xref>; and among three identities in Experiment 2, see <xref rid="fig3" ref-type="fig">Figure 3</xref>) using Abrosoft Fantamorph (v. 5.4.7) with seven percentages of morphing: 0, 17, 33, 50, 67, 83, 100 (see <xref rid="fig2" ref-type="fig">Figures 2</xref>, <xref rid="fig3" ref-type="fig">3</xref>).</p>
</sec>
<sec id="s3b">
<title>Experiment 1</title>
<sec id="s3b1">
<title>Paradigm</title>
<p>The experimental paradigm was similar to that by (<xref rid="c1" ref-type="bibr">Afraz et al., 2010</xref>). In every trial participants would see a briefly flashed image in one of eight locations at the periphery of their visual field (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). Each image was shown for 50 ms at a distance of 7&#x02DA; of visual angle from the fixation point, and subtended approximately 4&#x02DA; x 4&#x02DA; of visual angle. The images could appear in one of eight locations evenly spaced by 45 angular degrees. For Experiment 1, only the morph <italic>ab</italic> was used (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). Participants were required to maintain fixation on a central red dot subtending approximately 1&#x02DA; of visual angle.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption>
<title>Experimental paradigm.</title> <p>The left panel shows an example of the experimental paradigm, while the right panel shows the angular locations used in Experiment 1 (eight locations, top panel) and in Experiment 2 (four locations, bottom panel).</p></caption>
<graphic xlink:href="253468_fig1.tif"/>
</fig>
<p>After the image disappeared, participants reported which identity they saw using the left (identity <italic>a</italic>) and right (identity <italic>b</italic>) arrow keys. There was no time limit for responding, and participants were asked to be as accurate as possible. After responding, participants had to press the spacebar key to continue to the next trial.</p>
<p>Participants performed five blocks containing 112 trials each, for a total of 560 trials. In each block all the images appeared twice for every angular location (8 angular locations &#x00D7; 7 morph percentages &#x00D7; 2 = 112). This provided ten data points for each percentage morphing at each location, for a total of 70 trials at each angular location.</p>
<p>Before the experimental session participants were shown the identities used in the experiment (corresponding to 0&#x0025; and 100&#x0025; morphing, see <xref rid="fig2" ref-type="fig">Figure 2</xref>), and practiced the task with 20 trials. These data were discarded from the analyses. Participants performed two identical experimental sessions at least four weeks apart.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption>
<title>Stable and idiosyncratic biases in identification in Experiment 1.</title> <p>A) Psychometric fit for two subjects from one of the two sessions. Colors indicate angular location; actual data (points) are shown only for the extreme locations to avoid visual clutter. B) The parameter estimates across sessions (at least 33 days apart) were stable (r = 0.71 [0.47, 0.84], see <xref rid="tbl1" ref-type="table">Table 1</xref>). C) Example morphs used in the experiment. Note that the morphs depicted here are shown for illustration only, and participants saw morphs of identities that were personally familiar to them.</p></caption>
<graphic xlink:href="253468_fig2.tif"/>
</fig>
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>Table 1.</label>
<caption><p>Correlation of parameter estimates across sessions for the two experiments.</p></caption>
<graphic xlink:href="253468_tbl1.tif"/>
</table-wrap>
<p>Participants sat at a distance of approximately 50 cm from the screen, with their chin positioned on a chin-rest. The experiment was run using Psychtoolbox (<xref rid="c20" ref-type="bibr">Kleiner et al., 2007</xref>) (version 3.0.12) in MATLAB (R2014b). The screen operated at a resolution of 1920x1200 and a 60Hz refresh rate.</p>
</sec>
<sec id="s3b2">
<title>Subjects</title>
<p>We recruited six subjects for this experiment (three males, including one of the authors, MVdOC). The sample size for Experiment 1 was not determined by formal estimates of power, and was limited by the availability of participants familiar with the stimulus identities. After the first experimental session, two participants (one male, one female) were at chance level in the task, thus only data from four subjects (two males, mean age 27.50 &#x00B1; 2.08 SD) were used for the final analyses.</p>
<p>All subjects had normal or corrected-to-normal vision, and provided written informed consent to participate in the experiment. The study was approved by the Dartmouth College Committee for the Protection of Human Subjects.</p>
</sec>
</sec>
<sec id="s3c">
<title>Experiment 2</title>
<sec id="s3c1">
<title>Paradigm</title>
<p>Experiment 2 differed from Experiment 1 in the following parameters (see <xref rid="fig1" ref-type="fig">Figures 1</xref>, <xref rid="fig3" ref-type="fig">3</xref>): 1. three morph continua (<italic>ab</italic>, <italic>ac</italic>, <italic>bc</italic>) instead of one; 2. images appeared in four angular locations (45&#x02DA;, 135&#x02DA;, 225&#x02DA;, 315&#x02DA;) instead of eight; 3. images were shown for 100 ms instead of 50 ms to make the task easier.</p>
<p>All other parameters were the same as in Experiment 1. Participants had to indicate which of the three identities they saw by pressing the left (identity <italic>a</italic>), right (identity <italic>b</italic>), or down (identity <italic>c</italic>) arrow keys.</p>
<p>Participants performed ten blocks containing 84 trials each, for a total of 840 trials. In each block all the images appeared once for every angular location (4 angular locations &#x00D7; 7 morph percentages &#x00D7; 3 morphs = 84). We used 70 data points at every angular location to fit the model for each pair of identities. Thus, we used the responses to different unmorphed images for each pair of identities, ensuring independence of the models.</p>
<p>Before the experimental session participants were shown the identities used in the experiment (corresponding to 0&#x0025; and 100&#x0025; morphing, see <xref rid="fig3" ref-type="fig">Figure 3</xref>), and practiced the task with 20 trials. These data were discarded from the analyses. Participants performed two experimental sessions at least four weeks apart.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption>
<title>Stable and idiosyncratic biases in identification in Experiment 2.</title> <p>Stable and idiosyncratic biases in identification in Experiment 2. A) Psychometric fit for one subject from one of the two sessions for each of the morphs. Colors indicate angular location; actual data (points) are shown only for the extreme locations to avoid visual clutter. B) The parameter estimates across sessions (at least 28 days apart) were stable (r = 0.64 [0.5, 0.75], see <xref rid="tbl1" ref-type="table">Table 1</xref>). C) Example morphs used in the experiment. Note that the morphs depicted here are shown only for illustration (participants saw morphs of identities who were personally familiar).</p></caption>
<graphic xlink:href="253468_fig3.tif"/>
</fig>
</sec>
<sec id="s3c2">
<title>Subjects</title>
<p>Ten participants (five males, mean age 27.30 &#x00B1; 1.34 SD) participated in Experiment 2, five of which were recruited for Experiment 1 as well. No authors participated in Experiment 2. The sample size (n = 10) was determined using G&#x002A;Power3 (<xref rid="c12" ref-type="bibr">Faul et al., 2007</xref>, <xref rid="c11" ref-type="bibr">2009</xref>) to obtain 80&#x0025; power at <italic>&#x03B1;</italic> = 0.05 based on the correlation of the PSE estimates across sessions in Experiment 1, using a bivariate normal model (one-tailed).</p>
<p>All subjects had normal or corrected-to-normal vision, and provided written informed consent to participate in the experiment. The study was approved by the Dartmouth College Committee for the Protection of Human Subjects.</p>
</sec>
</sec>
<sec id="s3d">
<title>Familiarity and contact scales</title>
<p>After the two experimental sessions, participants completed a questionnaire designed to assess how familiar each participant was with the identities shown in the experiment. Participants saw each target identity, and were asked to complete various scales for that identity. The questionnaire comprised the &#x201C;Inclusion of the Other in the Self&#x201D; scale (IOS) (<xref rid="c2" ref-type="bibr">Aron et al., 1992</xref>; <xref rid="c13" ref-type="bibr">G&#x00E4;chter et al., 2015</xref>), the &#x201C;Subjective Closeness Inventory&#x201D; (SCI) (<xref rid="c4" ref-type="bibr">Berscheid et al., 1989</xref>), and the &#x201C;We-scale&#x201D; (<xref rid="c8" ref-type="bibr">Cialdini et al., 1997</xref>). The IOS scale showed two circles increasingly overlapping labeled &#x201C;You&#x201D; and &#x201C;X&#x201D;, and participants were given the following instructions: <italic>Using the figure below select which pair of circles best describes your relationship with this person. In the figure &#x201C;X&#x201D; serves as a placeholder for the person shown in the image at the beginning of this section, and you should think of &#x201C;X&#x201D; being that person. By selecting the appropriate number please indicate to what extent you and this person are connected (<xref rid="c2" ref-type="bibr">Aron et al., 1992</xref>; <xref rid="c13" ref-type="bibr">G&#x00E4;chter et al., 2015</xref>)</italic>. The SCI scale comprised the two following questions: <italic>Relative to all your other relationships (both same and opposite sex) how would you characterize your relationship with the person shown at the beginning of this section?</italic>, and <italic>Relative to what you know about other people's close relationships, how would you characterize your relationship with the person shown at the beginning of this section?</italic> Participants responded with a number between one <italic>(Not close at all)</italic> and seven <italic>(Very close) (<xref rid="c4" ref-type="bibr">Berscheid et al., 1989</xref>)</italic>. The We-scale comprised the following question: <italic>Please select the appropriate number below to indicate to what extent you would use the term &#x201C;WE&#x201D; to characterize you and the person shown at the beginning of this section.</italic> Participants responded with a number between one <italic>(Not at all)</italic> and seven <italic>(Very much so).</italic> For each participant and each identity we created a composite &#x201C;familiarity score&#x201D; by averaging the scores in the three scales.</p>
<p>We also introduced a scale aimed at estimating the amount of interaction or contact between the participant and the target identity. The scale was based on the work by (<xref rid="c19" ref-type="bibr">Idson and Mischel, 2001</xref>), and participants were asked to respond Yes/No to the following six questions: <italic>Have you ever seen him during a departmental event?</italic>, <italic>Have you ever seen him during a party?</italic>, <italic>Have you ever had a group lunch/dinner/drinks with him?</italic>, <italic>Have you ever had a one-on-one lunch/dinner/drinks with him?</italic>, <italic>Have you ever texted him personally (not a group message)?</italic>, and <italic>Have you ever emailed him personally (not a group email)?</italic> The responses were converted to 0/1 and for each participant and for each identity we created a &#x201C;contact score&#x201D; by summing all the responses.</p>
<p>For each subject separately, to obtain a measure of familiarity and contact related to each morph, we averaged the familiarity and contact scores of each pair of identities (e.g., the familiarity score of morph <italic>ab</italic> was the average of the scores for identity <italic>a</italic> and identity <italic>b</italic>).</p>
</sec>
<sec id="s3e">
<title>Psychometric fit</title>
<p>For both experiments we fitted a group-level psychometric curve using Logit Mixed-Effect models as implemented in <italic>lme4 (<xref rid="c3" ref-type="bibr">Bates et al., 2015</xref>)</italic>. For each experiment and each session, we fitted a model of the form</p>
<disp-formula id="ueqn1">
<alternatives>
<graphic xlink:href="253468_ueqn1.gif"/></alternatives>
</disp-formula>
<p>where <italic>k</italic> indicates the subject, <italic>n</italic> is the number of angular locations (<italic>n = 8</italic> for the first experiment, and <italic>n = 4</italic> for the second experiment), <italic>I<sub>i</sub></italic> is an indicator variable for the angular location, <italic>&#x03B2;<sub>i</sub></italic> are the model fixed-effects, and <italic>z<sub>i</sub></italic> are the subject-level random-effects (random intercept). From this model, we defined for each subject the Point of Subjective Equality (PSE) as the point <italic>x</italic> such that logit(<italic>x</italic>) = 0.5, that is for each angular location</p>
<disp-formula id="ueqn2">
<alternatives>
<graphic xlink:href="253468_ueqn2.gif"/></alternatives>
</disp-formula>
<p>Thus, the PSE for subject <italic>k</italic> at angular location <italic>i</italic> can be decomposed in a population-level PSE and a subject-specific deviation from the population level, indicated with PSE<sup><italic>p</italic></sup> and &#x0394;PSE<sup><italic>k</italic></sup> respectively.</p>
<p>In Experiment 2 we fitted three separate models for each of the morph continua. In addition, prior to fitting we removed all trials in which subjects mistakenly reported a third identity. For example, if an image belonging to morph <italic>ab</italic> was presented, and subjects responded with <italic>c</italic>, the trial was removed.</p>
</sec>
<sec id="s3f" sec-type="availability">
<title>Code and data availability</title>
<p>Code and data for both experiments are available at [link removed: will be made public after publication].</p>
</sec>
</sec>
<sec id="s4">
<title>Results</title>
<sec id="s4a">
<title>Experiment 1</title>
<p>In this experiment, participants performed a two-alternative forced-choice (AFC) task on identity discrimination. In each trial they saw a face presented for 50 ms, and were asked to indicate which of the two identities they just saw. Each face could appear in one of eight stimulus locations. Participants performed the same experiment with the same task a second time, at least 33 days after the first session (average 35 days &#x00B1; 4 days standard deviation).</p>
<p>Participants showed stable and idiosyncratic retinal heterogeneity for identification. The PSE estimates for the two sessions were significantly correlated (see <xref rid="tbl1" ref-type="table">Table 1</xref> and <xref rid="fig2" ref-type="fig">Figure 2B</xref>), showing stable estimates, and the within-subject correlations of &#x0394;PSEs (see Methods) was significantly higher than the between-subject correlation (correlation difference: 0.87 [0.64, 1.10], 95&#x0025; BCa confidence intervals (<xref rid="c10" ref-type="bibr">Efron, 1987</xref>); see <xref rid="tbl2" ref-type="table">Table 2</xref>), showing that the biases were idiosyncratic (see <xref rid="fig2" ref-type="fig">Figure 2A</xref> for example fits for two different subjects).</p>
<table-wrap id="tbl2" position="float" orientation="portrait">
<label>Table 2.</label>
<caption><p>Comparison of within-subjects correlations of parameter estimates across sessions with between-subjects correlations.</p></caption>
<graphic xlink:href="253468_tbl2.tif"/>
</table-wrap>
</sec>
<sec id="s4b">
<title>Experiment 2</title>
<p>In this experiment, participants performed a similar task as in Experiment 1, with the following differences. First, each face was presented for 100 ms instead of 50 ms in order to make the task easier; second, each face could belong to one of three morphs, and participants were required to indicate which of three identities the face belonged to; third, each face could appear in four retinal locations instead of eight (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). Each participant performed another experimental session at least 28 days after the first session (average 33 days &#x00B1; 8 days SD).</p>
<p>We found that participants exhibited stable biases across sessions for the three morphs (see <xref rid="tbl1" ref-type="table">Table 1</xref> and <xref rid="fig3" ref-type="fig">Figure 3</xref>). Interestingly, within-subjects correlations were higher than between-subjects correlations for the two morphs that included the identity <italic>c</italic> (morphs <italic>ac</italic> and <italic>bc</italic>), but not for morph <italic>ab</italic> (see <xref rid="tbl2" ref-type="table">Table 2</xref>), suggesting stronger differences in spatial heterogeneity caused by identity <italic>c</italic>. To test this further, we performed a two-way ANOVA on the PSE estimates across sessions with participants and angular locations as factors. The ANOVA was run for each pair of morphs containing the same identity (e.g., for identity <italic>a</italic> the ANOVA was run on data from morphs <italic>ab</italic> and <italic>ac</italic>), and the PSE estimates were transformed to be with respect to the same identity (e.g., for identity <italic>b</italic> we considered PSE<italic><sub>bc</sub></italic> and 100 - PSE<italic><sub>ab</sub></italic>). We found significant interactions between participants and angular locations for identity <italic>b</italic> (F(27, 120) = 1.77, p = 0.01947) and identity <italic>c</italic> (F(27, 120) = 3.34, p = 3.229e-06), but not identity <italic>a</italic> (F(27, 120) =1.17, p = 0.2807), confirming that participants showed increased spatial heterogeneity for identities <italic>b</italic> and <italic>c</italic>. Moreover, inspecting the PSE estimates for each individual subjects (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) revealed lower variance across retinal locations of the biases for morph <italic>ab</italic> than the other two morphs.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption>
<title>The strength of idiosyncratic biases was modulated by personal familiarity.</title> <p>A) Individual subjects&#x2019; &#x0394;PSE for each morph, averaged across sessions. Note the difference in variance across angular locations for the three different morphs (left to right)). B) The variance across angular locations of &#x0394;PSE estimates was inversely correlated with the reported familiarity of the identities (left panel; r = -0.56 [-0.71, -0.30]), even when adjusting for the Contact score (middle panel; r<sub>p</sub> = -0.42 [-0.61, -0.16]). The right panel shows the scatterplot between the Contact score and the &#x0394;PSE variance, adjusted for the Familiarity score, which were significantly correlated as well (r<sub>p</sub> = -0.44 [-0.62, -0.17]). See Methods for definition of the Familiarity score and the Contact score.</p>
</caption>
<graphic xlink:href="253468_fig4.tif"/>
</fig>
<p>The variance of the average &#x0394;PSE estimates across sessions for each subject was significantly correlated with the reported familiarity of the identities (r = -0.56 [-0.71, -0.30], t(28) = -3.59, p = 0.001248), showing that the strength of the retinal bias for identities was inversely modulated by personal familiarity (see <xref rid="fig4" ref-type="fig">Figure 4B</xref>). Because the amount of personal familiarity was correlated with the amount of contact with a target identity (r = 0.45 [0.17, 0.68], t(28) = 2.65, p = 0.01304), we tested whether a linear model predicting &#x0394;PSE with both contact and familiarity as predictors could fit the data better. Both models were significant, but the model with two predictors explained more variance as indicated by higher R<sup>2</sup>: R<sup>2</sup> = 0.45, adjusted R<sup>2</sup> = 0.40 for the model with both Familiarity and Contact scores (F(2, 27) = 10.82, p = 0.0003539), and R<sup>2</sup> = 0.32, adjusted R<sup>2</sup> = 0.29 for the model with the Familiarity score only (F(1, 28) = 12.88, p = 0.001248). Importantly, both predictors were significant (see <xref rid="tbl3" ref-type="table">Table 3</xref>), indicating that familiarity modulated the variance of the &#x0394;PSE estimates in addition to modulation based on the amount of contact with a person. After adjusting for the contact score, the variance of the &#x0394;PSE estimates and the familiarity score were still significantly correlated (r<sub>p</sub> = -0.42 [-0.61, -0.16], t(28) = -2.42, p = 0.02235).</p>
<table-wrap id="tbl3" position="float" orientation="portrait">
<label>Table 3.</label>
<caption><p>Models predicting variance of the &#x0394;PSE estimates across angular locations in Experiment 2.</p></caption>
<graphic xlink:href="253468_tbl3.tif"/>
</table-wrap>
</sec>
</sec>
<sec id="s5">
<title>Discussion</title>
<p><xref rid="c1" ref-type="bibr">Afraz et al. (2010)</xref> reported spatial heterogeneity for recognition of facial attributes such as gender and age, suggesting that relatively independent neural populations tuned to facial features might sample different regions of the visual field. Prolonged social interactions with personally familiar faces lead to facilitated, prioritized processing of those faces. Here we wanted to investigate if this learning of face identity through repeated social interactions also affects these local visual processes, by measuring spatial heterogeneity of identity recognition. We measured whether face identification performance for personally familiar faces differed according to the location in the visual field where face images were presented. We found that participants exhibited idiosyncratic, retinotopic biases for different face identities that were stable across experimental sessions. Importantly, the variability of the retinotopic bias was reduced with increased familiarity with the target identities. These data support the hypothesis that familiarity entails learning visual features that affect processing in visual areas with a retinotopic organization (<xref rid="c28" ref-type="bibr">Visconti di Oleggio Castello et al., 2017a</xref>).</p>
<p>These results extend the reports of spatial heterogeneity in visual processing to face identification. Similar biases exist for high-level judgments such as face gender and age (<xref rid="c1" ref-type="bibr">Afraz et al., 2010</xref>), as well as shape discrimination (<xref rid="c1" ref-type="bibr">Afraz et al., 2010</xref>), crowding, and saccadic precision (<xref rid="c17" ref-type="bibr">Greenwood et al., 2017</xref>). <xref rid="c1" ref-type="bibr">Afraz et al. (2010</xref>) suggested that neurons in IT exhibit biases that are dependent on retinal location because their receptive field sizes are not large enough to provide complete translational invariance, and stimuli in different locations will activate a limited group of neurons. In this work, we show that these perceptual biases for face processing not only exist for gender and age judgments (<xref rid="c1" ref-type="bibr">Afraz et al., 2010</xref>), but also for face identification and that these biases are affected by learning. Retinotopic organization is stronger in earlier visual areas, suggesting that high-level judgments of gender, age, and identity may be biased by variability of feature detectors in visual areas such as the occipital face area, or even earlier.</p>
<p>In this work, we showed that the extent of variation in biases across retinal locations was inversely correlated with the reported familiarity with individuals, suggesting that a history of repeated interaction with a person may tune the responses of neurons to that individual in different retinal locations, generating more homogeneous responses. Repeated exposure to the faces of familiar individuals during real-life social interactions results in a detailed representation of the visual appearance of a personally familiar face. Our results showed that both ratings of familiarity and ratings of amount of contact were strong predictors for reduced retinotopic bias. This supports our hypothesis that facilitated processing might be mediated by the development or tuning of detectors for diagnostic fragments of personally familiar faces that may exist in the visual pathway in areas that still have localized analyses and have a retinotopic organization (<xref rid="c15" ref-type="bibr">Gobbini et al., 2013</xref>; <xref rid="c27" ref-type="bibr">Visconti di Oleggio Castello et al., 2014</xref>, <xref rid="c29" ref-type="bibr">2017b</xref>; <xref rid="c26" ref-type="bibr">Visconti di Oleggio Castello and Gobbini, 2015</xref>).</p>
<p>Future research can investigate the mechanism that generates these biases and how learning reduces them. However, our results suggest that prioritized processing for personally familiar faces may exist at relatively early stages of the visual processing hierarchy, as shown by the local biases reported here. We hypothesize that these differences may be one of the mechanisms that underlies the known behavioral advantages for perception of personally familiar faces (<xref rid="c6" ref-type="bibr">Burton et al., 1999</xref>; <xref rid="c16" ref-type="bibr">Gobbini and Haxby, 2007</xref>; <xref rid="c14" ref-type="bibr">Gobbini, 2010</xref>; <xref rid="c15" ref-type="bibr">Gobbini et al., 2013</xref>; <xref rid="c27" ref-type="bibr">Visconti di Oleggio Castello et al., 2014</xref>, <xref rid="c29" ref-type="bibr">2017b</xref>; <xref rid="c23" ref-type="bibr">Ramon et al., 2015</xref>; <xref rid="c26" ref-type="bibr">Visconti di Oleggio Castello and Gobbini, 2015</xref>; <xref rid="c7" ref-type="bibr">Chauhan et al., 2017</xref>; <xref rid="c22" ref-type="bibr">Ramon and Gobbini, 2017</xref>).</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Afraz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Pashkam</surname> <given-names>MV</given-names></string-name>, <string-name><surname>Cavanagh</surname> <given-names>P</given-names></string-name> (<year>2010</year>) <article-title>Spatial heterogeneity in the perception of face and form attributes</article-title>. <source>Curr Biol</source> <volume>20</volume>:<fpage>2112</fpage>&#x2013;<lpage>2116</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Aron</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aron</surname> <given-names>EN</given-names></string-name>, <string-name><surname>Smollan</surname> <given-names>D</given-names></string-name> (<year>1992</year>) <article-title>Inclusion of Other in the Self Scale and the structure of interpersonal closeness</article-title>. <source>J Pers Soc Psychol</source> <volume>63</volume>:<fpage>596</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Bates</surname> <given-names>D</given-names></string-name>, <string-name><surname>M&#x00E4;chler</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bolker</surname> <given-names>B</given-names></string-name>, <string-name><surname>Walker</surname> <given-names>S</given-names></string-name> (<year>2015</year>) <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>J Stat Softw</source> <volume>67</volume>:<fpage>1</fpage>&#x2013;<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Berscheid</surname> <given-names>E</given-names></string-name>, <string-name><surname>Snyder</surname> <given-names>M</given-names></string-name>, <string-name><surname>Omoto</surname> <given-names>AM</given-names></string-name> (<year>1989</year>) <article-title>The Relationship Closeness Inventory: Assessing the closeness of interpersonal relationships</article-title>. <source>J Pers Soc Psychol</source> <volume>57</volume>:<fpage>792</fpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bobes</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Lage Castellanos</surname> <given-names>A</given-names></string-name>, <string-name><surname>Qui&#x00F1;ones</surname> <given-names>I</given-names></string-name>, <string-name><surname>Garc&#x00ED;a</surname> <given-names>L</given-names></string-name>, <string-name><surname>Valdes-Sosa</surname> <given-names>M</given-names></string-name> (<year>2013</year>) <article-title>Timing and tuning for familiarity of cortical responses to faces</article-title>. <source>PLoS One</source> <volume>8</volume>:<fpage>e76100</fpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Burton</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>S</given-names></string-name>, <string-name><surname>Cowan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bruce</surname> <given-names>V</given-names></string-name> (<year>1999</year>) <article-title>Face Recognition in Poor-Quality Video: Evidence From Security Surveillance</article-title>. <source>Psychol Sci</source> <volume>10</volume>:<fpage>243</fpage>&#x2013;<lpage>248</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Chauhan</surname> <given-names>V</given-names></string-name>, <string-name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></string-name>, <string-name><surname>Soltani</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2017</year>) <article-title>Social Saliency of the Cue Slows Attention Shifts</article-title>. <source>Front Psychol</source> <volume>8</volume>:<fpage>738</fpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Cialdini</surname> <given-names>RB</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Lewis</surname> <given-names>BP</given-names></string-name>, <string-name><surname>Luce</surname> <given-names>C</given-names></string-name>, <string-name><surname>Neuberg</surname> <given-names>SL</given-names></string-name> (<year>1997</year>) <article-title>Reinterpreting the empathy&#x2013;altruism relationship: When one into one equals oneness</article-title>. <source>J Pers Soc Psychol</source> <volume>73</volume>:<fpage>481</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Diamond</surname> <given-names>R</given-names></string-name>, <string-name><surname>Carey</surname> <given-names>S</given-names></string-name> (<year>1986</year>) <article-title>Why faces are and are not special: An effect of expertise</article-title>. <source>J Exp Psychol Gen</source> <volume>115</volume>:<fpage>107</fpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Efron</surname> <given-names>B</given-names></string-name> (<year>1987</year>) <article-title>Better Bootstrap Confidence Intervals</article-title>. <source>J Am Stat Assoc</source> <volume>82</volume>:<fpage>171</fpage>&#x2013;<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Faul</surname> <given-names>F</given-names></string-name>, <string-name><surname>Erdfelder</surname> <given-names>E</given-names></string-name>, <string-name><surname>Buchner</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lang</surname> <given-names>A-G</given-names></string-name> (<year>2009</year>) <article-title>Statistical power analyses using G&#x002A;Power 3.1: tests for correlation and regression analyses</article-title>. <source>Behav Res Methods</source> <volume>41</volume>:<fpage>1149</fpage>&#x2013;<lpage>1160</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Faul</surname> <given-names>F</given-names></string-name>, <string-name><surname>Erdfelder</surname> <given-names>E</given-names></string-name>, <string-name><surname>Lang</surname> <given-names>A-G</given-names></string-name>, <string-name><surname>Buchner</surname> <given-names>A</given-names></string-name> (<year>2007</year>) <article-title>G&#x002A;Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title>. <source>Behav Res Methods</source> <volume>39</volume>:<fpage>175</fpage>&#x2013;<lpage>191</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>G&#x00E4;chter</surname> <given-names>S</given-names></string-name>, <string-name><surname>Starmer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Tufano</surname> <given-names>F</given-names></string-name> (<year>2015</year>) <article-title>Measuring the Closeness of Relationships: A Comprehensive Evaluation of the &#x201C;Inclusion of the Other in the Self&#x201D; Scale</article-title>. <source>PLoS One</source> <volume>10</volume>:<fpage>e0129478</fpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2010</year>) <article-title>Distributed process for retrieval of person knowledge</article-title>. <source>Social neuroscience: Toward understanding the underpinnings of the social mind</source>:<fpage>40</fpage>&#x2013;<lpage>53</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Gors</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Halchenko</surname> <given-names>YO</given-names></string-name>, <string-name><surname>Rogers</surname> <given-names>C</given-names></string-name>, <string-name><surname>Guntupalli</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Hughes</surname> <given-names>H</given-names></string-name>, <string-name><surname>Cipolli</surname> <given-names>C</given-names></string-name> (<year>2013</year>) <article-title>Prioritized Detection of Personally Familiar Faces</article-title>. <source>PLoS One</source> <volume>8</volume>:<fpage>e66620</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Haxby</surname> <given-names>JV</given-names></string-name> (<year>2007</year>) <article-title>Neural systems for recognition of familiar faces</article-title>. <source>Neuropsychologia</source> <volume>45</volume>:<fpage>32</fpage>&#x2013;<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Greenwood</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Szinte</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sayim</surname> <given-names>B</given-names></string-name>, <string-name><surname>Cavanagh</surname> <given-names>P</given-names></string-name> (<year>2017</year>) <article-title>Variations in crowding, saccadic precision, and spatial localization reveal the shared topology of spatial vision</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>114</volume>:<fpage>E3573</fpage>&#x2013;<lpage>E3582</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Guntupalli</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2017</year>) <article-title>Reading Faces: From Features to Recognition</article-title>. <source>Trends Cogn Sci</source> <volume>21</volume>:<fpage>915</fpage>&#x2013;<lpage>916</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Idson</surname> <given-names>LC</given-names></string-name>, <string-name><surname>Mischel</surname> <given-names>W</given-names></string-name> (<year>2001</year>) <article-title>The personality of familiar and significant people: the lay perceiver as a social-cognitive theorist</article-title>. <source>J Pers Soc Psychol</source> <volume>80</volume>:<fpage>585</fpage>&#x2013;<lpage>596</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Kleiner</surname> <given-names>M</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>D</given-names></string-name>, <string-name><surname>Pelli</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ingling</surname> <given-names>A</given-names></string-name>, <string-name><surname>Murray</surname> <given-names>R</given-names></string-name> (<year>2007</year>) <article-title>What&#x2019;s new in Psychtoolbox-3</article-title>. <source>Perception</source>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Natu</surname> <given-names>V</given-names></string-name>, <string-name><surname>O&#x2019;Toole</surname> <given-names>AJ</given-names></string-name> (<year>2011</year>) <article-title>The neural processing of familiar and unfamiliar faces: A review and synopsis</article-title>. <source>Br J Psychol</source> <volume>102</volume>:<fpage>726</fpage>&#x2013;<lpage>747</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Ramon</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2017</year>) <article-title>Familiarity matters: A review on prioritized processing of personally familiar faces</article-title>. <source>Vis cogn</source>:<fpage>1</fpage>&#x2013;<lpage>17</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Ramon</surname> <given-names>M</given-names></string-name>, <string-name><surname>Vizioli</surname> <given-names>L</given-names></string-name>, <string-name><surname>Liu-Shuang</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rossion</surname> <given-names>B</given-names></string-name> (<year>2015</year>) <article-title>Neural microgenesis of personally familiar face recognition</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>112</volume>:<fpage>E4835</fpage>&#x2013;<lpage>E4844</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Sugiura</surname> <given-names>M</given-names></string-name> (<year>2014</year>) <article-title>Neuroimaging studies on recognition of personally familiar people</article-title>. <source>Front Biosci</source> <volume>19</volume>:<fpage>672</fpage>&#x2013;<lpage>686</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Taylor</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Arsalidou</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bayless</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Morris</surname> <given-names>D</given-names></string-name>, <string-name><surname>Evans</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Barbeau</surname> <given-names>EJ</given-names></string-name> (<year>2009</year>) <article-title>Neural correlates of personally familiar faces: parents, partner and own faces</article-title>. <source>Hum Brain Mapp</source> <volume>30</volume>:<fpage>2008</fpage>&#x2013;<lpage>2020</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2015</year>) <article-title>Familiar Face Detection in 180ms</article-title>. <source>PLoS One</source> <volume>10</volume>:<fpage>e0136548</fpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></string-name>, <string-name><surname>Guntupalli</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>H</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2014</year>) <article-title>Facilitated detection of social cues conveyed by familiar faces</article-title>. <source>Front Hum Neurosci</source> <volume>8</volume>:<fpage>678</fpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></string-name>, <string-name><surname>Halchenko</surname> <given-names>YO</given-names></string-name>, <string-name><surname>Guntupalli</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Gors</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2017a</year>) <article-title>The neural representation of personally familiar and unfamiliar faces in the distributed system for face perception</article-title>. <source>Sci Rep</source> <volume>7</volume>:<fpage>12237</fpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wheeler</surname> <given-names>KG</given-names></string-name>, <string-name><surname>Cipolli</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gobbini</surname> <given-names>MI</given-names></string-name> (<year>2017b</year>) <article-title>Familiarity facilitates feature-based face processing</article-title>. <source>PLoS One</source> <volume>12</volume>:<fpage>e0178895</fpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Willenbockel</surname> <given-names>V</given-names></string-name>, <string-name><surname>Sadr</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fiset</surname> <given-names>D</given-names></string-name>, <string-name><surname>Horne</surname> <given-names>GO</given-names></string-name>, <string-name><surname>Gosselin</surname> <given-names>F</given-names></string-name>, <string-name><surname>Tanaka</surname> <given-names>JW</given-names></string-name> (<year>2010</year>) <article-title>Controlling low-level image properties: The SHINE toolbox</article-title>. <source>Behav Res Methods</source> <volume>42</volume>:<fpage>671</fpage>&#x2013;<lpage>684</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Young</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Burton</surname> <given-names>AM</given-names></string-name> (<year>2017</year>) <article-title>Are We Face Experts?</article-title> <source>Trends Cogn Sci</source>.</mixed-citation></ref>
</ref-list>
</back>
</article>