<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/306951</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>FMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Esteban</surname><given-names>Oscar</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6533-164X</contrib-id>
<name><surname>Markiewicz</surname><given-names>Christopher J.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Blair</surname><given-names>Ross W.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0867-1469</contrib-id>
<name><surname>Moodie</surname><given-names>Craig A.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1652-9297</contrib-id>
<name><surname>Isik</surname><given-names>A. Ilkay</given-names></name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9402-2184</contrib-id>
<name><surname>Erramuzpe</surname><given-names>Asier</given-names></name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4892-2659</contrib-id>
<name><surname>Kent</surname><given-names>James D.</given-names></name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7252-7771</contrib-id>
<name><surname>Goncalves</surname><given-names>Mathias</given-names></name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1358-196X</contrib-id>
<name><surname>DuPre</surname><given-names>Elizabeth</given-names></name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Snyder</surname><given-names>Madeleine</given-names></name>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1733-5478</contrib-id>
<name><surname>Oya</surname><given-names>Hiroyuki</given-names></name>
<xref ref-type="aff" rid="a9">9</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5312-6729</contrib-id>
<name><surname>Ghosh</surname><given-names>Satrajit S.</given-names></name>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a10">10</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wright</surname><given-names>Jessey</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9030-2202</contrib-id>
<name><surname>Durnez</surname><given-names>Joke</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6755-0259</contrib-id>
<name><surname>Poldrack</surname><given-names>Russell A.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x2021;</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3321-7583</contrib-id>
<name><surname>Gorgolewski</surname><given-names>Krzysztof J.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x2021;</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, Stanford University</institution>, California, <country>USA</country>;</aff>
<aff id="a2"><label>2</label><institution>Medical School Center, Stanford University</institution>, California, <country>USA</country>;</aff>
<aff id="a3"><label>3</label><institution>Max Planck Institute for Empirical Aesthetics</institution>, Hesse, <country>Germany</country>;</aff>
<aff id="a4"><label>4</label><institution>Computational Neuroimaging Lab, Biocruces Health Research Institute</institution>, Bilbao, <country>Spain</country>;</aff>
<aff id="a5"><label>5</label><institution>Neuroscience Program, University of Iowa</institution>, <country>USA</country>;</aff>
<aff id="a6"><label>6</label><institution>McGovern Institute for Brain Research, Massachusetts Institute of Technology: MIT</institution>, Cambridge, MA, <country>USA</country>;</aff>
<aff id="a7"><label>7</label><institution>Montreal Neurological Institute, McGill University</institution>;</aff>
<aff id="a8"><label>8</label><institution>Department of Psychiatry, Stanford Medical School, Stanford University</institution>, California, <country>USA</country>;</aff>
<aff id="a9"><label>9</label><institution>Department of Neurosurgery, University of Iowa Health Care</institution>, Iowa City, Iowa;</aff>
<aff id="a10"><label>10</label><institution>Department of Otolaryngology, Harvard Medical School</institution>, Boston, MA, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label><bold>For correspondence:</bold> <email>phd@oscaresteban.es</email> (OE); <email>krzysztof.gorgolewski@gmail.com</email> (KG)</corresp>
<fn id="n1" fn-type="equal"><label>&#x2021;</label><p>Contributed equally to this work</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>306951</elocation-id>
<history>
<date date-type="received">
<day>25</day>
<month>4</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>25</day>
<month>4</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>25</day>
<month>4</month>
<year>2018</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="306951.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<p>Preprocessing of functional MRI (fMRI) involves numerous steps to clean and standardize data before statistical analysis. Generally, researchers create <italic>ad hoc</italic> preprocessing workflows for each new dataset, building upon a large inventory of tools available for each step. The complexity of these workflows has snowballed with rapid advances in MR data acquisition and image processing techniques. We introduce <italic>fMRIPrep</italic>, an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for task-based and resting fMRI data. <italic>FMRIPrep</italic> automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing with no manual intervention. By introducing visual assessment checkpoints into an iterative integration framework for software-testing, we show that <italic>fMRIPrep</italic> robustly produces high-quality results on a diverse fMRI data collection comprising participants from 54 different studies in the OpenfMRI repository. We review the distinctive features of <italic>fMRIPrep</italic> in a qualitative comparison to other preprocessing workflows. We demonstrate that <italic>fMRIPrep</italic> achieves higher spatial accuracy as it introduces less uncontrolled spatial smoothness than one commonly used preprocessing tool. <italic>FMRIPrep</italic> has the potential to transform fMRI research by equipping neuroscientists with a high-quality, robust, easy-to-use and transparent preprocessing workflow which can help ensure the validity of inference and the interpretability of their results.</p>
</abstract>
<counts>
<page-count count="20"/>
</counts>
</article-meta>
</front>
<body>
<sec>
<p>Functional magnetic resonance imaging (fMRI) is a commonly used technique to map human brain activity<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. However, the blood-oxygen-level dependent (BOLD) signal measured by fMRI is typically mixed with many non-neural sources of variability<sup><xref ref-type="bibr" rid="c2">2</xref></sup>. Preprocessing identifies the nuisance sources and reduces their effect on the data<sup><xref ref-type="bibr" rid="c3">3</xref></sup>. Other major preprocessing steps<sup><xref ref-type="bibr" rid="c4">4</xref></sup> deal with particular imaging artifacts and the anatomical location of signals. For instance, slice-timing<sup><xref ref-type="bibr" rid="c5">5</xref></sup> correction (STC), head-motion correction (HMC), and susceptibility distortion correction (SDC) address particular artifacts; while coregistration, and spatial normalization are concerned with signal location (see Online Methods, sec. Preprocessing of fMRI in a nutshell, for a summary). Extracting a signal that is most faithful to the underlying neural activity is crucial to ensure the validity of inference and interpretability of results<sup><xref ref-type="bibr" rid="c6">6</xref></sup>. Faulty preprocessing may lead to the interpretation of noise patterns as signals of interest. For example, Power et al. demonstrated that unaccounted-for head-motion can generate spurious and systematic correlations in resting-state fMRI<sup><xref ref-type="bibr" rid="c7">7</xref></sup>, which would be interpreted as functional connectivity. An illustration of failed spatial normalization familiar to most researchers is finding significant activation outside of thebrain. Other preprocessing choices may result in the removal of signal originating from brain activity. The ongoing debate on the need for regressing out global signals<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref></sup> reflects just such concerns. Thus, a primary goal of preprocessing is to reduce sources of Type I errors without inducing excessive Type II errors.</p>
<p>Workflows for preprocessing fMRI produce two broad classes of outputs: <italic>preprocessed</italic> data (as opposed to <italic>raw</italic>, original data) and measurements of experimental <italic>confounds</italic> for use in later modeling. Preprocessed data generally include new fMRI time-series after the application of retrospective signal correction and filtering algorithms. In addition, these data are typically resampled onto a target space appropriate for analysis, such as a standardized anatomical reference. The <italic>confounds</italic> are additional time-series such as physiological recordings and estimated noise sources that are useful for analysis (e.g. they can be applied as nuisance regressors). Some commonly used confounds include: motion parameters, framewise displacement (FD<sup><xref ref-type="bibr" rid="c7">7</xref></sup>), spatial standard deviation of the data after temporal differencing (DVARS<sup><xref ref-type="bibr" rid="c7">7</xref></sup>), global signals, etc. Preprocessing may include further steps for denoising and estimation of confounds. For instance, dimensionality reduction methods based on principal components analysis (PCA) or independent components analysis (ICA), such as component-based noise correction (<italic>Comp-Cor</italic><sup><xref ref-type="bibr" rid="c10">10</xref></sup>) or automatic removal of motion artifacts (ICA-AROMA<sup><xref ref-type="bibr" rid="c11">11</xref></sup>).</p>
<p>The neuroimaging community is well equipped with tools that implement the majority of the individual steps of preprocessing described so far. These tools are readily available within software packages including AFNI<sup><xref ref-type="bibr" rid="c12">12</xref></sup>, ANTs<sup><xref ref-type="bibr" rid="c13">13</xref></sup>, FreeSurfer<sup><xref ref-type="bibr" rid="c14">14</xref></sup>, FSL<sup><xref ref-type="bibr" rid="c15">15</xref></sup>, Nilearn<sup><xref ref-type="bibr" rid="c16">16</xref></sup>, or SPM<sup><xref ref-type="bibr" rid="c17">17</xref></sup>. Despite the wealth of accessible software and multiple attempts to outline best practices for preprocessing<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c4">4</xref>,<xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup>, the large variety of data acquisition protocols have led to the use of <italic>ad hoc</italic> pipelines customized for nearly every study; for example, Carp<sup><xref ref-type="bibr" rid="c19">19</xref></sup> found 223 unique analysis workflows across 241 fMRI studies. Thus, current preprocessing workflows offer a poor trade-off between the quality of results and robust, consistent performance on datasets other than those that they were built for. Alternatively, researchers can adopt the acquisition protocols defined by large neuroimaging consortia like the Human Connectome Project (HCP<sup><xref ref-type="bibr" rid="c20">20</xref></sup>) or the UK Biobank<sup><xref ref-type="bibr" rid="c21">21</xref></sup>, which then allows the use of their preprocessing pipelines<sup><xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c23">23</xref></sup> developed for those studies. Since these pipelines are optimized for particular data acquisition protocols, they are not applicable to datasets acquired using different protocols. In practice, the neuroimaging community lacks a preprocessing workflow that reliably provides high-quality and consistent results on arbitrary datasets.</p>
<p>Here we introduce <italic>fMRIPrep</italic>, a preprocessing workflow for task-based and resting-state fMRI. <italic>FMRI-Prep</italic> is built around four driving principles: 1) <bold>robustness</bold> to the idiosyncrasies of the input dataset; 2) <bold>quality</bold> of preprocessing outcomes; 3) <bold>transparency</bold> to encourage the scrutiny of preprocessing results for quality, and to facilitate accurate communication of the methods; and 4) <bold>ease-of-use</bold> with the minimization of manual intervention. <italic>FMRIPrep</italic> is robust by virtue of a flexible, self-adapting architecture that combines tools from existing neuroimaging analysis packages. Tools for each processing operation are selected through an evidence-driven and community-informed optimization process. Here we also report a comprehensive evaluation of the workflow on a large and heterogeneous subsample of the OpenfMRI repository, to quantify robustness and quality of the results. This evaluation leverages the comprehensive visual reports generated by <italic>fMRIPrep</italic>, which facilitate assessment and curation of the results. These reports exemplify the &#x201C;glass-box&#x201D; philosophy with which the software was developed; rather than hiding a complex set of operations within a monolithic black box, <italic>fMRIPrep</italic> exposes interim results at multiple steps to encourage active engagement by the scientist.</p></sec>
<sec id="s1">
<title>RESULTS</title>
<p><italic>FMRIPrep</italic> is a robust and convenient tool for researchers and clinicians to prepare both task-based and resting-state fMRI for analysis. Its outputs enable a broad range of applications, including within-subject analysis using functional localizers, voxel-based analysis, surface-based analysis, task-based group analysis, resting-state connectivity analysis, and many others. In the following, we describe the overall architecture, software engineering principles, and a comprehensive validation of the tool.</p>
<sec id="s1a">
<title>A modular design allows for a flexible, adaptive workflow</title>
<p>The foundation of <italic>fMRIPrep</italic> is presented in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The workflow is composed by sub-workflows that are dynamically assembled into different configurations depending on the input data. These building blocks combine tools from widely-used, open-source neuroimaging packages (see <xref ref-type="table" rid="tbl1">Table 1</xref> for a summary). <italic>Nipype</italic><sup><xref ref-type="bibr" rid="c25">25</xref></sup> is used to stage the workflows and to deal with execution details (such as resource management). As presented in <xref ref-type="fig" rid="fig1">Figure 1</xref>, the workflow comprises two major blocks, separated into anatomical and functional MRI processing streams.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>State-of-art neuroimaging offers a large catalog of readily available software tools.</title><p><italic>FMRIPrep</italic> integrates best-in-breed tools for each of the preprocessing tasks that its workflow covers.</p></caption>
<graphic xlink:href="306951_tbl1.tif"/>
</table-wrap>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title><italic>FMRIPrep</italic> is a fMRI preprocessing tool that adapts to the input dataset.</title><p>Leveraging the Brain Imaging Data Structure (BIDS<sup><xref ref-type="bibr" rid="c24">24</xref></sup>), the software self-adjusts automatically, configuring the optimal workflow for the given input dataset. Thus, no manual intervention is required to locate the required inputs (one T1-weighted image and one BOLD series), read acquisition parameters (such as the repetition time -TR- and the slice acquisition-times) or find additional acquisitions intended for specific preprocessing steps (like field maps and other alternatives for the estimation of the susceptibility distortion). Outputs are easy to navigate due to compliance with the BIDS Extension Proposal for derived data (see Online Methods, <italic>Figure S4</italic>).</p></caption>
<graphic xlink:href="306951_fig1.tif"/>
</fig>
<sec id="s1a1">
<title>Automatically understanding the input dataset</title>
<p>The Brain Imaging Data Structure (BIDS<sup><xref ref-type="bibr" rid="c24">24</xref></sup>) allows <italic>fMRIPrep</italic> to precisely identify the structure of the input data and gather all the available metadata (e.g. imaging parameters). <italic>FMRIPrep</italic> reliably adapts to dataset irregularities such as missing acquisitions or runs through a set of heuristics. For instance, if only one participant of a sample lacks field-mapping acquisitions, <italic>fMRIPrep</italic> will by-pass the correction step for that one participant.</p>
</sec>
<sec id="s1a2">
<title>Preprocessing anatomical images</title>
<p>The T1-weighted (T1w) image is corrected for intensity nonuniformity (INU) using <monospace>N4BiasFieldCorrection</monospace><sup><xref ref-type="bibr" rid="c26">26</xref></sup> (ANTs), and skull-stripped using <monospace>antsBrainExtraction.sh</monospace> (ANTs). Skull-stripping is performed through coregistration to a template, with two options available: the OASIS template<sup><xref ref-type="bibr" rid="c27">27</xref></sup> (default) or the NKI template<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. Using visual inspection, we have found that this approach outperforms other common approaches, which is consistent with previous reports<sup><xref ref-type="bibr" rid="c22">22</xref></sup>. When several T1w volumes are found, the INU-corrected versions are first fused into a reference T1w map of the subject with <monospace>mri_robust_template</monospace><sup><xref ref-type="bibr" rid="c29">29</xref></sup> (FreeSurfer). Brain surfaces are reconstructed from the subject&#x2019;s T1w reference (and T2-weighted images if available) using recon-all<sup><xref ref-type="bibr" rid="c30">30</xref></sup> (FreeSurfer). The brain mask estimated previously is refined with a custom variation of a method (originally introduced in Mindboggle<sup><xref ref-type="bibr" rid="c31">31</xref></sup>) to reconcile ANTs-derived and FreeSurfer-derived segmentations of the cortical gray matter (GM). Both surface reconstruction and subsequent mask refinement are optional and can be disabled to save run time when surface-based analysis is not needed. Spatial normalization to the ICBM 152 Nonlinear Asymmetrical template<sup><xref ref-type="bibr" rid="c32">32</xref></sup> (version 2009c) is performed through nonlinear registration with <monospace>antsRegistration</monospace> <sup><xref ref-type="bibr" rid="c33">33</xref></sup> (ANTs), using brain-extracted versions of both the T1w reference and the standard template. ANTs was selected due to its superior performance in terms of volumetric group level over-lap<sup><xref ref-type="bibr" rid="c34">34</xref></sup>. Brain tissues &#x2013;cerebrospinal fluid (CSF), white matter (WM) and GM&#x2013; are segmented from the reference, brain-extracted T1w using <monospace>fast</monospace><sup><xref ref-type="bibr" rid="c35">35</xref></sup> (FSL).</p></sec>
<sec id="s1a3">
<title>Preprocessing functional runs</title>
<p>For every BOLD run found in the dataset, a reference volume and its skull-stripped version are generated using an in-house methodology (reported in Online Methods, sec. Particular processing elements of <italic>fMRIPrep</italic>). Then, head-motion parameters (volume-to-reference transform matrices, and corresponding rotation and translation parameters) are estimated using <monospace>mcflirt</monospace><sup><xref ref-type="bibr" rid="c36">36</xref></sup> (FSL). Among several alternatives (see <xref ref-type="table" rid="tbl1">Table 1</xref>), <monospace>mcflirt</monospace> is used because its results are comparable to other tools<sup><xref ref-type="bibr" rid="c37">37</xref></sup> and it stores the estimated parameters in a format that facilitates the composition of spatial transforms to achieve one-step interpolation (see below). If slice timing information is available, BOLD runs are (optionally) slice time corrected using <monospace>3dTshift</monospace> (AFNI<sup><xref ref-type="bibr" rid="c12">12</xref></sup>). When field map information is available, or the experimental &#x201C;fieldmap-less&#x201D; correction is requested (see Highlights of <italic>fMRIPrep</italic> within the neuroimaging context), SDC is performed using the appropriate methods (see Online Methods, <italic>Figure S3</italic>). This is followed by co-registration to the corresponding T1w reference using boundary-based registration<sup><xref ref-type="bibr" rid="c38">38</xref></sup> with nine degrees of freedom (to minimize remaining distortions). If surface reconstruction is selected, <italic>fMRIPrep</italic> uses <monospace>bbregister</monospace> (FreeSurfer). Otherwise, the boundary based coregistration implemented in <monospace>flirt</monospace> (FSL) is applied. In our experience, <monospace>bbregister</monospace> yields the better results<sup><xref ref-type="bibr" rid="c38">38</xref></sup> due to the high resolution and the topological correctness of the GM/WM surfaces driving registration. To support a large variety of output spaces for the results (e.g. the native space of BOLD runs, the corresponding T1w, FreeSurfer&#x2019;s <italic>fsaverage</italic> spaces, the atlas used as target in the spatial normalization step, etc.), the transformations between spaces can be combined. For example, to generate preprocessed BOLD runs in template space (e.g. MNI), the following transforms are concatenated: head-motion parameters, the warping to reverse susceptibility-distortions (if calculated), BOLD-to-T1w, and T1w-to-template mappings. The BOLD signal is also sampled onto the corresponding participant&#x2019;s surfaces using <monospace>mri_-vol2surf</monospace> (FreeSurfer), when surface reconstruction is being performed. Thus, these sampled surfaces can easily be transformed onto different output spaces available by concatenating transforms calculated throughout <italic>fMRIPrep</italic> and internal mappings between spaces calculated with <monospace>recon-all</monospace>. The composition of transforms allows for a single-interpolation resampling of volumes using <monospace>antsApplyTransforms</monospace> (ANTs). Lanczos interpolation is applied to minimize the smoothing effects of linear or Gaussian kernels<sup><xref ref-type="bibr" rid="c39">39</xref></sup>. Optionally, ICA-AROMA can be performed and corresponding &#x201C;non-aggressively&#x201D; denoised runs are then produced.</p></sec>
<sec id="s1a4">
<title>Extraction of nuisance time-series</title>
<p><italic>FMRIPrep</italic> is analysis-agnostic and thus, it does not perform any temporal denoising. Nonetheless, it provides researchers with a diverse set of confound estimates that could be used for explicit nuisance regression or as part of higher-level models. This lends itself to decoupling preprocessing and behavioral modeling as well as evaluating robustness of final results across different denoising schemes. A set of physiological noise regressors are extracted for the purpose of performing component-based noise correction (<italic>CompCor</italic><sup><xref ref-type="bibr" rid="c10">10</xref></sup>). Principal components are estimated after high-pass filtering the BOLD time-series (using a discrete cosine filter with 128s cut-off) for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). Six tCompCor components are then calculated from the top 5&#x0025; variable voxels within a mask covering the subcortical regions. Such subcortical mask is obtained by heavily eroding the brain mask, which ensures it does not include cortical GM regions. For aCompCor, six components are calculated within the intersection of the aforementioned mask and the union of CSF and WM masks calculated in T1w space, after their projection to the native space of each functional run (using the inverse BOLD-to-T1w transformation). Frame-wise displacement<sup><xref ref-type="bibr" rid="c40">40</xref></sup> is calculated for each functional run, using the implementation in Nipype. DVARS are also calculated using Nipype. Three global signals are extracted within the CSF, the WM, and the whole-brain masks using Nilearn<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. If ICA-AROMA<sup><xref ref-type="bibr" rid="c11">11</xref></sup> is requested, the &#x201C;aggressive&#x201D; noise-regressors are collected and placed within the corresponding confounds files. In addition, a &#x201C;non-aggressive&#x201D; version of preprocessed data is also provided since this variant of ICA-AROMA denoising cannot be performed using only nuisance regressors.</p></sec></sec>
<sec id="s1b">
<title>Visual reports ease quality control and maximize transparency</title>
<p>Users can assess the quality of preprocessing with an individual report generated per participant. <xref ref-type="fig" rid="fig2">Figure 2</xref> shows an example of such reports and describes their structure. Reports contain dynamic and static mosaic views of images at different quality control points along the preprocessing pipeline. Many visual elements of the reports, as well as some of the figures in this manuscript are generated using Nilearn<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. Only a web browser is required to open the reports on any platform, since they are written in hypertext markup language (HTML). HTML also enables the trivial integration within online neuroimaging services such as <ext-link ext-link-type="uri" xlink:href="http://OpenNeuro.org">OpenNeuro.org</ext-link>, and maximizes shareability between peers. These reports effectively minimize the amount of time required for assessing the quality of the results. They also help understand the internals of processing by visually reporting the full provenance of data throughout the workflow. As an additional transparency enhancement, reports are accompanied by a <italic>citation boilerplate</italic> (see Online Methods, <italic>Box S1</italic>) that follows the guidelines for reporting fMRI studies by Poldrack et al.<sup><xref ref-type="bibr" rid="c41">41</xref></sup>. Meant for its inclusion within the methodological section of papers using <italic>fMRIPrep</italic>, the boilerplate provides a literate description of the processing that includes software versions of all tools involved in the particular workflow and gives due credit to all authors of all of the individual pieces of software used within <italic>fMRIPrep</italic>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Anatomy of the visual reports generated by <italic>fMRIPrep</italic>.</title><p>The visual reports ease quality control of the results and help understand the preprocessing flow.</p></caption>
<graphic xlink:href="306951_fig2.tif"/>
</fig></sec>
<sec id="s1c">
<title>Highlights of <italic>fMRIPrep</italic> within the neuroimaging context</title>
<p><italic>FMRIPrep</italic> is not the first preprocessing pipeline for fMRI data. The most widely used neuroimaging packages generally provide workflows, such as <monospace>afni_proc.py</monospace> (AFNI) or <monospace>feat</monospace> (FSL). Other alternatives include C-PAC<sup><xref ref-type="bibr" rid="c42">42</xref></sup> (configurable pipeline for the analysis of connectomes), HCP Pipelines or the Batch Editor of SPM. In this section, we highlight some additional features beyond robustness and quality that will likely incline scientists to find in <italic>fMRIPrep</italic> the best fit for their fMRI preprocessing needs.</p>
<sec id="s1c1">
<title>Analysis-agnostic: <italic>fMRIPrep</italic> is meant to support all kinds of analysis</title>
<p>To some extent, all alternative workflows limit the possible analyses that can be performed on the preprocessed data. These limitations mostly derive from the coordinates space of the outputs and the regular (volume) vs. irregular (surface) sampling of the BOLD signal. For example, HCP Pipelines supports surface-based analyses on subject or template space. Conversely, <monospace>afni_proc.py</monospace>, C-PAC and feat are volume-based only. <italic>FMRIPrep</italic> allows a multiplicity of output spaces including subject-space and atlases for both volume-based and surface-based analyses. While <italic>fMRIPrep</italic> avoids including processing steps that may limit further analysis (e.g. spatial smoothing), other tools are designed to perform preprocessing that supports specific analysis pipelines. For instance, C-PAC performs several processing steps towards the connectivity analysis of resting-state fMRI.</p></sec>
<sec id="s1c2">
<title>Susceptibility distortion correction (SDC) in the absence of field maps</title>
<p>Many legacy and current human fMRI protocols lack the MR field maps necessary to perform standard methods for SDC. <italic>FMRIPrep</italic> adapts the &#x201C;fieldmap-less&#x201D; correction method for diffusion echo-planar imaging (EPI) images introduced by Wang et al.<sup><xref ref-type="bibr" rid="c43">43</xref></sup>. They propose using the same-subject T1w reference as the <italic>undistorted</italic> target in a nonlinear registration scheme. To maximize the similarity between the T2<sup>&#x22C6;</sup> contrast of the EPI scan and the reference T1w, the intensities of the latter are inverted. To regularize the optimization of the deformation field only displacements along the phase-encoding (PE) direction are allowed, and the magnitude of the displacements is modulated using priors. To our knowledge, no other existing pipeline implements &#x201C;fieldmap-less&#x201D; SDC to the BOLD images.</p></sec>
<sec id="s1c3">
<title><italic>FMRIPrep</italic> is thoroughly documented, community-driven, and developed with high-standards of software engineering</title>
<p>Preprocessing pipelines are generally well documented, however the extreme flexibility of <italic>fMRIPrep</italic> makes its proper documentation substantially more challenging. As for other large scientific software communities, <italic>fMRIPrep</italic> contributors pledge to keep the documentation thorough and updated along coding iterations. Packages also differ on the involvement of the community: while <italic>fMRI-Prep</italic> includes researchers in the decision making process and invites their suggestions and contributions, other packages have a more closed model where the feedback from users is more limited (e.g. a mailing list). In contrast to other pipelines, <italic>fMRIPrep</italic> is community-driven. This paradigm allows the fast adoption of cutting-edge advances on fMRI preprocessing. For example, while <italic>fMRIPrep</italic> initially performed STC before HMC, we adapted the tool to the recent recommendations of Power et al.<sup><xref ref-type="bibr" rid="c18">18</xref></sup> upon a user&#x2019;s request<xref ref-type="fn" rid="fn1">&#x002A;</xref>. This model has allowed the user base to grow rapidly and enabled substantial third-party contributions to be included in the software, such as the support for processing datasets without anatomical information. The open-source nature of <italic>fMRIPrep</italic> has permitted frequent code reviews that are effective in enhancing the software&#x2019;s quality and reliability<sup><xref ref-type="bibr" rid="c44">44</xref></sup>. Finally, <italic>fMRIPrep</italic> undergoes continuous integration testing (see Online Methods, <italic>Figure S5</italic>), a technique that has recently been proposed as a mean to ensure reproducibility of analyses in computational sciences<sup><xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c46">46</xref></sup>.</p>
</sec>
<sec id="s1c4">
<title>Ensuring reproducibility with hard versioning and containers</title>
<p>For enhanced reproducibility, <italic>fMRIPrep</italic> fully supports execution via the Docker (<ext-link ext-link-type="uri" xlink:href="https://docker.com">https://docker.com</ext-link>) and Singularity<sup><xref ref-type="bibr" rid="c47">47</xref></sup> container platforms. Container images are generated and uploaded to a public repository for each new version of <italic>fMRIPrep</italic>. This helps address the widespread lack of reporting of specific software versions and the large variability of software versions, which threaten the reproducibility of fMRI analyses<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. These containers are released with a fixed set of software versions for <italic>fMRIPrep</italic> and all its dependencies, maximizing run-to-run reproducibility in an easy way. Except for C-PAC, alternative pipelines do not provide official support for containers. The adoption of the BIDS-Apps<sup><xref ref-type="bibr" rid="c45">45</xref></sup> container model makes <italic>fMRIPrep</italic> amenable to a multiplicity of infrastructures and platforms: PC, high-performance computing (HPC), Cloud, etc.</p></sec></sec>
<sec id="s1d">
<title><italic>FMRIPrep</italic> yields high-quality results on a diverse set of input data</title>
<p><xref ref-type="fig" rid="fig3">Figure 3</xref> presents the validation framework that we applied to iteratively maximize the robustness of the tool and validate the quality of the results. The validation framework implements a testing plan elaborated prior the release of the version 1.0 of the software (see Online Methods, sec. Evaluation of <italic>fMRIPrep</italic>). The plan is divided in two validation phases in which different data samples and validation procedures are applied. <xref ref-type="table" rid="tbl2">Table 2</xref> describes the data samples used on each phase and emphasizes how these data are collected from a large number of different, unrelated studies. In Phase I, we ran <italic>fMRIPrep</italic> on a manually selected sample of participants that are potentially challenging to the tool&#x2019;s robustness, exercising the adaptiveness to the input data. Phase II focused on the visual assessment of the quality of preprocessing results on a large and heterogeneous sample.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Data from <ext-link ext-link-type="uri" xlink:href="http://OpenfMRI">OpenfMRI</ext-link> used in evaluation.</title>
<p>S:number of sessions; T: number of tasks; R: number of BOLD runs; Modalities: number of runs for each modality, per subject (FM indicates acquisitions for susceptibility distortion correction); Part. IDs (phase): participant identifiers included in testing phase; N: total of unique participants; TR: repetition time; #TR: length of time-series (volumes); Resolution: voxel size of BOLD series.</p></caption>
<graphic xlink:href="306951_tbl2.tif"/>
</table-wrap>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Combining visual assessment within the software testing flow.</title>
<p>We complement well-established techniques for software integration testing with manual assessment of the outputs. The evaluation framework is designed with two subsequent testing phases. Phase I focuses on fault-discovery and visual reports are used to better understand the issues found. The top box (Example fix 1) shows an example of defect identified and solved during this testing cycle. After addressing a total of 21 issues affecting 7 datasets, and the release of <italic>fMRIPrep</italic> version 1.0.0, the next testing stage is initiated. Phase II focuses on increasing the overall quality of results as evaluated visually by experts. Following an inspection protocol, reports from 213 participants belonging to 58 different studies were individually assessed. We found 12 additional issues affecting 11 datasets that have been addressed with the release of <italic>fMRIPrep</italic> version 1.0.3 on January 3, 2018. The bottom box (Example fix 2) illustrates one of these issues, which produced errors in the brain extraction process from BOLD data.</p></caption>
<graphic xlink:href="306951_fig3.tif"/>
</fig>
<sec id="s1d1">
<title>Validation Phase I &#x2013; Fault-discovery testing</title>
<p>We tested <italic>fMRIPrep</italic> on a set of 30 datasets from <ext-link ext-link-type="uri" xlink:href="http://OpenfMRI">OpenfMRI</ext-link> (see <xref ref-type="table" rid="tbl2">Table 2</xref>). Included participants were manually selected for their low quality as visually assessed by two experts using MRIQC<sup><xref ref-type="bibr" rid="c105">105</xref></sup> (the assessment protocol is further described in in Online Methods, sec. Evaluation of <italic>fMRIPrep</italic>). Data showing substandard quality are known to likely degrade the outcomes of image processing<sup><xref ref-type="bibr" rid="c105">105</xref></sup>, and therefore they are helpful to test software reliability. Phase I concluded with the release of <italic>fMRIPrep</italic> version 1.0 on December 6, 2017.</p></sec>
<sec id="s1d2">
<title>Validation Phase II &#x2013; Quality assurance and reliability testing</title>
<p>We extended the evaluation data up to 54 datasets from OpenfMRI (see <xref ref-type="table" rid="tbl2">Table 2</xref>). Participants were selected randomly as described in Online Methods, sec. Evaluation of <italic>fMRIPrep</italic>. Validation Phase II integrated a protocol for the screening of results into the software testing (<xref ref-type="fig" rid="fig3">Figure 3</xref>). As shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>, this effectively contributed to substantive improvements on the quality of results. Three raters (authors CJM, KJG and OE) evaluated the 213 visual reports at six quality control points throughout the pipeline, and also assigned an overall score to each participant. Their ratings are made available with the corresponding reports for scrutiny. The scoring scale has three levels: 1 (&#x201C;poor&#x201D;), 2 (&#x201C;acceptable&#x201D;) and 3 (&#x201C;excellent&#x201D;). A special rating of 0 (&#x201C;unusable&#x201D;) is assigned to critical failures that hamper any further processing beyond the quality control checkpoint. After Phase II, 50 datasets out of the total 54 were rated above the &#x201C;acceptable&#x201D; average quality level. The remaining 4 datasets were all above the &#x201C;poor&#x201D; level and in or nearby the &#x201C;acceptable&#x201D; rating. <xref ref-type="fig" rid="fig4">Figure 4</xref> illustrates the quality of results, while Online Methods, <italic>Figure S6</italic> shows the individual evolution of every dataset at each of the seven quality control points. Phase II concluded with the release of <italic>fMRIPrep</italic> version 1.0.8 on February 22, 2018.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Integrating visual assessment into the software testing framework effectively increases the quality of results.</title><p>In an early assessment of quality using <italic>fMRIPrep</italic> version 1.0.0, the overall rating of two datasets was below the &#x201C;poor&#x201D; category and four below the &#x201C;acceptable&#x201D; level (left column of colored circles). After addressing some outstanding issues detected by the early assessment, the overall quality of processing is substantially improved (right column of circles), and no datasets are below the &#x201C;poor&#x201D; quality level. Only two datasets are rated below the &#x201C;acceptable&#x201D; level in the second assessment (using <italic>fMRIPrep</italic> version 1.0.7).</p></caption>
<graphic xlink:href="306951_fig4.tif"/>
</fig></sec></sec>
<sec id="s1e">
<title><italic>FMRIPrep</italic> improves spatial precision through reduced smoothing</title>
<p>We investigate whether the focus on robustness against data irregularity comes at a cost in quality of the preprocessing outcomes by comparing it to the commonly used FSL <monospace>feat</monospace> workflow. Using all the scans of the &#x201C;stopsignal&#x201D; task in DS000030 (N=257 participants) from <ext-link ext-link-type="uri" xlink:href="http://OpenfMRI">OpenfMRI</ext-link>, we ran <italic>fMRIPrep</italic> and a standard <monospace>feat</monospace> workflow. We chose <monospace>feat</monospace> because DS000030 had successfully been preprocessed and analyzed with FSL tools previously<sup><xref ref-type="bibr" rid="c55">55</xref></sup>. Smoothing is intentionally excluded from both preprocessing routes with the aim to apply it early within a common (identical) analysis workflow. We calculated standard deviation maps in MNI space<sup><xref ref-type="bibr" rid="c106">106</xref></sup> for the temporal average map of the &#x201C;stopsignal&#x201D; task derived from preprocessing with both alternatives. Visual inspection of these variability maps (<xref ref-type="fig" rid="fig5">Figure 5</xref>) reveals a higher anatomical accuracy of <italic>fMRIPrep</italic> over <monospace>feat</monospace>, likely reflecting the combined effects of a more precise spatial normalization scheme and the application of &#x201C;fieldmap-less&#x201D; SDC. <italic>FMRIPrep</italic> outcomes are particularly better aligned with the underlying anatomy in regions typically warped by susceptibility distortions such as the orbitofrontal lobe, as demonstrated by close-ups in Online Methods, <italic>Figure S7</italic>.</p>
<p>We also compared preprocessing done with <italic>fMRIPrep</italic> and FSL&#x2019;s <monospace>feat</monospace> in two common fMRI analyses. First, we performed within subject statistical analysis using <monospace>feat</monospace>&#x2013;the same tool provides preprocessing and first-level analysis-on both sets of preprocessed data. Second, we perform a group statistical analysis using ordinary least squares (OLS) mixed modeling (<monospace>flame</monospace><sup><xref ref-type="bibr" rid="c107">107</xref></sup>, FSL). In both experiments, we applied identical analysis workflows and settings to both preprocessing alternatives. Using AFNI&#x2019;s <monospace>3dFWHMx</monospace>, we estimated the smoothness of data right after preprocessing (unsmoothed), and after an initial smoothing step of 5.0mm (full-width half-minimum, FWHM) of the common analysis workflow. As visually suggested by <xref ref-type="fig" rid="fig5">Figure 5</xref>, we indeed found that <monospace>feat</monospace> produces smoother data (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Although preprocessed data were resampled to an isotropic voxel size of 2.0&#x00D7;2.0&#x00D7;2.0 [mm], the smoothness estimation (before the prescribed smoothing step) for <italic>fMRIPrep</italic> was below 4.0mm, very close to the original resolution of 3.0&#x00D7;3.0&#x00D7;4.0 [mm] of these data. The first-level analysis showed that the thresholded activation count maps for the go vs. successful stop contrast in the &#x201C;stopsignal&#x201D; task were very similar (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). It can be seen that the results from both pipelines identified activation in the same regions. However, since data preprocessed with <monospace>feat</monospace> are smoother, the results from <italic>fMRIPrep</italic> are more local and better aligned with the cortical sheet.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Maps of between-subjects variability of the averaged BOLD time-series resampled into MNI space.</title><p>We preprocessed DS000030 (N=257) with <italic>fMRIPrep</italic> and FSL <monospace>feat</monospace>. This figure shows greater between-subject variability of the averaged BOLD series obtained with <monospace>feat</monospace>, in MNI space. The top box of the panel shows these maps at different axial planes of the image grid, with reference contours from the MNI atlas. The map summarizing <monospace>feat</monospace>-derived results displays greater variability outside the brain mask delineated with the black contour. This effect is generally associated with a lower performance of spatial normalization<sup><xref ref-type="bibr" rid="c106">106</xref></sup>. The histogram at the right side plots the normalized frequency of variability (arbitrary units) for both maps, within the brain mask. The distribution corresponding to FSL <monospace>feat</monospace> shows a heavier tail. See Online Methods, <italic>Figure S7</italic> for close-ups into regions affected by susceptibility-derived distortions.</p></caption>
<graphic xlink:href="306951_fig5.tif"/>
</fig>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>A | Estimating the spatial smoothness of data before and after the initial smoothing step of the analysis workflow confirmed that results of preprocessing with <monospace>feat</monospace> are intrinsically smoother. Therefore, <italic>fMRIPrep</italic> allows the researcher for a finer control over the smoothness of their analysis. <bold>B</bold> | Thresholded activation count maps for the go vs. successful stop contrast in the &#x201C;stopsignal&#x201D; task after preprocessing using either <italic>fMRIPrep</italic> or FSL&#x2019;s <monospace>feat</monospace>, with identical single subject statistical modeling. Both tools obtained similar activation maps, with <italic>fMRIPrep</italic> results being slightly better aligned with the underlying anatomy.</p></caption>
<graphic xlink:href="306951_fig6.tif"/>
</fig>
<p>To investigate the implications of either pipeline on the group analysis use-case, we run the same OLS modeling on two disjoint subsets of randomly selected subjects. We calculate several metrics of spatial agreement on the resulting maps of (uncorrected) <italic>p</italic>-statistical values, and also after binarizing these maps with a threshold chosen to control for the false discovery rate at 5&#x0025;. The overlap of statistical maps, as well as Pearson&#x2019;s correlation, were tightly related to the smoothing of the input data. In Online Methods, sec. Comparison to FSL <monospace>feat</monospace> we report the group-level analysis in full. We ran two variants of the analysis: with a prescribed smoothing of 5.0mm FWHM, and without smoothing step. These results showed that, at the group-level analysis, <italic>fMRIPrep</italic> and <monospace>feat</monospace> perform equivalently.</p>
</sec></sec>
<sec id="s2">
<title>DISCUSSION</title>
<p><italic>FMRIPrep</italic> is a fMRI preprocessing workflow developed to excel at four aspects of scientific software: <italic>robustness</italic> to data idiosyncrasies, high <italic>quality</italic> and consistency of results, maximal <italic>transparency</italic> in the assessment of results and subsequent communication, and <italic>ease-of-use</italic>. We describe how using the Brain Imaging Data Structure (BIDS <sup><xref ref-type="bibr" rid="c24">24</xref></sup>) along with a flexible design allows the workflow to self-adapt to the idiosyncrasy of inputs (sec. A modular design allows for a flexible, adaptive workflow). The workflow (briefly summarized in <xref ref-type="fig" rid="fig1">Figure 1</xref>) integrates state-of-art tools from widely used neuroimaging software packages at each preprocessing step (see <xref ref-type="table" rid="tbl1">Table 1</xref>). Some other relevant facets of <italic>fMRIPrep</italic> and how they relate to existing alternative pipelines are presented in sec. Highlights of <italic>fMRIPrep</italic> within the neu-roimaging context. To note some, the analysis-agnostic nature of the tool, or the uniqueness of the &#x201C;fieldmap-less&#x201D; SDC method. We highlight that <italic>fMRIPrep</italic> is developed with the best software engineering principles, which are fundamental to ensure software reliability. The pipeline is easy to use for researchers and clinicians without extensive computer engineering experience, and produces comprehensive visual reports (<xref ref-type="fig" rid="fig2">Figure 2</xref>). These automated reports exemplify the &#x201C;glass-box&#x201D; principle, which requires that software allows scientists to understand how it works internally. This is in contrast to typical &#x201C;black-box&#x201D; applications that perform valuable services without providing a way to understand how the tool has transformed their data into the desired output. These reports maximize transparency by allowing scientists to critically inspect and better understand the underlying mechanisms of their preprocessing.</p>
<p>We demonstrate the robustness of <italic>fMRIPrep</italic> on a data collection from datasets associated with different studies (<xref ref-type="table" rid="tbl2">Table 2</xref>), representing the variety of input data in the field (sec. <italic>FMRIPrep</italic> yields high-quality results on a diverse set of input data). We then interrogate the quality of those results with the individual inspection of the corresponding visual reports by experts (sec. Visual reports ease quality control and maximize transparency and the corresponding summary in <xref ref-type="fig" rid="fig4">Figure 4</xref>). A comparison to FSL&#x2019;s <monospace>feat</monospace> (sec. <italic>FMRIPrep</italic> improves spatial precision through reduced smoothing) demonstrates that <italic>fMRIPrep</italic> achieves higher spatial accuracy and introduces less uncontrolled smoothness (<xref ref-type="fig" rid="fig5">Figures 5</xref>, <xref ref-type="fig" rid="fig6">6</xref>). Group <italic>p</italic>-statistical maps only differed on their smoothness (sharper for the case of <italic>fMRIPrep</italic>). The fact that first-level and second-level analyses resulted in small differences between <italic>fMRIPrep</italic> and our <italic>ad hoc</italic> implementation of a <monospace>feat</monospace>-based workflow indicates that the individual preprocessing steps perform similarly when they are fine-tuned to the input data. That justifies the need for <italic>fMRIPrep</italic>, which autonomously adapts the workflow to the data without error-prone manual intervention. To a limited extent, that also mitigates some concerns and theoretical risks arisen from the analytical degrees-of-freedom<sup><xref ref-type="bibr" rid="c19">19</xref></sup> available to researchers. <italic>FMRIPrep</italic> stands out amongst pipelines because it automates the adaptation to the input dataset without compromising the quality of results.</p>
<p>One limitation of this work is the use of visual (the reports) and semi-visual (e.g. <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="fig" rid="fig6">Figure 6</xref>) assessments for the quality of preprocessing outcomes. Although some frameworks have been proposed for the quantitative evaluation of preprocessing on task-based (such as NPAIRS<sup><xref ref-type="bibr" rid="c108">108</xref></sup>) and resting-state<sup><xref ref-type="bibr" rid="c109">109</xref></sup> fMRI, they impose a set of assumptions on the test data and the workflow being assessed that severely limit their suitability. The modular design of <italic>fMRIPrep</italic> defines an interface to each processing step, which will permit the programmatic evaluation of the many possible combinations of software tools and processing steps. That will also enable the use of quantitative testing frameworks to pursue the minimization of Type I errors without the cost of increasing Type II errors.</p>
<p>The range of possible applications for <italic>fMRIPrep</italic> also presents some boundaries. For instance, very narrow field-of-view (FoV) images oftentimes do not contain enough information for standard image registration methods to work correctly. Reduced FoV datasets from <ext-link ext-link-type="uri" xlink:href="http://OpenfMRI">OpenfMRI</ext-link> were excluded from the evaluation since they are not yet fully supported by <italic>fMRIPrep</italic>. Extending <italic>fMRIPrep</italic>&#x2019;s support for these particular images is already a future line of the development roadmap. <italic>FMRIPrep</italic> may also under-perform for particular populations (e.g. infants) or when brains show nonstandard structures, such as tumors, resected regions or lesions. Nonetheless, <italic>fMRIPrep</italic>&#x2019;s architecture makes it straightforward to extend the tool to support specific populations or new species by providing appropriate atlases of those brains. This future line of work would be particularly interesting in order to adapt the workflow to data collected from rodents and nonhuman primates. By contrast, <italic>fMRIPrep</italic> performed robustly on data from a simultaneous MRI/electrocorticography (ECoG) study, which is extremely challenging to analyze due to the massive BOLD signal drop-out near the implanted cortical electrodes (see Online Methods, <italic>Figure S10</italic>).</p>
<p>Approximately 80&#x0025; of the analysis pipelines investigated by Carp<sup><xref ref-type="bibr" rid="c19">19</xref></sup> were implemented using either AFNI<sup><xref ref-type="bibr" rid="c12">12</xref></sup>, FSL<sup><xref ref-type="bibr" rid="c15">15</xref></sup>, or SPM<sup><xref ref-type="bibr" rid="c17">17</xref></sup>. <italic>Ad hoc</italic> pipelines adapt the basic workflows provided by these tools to the particular dataset at hand. Although workflow frameworks like Nipype<sup><xref ref-type="bibr" rid="c110">110</xref></sup> ease the integration of tools from different packages, these pipelines are typically restricted to just one of these alternatives (AFNI, FSL or SPM). Otherwise, scientists can adopt the acquisition protocols and associated preprocessing software of large consortia like the Human Connectome Project (HCP) or the UK Biobank. This option allows scientists to shortcut the intricacies of preprocessing by applying a &#x201C;black-box&#x201D; that has been validated on similar data by a third party. The <italic>off-the-shelf</italic> applicability of these workflows is contravened by important limitations on the experimental design. Therefore, researchers typically opt to recode their custom preprocessing workflows with nearly every new study<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. That practice entails a &#x201C;pipeline debt&#x201D;, which requires the investment on proper software engineering to ensure an acceptable correctness and stability of the results (e.g. continuous integration testing) and reproducibility (e.g. versioning, packaging, containerization, etc.). A trivial example of this risk would be the leakage of <italic>magic numbers</italic> that are hard-coded in the source (e.g. a crucial imaging parameter that inadvertently changed from one study to the next one). Until <italic>fMRIPrep</italic>, an analysis-agnostic approach that builds upon existing software instruments and optimizes preprocessing for robustness to data idiosyncrasies, quality of outcomes, ease-of-use, and transparency, was lacking.</p>
<p>The rapid increase in volume and diversity of available data, as well as the evolution of more sophisticated techniques for processing and analysis, presents an opportunity for significantly advancing research in neuroscience. However, the influx of new data, new analysis methods, and new modeling strategies represents a risk as well as an opportunity. The inferential promises of big data, and the sophisticated analysis tools that can leverage it, incentivize researchers to progressively build on more complex analysis pipelines that rely on more complex and more obscure models of the data to produce interpretable results. This way of moving forward risks producing a future generation of cognitive neuroscientists who have become experts in using sophisticated computational methods, but have little to no working knowledge of the biological processes underlying brain&#x2019;s function<sup><xref ref-type="bibr" rid="c111">111</xref></sup>. It also obscures important steps in the inductive process mediating between experimental measurements and reported findings. Easy-to-use, <italic>off-the-shelf</italic> tools that function as black boxes &#x2013;providing scientists with limited insight into how the tool functions, and developed primarily behind closed doors&#x2013; may only exacerbate this problem. <italic>FMRIPrep</italic> offers a novel &#x201C;glass-box&#x201D; approach for the development, maintenance and use of computational tools that mitigates these risks. By standardizing preprocessing, <italic>fMRIPrep</italic> allows researchers to focus their attention and expertise on the inferentially significant stages of data production, analysis and interpretation. Additionally, <italic>fMRIPrep</italic> mitigates concerns about black-box processing by being thoroughly documented, producing reports and visualizations at critical quality control points in the workflow, and being developed according to the best practices of open source engineering. These features of <italic>fMRIPrep</italic> make it possible for researchers to learn how the tool works, develop an understanding of each step in the workflow, and even reconstruct the preprocessing pipeline from first principles. <italic>FMRIPrep</italic> aims to better equip fMRI practitioners to perform reliable, reproducible, statistical analyses with a high-standard, consistent, and adaptive preprocessing instrument.</p></sec>
<sec id="s3">
<title>CONCLUSION</title>
<p>Despite efforts to achieve high-quality preprocessing of idiosyncratic fMRI datasets, doing so reliably has remained an open problem. <italic>FMRIPrep</italic> is an analysis-agnostic, preprocessing workflow that yields consistent results across a wide range of input datasets. <italic>FMRIPrep</italic> is built on top of the best neuroimaging tools selected from various software packages. These tools are integrated into workflows that can be dynamically combined to compose a full preprocessing workflow adapted to the input data. The optimal workflow for the input dataset is constructed at runtime, blending a set of heuristics with the Brain Imaging Data Structure (BIDS) to read the inputs. <italic>FMRIPrep</italic> excels in four design goals: robustness, high-quality of results, transparency and ease-of-use. To validate and demonstrate these features, we integrate the individual screening of preprocessing results with continuous integration techniques of software testing. The process is aided by comprehensive, portable reports that inform the scientist about the workflow, ease the quality control of results and maximize the shareability of research outcomes. We highlight the aspects that justify the development of <italic>fMRIPrep</italic> with respect to currently available preprocessing workflows. We quantitatively demonstrate that <italic>fMRIPrep</italic> does not introduce uncontrolled smoothing as compared to one alternative software. <italic>FMRIPrep</italic> aims to better equip fMRI practitioners to perform reliable, reproducible statistical analyses with a high-standard, transparent, and verifiable instrument.</p></sec>
</body>
<back>
<fn-group>
<fn id="fn1"><label>&#x002A;</label><p><ext-link ext-link-type="uri" xlink:href="https://neurostars.org/t/obtaining-movement-estimates-before-slice-time-correction/1007">https://neurostars.org/t/obtaining-movement-estimates-before-slice-time-correction/1007</ext-link></p></fn>
</fn-group>
<ack>
<title>ACKNOWLEDGMENTS</title>
<p>This work was supported by the Laura and John Arnold Foundation, NIH R01 EB020740, NIH 1R24MH114705-01, and NINDS grant 1U01NS103780-01. JD has received funding from the European Union&#x2019;s Horizon 2020 research and innovation program under the Marie Sklodowska-Curie grant agreement No 706561.</p>
</ack>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> &#x0026; <string-name><surname>Farah</surname>, <given-names>M. J.</given-names></string-name> <article-title>Progress and challenges in probing the human brain</article-title>. <source>Nature</source> <volume>526</volume>, <fpage>371</fpage>&#x2013;<lpage>379</lpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1038/nature15692</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Plitt</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name> &#x0026; <string-name><surname>Martin</surname>, <given-names>A.</given-names></string-name> <article-title>Sources and implications of whole-brain fMRI signals in humans</article-title>. <source>NeuroImage</source> <volume>146</volume>, <fpage>609</fpage>&#x2013;<lpage>625</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.09.038</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><string-name><surname>Lindquist</surname>, <given-names>M. A</given-names></string-name>. <article-title>The Statistical Analysis of fMRI Data</article-title>. <source>Statistical Science</source> <volume>23</volume>, <fpage>439</fpage>&#x2013;<lpage>464</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1214/09-STS282</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><string-name><surname>Strother</surname>, <given-names>S. C</given-names></string-name>. <article-title>Evaluating fMRI preprocessing pipelines</article-title>. <source>IEEE Engineering in Medicine and Biology Magazine</source> <volume>25</volume>, <fpage>27</fpage>&#x2013;<lpage>41</lpage> (<year>2006</year>). doi:<pub-id pub-id-type="doi">10.1109/MEMB.2006.1607667</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><string-name><surname>Sladky</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Slice-timing effects and their correction in functional MRI</article-title>. <source>NeuroImage</source> <volume>58</volume>, <fpage>588</fpage>&#x2013;<lpage>594</lpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.06.078</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="book"><string-name><surname>Ashburner</surname>, <given-names>J</given-names></string-name>. <chapter-title>Preparing fMRI Data for Statistical Analysis</chapter-title>. In <person-group person-group-type="editor"><string-name><surname>Filippi</surname>, <given-names>M.</given-names></string-name></person-group> (ed.) <source>fMRI Techniques and Protocols</source>, no. 41 in Neuromethods, <fpage>151</fpage>&#x2013;<lpage>178</lpage> (<publisher-name>Humana Press</publisher-name>, <year>2009</year>). doi:<pub-id pub-id-type="doi">10.1007/978-1-60327-919-2_6</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Barnes</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name> &#x0026; <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name> <article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title>. <source>NeuroImage</source> <volume>59</volume>, <fpage>2142</fpage>&#x2013;<lpage>2154</lpage> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.018</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><string-name><surname>Murphy</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Birn</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Handwerker</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>T. B.</given-names></string-name> &#x0026; <string-name><surname>Bandettini</surname>, <given-names>P. A.</given-names></string-name> <article-title>The impact of global signal regression on resting state correlations: Are anti-correlated networks introduced?</article-title> <source>NeuroImage</source> <volume>44</volume>, <fpage>893</fpage>&#x2013;<lpage>905</lpage> (<year>2009</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.036</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Nalci</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Falahpour</surname>, <given-names>M.</given-names></string-name> <article-title>The global signal in fMRI: Nuisance or Information?</article-title> <source>NeuroImage</source> <volume>150</volume>, <fpage>213</fpage>&#x2013;<lpage>229</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.036</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><string-name><surname>Behzadi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Restom</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Liau</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Liu</surname>, <given-names>T. T.</given-names></string-name> <article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title>. <source>NeuroImage</source> <volume>37</volume>, <fpage>90</fpage>&#x2013;<lpage>101</lpage> (<year>2007</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><string-name><surname>Pruim</surname>, <given-names>R. H. R.</given-names></string-name> <etal>et al.</etal> <article-title>ICA-AROMA: A robust ICA-based strategy for removing motion artifacts from fMRI data</article-title>. <source>NeuroImage</source> <volume>112</volume>, <fpage>267</fpage>&#x2013;<lpage>277</lpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.02.064</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name> &#x0026; <string-name><surname>Hyde</surname>, <given-names>J. S.</given-names></string-name> <article-title>Software tools for analysis and visualization of fMRI data</article-title>. <source>NMR in Biomedicine</source> <volume>10</volume>, <fpage>171</fpage>&#x2013;<lpage>178</lpage> (<year>1997</year>). doi:<pub-id pub-id-type="doi">10.1002/(SICI)1099-1492(199706/08)10:4/5&#x003C;171::AID-NBM453&#x003E;3.0.CO;2-L</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><string-name><surname>Avants</surname>, <given-names>B. B.</given-names></string-name> <etal>et al.</etal> <article-title>A reproducible evaluation of ANTs similarity metric performance in brain image registration</article-title>. <source>NeuroImage</source> <volume>54</volume>, <fpage>2033</fpage>&#x2013;<lpage>44</lpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.09.025</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><string-name><surname>Fischl</surname>, <given-names>B</given-names></string-name>. <article-title>FreeSurfer</article-title>. <source>NeuroImage</source> <volume>62</volume>, <fpage>774</fpage>&#x2013;<lpage>781</lpage> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name> <article-title>FSL</article-title>. <source>NeuroImage</source> <volume>62</volume>, <fpage>782</fpage>&#x2013;<lpage>790</lpage> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><string-name><surname>Abraham</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Frontiers in Neuroinformatics</source> <volume>8</volume> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="book"><string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Ashburner</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kiebel</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name> &#x0026; <string-name><surname>Penny</surname>, <given-names>W. D.</given-names></string-name> <source>Statistical parametric mapping : the analysis of functional brain images</source> (<publisher-name>Academic Press</publisher-name>, <publisher-loc>London</publisher-loc>, <year>2006</year>).</mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Plitt</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kundu</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Bandettini</surname>, <given-names>P. A.</given-names></string-name> &#x0026; <string-name><surname>Martin</surname>, <given-names>A.</given-names></string-name> <article-title>Temporal interpolation alters motion in fMRI scans: Magnitudes and consequences for artifact detection</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0182939</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0182939</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><string-name><surname>Carp</surname>, <given-names>J</given-names></string-name>. <article-title>The secret lives of experiments: Methods reporting in the fMRI literature</article-title>. <source>NeuroImage</source> <volume>63</volume>, <fpage>289</fpage>&#x2013;<lpage>300</lpage> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.07.004</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><string-name><surname>Van Essen</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> <article-title>The Human Connectome Project: A data acquisition perspective</article-title>. <source>NeuroImage</source> <volume>62</volume>, <fpage>2222</fpage>&#x2013;<lpage>2231</lpage> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.02.018</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name> <etal>et al.</etal> <article-title>Multimodal population brain imaging in the UK Biobank prospective epidemiological study</article-title>. <source>Nature Neuroscience</source> <volume>19</volume>, <fpage>1523</fpage>&#x2013;<lpage>1536</lpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1038/nn.4393</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name> <etal>et al.</etal> <article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title>. <source>NeuroImage</source> <volume>80</volume>, <fpage>105</fpage>&#x2013;<lpage>124</lpage> (<year>2013</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><string-name><surname>Alfaro-Almagro</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal> <article-title>Image processing and Quality Control for the first 10,000 brain imaging datasets from UK Biobank</article-title>. <source>NeuroImage</source> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.034</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal> <article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title>. <source>Scientific Data</source> <volume>3</volume>, <fpage>160044</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1038/sdata.2016.44</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal> <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python</article-title>. <source>Zenodo [Software]</source> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.5281/zenodo.50186</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name> <etal>et al.</etal> <article-title>N4ITK: Improved N3 Bias Correction</article-title>. <source>IEEE Transactions on Medical Imaging</source> <volume>29</volume>, <fpage>1310</fpage>&#x2013;<lpage>1320</lpage> (<year>2010</year>). doi:<pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><string-name><surname>Marcus</surname>, <given-names>D. S.</given-names></string-name> <etal>et al.</etal> <article-title>Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>19</volume>, <fpage>1498</fpage>&#x2013;<lpage>1507</lpage> (<year>2007</year>). doi:<pub-id pub-id-type="doi">10.1162/jocn.2007.19.9.1498</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><string-name><surname>Nooner</surname>, <given-names>K. B.</given-names></string-name> <etal>et al.</etal> <article-title>The NKI-Rockland Sample: A Model for Accelerating the Pace of Discovery Science in Psychiatry</article-title>. <source>Frontiers in Neuroscience</source> <volume>6</volume> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.3389/fnins.2012.00152</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><string-name><surname>Reuter</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rosas</surname>, <given-names>H. D.</given-names></string-name> &#x0026; <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name> <article-title>Highly accurate inverse consistent registration: A robust approach</article-title>. <source>NeuroImage</source> <volume>53</volume>, <fpage>1181</fpage>&#x2013;<lpage>1196</lpage> (<year>2010</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.020</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>30</label><mixed-citation publication-type="journal"><string-name><surname>Dale</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Sereno</surname>, <given-names>M. I.</given-names></string-name> <article-title>Cortical Surface-Based Analysis: I. Segmentation and Surface Reconstruction</article-title>. <source>NeuroImage</source> <volume>9</volume>, <fpage>179</fpage>&#x2013;<lpage>194</lpage> (<year>1999</year>). doi:<pub-id pub-id-type="doi">10.1006/nimg.1998.0395</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="journal"><string-name><surname>Klein</surname>, <given-names>A</given-names></string-name>. <etal>et al.</etal> <article-title>Mindboggling morphometry of human brains</article-title>. <source>PLOS Computational Biology</source> <volume>13</volume>, <fpage>e1005350</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1005350</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="journal"><string-name><surname>Fonov</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Evans</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>McKinstry</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Almli</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Collins</surname>, <given-names>D.</given-names></string-name> <article-title>Unbiased nonlinear average age-appropriate brain templates from birth to adulthood</article-title>. <source>NeuroImage</source> <volume>47</volume>, Supplement <issue>1</issue>, <fpage>S102</fpage> (<year>2009</year>). doi:<pub-id pub-id-type="doi">10.1016/S1053-8119(09)70884-5</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><string-name><surname>Avants</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Epstein</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Grossman</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Gee</surname>, <given-names>J.</given-names></string-name> <article-title>Symmetric diffeomorphic image registration with crosscorrelation: Evaluating automated labeling of elderly and neurodegenerative brain</article-title>. <source>Medical Image Analysis</source> <volume>12</volume>, <fpage>26</fpage>&#x2013;<lpage>41</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id>.</mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><string-name><surname>Klein</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration</article-title>. <source>NeuroImage</source> <volume>46</volume>, <fpage>786</fpage>&#x2013;<lpage>802</lpage> (<year>2009</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.12.037</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name> <article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title>. <source>IEEE Transactions on Medical Imaging</source> <volume>20</volume>, <fpage>45</fpage>&#x2013;<lpage>57</lpage> (<year>2001</year>). doi:<pub-id pub-id-type="doi">10.1109/42.906424</pub-id>.</mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bannister</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name> <article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title>. <source>NeuroImage</source> <volume>17</volume>, <fpage>825</fpage>&#x2013;<lpage>841</lpage> (<year>2002</year>). doi:<pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><string-name><surname>Oakes</surname>, <given-names>T. R.</given-names></string-name> <etal>et al.</etal> <article-title>Comparison of fMRI motion correction software tools</article-title>. <source>NeuroImage</source> <volume>28</volume>, <fpage>529</fpage>&#x2013;<lpage>543</lpage> (<year>2005</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.05.058</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="journal"><string-name><surname>Greve</surname>, <given-names>D. N.</given-names></string-name> &#x0026; <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name> <article-title>Accurate and robust brain image alignment using boundary-based registration</article-title>. <source>NeuroImage</source> <volume>48</volume>, <fpage>63</fpage>&#x2013;<lpage>72</lpage> (<year>2009</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><string-name><surname>Lanczos</surname>, <given-names>C</given-names></string-name>. <article-title>Evaluation of Noisy Data</article-title>. <source>Journal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis</source> <volume>1</volume>, <fpage>76</fpage>&#x2013;<lpage>85</lpage> (<year>1964</year>). doi:<pub-id pub-id-type="doi">10.1137/0701007</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="journal"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name> <etal>et al.</etal> <article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title>. <source>NeuroImage</source> <volume>84</volume>, <fpage>320</fpage>&#x2013;<lpage>341</lpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>41</label><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <etal>et al.</etal> <article-title>Guidelines for reporting an fMRI study</article-title>. <source>NeuroImage</source> <volume>40</volume>, <fpage>409</fpage>&#x2013;<lpage>414</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.11.048</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>42</label><mixed-citation publication-type="book"><string-name><surname>Sikka</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <chapter-title>Towards automated analysis of connectomes: The configurable pipeline for the analysis of connectomes (C-PAC)</chapter-title>. In <source>5th INCF Congress of Neuroinformatics</source>, vol. <volume>117</volume> (<publisher-loc>Munich, Germany</publisher-loc>, <year>2014</year>). doi:<pub-id pub-id-type="doi">10.3389/conf.fninf.2014.08.00117</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>43</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>Evaluation of Field Map and Nonlinear Registration Methods for Correction of Susceptibility Artifacts in Diffusion MRI</article-title>. <source>Frontiers in Neuroinformatics</source> <fpage>11</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.3389/fninf.2017.00017</pub-id>.</mixed-citation></ref>
<ref id="c44"><label>44</label><mixed-citation publication-type="book"><string-name><surname>McIntosh</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kamei</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Hassan</surname>, <given-names>A. E.</given-names></string-name> <chapter-title>The Impact of Code Review Coverage and Code Review Participation on Software Quality: A Case Study of the Qt, VTK, and ITK Projects</chapter-title>. In <source>Proceedings of the 11th Working Conference on Mining Software Repositories, MSR</source> <year>2014</year>, <fpage>192</fpage>&#x2013;<lpage>201</lpage> (<publisher-name>ACM</publisher-name>, <publisher-loc>New York, NY, USA</publisher-loc>, 2014). doi:<pub-id pub-id-type="doi">10.1145/2597073.2597076</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>45</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal> <article-title>BIDS Apps: Improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods</article-title>. <source>PLOS Computational Biology</source> <volume>13</volume>, <fpage>e1005209</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1005209</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>46</label><mixed-citation publication-type="journal"><string-name><surname>Beaulieu-Jones</surname>, <given-names>B. K.</given-names></string-name> &#x0026; <string-name><surname>Greene</surname>, <given-names>C. S.</given-names></string-name> <article-title>Reproducibility of computational workflows is automated using continuous analysis</article-title>. <source>Nature Biotechnology</source> <volume>35</volume>, <fpage>342</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1038/nbt.3780</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>47</label><mixed-citation publication-type="journal"><string-name><surname>Kurtzer</surname>, <given-names>G. M.</given-names></string-name>, <string-name><surname>Sochat</surname>, <given-names>V.</given-names></string-name> &#x0026; <string-name><surname>Bauer</surname>, <given-names>M. W.</given-names></string-name> <article-title>Singularity: Scientific containers for mobility of compute</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0177459</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0177459</pub-id>.</mixed-citation></ref>
<ref id="c48"><label>48</label><mixed-citation publication-type="journal"><string-name><surname>Schonberg</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> <article-title>Decreasing Ventromedial Prefrontal Cortex Activity During Sequential Risk-Taking: An fMRI Investigation of the Balloon Analog Risk Task</article-title>. <source>Frontiers in Neuroscience</source> <volume>6</volume> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.3389/fnins.2012.00080</pub-id>.</mixed-citation></ref>
<ref id="c49"><label>49</label><mixed-citation publication-type="journal"><string-name><surname>Aron</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Gluck</surname>, <given-names>M. A.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>Long-term test-retest reliability of functional MRI in a classification learning task</article-title>. <source>NeuroImage</source> <volume>29</volume>, <fpage>1000</fpage>&#x2013;<lpage>1006</lpage> (<year>2006</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.08.010</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>50</label><mixed-citation publication-type="journal"><string-name><surname>Xue</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>The Neural Substrates of Visual Perceptual Learning of Words: Implications for the Visual Word Form Area Hypothesis</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>19</volume>, <fpage>1643</fpage>&#x2013;<lpage>1655</lpage> (<year>2007</year>). doi:<pub-id pub-id-type="doi">10.1162/jocn.2007.19.10.1643</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>51</label><mixed-citation publication-type="journal"><string-name><surname>Tom</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>C. R.</given-names></string-name>, <string-name><surname>Trepel</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>The Neural Basis of Loss Aversion in Decision-Making Under Risk</article-title>. <source>Science</source> <volume>315</volume>,<fpage>515</fpage>&#x2013;<lpage>518</lpage> (<year>2007</year>). doi:<pub-id pub-id-type="doi">10.1126/science.1134239</pub-id>.</mixed-citation></ref>
<ref id="c52"><label>52</label><mixed-citation publication-type="journal"><string-name><surname>Xue</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Aron</surname>, <given-names>A. R.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>Common Neural Substrates for Inhibition of Spoken and Manual Responses</article-title>. <source>Cerebral Cortex</source> <volume>18</volume>, <fpage>1923</fpage>&#x2013;<lpage>1932</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1093/cercor/bhm220</pub-id>.</mixed-citation></ref>
<ref id="c53"><label>53</label><mixed-citation publication-type="journal"><string-name><surname>Aron</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>Triangulating a Cognitive Control Network Using Diffusion-Weighted Magnetic Resonance Imaging (MRI) and Functional MRI</article-title>. <source>Journal of Neuroscience</source> <volume>27</volume>, <fpage>3743</fpage>&#x2013;<lpage>3752</lpage> (<year>2007</year>). doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0519-07.2007</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>54</label><mixed-citation publication-type="journal"><string-name><surname>Foerde</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Knowlton</surname>, <given-names>B. J.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>Modulation of competing memory systems by distraction</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>103</volume>, <fpage>11778</fpage>&#x2013;<lpage>11783</lpage> (<year>2006</year>). doi:<pub-id pub-id-type="doi">10.1073/pnas.0602659103</pub-id>.</mixed-citation></ref>
<ref id="c55"><label>55</label><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <etal>et al.</etal> <article-title>A phenome-wide examination of neural and cognitive function</article-title>. <source>Scientific Data</source> <volume>3</volume>, <fpage>160110</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1038/sdata.2016.110</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>56</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Durnez</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <article-title>Preprocessed Consortium for Neuropsychiatric Phenomics dataset</article-title>. <source>F1000Research</source> <volume>6</volume>, <fpage>1262</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.12688/f1000research.11964.2</pub-id>.</mixed-citation></ref>
<ref id="c57"><label>57</label><mixed-citation publication-type="journal"><string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name> <etal>et al.</etal> <article-title>Functional System and Areal Organization of a Highly Sampled Individual Human Brain</article-title>. <source>Neuron</source> <volume>87</volume>, <fpage>657</fpage>&#x2013;<lpage>670</lpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.037</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>58</label><mixed-citation publication-type="book"><string-name><surname>Alvarez</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Jasdzewski</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <chapter-title>Building memories in two languages: an fMRI study of episodic encoding in bilinguals</chapter-title>. In <source>SfN Neuroscience</source> (<publisher-loc>Orlando, FL, US</publisher-loc>, <year>2002</year>). URL <ext-link ext-link-type="uri" xlink:href="http://www.sfn.org/annual-meeting/past-and-future-annual-meetings/abstract-archive/abstract-archive-detail">http://www.sfn.org/annual-meeting/past-and-future-annual-meetings/abstract-archive/abstract-archive-detail</ext-link>.</mixed-citation></ref>
<ref id="c59"><label>59</label><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> <etal>et al.</etal> <article-title>Interactive memory systems in the human brain</article-title>. <source>Nature</source> <volume>414</volume>, <fpage>546</fpage>&#x2013;<lpage>550</lpage> (<year>2001</year>). doi:<pub-id pub-id-type="doi">10.1038/35107080</pub-id>.</mixed-citation></ref>
<ref id="c60"><label>60</label><mixed-citation publication-type="journal"><string-name><surname>Kelly</surname>, <given-names>A. M. C.</given-names></string-name>, <string-name><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <string-name><surname>Biswal</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name> &#x0026; <string-name><surname>Milham</surname>, <given-names>M. P.</given-names></string-name> <article-title>Competition between functional brain networks mediates behavioral variability</article-title>. <source>NeuroImage</source> <volume>39</volume>, <fpage>527</fpage>&#x2013;<lpage>537</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.08.008</pub-id>.</mixed-citation></ref>
<ref id="c61"><label>61</label><mixed-citation publication-type="journal"><string-name><surname>Mennes</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Inter-individual differences in resting-state functional connectivity predict task-induced BOLD activity</article-title>. <source>NeuroImage</source> <volume>50</volume>, <fpage>1690</fpage>&#x2013;<lpage>1701</lpage> (<year>2010</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.002</pub-id>.</mixed-citation></ref>
<ref id="c62"><label>62</label><mixed-citation publication-type="journal"><string-name><surname>Mennes</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Linking inter-individual differences in neural activation and behavior to intrinsic brain dynamics</article-title>. <source>NeuroImage</source> <volume>54</volume>, <fpage>2950</fpage>&#x2013;<lpage>2959</lpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.10.046</pub-id>.</mixed-citation></ref>
<ref id="c63"><label>63</label><mixed-citation publication-type="journal"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name> <etal>et al.</etal> <article-title>Distributed and Overlapping Representations of Faces and Objects in Ventral Temporal Cortex</article-title>. <source>Science</source> <volume>293</volume>, <fpage>2425</fpage>&#x2013;<lpage>2430</lpage> (<year>2001</year>). doi:<pub-id pub-id-type="doi">10.1126/science.1063736</pub-id>.</mixed-citation></ref>
<ref id="c64"><label>64</label><mixed-citation publication-type="journal"><string-name><surname>Hanson</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Matsuka</surname>, <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name> <article-title>Combinatorial codes in ventral temporal lobe for object recognition: Haxby (2001) revisited: is there a face area?</article-title> <source>NeuroImage</source> <volume>23</volume>, <fpage>156</fpage>&#x2013;<lpage>166</lpage> (<year>2004</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.05.020</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>65</label><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Pattamadilok</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Knierim</surname>, <given-names>I.</given-names></string-name> &#x0026; <string-name><surname>Devlin</surname>, <given-names>J. T.</given-names></string-name> <article-title>Consistency and variability in functional localisers</article-title>. <source>NeuroImage</source> <volume>46</volume>, <fpage>1018</fpage>&#x2013;<lpage>1026</lpage> (<year>2009</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.014</pub-id>.</mixed-citation></ref>
<ref id="c66"><label>66</label><mixed-citation publication-type="journal"><string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Davidson</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Hughes</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Lindquist</surname>, <given-names>M. A.</given-names></string-name> &#x0026; <string-name><surname>Ochsner</surname>, <given-names>K. N.</given-names></string-name> <article-title>Prefrontal-Subcortical Pathways Mediating Successful Emotion Regulation</article-title>. <source>Neuron</source> <volume>59</volume>, <fpage>1037</fpage>&#x2013;<lpage>1050</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.006</pub-id>.</mixed-citation></ref>
<ref id="c67"><label>67</label><mixed-citation publication-type="journal"><string-name><surname>Moran</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Jolly</surname>, <given-names>E.</given-names></string-name> &#x0026; <string-name><surname>Mitchell</surname>, <given-names>J. P.</given-names></string-name> <article-title>Social-Cognitive Deficits in Normal Aging</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>, <fpage>5553</fpage>&#x2013;<lpage>5561</lpage> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5511-11.2012</pub-id>.</mixed-citation></ref>
<ref id="c68"><label>68</label><mixed-citation publication-type="journal"><string-name><surname>Uncapher</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Hutchinson</surname>, <given-names>J. B.</given-names></string-name> &#x0026; <string-name><surname>Wagner</surname>, <given-names>A. D.</given-names></string-name> <article-title>Dissociable Effects of Top-Down and Bottom-Up Attention during Episodic Encoding</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>, <fpage>12613</fpage>&#x2013;<lpage>12628</lpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0152-11.2011</pub-id>.</mixed-citation></ref>
<ref id="c69"><label>69</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal> <article-title>A test-retest fMRI dataset for motor, language and spatial attention functions</article-title>. <source>Giga-Science</source> <volume>2</volume>, <fpage>1</fpage>&#x2013;<lpage>4</lpage> (<year>2013</year>). doi:<pub-id pub-id-type="doi">10.1186/2047-217X-2-6</pub-id>.</mixed-citation></ref>
<ref id="c70"><label>70</label><mixed-citation publication-type="journal"><string-name><surname>Repovs</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name> <article-title>Working memory related brain network connectivity in individuals with schizophrenia and their siblings</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>6</volume> (<year>2012</year>). doi:<pub-id pub-id-type="doi">10.3389/fnhum.2012.00137</pub-id>.</mixed-citation></ref>
<ref id="c71"><label>71</label><mixed-citation publication-type="journal"><string-name><surname>Repovs</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Csernansky</surname>, <given-names>J. G.</given-names></string-name> &#x0026; <string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name> <article-title>Brain Network Connectivity in Individuals with Schizophrenia and Their Siblings</article-title>. <source>Biological Psychiatry</source> <volume>69</volume>, <fpage>967</fpage>&#x2013;<lpage>973</lpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.1016/j.biopsych.2010.11.009</pub-id>.</mixed-citation></ref>
<ref id="c72"><label>72</label><mixed-citation publication-type="journal"><string-name><surname>Walz</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Simultaneous EEG-fMRI Reveals Temporal Evolution of Coupling between Supramodal Cortical Attention Networks and the Brainstem</article-title>. <source>Journal of Neuroscience</source> <volume>33</volume>, <fpage>19212</fpage>&#x2013;<lpage>19222</lpage> (<year>2013</year>). doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2649-13.2013</pub-id>.</mixed-citation></ref>
<ref id="c73"><label>73</label><mixed-citation publication-type="journal"><string-name><surname>Walz</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Simultaneous EEG-fMRI reveals a temporal cascade of task-related and default-mode activations during a simple target detection task</article-title>. <source>NeuroImage</source> <volume>102</volume>, <fpage>229</fpage>&#x2013;<lpage>239</lpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.014</pub-id>.</mixed-citation></ref>
<ref id="c74"><label>74</label><mixed-citation publication-type="journal"><string-name><surname>Conroy</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Walz</surname>, <given-names>J. M.</given-names></string-name> &#x0026; <string-name><surname>Sajda</surname>, <given-names>P.</given-names></string-name> <article-title>Fast Bootstrapping and Permutation Testing for Assessing Reproducibility and Interpretability of Multivariate fMRI Decoding Models</article-title>. <source>PLOS ONE</source> <volume>8</volume>, <fpage>e79271</fpage> (<year>2013</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0079271</pub-id>.</mixed-citation></ref>
<ref id="c75"><label>75</label><mixed-citation publication-type="journal"><string-name><surname>Walz</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Prestimulus EEG alpha oscillations modulate task-related fMRI BOLD responses to auditory stimuli</article-title>. <source>NeuroImage</source> <volume>113</volume>, <fpage>153</fpage>&#x2013;<lpage>163</lpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.03.028</pub-id>.</mixed-citation></ref>
<ref id="c76"><label>76</label><mixed-citation publication-type="journal"><string-name><surname>Velanova</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Wheeler</surname>, <given-names>M. E.</given-names></string-name> &#x0026; <string-name><surname>Luna</surname>, <given-names>B.</given-names></string-name> <article-title>Maturational Changes in Anterior Cingulate and Frontoparietal Recruitment Support the Development of Error Processing and Inhibitory Control</article-title>. <source>Cerebral Cortex</source> <volume>18</volume>, <fpage>2505</fpage>&#x2013;<lpage>2522</lpage> (<year>2008</year>). doi:<pub-id pub-id-type="doi">10.1093/cercor/bhn012</pub-id>.</mixed-citation></ref>
<ref id="c77"><label>77</label><mixed-citation publication-type="journal"><string-name><surname>Padmanabhan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Geier</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Ordaz</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Teslovich</surname>, <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Luna</surname>, <given-names>B.</given-names></string-name> <article-title>Developmental changes in brain function underlying the influence of reward processing on inhibitory control</article-title>. <source>Developmental Cognitive Neuroscience</source> <volume>1</volume>, <fpage>517</fpage>&#x2013;<lpage>529</lpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.1016/j.dcn.2011.06.004</pub-id>.</mixed-citation></ref>
<ref id="c78"><label>78</label><mixed-citation publication-type="journal"><string-name><surname>Geier</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Terwilliger</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Teslovich</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Velanova</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Luna</surname>, <given-names>B.</given-names></string-name> <article-title>Immaturities in Reward Processing and Its Influence on Inhibitory Control in Adolescence</article-title>. <source>Cerebral Cortex</source> <volume>20</volume>, <fpage>1613</fpage>&#x2013;<lpage>1629</lpage> (<year>2010</year>). doi:<pub-id pub-id-type="doi">10.1093/cercor/bhp225</pub-id>.</mixed-citation></ref>
<ref id="c79"><label>79</label><mixed-citation publication-type="journal"><string-name><surname>Cera</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Tartaro</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Sensi</surname>, <given-names>S. L.</given-names></string-name> <article-title>Modafinil Alters Intrinsic Functional Connectivity of the Right Posterior Insula: A Pharmacological Resting State fMRI Study</article-title>. <source>PLOS ONE</source> <volume>9</volume>, <fpage>e107145</fpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0107145</pub-id>.</mixed-citation></ref>
<ref id="c80"><label>80</label><mixed-citation publication-type="journal"><string-name><surname>Woo</surname>, <given-names>C.-W.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Buhle</surname>, <given-names>J. T.</given-names></string-name> &#x0026; <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name> <article-title>Distinct Brain Systems Mediate the Effects of Nociceptive Input and Self-Regulation on Pain</article-title>. <source>PLOS Biology</source> <volume>13</volume>, <fpage>e1002036</fpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1002036</pub-id>.</mixed-citation></ref>
<ref id="c81"><label>81</label><mixed-citation publication-type="journal"><string-name><surname>Smeets</surname>, <given-names>P. A. M.</given-names></string-name>, <string-name><surname>Kroese</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Evers</surname>, <given-names>C</given-names></string-name>. &#x0026; <string-name><surname>de Ridder</surname>, <given-names>D. T. D.</given-names></string-name> <article-title>Allured or alarmed: Counteractive control responses to food temptations in the brain</article-title>. <source>Behavioural Brain Research</source> <volume>248</volume>, <fpage>41</fpage>&#x2013;<lpage>45</lpage> (<year>2013</year>). doi:<pub-id pub-id-type="doi">10.1016/j.bbr.2013.03.041</pub-id>.</mixed-citation></ref>
<ref id="c82"><label>82</label><mixed-citation publication-type="journal"><string-name><surname>Pernet</surname>, <given-names>C. R.</given-names></string-name> <etal>et al.</etal> <article-title>The human voice areas: Spatial organization and inter-individual variability in temporal and extra-temporal cortices</article-title>. <source>NeuroImage</source> <volume>119</volume>, <fpage>164</fpage>&#x2013;<lpage>174</lpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.050</pub-id>.</mixed-citation></ref>
<ref id="c83"><label>83</label><mixed-citation publication-type="journal"><string-name><surname>Verstynen</surname>, <given-names>T. D</given-names></string-name>. <article-title>The organization and dynamics of corticostriatal pathways link the medial orbitofrontal cortex to future behavioral responses</article-title>. <source>Journal of Neurophysiology</source> <volume>112</volume>, <fpage>2457</fpage>&#x2013;<lpage>2469</lpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1152/jn.00221.2014</pub-id>.</mixed-citation></ref>
<ref id="c84"><label>84</label><mixed-citation publication-type="journal"><string-name><surname>Bursley</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Nestor</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tarr</surname>, <given-names>M. J.</given-names></string-name> &#x0026; <string-name><surname>Creswell</surname>, <given-names>J. D.</given-names></string-name> <article-title>Awake, Offline Processing during Associative Learning</article-title>. <source>PLOS ONE</source> <volume>11</volume>, <fpage>e0127522</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0127522</pub-id>.</mixed-citation></ref>
<ref id="c85"><label>85</label><mixed-citation publication-type="journal"><string-name><surname>Ella</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>David</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Avi</surname>, <given-names>K.</given-names></string-name> <article-title>Learning from the other limb&#x2019;s experience: sharing the trained M1 representation of the motor sequence knowledge</article-title>. <source>The Journal of Physiology</source> <volume>594</volume>, <fpage>169</fpage>&#x2013;<lpage>188</lpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1113/JP270184</pub-id>.</mixed-citation></ref>
<ref id="c86"><label>86</label><mixed-citation publication-type="journal"><string-name><surname>Gabitov</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Manor</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Karni</surname>, <given-names>A.</given-names></string-name> <article-title>Patterns of Modulation in the Activity and Connectivity of Motor Cortex during the Repeated Generation of Movement Sequences</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>27</volume>, <fpage>736</fpage>&#x2013;<lpage>751</lpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00751</pub-id>.</mixed-citation></ref>
<ref id="c87"><label>87</label><mixed-citation publication-type="journal"><string-name><surname>Gabitov</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Manor</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Karni</surname>, <given-names>A.</given-names></string-name> <article-title>Done That: Short-term Repetition Related Modulations of Motor Cortex Activity as a Stable Signature for Overnight Motor Memory Consolidation</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>26</volume>, <fpage>2716</fpage>&#x2013;<lpage>2734</lpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00675</pub-id>.</mixed-citation></ref>
<ref id="c88"><label>88</label><mixed-citation publication-type="journal"><string-name><surname>Lepping</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Atchley</surname>, <given-names>R. A.</given-names></string-name> &#x0026; <string-name><surname>Savage</surname>, <given-names>C. R.</given-names></string-name> <article-title>Development of a validated emotionally provocative musical stimulus set for research</article-title>. <source>Psychology of Music</source> <volume>44</volume>, <fpage>1012</fpage>&#x2013;<lpage>1028</lpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1177/0305735615604509</pub-id>.</mixed-citation></ref>
<ref id="c89"><label>89</label><mixed-citation publication-type="journal"><string-name><surname>Park</surname>, <given-names>C.-A.</given-names></string-name> &#x0026; <string-name><surname>Kang</surname>, <given-names>C.-K.</given-names></string-name> <article-title>Sensing the effects of mouth breathing by using 3-tesla MRI</article-title>. <source>Journal of the Korean Physical Society</source> <volume>70</volume>, <fpage>1070</fpage>&#x2013;<lpage>1076</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.3938/jkps.70.1070</pub-id>.</mixed-citation></ref>
<ref id="c90"><label>90</label><mixed-citation publication-type="journal"><string-name><surname>Iannilli</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal> <article-title>Effects of Manganese Exposure on Olfactory Functions in Teenagers: A Pilot Study</article-title>. <source>PLOS ONE</source> <volume>11</volume>, <fpage>e0144783</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0144783</pub-id>.</mixed-citation></ref>
<ref id="c91"><label>91</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wedell</surname>, <given-names>D. H.</given-names></string-name> &#x0026; <string-name><surname>Shinkareva</surname>, <given-names>S. V.</given-names></string-name> <article-title>Identifying Core Affect in Individuals from fMRI Responses to Dynamic Naturalistic Audiovisual Stimuli</article-title>. <source>PLOS ONE</source> <volume>11</volume>, <fpage>e0161589</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0161589</pub-id>.</mixed-citation></ref>
<ref id="c92"><label>92</label><mixed-citation publication-type="journal"><string-name><surname>T&#x00E9;treault</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>Brain Connectivity Predicts Placebo Response across Chronic Pain Clinical Trials</article-title>. <source>PLOS Biology</source> <volume>14</volume>, <fpage>e1002570</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1002570</pub-id>.</mixed-citation></ref>
<ref id="c93"><label>93</label><mixed-citation publication-type="journal"><string-name><surname>Chakroff</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>When minds matter for moral judgment: intent information is neurally encoded for harmful but not impure acts</article-title>. <source>Social Cognitive andAffective Neuroscience</source> <volume>11</volume>, <fpage>476</fpage>&#x2013;<lpage>484</lpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1093/scan/nsv131</pub-id>.</mixed-citation></ref>
<ref id="c94"><label>94</label><mixed-citation publication-type="journal"><string-name><surname>Koster-Hale</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Dungan</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Young</surname>, <given-names>L. L.</given-names></string-name> <article-title>Decoding moral judgments from neural representations of intentions</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>110</volume>, <fpage>5648</fpage>&#x2013;<lpage>5653</lpage> (<year>2013</year>). doi:<pub-id pub-id-type="doi">10.1073/pnas.1207992110</pub-id>.</mixed-citation></ref>
<ref id="c95"><label>95</label><mixed-citation publication-type="journal"><string-name><surname>Gao</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal> <article-title>My Body Looks Like That Girls: Body Mass Index Modulates Brain Activity during Body Image Self-Reflection among Young Women</article-title>. <source>PLOS ONE</source> <volume>11</volume>, <fpage>e0164450</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0164450</pub-id>.</mixed-citation></ref>
<ref id="c96"><label>96</label><mixed-citation publication-type="journal"><string-name><surname>Romaniuk</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Pope</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nicol</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Steele</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Hall</surname>, <given-names>J.</given-names></string-name> <article-title>Neural correlates of fears of abandonment and rejection in borderline personality disorder</article-title>. <source>Wellcome Open Research</source> <volume>1</volume>, <fpage>33</fpage> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.12688/wellcomeopenres.10331.1</pub-id>.</mixed-citation></ref>
<ref id="c97"><label>97</label><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Nencka</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Lebel</surname>, <given-names>R. M.</given-names></string-name> &#x0026; <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name> <article-title>Multiband multi-echo imaging of simultaneous oxygenation and flow timeseries for resting state connectivity</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0169253</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0169253</pub-id>.</mixed-citation></ref>
<ref id="c98"><label>98</label><mixed-citation publication-type="journal"><string-name><surname>Dalenberg</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Weitkamp</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Renken</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Nanetti</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Horst</surname>, <given-names>G. J.</given-names></string-name> <article-title>t. Flavor pleasantness processing in the ventral emotion network</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0170310</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0170310</pub-id>.</mixed-citation></ref>
<ref id="c99"><label>99</label><mixed-citation publication-type="journal"><string-name><surname>Roy</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>The evolution of cost-efficiency in neural networks during recovery from traumatic brain injury</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0170541</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0170541</pub-id>.</mixed-citation></ref>
<ref id="c100"><label>100</label><mixed-citation publication-type="journal"><string-name><surname>Gordon</surname>, <given-names>E. M.</given-names></string-name> <etal>et al.</etal> <article-title>Precision Functional Mapping of Individual Human Brains</article-title>. <source>Neuron</source> <volume>95</volume>, <fpage>791</fpage>&#x2013;<lpage>807.e7</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.011</pub-id>.</mixed-citation></ref>
<ref id="c101"><label>101</label><mixed-citation publication-type="journal"><string-name><surname>Veldhuizen</surname>, <given-names>M. G.</given-names></string-name> <etal>et al.</etal> <article-title>Integration of Sweet Taste and Metabolism Determines Carbohydrate Reward</article-title>. <source>Current Biology</source> <volume>27</volume>, <fpage>2476</fpage>&#x2013;<lpage>2485</lpage>.e6 (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1016/j.cub.2017.07.018</pub-id>.</mixed-citation></ref>
<ref id="c102"><label>102</label><mixed-citation publication-type="journal"><string-name><surname>Greene</surname>, <given-names>D. J.</given-names></string-name> <etal>et al.</etal> <article-title>Behavioral interventions for reducing head motion during MRI scans in children</article-title>. <source>NeuroImage</source> <volume>171</volume>, <fpage>234</fpage>&#x2013;<lpage>245</lpage> (<year>2018</year>). doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.023</pub-id>.</mixed-citation></ref>
<ref id="c103"><label>103</label><mixed-citation publication-type="journal"><string-name><surname>Nastase</surname>, <given-names>S. A.</given-names></string-name> <etal>et al.</etal> <article-title>Attention Selectively Reshapes the Geometry of Distributed Semantic Representation</article-title>. <source>Cerebral Cortex</source> <volume>27</volume>, <fpage>4277</fpage>&#x2013;<lpage>4291</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1093/cercor/bhx138</pub-id>.</mixed-citation></ref>
<ref id="c104"><label>104</label><mixed-citation publication-type="journal"><string-name><surname>Kanazawa</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title>Phonological memory in sign language relies on the visuomotor neural system outside the left hemisphere language network</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0177599</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0177599</pub-id>.</mixed-citation></ref>
<ref id="c105"><label>105</label><mixed-citation publication-type="journal"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal> <article-title>MRIQC: Advancing the automatic prediction of image quality in MRI from unseen sites</article-title>. <source>PLOS ONE</source> <volume>12</volume>, <fpage>e0184661</fpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0184661</pub-id>.</mixed-citation></ref>
<ref id="c106"><label>106</label><mixed-citation publication-type="journal"><string-name><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name> <etal>et al.</etal> <article-title>The impact of T1 versus EPI spatial normalization templates for fMRI data analyses</article-title>. <source>Human BrainMapping</source> <volume>38</volume>, <fpage>5331</fpage>&#x2013;<lpage>5342</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1002/hbm.23737</pub-id>.</mixed-citation></ref>
<ref id="c107"><label>107</label><mixed-citation publication-type="journal"><string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name> <article-title>General multilevel linear modeling for group analysis in FMRI</article-title>. <source>NeuroImage</source> <volume>20</volume>, <fpage>1052</fpage>&#x2013;<lpage>1063</lpage> (<year>2003</year>). doi:<pub-id pub-id-type="doi">10.1016/S1053-8119(03)00435-X</pub-id>.</mixed-citation></ref>
<ref id="c108"><label>108</label><mixed-citation publication-type="journal"><string-name><surname>Strother</surname>, <given-names>S. C.</given-names></string-name> <etal>et al.</etal> <article-title>The Quantitative Evaluation of Functional Neuroimaging Experiments: The NPAIRS Data Analysis Framework</article-title>. <source>NeuroImage</source> <volume>15</volume>, <fpage>747</fpage>&#x2013;<lpage>771</lpage> (<year>2002</year>). doi:<pub-id pub-id-type="doi">10.1006/nimg.2001.1034</pub-id>.</mixed-citation></ref>
<ref id="c109"><label>109</label><mixed-citation publication-type="journal"><string-name><surname>Karaman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nencka</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Bruce</surname>, <given-names>I. P.</given-names></string-name> &#x0026; <string-name><surname>Rowe</surname>, <given-names>D. B.</given-names></string-name> <article-title>Quantification of the Statistical Effects of Spatiotemporal Processing of Nontask fMRI Data</article-title>. <source>Brain Connectivity</source> <volume>4</volume>, <fpage>649</fpage>&#x2013;<lpage>661</lpage> (<year>2014</year>). doi:<pub-id pub-id-type="doi">10.1089/brain.2014.0278</pub-id>.</mixed-citation></ref>
<ref id="c110"><label>110</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal> <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python</article-title>. <source>Frontiers in Neuroinformatics</source> <volume>5</volume>, <fpage>13</fpage> (<year>2011</year>). doi:<pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id>.</mixed-citation></ref>
<ref id="c111"><label>111</label><mixed-citation publication-type="journal"><string-name><surname>Marder</surname>, <given-names>E</given-names></string-name>. <article-title>Understanding Brains: Details, Intuition, and Big Data</article-title>. <source>PLOS Biology</source> <volume>13</volume>, <fpage>e1002147</fpage> (<year>2015</year>). doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1002147</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
</article>