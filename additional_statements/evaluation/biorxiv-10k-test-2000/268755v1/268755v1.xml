<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/268755</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Reproducible big data science: A case study in continuous FAIRness</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2130-2887</contrib-id>
<name>
<surname>Madduri</surname>
<given-names>Ravi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chard</surname>
<given-names>Kyle</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>D&#x2019;Arcy</surname>
<given-names>Mike</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jung</surname>
<given-names>Segun C.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rodriguez</surname>
<given-names>Alexis</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sulakhe</surname>
<given-names>Dinanath</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Deutsch</surname>
<given-names>Eric W.</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Funk</surname>
<given-names>Cory</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Heavner</surname>
<given-names>Ben</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Richards</surname>
<given-names>Matthew</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shannon</surname>
<given-names>Paul</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dinov</surname>
<given-names>Ivo</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Glusman</surname>
<given-names>Gustavo</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Price</surname>
<given-names>Nathan</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Van Horn</surname>
<given-names>John D.</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kesselman</surname>
<given-names>Carl</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Toga</surname>
<given-names>Arthur W.</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2129-5269</contrib-id>
<name>
<surname>Foster</surname>
<given-names>Ian</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a8">8</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Globus, University of Chicago, Chicago</institution>, Illinois, <country>United States of America</country></aff>
<aff id="a2"><label>2</label><institution>Data Science and Learning Division, Argonne National Laboratory</institution>, Lemont, Illinois, <country>United States of America</country></aff>
<aff id="a3"><label>3</label><institution>Information Sciences Institute, University of Southern California, Los Angeles</institution>, California, <country>United States of America</country></aff>
<aff id="a4"><label>4</label><institution>Institute for Systems Biology, Seattle</institution>, Washington, <country>United States of America</country></aff>
<aff id="a5"><label>5</label><institution>Department of Biostatistics, School of Public Health, University of Washington</institution>, Seattle, Washington, <country>United States of America</country></aff>
<aff id="a6"><label>6</label><institution>Statistics Online Computational Resource, School of Nursing, University of Michigan</institution>, Ann Arbor, Michigan, <country>United States of America</country></aff>
<aff id="a7"><label>7</label><institution>Neuroimaging and Informatics Institute, Keck School of Medicine, University of Southern California</institution>, Los Angeles, California, <country>United States of America</country></aff>
<aff id="a8"><label>8</label><institution>Department of Computer Science, University of Chicago</institution>, Chicago, Illinois, <country>United States of America</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>&#x002A;</label><p><email>foster@uchicago.edu</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>268755</elocation-id>
<history>
<date date-type="received">
<day>27</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>27</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>27</day>
<month>2</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="268755.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Big biomedical data create exciting opportunities for discovery, but make it difficult to capture analyses and outputs in forms that are findable, accessible, interoperable, and reusable (FAIR). In response, we describe tools that make it easy to capture, and assign identifiers to, data and code throughout the data lifecycle. We illustrate the use of these tools via a case study involving a multi-step analysis that creates an atlas of putative transcription factor binding sites from terabytes of ENCODE DNase I hypersensitive sites sequencing data. We show how the tools automate routine but complex tasks, capture analysis algorithms in understandable and reusable forms, and harness fast networks and powerful cloud computers to process data rapidly, all without sacrificing usability or reproducibility&#x2014;thus ensuring that big data are not hard-to-(re)use data. We compare and contrast our approach with other approaches to big data analysis and reproducibility.</p>
</abstract>
<counts>
<page-count count="20"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Rapidly growing data collections create exciting opportunities for a new mode of scientific discovery in which alternative hypotheses are developed and tested against existing data, rather than by generating new data to validate a predetermined hypothesis [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>]. A key enabler of these data-driven discovery methods is the ability to easily access and analyze data of unprecedented size, complexity, and generation rate (i.e., volume, variety, and velocity)&#x2014;so called big data. Equally important to the scientific method is that results be easily consumed by other scientists [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>]: that is that results be findable, accessible, interoperable, and re-usable (FAIR) [<xref ref-type="bibr" rid="c5">5</xref>].</p>
<p>Yet there is currently a considerable gap between the scientific potential and practical realization of data-driven approaches in biomedical discovery [<xref ref-type="bibr" rid="c6">6</xref>]. This unfortunate situation results, in part at least, from inadequacies in the computational and data management approaches available to biomedical researchers. In particular, tools rarely scale to big data. For example, while a desktop tool may allow an analysis method to be readily applied to a small dataset (e.g., a single genome), applying the same method to a large dataset (e.g., 1,000 genomes) requires specialized infrastructure and expertise. The complexity of the associated data and computation management tasks frequently becomes a gating factor to progress. These difficulties are magnified by the disjointed nature of the biomedical data landscape, which often lacks common interfaces for data discovery and data access, conventions for bundling and transporting datasets, and methods for referencing data produced in different locations,. and features non-portable and idiosyncratic analysis suites.</p>
<p>We show here that these difficulties can be overcome via the use of relatively simple tools that either entirely automate or significantly streamline the many, often mundane, tasks that consume biomedical researcher time. These tools include Big Data Bags (BDBags) for data exchange and minimal identifiers (Minids) as persistent identifiers for intermediate data products [<xref ref-type="bibr" rid="c7">7</xref>]; Globus cloud services for authentication and data transfer [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>]; and the Galaxy-based Globus Genomics [<xref ref-type="bibr" rid="c10">10</xref>] and Docker containers [<xref ref-type="bibr" rid="c11">11</xref>] for reproducible cloud-based computations. Simple application programming interface (API)-level integration means that, for example, whenever a new BDBag is created to bundle outputs from a computation, a Minid can easily be created that can then be consumed by a subsequent computational step.</p>
<p>To demonstrate what can be achieved in this space, we present here a case study of big data analysis, a transcription factor binding site (TFBS) analysis that creates an atlas of putative transcription factor binding sites from ENCODE DNase I hypersensitive sites sequencing (DNase-seq) data, across 27 tissue types. This application involves the retrieval and analysis of multiple terabytes of publicly available DNase-seq data with an aggregated set of position weight matrices representing transcription factor binding sites; a range of open source analysis programs, Galaxy workflows, and customized R scripts; high-speed networks for data exchange; and tens of thousands of core-hours of computation on workstations and public clouds. We introduce the analysis method, review the tools used in its implementation, and present the implementation itself, showing how the tools enable the principled capture of a complex computational workflow in a reusable form. In particular, we show how all resources used in this work, and the end-to-end process itself, are captured in reusable forms that are accessible via persistent identifiers.</p>
<p>The remainder of this paper is as follows. In &#x00A7;2, we introduce the TFBS atlas application and in &#x00A7;3 the tools that we use to create a FAIR implementation. We describe the implementation in &#x00A7;4 and &#x00A7;5, discuss implications of this work and its relationship to other approaches in &#x00A7;6, and conclude in &#x00A7;7.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>An atlas of transcription factor binding sites</title>
<p>Large quantities of DNase I hypersensitive sites sequencing (DNase-seq) data are now available, for example from the Encyclopedia of DNA Elements (ENCODE) [<xref ref-type="bibr" rid="c12">12</xref>]. Funk et al. [<xref ref-type="bibr" rid="c13">13</xref>] show how such data can be used to construct genome-wide maps of candidate transcription factor binding sites (TFBSs) via the large-scale application of footprinting methods. As outlined in <xref rid="fig1" ref-type="fig">Fig 1,</xref> their method comprises five main steps, which are labeled in the figure and referenced throughout this paper as &#x2460;..&#x2464;:
<list list-type="simple">
<list-item><p>&#x2460; Retrieve tissue-specific DNase-seq data from ENCODE, for hundreds of biosample replicates and 27 tissue types.</p></list-item>
<list-item><p>&#x2461;Combine the DNase-seq replicates data for each aligned replicate in each tissue and merge the results. Alignments are computed for two seed sizes, yielding double the number of output files.</p></list-item>
<list-item><p>&#x2462;Apply two footprinting methods&#x2014;Wellington [<xref ref-type="bibr" rid="c14">14</xref>] and HMM-based identification of TF footprints (HINT) [<xref ref-type="bibr" rid="c15">15</xref>], each of which has distinct strengths and limitations [<xref ref-type="bibr" rid="c16">16</xref>]&#x2014;to each DNase-seq from &#x2461; to infer footprints. (On average, this process identifies a few million footprints for each tissue type, of which many but certainly not all are found by both approaches.)</p></list-item>
<list-item><p>&#x2463;Starting with a supplied set of non-redundant position weight matrices (PWMs) representing transcription-factor-DNA interactions, create a catalog of &#x201C;hits&#x201D; within the human genome, i.e., the genomic coordinates of occurrences of the supplied PWMs.</p></list-item>
<list-item><p>&#x2464;Intersect the footprints from &#x2462; and the hits from &#x2463; to identify candidate TFBSs in the DNase-seq data.</p></list-item>
</list>
</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1.</label>
<caption><p>A high-level view of the TFBS identification workflow, showing the six principal datasets, labeled D1&#x2013;D6, and the five computational phases, labeled &#x2460;&#x2013; &#x2464;.</p></caption>
<graphic xlink:href="268755_fig1.tif"/>
</fig>
<p>We provide more details on each step in subsequent sections, where we also discuss the specifics of the data that are passed between steps and preserved for subsequent access. Here we note some characteristics of the overall workflow that are important from a reproducibility perspective. The workflow involves many steps and files, making it important that the provenance of final results be captured automatically rather than manually. It involves considerable data (terabytes: TBs) and computation (hundreds of node-hours on 32-core nodes) and thus requires parallel computing (e.g., on a cloud) in order to complete in a timely manner. Finally, it makes use of multiple types of computation: an online service (encode2bag), big data Galaxy pipelines running in parallel on the cloud, and R code running on a workstation or laptop. These diverse characteristics are typical of many modern bioinformatics applications.</p>
</sec>
<sec id="s3">
<label>3</label>
<title>Tools used in TFBS atlas implementation</title>
<p>Before describing our implementation of the TFBS workflow, we introduce tools that we leverage in its development. These tools, developed or enhanced within the NIH-funded Big Data for Discovery Science center (BDDS) [<xref ref-type="bibr" rid="c17">17</xref>], simplify the development of scalable and reusable software by providing robust solutions to a range of big data problems, from data exchange to scalable analysis.</p>
<sec id="s3a">
<label>3.1.</label>
<title>BDBags, Research Objects, and Minids for data exchange</title>
<p>Reproducible big data science requires mechanisms for describing, referring to, and exchanging large and complex datasets that may comprise many directories and files (elements). Key requirements here are [<xref ref-type="bibr" rid="c7">7</xref>] enumeration: explicit enumeration of a dataset&#x2019;s elements, so that subsequent additions or deletions can be detected; fixity: enable verification of dataset contents, so that data consumers can detect errors in data transmission or modifications to data elements; description: provide interoperable methods for tracking the attributes (metadata) and origins (provenance) of dataset contents; distribution: allow a dataset to contain elements from more than one location; and identification: provide a reliable and concise way of referring to datasets for purposes of collaboration, publication, and citation.</p>
<p>We leverage three technologies to meet these requirements. We use the BDBag to define a dataset and its contents by enumerating its elements, regardless of their location (enumeration, fixity, and distribution); the Research Object (RO) [<xref ref-type="bibr" rid="c18">18</xref>] to characterize a dataset and its contents with arbitrary levels of detail, regardless of their location (description); and the Minid to uniquely identify a dataset and, if desired, its constituent elements, regardless of their location (identify, fixity). Importantly, these mechanisms can all be used without deploying complex software on researcher computers.</p>
<p>The <bold>Big Data Bag</bold> (BDBag) exchange format and associated tools [<xref ref-type="bibr" rid="c7">7</xref>] provide a robust mechanism for exchanging large and complex data collections. The BDBag exchange format extends the BagIT specification [<xref ref-type="bibr" rid="c19">19</xref>] to provide a self-describing format for representing large data. To give a flavor of the BDBag specification, we show an example in <xref rid="fig2" ref-type="fig">Fig 2</xref>. The dataset contents are the directories and files contained within the data directory. The other elements provide checksum and metadata information required to verify and interpret the data. Importantly, a BDBag can encode references to remotely accessible data, with the information required to retrieve those data provided in the fetch.txt file as a (URL, LENGTH, FILENAME) triple. This mechanisms supports the exchange of large datasets without copying large amounts of data (a &#x201C;holey&#x201D; BDBag that contains only references, not data, may be just a few hundreds of bytes in size); it also allows the definition of data collections that specific individuals may not have immediate permission to access, as when access to data elements is restricted by data use agreements. Given a BDBag, BDBag tools can be used to materialize those data in a standard way, capture metadata, and verify contents based on checksums of individual data and metadata items.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2.</label>
<caption><p>An example BDBag, with contents in the data folder, description in the metadata folder, and other elements providing data required to fetch remote elements (<monospace>fetch.txt</monospace>) and validate its components.</p></caption>
<graphic xlink:href="268755_fig2.tif"/>
</fig>
<p>The BDBag specification adopts the <bold>Research Object</bold> (RO) framework to associate attribution and provenance information, and structured and unstructured annotations describing individual resources, with the data contained in a BDBag. A BDBag&#x2019;s metadata directory contains annotations and the RO manifest.json in JSON-LD format [<xref ref-type="bibr" rid="c20">20</xref>]: see <xref rid="fig2" ref-type="fig">Fig 2</xref>.</p>
<p>Reproducible science requires mechanisms for robustly naming datasets, so that researchers can uniquely reference and locate data, and share and exchange names (rather than an entire dataset) while being able to ensure that a dataset&#x2019;s contents are unchanged. We use the minimal viable identifier (<bold>Minid</bold>) for this purpose. As the name suggests, Minids are lightweight identifiers that can be easily created, resolved, and used. Minids are built upon Archival Resource Keys (ARKs) and take the form <monospace>ark:/57799/[suffix]</monospace>, where the shoulder (57799) is used for all Minids, and the suffix is a unique sequence of characters. Minids can be resolved to a landing page using an independent resolution service such as name-to-thing: for example, visiting the URL <ext-link ext-link-type="uri" xlink:href="https://n2t.net/ark:/57799/b9j01d">https://n2t.net/ark:/57799/b9j01d</ext-link> redirects the browser to the landing page for the object with the Minid <monospace>ark:/57799/b9j01d</monospace>, as shown in <xref rid="fig3" ref-type="fig">Fig 3</xref>. In addition, <bold>minid</bold> is registered as a prefix at <ext-link ext-link-type="uri" xlink:href="http://identifiers.org">identifiers.org</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://n2t.net">n2t.net</ext-link> so that a more compact URI form [<xref ref-type="bibr" rid="c21">21</xref>] (e.g., <ext-link ext-link-type="uri" xlink:href="https://n2t.net/minid:b9j01d">https://n2t.net/minid:b9j01d</ext-link>) can be used to reference data.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig 3.</label>
<caption><p>A Minid landing page for a BDBag generated by the <monospace>encode2bag</monospace> tool, showing the associated metadata, including locations (in this case, just one).</p></caption>
<graphic xlink:href="268755_fig3.tif"/>
</fig>
<p>A landing page is intended to be always available, even if the data are not. It presents the complete metadata record for the Minid and links to one or more locations where the referenced data can be obtained. Allowing more than one data location enables data replication. For example, a Minid may reference one copy of a dataset in the source repository, additional copies in different vendor cloud object stores, and yet another copy on a local file system. Because the Minid includes a checksum of the content, we can ensure that whatever copy is used, it contains the correct and intended content. It is up to the consumer of the Minid to determine which copy of the data is &#x201C;best&#x201D; for their purpose, and the responsibility of the Minid creator to interact with the landing page service to register new copies. The GET methods for the landing page support HTTP content negotiation; results may be returned in human-readable (HTML) or machine-readable (JSON) form.</p>
<p>While Minids and BDBags can be used independently, they can be used together to powerful effect. As we illustrate in later sections, we can create a Minid for a BDBag, allowing us to uniquely identify the BDBag instance and providing a repeatable method for referring to the BDBag. A Minid can be used as the URL for a remote file reference within a BDBag&#x2019;s <monospace>fetch.txt</monospace> file, in place of a direct URL to a file storage location.</p>
<p>The BDBag tooling knows how to resolve such a Minid reference through the landing page to a copy of the BDBag data for materialization into the complete data set. We leverage both of these combinations of Minids and bags in the TFBS workflows.</p>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Globus data management services</title>
<p>The often distributed nature and large size of biomedical data complicates data management tasks&#x2014;such as, in our case study, moving ENCODE data to cloud computers for analysis, and providing persistent access to analysis results. We use two capabilities provided by Globus [<xref ref-type="bibr" rid="c9">9</xref>] to overcome these difficulties.</p>
<p>First, we use Globus identity management, authentication, and authorization capabilities to enable researchers to authenticate with their institutional credentials and then access different data sources and data services without requiring further authentication.</p>
<p>Second, we use the Globus file-based data management services to enable efficient, reliable, and secure remote data access, secure and reliable file transfer, and controlled sharing. With more than 10,000 storage systems accessible via the Globus Connect interface, and support for data access from many different file systems and object stores, Globus translates the often baffling and heterogeneous world of distributed storage into a uniform, easily navigable data space.</p>
<p>A third capability that we expect to leverage in future work is Globus data publication [<xref ref-type="bibr" rid="c22">22</xref>] to support large-scale data publication. This service provides workflows for making data immutable, associating descriptive metadata, and assigning persistent identifiers such as digital object identifiers (DOIs) [<xref ref-type="bibr" rid="c23">23</xref>].</p>
</sec>
<sec id="s3c">
<label>3.3</label>
<title>Globus Genomics for parallel cloud-based computation</title>
<p>Small data analyses can be implemented effectively via R or Python scripts, that can be executed on a workstation or a cloud-hosted virtual machine and then shared as documents or via notebook environments such as Jupyter [<xref ref-type="bibr" rid="c24">24</xref>]. Big data analyses can be more challenging to implement and share, due to the need to orchestrate the execution of multiple application programs on many processors in order to process large quantities of data in a timely manner, whether for quality control [<xref ref-type="bibr" rid="c25">25</xref>], computation of derived quantities, or other purposes.</p>
<p>We use Globus Genomics [<xref ref-type="bibr" rid="c10">10</xref>] to orchestrate multi-application analysis on multi-processor cloud computing platforms. Globus Genomics builds on the Galaxy workflow environment [<xref ref-type="bibr" rid="c26">26</xref>], widely used in bioinformatics to support the graphical specification of multi-step computational analyses. Globus Genomics extends Galaxy&#x2019;s capabilities with support for Globus data access, parallel execution on cloud platforms, dispatch of applications within Docker containers, input of BDBags referenced via Minids, and other features useful for big data applications.</p>
<p>Other workflow systems with capabilities similar to those of the Galaxy system include the Python-based Toil [<xref ref-type="bibr" rid="c27">27</xref>], the Pipeline environment [<xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>], and the Common Workflow Language (CWL) [<xref ref-type="bibr" rid="c30">30</xref>]. The approach described here could be easily adopted to use different workflow languages and systems.</p>
</sec>
<sec id="s3d">
<label>3.4</label>
<title>Containers for capturing software used in computations</title>
<p>A final challenge in reproducible science is recording the software used to perform a computation. Source code allows a reader to examine application logic [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>], but may not run on a new platform. Container technologies such as Docker [<xref ref-type="bibr" rid="c11">11</xref>] and</p>
<p>Singularity [<xref ref-type="bibr" rid="c33">33</xref>] can be used to capture a complete software stack in a form that can be executed on many platforms. We use Docker here to package the various applications used in the footprinting workflow. A benefit of this technology is that a container image can be described (and built) with a simple text script that describes the base operating system and the components to be loaded: in the case of Docker, a <italic>Dockerfile</italic>. Thus it is straightforward to version, share, and reproducibly rebuild a container [<xref ref-type="bibr" rid="c34">34</xref>].</p>
</sec>
</sec>
<sec id="s3e">
<label>4</label>
<title>A scalable, reproducible TFBS workflow</title>
<p>Having described the major technologies on which we build, we now describe the end-to-end workflow of <xref rid="fig1" ref-type="fig">Fig 1</xref>. We cover each of &#x2460; &#x2013; &#x2464; in turn. <xref rid="tbl1" ref-type="table">Table 1</xref> summarizes the biosamples, data, and computations involved in the workflow.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Details of the per-tissue computations performed in the ensemble footprinting phase. Data sizes are in GB. Times are in hours on a 32-core AWS node; they sum to 2,149.1 node hours or 68,771 core hours. DNase: DNase Hypersensitivity (DNase-seq) data from ENCODE. Align: Aligned sequence data. Foot: Footprint data and footprint inference computation. Numbers may not sum perfectly due to rounding.</p></caption>
<graphic xlink:href="268755_tbl1.tif"/>
</table-wrap>
<sec id="s3f">
<label>4.1</label>
<title>Obtaining input data: encode2bag</title>
<p>The TFBS algorithm operates on DNase Hypersensitivity (DHS) data in the form of DNase-seq data obtained by querying the ENCODE database for DNase-seq data for each of 27 tissue types. These queries, when performed by Funk et al. [<xref ref-type="bibr" rid="c13">13</xref>], yielded a total of 1,591 FASTQ files corresponding to 1,355 replicates from 193 biosamples. (Each tissue-specific biosample may have multiple replicates: for example, the tissue type <italic>adrenal gland</italic> has eight replicates from three biosamples. Also, some replicates are broken into more than one FASTQ files.) Note that an identical query performed against ENCODE at a different time may yield different results, as new data are added or removed and quality control procedures evolve. Thus, it is important to record the results of these queries at the time they were executed, in a reproducible form.</p>
<p>ENCODE provides a web portal that a researcher can use to query the ENCODE database, using menus to specify parameters such as assay, biosample, and genomic annotations. The result is a set of data URLs, which must be downloaded individually and unfortunately do not come with associated metadata or context. Researchers often resort to building shell scripts to download and store the raw datasets. These manual data retrieval and management steps can be error-prone, time consuming, and difficult to reproduce. Researchers must manually save queries to record data provenance, and the only way to validate that downloaded files have not been corrupted is to download them again.</p>
<p>To simplify this process, we used BDBag, Minid, and Globus tools to create a lightweight command line utility and web service, <monospace>encode2bag</monospace>, shown as <bold>&#x2460;</bold> in <xref rid="fig1" ref-type="fig">Fig 1</xref>. A researcher can use either the web interface or the command line interface to either enter an ENCODE query or upload an ENCODE metadata file describing a collection of datasets. They can then access the corresponding data, <italic>plus associated metadata and checksums</italic>, as a BDBag. <xref rid="fig4" ref-type="fig">Fig 4</xref> shows an illustrative example in which the web interface is used to request data from urinary bladder DNase-seq experiments.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig 4.</label>
<caption><p>The encode2bag portal. The user has entered an ENCODE query for urinary bladder DNase-seq data and clicked &#x201C;Create BDBag.&#x201D; The portal generates a Minid for the BDBag and a Globus link for reliable, high-speed access.</p></caption>
<graphic xlink:href="268755_fig4.tif"/>
</fig>
<p>Selecting the &#x201C;Create BDBag&#x201D; button triggers the creation of a &#x007E;100 kilobyte BDBag that encapsulates references to the files in question, metadata associated with those files, the query used to identify the data, and the checksums required to validate the files and metadata. The BDBag is stored in AWS Simple Storage Service (S3) cloud storage from where it can be accessed for purposes of sharing, reproducibility, or validation. Because this BDBag contains references to data, rather the data themselves, it captures the entire response to the query in a small (hundreds of kilobytes) form that can be easily downloaded, moved, and shared. When needed, all, or a subset of, the files named within the BDBag&#x2019;s fetch.txt file can be downloaded (using BDBag tools), while ensuring that their contents match those of the original query.</p>
<p>To further streamline access to query results, <monospace>encode2bag</monospace> assigns a Minid for each BDBag that it creates, so as to provide for unambiguous naming and identification of research data products that are used for data provenance. In the example in <xref rid="fig4" ref-type="fig">Fig 4</xref> the Minid is <monospace>ark:/57799/b9j01d</monospace>; as discussed earlier, resolving this identifier leads to a landing page similar to that shown in <xref rid="fig3" ref-type="fig">Fig 3,</xref> which in turn contains a reference to the BDBag. The Minid can be passed between services as a concise reference to the BDBag.</p>
<p>The Funk et al. [<xref ref-type="bibr" rid="c13">13</xref>] workflow uses <monospace>encode2bag</monospace> to create BDBags for each of the 27 tissue types in ENCODE, each with its own Minid. For example, the DNase-seq data associated with adrenal tissue is at <monospace>ark:/57799/b9w37t</monospace>. These 27 BDBags contain references to a total of 2.4 TB of ENCODE data; references that can be followed at any time to access the associated data. It is these BDBags that are the input to the next step of the TFBS workflow, &#x2461;.</p>
<p>The fact that &#x2460; produces one BDBag per tissue type, each with a Minid, allows each tissue type to be processed independently in subsequent steps, providing considerable opportunities for acceleration via parallel processing. When publishing data for use by others, on the other hand, it would be cumbersome to have to share 27 separate Minids. Thus, as described in later sections, we also create for each such collection of BDBags a &#x201C;bag of bags,&#x201D; a BDBag that contains references to a set of other BDBags. This pervasive use of Minids and BDBags greatly simplifies the implementation and documentation of the TFBS workflow.</p>
</sec>
<sec id="s3g">
<label>4.2.</label>
<title>Aligning DNase-seq sample data</title>
<p>Now that &#x2460; has prepared the input data, &#x2461; prepares those data for the footprinting computation. For each of the 27 tissue types, the input to this phase comprises DNase-seq replicates for one or more biosamples (typically multiple replicates for each biosample), organized as a BDBag. The analysis first fetches the sequence data and, for each biosample, uses the SNAP sequence aligner to align the associated replicates. The resulting replicate alignments are merged and sorted to yield a single binary alignment data (BAM) file per biosample. The BAM files for all biosamples for each tissue type are combined into a BDBag.</p>
<p>As the ENCODE data consist primarily of short sequence reads, Funk et al. [<xref ref-type="bibr" rid="c13">13</xref>] ran the sequence alignment process twice, with seed lengths of 16 and 20, respectively. &#x2460; thus produces two BDBags per tissue type, for a total of 54. (The two sets of outputs allow &#x2464; to compare the merits of the two seed lengths for identifying footprints.)</p>
<p>While the computations involved in &#x2461; are relatively simple, the size of the datasets being manipulated and the cost of the computations make it important to execute subcomputations in parallel whenever possible. Each tissue and seed can be processed independently, as can the alignments of the replicates for each biosample, the merge and sort for each biosample, and (in &#x2462;) the footprint generation by HINT and Wellington. We use Globus Genomics to manage the resulting parallel computations in a way that both enables cloud-based parallel execution and reproducibility.</p>
<p><xref rid="fig5" ref-type="fig">Fig 5</xref> shows the Galaxy workflow that implements &#x2461; and &#x2462;. In this figure, each smaller box represents a separate application, with a name (the shaded header), one or more inputs (below the header and above the line), and one or more outputs (below the line). Each link connects an output from one application to the input of another.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig 5.</label>
<caption><title>Our DNase-seq ensemble footprinting workflow, used to implement &#x2461; and &#x2462; of <xref rid="fig1" ref-type="fig">Fig 1</xref>. The master workflow A takes a BDBag from bottom, using subworkflows B and C to implement &#x2461; as input. It executes from top to and then subworkflow D to implement &#x2462;. It produces as output BDBags containing aligned DNase-seq data and footprints, with the latter serving as input to &#x2464;.</title></caption>
<graphic xlink:href="268755_fig5.tif"/>
</fig>
<p><xref rid="fig5" ref-type="fig">Fig 5</xref> comprises four distinct workflows. The (A) master workflow, on the left, is run once for each tissue type, with each run taking a BDBag from &#x2460; as input and producing multiple BDBags as output. This workflow runs seven different applications in sequence, from top to bottom. Two of these applications, the boxes labeled &#x201C;Batch Submit&#x201D; (color-coded in red and green) themselves invoke substantial subworkflows. The two subworkflows leverage Globus Genomics features to launch multiple processes in parallel on the Amazon cloud, for (B) replicate alignment and (D) biosample footprint generation, respectively.</p>
<p>We mention a few additional features of the workflow. The first application in the master workflow, &#x201C;Get BDBag from Minid,&#x201D; dereferences a supplied Minid to retrieve the contents of the BDBag that it identifies. Thus the workflow can operate on any DNase-seq dataset contained in a BDBag and referenced by a Minid, including but not restricted to those produced by the <monospace>encode2bag</monospace> service.</p>
<p>This third application in the master workflow, &#x201C;SNAP Workflow Batch,&#x201D; invokes a subworkflow that comprises five applications (see <xref rid="fig5" ref-type="fig">Fig 5B</xref>). This subworkflow resolves the BDBag to identify the number of biosamples and replicates for an input tissue. Its second step manages a second subworkflow, <xref rid="fig5" ref-type="fig">Fig 5C,</xref> to execute the SNAP alignment algorithm for the input replicates of a biosample, All replicate alignments are executed in parallel and monitored for completeness. Once all replicate BAM files of a biosample are generated, the workflow merges and sorts them to produce a single BAM file for the biosample.</p>
</sec>
<sec id="s3h">
<label>4.3.</label>
<title>Identifying footprints</title>
<p>Having assembled the DNase-seq data into a set of aligned BAM files, &#x2462; of <xref rid="fig1" ref-type="fig">Fig 1</xref> uses the F-Seq program [<xref ref-type="bibr" rid="c35">35</xref>] to identify regions of open chromatin and then applies the HINT and Wellington footprint algorithms to those regions to generate footprints. This logic is implemented by the lower three applications in the master workflow shown in <xref rid="fig5" ref-type="fig">Fig 5A</xref>. The &#x201C;Footprints Workflow Batch Submit&#x201D; application runs the footprint generation subworkflow of <xref rid="fig5" ref-type="fig">Fig 5D,</xref> which first converts BAM files to Browser Extensible Data (BED) format, as required by the F-Seq tool; then runs the F-Seq tool on the BED file to identify areas of open chromatin; and finally runs the Wellington and HINT footprinting algorithms on both BED and BAM files to generate candidate footprints. Additional information on the generation process is available online [<xref ref-type="bibr" rid="c36">36</xref>].</p>
</sec>
<sec id="s3i">
<label>4.4.</label>
<title>Generating the catalog of hits</title>
<p>While each footprint identified in &#x2462; is a <italic>potential</italic> TFBS, simply calling each footprint as a TFBS does not identify the cognate TF. Additionally, some footprints may correspond to unidentified or uncharacterized TFs that cannot be utilized. In preparation for eliminating such footprints, &#x2463; creates a <italic>hit catalog</italic> that links the observed footprints to known TF binding motifs.</p>
<p>The input to &#x2463;, shown as Motif in <xref rid="fig1" ref-type="fig">Fig 1,</xref> is a collection of 1,530 nonredundant TF binding motifs assembled by Funk et al. [<xref ref-type="bibr" rid="c13">13</xref>]. This motif collection was assembled by using the Tomtom program from the MEME suite [<xref ref-type="bibr" rid="c37">37</xref>] to identify non-redundant motifs within the JASPAR 2016 [<xref ref-type="bibr" rid="c38">38</xref>], HOCOMOCO v10 [<xref ref-type="bibr" rid="c39">39</xref>], UniPROBE [<xref ref-type="bibr" rid="c40">40</xref>], and SwissRegulon [<xref ref-type="bibr" rid="c41">41</xref>] motif libraries, each of which was accessed via the Bioconductor R package MotifDb [<xref ref-type="bibr" rid="c42">42</xref>]. Tomtom was then used to compute pair-wise simularity scores for motifs from different libraries and then used those scores to eliminate redundant motifs. More details are available online [<xref ref-type="bibr" rid="c36">36</xref>]. This process involves human judgment and so we do not record the associated code as part of our reproducibility package. Rather we make available the resulting human-curated catalog to enable reproducibility of the subsequent workflow.</p>
<p>&#x2463; uses the Find Individual Motif Occurrences (FIMO) tool [<xref ref-type="bibr" rid="c43">43</xref>], also from the MEME suite, to identity potential TF binding sites in the GRCh38 human reference genome. It uses FIMO (from the Regulatory Genomics toolkit version 0.11.2 as captured in the Docker container <monospace>ark:/57799/b9jd6f</monospace>) to search GRCh38 (captured in the hg38 folder of <monospace>ark:/57799/b9fx1s</monospace>) for matches with each of the 1,530 non-redundant motifs. An individual motif can match multiple times, and thus the output of this step is a total of 1,344,953,740 hits, each comprising a motif, a genomic location, the probability of the motif occurring at that location, and the match score of the sequence position.</p>
</sec>
<sec id="s3j">
<label>4.5.</label>
<title>TFBS inference</title>
<p>The final step in the TFBS workflow involves intersecting the footprints produced in &#x2462; with the hits produced in &#x2463; to generate a set of candidate TFBSs. To accelerate the process of intersecting genomic locations, the Bioconductor R package GenomicRanges [<xref ref-type="bibr" rid="c44">44</xref>] is used to create GRanges objects for each of the 108 footprint files and for the hits catalog. Each footprint file is then intersected with the hits catalog independently to produce a total of 108 TFBS candidate files. For convenience, the footprints and TFBSs are also loaded into a cloud-based relational database, organized by tissue type, accessible as described online [<xref ref-type="bibr" rid="c45">45</xref>].</p>
</sec>
</sec>
<sec id="s4">
<label>5</label>
<title>Recap: A FAIR TFBS workflow</title>
<p>We review here the complete TFBS workflow, for which we specify the input datasets consumed by the workflow, the output datasets produced by the workflow, and the programs used to transform the inputs into the outputs. The inputs and programs are provided to enable readers to reproduce the results of the workflow; the outputs are provided for readers who want to use those results.</p>
<p>We specify each input, output, and program by providing a Minid. Several of these Minids reference what we call a &#x201C;bag of bags&#x201D; BDBag: a single BDBag that itself contains a set of BDBags, for example one per tissue. This use of a bag of bags allows us to refer to the dataset with a single identifier; the reader (or a program) can access the complete dataset by retrieving the bag of bags and using the BDBag tools to automatically download and materialize the constituent BDBags contained in its data directory. Each BDBag contains descriptive metadata for its contents.</p>
<p><xref rid="tbl2" ref-type="table">Table 2</xref> provide identifiers for the six datasets shown in <xref rid="fig1" ref-type="fig">Fig 1,</xref> and <xref rid="tbl3" ref-type="table">Table 3</xref> provides identifiers for the software used to implement the five computational steps of <xref rid="fig1" ref-type="fig">Fig 1</xref>. We also aggregate the information in these tables into a single document so that they can be accessed via a persistent digital object identifier [<xref ref-type="bibr" rid="c46">46</xref>]. To simplify the creation of Docker container components, we created a tool that generates a Docker manifest from a Galaxy tool definition [<xref ref-type="bibr" rid="c47">47</xref>].</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><p>The six datasets shown in <xref rid="fig1" ref-type="fig">Fig 1,</xref> D1&#x2013;D6. For each we indicate whether it is an input or output.</p></caption>
<graphic xlink:href="268755_tbl2.tif"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><p>The software used to implement the five steps shown in <xref rid="fig1" ref-type="fig">Fig 1</xref>. As the software for &#x2460; is used only to produce the input data at <monospace>ark:/57799/b9dt2t</monospace>, we do not provide identifiers for specific versions of that software.</p></caption>
<graphic xlink:href="268755_tbl3.tif"/>
</table-wrap>
<p>As a first step towards evaluating whether this information is enough to enable reproducibility, we asked a colleague to reproduce an analysis described in this paper: specifically, to regenerate the results for urinary bladder, for which, as shown in <xref rid="tbl1" ref-type="table">Table 1,</xref> there are only two replicates. They were successful.</p>
</sec>
<sec id="s5">
<label>6</label>
<title>Discussion</title>
<p>The TFBS inference workflow implementation presented in <xref ref-type="sec" rid="s4">Section 4</xref> is structured in a way that it can be easily re-run by others. It is, furthermore, organized in a way that allows it to make easy use of parallel cloud computing. These desirable properties are the result of a disciplined approach to application development that aims for compliance with the ten simple rules for reproducible computational research defined by Sandve et al. [<xref ref-type="bibr" rid="c48">48</xref>]:</p>
<list list-type="order">
<list-item><p><italic>For every result, keep track of how it was produced.</italic> We preserve workflows and assign Minids to workflow results.</p></list-item>
<list-item><p><italic>Avoid manual data manipulation steps.</italic> We encode all data manipulation steps in either Galaxy workflows or R scripts.</p></list-item>
<list-item><p><italic>Archive the exact versions of all external programs used.</italic> We create a Docker container with versions of the tools used in the analysis, and generate Minids for the Docker file and Docker image of the container.</p></list-item>
<list-item><p><italic>Version control all custom scripts.</italic> We maintain our programs in GitHub, which supports versioning, and provide Minids for the versions used.</p></list-item>
<list-item><p><italic>Record all intermediate results, when possible in standardized formats.</italic> We record the major intermediate results, in the same manner as inputs and output, using FASTQ, BAM, and BED formats. In the case of database files, we dump tables to a text file via SQL commands.</p></list-item>
<list-item><p><italic>For analyses that include randomness, note underlying random seeds.</italic> F-Seq uses the Java random number generator, but does not set or record a seed. We would need to modify F-Seq to record that information.</p></list-item>
<list-item><p><italic>Always store raw data behind plots.</italic> Minids provide concise references to the raw data used to create the plots in the paper, which are bundled in BDBags.</p></list-item>
<list-item><p><italic>Generate hierarchical analysis output, allowing layers of increasing detail to be inspected.</italic> Because we record the complete provenance of each result, a reader can easily trace lineage from a fact, plot, or summarized result back through the processing steps and intermediate and raw data used to derive that result.</p></list-item>
<list-item><p><italic>Connect textual statements to underlying results.</italic> Our use of Minids would make it easy for Funk et al. [<xref ref-type="bibr" rid="c13">13</xref>] to reference specific data in their text. They do not do at present, but may in a future version of their paper.</p></list-item>
<list-item><p><italic>Provide public access to scripts, runs, and results.</italic> Each is publicly available at a location accessible via a persistent identifier, as detailed in <xref rid="tbl2" ref-type="table">Tables 2</xref> and <xref rid="tbl3" ref-type="table">3</xref>.</p></list-item>
</list>
<p>The tools used in this case study do not in themselves ensure reproducibility and scalable execution, but they make it easy to create an implementation with those characteristics. For example, BDBag tools and Minid and Globus APIs allowed us to create the <monospace>encode2bag</monospace> web interface to ENCODE in just a few hours of effort, permitting a streamlining of the overall workflow that we likely would not have attempted otherwise. Similarly, the ability to create a new Minid at any time via a simple API call made it straightforward to create persistent identifiers for intermediate data products, which contributes to those data being Findable, Accessible, Interoperable, and Reusable (FAIR)&#x2014;four attributes of digital objects that are often viewed as fundamental to data-driven discovery [<xref ref-type="bibr" rid="c5">5</xref>]. And the fact that we could easily create a readable specification of the ensemble footprinting method as a Galaxy workflow, and then dispatch that workflow to Globus Genomics for parallel cloud execution without regard to the location of input and output data, reduced both time requirements and opportunities for error in those logistically complex computations. So too did the ease with which we could package applications within Docker containers.</p>
<sec id="s5a">
<label>6.1.</label>
<title>Other approaches</title>
<p>It is instructive to compare and contrast the methods described in this paper with other approaches to big data and/or reproducible science.</p>
<p>Biomedicine is not alone in struggling with the complexities described here [<xref ref-type="bibr" rid="c49">49</xref>]. But big data tools from outside biomedicine tend to focus on narrow aspects of the analytic problem, leaving researchers on their own when it comes to managing the end-to-end discovery process [<xref ref-type="bibr" rid="c50">50</xref>].</p>
<p>Many approaches to reproducibility focus on using mechanisms such as makefiles [<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>], open source software [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>], specialized programming environments [<xref ref-type="bibr" rid="c53">53</xref>], and virtual machines [<xref ref-type="bibr" rid="c54">54</xref>] to organize the code and/or data required for a computation. These approaches work well for small data but face challenges when computations must scale to terabytes and span sites.</p>
<p>Another set of approaches require that all data be placed, and analysis occur, within a single, homogeneous environment. In the case of the Analysis Commons [<xref ref-type="bibr" rid="c55">55</xref>] and Genomic Data Commons [<xref ref-type="bibr" rid="c56">56</xref>], this environment is a (public or private) cloud. Other systems leverage containers and related technologies to create a single reproducible artifact. Binder [<xref ref-type="bibr" rid="c57">57</xref>] allows researchers to create computational environments to interact with published code and data. Interactive notebooks, housed in public GitHub repositories, can be run in a version-controlled computational environment. Researchers structure their repository following simple conventions and include build files to describe the computational environment. Binder then uses a JupyterHub-like model to construct and spawn a computational environment in which to execute the notebook. Similarly, WholeTale [<xref ref-type="bibr" rid="c58">58</xref>] allows a researcher to construct a &#x201C;Tale,&#x201D; a computational narrative for a result. The researcher constructs a computational environment, selects one or more frontend analysis environments (e.g., Jupyter), and conducts their research within that environment. WholeTale tracks data imported into the environment (via linkage to identifiers or checksums) to produce a reproducible artifact (data, computation, and environment) for subsequent reuse and verification.</p>
<p>These approaches reduce complexity by enforcing physical or logical locality. They can work well when all required data and code can be integrated into the required homogenous environment. However, as the TFBS case study illustrates, data and computation are often distributed. Furthermore, the ability to move seamlessly among different storage and computational environments, as enabled by tools such as Globus, BDBags, and Globus Genomics, increases flexibility. The approach presented in this paper represents an alternative strategy for making science reproducible by directly addressing the needs of researchers working in loosely coupled environments in which multiple tools, services, and scripts are combined with distributed data products to conduct a given analysis.</p>
</sec>
<sec id="s5b">
<label>6.2.</label>
<title>A data commons</title>
<p>Rather than requiring the use of a single computational environment, the technologies used in this case study facilitate interoperability among environments, so that data can be accessed from many locations (Globus Connect) using common security mechanisms (Globus Auth), transferred in a compact form (BDBags) with consistent naming and checksums for verification of integrity (Minids), and then analyzed rapidly using software in common formats (Docker), declarative workflows (Galaxy), and parallel computation (Globus Genomics). These elements represent useful steps towards a data commons, which Bonnazi et al. [<xref ref-type="bibr" rid="c59">59</xref>] have described in these terms:</p>
<disp-quote><p>a shared virtual space where scientists can work with the digital objects of biomedical research; i.e., it is a system that will allow investigators to find, manage, share, use, and reuse data, software, metadata and workflows. It is a digital ecosystem that supports open science and leverages currently available computing platforms in a flexible and scalable manner to allow researchers to find and use computing environments, access public data sets and connect with other resources and tools (e.g. other data, software, workflows, etc.) associated with scholarly research.</p></disp-quote>
<p>By thus reducing barriers to finding and working with large data and complex software, our strategy makes it easier for researchers to access, analyze, and share data without regard to scale or location.</p>
</sec>
<sec id="s5c">
<label>7</label>
<title>Summary</title>
<p>We have presented tools designed to facilitate the implementation of complex, &#x201C;big data&#x201D; computations in ways that make the associated data and code findable, accessible, interoperable, and reusable (FAIR). To illustrate the use of these tools, we have described the implementation of a multi-stage DNase I hypersensitive sites sequencing data analysis that retrieves large datasets from a public repository and uses a mix of parallel cloud and workstation computation to identify candidate transcription factor binding sites. This pipeline can be rerun in its current form, for example as new DNase I hypersensitive sites sequencing data become available; extended with additional footprinting methods (for example, protein interaction quantification [<xref ref-type="bibr" rid="c60">60</xref>]) as new techniques become available; or modified to apply different integration and analysis methods. The case study thus demonstrates solutions to problems of scale and reproducibility in the heterogeneous, distributed world that characterizes much of modern biomedicine. We hope to see others experiment with these tools in other contexts and report their experiences.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank the Galaxy and Globus teams, and other developers of tools on which we build here, for their work. We also thank the NIH Commons Cloud Credits program and the Amazon Web Services Research Cloud Credits program for their support. This work was supported in part by NIH contracts 1U54EB020406-01: Big Data for Discovery Science Center, 1OT3OD025458-01: A Commons Platform for Promoting Continuous Fairness, and 5R01HG009018: Hardening Globus Genomics; and DOE contract DE-AC02-06CH11357.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="book"><string-name><surname>Hey</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tansley</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tolle</surname> <given-names>KM</given-names></string-name>. <source>The fourth paradigm: Data-intensive scientific discovery</source>. <publisher-name>Microsoft research Redmond</publisher-name>, <publisher-loc>WA</publisher-loc>; <year>2009</year>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Kitchin</surname> <given-names>R.</given-names></string-name> <article-title>Big Data, new epistemologies and paradigm shifts</article-title>. <source>Big Data &#x0026; Society</source>. <year>2014</year>;<volume>1</volume>(<issue>1</issue>):<fpage>2053951714528481</fpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Tenopir</surname> <given-names>C</given-names></string-name>, <string-name><surname>Allard</surname> <given-names>S</given-names></string-name>, <string-name><surname>Douglass</surname> <given-names>K</given-names></string-name>, <string-name><surname>Aydinoglu</surname> <given-names>AU</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>L</given-names></string-name>, <string-name><surname>Read</surname> <given-names>E</given-names></string-name>, <etal>et al.</etal> <article-title>Data sharing by scientists: practices and perceptions</article-title>. <source>PLOS ONE</source>. <year>2011</year>;<volume>6</volume>(<issue>6</issue>):<fpage>e21101</fpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Collins</surname> <given-names>FS</given-names></string-name>, <string-name><surname>Varmus</surname> <given-names>H.</given-names></string-name> <article-title>A new initiative on precision medicine</article-title>. <source>New England Journal of Medicine</source>. <year>2015</year>;<volume>372</volume>(<issue>9</issue>):<fpage>793</fpage>&#x2013;<lpage>795</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Wilkinson</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Dumontier</surname> <given-names>M</given-names></string-name>, <string-name><surname>Aalbersberg</surname> <given-names>IJ</given-names></string-name>, <string-name><surname>Appleton</surname> <given-names>G</given-names></string-name>, <string-name><surname>Axton</surname> <given-names>M</given-names></string-name>, <string-name><surname>Baak</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>The FAIR Guiding Principles for scientific data management and stewardship</article-title>. <source>Scientific Data</source>. <year>2016</year>;<volume>3</volume>:<fpage>160018</fpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Marx</surname> <given-names>V.</given-names></string-name> <article-title>Biology: The big challenges of big data</article-title>. <source>Nature</source>. <year>2013</year>;<volume>498</volume>(<issue>7453</issue>):<fpage>255</fpage>&#x2013;<lpage>260</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="confproc"><string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>D&#x2019;Arcy</surname> <given-names>M</given-names></string-name>, <string-name><surname>Heavner</surname> <given-names>B</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>I</given-names></string-name>, <string-name><surname>Kesselman</surname> <given-names>C</given-names></string-name>, <string-name><surname>Madduri</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <chapter-title>I&#x2019;ll take that to go: Big data bags and minimal identifiers for exchange of large, complex datasets</chapter-title>. In: <conf-name>IEEE International Conference on Big Data</conf-name>; <year>2016</year>. p. <fpage>319</fpage>&#x2013;<lpage>328</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Anathankrishnan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>I</given-names></string-name>, <string-name><surname>Lidman</surname> <given-names>M</given-names></string-name>, <string-name><surname>McCollam</surname> <given-names>B</given-names></string-name>, <string-name><surname>Rosen</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal> <article-title>Globus Auth</article-title>: <source>A Research Identity and Access Management Platform</source>; <year>2016</year>. p. <fpage>203</fpage>&#x2013;<lpage>212</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>Tuecke</surname> <given-names>S</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>I.</given-names></string-name> <article-title>Efficient and secure transfer, synchronization, and sharing of big data</article-title>. <source>IEEE Cloud Computing</source>. <year>2014</year>;<volume>1</volume>(<issue>3</issue>):<fpage>46</fpage>&#x2013;<lpage>55</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Madduri</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Sulakhe</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lacinski</surname> <given-names>L</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>B</given-names></string-name>, <string-name><surname>Rodriguez</surname> <given-names>A</given-names></string-name>, <string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal> <article-title>Experiences Building Globus Genomics: A Next-Generation Sequencing Analysis Service using Galaxy, Globus, and Amazon Web Services</article-title>. <source>Concurrency and Computation</source>. <year>2014</year>;<volume>26</volume>(<issue>13</issue>):<fpage>2266</fpage>&#x2013;<lpage>79</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Merkel</surname> <given-names>D.</given-names></string-name> <article-title>Docker: Lightweight Linux containers for consistent development and deployment</article-title>. <source>Linux Journal</source>. <year>2014</year>;<volume>2014</volume>(<issue>239</issue>):<fpage>2</fpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><collab>ENCODE Project Consortium</collab>. <article-title>An integrated encyclopedia of DNA elements in the human genome</article-title>. <source>Nature</source>;<volume>489</volume>:<fpage>57</fpage>&#x2013;<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Funk</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Jung</surname> <given-names>S</given-names></string-name>, <string-name><surname>Richards</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Rodriguez</surname> <given-names>A</given-names></string-name>, <string-name><surname>Shannon</surname> <given-names>P</given-names></string-name>, <string-name><surname>Donovan</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <article-title>Atlas of Transcription Factor Binding Sites from ENCODE DNase Hypersensitivity Data Across 27 Tissue Types</article-title>. <source>bioRxiv</source>. <year>2018</year>;doi:<pub-id pub-id-type="doi">10.1101/252023.</pub-id></mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Piper</surname> <given-names>J</given-names></string-name>, <string-name><surname>Elze</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Cauchy</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cockerill</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Bonifer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ott</surname> <given-names>S.</given-names></string-name> <article-title>Wellington: A novel method for the accurate identification of digital genomic footprints from DNase-seq data</article-title>. <source>Nucleic Acids Res</source>. <year>2013</year>;<volume>41</volume>(<issue>21</issue>):<fpage>e201</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Gusmao</surname> <given-names>EG</given-names></string-name>, <string-name><surname>Dieterich</surname> <given-names>C</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>M</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>IG</given-names></string-name>. <article-title>Detection of active transcription factor binding sites with the combination of DNase hypersensitivity and histone modifications</article-title>. <source>Bioinformatics</source>. <year>2014</year>;<volume>30</volume>(<issue>22</issue>):<fpage>3143</fpage>&#x2013;<lpage>51</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Gusmao</surname> <given-names>EG</given-names></string-name>, <string-name><surname>Allhoff</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>M</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>IG</given-names></string-name>. <article-title>Analysis of computational footprinting methods for DNase sequencing experiments</article-title>. <source>Nature Methods</source>. <year>2016</year>;<volume>13</volume>(<issue>4</issue>):<fpage>303</fpage>&#x2013;<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Toga</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>I</given-names></string-name>, <string-name><surname>Kesselman</surname> <given-names>C</given-names></string-name>, <string-name><surname>Madduri</surname> <given-names>R</given-names></string-name>, <string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>Deutsch</surname> <given-names>EW</given-names></string-name>, <etal>et al.</etal> <article-title>Big biomedical data as the key resource for discovery science</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2015</year>;<volume>22</volume>(<issue>6</issue>):<fpage>1126</fpage>&#x2013;<lpage>31</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="confproc"><string-name><surname>Bechhofer</surname> <given-names>S</given-names></string-name>, <string-name><surname>De Roure</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gamble</surname> <given-names>M</given-names></string-name>, <string-name><surname>Goble</surname> <given-names>C</given-names></string-name>, <string-name><surname>Buchan</surname> <given-names>I.</given-names></string-name> <chapter-title>Research Objects: Towards exchange and reuse of digital knowledge</chapter-title>. In: <conf-name>Workshop on The Future of the Web for Collaborative Science</conf-name>; <year>2010</year>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="other"><string-name><surname>Kunze</surname> <given-names>J</given-names></string-name>, <string-name><surname>Littman</surname> <given-names>J</given-names></string-name>, <string-name><surname>Madden</surname> <given-names>L</given-names></string-name>, <string-name><surname>Summers</surname> <given-names>E</given-names></string-name>, <string-name><surname>Boyko</surname> <given-names>A</given-names></string-name>, <string-name><surname>Vargas</surname> <given-names>B.</given-names></string-name> <article-title>The BagIt File Packaging Format (V0.97</article-title>). Internet Engineering Task Force, Internet Draft (work in progress), draft-kunze-bagit-14.txt; <year>2017</year>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="website"><string-name><surname>Sporny</surname> <given-names>M</given-names></string-name>, <string-name><surname>Longley</surname> <given-names>D</given-names></string-name>, <string-name><surname>Kellogg</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lanthaler</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lindstr&#x00A8;om</surname> <given-names>N.</given-names></string-name> <article-title>JSON-LD 1.1: A JSON-based Serialization for Linked Data</article-title>; <year>2018</year>. Available from: <ext-link ext-link-type="uri" xlink:href="https://json-ld.org/spec/latest/json-ld/">https://json-ld.org/spec/latest/json-ld/</ext-link>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Wimalaratne</surname> <given-names>S</given-names></string-name>, <string-name><surname>Juty</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kunze</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jan&#x00E9;e</surname> <given-names>G</given-names></string-name>, <string-name><surname>McMurry</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Beard</surname> <given-names>N</given-names></string-name>, <etal>et al.</etal> <article-title>Uniform Resolution of Compact Identifiers for Biomedical Data</article-title>. <source>bioRxiv</source>. <year>2018</year>;doi:<pub-id pub-id-type="doi">10.1101/101279.</pub-id></mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="confproc"><string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>Pruyne</surname> <given-names>J</given-names></string-name>, <string-name><surname>Blaiszik</surname> <given-names>B</given-names></string-name>, <string-name><surname>Ananthakrishnan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Tuecke</surname> <given-names>S</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>I.</given-names></string-name> <article-title>Globus data publication as a service: Lowering barriers to reproducible science</article-title>. In: <conf-name>11th International Conference on e-Science</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2015</year>. p. <fpage>401</fpage>&#x2013;<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Paskin</surname> <given-names>N.</given-names></string-name> <article-title>Digital object identifiers for scientific data</article-title>. <source>Data Science Journal</source>. <year>2005</year>;<volume>4</volume>:<fpage>12</fpage>&#x2013;<lpage>20</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="confproc"><string-name><surname>Kluyver</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ragan-Kelley</surname> <given-names>B</given-names></string-name>, <string-name><surname>P&#x00E9;rez</surname> <given-names>F</given-names></string-name>, <string-name><surname>Granger</surname> <given-names>BE</given-names></string-name>, <string-name><surname>Bussonnier</surname> <given-names>M</given-names></string-name>, <string-name><surname>Frederic</surname> <given-names>J</given-names></string-name>, <etal>et al.</etal> <article-title>Jupyter Notebooks&#x2013;a publishing format for reproducible computational workflows</article-title>. In: <conf-name>20th International Conference on Electronic Publishing</conf-name>; <year>2016</year>. p. <fpage>87</fpage>&#x2013;<lpage>90</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Deutsch</surname> <given-names>E</given-names></string-name>, <string-name><surname>Kramer</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ames</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bauman</surname> <given-names>A</given-names></string-name>, <string-name><surname>Campbell</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal> <article-title>BDQC: A general-purpose analytics tool for domain-blind validation of Big Data</article-title>. <source>bioRxiv</source>. <year>2018</year>; p. <fpage>258822</fpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Afgan</surname> <given-names>E</given-names></string-name>, <string-name><surname>Baker</surname> <given-names>D</given-names></string-name>, <string-name><surname>van den Beek</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blankenberg</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bouvier</surname> <given-names>D</given-names></string-name>, <string-name><surname>&#x010C;ech</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update</article-title>. <source>Nucleic Acids Research</source>. <year>2016</year>;<volume>44</volume>(<issue>W1</issue>):<fpage>W3</fpage>&#x2013;<lpage>W10</lpage>. doi:<pub-id pub-id-type="doi">10.1093/nar/gkw343.</pub-id></mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Vivian</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rao</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Nothaft</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Ketchum</surname> <given-names>C</given-names></string-name>, <string-name><surname>Armstrong</surname> <given-names>J</given-names></string-name>, <string-name><surname>Novak</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>Toil enables reproducible, open source, big biomedical data analyses</article-title>. <source>Nature Biotechnology</source>. <year>2017</year>;<volume>35</volume>(<issue>4</issue>):<fpage>314</fpage>&#x2013;<lpage>316</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Dinov</surname> <given-names>ID</given-names></string-name>, <string-name><surname>Heavner</surname> <given-names>B</given-names></string-name>, <string-name><surname>Tang</surname> <given-names>M</given-names></string-name>, <string-name><surname>Glusman</surname> <given-names>G</given-names></string-name>, <string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>Darcy</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>Predictive Big Data Analytics: A Study of Parkinson&#x2019;s Disease Using Large, Complex, Heterogeneous, Incongruent, Multi-Source and Incomplete Observations</article-title>. <source>PLOS ONE</source>. <year>2016</year>;<volume>11</volume>(<issue>8</issue>):<fpage>1</fpage>&#x2013;<lpage>28</lpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0157077.</pub-id></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Dinov</surname> <given-names>ID</given-names></string-name>, <string-name><surname>Petrosyan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Eggert</surname> <given-names>P</given-names></string-name>, <string-name><surname>Hobel</surname> <given-names>S</given-names></string-name>, <string-name><surname>Vespa</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal> <article-title>High-throughput neuroimaging-genetics computational infrastructure</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2014</year>;<volume>8</volume>:<fpage>41</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fninf.2014.00041.</pub-id></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="website"><string-name><surname>Amstutz</surname> <given-names>P</given-names></string-name>, <string-name><surname>Crusoe</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Tijani&#x0107;</surname> <given-names>N</given-names></string-name>, <string-name><surname>Chapman</surname> <given-names>B</given-names></string-name>, <string-name><surname>Chilton</surname> <given-names>J</given-names></string-name>, <string-name><surname>Heuer</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>Common Workflow Language, v1.0</article-title>; <year>2016</year>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.3115156.v2">http://dx.doi.org/10.6084/m9.figshare.3115156.v2</ext-link>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Peng</surname> <given-names>RD.</given-names></string-name> <article-title>Reproducible research in computational science</article-title>. <source>Science</source>. <year>2011</year>;<volume>334</volume>(<issue>6060</issue>):<fpage>1226</fpage>&#x2013;<lpage>1227</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Morin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Urban</surname> <given-names>J</given-names></string-name>, <string-name><surname>Adams</surname> <given-names>P</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>I</given-names></string-name>, <string-name><surname>Sali</surname> <given-names>A</given-names></string-name>, <string-name><surname>Baker</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>Shining light into black boxes</article-title>. <source>Science</source>. <year>2012</year>;<volume>336</volume>(<issue>6078</issue>):<fpage>159</fpage>&#x2013;<lpage>160</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Kurtzer</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Sochat</surname> <given-names>V</given-names></string-name>, <string-name><surname>Bauer</surname> <given-names>MW</given-names></string-name>. <article-title>Singularity: Scientific containers for mobility of compute</article-title>. <source>PLOS ONE</source>. <year>2017</year>;<volume>12</volume>(<issue>5</issue>):<fpage>e0177459</fpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Chamberlain</surname> <given-names>R</given-names></string-name>, <string-name><surname>Schommer</surname> <given-names>J.</given-names></string-name> <article-title>Using Docker to support reproducible research</article-title>; <year>2014</year>. <source>Available from</source>: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.1101910.v1">https://doi.org/10.6084/m9.figshare.1101910.v1</ext-link>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Boyle</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Guinney</surname> <given-names>J</given-names></string-name>, <string-name><surname>Crawford</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Furey</surname> <given-names>TS</given-names></string-name>. <article-title>F-Seq: a feature density estimator for high-throughput sequence tags</article-title>. <source>Bioinformatics</source>. <year>2008</year>;<volume>24</volume>(<issue>21</issue>):<fpage>2537</fpage>&#x2013;<lpage>2538</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="website"><article-title>Generate the transcription factor binding motif catalog</article-title>;. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/globusgenomics/genomics-footprint/tree/master/">https://github.com/globusgenomics/genomics-footprint/tree/master/</ext-link> generate&#x005F;motif.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Bailey</surname> <given-names>TL</given-names></string-name>, <string-name><surname>Boden</surname> <given-names>M</given-names></string-name>, <string-name><surname>Buske</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Frith</surname> <given-names>M</given-names></string-name>, <string-name><surname>Grant</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Clementi</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal> <article-title>MEME Suite: Tools for motif discovery and searching</article-title>. <source>Nucleic Acids Research</source>. <year>2009</year>;<volume>37</volume>:<fpage>W202</fpage>&#x2013;<lpage>W208</lpage>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Mathelier</surname> <given-names>A</given-names></string-name>, <string-name><surname>Fornes</surname> <given-names>O</given-names></string-name>, <string-name><surname>Arenillas</surname> <given-names>DJ</given-names></string-name>, <string-name><given-names>Chen</given-names> <surname>Cy</surname></string-name>, <string-name><surname>Denay</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>J</given-names></string-name>, <etal>et al.</etal> <article-title>JASPAR 2016: A major expansion and update of the open-access database of transcription factor binding profiles</article-title>. <source>Nucleic Acids Research</source>. <year>2015</year>;<volume>44</volume>(<issue>D1</issue>):<fpage>D110</fpage>&#x2013;<lpage>D115</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Kulakovskiy</surname> <given-names>IV</given-names></string-name>, <string-name><surname>Vorontsov</surname> <given-names>IE</given-names></string-name>, <string-name><surname>Yevshin</surname> <given-names>IS</given-names></string-name>, <string-name><surname>Soboleva</surname> <given-names>AV</given-names></string-name>, <string-name><surname>Kasianov</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Ashoor</surname> <given-names>H</given-names></string-name>, <etal>et al.</etal> <article-title>HOCOMOCO: Expansion and enhancement of the collection of transcription factor binding sites models</article-title>. <source>Nucleic Acids Research</source>. <year>2015</year>;<volume>44</volume>(<issue>D1</issue>):<fpage>D116</fpage>&#x2013;<lpage>D125</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Hume</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Barrera</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Gisselbrecht</surname> <given-names>SS</given-names></string-name>, <string-name><surname>Bulyk</surname> <given-names>ML</given-names></string-name>. <article-title>UniPROBE, update 2015: New tools and content for the online database of protein-binding microarray data on protein&#x2013;DNA interactions</article-title>. <source>Nucleic Acids Research</source>. <year>2014</year>;<volume>43</volume>(<issue>D1</issue>):<fpage>D117</fpage>&#x2013;<lpage>D122</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Pachkov</surname> <given-names>M</given-names></string-name>, <string-name><surname>Erb</surname> <given-names>I</given-names></string-name>, <string-name><surname>Molina</surname> <given-names>N</given-names></string-name>, <string-name><surname>Van Nimwegen</surname> <given-names>E.</given-names></string-name> <article-title>SwissRegulon: A database of genome-wide annotations of regulatory sites</article-title>. <source>Nucleic Acids Research</source>. <year>2006</year>;<volume>35</volume>(<issue>suppl 1</issue>):<fpage>D127</fpage>&#x2013;<lpage>D131</lpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Shannon</surname> <given-names>P</given-names></string-name>, <string-name><surname>Richards</surname> <given-names>M.</given-names></string-name> <article-title>MotifDb: An Annotated Collection of Protein-DNA Binding Sequence Motifs</article-title>. <source>R package version 1.20.0</source>; <year>2017</year>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Grant</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Bailey</surname> <given-names>TL</given-names></string-name>, <string-name><surname>Noble</surname> <given-names>WS</given-names></string-name>. <article-title>FIMO: Scanning for occurrences of a given motif</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>27</volume>(<issue>7</issue>):<fpage>1017</fpage>&#x2013;<lpage>1018</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Lawrence</surname> <given-names>M</given-names></string-name>, <string-name><surname>Huber</surname> <given-names>W</given-names></string-name>, <string-name><surname>Pag&#x00E8;s</surname> <given-names>H</given-names></string-name>, <string-name><surname>Aboyoun</surname> <given-names>P</given-names></string-name>, <string-name><surname>Carlson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gentleman</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <article-title>Software for Computing and Annotating Genomic Ranges</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>8</issue>):<fpage>e1003118</fpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="website"><article-title>How to use the footprint databases</article-title>;. Available from: <ext-link ext-link-type="uri" xlink:href="http://footprints.bdds.globusgenomics.org">http://footprints.bdds.globusgenomics.org</ext-link>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="website"><string-name><surname>Funk</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Jung</surname> <given-names>S</given-names></string-name>, <string-name><surname>Richards</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Rodriguez</surname> <given-names>A</given-names></string-name>, <string-name><surname>Shannon</surname> <given-names>P</given-names></string-name>, <string-name><surname>Donovan</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <article-title>Data for transcription factor binding site atlas paper</article-title>; <year>2018</year>. Available from: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5924077">https://doi.org/10.6084/m9.figshare.5924077</ext-link>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="website"><article-title>Java program for the automation of creating Dockerfile, building it, and pushing it to the Docker Hub</article-title>;. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/globusgenomics/GlobusGenomics&#x005F;Java">https://github.com/globusgenomics/GlobusGenomics&#x005F;Java</ext-link>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Sandve</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Nekrutenko</surname> <given-names>A</given-names></string-name>, <string-name><surname>Taylor</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hovig</surname> <given-names>E.</given-names></string-name> <article-title>Ten simple rules for reproducible computational research</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>10</issue>):<fpage>e1003285</fpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Mattmann</surname> <given-names>CA</given-names></string-name>. <article-title>Computing: A vision for data science</article-title>. <source>Nature</source>. <year>2013</year>;<volume>493</volume>(<issue>7433</issue>):<fpage>473</fpage>&#x2013;<lpage>475</lpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Boyle</surname> <given-names>J.</given-names></string-name> <article-title>Biology must develop its own big-data systems</article-title>. <source>Nature</source>. <year>2013</year>;<volume>499</volume>(<issue>7456</issue>):<fpage>7</fpage>&#x2013;<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="confproc"><string-name><surname>Claerbou</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Karrenfach</surname> <given-names>M.</given-names></string-name> <chapter-title>Electronic documents give reproducible research a new meaning</chapter-title>. In: <conf-name>Society of Exploration Geophysicists Annual Meeting</conf-name>; <year>1992</year>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Schwab</surname> <given-names>M</given-names></string-name>, <string-name><surname>Karrenbach</surname> <given-names>M</given-names></string-name>, <string-name><surname>Claerbout</surname> <given-names>J.</given-names></string-name> <article-title>Making scientific computations reproducible</article-title>. <source>Computing in Science &#x0026; Engineering</source>. <year>2000</year>;<volume>2</volume>(<issue>6</issue>):<fpage>61</fpage>&#x2013;<lpage>67</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Mesirov</surname> <given-names>JP</given-names></string-name>. <article-title>Accessible reproducible research</article-title>. <source>Science</source>. <year>2010</year>;<volume>327</volume>(<issue>5964</issue>):<fpage>415</fpage>&#x2013;<lpage>416</lpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="other"><string-name><surname>Jensen</surname> <given-names>TL</given-names></string-name>, <string-name><surname>Frasketi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Conway</surname> <given-names>K</given-names></string-name>, <string-name><surname>Villarroel</surname> <given-names>L</given-names></string-name>, <string-name><surname>Hill</surname> <given-names>H</given-names></string-name>, <string-name><surname>Krampis</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal> <article-title>RSEQREP: RNA-Seq Reports, an open-source cloud-enabled framework for reproducible RNA-Seq data processing, analysis, and result reporting</article-title>. <source>F1000Research</source>. <year>2017</year>;<fpage>6</fpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Brody</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Morrison</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Bis</surname> <given-names>JC</given-names></string-name>, <string-name><surname>O&#x2019;Connell</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Huffman</surname> <given-names>JE</given-names></string-name>, <etal>et al.</etal> <article-title>Analysis commons, a team approach to discovery in a big-data environment for genetic epidemiology</article-title>. <source>Nature Genetics</source>. <year>2017</year>;<volume>49</volume>(<issue>11</issue>):<fpage>1560</fpage>&#x2013;<lpage>1563</lpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Grossman</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Heath</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Ferretti</surname> <given-names>V</given-names></string-name>, <string-name><surname>Varmus</surname> <given-names>HE</given-names></string-name>, <string-name><surname>Lowy</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Kibbe</surname> <given-names>WA</given-names></string-name>, <etal>et al.</etal> <article-title>Toward a shared vision for cancer genomic data</article-title>. <source>New England Journal of Medicine</source>. <year>2016</year>;<volume>375</volume>(<issue>12</issue>):<fpage>1109</fpage>&#x2013;<lpage>1112</lpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="website"><string-name><surname>Culich</surname> <given-names>A</given-names></string-name>, <string-name><surname>Granger</surname> <given-names>B</given-names></string-name>, <string-name><surname>Head</surname> <given-names>T</given-names></string-name>, <string-name><surname>Holdgraf</surname> <given-names>C</given-names></string-name>, <string-name><surname>Panda</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Perez</surname> <given-names>F</given-names></string-name>, <etal>et al.</etal> <article-title>Binder: Enabling sharing and publication of reproducible computational research</article-title>; <year>2017</year>. Available from: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5671840.v1">https://doi.org/10.6084/m9.figshare.5671840.v1</ext-link>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Brinckman</surname> <given-names>A</given-names></string-name>, <string-name><surname>Chard</surname> <given-names>K</given-names></string-name>, <string-name><surname>Gaffney</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hategan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Kowalik</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal> <article-title>Computing Environments for Reproducibility: Capturing the &#x201C;Whole Tale&#x201D;</article-title>. <source>Future Generation Computer Systems</source>. <year>2017</year>;.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>Bonazzi</surname> <given-names>VR</given-names></string-name>, <string-name><surname>Bourne</surname> <given-names>PE</given-names></string-name>. <article-title>Should biomedical research be like Airbnb</article-title>? <source>PLoS Biol</source>. <year>2017</year>;<volume>15</volume>:<fpage>e2001818</fpage>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Sherwood</surname> <given-names>RI</given-names></string-name>, <string-name><surname>Hashimoto</surname> <given-names>T</given-names></string-name>, <string-name><surname>O&#x2019;Donnell</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Lewis</surname> <given-names>S</given-names></string-name>, <string-name><surname>Barkal</surname> <given-names>AA</given-names></string-name>, <string-name><surname>van Hoff</surname> <given-names>JP</given-names></string-name>, <etal>et al.</etal> <article-title>Discovery of directional and nondirectional pioneer transcription factors by modeling DNase profile magnitude and shape</article-title>. <source>Nat Biotechnol</source>. <year>2014</year>;<volume>32</volume>(<issue>2</issue>):<fpage>171</fpage>&#x2013;<lpage>8</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>