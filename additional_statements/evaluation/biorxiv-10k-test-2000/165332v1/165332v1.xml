<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/165332</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Dynamic cortical representations of perceptual filling-in for missing acoustic rhythm</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Constantino</surname>
<given-names>Francisco Cervantes</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0858-0698</contrib-id>
<name>
<surname>Simon</surname>
<given-names>Jonathan Z.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Program in Neuroscience and Cognitive Science, University of Maryland</institution>, College Park, MD 20742, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Electrical and Computer Engineering University of Maryland</institution>, College Park, MD 20742, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Department of Biology University of Maryland</institution>, College Park, MD 20742, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Institute for Systems Research University of Maryland</institution>, College Park, MD 20742, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author <email>jzsimon@umd.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>165332</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>18</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>7</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="165332.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>In the phenomenon of perceptual filling-in, missing sensory information can be reconstructed via interpolation from adjacent contextual cues by what is necessarily an endogenous, not yet well understood, neural process. In this investigation, sound stimuli were chosen to allow observation of fixed cortical oscillations driven by contextual (but missing) sensory input, thus entirely reflecting endogenous neural activity. The stimulus employed was a 5 Hz frequency-modulated tone, with brief masker probes (noise bursts) occasionally added. For half the probes, the rhythmic frequency modulation was moreover removed. Listeners reported whether the tone masked by each probe was perceived as being rhythmic or not. Time-frequency analysis of neural responses obtained by magnetoencephalography (MEG) shows that for maskers without the underlying acoustic rhythm, trials where rhythm was nonetheless perceived show higher evoked sustained rhythmic power than trials for which no rhythm was reported. The results support a model in which perceptual filling-in is aided by differential co-modulations of cortical activity at rates directly relevant to human speech communication. We propose that the presence of rhythmically-modulated neural dynamics predicts the subjective experience of a rhythmically modulated sound in real time, even when the perceptual experience is not supported by corresponding sensory data.</p>
</abstract>
<counts>
<page-count count="29"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The ability to overcome the problem of missing but important sensory information, such as a conversation obscured by heavy background noise, is ethologically valuable. Even when physical information may be lost entirely, restorative phenomena such as the auditory continuity illusion, phonemic restoration, and other forms of perceptual filling-in<sup><xref rid="c1" ref-type="bibr">1</xref>&#x2013;<xref rid="c3" ref-type="bibr">3</xref></sup>, allow for the percept of stable hearing in natural environments. These effects have long been hypothesized to rely on the brain&#x2019;s ability to conjecture a reasonable guess as to the nature of the missing fragments<sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c4" ref-type="bibr">4</xref></sup>. Furthermore, as has been extensively argued, predictive coding is a task well suited for cerebral cortex<sup><xref rid="c5" ref-type="bibr">5</xref>&#x2013;<xref rid="c7" ref-type="bibr">7</xref></sup> but systematic accounts of endogenous cortical mechanisms responsible for these percepts remain unspecified.</p>
<p>Rhythmically-modulated sounds generate steady predictable events for which disruptions and resumptions may indicate the grouping strength of dynamic perceptual streams<sup><xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c9" ref-type="bibr">9</xref></sup>. If replacement of these sounds by noise may, under some circumstances, preserve the perceived rhythm in apparent continuity, how are such streams instantiated at the neural level?Rhythmic sounds drive auditory steady-state responses (aSSR) in auditory cortex and can be recorded non-invasively via magnetoencephalography (MEG)<sup><xref rid="c10" ref-type="bibr">10</xref>&#x2013;<xref rid="c12" ref-type="bibr">12</xref></sup>, with responses to rhythmic rates &#x003C;10 Hz being especially prominent<sup><xref rid="c13" ref-type="bibr">13</xref>&#x2013;<xref rid="c16" ref-type="bibr">16</xref></sup>. To the extent to which the neural responses track the stimulus rhythm, they can be considered sparse neural representations of the modulation rate. This experimental framework was employed to investigate the cortical effects of briefly masking and removing an ongoing low-frequency rhythmic pattern. We hypothesize that for cases where perceptual restoration of the removed rhythm occurs, the neural signature of the removal is attenuated&#x2014;akin to stabilization of a cortical representation, in line with perceptual grouping under dynamic continuity. This predicts that during perceptual filling-in, the dynamical evolution of a listener&#x2019;s cortical response retains oscillation in synchrony with the expected but acoustically missing rhythm.</p>
<p>Listeners&#x2019; perception of a continuous 5 Hz rhythmic pattern during masking was probed in a two-alternative forced choice task, where the acoustic pattern may or may not have been removed with equal probability. Simultaneously obtained MEG responses were then partitioned according to both physical and perceptual conditions, using wavelet analysis to localize oscillatory responses in time and frequency. The finding of rhythmic aSSR-like responses in cases where perceptual filling-in occurs is consistent with underlying mechanisms requiring a sustained neural representation of the restored feature<sup><xref rid="c2" ref-type="bibr">2</xref></sup>. Importantly, it demonstrates dynamical restoration processes occurring at scales commensurate with informal speech articulation rates<sup><xref rid="c17" ref-type="bibr">17</xref></sup>, as well as within MEG frequency bands that reflect cortical phase-locking to the slow temporal envelope of natural stimuli<sup><xref rid="c15" ref-type="bibr">15</xref>,<xref rid="c18" ref-type="bibr">18</xref></sup>.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Sustained neural rhythm follows acoustic rhythm in noise</title>
<p>Subjects listened to four blocks (&#x007E;14 min each) of a 5 Hz frequency modulated (FM) rhythmic stimulus, repeatedly masked by noise probes at pseudo-random times (see <italic>Methods</italic>). Half of the probes replaced the underlying rhythmic FM tone with a constant frequency tone, and half instead simply masked the underlying rhythmic stimulus, here called non-rhythmic and rhythmic probes, respectively (<xref rid="fig1" ref-type="fig">Fig. 1A</xref> insets). Between noise masker segments, MEG responses to steady rhythmic intervals show strong aSSR, even on a per-trial basis. Noise masker segments generate strong transient onset-like responses, after which any residual phase-locked response may disappear, on average, for rhythm-absent probes but not rhythmically-driven probes (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). To determine whether across subjects this change results from a decrease in aSSR power, or increased temporal jitter that would reduce averaged aSSR, inter-trial phase coherence (ITPC) and power analyses were performed on single-trial and evoked data respectively (e.g. <xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Results of inter-trial phase coherence (ITPC) analysis reveal that, within the 0.55 &#x2013; 1.22 s post probe onset interval, the ITPC difference is significant across (<italic>N</italic>= 35) listeners (<italic>p</italic> &#x003C; 0.001; non-parametric permutation test). Testing for evoked rhythmic power for across listeners similarly reveals a significant difference (<italic>p</italic>&#x003C; 0.001) within the 0.56&#x2013; 1.23 s post probe onset interval. Thus the dual phase and power analyses show that both decreased aSSR power and increased intertrial jitter contribute to the decrease of the neural 5 Hz component in rhythmically absent versus driven probes.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Neural representations of rhythm in noise versus tone in noise from a representative subject.</title>
<p>(<bold>a</bold>) MEG responses before, during, and after a noise probe are shown (single MEG component obtained via spatial filtering; see <italic>Methods</italic> and Supplementary Fig. 1). The basic stimulus consists of a 5 Hz pulsatile (short duty-cycle) FM tone, centered at <italic>f</italic><sub><italic>0</italic></sub> = 1024 Hz, to which 1.24 s noise probes were applied. Insets: illustration of a non-rhythmic probe where pulses are replaced by the constant tone (top); and a rhythmic probe, where the FM continues under the noise (bottom). Before and after the probes, phase locking to the main rhythmic stimulus is apparent even on a per-trial basis. Overlaid on each response raster, evoked activity (averaged separately for each probe type) reveals a measurable aSSR during rhythmically-driven probes (top) but not during rhythm-absent probes (bottom). (<bold>b</bold>) Top: Phase analysis at 5 Hz shows estimated phase-locking over time as measured by ITPC. During masking ITPC values drop to near floor in rhythm absent probes (orange) but only to half of baseline levels in rhythm-driven probes (blue). Bottom: Analysis of spectral power (also at the 5 Hz rhythm rate) also shows considerable difference between probe types for this subject.</p></caption>
<graphic xlink:href="165332_fig1.tif"/>
</fig>
</sec>
<sec id="s2b">
<title>Sustained neural rhythm follows listeners&#x2019; perceived rhythm in noise</title>
<p>In order to determine how neural representations of rhythm co-varied with perception, after each trial the probe was classified by the subject as perceived as rhythmic or as non-rhythmic. This resulted in a 2-by-2 partition of analyzed trials: (1) non-rhythmic probes perceived rhythmic (&#x2018;filling-in&#x2019;); (2) non-rhythmic probes perceived non-rhythmic (rhythm &#x2018;absent&#x2019;); (3) rhythmic probes perceived rhythmic (rhythm &#x2018;present&#x2019;); and (4) rhythmic probes perceived non-rhythmic (rhythm &#x2018;missed&#x2019;). <xref rid="fig2" ref-type="fig">Fig. 2</xref> shows the grand average evoked 5 Hz response power before, during, and after noise probes, for each combined condition of stimulus and percept.Transient (and broadband) masker-onset responses were evident during the initial 0.3 s post masker onset (cf. Supplementary <xref rid="fig2" ref-type="fig">Fig. 2</xref>) (brief pre-causal dips accompanying these transients are due to convolution residuals from the continuous wavelet transform).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Percept-specific endogenous representations of patterned sound.</title>
<p>Grand averages (<italic>N</italic> = 35) of rhythmic evoked power and intertrial phase coherence partitioned by probe type and reported percept. Noise probe starts at the first vertical line at <italic>t</italic> = 0 s and continues until the next vertical line at <italic>t</italic> = 1.24 s. (<bold>a</bold>) Non-rhythmic probes: (Left) After an initial transient, rhythmic evoked power was reduced regardless of percept, but differentially by 7.9 dB depending on percept as present (magenta), or absent (orange). (Right) No significant difference was observed for ITPC, where there was a reduction to near floor during the probe. (<bold>b</bold>) Rhythmic probes: (Left) During masking, rhythmic evoked power drops by 9.5 dB in average, holding relatively steady for the duration of the probe. (Right) Similarly, inter-trial phase coherence drops by about 81&#x0025; for the duration of the probe. For probes in which the rhythm was missed (brown), however, both evoked power and ITPC showed an additional reduction (only near the end of the probe) compared to rhythmically-driven probes (blue). Solid lines: mean across subjects and trials; Color bands: bootstrap 95&#x0025; confidence of the mean over subjects; Grey bands: time intervals with no significant difference by percept.</p></caption>
<graphic xlink:href="165332_fig2.tif"/>
</fig>
<p>For non-rhythmic probes (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>), phase coherence dropped to almost 0&#x0025; for both perceptual conditions (filling-in and absent, right panel). Rhythmic spectral power also dropped from the initial baseline for both perceptual states, but the decrease was on average 7.9 dB worse when subjects reported the rhythm absent than present (filling-in). Decreases were restored to baseline values by 0.8 to 1.2 s post probe offset (equivalent to between 4 and 6 rhythmic pulse cycles. Thus, within non-rhythmic probes, a sustained and significant percept-specific difference was observed in rhythmic evoked power (0.56 to 1.19 s, <italic>p</italic> &#x003C; 0.001), but this was not the case for phase locking (<italic>p</italic>&#x003E; 0.18).</p>
<p>For rhythmic probes (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>), the masker was associated with an average relative decrease of 9.5 dB evoked power regardless of perceptual condition (driven and missed), and with a relative decrease of &#x007E;75&#x0025; in trial-to-trial phase locking. When subjects missed the rhythm, evoked power and inter-trial phase coherence both further decreased, with percept-specific decreases sustained over a longer period for ITPC (0.84 &#x2013; 1.25 s, <italic>p</italic> &#x003C; 0.001; right panel) than evoked power (1.04 &#x2013; 1.15 s, <italic>p</italic> = 0.008; left panel).</p>
</sec>
<sec id="s2c">
<title>Rhythmic neural power as discrimination statistic in a rhythm detection task</title>
<p>With the observation that differential neural processing of masked rhythm depends on listeners&#x2019; percept, it was next investigated whether the observed divergence might have properties of an internal variable underlying discrimination. Based on the previous result, we hypothesized that the 5 Hz target neural processing power in the final &#x007E;600 ms of the probe interval might act as such variable. For each subject, a metric was created from the rhythmic evoked power differences contrast, integrated over the 0.56 &#x2013; 1.24 s interval of interest post probe onset. To illustrate the use of this latent variable as a discrimination statistic, a bootstrap resampling of trials (with replacement) was used to produce distributions of evoked power sustained over the critical window (two representative subjects shown in <xref rid="fig3" ref-type="fig">Fig. 3A</xref>). A neural discriminability metric was then computed from their relative separation (see <bold><italic>Methods</italic>).</bold> To assess the potential of this sustained evoked power to operate as a variable relevant to perceptual discrimination, the neural metric was compared with psychometric <italic>d</italic>&#x2019; scores that index behavioral sensitivity of listeners to the detection task<sup><xref rid="c19" ref-type="bibr">19</xref></sup> (<xref rid="fig3" ref-type="fig">Fig. 3B,</xref> blue), with the result that the two are significantly correlated (<italic>&#x03C1;</italic> = 0.728, <italic>p</italic>=1.04 &#x00D7;10<sup>-6</sup>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Rhythmic target po wer acts as a discriminant neural statistic for perceived rhythm.</title>
<p>(<bold>a</bold>) Top: In two representative subjects, behavior covaries with empirically-derived neural discriminability distributions. Probability distributions of a given level of sustained (time-integrated) evoked power depend on the acoustic presence (blue) or absence (red) of stimulus rhythmic FM; a neural discriminability score (proportional to horizontal black bar length) can be obtained from them. In the first subject (left panel), the small overlap between the distributions gives high neural discriminability; for the second subject (right panel), both distributions overlap substantially, giving poor discriminability. Bottom: Next, empirically-derived neural distributions were obtained <italic>only from non-rhythmic probes</italic> (i.e., the red curves in the top panels), now conditioned instead by percept. A similar pattern in the distributions is observed. Distributions obtained via bootstrap. (<bold>b</bold>) Over subjects, the psychometric <italic>d</italic>&#x2019; sensitivity index (abscissa) correlates with the neurometric discriminability index based on acoustic contrast (rhythmic versus non-rhythmic probe, blue;<italic>&#x03C1;</italic> = 0.73, <italic>p</italic> = 1.0&#x00D7;10<sup>-6</sup>). Critically, behavioral sensitivity to &#x2018;filling-in&#x2019; also correlates with rhythmic evoked power differences despite the absence of stimulus rhythm via the related neurometric discriminability index based on perceptual contrast (filling-in versus reported absent, magenta; <italic>&#x03C1;</italic> = 0.69, <italic>p</italic> = 6.1&#x00D7;10<sup>-6</sup>).</p></caption>
<graphic xlink:href="165332_fig3.tif"/>
</fig>
<p>A related latent discrimination statistic, directly relevant to the phenomenon of filling-in, is computed with contributions only from endogenous (non-sensory) factors, by analyzing the responses to non-rhythmic probes exclusively(<xref rid="fig3" ref-type="fig">Fig. 3A,</xref> bottom). In these purely percept-specific (constant acoustics) distributions, neural power discriminability was defined analogously as the difference in rhythmic evoked power between filling-in and rhythm-absent trials, integrated over the time at which significant differences were observed at the group level in the previous section (0.56 to 1.19 s post probe onset, as in <xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Just as for the acoustic contrasts, this discriminability index also correlates strongly with the psychometric sensitivity indices across listeners (<xref rid="fig3" ref-type="fig">Fig. 3B,</xref> magenta) (<italic>&#x03C1;</italic>=0.745, <italic>p</italic>=4.23&#x00D7;10<sup>-7</sup>). Thus, consistent with the properties of a latent discrimination statistic, sustained evoked power may account for both stimulus-and percept-specific differential processing, where the latter reflects only endogenous neural processes.</p>
</sec>
<sec id="s2d">
<title>Spectrum of power increase in target-related neural rhythm dynamics with filling-in</title>
<p>Given the possibility that increased power at the 5 Hz rhythmic frequency would be accompanied by increased spectral power at other frequencies, it is important to consider whether change arises as a power gain specific to the target frequency or as a modulatory effect over a larger spectral region that includes the target frequency band. By extending the wavelet analysis over a broader frequency range (1-25 Hz), the spectral extent of restoration was probed to address whether changes are target-specific, or instead accompanied by other activity that may be behaviorally relevant.</p>
<p>Evoked power analyses across probe conditions and subjects reveal that the evoked response contains two frequency ranges, one centered on the target 5 Hz, and the other centered on the 10 Hz first harmonic (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). To analyze time-frequency power contrast between conditions, corresponding spectrograms (baseline corrected per frequency band) were subtracted. In particular, the &#x2018;driven&#x2019; minus &#x2018;absent&#x2019; map results in a contrast whose differences arise from synchronization to physical differences in the sound, while &#x2018;filling-in&#x2019;minus&#x2018;absent&#x2019; maps differences due entirely to endogenous activity (<xref rid="fig4" ref-type="fig">Fig. 4B,</xref> left panels). For the first case, the defined &#x2018;synchronized&#x2019; contrast (<xref rid="fig4" ref-type="fig">Fig. 4B,</xref> top left) group average data shows a spectrotemporal region, &#x007E;600 ms post probe offset until the end of the probe, of significant differential neural processing (<italic>p</italic> = 3.3&#x00D7;10<sup>-4</sup>), rooted in physical stimuli differences. The region is limited to the spectral neighborhood of the target (half maximum 4.1-6.7 Hz; maximum 3.8-7.5 Hz), which may be expected as smearing from Fourier/Heisenberg uncertainty. For the &#x2018;endogenous&#x2019; contrast (<xref rid="fig4" ref-type="fig">Fig. 4B,</xref> bottom left), a similar profile was found (half maximum 4.1-6.6 Hz; maximum 3.8-6.8 Hz; <italic>p</italic> = 6.7&#x00D7;10<sup>-4</sup>), with additional enhancement around the target first harmonic (0.4 to 1.1 s post probe onset; half maximum 9.7-11 Hz; maximum 8.9 to 11.9 Hz; <italic>p</italic> = 0.01). In a related analysis of a third partition contrast, &#x2018;rhythm-driven&#x2019; minus &#x2018;missed&#x2019;, no spectrotemporal cluster of significance was found (<italic>p</italic>=0.29).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Stimulus-and percept-specific spectrotemporal modulations of cortical activity during restored rhythm.</title>
<p>(<bold>a</bold>) Wavelet power correlograms, in a 1-25 Hz frequency range, reveal qualitative differences in steady neural responses post probe onset, across participants (<italic>N</italic> = 32). Color arrows indicate spectrogram pairs submitted to difference contrasts as follows. (<bold>b</bold>) Differences between spectrograms reveal differential processing under alternative percepts, whether based on different physical sounds (top left), or on endogenous restorative processes (bottom left), in both cases specific to the target 5 Hz frequency band. The latter case of filling-in generates enhanced sustained power in the first harmonic band (&#x007E;10 Hz) as well. Synchronization maps are shown masked by regions of group-level significance, as determined by permutations within contrast pairs, performed independently across subjects (&#x2018;driven&#x2019;, <italic>p</italic> = 3.3&#x00D7;10<sup>-4</sup>;&#x2018;filling-in&#x2019;-near 5 Hz <italic>p</italic> = 6.7&#x00D7;10<sup>-4</sup>, filling-in&#x2019;near10 Hz <italic>p</italic> = 0.01). The lower-rate rhythmic enhancements (&#x007E;5 Hz) coincide spectrotemporally even though the sensory bases for each are different (right). White vertical lines indicate noise probe temporal edges.</p></caption>
<graphic xlink:href="165332_fig4.tif"/>
</fig>
<p>Upon examination of whether the additional spectral information conveyed by these maps improved neural predictions regarding listeners&#x2019; behavior, we found that neural discriminability indices based upon the &#x2018;synchronized&#x2019; region in this section showed no improvement over the target frequency specific index obtained previously for 5 Hz only measures (<italic>&#x03C1;</italic> = 0.53; <italic>p</italic> = 0.001). The &#x2018;endogenous&#x2019; regions, jointly, showed no improvement in predictive power of listener&#x2019;s performance (<italic>&#x03C1;</italic> = 0.72; <italic>p</italic> = 1.4&#x00D7;10<sup>-6</sup>) over that of the target-based index alone. Separating these regions into 5 Hz and 10 Hz domains revealed that the lower (target rhythm) region was more predictive (5 Hz only: <italic>&#x03C1;</italic> = 0.73, <italic>p</italic> = 8.2 &#x00D7; 10<sup>-7</sup>; 10 Hz only: <italic>&#x03C1;</italic> = 0.44, <italic>p</italic> = 0.01). These results suggest that differential narrowband 5 Hz power is most critical to explain listeners&#x2019; detection performance shown previously, and that for filling-in trials, some improvement also arises from integrating over the broadened filter to include neighbor target frequencies present in the average timeseries of endogenous neural activity.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The subjective experience of attending effectively to complex sound scenes in noisy environments can be substantially assisted by perceptual restoration. This effect is investigated using MEG to record the neural dynamics of a steady temporal pattern while repaired perceptually. Measures of differential cortical processing contributed to the identification of a discrimination statistic predicting a subject&#x2019;s behavioral performance sensitivity. The data are consistent with the view that perceptual restoration is attributable to endogenous neural processes, emerging from learnable temporal patterns present in the tracked auditory object, at modulation rates that dominate natural communication speech sounds.</p>
<p>Perceptual restoration, the effect of hearing the continuation of a sound regardless of an interrupting masker, includes descriptions of &#x201C;auditory induction&#x201D;, &#x201C;temporal induction&#x201D;, &#x201C;perceptual synthesis&#x201D;, or &#x201C;contextual catenation&#x201D; of dynamic sounds in classic studies<sup><xref rid="c20" ref-type="bibr">20</xref>,<xref rid="c21" ref-type="bibr">21</xref></sup>. It implies an ability to discount disruptive but extraneous interruptions to relevant acoustic signals, so much so that even noise-filled <italic>gaps</italic> are more likely to be discounted as such<sup><xref rid="c21" ref-type="bibr">21</xref></sup>.Where multiple interpretations of a relevant acoustic signal are possible (e.g. phonemes), perceptual restoration has been probed in identification tasks; for more constrained decision spaces, it may be probed based on sound delivery quality assessments, such as gap localization of the excised token signal (e.g. Warren&#x2019;s paradigm<sup><xref rid="c21" ref-type="bibr">21</xref></sup>), and by discrimination of noise-added vs. noise-replaced token gap alternatives (e.g. Samuel&#x2019;s paradigm<sup><xref rid="c22" ref-type="bibr">22</xref></sup>). Our method subscribes to the latter approach, also referred to as &#x2018;filling-in&#x2019;, which emphasizes the signal detection strategy followed in cases where a listener classification is inconsistent with the token absence in a gap<sup><xref rid="c3" ref-type="bibr">3</xref>,<xref rid="c23" ref-type="bibr">23</xref>&#x2013;<xref rid="c29" ref-type="bibr">29</xref></sup>. As has been noted<sup><xref rid="c30" ref-type="bibr">30</xref></sup>, from the listener&#x2019;s utilitarian perspective, this effect of induction in a challenging environment is not aimed at the production of decision errors (or illusions) but to assist against masking. Restoration refers to the perception of a token projected by a context (such as a speaker&#x2019;s intention), with apparent intactness<sup><xref rid="c30" ref-type="bibr">30</xref></sup>. Critical to this is a strong masker, along with contextual evidence favoring a specific acoustic token with high probability. This combination allows inference that the lack of auditory evidence of the token could be ascribed to energetic masking<sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c4" ref-type="bibr">4</xref>,<xref rid="c31" ref-type="bibr">31</xref></sup>.</p>
<p>A simple and compelling example of perceptual restoration is that of a pure tone followed by a brief noise-filled gap where the tone has been excised: this leads to a strong illusory percept of continuity of the tone<sup><xref rid="c32" ref-type="bibr">32</xref></sup>. The percept appears to rely on two related effects, the more obvious being conveying the original signal as uninterrupted, but also, critically, accompanied by an attenuation of discontinuity boundaries<sup><xref rid="c33" ref-type="bibr">33</xref></sup>. Neural correlates of both effects have been observed in single units in macaque primary auditory cortex (A1), where up to 35&#x0025; of sampled single units respond to a gap with noise as though the tone were continuously present<sup><xref rid="c34" ref-type="bibr">34</xref>,<xref rid="c35" ref-type="bibr">35</xref></sup>. In some cases there is also failure of a transient response at the end of the gap<sup><xref rid="c34" ref-type="bibr">34</xref></sup>.For human listeners, there is evidence that such compensatory principles may extend to disruptions to dynamically modulated sound, including amplitude-modulated (AM) sound, single vowels, and consonants within words<sup><xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c9" ref-type="bibr">9</xref>,<xref rid="c24" ref-type="bibr">24</xref>,<xref rid="c28" ref-type="bibr">28</xref>,<xref rid="c36" ref-type="bibr">36</xref>,<xref rid="c37" ref-type="bibr">37</xref></sup>, the latter of which fall under the concept of phonemic restoration<sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c3" ref-type="bibr">3</xref>,<xref rid="c22" ref-type="bibr">22</xref></sup>. Depending on stimulus, neural correlates have been localized to different areas, including Heschl&#x2019;s gyrus for missing AM noise<sup><xref rid="c36" ref-type="bibr">36</xref></sup>, the posterior aspect of superior temporal gyrus for disrupted vowels<sub>28</sub>, and wider brain networks including the superior temporal lobe in the case of missed phonemes<sup><xref rid="c24" ref-type="bibr">24</xref>,<xref rid="c37" ref-type="bibr">37</xref></sup>. In addition, mixed evidence points to a basis for restoration in terms of endogenous modulations to boundary encoding: on the one hand, the search for differential onset responses to noise when under restoration, indexing alternative encoding, has yielded negative results so far<sup><xref rid="c27" ref-type="bibr">27</xref>,<xref rid="c28" ref-type="bibr">28</xref></sup>; on the other, induced narrow-band (3-4 Hz) desynchronizations that are restoration-specific, and occur after gap onset, have been suggested by results from EEG<sup><xref rid="c28" ref-type="bibr">28</xref>,<xref rid="c38" ref-type="bibr">38</xref></sup>.</p>
<p>In this study the differential temporal boundary encoding under restoration was not specifically addressed<sup><xref rid="c38" ref-type="bibr">38</xref></sup>, but instead the emphasis was on the neural representation of the missing rhythm itself, via measures of evoked rhythmic MEG responses. While restoration of continuous tones has been observed for segments as long as 1.4 s<sup><xref rid="c39" ref-type="bibr">39</xref></sup> behaviorally, to our knowledge this is the first investigation where cortical aSSRs are directly implicated in perceptual restoration, sustained in real time representing a temporal code. That neural phase information was not reliable, despite an apparent continuity of the rhythm, is consistent with behavioral analyses suggesting that listeners may not track phase information under illusory FM continuity<sup><xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c9" ref-type="bibr">9</xref></sup>. An cortical EEG study by Vinnik and colleagues<sup><xref rid="c27" ref-type="bibr">27</xref></sup> showed no change to neural spectral power sustained along noise gaps embedded in a 40 Hz AM context stimulus during restoration; on the other hand, it has been shown that changes to neural spectral power in brainstem responses may occur during restored pitch of a missing 800 Hz carrier tone<sup><xref rid="c29" ref-type="bibr">29</xref></sup>. It is possible that while gamma-rate acoustic modulations can be represented cortically with a temporal code<sup><xref rid="c13" ref-type="bibr">13</xref>,<xref rid="c40" ref-type="bibr">40</xref></sup>, they are also at rates that involve pitch quality &#x2013; a representation of which implies substantially distinct cortical coding modes<sup><xref rid="c41" ref-type="bibr">41</xref></sup> assisting restoration.</p>
<p>In other sensory modalities, some restorative phenomena may fall in the category of perceptual experience that does not represent the absence of a physical stimulus, but rather, an alternative interpretation based on additional contextual information, e.g., the case of illusory induction of perceived kinesthetic trajectories<sup><xref rid="c42" ref-type="bibr">42</xref>,<xref rid="c43" ref-type="bibr">43</xref></sup>, and of spatial contours in certain visual displays<sup><xref rid="c44" ref-type="bibr">44</xref>&#x2013;<xref rid="c46" ref-type="bibr">46</xref></sup>. Context-sensitivity in general is considered a requisite for cortical predictive coding<sup><xref rid="c47" ref-type="bibr">47</xref></sup>, which in the case of hearing may depend on known priors regarding the sound temporal dynamics. A compelling example arises from missing, but highly expected, click-like sounds that generate auditory onset-like responses locked to the nominal time of delivery of the missed sound<sup><xref rid="c48" ref-type="bibr">48</xref></sup>. Additionally, long duration, rhythmic metric structures may produce endogenous neural locking to a subharmonic frequency of the actual acoustic beat when it has the potential to be perceived as the underlying rhythm, whether listeners are instructed to do so<sup><xref rid="c49" ref-type="bibr">49</xref></sup>, or passively listen in the absence of instruction<sup><xref rid="c50" ref-type="bibr">50</xref></sup>. Correspondingly, the data here show that with perceptual restoration of masked rhythm, endogenous representational differences may emerge as early as 0.6 s post masking, at the target rhythm. There is also activity at the first harmonic, 10 Hz, but there one cannot entirely rule out yet alternative explanations involving enhanced alpha activity<sup><xref rid="c27" ref-type="bibr">27</xref></sup>, since with increased alertness at some trials over others, a systematic differential in spontaneous alpha activity might be responsible<sup><xref rid="c51" ref-type="bibr">51</xref></sup>. For filling-in and rhythm-missed trials related to inattention, reduced vigilance might be expected to effectively increase alpha activity. We did not, however find this; instead, filling-in trials displayed a narrow-band 10 Hz power increase strongly concurrent with the target duration, therefore consistent with being a harmonic of the endogenous 5 Hz rhythm. Alpha-band related effects due to non-uniform attentional states should be investigated in future studies using rhythms whose first harmonics are not in the alpha band. Our data does not reject the possibility of spontaneous and temporally patterned cortical activity profiles influencing sensory processing, as in ongoing slow-wave activity that may interact with evoked signals as a temporally coordinated modulation of excitability across distributed cortical fields<sup><xref rid="c52" ref-type="bibr">52</xref>,<xref rid="c53" ref-type="bibr">53</xref></sup>.</p>
<p>Focus on analysis of endogenous activity may address circumstances under which the brain repairs certain temporal features of highly stereotyped sound. This is part of the general problem of determining what relationship does a neurally-instantiated representation of a missed pattern has with a template representation mapping to actual acoustic experience. Solutions may offer key insight into biologically-inspired applications dealing with incomplete information. In particular, the modulation studied here corresponds to the temporal scale of syllabic production in human speech<sup><xref rid="c54" ref-type="bibr">54</xref></sup> and the slow temporal envelope of natural stimuli<sup><xref rid="c55" ref-type="bibr">55</xref></sup>, thus raising the question of whether similar restorative phenomena exist during sequences of inner or imagined speech, as well as during auditory hallucinations.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>35 subjects (12 women, 25.7 &#x00B1; 4.4 years of age) with no history of neurological disorder or metal implants participated in the study, and received monetary compensation proportional to the study duration (&#x007E; 2 hours). Experiment protocol was approved by the UMCP Institutional Review Board; informed written consent was obtained from each participant.</p>
</sec>
<sec id="s4b">
<title>Stimuli</title>
<p>Four template sound stimuli were constructed with MATLAB<sup>&#x00AE;</sup> (MathWorks, Natick, United States), each consisting of &#x007E;15 minutes of a 1024 Hz tone frequency-modulated (FM) at 5 Hz with modulation range (log-sinusoidal) 512&#x2013;2048 Hz and a 20&#x0025; duty cycle<sup><xref rid="c16" ref-type="bibr">16</xref></sup>. 420 rhythmic probes were created by adding 1.24 s of noise to the basic stimulus, at pseudo-random times. Noise was generated de novo per probe, and spectrally matched to the FM but with random phase. A fixed signal-to-noise ratio value was chosen from the -4 to 4 dB range, per participant. 420 non-rhythmic type trials were additionally created in the same manner, except that the underlying FM was replaced with constant carrier frequency. Inter-probe time intervals were 1.6 s plus a discrete Poisson-distributed random delay (l = 1.2 s); the exact onset time was rounded to a multiple of the stimulus period (0.2 s), so that all probe onset times kept constant phase with the main rhythm. Sound stimuli were delivered through Presentation<sup>&#x00AE;</sup> (NeuroBehavioral Systems, Berkeley, United States), equalized to be approximately flat from 40&#x2013;3000 Hz, at a sound pressure level &#x007E; 70 dB. Sounds were transmitted via E-A-RTONE&#x00AE; 3A tubes (impedance 50 &#x03A9;) and E-A-RLINK&#x00AE; disposable foam intra-auricular ends (Etymotic Research, Elk Grove Village, United States) inserted in the ear canals.</p>
</sec>
<sec id="s4c">
<title>Experimental design</title>
<p>After a brief practice session, subjects were instructed to push one of a pair of buttons based on whether they detected a 5 Hz rhythm. In order of importance, participants were instructed to: (i) wait until probe ended before pressing the button, weighting accuracy over reaction time; (ii) respond only to the probe immediately presented;(iii) modify their choice by pressing the other button only if certain and still before the next trial. Trials that did not meet the requirements, and corrected trials, were excluded (median 6.8&#x0025; and 1.3&#x0025; of trials respectively). To avoid transient cortical dynamics associated with motor response execution<sup><xref rid="c56" ref-type="bibr">56</xref></sup>, trials beginning less than 250 ms from the previous response were also excluded (median 6.3&#x0025; of trials). To more evenly distribute the proportion of correct answers across participants, the masker signal-to-noise ratio (SNR) was fixed in advance, from on of 0, &#x00B1;1, &#x00B1;2 or &#x00B1;4 dB. Silent films were presented concurrently, which subjects were instructed to watch.</p>
</sec>
<sec id="s4d">
<title>Data recording</title>
<p>MEG data were collected with a 160-channel system (Kanazawa Technology Institute, Kanazawa, Japan) inside a magnetically-shielded room (Yokogawa Electric Corporation, Musashino, Japan). Sensors (15.5 mm diameter) were uniformly distributed inside a liquid-He Dewar, spaced &#x007E;25 mm apart. Sensors were configured as first-order axial gradiometers with 50 mm separation and sensitivity &#x003E; 5 fT&#x00B7;Hz-1/2 in the white noise region (&#x003E; 1 KHz). Three of the 160 sensors were magnetometers employed as environment reference channels. A 1 Hz high-pass filter, 200 Hz low-pass filter, and 60 Hz notch filter were applied before sampling at 1 KHz. Participants lay supine inside the magnetically shielded room under soft lighting, and were asked to minimize movement, particularly of the head. Every session had four experimental blocks. In the case of seven participants, the experiment had to be suspended early due to time constraints (mean 89&#x0025; completion in these participants, minimum 75&#x0025;); for one participant only 2 blocks out of 4 were recorded due to transfer failure. Two participants requested pauses during a block, which was terminated and later repeated in whole.</p>
</sec>
<sec id="s4e">
<title>Data processing</title>
<p>A 1-30 Hz band-pass third order elliptic filter with at most 1 dB ripple and 20 dB stopband attenuation was applied and noise sources were removed as follows. <italic>Environment noise</italic>. Time-shifted principal component analysis<sup><xref rid="c57" ref-type="bibr">57</xref></sup> (TS-PCA) was applied to remove environmental noise, using the three reference magnetometers (<italic>Nlags</italic> = 43). <italic>Sensor-specific noise</italic>. Sensor-generated sources unrelated to brain activity were subtracted using sensor noise suppression (SNS)<sup><xref rid="c58" ref-type="bibr">58</xref></sup>. <italic>Spatial filtering</italic>. A per-participant data-driven model was used to synthesize spatial filters from the responses to the unmasked rhythmic sound stimulus via denoising spatial separation (DSS)<sup><xref rid="c59" ref-type="bibr">59</xref></sup>. The responses were structured as a matrix of dimensions <italic>T</italic> x <italic>N</italic> x <italic>K</italic>; where <italic>T</italic> is the number of samples (=1400), <italic>N</italic> is the number of usable recording segments (average=514.3), and <italic>K</italic> the number of active sensors (average=156.8).This spatial filter selects for the most reproducible aSSR component over trials, generating a single virtual sensor used in the remaining analysis.</p>
</sec>
<sec id="s4f">
<title>Data analysis</title>
<p>Trials were classified a posteriori, according to subjects&#x2019; reports, into one of four groups: rhythmic-trial perceived such (&#x2018;driven&#x2019;) or as not as non-rhythmic (&#x2018;missed&#x2019;);non-rhythmic trial perceived as such (&#x2018;absent&#x2019;), or as rhythmic (&#x2018;filling-in&#x2019;). Time-frequency analysis used a Morlet wavelet transform with 0.2 s scale, permitting estimation of spectral evoked power at the bandwidth of experimental interest (5 Hz). For evoked power and ITPC contrasts, statistical clusters were found during which there were significant differences across experiment conditions according to non-parametric permutation tests<sup><xref rid="c60" ref-type="bibr">60</xref></sup>. A measure of neural discriminability&#x2019;, <inline-formula><alternatives><inline-graphic xlink:href="165332_inline1.gif"/></alternatives></inline-formula>is defined as the area between two evoked power curves <italic>P</italic> obtained each at conditions <italic>A</italic> and <italic>B</italic> for the <italic>i</italic>-th subject, and computed over a fixed time interval (<italic>T</italic><sub><italic>0</italic></sub> = 0.58 s and <italic>T</italic><sub><italic>1</italic></sub> =1.2 s post noise onset on average), as defined by statistical clusters of significance found at the group level for the given contrast <italic>AB</italic>. Measures for shifts in ITPC were computed in similar way. Perceptual sensitivity of a subject in detection is given by <italic>d</italic>-prime analysis<sup><xref rid="c19" ref-type="bibr">19</xref></sup>, <inline-formula><alternatives><inline-graphic xlink:href="165332_inline2.gif"/></alternatives></inline-formula> where for each subject <italic>i, H</italic> the fraction of rhythmic probes labeled rhythmic, and <italic>Fi</italic> the fraction of non-rhythmic probes labeled rhythmic, undergo a z-transformation.<sup><xref rid="c61" ref-type="bibr">61</xref></sup></p>
<p>To investigate whether the observed pattern of percept-specific differences was due to unintended acoustical or statistical properties in the stimulus constructs, stimulus probes were analyzed a posteriori. No significant differences were found in stimulus temporal modulations when partitioned by percept, within rhythmic (<italic>p</italic>=0.85) nor non-rhythmic (<italic>p</italic>=0.84) probes (paired-sample <italic>t</italic>-tests, Supplementary Fig. S3).</p>
<p>Subjects&#x2019; reported percepts corresponded to the physical acoustics (presence or absence of rhythm) approximately 5 times as often as not, resulting in data pools with differing signal-to-noise ratio improvement from averaging. Therefore inter-trial phase coherence measures included bias correction<sup><xref rid="c62" ref-type="bibr">62</xref></sup> as small sample sizes are especially prone to bias. The unbiased estimator is based on the squared ITPC (also defined as squared &#x2018;modified resultant length&#x2019;<sup><xref rid="c62" ref-type="bibr">62</xref></sup>), which may be negative after estimated bias subtraction. To investigate the possibility of related biases in the rhythmic evoked power measures, post hoc two-sided non-parametric permutation tests were performed by collecting, for each subject, all trials from the two conditions to be compared, and instantiating resampled of partitions of fixed size (original sample sizes per subject); the group-level test statistic obtained in the actual partition was then contrasted against those obtained at group level across the distribution of resampled instances. Using the 5 Hz evoked power difference between conditions in the same intervals of significance, it was found that responses to non-rhythmic probes show significantly greater power when reported perceived as rhythmic versus non-rhythmic (0.56 to 1.19 s; <italic>p</italic>=0.007); a similar result held for responses to rhythmic probes, which also show significantly greater power when reported perceived as rhythmic versus non-rhythmic (1.04 to 1.15 s; <italic>p</italic>=0.034). Potential systematic differences resulting from the per-subject signal-to-noise (SNR) ratio were also investigated, but no evidence was found of differences, neurally (<italic>&#x03C1;</italic>=0.10, <italic>p</italic>=0.57) or behaviorally (<italic>&#x03C1;=</italic>0.33, <italic>p</italic>=0.054). One participant was excluded from the analysis due to zero reported perceptual differences from the acoustics.</p>
</sec>
<sec id="s4g" sec-type="availability">
<title>Data availability</title>
<p>All relevant data are available to all interested parties in a public repository.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Warren</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Obusek</surname>, <given-names>C. J.</given-names></string-name> &#x0026; <string-name><surname>Ackroff</surname>, <given-names>J. M.</given-names></string-name> <article-title>Auditory Induction: Perceptual Synthesis of Absent Sounds</article-title>. <source>Science 176</source>, <fpage>1149</fpage>&#x2013;<lpage>1151</lpage> (<year>1972</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Bregman</surname>, <given-names>A. S.</given-names></string-name> <source>Auditory scene analysis: the perceptual organization of sound. (MIT Press</source>, <year>2006</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Samuel</surname>, <given-names>A</given-names></string-name>. <article-title>Phoneme Restoration</article-title>. <source>Lang. Cogn. Process</source>. <volume>11</volume>, <fpage>647</fpage>&#x2013;<lpage>654</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Bashford</surname>, <given-names>J. A.</given-names></string-name> &#x0026; <string-name><surname>Warren</surname>, <given-names>R. M.</given-names></string-name> <article-title>Multiple phonemic restorations follow the rules for auditory induction</article-title>. <source>Percept. Psychophys</source>. <volume>42</volume>, <fpage>114</fpage>&#x2013;<lpage>121</lpage> (<year>1987</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name> <article-title>A theory of cortical responses</article-title>. <source>Philos. Trans. R. Soc. B Biol. Sci</source>. <volume>360</volume>, <fpage>815</fpage>&#x2013;<lpage>836</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Clark</surname>, <given-names>A</given-names></string-name>. <article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title>. <source>Behav. Brain Sci</source>. <volume>36</volume>, <fpage>181</fpage>&#x2013;<lpage>204</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Rao</surname>, <given-names>R. P.</given-names></string-name> &#x0026; <string-name><surname>Ballard</surname>, <given-names>D. H.</given-names></string-name> <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nat. Neurosci</source>. <volume>2</volume>, <fpage>79</fpage>&#x2013;<lpage>87</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Lyzenga</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Carlyon</surname>, <given-names>R. P.</given-names></string-name> &#x0026; <string-name><surname>Moore</surname>, <given-names>B. C. J.</given-names></string-name> <article-title>Dynamic aspects of the continuity illusion: Perception of level and of the depth, rate, and phase of modulation</article-title>. <source>Hear. Res</source>. <volume>210</volume>, <fpage>30</fpage>&#x2013;<lpage>41</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Carlyon</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Micheyl</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Deeks</surname>, <given-names>J. M.</given-names></string-name> &#x0026; <string-name><surname>Moore</surname>, <given-names>B. C. J</given-names></string-name>. <article-title>Auditory processing of real and illusory changes in frequency modulation (FM) phase</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>116</volume>, <fpage>3629</fpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Ross</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Borgmann</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Draganova</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>L. E.</given-names></string-name> &#x0026; <string-name><surname>Pantev</surname>, <given-names>C</given-names></string-name>. <article-title>A high-precision magnetoencephalographic study of human auditory steady-state responses to amplitude-modulated tones</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>108</volume>, <fpage>679</fpage>&#x2013;<lpage>691</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Schoonhoven</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Boden</surname>, <given-names>C. J. R.</given-names></string-name>, <string-name><surname>Verbunt</surname>, <given-names>J. P. A.</given-names></string-name> &#x0026; <string-name><surname>de Munck</surname>, <given-names>J. C.</given-names></string-name> <article-title>A whole head MEG study of the amplitude-modulation-following response: phase coherence, group delay and dipole source analysis</article-title>. <source>Clin. Neurophysiol. Off. J. Int. Fed. Clin. Neurophysiol</source>. <volume>114</volume>, <fpage>2096</fpage>&#x2013;<lpage>2106</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Draganova</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ross</surname>, <given-names>Wollbrink</given-names></string-name>,&#x0026;Pantev,C. <article-title>Cortical Steady-State Responses to Central and PeripheraAuditory Beats</article-title>. <source>Cereb. Cortex</source> <volume>18</volume>, <fpage>1193</fpage>&#x2013;<lpage>1200</lpage>(<year>2008</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>Sensitivity to temporal modulation rate and spectral bandwidth in the human auditory system: MEG evidence</article-title>. <source>J. Neurophysiol</source>. <volume>107</volume>, <fpage>2033</fpage>&#x2013;<lpage>2041</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Luo</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Poeppel</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Simon</surname>, <given-names>J. Z.</given-names></string-name> <article-title>Concurrent encoding of frequency and amplitude modulation in human auditory cortex: MEG evidence</article-title>. <source>J. Neurophysiol</source>. <volume>96</volume>, <fpage>2712</fpage>&#x2013;<lpage>2723</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Giraud</surname>, <given-names>A. L.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>Representation of the temporal envelope of sounds in the human brain</article-title>. <source>J. Neurophysiol</source>. <volume>84</volume>, <fpage>1588</fpage>&#x2013;<lpage>1598</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Millman</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>Prendergast</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Kitterick</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Woods</surname>, <given-names>W. P.</given-names></string-name> &#x0026; <string-name><surname>Green</surname>, <given-names>G. G. R.</given-names></string-name> <article-title>Spatiotemporal reconstruction of the auditory steady-state response to frequency modulation using magnetoencephalography</article-title>. <source>NeuroImage</source> <volume>49</volume>, <fpage>745</fpage>&#x2013;<lpage>758</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Jacewicz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>R. A.</given-names></string-name>, <string-name><given-names>O&#x0026;C.</given-names>, <surname>Neill</surname></string-name> &#x0026; <string-name><surname>Salmons</surname>, <given-names>J.</given-names></string-name> <article-title>Articulation rate across dialect, age, and gender</article-title>. <source>Lang. Var. Change</source> <volume>21</volume>, <fpage>233</fpage>&#x2013;<lpage>256</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Ding</surname>, <given-names>N.</given-names></string-name> &#x0026; <string-name><surname>Simon</surname>, <given-names>J. Z.</given-names></string-name> <article-title>Neural coding of continuous speech in auditory cortex during monaural and dichotic listening</article-title>. <source>J. Neurophysiol</source>. <volume>107</volume>, <fpage>78</fpage>&#x2013;<lpage>89</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Green</surname>, <given-names>D. M.</given-names></string-name> &#x0026; <string-name><surname>Swets</surname>, <given-names>J. A.</given-names></string-name> <source>Signal detection theory and psychophysics. (Peninsula Publ</source>, <year>2000</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Warren</surname>, <given-names>R. M.</given-names></string-name> <article-title>Perceptual restoration of obliterated sounds</article-title>. <source>Psychol. Bull</source>. <volume>96</volume>, <fpage>371</fpage>&#x2013;<lpage>383</lpage> (<year>1984</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Warren</surname>, <given-names>R. M.</given-names></string-name> <article-title>Perceptual Restoration of Missing Speech Sounds</article-title>. <source>Science</source> <volume>167</volume>, <fpage>392</fpage>&#x2013;<lpage>393</lpage> (<year>1970</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Samuel</surname>, <given-names>A. G.</given-names></string-name> <article-title>Phonemic restoration: Insights from a new methodology</article-title>. <source>J. Exp. Psychol.Gen</source>. <volume>110</volume>, <fpage>474</fpage>&#x2013;<lpage>494</lpage> (<year>1981</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Kluender</surname>, <given-names>K. R.</given-names></string-name> &#x0026; <string-name><surname>Jenison</surname>, <given-names>R. L.</given-names></string-name> <article-title>Effects of glide slope, noise intensity, and noise duration on the extrapolation of FM glides through noise</article-title>. <source>Percept. Psychophys</source>. <volume>51</volume>, <fpage>231</fpage>&#x2013;<lpage>238</lpage> (<year>1992</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Shahin</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Bishop</surname>, <given-names>C. W.</given-names></string-name> &#x0026; <string-name><surname>Miller</surname>, <given-names>L. M.</given-names></string-name> <article-title>Neural mechanisms for illusory filling-in of degraded speech</article-title>. <source>NeuroImage</source> <volume>44</volume>, <fpage>1133</fpage>&#x2013;<lpage>1143</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Shahin</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Kerlin</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Bhat</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Miller</surname>, <given-names>L. M.</given-names></string-name> <article-title>Neural restoration of degraded audiovisual speech</article-title>. <source>NeuroImage</source> <volume>60</volume>, <fpage>530</fpage>&#x2013;<lpage>538</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Riecke</surname>, <given-names>L.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>Recalibration of the auditory continuity illusion: sensory and decisional effects</article-title>. <source>Hear. Res</source>. <volume>277</volume>, <fpage>152</fpage>&#x2013;<lpage>162</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Vinnik</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Itskov</surname>, <given-names>P. M.</given-names></string-name> &#x0026; <string-name><surname>Balaban</surname>, <given-names>E.</given-names></string-name> <article-title>&#x03B2;-And &#x03B3;-band EEG power predicts illusory auditory continuity perception</article-title>. <source>J. Neurophysiol</source>. <volume>108</volume>, <fpage>2717</fpage>&#x2013;<lpage>2724</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Riecke</surname>, <given-names>L.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>Hearing an Illusory Vowel in Noise: Suppression of Auditory Cortical Activity</article-title>. <source>J. Neurosci</source>. <volume>32</volume>, <fpage>8024</fpage>&#x2013;<lpage>8034</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Bidelman</surname>, <given-names>G. M.</given-names></string-name> &#x0026; <string-name><surname>Patro</surname>, <given-names>C.</given-names></string-name> <article-title>Auditory perceptual restoration and illusory continuity correlates in the human brainstem</article-title>. <source>Brain Res</source>. <volume>1646</volume>, <fpage>84</fpage>&#x2013;<lpage>90</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Repp</surname>, <given-names>B. H.</given-names></string-name> <article-title>Perceptual restoration of a &#x2018;missing&#x2019; speech sound: auditory induction or illusion?</article-title> <source>Percept. Psychophys</source>. <volume>51</volume>, <fpage>14</fpage>&#x2013;<lpage>32</lpage> (<year>1992</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Verschuure</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Brocaar</surname>, <given-names>M. P.</given-names></string-name> <article-title>Intelligibility of interrupted meaningful and nonsense speech with and without intervening noise</article-title>. <source>Percept. Psychophys</source>. <volume>33</volume>, <fpage>232</fpage>&#x2013;<lpage>240</lpage> (<year>1983</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Elfner</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Homick</surname>, <given-names>J. L.</given-names></string-name> <article-title>Some Factors Affecting the Perception of Continuity in Alternately Sounded Tone and Noise Signals</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>40</volume>, <fpage>27</fpage>&#x2013;<lpage>31</lpage> (<year>1966</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Petkov</surname>, <given-names>C. I.</given-names></string-name> &#x0026; <string-name><surname>Sutter</surname>, <given-names>M. L.</given-names></string-name> <article-title>Evolutionary conservation and neuronal mechanisms of auditory perceptual restoration</article-title>. <source>Hear. Res</source>. <volume>271</volume>, <fpage>54</fpage>&#x2013;<lpage>65</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Petkov</surname>, <given-names>C. I.</given-names></string-name>, <string-name><surname>O&#x2019;Connor</surname>, <given-names>K. N.</given-names></string-name> &#x0026; <string-name><surname>Sutter</surname>, <given-names>M. L.</given-names></string-name> <article-title>Encoding of Illusory Continuity in Primary Auditory Cortex</article-title>. <source>Neuron</source> <volume>54</volume>, <fpage>153</fpage>&#x2013;<lpage>165</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Petkov</surname>, <given-names>C. I.</given-names></string-name>, <string-name><surname>O&#x2019;Connor</surname>, <given-names>K. N.</given-names></string-name> &#x0026; <string-name><surname>Sutter</surname>, <given-names>M. L.</given-names></string-name> <article-title>Illusory Sound Perception in Macaque Monkeys</article-title>. <source>J. Neurosci</source>. <volume>23</volume>, <fpage>9155</fpage>&#x2013;<lpage>9161</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Riecke</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>van Opstal</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Goebel</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Formisano</surname>, <given-names>E.</given-names></string-name> <article-title>Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex</article-title>. <source>J. Neurosci</source>. <volume>27</volume>, <fpage>12684</fpage>&#x2013;<lpage>12689</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Leonard</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Baud</surname>, <given-names>M. O.</given-names></string-name>, <string-name><surname>Sjerps</surname>, <given-names>M. J.</given-names></string-name> &#x0026; <string-name><surname>Chang</surname>, <given-names>E. F.</given-names></string-name> <article-title>Perceptual restoration of masked speech in human cortex</article-title>. <source>Nat. Commun</source>. <volume>7</volume>, (<year>2016</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Riecke</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Esposito</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Bonte</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Formisano</surname>, <given-names>E.</given-names></string-name> <article-title>Hearing Illusory Sounds in Noise: The Timing of Sensory-Perceptual Transformations in Auditory Cortex</article-title>. <source>Neuron</source> <volume>64</volume>, <fpage>550</fpage>&#x2013;<lpage>561</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Riecke</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Opstal</surname>, <given-names>A. J.</given-names></string-name> <string-name><surname>van &#x0026; Formisano</surname>, <given-names>E.</given-names></string-name> <article-title>The auditory continuity illusion: A parametric investigation and filter model</article-title>. <source>Percept. Psychophys</source>. <volume>70</volume>, <fpage>1</fpage>&#x2013;<lpage>12</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Ro&#x00DF;</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Picton</surname>, <given-names>T. W.</given-names></string-name> &#x0026; <string-name><surname>Pantev</surname>, <given-names>C.</given-names></string-name> <article-title>Temporal integration in the human auditory cortex as represented by the development of the steady-state magnetic field</article-title>. <source>Hear. Res</source>. <volume>165</volume>, <fpage>68</fpage>&#x2013;<lpage>84</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Nourski</surname>, <given-names>K. V.</given-names></string-name> &#x0026; <string-name><surname>Brugge</surname>, <given-names>J. F.</given-names></string-name> <article-title>Representation of temporal sound features in the human auditory cortex</article-title>. <source>Rev. Neurosci</source>. <volume>22</volume>, <fpage>187</fpage>&#x2013;<lpage>203</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Thyrion</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Roll</surname>, <given-names>J.-P.</given-names></string-name> <article-title>Perceptual Integration of Illusory and Imagined Kinesthetic Images</article-title>. <source>J. Neurosci</source>. <volume>29</volume>, <fpage>8483</fpage>&#x2013;<lpage>8492</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Casini</surname>, <given-names>L.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>Cortical correlates of illusory hand movement perception in humans: A MEG study</article-title>. <source>Brain Res</source>. <volume>1121</volume>, <fpage>200</fpage>&#x2013;<lpage>206</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>T. S.</given-names></string-name> &#x0026; <string-name><surname>Nguyen</surname>, <given-names>M.</given-names></string-name> <article-title>Dynamics of subjective contour formation in the early visual cortex</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>98</volume>, <fpage>1907</fpage>&#x2013;<lpage>1911</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Murray</surname>, <given-names>M. M.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>The spatiotemporal dynamics of illusory contour processing: combined high-density electrical mapping, source analysis, and functional magnetic resonance imaging</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>22</volume>, <fpage>5055</fpage>&#x2013;<lpage>5073</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Montaser-Kouhsari</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Landy</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> &#x0026; <string-name><surname>Larsson</surname>, <given-names>J.</given-names></string-name> <article-title>Orientation-selective adaptation to illusory contours in human visual cortex</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>27</volume>, <fpage>2186</fpage>&#x2013;<lpage>2195</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name> <article-title>Learning and inference in the brain</article-title>. <source>Neural Netw</source>. <volume>16</volume>, <fpage>1325</fpage>&#x2013;<lpage>1352</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>SanMiguel</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Widmann</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bendixen</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Trujillo-Barreto</surname>, <given-names>N.</given-names></string-name> &#x0026; <string-name><surname>Schr&#x00F6;ger</surname>, <given-names>E.</given-names></string-name> <article-title>Hearing Silences: Human Auditory Processing Relies on Preactivation of Sound-Specific Brain Activity Patterns</article-title>. <source>J. Neurosci</source>. <volume>33</volume>, <fpage>8633</fpage>&#x2013;<lpage>8639</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Nozaradan</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Peretz</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Missal</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Mouraux</surname>, <given-names>A.</given-names></string-name> <article-title>Tagging the Neuronal Entrainment to Beat and Meter</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>10234</fpage>&#x2013;<lpage>10240</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Tal</surname>, <given-names>I.</given-names></string-name> <string-name><surname>et</surname> <given-names>al.</given-names></string-name> <article-title>Neural Entrainment to the Beat: The &#x2018;Missing-Pulse&#x2019; Phenomenon</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>37</volume>, <fpage>6331</fpage>&#x2013;<lpage>6341</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Oken</surname>, <given-names>B. S.</given-names></string-name>, <string-name><surname>Salinsky</surname>, <given-names>M. C.</given-names></string-name> &#x0026; <string-name><surname>Elsas</surname>, <given-names>S. M.</given-names></string-name> <article-title>Vigilance, alertness, or sustained attention: physiological basis and measurement</article-title>. <source>Clin. Neurophysiol. Off. J. Int. Fed. Clin. Neurophysiol</source>. <volume>117</volume>, <fpage>1885</fpage>&#x2013;<lpage>1901</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Farley</surname>, <given-names>B. J.</given-names></string-name> &#x0026; <string-name><surname>Nore&#x00F1;a</surname>, <given-names>A. J.</given-names></string-name> <article-title>Spatiotemporal Coordination of Slow-Wave Ongoing Activity across Auditory Cortical Areas</article-title>. <source>J. Neurosci</source>. <volume>33</volume>, <fpage>3299</fpage>&#x2013;<lpage>3310</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Ng</surname>, <given-names>B. S. W.</given-names></string-name>, <string-name><surname>Schroeder</surname>, <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Kayser</surname>, <given-names>C.</given-names></string-name> <article-title>A precluding but not ensuring role of entrained low-frequency oscillations for auditory perception</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>32</volume>, <fpage>12268</fpage>&#x2013;<lpage>12276</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Luo</surname>, <given-names>H.</given-names></string-name> &#x0026; <string-name><surname>Poeppel</surname>, <given-names>D.</given-names></string-name> <article-title>Phase Patterns of Neuronal Responses Reliably Discriminate Speech in Human Auditory Cortex</article-title>. <source>Neuron</source> <volume>54</volume>, <fpage>1001</fpage>&#x2013;<lpage>1010</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Chandrasekaran</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Turesson</surname>, <given-names>H. K.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>C. H.</given-names></string-name> &#x0026; <string-name><surname>Ghazanfar</surname>, <given-names>A. A.</given-names></string-name> <article-title>The Influence of Natural Scene Dynamics on Auditory Cortical Activity</article-title>. <source>J. Neurosci</source>. <volume>30</volume>, <fpage>13919</fpage>&#x2013;<lpage>13931</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Yamanaka</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Yamamoto</surname>, <given-names>Y.</given-names></string-name> <article-title>Lateralised EEG power and phase dynamics related to motor response execution</article-title>. <source>Clin. Neurophysiol</source>. <volume>121</volume>, <fpage>1711</fpage>&#x2013;<lpage>1718</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>de Cheveign&#x00E9;</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Simon</surname>, <given-names>J. Z.</given-names></string-name> <article-title>Denoising based on time-shift PCA</article-title>. <source>J. Neurosci.Methods</source> <volume>165</volume>, <fpage>297</fpage>&#x2013;<lpage>305</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>de Cheveign&#x00E9;</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Simon</surname>, <given-names>J. Z.</given-names></string-name> <article-title>Sensor noise suppression</article-title>. <source>J. Neurosci. Methods</source> <volume>168, 195&#x2013;202</volume> (<year>2008</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>de Cheveign&#x00E9;</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Simon</surname>, <given-names>J. Z.</given-names></string-name> <article-title>Denoising based on spatial filtering</article-title>. <source>J. Neurosci. Methods</source> <volume>171</volume>, <fpage>331</fpage>&#x2013;<lpage>339</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name> &#x0026; <string-name><surname>Oostenveld</surname>, <given-names>R.</given-names></string-name> <article-title>Nonparametric statistical testing of EEG-and MEG-data</article-title>. <source>J. Neurosci. Methods</source> <volume>164</volume>, <fpage>177</fpage>&#x2013;<lpage>190</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Macmillan</surname>, <given-names>N. A.</given-names></string-name> &#x0026; <string-name><surname>Creelman</surname>, <given-names>C. D.</given-names></string-name> <source>Detection theory: a user&#x2019;s guide. (Lawrence Erlbaum Associates</source>, <year>2005</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Kutil</surname>, <given-names>R.</given-names></string-name> <article-title>Biased and unbiased estimation of the circular mean resultant length and its variance</article-title>. <source>Statistics</source> <volume>46</volume>, <fpage>549</fpage>&#x2013;<lpage>561</lpage> (<year>2012</year>).</mixed-citation></ref>
</ref-list>
<ack>
<title>Acknowledgements</title>
<p>This study was funded by the National Institutes of Health (R01-DC-00843, R01-DC-014085). We thank support to FCC by the Mexican National Council of Science and Technology through its graduate scholarship program. We thank Natalia Lapinskaya for excellent technical assistance, and Richard Payne, Matthew Goupell, Jonathan Fritz, Ellen Lau, Daniel Butts and Behtash Babadi for discussions.</p>
</ack>
<sec>
<title>Author Contributions</title>
<p>FCC conceived, designed, and performed the experiments, analyzed the data, and prepared the manuscript figures. JZS supervised the research. Both authors wrote the manuscript text.</p>
</sec>
<sec id="s5">
<title>Additional Information</title>
<sec id="s5a" sec-type="COI-statement">
<title>Competing financial interests</title>
<p>The authors declare no competing financial interests.</p>
</sec>
</sec>
</back>
</article>