<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/067215</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Advances in the recovery of haplotypes from the metagenome</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Nicholls</surname>
<given-names>Samuel M.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Aubrey</surname>
<given-names>Wayne</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>de Grave</surname>
<given-names>Kurt</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schietgat</surname>
<given-names>Leander</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Creevey</surname>
<given-names>Christopher J.</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Clare</surname>
<given-names>Amanda</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Computer Science, Aberystwyth University</institution>, Aberystwyth, SY23 3DB, <country>United Kingdom</country></aff>
<aff id="a2"><label>2</label><institution>Department of Computer Science, Katholieke Universiteit Leuven</institution>, Celestijnenlaan 200A, 3001 Leuven, <country>Belgium</country></aff>
<aff id="a3"><label>3</label><institution>Institute of Biological, Environmental and Rural Sciences, Aberystwyth University</institution>, Aberystwyth, SY23 3DA, <country>United Kingdom</country></aff>
<aff id="a4"><label>4</label><institution>Flanders Make, Oude Diestersebaan 133</institution>, 3920 Lommel, <country>Belgium</country></aff>
</contrib-group>
<author-notes>
<fn fn-type="other"><p>Contact: <email>afc@aber.ac.uk</email> (&#x002B;441970 622429), <email>chc30@aber.ac.uk</email> (&#x002B;441970 621612)</p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2016</year></pub-date>
<elocation-id>067215</elocation-id>
<history>
<date date-type="received">
<day>01</day>
<month>8</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>02</day>
<month>8</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2016</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="067215.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>High-throughput DNA sequencing has enabled us to look beyond consensus reference sequences to the variation observed in sequences within organisms; their haplotypes. Recovery, or assembly of haplotypes has proved computationally difficult and there exist many probabilistic heuristics that attempt to recover the original haplotypes for a single organism of known ploidy. However, existing approaches make simplifications or assumptions that are easily violated when investigating sequence variation within a metagenome.</p>
<p>We propose the metahaplome as the set of haplotypes for any particular genomic region of interest within a metagenomic data set and present Hansel and Gretel, a data structure and algorithm that together provide a proof of concept framework for the recovery of true haplotypes from a metagenomic data set. The algorithm performs incremental haplotype recovery, using smoothed Naive Bayes &#x2014; a simple, efficient and effective method.</p>
<p>Hansel and Gretel pose several advantages over existing solutions: the framework is capable of recovering haplotypes from metagenomes, does not require a priori knowledge about the input data, makes no assumptions regarding the distribution of alleles at variant sites, is robust to error, and uses all available evidence from aligned reads, without altering or discarding observed variation. We evaluate our approach using synthetic metahaplomes constructed from sets of real genes and show that up to 99&#x0025; of SNPs on a haplotype can be correctly recovered from short reads that originate from a metagenomic data set.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>&#x2018;de novo assembly&#x2019;</kwd>
<kwd>&#x2018;metagenome&#x2019;</kwd>
<kwd>&#x2018;haplotype&#x2019;</kwd>
<kwd>&#x2018;algorithm&#x2019;</kwd>
<kwd>&#x2018;variation&#x2019;</kwd>
</kwd-group>
<counts>
<page-count count="29"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Genomic research has gone beyond finding a consensus sequence to represent a species in favour of understanding the true genetic diversity that exists within populations (<xref ref-type="bibr" rid="c10">Gibbs et al., 2003</xref>). High-throughput sequencing has allowed us to look further than consensus variation across populations of a species and reconstruct the genetic variants that characterizes each individual (haplotype).</p>
<p>Haplotype recovery approaches (also known as haplotype assembly) attempt to reconstruct haplotypes given a set of DNA fragments from a population (<xref ref-type="bibr" rid="c13">Lancia et al., 2001</xref>). Typically such approaches rely on the availability of reference sequences for the species under investigation. However, microbial communities consist of a large number of organisms for which no references exist and cannot at present be cultured <italic>in vitro</italic>. This has led to approaches that isolate and sequence DNA directly from the environment (metagenomics).</p>
<p>Microbial communities contain many organisms that co-exist in competition for the available resources and these communities represent an untapped wealth of genetic diversity. Information on this diversity is typically lost through current <italic>de novo</italic> analysis pipelines that make assumptions about ploidy and the source of the DNA. The majority of computational approaches assume reads originate from a single individual.</p>
<p>This impacts our ability to isolate the full repertoire of enzymes from microbial communities. If solved, this would advance exploitation of industrially relevant enzymes for the refinement of biofuels, production of plastics, scrub oil from water and even identify new classes of antibiotics (<xref ref-type="bibr" rid="c22">Zhang and Kim, 2010</xref>).</p>
<p>We would like to determine the collection of haplotypes for any genomic region of interest such as a particular enzyme, which we define as the <bold>meta-haplome</bold>.</p>
<sec id="s1a">
<title>Assembly and pseudo-references</title>
<p>An assembly of reads from a metagenome can act as a pseudo-reference in the absence of a fully assembled genome. However, the pseudo-reference is a consensus of the read information and cannot represent the true haplotypes present. Furthermore, the pseudo-reference may not exist in nature and not constitute a viable enzyme. Once we have constructed the pseudo-reference, we discard the only evidence of the real haplotypes, the reads themselves.</p>
<p>Most assemblers are designed for single species genomes, are optimised to remove low level variation, and aim to produce a single sequence. Metagenome assemblers improve this with techniques for management of large data and correcting poorly assembled contiguous sequences (contigs) (<xref ref-type="bibr" rid="c18">Namiki et al., 2012</xref>). However they do not aim to solve the problem of recovering haplotypes. Other researchers have identified the problem that consensus assembly poses for the downstream analysis of variants and are moving towards alternative assembly approaches, such as graph-based assemblyGarrison et al. (2016).</p>
</sec>
<sec id="s1b">
<title>Haplotype recovery</title>
<p>The problem of haplotype recovery was first described by <xref ref-type="bibr" rid="c13">Lancia et al. (2001)</xref>. Lancia introduced the first terminology and notation for &#x201C;computational SNPology&#x201D;<xref ref-type="fn" rid="fn1"><sup>1</sup></xref> (single nucleotide polymorphism) that served as a foundation for many other approaches and algorithms that followed. Lancia&#x2019;s framework introduced the <bold>SNP matrix</bold> (typically denoted M): an <italic>n</italic> &#x00D7; <italic>m</italic> matrix encoding the binary allele (<italic>A, B</italic>) observed at each SNP site 1..<italic>n</italic> on each fragment 1..<italic>m</italic>. That is, <italic>M</italic>[<italic>i</italic>][<italic>j</italic>] is the allele observed at the <italic>j</italic>&#x2019;th SNP of the i&#x2019;th fragment (<xref ref-type="bibr" rid="c13">Lancia et al., 2001</xref>).</p>
<p>In this work Lancia introduced three optimisation problems:
<list list-type="bullet">
<list-item><p><italic>Minimum fragment removal</italic> (<bold>MFR</bold>);</p></list-item>
<list-item><p><italic>Minimum SNP removal</italic> (<bold>MSR</bold>); and</p></list-item>
<list-item><p><italic>Longest haplotype reconstruction</italic> (<bold>LHR</bold>).</p></list-item>
</list></p>
<p>All three approaches focus on removing the minimal number of rows or columns from the SNP matrix to correct &#x201C;conflicts&#x201D; until there exists a pair of haplotypes without conflicting evidence.</p>
<p><xref ref-type="bibr" rid="c17">Lippert et al. (2002)</xref> introduced various solutions for the problems of MFR and MSR, but their main contribution was the definition of the <italic>minimum error correction</italic> (<bold>MEC</bold>) approach. MEC (also known as <italic>minimum letter flip</italic> (<bold>MLF</bold>)) attempts to find the minimum number of elements to &#x201C;flip&#x201D; in the SNP matrix M, such that a pair of haplotypes becomes feasible. Implementations of MFR, MSR and MEC/MLF include <monospace>Fast Hare, HapCUT</monospace> and others (<xref ref-type="bibr" rid="c9">Geraci, 2010</xref>; <xref ref-type="bibr" rid="c12">Lancia, 2016</xref>; <xref ref-type="bibr" rid="c19">Panconesi and Sozio, 2004</xref>; <xref ref-type="bibr" rid="c5">Bansal and Bafna, 2008</xref>).</p>
<p>All of these approaches focus on removing (or altering) observed evidence in the SNP matrix M until two compatible haplotypes can be defined. Each of these approaches has been demonstrated to be NP-hard. These methods typically fail to scale with the large sets of sequence data that have become common place since 2008 <xref ref-type="bibr" rid="c2">Aguiar and Istrail (2012)</xref>.</p>
<p>Probabilistic approaches provide alternative methods that try to address this issue (<xref ref-type="bibr" rid="c12">Lancia, 2016</xref>; <xref ref-type="bibr" rid="c16">Li et al., 2004</xref>). <xref ref-type="bibr" rid="c20">Wang et al. (2006)</xref> introduced a polynomial time Markov chain based algorithm for the determination of diploid haplotypes. Markov models capture probabilities of transitions from one variant to the next, but have the memory-less property that each transition between the variant states is determined only by the state at the previous variant. Wang et <italic>al</italic>. tested increasing the &#x201C;memory&#x201D; (order) of the model to 3, however the results were not improved. This approach makes the assumption that the haplotypes to recover are from a diploid species, and that the genotypes of the allele pairs comprising the haplotypes are known in advance.</p>
<p><xref ref-type="bibr" rid="c2">Aguiar and Istrail (2012)</xref> created <monospace>HapCompass</monospace>, which introduces a novel data structure: the <italic>compass graph</italic>, in which haplotype phasings correspond to spanning trees, in order to scale to the data output from modern sequencing methods. They later expanded on HapCompass (<xref ref-type="bibr" rid="c3">Aguiar and Istrail, 2013</xref>) to produce the first haplotype recovery algorithm to operate on polyploid genomes. However, it requires the ploidy to be specified in advance (diploid is assumed otherwise), which is unknown for metagenomes.</p>
<p>Evidently, the problem of haplotyping is a rich area of research, and has received much focus since it was first introduced in 2001, but the majority of modern haplotyping recovery software systems are not designed for metagenomic applications.</p>
<p>Existing algorithms are designed for single-species haplotype segregation, usually diploid species such as human. Typically they make easily violated assumptions, for example: SNP sites are bi-allelic (<xref ref-type="bibr" rid="c4">Ahn and Vikalo, 2015</xref>). However, metagenomes consist of an unknown number of organisms and their SNP sites can feature more than two alleles.</p>
<p>Approaches like those first presented by Lancia (<xref ref-type="bibr" rid="c13">Lancia et al., 2001</xref>) focus on the removal of errors. Such an approach would prove problematic if applied to metagenomic data, where errors are not just assumed, but are indistinguishable from both intra- and inter-species variation in the metagenome. For the same reason minimum letter flip (MLF) can be seen as unsuitable as it alters the observed information.</p>
<p>This type of problem is suited to Markov model based approaches. Markov models are particularly helpful on data sets without prior information (in their case, data errors, but in our case, contaminants: we know nothing of the species present, nor their distributions). We have applied a Markov model based approach to attempt to address the problem of haplotypes from metagnomic data sets.</p>
<p>In this work we introduce:
<list list-type="order">
<list-item><p>a novel probabilistic pseudo-graph data structure, <bold>Hansel</bold>, designed to store and provide an interface to pairwise co-occurring SNP evidence from sequenced reads.</p></list-item>
<list-item><p>an algorithm, <bold>Gretel</bold>: designed to take advantage of the <monospace>Hansel</monospace> data structure to load and traverse <monospace>Hansel</monospace> graphs to recover possible hap-lotypes from a <italic>metahaplome</italic>.</p></list-item>
</list></p>
</sec>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The metahaplome</title>
<p>We define the metahaplome as the set of haplotypes for any particular genomic region of interest within a metagenomic data set.</p>
</sec>
<sec id="s2b">
<title>Hansel and Gretel</title>
<p>We present <monospace>Hansel</monospace> and <monospace>Gretel</monospace>, a data structure and algorithm for the recovery of haplotypes from a metahaplome. Advantages of our method include:
<list list-type="bullet">
<list-item><p>recovers haplotypes from metagenomic data</p></list-item>
<list-item><p>does not need <italic>a priori</italic> knowledge of the number of haplotypes</p></list-item>
<list-item><p>makes no assumptions about the distribution of alleles at any variant site</p></list-item>
<list-item><p>does not need to distinguish between sequence error and variation</p></list-item>
<list-item><p>uses all available evidence provided by the raw reads</p></list-item>
<list-item><p>does not require any user-defined parameters</p></list-item>
</list></p>
<p>We provide open source implementations for the data structure API (<monospace>Hansel</monospace>) and the haplotype recovery algorithm (<monospace>Gretel</monospace>) at <ext-link ext-link-type="uri" xlink:href="https://github.com/samstudio8/gretel">https://github.com/samstudio8/gretel</ext-link>.</p>
</sec>
<sec id="s2c">
<title>Synthetic metahaplomes</title>
<p>We evaluate <monospace>Hansel</monospace> and <monospace>Gretel</monospace> on simple simulated metahaplomes constructed as described in our Methods.</p>
<p>We quantify success by evaluating each recovered haplotype against each of the generated haplotypes known to exist in the metahaplome. For each input, its best corresponding output is defined as the haplotype found by <monospace>Gretel</monospace> that shares the highest sequence identity with the generated input (Figure). We report the average of the best identity percentages for each input/output haplotype pair as the quality metric for our approach on synthetic metahaplomes.</p>
<p>Our results in <xref ref-type="table" rid="tbl1">Table 1</xref> are promising. Best recovery rates (the highest recovery rate seen across the 10 randomly generated metahaplomes for that combination of haplotype length and number) are 100&#x0025; for all but two (99.0&#x0025;, 99.6&#x0025;) of all tested lengths of metahaplomes containing up to 10 input haplotypes. We are able to recover at least one (but typically more) input haplotypes in their entirety, even for sequences consisting of 250 SNPs.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Results of the synthetic metahaplome tests. The metahaplomes contained a known number of haplotypes of fixed size. Reads were randomly generated to span between 2&#x2013;5 SNPs, with an approximate coverage of 3&#x2013;5x for each haplotype. Each cell details the lowest (top), average (bold) and highest (bottom) best recovery rates (Figure) as discovered by <monospace>Gretel</monospace> over 10 repeats.</p></caption>
<graphic xlink:href="067215_tbl1.tif"/>
</table-wrap>
<p>It is not surprising to observe that recovery success rates reduce with increased haplotype length (<italic>i.e</italic>. number of SNPs) and/or number of input haplotypes. Despite this, we report high recovery rates for haplotypes from metahaplomes with 100 SNPs or more, for small numbers of haplotypes.</p>
</sec>
<sec id="s2d">
<title>Metahaplomes from real genes</title>
<p>To extend our validation to reads derived from real sequence, we experimented with two metahaplomes constructed from two sets of real genes: dihydrofolate reductase <italic>DHFR</italic>, and Aminoacyl tRNA synthase complex-interacting multifunctional protein 1 <italic>AIMP1</italic>. DHFR and AIMP1 were selected as a test to evaluate whether variation across highly conserved genes could be recovered by our algorithm. To test the limitations of our method, we also evaluated our framework against a densely populated metahaplome of highly variable influenza sequences.</p>
<p>Our Methods section provides insight into the creation of the metahaplomes used for evaluation. For DHFR, AIMP1 and FLU-A7, we report the percentage of correctly recovered SNPs for each input and its corresponding best recovered haplotype, as determined by BLAST.</p>
</sec>
<sec id="s2e">
<title>DHFR</title>
<p><xref ref-type="table" rid="tbl2">Table 2</xref> presents the percentage of correctly recovered SNPs on the best haplotype recovered for each of the input sequences. In general, the algorithm performs well, both <italic>BC070280.1</italic> and <italic>XR&#x005F;63&#x0104;888.1</italic> are recovered with few errors. The recovered haplotype for the latter has a 98.9&#x0025; recovery rate, when recovered from reads of length 120, with 15x coverage.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2;</label>
<caption><p>Results summarising the percentage of SNPs correctly recovered by <monospace>Gretel</monospace> for each DHFR metahaplome constructed with synthetic reads of a given size and coverage (see columns). Each cell is the percentage of correctly recovered SNPs on the best recovered haplotype for the metahaplome column and input gene row.</p></caption>
<graphic xlink:href="067215_tbl2.tif"/>
</table-wrap>
<p>Clearly, <monospace>Gretel</monospace> has particular difficulty recovering the <italic>AK232978.1</italic> and <italic>XM012113510.1</italic> haplotypes, which both demonstrate lower identities with the pseudo-reference. We observe that reads that are more divergent from the pseudo-reference sequence are discarded by alignment operations, denying <monospace>Gretel</monospace> the pairwise evidence needed to recover these less similar sequences. Despite this, on average <italic>XM012113510.1</italic> is recovered at over 75&#x0025; accuracy.</p>
</sec>
<sec id="s2f">
<title>AIMP1</title>
<p><xref ref-type="table" rid="tbl3">Table 3</xref> presents the percentage of SNPs that are correctly recovered for the best haplotype recovered for each of the AIMP1 genes that are represented by synthetic reads in the metahaplome. Recoveries were not possible for either of the 60bp read metahaplomes, nor the 75bp 7.5x coverage meta-haplome as there existed a pair of SNPs too far apart to be spanned by at least one read in the data set. Of the results where analysis was possible, recovery rates are very high. Three of the five input genes have average recovery rates of over 96&#x0025;; that is, at least 96&#x0025; of the (on average) 70 variants are recovered correctly and match the expected input haplotype. We again have trouble recovering the sequence exhibiting the highest deviation from the reference <italic>XM&#x005F;006778898.2</italic>, scoring an average recovery of just under 60&#x0025;.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><p>Results summarising the percentage of SNPs correctly recovered by <monospace>Gretel</monospace> for each AIMP1 metahaplome constructed with synthetic reads of a given size and coverage (see columns). Each cell is the percentage of correctly recovered SNPs on the best recovered haplotype for the metahap-lome column and input gene row. Rows are ordered by decreasing identity to the pseudo-reference.</p></caption>
<graphic xlink:href="067215_tbl3.tif"/>
</table-wrap>
</sec>
<sec id="s2g">
<title>FLU-A7 (metahaplome of 71 haplotypes)</title>
<p>We test the limitations of our approach with a metahaplome of 71 highly variable Influenza A Segment 7 haplotypes. For brevity we summarise in <xref ref-type="table" rid="tbl4">Table 4</xref> the recoveries obtained across all 71 haplotypes and describe the percentage of SNPs recovered for the worst, average and best recovered haplotypes. Particularly impressive is the best haplotype recovered from the 120bp 7.5x data set, where 99&#x0025; of the 264 SNPs agreed with those on its corresponding input gene. On average, the haplotype with the lowest sequence identity to the pseudo-reference has an worst recovery rate of 52.5&#x0025;, which is far better than expected by chance alone.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><p>Results summarising the percentage of SNPs correctly recovered by Gretel for the FLU-A7 metahaplome (71 highly variable Influenza A Segment 7 haplotypes) constructed using synthetic reads of different sizes and coverages (see columns). Cells show the percentages of correctly recovered SNPs for the best recovered haplotype, average haplotype and worst recovered haplotype.</p></caption>
<graphic xlink:href="067215_tbl4.tif"/>
</table-wrap>
<p>It should be noted that for each of these metahaplomes, between 25&#x0025; and 50&#x0025; of the generated synthetic reads were discarded. It is highly likely with finer tuning, a different alignment algorithm, or an alternative approach to alignment, we could drastically improve the already reasonable scores presented here.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have provided a description of a previously undefined problem and made advances in the recovery of haplotypes from a metagenome. We offer the term metahaplome to represent the set of haplotypes for any particular region of interest within a metagenomic data set.</p>
<p>We introduced Hansel, a novel data structure which encodes the variation seen across a <bold>metahaplome</bold>. Hansel permits traversal of that variation like a graph, yet allowing for probabilistically weighted edges to consider the state of the haplotype recovered so far. We also introduced <italic>Gretel</italic>, an algorithm capable of traversing the metahaplome represented by <italic>Hansel</italic> for the recovery of genuine haplotypes from a metahaplome constructed from the raw reads of a metagenomic data set. For the first time, it is possible to computationally extract variants of commercially relevant genes.</p>
<p>Together <monospace>Hansel</monospace> and <monospace>Gretel</monospace> form a new framework for the recovery of haplotypes in metagenomes, allowing data sets where short read length has previously restricted effective analysis.</p>
<sec id="s3a">
<title>Performance and tractability</title>
<p>Without an annotated metagenome, it is clearly difficult to quantify the effectiveness of our approach. The testing presented here has been performed with data simulated from real genes in order to explore the limitations of the algorithm.</p>
<p>As described in our methods, initial testing was completed with randomly generated haplotypes to measure performance with regard to both haplotype length and number of haplotypes. We demonstrate very high recovery rates, even in the presence of many SNPs.</p>
<p>We evaluated the approach with synthetic reads generated from metahaplomes consisting of mixtures of real genes (DHFR and AIMP1) and demonstrated it is possible to recover haplotypes from short read data accurately. Successful recoveries can be made with our framework even in the presence of many haplotypes. We demonstrate high recovery rates in the FLU-A7 metahaplome, containing short reads generated from 71 highly variable influenza sequences.</p>
<p>However, our results have also demonstrated that our approach is strongly biased by the alignment of reads against the pseudo-reference. During testing of both the DHFR and AIMP1 data set, it was found that many synthetic reads would not align back to the pseudo-reference. Input genes <italic>(i.e</italic>. haplotypes) for the DHFR and AIMP1 metahaplomes were selected with decreasing sequence identity from the pseudo-reference (the pseudo-reference). Unfortunately, when short reads were generated, it was found that <monospace>bowtie2</monospace> discarded up to 20&#x0025; of the synthetic reads, particularly those yielded from less similar sequences.</p>
<p>This is of course not unexpected: it should not be a surprise that sequences with lower identity to the target are likely to eventually fall below some threshold and be discarded. However, this does raise an important caveat to our work: both assemblers and aligners will exert influence over the tractability of how many and how accurately haplotypes in a given metahaplome can be recovered. Many software packages that perform these tasks have expectations and make assumptions that are not ideal in the case of recovering haplotypes from a metagenome. Here, the discarding of reads denies <monospace>Hansel</monospace> and <monospace>Gretel</monospace> access to critical evidence require to reconstruct those particular haplotypes.</p>
<p>It should be noted that the pseudo-reference is not used by <monospace>Hansel</monospace> or <monospace>Gretel</monospace>, it serves only as a common sequence on which to align raw reads before calling SNPs. Very high recovery rates on sequences that share identity with the pseudo-reference are a reflection of the strength of our approach, and not a trivial recovery.</p>
<p>Perhaps most significantly, the tractability of the problem is bound by the quality of the data available. As stated by Lancia in 2001, it is entirely possible that, even without error, there are scenarios where data is insufficient to successfully recover haplotypes and the problem is rendered impossible <xref ref-type="bibr" rid="c13">Lancia et al. (2001)</xref>. Indeed, as explained in our Methods section, there are multiple potential inconsistencies that can occur in the alignment that are not trivial to address.</p>
<p>It should be noted that although our framework has been designed with the recovery of haplotypes in a metagenome at a gene level <italic>(i.e</italic>. variants of a gene involved in a catalytic reaction of interest, such as degradation of biomass) in mind, given sufficient coverage of SNPs, our approach could work on regions significantly longer than that of a gene.</p>
<p>Regarding time and resource requirements, Hansel and Gretel is designed to work on all reads from a metagenome that align to some region of interest on the pseudo-reference. Typically these subsets are small (on the order of 10&#x2013;100K reads) and so our framework can be run on an ordinary desktop in minutes, without significant demands on disk, memory or CPU.</p>
</sec>
<sec id="s3b">
<title>Advantages of our approach</title>
<p>In contrast to other methods, our framework aims to make as few assumptions as possible. <monospace>Gretel</monospace> is designed for metagenomic data sets where the number of haplotypes is unknown. Whilst <monospace>HapCompass</monospace> is designed to identify haplotypes for a polyploid organism, it requires advance knowledge of the number of expected haplotypes <xref ref-type="bibr" rid="c1">Aguiar (2014)</xref> which is unknown for metagenomic data sets.</p>
<p>Most SNP calling algorithms discard SNP sites that feature three or more alleles <italic>(i.e</italic>. non bi-allelic sites) as errors, or under the assumption that input data represents sequenced reads from a diploid species <xref ref-type="bibr" rid="c4">Ahn and Vikalo (2015)</xref>. Although <monospace>ParticleHap</monospace> (<xref ref-type="bibr" rid="c4">Ahn and Vikalo, 2015</xref>) relaxes this assumption by incorporating genotype calling, it is to reduce the risk of erroneously called genotypes preventing reconstruction of the two haplotypes for a diploid genome.</p>
<p>Many existing methods rely on discarding or altering observed SNPs until a pair of haplotypes can be determined. <monospace>Hansel</monospace> and <monospace>Gretel</monospace> uses all available pairwise observations and works to recover the most likely haplotypes. Unlike other methods, we do not assume that the observed evidence must be contaminant or sequencing error that needs discarding or altering to recover the real haplotypes. Although sequence error is an inevitability, errors will be poorly supported by read data and are unlikely to form components of recovered haplotypes.</p>
</sec>
</sec>
<sec id="s4">
<title>Future work</title>
<p><monospace>Gretel</monospace> is a proof of concept. Although we have demonstrated success in our Results, there are still other sources of evidence not currently used by our algorithm &#x2014; namely paired end reads and alignment base quality scores. Read pairs will certainly provide useful co-occurrence information for SNPs that span some known insert, however careful consideration on how to integrate this data is necessary. The order of the Markov chain that constructs haplotypes will typically be small, as it represents the number of selected variants from the current head of a path to include when considering probabilities for which variant should come next. As reads typically span only a few SNP sites, it is not effective (and can be detrimental) to set the &#x201C;lookback&#x201D; parameter <italic>L</italic> to a value high enough to consider variants seen at the other side of an insert.</p>
<p>Additionally, the second read of a pair will provide evidence for variants that are likely appear after an insert (given the variants seen in the first read of the pair), but no evidence for what variants should be selected during the insert. During recovery, this potentially puts us in the position of having evidence for what a variant a few positions ahead of our current location should be, but no idea of how to get there. A solution may be to permit <monospace>Gretel</monospace> to fill in future variants given paired end evidence (if available) as placeholders and backpropagate towards the head of the path to predict which variants are likely to appear given the placeholder observed in the future. This is possible as the pairwise information stored in <monospace>Hansel</monospace> by <monospace>Gretel</monospace> is not directional. Observations are bidirectional, and although the structure presented by <monospace>Hansel</monospace> is a directed graph, the direction can be either forwards or backwards, just not both. This would allow reconstruction of haplotypes from either end of a gene.</p>
<p>Alignment scores would permit some form of weighting mechanism to be applied to observations. Low confidence base calls can be considered as less informative than those with high calling confidence, but experimentation on how to reliably tune this parameter for pairwise information (how should we weight a pair of variants where one call is good, and the other is bad) would be needed.</p>
<p>Our largest obstacle is that of <italic>smoothing</italic>. In general, smoothing tries to reduce overfitting of a model. Here, we want to avoid scenarios where SNP sites with very low read coverage (and thus few informative observations) are assumed to be fully representative of the true variation. Many of the alignment artefacts described in our Methods section (<xref ref-type="fig" rid="fig2">Figure 2</xref>) as posing a problem for reconstruction <italic>(e.g</italic>. SNP pairs with few valuable observations, SNP sites that are not connected by reads) can begin to be better addressed with an appropriate model for smoothing. Future work aims to build upon the simple add-one smoothing found in our current model to incorporate more intelligent smoothing of low frequency observations.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>An example demonstrating the calculation of the recovery rate of haplotypes from generated synthetic metahaplomes. Rows represent known input haplotypes, columns represent the haplotypes recovered by <monospace>Gretel</monospace>. Cells report the percentage sequence identity of that input-output pair. The average best recovery is the sum of the best identity percentage for each input haplotype, divided by the number of inputs. Values are for illustrative purposes only. <xref ref-type="table" rid="tbl1">Table 1</xref> reports the average scores of the best recovery rate for each generated haplotype.</p></caption>
<graphic xlink:href="067215_fig1.tif"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Artefacts of read alignments that cause difficulties for recovery of haplotypes from metahaplomes (a) Reads do not span a pair of SNPs, no pairwise evidence describing how the graph can be traversed is available (b) single SNP reads do not provide sufficient evidence about their source or destination variants and add many potential edges to the graph (c) coverage of reads exists between a pair of SNPs but the information available is insufficient to determine paths through the graph (d) low coverage between SNP sites can cause decisions to be biased</p></caption>
<graphic xlink:href="067215_fig2.tif"/>
</fig>
<p><monospace>Hansel</monospace> and <monospace>Gretel</monospace> only consider SNPs. It is likely that real haplotypes will exhibit insertions and deletions (indels) against a pseudo-reference. Further thought and experimentation is needed to devise a methodology that permits the consideration of indels by our approach. Whilst an initial solution may be to add an additional symbol to represent an indel to the <monospace>Hansel</monospace> structure, we must find a way to incorporate this evidence into a structure that currently only considers paired SNP variation.</p>
<p><monospace>Gretel&#x2019;s</monospace> algorithm involves a greedy bias. We assume the &#x201C;best&#x201D; haplotype is the most likely haplotype, and that it can recovered by selecting the edge with the highest probability at each SNP. However there are likely to exist solutions whose overall likelihood may be higher if we permitted <monospace>Gretel</monospace> to look ahead along the path to inspect a small number of future choices. It is possible that this will alter little in in practice, as each read only spans a small number of SNPs.</p>
<p>The &#x201C;lookback&#x201D; parameter <italic>L</italic> does have some influence on both the efficiency and accuracy of the recovery. A meaningful choice for this parameter is to use the mean number of SNPs covered per read.</p>
<p>As briefly described in our Methods, Gretel will continue to generate possible haplotypes until the available evidence in Hansel is exhausted. Thus our algorithm is capable of determining its own stopping criteria. Recovered haplotypes can be ranked according to metadata provided by Gretel such as the log likelihood of that haplotype occurring given the variation observed across the original raw reads. We intend to explore additional metrics that may be used to determine other methods for scoring (and filtering) returned haplotypes.</p>
<p>Finally, we would like to investigate potential methodologies for abandoning the requirement of a common reference (that is, in our terminology, the assembly, or pseudo-reference) and working solely with read data. A metagenomic assembly provides both a convenient proxy for the raw reads (that is, a gene found or predicted on the pseudo-reference can be assumed to have some affinity with reads that align to the same location), and a pseudo-reference to align reads against and call for SNPs. However, the processes of assembly, alignment and SNP calling each make assumptions and decisions that simplify or discard data, reducing the evidence available for the accurate recovery of haplotypes. With fast and efficient sequence search alternatives(<xref ref-type="bibr" rid="c6">Buchfink et al., 2015</xref>) it is easier to conduct sequence similarity searches across very large sets of metagenomic reads. Literature also exists for reference-free SNP calling<xref ref-type="bibr" rid="c11">Iqbal et al. (2012)</xref>, which both offer opportunities for introducing fewer assumptions and maintaining the in-tegrity of variants observed across metagenomic data before they reach a framework such as <monospace>Hansel</monospace> and <monospace>Gretel</monospace> for the recovery of haplotypes, from a metahaplome.</p>
</sec>
<sec id="s5">
<title>Conclusion</title>
<p>In this work we have introduced a definition for the <bold>metahaplome</bold>. We provide both a definition and implementation of a novel data structure, and a proof of concept algorithm, that together represent a framework for the reconstruction of haplotypes from metagenomic data sets. We demonstrated promising recovery rates and described many interesting avenues for future work and analysis.</p>
<p>We aim to empirically prove that <monospace>Gretel</monospace> is capable of reconstructing real haplotypes by using its output to design primers to extract a commercially interesting enzyme and its variants from a metagenome and confirm the results using single molecule sequencing.</p>
<p>For the first time, we have demonstrated computational techniques that are capable of using metagenomic reads to reconstruct viable proteins responsible for interesting catalytic reactions in a microbial community; a task that existing computational methods and alternative laboratory techniques such as rational design have struggled to achieve.</p>
<p>Our work is an advance in computational methods for extracting exciting exploitable enzymes from metagenomes.</p>
</sec>
<sec id="s6">
<title>Methods</title>
<sec id="s6a">
<title>The metahaplome</title>
<p>To enable recovery of haplotypes from a metahaplome for a metagenomic data set, we assume the following is available:
<list list-type="bullet">
<list-item><p>A set of <italic>raw reads</italic> from a metagenome</p></list-item>
<list-item><p>An assembly of those reads (the <italic>pseudo-reference</italic>)</p></list-item>
<list-item><p>A region of interest on the assembly (the <italic>target</italic>)</p></list-item>
<list-item><p>An <italic>alignment</italic> of the raw reads, against the pseudo-reference</p></list-item>
<list-item><p>A list of <italic>positions</italic> at which single nucleotide variations occur over the aligned reads</p></list-item>
</list></p>
<p>A pseudo-reference can be generated by assembling sequenced reads known to come from a metagenomic data set, with an assembler such as <monospace>VelvetZerbino</monospace> and Birney (2008). Selecting a suitable assembly algorithm and the dark art of choosing parameters such as k-mer size is left as an exercise to the reader. A region of interest on the assembly may be identified by homology search or gene prediction. Raw reads are filtered by whether or not they &#x201C;map back&#x201D; to the target region according to an alignment tool such as <monospace>bowtie2</monospace><xref ref-type="bibr" rid="c14">Langmead and S. (2012)</xref>. Reads that fall outside the target of interest (<italic>i.e</italic>. reads that do not cover any of the genomic positions covered by the target) are discarded. Variation at single nucleotide positions across reads along the target, can then be called with a SNP calling algorithm such as that provided by <monospace>samtools</monospace><xref ref-type="bibr" rid="c15">Li et al. (2009)</xref> or <monospace>GATK</monospace><xref ref-type="bibr" rid="c7">DePristo et al. (2011)</xref>. Alternatively, one may determine any position that features at least one (or some number of) reads that disagree with one-another or the pseudoreference as a SNP.</p>
<p>The combination of aligned reads, and the locations of single nucleotide variation on those reads can be exploited to recover real haplotypes from the metahaplome: the collection of haplotypes that exist for the given region of interest on the metagenome.</p>
<p>Our ability to recover haplotypes from a metahaplome depends on the quality and coverage of the available reads and their alignment. <xref ref-type="fig" rid="fig2">Figure 2</xref> depicts several inconsistencies in aligned reads that make recovery of haplotypes more difficult.</p>
</sec>
<sec id="s6b">
<title>Hansel: A novel data structure</title>
<p>We present <bold>Hansel</bold>, a probabilistically-weighted, graph-inspired, novel data structure. Although the structure can be traversed like a graph, its underlying representation is a four dimensional array whose elements represent the number of observations of a given symbol <italic>A</italic> appearing at position <italic>i</italic>, co-occurring with symbol <italic>B</italic> at position <italic>j</italic>.</p>
<p>This representation differs from the typical SNP matrix model (<xref ref-type="bibr" rid="c13">Lancia et al., 2001</xref>) that forms the basis of many of the surveyed approaches. Rather than a matrix of SNP columns and fragment rows, we discard the concept of a fragment entirely and aggregate the evidence seen across all fragments by position.</p>
<p>For each possible pairing of symbols (<italic>i.e</italic>. AA, AC,&#x2026; TG, TT), the <monospace>Hansel</monospace> structure keeps a matrix, whose elements record the number of observations of those symbols co-occurring on a read. More specifically, an element in the <monospace>Hansel</monospace> matrix <italic>H, H</italic>[<italic>A,B,i,j</italic>] stores the number of times symbol <italic>A</italic> at position <italic>i</italic> has been seen to co-occur with symbol <italic>B</italic> at position <italic>j</italic>. For example, the number of times a <monospace>C</monospace> at SNP position <monospace>3</monospace>, appears on the same read as a <monospace>T</monospace> at SNP position <monospace>6</monospace>.</p>
<p>Although this structure may appear limited, the data can be exploited to build other structures. For example, if one considers <italic>H</italic>[<italic>A, B</italic>, 1,2] for all possible <italic>A</italic> and <italic>B</italic>, one may list the available options for transitioning from position 1, to position 2. Extending this to consider every element <italic>H</italic>[<italic>A, B,i,i</italic> &#x002B; 1], for all possible combinations of symbols <italic>A</italic> and <italic>B</italic>, and all SNP positions <italic>i</italic>, we can construct a SNP transition graph <italic>G</italic> (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Three corresponding representations, (a) aligned reads, (b) the Hansel structure, (c) a graph that can be derived from the Hansel structure</p></caption>
<graphic xlink:href="067215_fig3.tif"/>
</fig>
<p>Intuitively, one may traverse <italic>G</italic> by selecting edges with the highest weight (where edge weights may be defined as the number of reads in which the current node was observed to occur with a given next node) to recover chains of symbols that represent an ordered sequence of SNPs that constitute a haplotype.</p>
<p>However, the data cannot be fully represented with a graph such as that seen in <xref ref-type="fig" rid="fig3">Figure 3</xref> alone. This representation defines a constraint whereby edges may only join adjacent SNPs and so cannot encode any information as to which non-adjacent polymorphisms co-occur. Without considering information about non-adjacent SNPs, one can traverse the graph to create paths that don&#x2019;t exist in nature (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Considering only adjacent SNPs, one may create paths for which there was no actual observed evidence. Here, the reads &#x007B;0011, 0001, 0100&#x007D; do not support either of the results &#x007B;0000, 0101&#x007D;, but both are valid paths through a graph that permits edges between pairs of adjacent SNPs.</p></caption>
<graphic xlink:href="067215_fig4.tif"/>
</fig>
<p>To recover real haplotypes accurately, we must consider more than just the head of the path. The <monospace>Hansel</monospace> structure is designed to store pairwise co-occurrences of all SNPs (not just those that are adjacent), as seen across all reads. Thus we can weight edges in the graph based not just on the number of reads containing the current node, and a possible next node, but previously selected nodes too.</p>
<p>However, this does come at a cost. We describe <monospace>Hansel</monospace> as &#x201C;graphinspired&#x201D;, as allowing edge weights to depend on more than just the current node (that is, allowing an edge to be weighted with information from the <monospace>Hansel</monospace> structure that does not pertain to that edge specifically) leads to several differences between the <monospace>Hansel</monospace> structure, and a weighted directed acyclic graph. Whilst these differences are not necessarily disadvantageous, they do change what we can infer about the structure.</p>
<p>Now, the structure of the graph is effectively unknown in advance (<xref ref-type="fig" rid="fig5">Figure 5</xref>). That is, not only are the weights of the edges not known ahead of traversal, but the entire layout of nodes and edges is also unknown until the graph is explored (although, arguably this would be true of very large simple graphs too). Indeed, this means it is also unknown whether or not the graph can even be successfully traversed.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>The physical characteristics of the graph are unknown <italic>a priori</italic>. The metahaplome must be explored to determine its components. Only branches that are selected are explored further.</p></caption>
<graphic xlink:href="067215_fig5.tif"/>
</fig>
<p>Secondly, the graph is dynamically weighted. The current path represents a memory that affects the availability and weights of outgoing edges at the current head node. Edge weights are calculated probabilistically <italic>during</italic> traversal and depend on both the distribution of variants observed at the position to traverse to next, but also some number of the variants that have been encountered and selected thus far in the path. Please refer to our supplementary materials for information on how probabilistic weightings are calculated.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><p>Pairwise conditionals between L last variants on the observed path, and each of the possible next variants are calculated and the best option (highest likelihood) is chosen</p></caption>
<graphic xlink:href="067215_fig6.tif"/>
</fig>
<p>Effectively, a &#x201C;fog of war&#x201D; exists over the graph that is only dissipated as it is traversed. In exchange for these minor caveats, we have a data structure that permits graph-like traversal that is intrinsic to our problem definition, whilst utilising informative pairwise SNP information collected from observations on raw metagenomic reads. <monospace>Hansel</monospace> fuses the advantages of a graph&#x2019;s simple representation (and its inherent traversability) with the advantage of a matrix of itemsets (that permit storage of all pertinent information).</p>
<p>We provide an open source implementation of <monospace>Hansel</monospace> in the form of a Python package that exposes a friendly interface capable of managing and querying pairwise observations to a graph-inspired data structure for determining likely chains of sequences from breadcrumbs of evidence.</p>
</sec>
<sec id="s6c">
<title>Gretel: An algorithm for recovering haplotypes from metagenomes</title>
<p>We introduce <monospace>Gretel</monospace>, a proof of concept algorithm designed to interface with the <monospace>Hansel</monospace> data structure to recover the most likely haplotypes from a metahaplome. To obtain likely haplotypes, <monospace>Gretel</monospace> traverses the probabilistic graph structure provided by <monospace>Hansel</monospace>, selecting the most likely SNPs at each possible node (<italic>i.e</italic>. traversing edges with the greatest probability), given some subset of the most recently selected nodes in the path so far. At each node, a Markov chain of some order L is employed to predict which of the possible variants for the next SNP is most likely, given the last L variants in the current path.</p>
<p>Execution of <monospace>Gretel</monospace> can be broken into the following steps:
<list list-type="order">
<list-item><p>Parse alignments and construct &#x201C;SNP strings&#x201D;</p></list-item>
<list-item><p>Populate <monospace>Hansel</monospace> structure with pairwise observations</p></list-item>
<list-item><p>Exploit the <monospace>Hansel</monospace> graph API to incrementally recover a path until a variant has been selected for each SNP position
<list list-type="bullet">
<list-item><p>Query for the available transitions from the current head node to the next SNP</p></list-item>
<list-item><p>Calculate the probabilities of each of the potential next variants appearing in the path given the last <italic>L</italic> variants</p></list-item>
<list-item><p>Append the most likely variant to the path and traverse the edge</p></list-item>
</list></p></list-item>
<list-item><p>Re-weight used observations in <monospace>Hansel</monospace> to allow for new path</p></list-item>
<list-item><p>Repeat (3&#x2013;4) until the graph can no longer be traversed or an optional additional stopping criterion has been reached</p></list-item>
</list></p>
<p>Haplotypes are reconstructed as a path through the <monospace>Hansel</monospace> structure, one SNP at a time, linearly, from the beginning of the sequence. At each SNP position, the <monospace>Hansel</monospace> structure is queried for the variants that were observed on the raw reads at the next position. <monospace>Hansel</monospace> also calculates the conditional probabilities of each of those variants appearing as the next SNP in the sequence, using a Markov chain that makes its predictions given the current state of the observations in the <monospace>Hansel</monospace> matrix and the last <italic>L</italic> selected SNPs. <monospace>Gretel&#x2019;s</monospace> approach is greedy: we only consider the probabilities of the next variant. Our razor is to assume that the best haplotypes are those that can be constructed by selecting the most likely edges at every opportunity.</p>
<p>Once a path is completed (a variant has been chosen for all SNP sites), the observations in the <monospace>Hansel</monospace> matrix are re-weighted by <monospace>Gretel</monospace>. Whilst our framework is probabilistic, it is not stochastic. Given the same <monospace>Hansel</monospace> structure and operating parameters, <monospace>Gretel</monospace> will behave in a deterministic fashion and return the same set of paths every time. However we are interested in recovering multiple, real haplotypes from a metahaplome, not just one. <monospace>Hansel</monospace> exposes a function in its interface for the re-weighting of observations. Currently, <monospace>Gretel</monospace> reduces the weight of each pairwise observation that forms a component of the completed path - in an attempt to erase evidence for that haplotype existing in the metahaplome at all, allowing evidence for other paths to now direct the probabilistic search strategy.</p>
<p>Finally, <monospace>Gretel</monospace> outputs recovered sequences as FASTA, requiring no special parsing, or munging of results to be able to conduct further sequence analyses.</p>
</sec>
<sec id="s6d">
<title>Testing methodology</title>
<p>Our testing evaluates the performance of our framework against metahaplomes consisting of synthetic reads derived from both randomly generated haplotypes, and also haplotypes created from real gene sequences.</p>
<p>There are no metagenomic data sets with rich haplotype level annotations. We chose to use synthetic data sets to evaluate our framework under known, controllable conditions, and to afford us the ability to actually quantify the accuracy of recovered haplotypes from a metahaplome.</p>
<p>In this section, we provide an overview of the methods to generate metahaplomes for both random haplotypes, and haplotypes based on real genes. We describe our approach for evaluation of our work. In our Results, we demonstrate the effectiveness and limitations of our framework.</p>
</sec>
<sec id="s6e">
<title>Synthetic metahaplomes</title>
<p>With the desire to first test our approach on data that was as simple as possible, we generated small, synthetic metahaplomes which contain a known number of randomly generated haplotypes, each of the same fixed length. Every position on the haplotype is regarded as a site of variation. Each of the random haplotypes in the metahaplome is permitted to select any of the four base pairs at random, for each genomic position. An arbitrary haplotype is drawn from the metahaplome and chosen to be the &#x2018;pseudoreference&#x2019;. We generate short reads from the other remaining haplotype sequences, each read is between 3&#x2013;5bp (thus, 3&#x2013;5 SNPs). These reads are constructed by sliding a window along each haplotype, whilst also varying the size, and overlap of those windows in an attempt to introduce some element of realism to the data.</p>
<p>As we know the location and width of each such window, we can append synthetic alignments to a SAM file without having to invoke an actual aligner. This is particularly important, given that the randomly generated haplotypes represent strings of SNPs and exhibit low sequence identity between one another. Combined with their very short nature, this prevents alignment tools from assisting us with generating an alignment format for input to our algorithm on such data. The majority of sites are tri- or tetra-alleleic and so for the same reason, the VCF is produced by our metahaplome generator, rather than an established diploid-assuming SNP caller. Both a SAM alignment, and a VCF are generated by our tool, circumventing the assumptions and biases of real aligners and SNP callers.</p>
<p>We detail the parameters and options of our metahaplome generator in the supplementary materials. The code is open source and freely available via our data and testing repository, online: <ext-link ext-link-type="uri" xlink:href="https://github.com/samstudio8/gretel-test">https://github.com/samstudio8/gretel-test</ext-link></p>
</sec>
<sec id="s6f">
<title>DHFR and AIMP1</title>
<p>We chose an arbitrary DHFR and AIMP1 gene from GenBank to serve as the &#x2018;master&#x2019; sequence (<italic>i.e</italic>. the pseudo-reference) for their respective metahaplomes.</p>
<p>A discontinuous megaBLAST was conducted for both of the DHFR and AIMP1 masters. From each, a set of five related but arbitrary genes of decreasing sequence identity (DHFR:&#x2248; 99.8&#x0025;, 97&#x0025;, 93&#x0025;, 90&#x0025;, 83&#x0025; and AIMP1: &#x2248; 99.9&#x0025;, 99.6&#x0025;, 99.3&#x0025;, 92&#x0025;, 91&#x0025;) were selected.</p>
<p>Each of the five genes were broken into reads with a uniform size and overlap. Resulting reads were aligned back to the master with <monospace>bowtie2</monospace>. Variants were called on the alignment with a script that determined all non-uniallelic locations as SNPs. The DHFR data yielded between 65&#x2013;90 SNPs per 564bp metahaplome, the AIMP1 data yielded 60&#x2013;75 SNPs per 939bp metahaplome.</p>
<p>For testing, multiple DHFR and AIMP1 metahaplomes were generated. The read size was uniform and haplotype recovery was measured for metahaplomes populated with reads of size 60, 75, 90 and 120. Per-haplotype coverage was estimated by dividing the average coverage observed by <monospace>samtools depth</monospace>, by the number of input haplotypes. Per-haplotype coverage was adjusted by increasing or decreasing the overlap of the reads.</p>
<p>Quantification of recovery rate proved much more difficult for data yielded from discontinuous searches. The current implementations of <monospace>Hansel</monospace> and <monospace>Gretel</monospace> is gap agnostic. Reads with insertions or deletions are handled by parsing their BAM CIGAR strings and adjusting the nucleotide that appears at the SNP sites that follow accordingly. However, although with this method the SNP is technically correct, information about the size and location of the gap is lost. Thus when the recovered haplotypes are written to FASTA, they are gapless. Testing input and output haplotypes base-for-base is therefore not possible, any gap in the input haplotype will be ignored and <monospace>Gretel</monospace>&#x2019;s performance will be reported poorly, even if the SNPs themselves are all correct (but in the wrong position).</p>
<p>We define the haplotype recovery rate from the DHFR and AIMP1 metahaplomes by BLAST. The known input genes are used as queries against a BLAST database constructed from the newly recovered output haplotypes from <monospace>Gretel</monospace>. For each input gene, the best output haplotype is defined as the path with the best BLAST hit, determined by bit score. In our Results, we report the proportion of SNPs that are correctly recovered on each gene&#x2019;s best output haplotype.</p>
</sec>
<sec id="s6g">
<title>FLU-A7</title>
<p>A data set of 772 Influenza A (Segment 7) sequences were obtained from GenBank, requesting any sequences deposited from July 1st 2016 to July 25th 2016. After removing a majority of duplicate sequences, 72 sequences, of mean length 1009bp remained. One sequence was randomly selected as our pseudo-assembly. The remaining 71 sequences were aligned to the master and sharded into synthetic reads via the same method as described in our Methods for the DHFR and AIMP1 metahaplomes. SNPs were called in the same way, determining any site without a unanimous consensus as a variant site. Regardless of parameters provided to the read generator, there were typically at least 250 SNPs observed over the 982bp metahaplome. We designate the data set <italic>FLU-A7</italic>.</p>
</sec>
<sec id="s6h">
<title>Ranking haplotypes recovered from a metagenome</title>
<p>Of course, with knowledge of the input haplotypes that we expect to recover, we are able to quantify our approach. For real metahaplomes, we need a mechanism to differentiate false positives, or rank our confidence in the returned haplotypes.</p>
<p>Future work will investigate this in more depth, but currently, in addition to the sequences themselves, <monospace>Gretel</monospace> outputs a &#x2018;crumbs&#x2019; file &#x2014; a whimsical name for a simple, tab delimited format &#x2014; contains metadata for each of the recovered sequences: log probability of that sequence existing given the evidence seen overall, how much of the evidence in <monospace>Hansel</monospace> that particular sequence was supported by, and how much of that evidence was re-weighted as a result of that path being chosen.</p>
<p>Currently, <monospace>Gretel</monospace> will continuously recover paths out of the remaining evidence until it encounters a node from which there is no evidence that can inform the next decision.</p>
</sec>
</sec>
</body>
<back>
<sec>
<title>Data Access</title>
<p>Our Hansel and Gretel framework is freely available, open source software available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/samstudio8/hansel">https://github.com/samstudio8/hansel</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/samstudio8/gretel">https://github.com/samstudio8/gretel</ext-link>, respectively.</p>
<p>The scripts used to generate metahaplomes and synthetic reads for both the randomly generated and real-gene haplotypes, and the testing data used to evaluate our methods is also available online via <ext-link ext-link-type="uri" xlink:href="https://github.com/samstudio8/gretel-test">https://github.com/samstudio8/gretel-test</ext-link></p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>CJC was funded by the Biotechnology and Biological Sciences Research Council (BBSRC) Institute Strategic Programme Grant, Rumen Systems Biology, (BB/E/W/10964A01). WA is funded through the Coleg Cymraeg Cenedlaethol Academic staffing scheme. SN is funded via the Aberystwyth University Doctoral Career Development Scholarship and the IBERS Doctoral Programme.</p>
</ack>
<sec id="s8">
<title>Disclosure Declaration</title>
<p>The authors have no conflict of interest to declare.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="other"><string-name><surname>Aguiar</surname>, <given-names>D.</given-names></string-name>, <year>2014</year>. <source>HapCompass manual</source>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Aguiar</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Istrail</surname>, <given-names>S.</given-names></string-name>, <year>2012</year>. <article-title>HapCompass: a fast cycle basis algorithm for accurate haplotype assembly of sequence data</article-title>. <source>Journal of Computational Biology</source>, <volume>19</volume>(<issue>6</issue>):<fpage>577</fpage>&#x2013;<lpage>590</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Aguiar</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Istrail</surname>, <given-names>S.</given-names></string-name>, <year>2013</year>. <article-title>Haplotype assembly in polyploid genomes and identical by descent shared tracts</article-title>. <source>Bioinformatics</source>, <volume>29</volume>(<issue>13</issue>):<fpage>i352</fpage>&#x2013;<lpage>i360</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Ahn</surname>, <given-names>S.</given-names></string-name> and <string-name><surname>Vikalo</surname>, <given-names>H.</given-names></string-name>, <year>2015</year>. <article-title>Joint haplotype assembly and genotype calling via sequential Monte Carlo algorithm</article-title>. <source>BMC Bioinformatics</source>, <volume>16</volume>(<issue>1</issue>):<fpage>223</fpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bansal</surname>, <given-names>V.</given-names></string-name> and <string-name><surname>Bafna</surname>, <given-names>V.</given-names></string-name>, <year>2008</year>. <article-title>HapCUT: an efficient and accurate algorithm for the haplotype assembly problem</article-title>. <source>Bioinformatics</source>, <volume>24</volume>(<issue>16</issue>):<fpage>i153</fpage>&#x2013;<lpage>i159</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Buchfink</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Xie</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Huson</surname>, <given-names>D. H.</given-names></string-name>, <year>2015</year>. <article-title>Fast and sensitive protein alignment using DIAMOND</article-title>. <source>Nature Methods</source>, <volume>12</volume>:<fpage>59</fpage>&#x2013;<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>DePristo</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Banks</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Poplin</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Garimella</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Maguire</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hartl</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Philippakis</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>del Angel</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rivas</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Hanna</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal>, <year>2011</year>. <article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title>. <source>Nature Genetics</source>, <volume>43</volume>:<fpage>491</fpage>&#x2013;<lpage>498</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="other"><string-name><surname>Garrison</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal>, <year>2016</year>. <article-title>vg: the variation graph toolkit</article-title>. <ext-link ext-link-type="uri" xlink:href="https://github.com/vgteam/vg">https://github.com/vgteam/vg</ext-link>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Geraci</surname>, <given-names>F.</given-names></string-name>, <year>2010</year>. <article-title>A comparison of several algorithms for the single individual SNP haplotyping reconstruction problem</article-title>. <source>Bioinformatics</source>, <volume>26</volume>(<issue>18</issue>):<fpage>2217</fpage>&#x2013;<lpage>2225</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Gibbs</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Belmont</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Hardenbol</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Willis</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ch&#x2019;ang</surname>, <given-names>L.-Y.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Shen</surname>, <given-names>Y.</given-names></string-name>, <etal>et al.</etal>, <year>2003</year>. <article-title>The international HapMap project</article-title>. <source>Nature</source>, <volume>426</volume>(<issue>6968</issue>):<fpage>789</fpage>&#x2013;<lpage>796</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Iqbal</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Caccamo</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Flicek</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>McVean</surname>, <given-names>G.</given-names></string-name>, <year>2012</year>. <article-title>De novo assembly and genotyping of variants using colored de bruijn graphs</article-title>. <source>Nature genetics</source>, <volume>44</volume>(<issue>2</issue>):<fpage>226</fpage>&#x2013;<lpage>232</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Lancia</surname>, <given-names>G.</given-names></string-name>, <year>2016</year>. <article-title>Algorithmic approaches for the single individual haplo-typing problem</article-title>. <source>RAIRO-Operations Research</source>, <volume>50</volume>(<issue>2</issue>):<fpage>331</fpage>&#x2013;<lpage>340</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><string-name><surname>Lancia</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Bafna</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Istrail</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lippert</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Schwartz</surname>, <given-names>R.</given-names></string-name>, <year>2001</year>. <chapter-title>SNPs problems, complexity, and algorithms</chapter-title>. <source>In Algorithms&#x2014;ESA 2001</source>, pages <fpage>182</fpage>&#x2013;<lpage>193</lpage>. <publisher-name>Springer</publisher-name>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Langmead</surname>, <given-names>B</given-names></string-name>. and S., S., <year>2012</year>. <article-title>Fast gapped-read alignment with Bowtie 2</article-title>. <source>Nature Methods</source>, <volume>9</volume>:<fpage>357</fpage>&#x2013;<lpage>359</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Handsaker</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wysoker</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fennell</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ruan</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Homer</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Marth</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Abecasis</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Durbin</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Subgroup</surname>, <given-names>G. P. D. P.</given-names></string-name>, <etal>et al.</etal>, <year>2009</year>. <article-title>The sequence alignment/map (SAM) format and SAMtools</article-title>. <source>Bioinformatics</source>, <volume>25</volume>:<fpage>2078</fpage>&#x2013;<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>J. H.</given-names></string-name>, and <string-name><surname>Waterman</surname>, <given-names>M. S.</given-names></string-name>, <year>2004</year>. <article-title>Haplotype reconstruction from SNP alignment</article-title>. <source>Journal of Computational Biology</source>, <volume>11</volume>(<issue>2&#x2013;3</issue>):<fpage>505</fpage>&#x2013;<lpage>516</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Lippert</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Schwartz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Lancia</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Istrail</surname>, <given-names>S.</given-names></string-name>, <year>2002</year>. <article-title>Algorithmic strategies for the single nucleotide polymorphism haplotype assembly problem</article-title>. <source>Briefings in Bioinformatics</source>, <volume>3</volume>(<issue>1</issue>):<fpage>23</fpage>&#x2013;<lpage>31</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Namiki</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Hachiya</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Tanaka</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Sakakibara</surname>, <given-names>Y.</given-names></string-name>, <year>2012</year>. <article-title>MetaVelvet: An extension of Velvet assembler to de novo metagenome assembly from short sequence reads</article-title>. <source>Nucleic Acids Res</source>, <volume>40</volume>(<issue>20</issue>):<fpage>e155</fpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="confproc"><string-name><surname>Panconesi</surname>, <given-names>A.</given-names></string-name> and <string-name><surname>Sozio</surname>, <given-names>M.</given-names></string-name>, <year>2004</year>. <article-title>Fast hare: A fast heuristic for single individual SNP haplotype reconstruction</article-title>. <conf-name>In International Workshop on Algorithms in Bioinformatics</conf-name>, pages <fpage>266</fpage>&#x2013;<lpage>277</lpage>. <conf-loc>Springer</conf-loc>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>R.-S.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>L.-Y.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>X.-S.</given-names></string-name>, and <string-name><surname>Chen</surname>, <given-names>L.</given-names></string-name>, <year>2006</year>. <article-title>A markov chain model for haplotype assembly from SNP fragments</article-title>. <source>Genome Informatics</source>, <volume>17</volume>(<issue>2</issue>):<fpage>162</fpage>&#x2013;<lpage>171</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Zerbino</surname>, <given-names>D. R.</given-names></string-name> and <string-name><surname>Birney</surname>, <given-names>E.</given-names></string-name>, <year>2008</year>. <article-title>Velvet: algorithms for de novo short read assembly using de Bruijn graphs</article-title>. <source>Genome Research</source>, <volume>18</volume>:<fpage>821</fpage>&#x2013;<lpage>829</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Kim</surname>, <given-names>S.-K.</given-names></string-name>, <year>2010</year>. <article-title>Research and application of marine microbial enzymes: status and prospects</article-title>. <source>Marine drugs</source>, <volume>8</volume>(<issue>6</issue>):<fpage>1920</fpage>&#x2013;<lpage>34</lpage>.</mixed-citation></ref>
</ref-list>
<sec id="s9" sec-type="supplementary-material">
<label>1</label>
<title>Supplementary Materials</title>
<sec id="s9a">
<label>1.1</label>
<title>Hansel as a graph</title>
<p>Consider an alphabet of symbols, &#x03A3; (<italic>e.g.</italic> &#x007B;<italic>A, C, G, T</italic>&#x007D;) and a list of <italic>m</italic> SNP positions 1..<italic>m</italic>. As described in our article, the <monospace>Hansel</monospace> structure <italic>H</italic> can be considered as a graph <italic>G</italic> &#x003D; (<italic>V, E</italic>). Here, we define <italic>V</italic>, and <italic>E</italic>:
<disp-formula id="eqn1">
<alternatives>
<graphic xlink:href="067215_eqn1.gif"/>
</alternatives>
</disp-formula>
<disp-formula id="eqn2">
<alternatives>
<graphic xlink:href="067215_eqn2.gif"/>
</alternatives>
</disp-formula></p>
<p><italic>V</italic>, the set of nodes (or vertices), containing an element for all pairings of a symbol in the alphabet, and position where at least one read contains that symbol at <italic>i</italic>, and has coverage for at least <italic>i</italic> &#x002B; 1.</p>
<p><italic>E</italic>, the set of edges, where an edge (<italic>A<sub>i</sub>, B</italic><sub><italic>i</italic>&#x002B;1</sub>) is determined to exist in <italic>E</italic> if there exists at least one read whereby symbol <italic>A</italic> was observed at position <italic>i</italic> to co-occur with symbol <italic>B</italic> at SNP position <italic>i</italic> &#x002B; 1.</p>
<p>It should be noted, that although <italic>G</italic> can be constructed from <italic>H</italic> such that it is undirected and contains cycles, both properties lead to nonsensical haplotypes. Under such circumstances, <monospace>Gretel</monospace> could construct a path that visits multiple nodes that appear at the same <italic>i</italic>, or a trail that visits the same node multiple times. Such sequences would be meaningless in the context of haplotype construction, thus the interface to <monospace>Hansel</monospace> acts in such a way, that <italic>G</italic> is a directed, acyclic graph.</p>
<p>We can define a haplotype as an alternating sequence of nodes (<italic>&#x03C5;</italic> &#x2208; <italic>V</italic>) and edges (<italic>e</italic> &#x2208; <italic>E</italic>). A path must always start and end at the special sentinel symbols <italic>&#x2205;<sub>S</sub></italic> and <italic>&#x2205;<sub>E</sub></italic>, respectively.</p>
<disp-formula id="eqn3">
<alternatives>
<graphic xlink:href="067215_eqn3.gif"/>
</alternatives>
</disp-formula>
<p>Although, as only one directed edge between some <italic>&#x03C5;<sub>i</sub></italic> and <italic>&#x03C5;</italic><sub><italic>i</italic>&#x002B;1</sub> may exist, we can define <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="067215_inline1.gif"/></alternatives></inline-formula> simply as a sequence of <italic>&#x03C5;</italic> &#x2208; <italic>V</italic>:
<disp-formula id="eqn4">
<alternatives>
<graphic xlink:href="067215_eqn4.gif"/>
</alternatives>
</disp-formula></p>
</sec>
<sec id="s9b">
<label>1.2</label>
<title>Probabilistic edge weights</title>
<p>However, as we described in our paper if the construction of <italic>G</italic> does not consider elements in <italic>H</italic>[<italic>A,B,i,j</italic>] where <italic>abs</italic>(<italic>i &#x2212; j</italic>) &#x003E; 1 it is likely one will recover haplotypes that do not actually exist.</p>
<p>Given the pairwise information available in <italic>H</italic>, for both adjacent, and non-adjacent SNPs, across all reads, we described that edges in the graph <italic>G</italic> derived from <italic>H</italic> can be weighted probabilistically.</p>
<p>We attempt to determine the next most likely symbol in a sequence, considering both the marginal distribution of symbols at the next position and the likelihood of those symbols appearing next, given an already observed partial sequence into account.</p>
<p>That is, the next symbol <italic>&#x03C5;</italic><sub><italic>i</italic>&#x002B;1</sub> in a path depends not only on the current symbol (<italic>&#x03C5;<sub>i</sub></italic>) but some number of previous symbols (<italic>&#x03C5;<sub>i&#x2212;1</sub>,&#x03C5;<sub>i&#x2212;2</sub>&#x2026;&#x03C5;<sub>0</sub></italic>).</p>
<p>The outgoing edges from <italic>&#x03C5;<sub>i</sub></italic> are probabilistically weighted by exploiting the observations stored in the <monospace>Hansel</monospace> structure to create probabilities, that then determine the likelihood of moving from some <italic>&#x03C5;<sub>i</sub></italic> to each of the possible <italic>&#x03C5;</italic><sub><italic>i</italic>&#x002B;1</sub>.</p>
<p>We take a Bayesian approach to the problem of probabilistically weighting edges in <monospace>Hansel</monospace>&#x2019;s graph representation. We define the probability of selecting <italic>&#x03C5;</italic><sub><italic>i</italic>&#x002B;1</sub>, conditioned on the path observed so far:
<disp-formula id="eqn5">
<alternatives>
<graphic xlink:href="067215_eqn5.gif"/>
</alternatives>
</disp-formula></p>
</sec>
<sec id="s9c">
<label>1.3</label>
<title>Simplification of conditional edge weights</title>
<p>Clearly, the number of factors in <xref ref-type="disp-formula" rid="eqn5">Equation 5</xref> increases with <italic>i</italic>. For longer paths (more single nucleotide polymorphisms detected along the target region of interest), evaluating the equation becomes more computationally expensive, and risks potentially compounding estimation errors.</p>
<p>To construct a whole path <italic>p</italic> from <italic>&#x03C5;</italic><sub>1</sub>&#x2026;<italic>&#x03C5;<sub>m</sub></italic>, the upper bound for the number of iterations will be |&#x03A3;| &#x00D7; <italic>m</italic> with calculations becoming increasingly complex as <italic>i</italic> increases.</p>
<p>To reduce complexity, we make an assumption of conditional independence between variants. Whilst this seems counter intuitive, the Naive Bayes model can deliver robust results despite its coarse assumption.</p>
<p>Thus we may simplify our previous equation and consider only the pairwise appearances of each <italic>&#x03C5;<sub>i</sub></italic> encountered thus far against <italic>&#x03C5;</italic><sub><italic>i</italic>&#x002B;1</sub>.</p>
<disp-formula id="eqn6">
<alternatives>
<graphic xlink:href="067215_eqn6.gif"/>
</alternatives>
</disp-formula>
<p>However as discussed in our article, reads will not cover all SNP positions 1.. <italic>m</italic> (if they did, we would not have to define this problem). Thus, we need not consider all variants in the current path when evaluating edge weights. Instead, we could limit the number of variants to consider, starting from the head of the path:
<disp-formula id="eqn7">
<alternatives>
<graphic xlink:href="067215_eqn7.gif"/>
</alternatives>
</disp-formula></p>
<p>We define <italic>L</italic> as the the &#x2018;lookback&#x2019; size, the number of variants of the current path to consider when selecting <italic>&#x03C5;</italic><sub><italic>i</italic>&#x002B;1</sub>. Conveniently, there is a reasonable intuition available for selecting a value for <italic>L</italic>: the mean number of SNP sites covered by the observed reads. Thus we avoid the scenario of introducing an algorithmically influential but mysterious parameter, such as <italic>k</italic>-mer size for metagenomic assembly.</p>
</sec>
<sec id="s9d">
<label>1.4</label>
<title>Estimation of pairwise conditional probabilities</title>
<p>We must still devise a method to calculate the components of <xref ref-type="disp-formula" rid="eqn7">Equation 7</xref>. We present the following approximations, inspired by the Bag of Words model, commonly implemented in text classification domains (such as a spam filters).</p>
<disp-formula id="eqn8">
<alternatives>
<graphic xlink:href="067215_eqn8.gif"/>
</alternatives>
</disp-formula>
<disp-formula id="eqn9">
<alternatives>
<graphic xlink:href="067215_eqn9.gif"/>
</alternatives>
</disp-formula>
</sec>
<sec id="s9e">
<label>1.5</label>
<title>Smoothing</title>
<p>To avoid the possibility of dividing by 0 in cases of <xref ref-type="disp-formula" rid="eqn9">Equation 9</xref> where a suitable read spanning <italic>i</italic> and <italic>j</italic> &#x003D; <italic>&#x03B2;</italic> does not exist, we apply Laplace smoothing to effectively add a dummy support read. Future work will investigate alternative smoothing methodology.</p>
<disp-formula id="eqn10">
<alternatives>
<graphic xlink:href="067215_eqn10.gif"/>
</alternatives>
</disp-formula>
</sec>
<sec id="s9f">
<label>1.6</label>
<title>Re-weighting</title>
<p>The paths generated by <monospace>Gretel</monospace> are probabilistic, but not stochastic. For a given <italic>H</italic>, <monospace>Gretel</monospace> will always return the same path. Since it is the elements of <italic>H</italic> that effectively drive traversal of <italic>G</italic>, we can perform some form of post-path generation transformation of <italic>H</italic> to prevent repetitive generation of the same path and return the next most likely path on the next iteration instead.</p>
<p>Given a path <italic>p</italic>, we inspect the marginal distribution of each variant for all <italic>i</italic> &#x2208; 1..<italic>m</italic> (<italic>i.e</italic>. the probability of selecting the same variant if we were looking at the site in isolation), and determine the smallest marginal. <monospace>Gretel</monospace> iterates over each variant <italic>p</italic>[<italic>i</italic>] in the path, and uses the Hansel interface to re-weight the element <italic>H</italic>[<italic>p</italic>[<italic>i</italic>],<italic>p</italic>[<italic>i</italic> &#x002B; 1],<italic>i,i</italic> &#x002B; 1] by subtracting the result of multiplying the smallest marginal by the original value for the observation:
<disp-formula id="eqn11">
<alternatives>
<graphic xlink:href="067215_eqn11.gif"/>
</alternatives>
</disp-formula>
<disp-formula id="eqn12">
<alternatives>
<graphic xlink:href="067215_eqn12.gif"/>
</alternatives>
</disp-formula></p>
</sec>
</sec>
<fn-group>
<fn id="fn1"><label>1</label><p>A phrase that did not seem to catch on in the literature</p></fn>
</fn-group>
</back>
</article>