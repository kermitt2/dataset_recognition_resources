<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/334292</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Limited One-time Sampling Irregularity Age Map (LOTS-IAM): Automatic Unsupervised Detection of Brain White Matter Abnormalities in Structural Magnetic Resonance Images</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1672-9149</contrib-id>
<name>
<surname>Rachmadi</surname>
<given-names>Muhammad Febrian</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2771-6546</contrib-id>
<name>
<surname>Vald&#x00E9;s-Hern&#x00E1;ndez</surname>
<given-names>Maria del C.</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Hongwei</given-names>
</name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moreno</surname>
<given-names>Ricardo Enrique Guerrero</given-names>
</name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Jianguo</given-names>
</name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rueckert</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Komura</surname>
<given-names>Taku</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<aff id="a1"><label>a</label><institution>School of Informatics, University of Edinburgh</institution>, Edinburgh, <country>UK</country></aff>
<aff id="a2"><label>b</label><institution>Centre for Clinical Brain Sciences, University of Edinburgh</institution>, Edinburgh, <country>UK</country></aff>
<aff id="a3"><label>c</label><institution>Computing, School of Science and Engineering, University of Dundee</institution>, Dundee, <country>UK</country></aff>
<aff id="a4"><label>d</label><institution>Department of Computing, Imperial College London</institution>, London, <country>UK</country></aff>
</contrib-group>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>334292</elocation-id>
<history>
<date date-type="received">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="334292.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>We propose a novel unsupervised approach of detecting and segmenting white matter abnormalities, using limited one-time sampling irregularity age map (LOTS-IAM). LOTS-IAM is a fully automatic unsupervised approach to extract brain tissue irregularities in magnetic resonance images (MRI) (<italic>e.g</italic>. T2-FLAIR white matter hyperintensities (WMH)). In this study, the limited one-time sampling scheme is proposed and implemented on GPU. We compared the performance of LOTS-IAM in detecting and segmenting WMH, with three unsupervised methods; the original IAM, one-time sampling IAM (OTS-IAM) and Lesion Growth Algorithm from public toolbox Lesion Segmentation Toolbox (LST-LGA), and two conventional supervised machine learning algorithms; support vector machine (SVM) and random forest (RF). Furthermore, we also compared LOTS-IAM&#x2019;s performance with five supervised deep neural networks algorithms; deep Boltzmann machine (DBM), convolutional encoder network (CEN), and three convolutional neural network (CNN) schemes: the 2D implementation of DeepMedic with the addition of global spatial information (2D-CNNGSI), patch-uResNet and patch-uNet. Based on our experiments, LOTS-IAM outperformed LST-LGA, the <italic>state-of-the-art</italic> of unsupervised WMH segmentation method, both in performance and processing speed. Our method also outperformed supervised conventional machine learning algorithms SVM and RF, and supervised deep neural networks algorithms DBM and CEN.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>white matter hyperintensities</kwd>
<kwd>lesion segmentation</kwd>
<kwd>unsupervised segmentation</kwd>
<kwd>dementia</kwd>
<kwd>MRI</kwd>
<kwd>voxel-based irregularity age map</kwd>
</kwd-group>
<counts>
<page-count count="15"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<p>White matter hyperintensities (WMH) are a common brain abnormality found in magnetic resonance imaging from patients with dementia/Alzheimer&#x2019;s Disease and other brain pathologies such as stroke and multiple sclerosis. WMH can be easily seen in the T2-Fluid Attenuation Inversion Recovery (FLAIR) as they appear brighter than the normal brain tissues. It is believed that WMH are associated with the progression of dementia (<xref ref-type="bibr" rid="c22">Wardlaw et al., 2013</xref>) and other comorbidities. Hence, not surprisingly, there have been many studies on methods for detecting or segmenting WMH automatically.</p>
<p>Supervised machine learning algorithms such as support vector machine (SVM), random forest (RF) (<xref ref-type="bibr" rid="c6">Ithapu et al., 2014</xref>) and deep learning convolutional neural network schemes, e.g. DeepMedic (<xref ref-type="bibr" rid="c8">Kamnitsas et al., 2017</xref>; <xref ref-type="bibr" rid="c15">Rachmadi et al., 2017a</xref>), uNet (<xref ref-type="bibr" rid="c17">Ronneberger et al., 2015</xref>; <xref ref-type="bibr" rid="c9">Li et al., 2018</xref>) and uResNet (<xref ref-type="bibr" rid="c4">Guerrero et al., 2018</xref>) have emerged as the <italic>state-of-the-art</italic> machine learning algorithms for automatic WMH segmentation. However, all supervised methods are highly dependent on manual labels produced by experts (<italic>i.e</italic>., physicians) for training process. Furthermore, the quality of the label itself is dependent on and varies according to expert&#x2019;s skill and opinion, which rises questions about reproducibility in different sets of data. These intra/inter-observer inconsistencies usually are quantified and reported, but this does not solve the problem.</p>
<p>Unsupervised machine learning algorithms which do not need manual labels to work can eliminate the aforementioned dependency. Methods such as Lesion Growth Algorithm from Lesion Segmentation Tool toolbox (LST-LGA) (<xref ref-type="bibr" rid="c19">Schmidt et al., 2012</xref>) and Lesion-TOADS (<xref ref-type="bibr" rid="c20">Shiee et al., 2010</xref>) have been developed, tested in many studies and publicly available for unsupervised WMH segmentation. Unfortunately, their performance is very limited compared to that from the supervised ones (<xref ref-type="bibr" rid="c6">Ithapu et al., 2014</xref>; <xref ref-type="bibr" rid="c15">Rachmadi et al., 2017a</xref>).</p>
<p>A newly proposed unsupervised method named irregularity age map (IAM) (<xref ref-type="bibr" rid="c16">Rachmadi et al., 2017b</xref>) has been proposed and reported to work better than LST-LGA, which is still the most commonly used method and the <italic>state-of-the-art</italic> for unsupervised WMH segmentation. However, its use is still limited because IAM&#x2019;s computation takes a lot of time to complete, and the original study of IAM was only quantitatively validated on 20 different MRI data without any comparison with supervised machine learning algorithms. This study expands the evaluation by using a bigger dataset with longitudinal data and comparing the performance of this new method not only with well-known, but also with state-of-art supervised machine learning algorithms.</p>
<p>In summary, the main contributions of this study are:</p>
<list list-type="order">
<list-item><p>Proposing a new approach named limited onetime sampling IAM (LOTS-IAM) which is faster than the original IAM.</p></list-item>
<list-item><p>Proposing a new post-processing step to improve LOTS-IAM&#x2019;s performance.</p></list-item>
<list-item><p>Full evaluation of LOTS-IAM on 60 MRI longitudinal data from the Alzheimers Disease Neuroimaging Initiative (ADNI) database.</p></list-item>
<list-item><p>Full comparison of LOTS-IAM&#x2019;s performance with performances of the original IAM, LSTLGA, SVM, RF, DBM, CEN, a patch-based 2D CNN with global spatial information (GSI), patch-uResNet and patch-uNet.</p></list-item>
</list>
</sec>
<sec id="s2">
<label>2.</label>
<title>Irregularity Age Map</title>
<p>The irregularity age map (IAM) approach for WMH assessment on brain MRI was proposed previously (<xref ref-type="bibr" rid="c16">Rachmadi et al., 2017b</xref>). It is based on a previous work in computer graphics (<xref ref-type="bibr" rid="c1">Bellini et al., 2016</xref>) to detect aged or wandered regions in texture images. The term &#x201C;age map&#x201D; is used to name the 2D array with values between 0 and 1 that denotes irregularities in textures dubbed as <italic>age values</italic>. The closer the value to 1, the more probable the image voxel is to belong to a group of clusters with different texture from that considered as the &#x201C;norm&#x201D;. The age map can be calculated using, instead, structural MRI, to detect abnormal regions within normal tissue. For this process, four steps are necessary: 1) preparation of the regions of interest where the algorithm will work (e.g. brain tissue mask), 2) patch generation, 3) age value calculation and 4)final age map generation. These four steps are visualised in <xref rid="fig1" ref-type="fig">Fig. 1</xref>. Steps 2 to 4 are executed slice by slice (<italic>i.e.</italic> in 2D).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Flow of the proposed LOTS-IAM-GPU. <bold>1) Pre-processing</bold>: brain tissues only T2-FLAIR MRI slice is generated from the original T2-FLAIR MRI and its corresponding brain masks (<italic>i.e</italic>., ICV and CSF). <bold>2) LOTS-IAM</bold>: the brain tissues only T2-FLAIR MRI slice is processed through the LOTS-IAM algorithm on GPU. <bold>3) Post-processing</bold>: final age map of the corresponding input MRI slice is produced after post-processing step, which is optional.</p></caption>
<graphic xlink:href="334292_fig1.tif"/>
</fig>
<p>For brain MRI scans, the brain tissue mask is necessary to exclude non-brain tissues not needed in the calculation of IAM and which can represent &#x201C;irregularities&#x201D; <italic>per se</italic>; for example skull, cerebrospinal fluid, veins and meninges. We want to compare and identify brain tissues within other brain tissues, not skull or other parts of non-brain tissues. For this purpose we use two binary masks: intracranial volume (ICV) and cerebrospinal fluid (CSF) masks. The ICV mask is generated by using optiBET (<xref ref-type="bibr" rid="c11">Lutkenhoff et al., 2014</xref>) while the CSF mask is generated by using and in-house algorithm developed by The University of Edinburgh (<xref ref-type="bibr" rid="c21">Vald&#x00E9;s Hern&#x00E1;ndez et al., 2015</xref>).</p>
<p>Patch generation is performed by dividing an MRI slice into non-overlapping grid-patches called <italic>source patches</italic> and randomly-sampling patches called <italic>target patches</italic>, which can overlap. The rationale for this patch generation is; if we successfully sample <italic>target patches</italic> mostly from normal brain tissues and do subtraction between a <italic>source patch</italic> and <italic>target patches</italic>, then irregular areas located within the <italic>source patch</italic> will produce a high value for the respective <italic>source patch</italic>. In this study, we use hierarchical subsets of four different sizes of source/target patch which are 1&#x00D7;1, 2&#x00D7;2, 4&#x00D7;4 and 8&#x00D7;8. Unlike in the original study on natural images where all possible target patches are used to produce the age map (<xref ref-type="bibr" rid="c1">Bellini et al., 2016</xref>), we use a set of randomly sampled target patches to fasten the computation.</p>
<p>Age value calculation is the core computation of the IAM where a distance value called <italic>age value</italic> is computed by using the function defined below. Let <bold>s</bold> be a source patch and <bold>t</bold> a target patch, the <italic>age value</italic> of the two patches <italic>d</italic> is:
<disp-formula id="eqn1">
<alternatives>
<graphic xlink:href="334292_eqn1.gif"/></alternatives>
</disp-formula>
where <italic>&#x03B1;</italic> &#x003D; 0.5 in this study. Both maximum and mean values of the subtracted patch are used to include maximum and average differences between source and target patches in calculation. Please note that source/target patches are matrices in the size of either 1&#x00D7;1, 2&#x00D7;2, 4&#x00D7;4 or 8&#x00D7;8. Also, please note that each <italic>source patch</italic> will be computed against a set of <italic>target patches</italic>, so each source patch has a set of age values. To get the final age value for one source patch, the corresponding set (<italic>i.e.</italic> to that source patch) of age values is sorted in ascending order and then the mean of the first 100 age values is calculated. The rationale is simple: the mean of the first 100 age values produced by and irregular source patch is still comparably higher than mean of the first 100 age values produced by normal source patches. All final age values from all source patches are then normalised from 0 to 1 real values to the create age map for one MRI slice. Examples of age maps generated by using four different sizes of source/target patches are shown in <xref rid="fig1" ref-type="fig">Fig. 1</xref></p>
<p>The final age map generation consists of three sub-steps, which are <italic>blending four age maps from age value calculation, penalty</italic> and <italic>global normalisation</italic>. <italic>Blending of four age maps</italic> is performed by using the following formulation:
<disp-formula id="eqn2">
<alternatives>
<graphic xlink:href="334292_eqn2.gif"/></alternatives>
</disp-formula>
where <italic>&#x03B1;</italic> &#x002B; <italic>&#x03B2;</italic> &#x002B; <italic>&#x03B3;</italic> &#x002B; <italic>&#x03B4;</italic> is equal to 1 and <italic>AM</italic><sub>1</sub>, <italic>AM</italic><sub>2</sub>, <italic>AM</italic><sub>4</sub> and <italic>AM</italic><sub>8</sub> are age maps from 1&#x00D7;1, 2&#x00D7;2, 4&#x00D7;4 and 8&#x00D7;8 source/target patches. In this study, <italic>&#x03B1;</italic> &#x003D; 0.65, <italic>&#x03B2;</italic> &#x003D; 0.2, <italic>&#x03B3;</italic> &#x003D; 0.1 and <italic>&#x03B4;</italic> &#x003D; 0.05 as weight blending parameters. Before the blending, age maps resulted from different size of source/target patches are up-sampled to fit the original size of the MRI slice and then smoothed by using Gaussian filter. The blended age map is then <italic>penalised</italic> using formulation below:
<disp-formula id="eqn3">
<alternatives>
<graphic xlink:href="334292_eqn3.gif"/></alternatives>
</disp-formula>
where <italic>p</italic><sub><italic>i</italic></sub> is voxel from the blended age map, <italic>v</italic><sub><italic>i</italic></sub> is voxel from the original MRI and <italic>p</italic><sub><italic>o</italic></sub> is the penalised voxel. Lastly, all age maps from different MRI slices are normalised together to produce 0 to 1 probability values of each voxel to be an &#x201C;irregularity&#x201D;with respect to the normal brain tissue. We name this normalisation procedure <italic>global normalisation</italic>. Visualisations of age value calculation, blending, penalty and global normalisation are shown in <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
<p>Some important notes on the computation of the IAM are: 1) source and target patches need to have the same size within the hierarchical framework, 2) the centre of source/target patches need to be inside ICV and outside CSF masks at the same time to be included in age value calculation, 3) the slice which does not provide any source patch is skipped to fasten computation (i.e where no brain tissue is observed) and 4) preliminary studies have not reported a decrease in the performance of IAM with regards to the use of only a subset of target patches (<italic>i.e</italic>., randomly-sampled target patches).</p>
<sec id="s2a">
<label>2.1.</label>
<title>One-time sampling IAM</title>
<p>While the original IAM has been reported to work well for WMH segmentation, its computation takes long time because it performs one sampling process for each source patch, selecting different target patches per source patch. For clarity, we dubbed this scheme as <italic>multiple-time sampling</italic> (MTS) scheme. MTS scheme is performed in the original IAM to satisfy the condition that target patches should not be too close to the source patch (<italic>i.e</italic>., location based condition). MTS scheme makes every source patch to have its own set of target patches, so extra time to do sampling for each source patch is unavoidable.</p>
<p>To fasten the overall IAM&#x2019;s computation, we propose one-time sampling (OTS) scheme for IAM where target patches are randomly sampled only once for each MRI slice, hence abandoning the location based condition of the MTS. In other words, age values of all source patches from one slice will be computed against one (i.e. the same) set of target patches. We call this combination of OTS and IAM one-time sampling IAM (OTS-IAM).</p>
</sec>
<sec id="s2b">
<label>2.2.</label>
<title>Limited one-time sampling IAM</title>
<p>If the number of patches to be simultaneously manipulated is reduced, the OTS scheme enables the possibility of GPU implementation for IAM. Therefore we propose here to limit to a certain value the number of target patches randomly sampled from a slice. The original IAM and OTS-IAM, which run on CPUs, use an undefined large random number of target patches which could range from 10&#x0025; to 75&#x0025; of all possible target patches, depending on the size of the brain tissue in an MRI slice. We name our new scheme limited one-time sampling IAM or LOTS-IAM.</p>
<p>In this study, we tested 6 different numbers of target patch samples which are 2048, 1024, 512, 256, 128 and 64. Because it is possible for LOTSIAM to use less than 100 target patch samples, we also modified the number of samples to be used to calculate the mean for age values. For LOTS-IAM, the first 128, 128, 64, 32, 32 and 16 age values are used to calculate the mean of age values for 2048, 1024, 512, 256, 128 and 64 number of target patch samples respectively. Furthermore, limited number of samples in power of two eases GPU implementation, especially in GPU memory allocation, which is the case for LOTS-IAM.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>MRI Data, Other Machine Learning Algorithms and Experiment Setup</title>
<p>A set of 60 T2-Fluid Attenuation Inversion Recovery (T2-FLAIR) MRI data from 20 subjects from the ADNI database was used for evaluation. Each subject had three scans obtained in three consecutive years. All T2-FLAIR MRI sequences have the same dimension 256 &#x00D7; 256 &#x00D7; 35. Ground truth was produced semi-automatically by an expert in medical image analysis using the region-growing algorithm in the Object Extractor tool of Analyze<sup><italic>TM</italic></sup> software guided by the co-registered T1and T2weighted sequences. For more details of the dataset, please see (<xref ref-type="bibr" rid="c15">Rachmadi et al., 2017a</xref>) and data-share url<sup><xref ref-type="fn" rid="fn1">1</xref></sup> to access the dataset.</p>
<p>Data used in this study were obtained from the ADNI (<xref ref-type="bibr" rid="c12">Mueller et al., 2005</xref>) public database<sup><xref ref-type="fn" rid="fn2">2</xref></sup>. The ADNI was launched in 2003 as a publicprivate partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimers disease (AD). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found in here<sup><xref ref-type="fn" rid="fn2">3</xref></sup>.</p>
<p>We compare performances of LOTS-IAM with other machine learning algorithms that are commonly used for WMH segmentation; namely the original IAM, One-time Sampling IAM (OTSIAM), Lesion Growth Algorithm from Lesion Segmentation Tool (LST-LGA), support vector machine (SVM), random forest (RF), deep Boltzmann machine (DBM), convolutional encoder network (CEN), patch-based 2D CNN with global spatial information (2D patch-CNN-GSI), patch-uResNet and patch-uNet. LST-LGA (<xref ref-type="bibr" rid="c19">Schmidt et al., 2012</xref>) is the current <italic>state-of-the-art</italic> for unsupervised hyperintensities segmentation. SVM and RF are machine learning algorithms commonly used for WMH segmentation in several studies (<xref ref-type="bibr" rid="c15">Rachmadi et al., 2017a</xref>), and they are used in this study as representations of supervised conventional machine learning algorithms. On the other hand, DBM, CNN and U-Net based methods represent supervised deep learning algorithms which are commonly used in recent years for WMH segmentation. For clarity, we do not further elaborate in the implementation of these algorithms. All experiments&#x2019; setup (<italic>i.e</italic>., training/testing and algorithm&#x2019;s configurations) for SVM, RF, DBM and CEN algorithms are described in detail in (<xref ref-type="bibr" rid="c15">Rachmadi et al., 2017a</xref>). Whereas, experiments&#x2019; setup for the 2D Patch-CNN-GSI, patch-uResNet and patch-uNet follow previous studies of (<xref ref-type="bibr" rid="c14">Rachmadi et al., 2018</xref>), (<xref ref-type="bibr" rid="c4">Guerrero et al., 2018</xref>) and (<xref ref-type="bibr" rid="c9">Li et al., 2018</xref>) respectively.</p>
<p>The only pre-processing step before the computation of IAM/OTS-IAM/LOTS-IAM is the generation of the brain mask as per in the original IAM study (<xref ref-type="bibr" rid="c16">Rachmadi et al., 2017b</xref>). However, we newly propose in paper a post-processing step using the normal appearing white matter (NAWM) mask to exclude non-white matter area of the brain. NAWM masks were generated using the FSL-FLIRT tool (<xref ref-type="bibr" rid="c7">Jenkinson et al., 2002</xref>).</p>
<p>Dice similarity coefficient (DSC) (<xref ref-type="bibr" rid="c2">Dice, 1945</xref>), which measures similarity between ground truth and automatic segmentation results, is used here as the primary metric for comparison between algorithms. Higher DSC score means better performance, and the DSC score itself can be computed as follow:
<disp-formula id="eqn4">
<alternatives>
<graphic xlink:href="334292_eqn4.gif"/></alternatives>
</disp-formula>
where <italic>TP</italic> is true positive, <italic>FP</italic> is false positive and <italic>FN</italic> is false negative.</p>
<p>Non-parametric Spearman&#x2019;s correlation coefficient (<xref ref-type="bibr" rid="c13">Myers et al., 2010</xref>) is used in this study to compute correlation between WMH volume produced by each automatic methods and visual ratings of WMH. Visual ratings of WMH is commonly used in clinical world to describe severity of white matter diseases (<xref ref-type="bibr" rid="c18">Scheltens et al., 1993</xref>), and correlation between visual rating and volume of WMH has been known to be high (<xref ref-type="bibr" rid="c5">Hern&#x00E1;ndez et al., 2013</xref>). In this study, Fazekas&#x2019;s visual rating (<xref ref-type="bibr" rid="c3">Fazekas et al., 1987</xref>) and Longstreth&#x2019;s rating scales (<xref ref-type="bibr" rid="c10">Longstreth et al., 1996</xref>) are used for non-parametric evaluation of each automatic method. This non-parametric test is similar as in previous study (<xref ref-type="bibr" rid="c15">Rachmadi et al., 2017a</xref>).</p>
</sec>
<sec id="s4">
<label>4.</label>
<title>Experiments and Results</title>
<sec id="s4a">
<label>4.1.</label>
<title>General Experiments and Results</title>
<p>All methods are tested and evaluated by using the DSC metric (<italic>i.e</italic>., its mean and standard deviation in the sample), and training/testing time. The increase in speed performance is given with respect to the original IAM method, for comparison between IAM implementations. <xref rid="tbl1" ref-type="table">Table 1</xref> shows the overall results of the performance of all methods in our sample, including other information (e.g. nature of the method, MRI sequences used and number of patches). Please note that the original IAM is listed as IAM-CPU.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Algorithm&#x2019;s information and experiment results based on the Dice similarity coefficient (DSC) for each algorithm evaluated. <bold>Explanation of abbreviations</bold>: &#x201C;SPV/UNSPV&#x201D; for supervised/unsupervised, &#x201C;Deep Net.&#x201D; for deep neural networks algorithm, &#x201C;Y/N&#x201D; for Yes/No, &#x201C;T2F/T1W&#x201D; for T2-FLAIR/T1-weighted, &#x201C;#SMPs&#x201D; for number of target patches, &#x201C;#M-SMPs&#x201D; for number of target patches of which the mean for determining the age value is calculated, &#x201C;TRSH&#x201D; for optimum threshold and &#x201C;Train/Test&#x201D; for training/testing time. Given &#x201C;speed increase&#x201D; is relative to IAM-CPU.</p></caption>
<graphic xlink:href="334292_tbl1.tif"/>
</table-wrap>
<p>From <xref rid="tbl1" ref-type="table">Table 1</xref>, we can see that all IAM configurations (<italic>i.e</italic>., IAM-CPU, OTS-IAM-CPU and LOTSIAM-GPU methods) outperformed LST-LGA in mean DSC metric. Furthermore, we also can see that performances of IAM/OTS-IAM/LOTSIAM not only outperformed LST-LGA but also some other supervised machine learning algorithms (<italic>i.e</italic>., SVM, RF and DBM). Moreover, some LOTS-IAM-GPU implementations also successfully outperformed CEN. To see these results clearly, <xref rid="fig2" ref-type="fig">Figure 2</xref> graphically shows the mean DSC values for LST-LGA, SVM, RF, DBM, CEN, patch-uResNet, patch-uNet, 2D patch-CNN-GSI and LOTS-IAMGPU-512s64m for all possible threshold values to their probabilistic output.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Mean of dice similarity coefficient (DSC) score for LST-LGA, SVM, RF, DBM, CEN, patch-uResNet, patchuNet, 2D patch-CNN-GSI and LOTS-IAM-GPU-512s64m in respect to all possible threshold values. LOTS-IAM is represented by LOTS-IAM-GPU-512s64m.</p></caption>
<graphic xlink:href="334292_fig2.tif"/>
</fig>
<p>A visual example showing the performance of IAM and other segmentation methods such as 2D Patch-CNN (2D-DeepMedic), Patch-uNet, LSTLGA and Patch-uResNet are compared in <xref rid="fig3" ref-type="fig">Figure 3</xref> (raw) and <xref rid="fig4" ref-type="fig">Figure 4</xref> (cut off). <xref rid="fig5" ref-type="fig">Figure 5</xref> shows how LOTS-IAM could potentially be applied to characterise abnormalities using other MRI sequences, such as T1-weighted (T1W).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Visualisation of <bold>raw</bold> probabilistic values of WMH produced by LOTS-IAM compared to other methods, which are the 2D Patch-CNN (2D-DeepMedic), Patch-uNet, LST-LGA, and Patch-uResNet.</p></caption>
<graphic xlink:href="334292_fig3.tif"/>
</fig>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Visualisation of <bold>thresholded</bold> probabilistic values of WMH produced by LOTS-IAM compare to other methods, which are the 2D Patch-CNN (2D-DeepMedic), Patch-uNet (uNet based deep neural networks), LST-LGA, and Patch-uResNet. The probabilistic values are cut off by their respective optimum threshold values.</p></caption>
<graphic xlink:href="334292_fig4.tif"/>
</fig>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Example of how LOTS-IAM could be performed on both FLAIR and T1-weighted (T1W). Please note that the current version of LOTS-IAM is highly optimised for FLAIR modality of MRI, not T1W.</p></caption>
<graphic xlink:href="334292_fig5.tif"/>
</fig>
</sec>
<sec id="s4b">
<label>4.2.</label>
<title>IAM vs. OTS-IAM vs. LOTS-IAM</title>
<p>One-time sampling (OTS) and limited one-time sampling (LOTS) not only successfully fastened IAM&#x2019;s computation but also improved IAM&#x2019;s performance, as shown in <xref rid="tbl1" ref-type="table">Table 1</xref>. Implementation of IAM on GPU successfully fastened IAM&#x2019;s processing speed by 17 to 435 times with respect to the original IAM-CPU. However, it is worth stressing that this increase in processing speed was not only due to the use of GPU instead of CPU, but also depending on the number of target patch samples used in the IAM&#x2019;s computation. One of the GPU implementations of LOTS-IAM (<italic>i.e</italic>., LOTS-IAMGPU-64s16m) ran faster than LST-LGA. However, note that the testing time listed in <xref rid="tbl1" ref-type="table">Table 1</xref> excludes registrations and the generation of other brain masks used either in pre-processing or postprocessing steps. The increase in speed achieved by the GPU implementation of IAM shows the effectiveness of the LOTS implementation for IAM&#x2019;s computation and performance.</p>
</sec>
<sec id="s4c">
<label>4.3.</label>
<title>Speed vs. Quality Test</title>
<p>The biggest achievement of this work is the increase in processing speed achieved by the implementation of LOTS-IAM on GPU, compared to the original IAM and OTS-IAM. The first iteration of IAM can only be run on CPU because of the multiple-time sampling (MTS) process. Whereas, OTS-IAM uses a high number of target patches (<italic>i.e</italic>., 2,048 samples) to compute the age map. In this study, we show that using limited number of target patches leads to not only faster computation but also better quality of WMH segmentation in some cases. <xref rid="fig6" ref-type="fig">Figure 6</xref> illustrates the relation between speed and quality of the output produced by IAM, OTS-IAM and all configurations of LOTSIAM. Please note that <xref rid="fig6" ref-type="fig">Figure 6</xref> is extracted from <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><p>Speed (min) versus quality (Mean of DSC) of different settings of IAM methods (extracted from <xref rid="tbl1" ref-type="table">Table 1</xref>). By implementing IAM on GPU and limiting number of target patch samples, computation time and result&#x2019;s quality are successfully improved.</p></caption>
<graphic xlink:href="334292_fig6.tif"/>
</fig>
</sec>
<sec id="s4d">
<label>4.4.</label>
<title>IAM&#x2019;s Blending Weights Tests</title>
<p>In this experiment, different sets of blending weights in IAM&#x2019;s computation were evaluated. As previously discussed, the only parameters that IAM has are four weights used to blend the four age maps hierarchically produced for the final age map generation. We tested the 7 different sets of IAM&#x2019;s blending weights listed in <xref rid="tbl2" ref-type="table">Table 2</xref>. The first 3 sets blend all four age maps while the other 4 only use one of the age maps. The effect of different sets of blending weights is illustrated in <xref rid="fig7" ref-type="fig">Figure 7</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>Mean and standard deviation of DSC produced by using different settings of weights for blending different age maps. Plots corresponding to settings listed in this table can be seen in <xref rid="fig7" ref-type="fig">Figure 7</xref>. LOTS-IAM tested in this experiment is LOTS-IAM-GPU-512s64m.</p></caption>
<graphic xlink:href="334292_tbl2.tif"/>
</table-wrap>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><p>Curves of mean dice similarity coefficient (DSC) produced by using different settings of weights for blending different age maps. LOTS-IAM used in this experiment is LOTS-IAM-GPU-512s64m. All settings of blending Weights are listed in <xref rid="tbl2" ref-type="table">Table 2</xref>.</p></caption>
<graphic xlink:href="334292_fig7.tif"/>
</fig>
<p>From <xref rid="fig7" ref-type="fig">Figure 7</xref>, we can see that blending all four age maps improves IAM&#x2019;s performance and works better than using only one of the four available age maps. Based on results listed in <xref rid="tbl2" ref-type="table">Table 2</xref>, blending weights of 0.65, 0.20, 0.10 and 0.05 for age maps produced from 1&#x00D7;1, 2&#x00D7;2, 4&#x00D7;4 and 8&#x00D7;8 source/target patches respectively gives the best DSC score of 0.4434. As this combination produced the best DSC score in this evaluation, we made this set as a default set for IAM computation. Coincidentally, this set of blending weights has been used from the start of IAM&#x2019;s development and also used in the first paper of IAM (<xref ref-type="bibr" rid="c16">Rachmadi et al., 2017b</xref>).</p>
<p>The reason behind using 0.65, 0.20, 0.10 and 0.05 is to use more information from the age map produced by using 1&#x00D7;1 source/target patches than from the other age maps. This experiment confirmed this combination of blending weights to be the best as shown in <xref rid="fig7" ref-type="fig">Figure 7</xref> and <xref rid="tbl2" ref-type="table">Table 2</xref>, and that the most influential age map is the one produced by using 1&#x00D7;1 source/target patches. This experiment also proved our initial hypothesis that blending hierarchically produced age maps improves IAM&#x2019;s performance.</p>
</sec>
<sec id="s4e">
<label>4.5.</label>
<title>IAM&#x2019;s Random Sampling Test and Evaluation</title>
<p>To automatically detect FLAIR&#x2019;s WMH without any expert supervision, IAM works on the assumption that normal brain tissue is predominant compared with the extent of abnormalities. Due to this assumption, random sampling is used in IAM&#x2019;s computation to choose the target patches. However, it raises an important question on the stability of IAM to produce the same level of results for one exact MRI data.</p>
<p>In this experiment, we randomly choose one MRI data out of the 60 MRI data that we have, and ran LOTS-IAM-GPU multiple times (<italic>i.e</italic>., 10 times in this study) for different number of target patch samples. Each result was then compared to the ground truth, grouped together and plotted as boxplots (<xref rid="fig8" ref-type="fig">Figure 8</xref>) and listed in <xref rid="tbl3" ref-type="table">Table 3</xref>.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><p>Mean and standard deviation values of DSC distributions for each IAM&#x2019;s setting depicted in <xref rid="fig8" ref-type="fig">Figure 8</xref>. Each of IAM&#x2019;s setting is tested on a random MRI data 10 times.</p></caption>
<graphic xlink:href="334292_tbl3.tif"/>
</table-wrap>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8:</label>
<caption><p>DSC distributions of one random MRI scan tested 10 times by using LOTS-IAM-GPU with different numbers of target patch samples. Each box represents distribution of DSC produced on respective threshold value. Dashed magenta line represents the mean of DSC on respective threshold value.</p></caption>
<graphic xlink:href="334292_fig8.tif"/>
</fig>
<p><xref rid="fig8" ref-type="fig">Figure 8</xref> and <xref rid="tbl3" ref-type="table">Table 3</xref> show that the deviation of IAM&#x2019;s computation for one MRI data is small in all different settings of LOTS-IAM-GPU. However, it is true that by adding number of target patches in IAM&#x2019;s patch generation alienates this deviation as shown in <xref rid="fig8" ref-type="fig">Figure 8</xref>, where the box-plots produced by LOTS-IAM-GPU-2048s128m are smaller than the ones produced by LOTS-IAM-GPU-64s16m.</p>
</sec>
<sec id="s4f">
<label>4.6.</label>
<title>WMH Burden Scalability Evaluation</title>
<p>In this experiment, all methods were tested and evaluated to see their performances on doing WMH segmentation in different volumes of WMH (<italic>i.e</italic>., WMH burden). DSC metric is still used in this experiment, but the dataset is grouped into three different groups based on the WMH burden of each patient. The groups are listed in <xref rid="tbl4" ref-type="table">Table 4</xref> while the results can be seen in <xref rid="fig9" ref-type="fig">Figure 9</xref> and <xref rid="tbl5" ref-type="table">Table 5</xref>. Please note that IAM is represented by LOTS-IAM-GPU512s64m as it is the best performer in the IAM methods group (see <xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><p>Three groups of MRI data based on WMH volume.</p></caption>
<graphic xlink:href="334292_tbl4.tif"/>
</table-wrap>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5:</label>
<caption><p>Mean and standard deviation values of dice similarity coefficient (DSC) score&#x2019;s distribution for all methods tested in this study in respect to WMH burden of each patient (see <xref rid="tbl4" ref-type="table">Table 4</xref>). Note that LOTS-IAM-GPU-512s64m is listed as LIG-512s64m in this table.</p></caption>
<graphic xlink:href="334292_tbl5.tif"/>
</table-wrap>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9:</label>
<caption><p>Distributions of dice similarity coefficient (DSC) score for all methods tested in this study in respect to WMH burden of each patient (see <xref rid="tbl4" ref-type="table">Table 4</xref>).</p></caption>
<graphic xlink:href="334292_fig9.tif"/>
</fig>
<p>From <xref rid="fig9" ref-type="fig">Figure 9</xref>, it can be appreciated that LOTSIAM-GPU-512s64m performed better than LSTLGA in this experiment outperforming LST-LGA&#x2019;s performances distribution in all groups. LOTSIAM-GPU-512s64m also performed better than the conventional supervised machine learning algorithms (i.e. SVM and RF) in Small and Medium groups. Whereas, LOTS-IAM-GPU-512s64m&#x2019;s performance was at the level, if not better, than the supervised deep neural networks algorithms DBM and CEN. However, LOTS-IAM-GPU-512s64m still could not beat the <italic>state-of-the-art</italic> supervised deep neural networks 2D patch-CNN in any group.</p>
<p>To make this observation clearer, <xref rid="tbl5" ref-type="table">Table 5</xref> lists the mean and standard deviation values that correspond to the box-plot shown in <xref rid="fig9" ref-type="fig">Figure 9</xref>. From both <xref rid="fig9" ref-type="fig">Figure 9</xref> and <xref rid="tbl5" ref-type="table">Table 5</xref> it can be observed that the deviation of IAM&#x2019;s performances in Small WMH burden is still high compared to the other methods evaluated. However, IAM&#x2019;s performance is more stable in Medium and Large WMH burdens.</p>
</sec>
<sec id="s4g">
<label>4.7.</label>
<title>Longitudinal Evaluation</title>
<p>In this experiment, we evaluate spatial agreement between the produced results in three consecutive years. For each subject, we aligned Year2 (Y2) and Year-3 (Y3) MRI and derived data to the Year-1 (Y1), subtracted the aligned WMH labels of the baseline/previous year from the follow-up year(s)(<italic>i.e</italic>., Y2-Y1, Y3-Y2, and Y3-Y1), and then labelled each voxel as <italic>&#x2019;Grow&#x2019;</italic> if it has value above zero after subtraction, with <italic>&#x2019;Shrink&#x2019;</italic> if it has value below zero after subtraction, and with <italic>&#x2019;Stay&#x2019;</italic> if it has value of zero after subtraction and one before subtraction. This way, we can see whether the method captures the progression of WMH across time (<italic>i.e</italic>., longitudinally). An example of the output from this experiment is shown in <xref rid="fig11" ref-type="fig">Figure 11</xref> where sections of the original FLAIR MRI, LOTSIAM, LST-LGA and uNet across three respective years (Y1, Y2 and Y3) for a subject are depicted.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10:</label>
<caption><p>Quality of spatial agreement (Mean of DSC) of the produced results in longitudinal test. Longitudinal test is done to see the performance of tested methods in longitudinal dataset of MRI (see <xref rid="tbl6" ref-type="table">Table 6</xref> for full report).</p></caption>
<graphic xlink:href="334292_fig10.tif"/>
</fig>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11:</label>
<caption><p>White matter hyperintensities (WMH) information presented by FLAIR MRI, LOTS-IAM, LST-LGA and uNet in 3 (three) consecutive years. The 2<sup><italic>nd</italic></sup>/3<sup><italic>rd</italic></sup> year of FLAIR MR images are co-registered first to the 1<sup><italic>st</italic></sup> year of FLAIR MRI and then processed by LOTS-IAM, LST-LGA and uNet. LOTS-IAM produces richer information of the WMH progression than LST-LGA/uNet as age maps of LOTS-IAM preserve the underlying variance of WMH&#x2019;s intensity, giving a good perspective on how WMH grow over time.</p></caption>
<graphic xlink:href="334292_fig11.tif"/>
</fig>
<p><xref rid="fig10" ref-type="fig">Figure 10</xref> summarises the results listed in <xref rid="tbl6" ref-type="table">Table 6</xref> for all methods (<italic>i.e</italic>., LST-LGA, LOTS-IAMGPU-512s64m, Patch-uNet, Patch-uResNet and 2D Patch-CNN-GSI). We can see that LOTS-IAMGPU-512s64m outperforms LST-LGA and competes with deep neural networks methods of PatchuNet, Patch-uResNet and 2D Patch-CNN-GSI, where LOTS-IAM-GPU-512s64m is the second best performer after Patch-uResNet in this longitudinal evaluation. This, again, confirms that the LOTSIAM competes with the <italic>state-of-the-art</italic> deep learning convolutional neural network methods.</p>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6:</label>
<caption><p>Mean and standard deviation values produced in longitudinal tes (see <xref rid="tbl4" ref-type="table">Table 4</xref>). LOTS-IAM-GPU-512s64m is listed as LIG-512s64m in this table.</p></caption>
<graphic xlink:href="334292_tbl6.tif"/>
</table-wrap>
</sec>
<sec id="s4h">
<label>4.8.</label>
<title>Non-Parametric Correlation Test</title>
<p>In this experiment, we want to see how close IAM&#x2019;s results correlate with visual ratings of WMH. Visual ratings of WMH are commonly used by expert to manually estimate WMH burden of one patient. Visual ratings used in this study are Fazekas&#x2019;s visual rating (<xref ref-type="bibr" rid="c3">Fazekas et al., 1987</xref>) and Longstreth&#x2019;s rating scales (<xref ref-type="bibr" rid="c10">Longstreth et al., 1996</xref>).</p>
<p>The correlation was calculated by using Spearman&#x2019;s correlation, and two Spearman&#x2019;s correlation coefficients were calculated: 1) between the total Fazekas&#x2019;s rating (<italic>i.e</italic>., the sum of periventricular white matter hyperintensities (PVWMH) and deep white matter hyperintensities (DWMH)) and manual/automatic WMH volume and 2) between Longstreth&#x2019;s rating and manual/automatic WMH volume. The results are listed in <xref rid="tbl7" ref-type="table">Table 7</xref>.</p>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7:</label>
<caption><p>Non-parametric correlation using Spearman&#x2019;s correlation coefficient between WMH volume and Fazekas and Longstreth visual ratings.</p></caption>
<graphic xlink:href="334292_tbl7.tif"/>
</table-wrap>
<p><xref rid="tbl7" ref-type="table">Table 7</xref> shows that, although not much better, all LOTS-IAM-GPU methods highly correlate with visual rating clinical scores. Despite LST-LGA&#x2019;s output having lower value of mean DSC (see <xref rid="tbl1" ref-type="table">Table1</xref>) compared to other methods, it still highly correlates with visual ratings. LOTS-IAM-GPU implementations have high values of both mean DSC and correlation with visual ratings.</p>
</sec>
</sec>
<sec id="s5">
<label>5.</label>
<title>Conclusion and Future Work</title>
<p>The optimisation of IAM presented (LOTS-IAMGPU) improves both performance and processing time with respect to previous versions of IAM. Despite not being a WMH segmentation method <italic>per se</italic>, it can be successfully applied for this purpose. Being unsupervised confers an additional value to this fully automatic method as it does not depend on expert-labelled data, and therefore is independent from any subjectivity and inconsistency from human experts, which usually influence supervised machine learning algorithms. Furthermore, our results show that LOTS-IAM also successfully outperformed some supervised deep neural networks algorithms which are DBM and CEN.</p>
<p>One major drawback of the original IAM is the long computation time that takes to process a single MRI data. LOTS-IAM-GPU successfully speeds up IAM&#x2019;s computation time by 17 to 435 times, not only owed to its implementation in GPU, but also to the use of a limited number of target patch samples. LOTS-IAM-GPU also outperforms LSTLGA, the current <italic>state-of-the-art</italic> method for unsupervised WMH segmentation, in both DSC metric and processing speed.</p>
<p>IAM could provide unsupervised labels for pretraining supervised deep neural networks algorithms, but this has not been explored yet. IAM can also be applied to detect abnormalities on other MRI sequences. Due to its nature, it can be hypothesised its applicability to segment brain lesions in CT scans. Further works should also explore its implementation on a multispectral approach that combines different MRI sequences. The implementation of LOTS-IAM-GPU is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/febrianrachmadi/lots-iam-gpu">https://github.com/febrianrachmadi/lots-iam-gpu</ext-link>.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The first author would like to thank Indonesia Endowment Fund for Education (LPDP) of Ministry of Finance, Republic of Indonesia, for funding his study at School of Informatics, the University of Edinburgh. Funds from Row Fogo Charitable Trust (MCVH) are also gratefully acknowledged. Data collection and sharing for this project was funded by the Alzheimer&#x2019;s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimers Association; Alzheimers Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research and Development, LLC.; Johnson and Johnson Pharmaceutical Research and Development LLC.; Lumosity; Lundbeck; Merck and Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (<ext-link ext-link-type="uri" xlink:href="http://www.fnih.org">www.fnih.org</ext-link>). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimers Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Bellini</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kleiman</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Cohen-Or</surname>, <given-names>D.</given-names></string-name>, <year>2016</year>. <article-title>Time-varying weathering in texture space</article-title>. <source>ACM Transactions on Graphics (TOG)</source> <volume>35</volume> (<issue>4</issue>), <fpage>141</fpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Dice</surname>, <given-names>L. R.</given-names></string-name>, <year>1945</year>. <article-title>Measures of the amount of ecologic asso-ciation between species</article-title>. <source>Ecology</source> <volume>26</volume> (<issue>3</issue>), <fpage>297</fpage>&#x2013;<lpage>302</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Fazekas</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Chawluk</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Alavi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hurtig</surname>, <given-names>H. I.</given-names></string-name>, <string-name><surname>Zimmerman</surname>, <given-names>R. A.</given-names></string-name>, <year>1987</year>. <article-title>Mr signal abnormalities at 1.5 t in alzheimer&#x2019;s dementia and normal aging</article-title>. <source>American journal of roentgenology</source> <volume>149</volume> (<issue>2</issue>), <fpage>351</fpage>&#x2013;<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Guerrero</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Qin</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Oktay</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Bowles</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Joules</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Wolz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Vald&#x00B4;es-Hern&#x00E1;ndez</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dickie</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Wardlaw</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal>, <year>2018</year>. <article-title>White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks</article-title>. <source>NeuroImage: Clinical</source> <volume>17</volume>, <fpage>918</fpage>&#x2013;<lpage>934</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Hern&#x00E1;ndez</surname>, <given-names>M. d. C. V.</given-names></string-name>, <string-name><surname>Morris</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Dickie</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Royle</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Maniega</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Aribisala</surname>, <given-names>B. S.</given-names></string-name>, <string-name><surname>Bastin</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Deary</surname>, <given-names>I. J.</given-names></string-name>, <string-name><surname>Wardlaw</surname>, <given-names>J. M.</given-names></string-name>, <year>2013</year>. <article-title>Close correlation between quantitative and qualitative assessments of white matter lesions</article-title>. <source>Neuroepidemiology</source> <volume>40</volume> (<issue>1</issue>), <fpage>13</fpage>&#x2013;<lpage>22</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Ithapu</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Singh</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Lindner</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Austin</surname>, <given-names>B. P.</given-names></string-name>, <string-name><surname>Hinrichs</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Carlsson</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Bendlin</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>S. C.</given-names></string-name>, <year>2014</year>. <article-title>Extracting and summarizing white matter hyperintensities using supervised segmentation methods in alzheimer&#x2019;s disease risk and aging studies</article-title>. <source>Human brain mapping</source> <volume>35</volume> (<issue>8</issue>), <fpage>4219</fpage>&#x2013;<lpage>4235</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bannister</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name>, <year>2002</year>. <article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>. <source>Neuroimage</source> <volume>17</volume> (<issue>2</issue>), <fpage>825</fpage>&#x2013;<lpage>841</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Kamnitsas</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Ledig</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Newcombe</surname>, <given-names>V. F.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Kane</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Menon</surname>, <given-names>D. K.</given-names></string-name>, <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Glocker</surname>, <given-names>B.</given-names></string-name>, <year>2017</year>. <article-title>Efficient multi-scale 3d CNN with fully connected CRF for accurate brain lesion segmentation</article-title>. <source>Medical Image Analysis</source> <volume>36</volume>, <fpage>61</fpage>&#x2013;<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Jiang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>W.-S.</given-names></string-name>, <string-name><surname>Menze</surname>, <given-names>B.</given-names></string-name>, <year>2018</year>. <article-title>Fully convolutional network ensembles for white matter hyperintensities segmentation in mr images</article-title>. <source>arXiv preprint arXiv:1802.05203</source>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Longstreth</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Manolio</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Arnold</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Burke</surname>, <given-names>G. L.</given-names></string-name>, <string-name><surname>Bryan</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Jungreis</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Enright</surname>, <given-names>P. L.</given-names></string-name>, <string-name><surname>O&#x2019;Leary</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Fried</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Group</surname>, <given-names>C. H. S. C. R.</given-names></string-name>, <etal>et al.</etal>, <year>1996</year>. <article-title>Clinical correlates of white matter findings on cranial magnetic resonance imaging of 3301 elderly people the cardiovascular health study</article-title>. <source>Stroke</source> <volume>27</volume> (<issue>8</issue>), <fpage>1274</fpage>&#x2013;<lpage>1282</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Lutkenhoff</surname>, <given-names>E. S.</given-names></string-name>, <string-name><surname>Rosenberg</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Chiang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Pickard</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Owen</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Monti</surname>, <given-names>M. M.</given-names></string-name>, <year>2014</year>. <article-title>Optimized brain extraction for pathological brains (optibet</article-title>). <source>PloS one</source> <volume>9</volume> (<issue>12</issue>), <fpage>e115551</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Mueller</surname>, <given-names>S. G.</given-names></string-name>, <string-name><surname>Weiner</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Thal</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Petersen</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Jack</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Jagust</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Trojanowski</surname>, <given-names>J. Q.</given-names></string-name>, <string-name><surname>Toga</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Beckett</surname>, <given-names>L.</given-names></string-name>, <year>2005</year>. <article-title>The alzheimer&#x2019;s disease neuroimaging initiative</article-title>. <source>Neuroimaging Clinics of North America</source> <volume>15</volume> (<issue>4</issue>), <fpage>869</fpage>&#x2013;<lpage>877</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Myers</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Well</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lorch</surname>, <given-names>R. F.</given-names></string-name>, <year>2010</year>. <article-title>Research design and statistical analysis</article-title>. <source>Routledge</source>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Rachmadi</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Vald&#x00E9;s-Hern&#x00E1;ndez</surname>, <given-names>M. d. C.</given-names></string-name>, <string-name><surname>Agan</surname>, <given-names>M. L. F.</given-names></string-name>, <string-name><surname>Di Perri</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Komura</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Initiative</surname>, <given-names>A. D. N.</given-names></string-name>, <etal>et al.</etal>, <year>2018</year>. <article-title>Segmentation of white matter hyperintensities using convolutional neural networks with global spatial information in routine clinical brain mri with none or mild vascular pathology</article-title>. <source>Computerized Medical Imaging and Graphics</source> <volume>66</volume>, <fpage>28</fpage>&#x2013;<lpage>43</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Rachmadi</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Vald&#x00E9;s-Hern&#x00E1;ndez</surname>, <given-names>M. d. C.</given-names></string-name>, <string-name><surname>Agan</surname>, <given-names>M. L. F.</given-names></string-name>, <string-name><surname>Komura</surname>, <given-names>T.</given-names></string-name>, <year>2017a</year>. <article-title>Deep learning vs. conventional machine learning: Pilot study of wmh segmentation in brain mri with absence or mild vascular pathology</article-title>. <source>Journal of Imaging</source> <volume>3</volume> (<issue>4</issue>), <fpage>66</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Rachmadi</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Vald&#x00B4;es-Hern&#x00B4;andez</surname>, <given-names>M. d. C.</given-names></string-name>, <string-name><surname>Komura</surname>, <given-names>T.</given-names></string-name>, <year>2017b</year>. <article-title>Voxel-based irregularity age map (iam) for brain&#x2019;s white matter hyperintensities in mri. In: Advanced Computer Science and Information Systems (ICACSIS</article-title>), <source>2017 International Conference on. IEEE</source>, pp. <fpage>321</fpage>&#x2013;<lpage>326</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Fischer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brox</surname>, <given-names>T.</given-names></string-name>, <year>2015</year>. <article-title>U-net: Convolutional networks for biomedical image segmentation</article-title>. In: <source>International Conference on Medical image computing and computer-assisted intervention. Springer</source>, pp. <fpage>234</fpage>&#x2013;<lpage>241</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Scheltens</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Barkhof</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Leys</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Pruvo</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Nauta</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Vermersch</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Steinling</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Valk</surname>, <given-names>J.</given-names></string-name>, <year>1993</year>. <article-title>A semiquantative rating scale for the assessment of signal hyperintensities on magnetic resonance imaging</article-title>. <source>Journal of the neurological sciences</source> <volume>114</volume> (<issue>1</issue>), <fpage>7</fpage>&#x2013;<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Schmidt</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gaser</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Arsic</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Buck</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>F&#x00A8;orschler</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Berthele</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hoshi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ilg</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Schmid</surname>, <given-names>V. J.</given-names></string-name>, <string-name><surname>Zimmer</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal>, <year>2012</year>. <article-title>An automated tool for detection of flair-hyperintense white-matter lesions in multiple scle-rosis</article-title>. <source>Neuroimage</source> <volume>59</volume> (<issue>4</issue>), <fpage>3774</fpage>&#x2013;<lpage>3783</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Shiee</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bazin</surname>, <given-names>P.-L.</given-names></string-name>, <string-name><surname>Ozturk</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Reich</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Calabresi</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Pham</surname>, <given-names>D. L.</given-names></string-name>, <year>2010</year>. <article-title>A topology-preserving approach to the segmentation of brain images with multiple sclerosis lesions</article-title>. <source>NeuroImage</source> <volume>49</volume> (<issue>2</issue>), <fpage>1524</fpage>&#x2013;<lpage>1535</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Vald&#x00E9;s Hern&#x00E1;ndez</surname>, <given-names>M. d. C.</given-names></string-name>, <string-name><surname>Armitage</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Thrippleton</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Chappell</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Sandeman</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Mu&#x00F1;oz Maniega</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shuler</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Wardlaw</surname>, <given-names>J. M.</given-names></string-name>, <year>2015</year>. <article-title>Rationale, design and methodology of the image analysis protocol for studies of patients with cerebral small vessel disease and mild stroke</article-title>. <source>Brain and behavior</source> <volume>5</volume> (<issue>12</issue>).</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Wardlaw</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>E. E.</given-names></string-name>, <string-name><surname>Biessels</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Cordonnier</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Fazekas</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Frayne</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Lindley</surname>, <given-names>R. I.</given-names></string-name>, <string-name><surname>T O&#x2019;Brien</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Barkhof</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Benavente</surname>, <given-names>O. R.</given-names></string-name>, <etal>et al.</etal>, <year>2013</year>. <article-title>Neuroimaging standards for research into small vessel disease and its contribution to ageing and neurodegeneration</article-title>. <source>The Lancet Neurology</source> <volume>12</volume> (<issue>8</issue>), <fpage>822</fpage>&#x2013;<lpage>838</lpage>.</mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn1">
<label><sup>1</sup></label>
<p><ext-link ext-link-type="uri" xlink:href="http://hdl.handle.net/10283/2214">http://hdl.handle.net/10283/2214</ext-link></p></fn>
<fn id="fn2">
<label><sup>2</sup></label>
<p><ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link></p></fn>
<fn id="fn3">
<label><sup>3</sup></label>
<p><ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf">http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf</ext-link></p></fn>
</fn-group>
</back>
</article>