<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/322248</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Ecology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Modelling palaeoecological time series using generalized additive models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9084-8413</contrib-id>
<name><surname>Simpson</surname><given-names>Gavin L.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Institute of Environmental Change and Society, University of Regina</institution>, Regina, Saskatchewan, <country>Canada</country>, S4S 0A2</aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="other"><p><email>gavin.simpson@uregina.ca</email></p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>322248</elocation-id>
<history>
<date date-type="received">
<day>14</day><month>5</month><year>2018</year>
</date>
<date date-type="rev-recd">
<day>14</day><month>5</month><year>2018</year>
</date>
<date date-type="accepted">
<day>15</day><month>5</month><year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="322248.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>In the absence of annual laminations, time series generated from lake sediments or other similar stratigraphic sequences are irregularly spaced in time, which complicates formal analysis using classical statistical time series models. In lieu, statistical analyses of trends in palaeoen-vironmental time series, if done at all, have typically used simpler linear regressions or (non-) parametric correlations with little regard for the violation of assumptions that almost surely occurs due to temporal dependencies in the data or that correlations do not provide estimates of the magnitude of change, just whether or not there is a linear or monotonic trend. Alternative approaches have used L<sc>OESS</sc>-estimated trends to justify data interpretations or test hypotheses as to the causal factors without considering the inherent subjectivity of the choice of parameters used to achieve the L<sc>OESS</sc> fit (e.g. span width, degree of polynomial). Generalized additive models (GAMs) are statistical models that can be used to estimate trends as smooth functions of time. Unlike L<sc>OESS</sc>, GAMs use automatic smoothness selection methods to objectively determine the complexity of the fitted trend, and as formal statistical models, GAMs, allow for potentially complex, non-linear trends, a proper accounting of model uncertainty, and the identification of periods of significant temporal change. Here, I present a consistent and modern approach to the estimation of trends in palaeoenvironmental time series using GAMs, illustrating features of the methodology with two example time series of contrasting complexity; a 150-year bulk organic matter &#x03B4;<sup>15</sup>N time series from Small Water, UK, and a 3000-year alkenone record from Braya-S&#x00F8;, Greenland. I discuss the underlying mechanics of GAMs that allow them to learn the shape of the trend from the data themselves and how simultaneous confidence intervals and the first derivatives of the trend are used to properly account for model uncertainty and identify periods of change. It is hoped that by using GAMs greater attention is paid to the statistical estimation of trends in palaeoenvironmental time series leading to more a robust and reproducible palaeoscience.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>time series</kwd>
<kwd>generalized additive model</kwd>
<kwd>simultaneous interval</kwd>
<kwd>spline</kwd>
<kwd>environmental change</kwd>
</kwd-group>
<counts>
<page-count count="36"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Palaeoecology and palaeolimnology have moved away from being descriptive disciplines, rapidly adopting new statistical developments in the 1990s and beyond (@ <xref ref-type="bibr" rid="c50">Smol et al., 2012</xref>). Less development has been observed in the area of trend estimation in palaeoenvironmental time series. The vast majority of data produced by palaeoecologists and palaeolimnologists is in the form of time-ordered observations on one or more proxies or biological taxa (<xref ref-type="bibr" rid="c7">Birks, 2012b</xref>; <xref ref-type="bibr" rid="c49">Smol, 2008</xref>; <xref ref-type="bibr" rid="c50">Smol et al., 2012</xref>). Typically these data are arranged irregularly in time; in the absence of annual laminae or varves, the sediment core is sectioned at regular depth intervals (<xref ref-type="bibr" rid="c20">Glew et al., 2001</xref>), which, owing to variation in accumulation rates over time and compaction by overlying sediments, results in an uneven sampling in time. An under appreciated feature of such sampling is that younger sediments often have larger variance than older sediments; each section of core represents fewer lake years in newer samples, relative to older samples. This variable averaging acts as a time-varying low-pass (high-cut) filter of the annual depositional signal.</p>
<p>Irregular intervals between samples means that the time-series analysis methods of autoregressive or moving average processes, in the form of autoregressive integrated moving average (ARIMA) models, are practically impossible to apply because software typically requires even spacing of observations in time. <xref ref-type="bibr" rid="c14">Dutilleul et al. (2012)</xref> and <xref ref-type="bibr" rid="c6">Birks (2012a)</xref>, eschewing the term <italic>time series</italic>, prefer to call such data <italic>temporal series</italic> on account of the irregular spacing of samples, a distinction that I find unnecessary.</p>
<p>Where statistical approaches have been applied to trend estimation in palaeoenvironmental time series, a commonly-used method is Loess (<xref ref-type="bibr" rid="c5">Birks, 1998</xref>, <xref ref-type="bibr" rid="c6">2012a</xref>; <xref ref-type="bibr" rid="c11">Cleveland, 1979</xref>; <xref ref-type="bibr" rid="c25">Juggins and Telford, 2012</xref>). L<sc>oess</sc>, locally weighted scatterplot smoother, as it&#x2019;s name suggests, was developed to smooth x-y scatterplot data (<xref ref-type="bibr" rid="c11">Cleveland, 1979</xref>). The method fits a smooth line through data by fitting weighted least squares (WLS) models to observations within a particular, user-specified window of the focal point, whose width is typically expressed as a proportion <italic>&#x03B1;</italic> of the <italic>n</italic> data points. Weights are determined by how close (in the x-axis only) an observation in the window is to the focal point giving greatest weight given to points closest to the focal point. The interim L<sc>OESS</sc>-smoothed value for the focal point is the predicted value from the weighted regression at the focal point. The interim values are updated using weights based on how far in the y-axis direction the interim smoothed value lies from the observed value plus the x-axis distance weights; this has the effect of down-weighting outlier observations. The final LoEss is obtained by joining the smoothed values. The user has to choose how large a window to use, whether to fit degree 1 (linear) or degree 2 (quadratic) polynomials in the WLS model, and how to weight points in the x-axis. When used in an exploratory mode, the user has considerable freedom to choose the detail of the L<sc>OESS</sc> fit; the window width, for example, can be infinitely tweaked to give as close a fit to the data, as assessed by eye, as is desired. Using cross-validation (CV) to choose <italic>&#x03B1;</italic> or the degree of polynomial in the WLS model is complicated for a number of reasons, not least because the CV scheme used must involve the time ordering of the data (e.g. <xref ref-type="bibr" rid="c4">Bergmeir et al., 2018</xref>). This subjectivity is problematic however once we wish to move beyond exploratory analysis and statistically identify trends to test hypotheses involving those trend estimates.</p>
<p>Running means or other types of filter (<xref ref-type="bibr" rid="c25">Juggins and Telford, 2012</xref>) have also been used extensively to smooth palaeoenvironmental time series, but, as with L<sc>OESS</sc>, their behaviour depends on a number of factors, including the filter width. Furthermore, the width of the filter causes boundary issues; with a centred filter, of width five, the filtered time series would be two data points shorter at both ends of the series because the filter values are not defined for the first and last two observations of the original series as these extra time points were not observed. Considerable research effort has been expended to identify ways to pad the original time series at one or both ends to maintain the original length in the filtered series, without introducing bias due to the padding (e.g. <xref ref-type="bibr" rid="c29">Mann, 2004</xref>, <xref ref-type="bibr" rid="c30">2008</xref>; <xref ref-type="bibr" rid="c33">Mills, 2006</xref>, <xref ref-type="bibr" rid="c34">2007</xref>, <xref ref-type="bibr" rid="c35">2010</xref>).</p>
<p>These are not the only methods that have been used to estimated trends in stratigraphic series. Another common approach involves fitting a simple linear trend using ordinary least squares regression and use the resulting <italic>t</italic> statistic as evidence against the null hypothesis of no trend despite the statistical assumptions being almost surely violated due to dependence among observations. The Pearson correlation coefficient, <italic>r</italic>, is also often used to detect trends in palaeo time series (<xref ref-type="bibr" rid="c6">Birks, 2012a</xref>), despite the fact that <italic>r</italic> provides no information as to the magnitude of the estimated trend, and the same temporal autocorrelation problem that dogs ordinary least squares similarly plagues significance testing for <italic>r</italic> (<xref ref-type="bibr" rid="c51">Tian et al., 2011</xref>). Additionally, both the simple least squares trend line and <italic>r</italic> are tests for <italic>linear</italic> trends only, and yet we typically face data sets with potentially far more complex trends than can be identified by these methods. Instead, non-parametric rank correlation coefficients have been used (<xref ref-type="bibr" rid="c6">Birks, 2012a</xref>; <xref ref-type="bibr" rid="c19">Gautheir, 2001</xref>), and whilst these do allow for the detection of non-linear trends, trends are restricted to be monotonic, no magnitude of the trend is provided, and the theory underlying significance testing of Spearman&#x2019;s <italic>&#x03C1;</italic> and Kendall&#x2019;s <italic>&#x03C4;</italic> assumes independent observations.</p>
<p>Here, I describe generalized additive models (GAMs; <xref ref-type="bibr" rid="c24">Hastie and Tibshirani, 1986</xref>, <xref ref-type="bibr" rid="c23">1990</xref>; <xref ref-type="bibr" rid="c47">Ruppert et al., 2003</xref>; <xref ref-type="bibr" rid="c62">Wood, 2017</xref>; <xref ref-type="bibr" rid="c64">Yee and Mitchell, 1991</xref>) for trend estimation. GAMs, like simple linear regression, are a regression-based method for estimating trends, yet they are also, superficially at least, similar to L<sc>OESS</sc>. GAMs and L<sc>OESS</sc> estimate smooth, non-linear trends in time series and both can handle the irregular spacing of samples in time, yet GAMs do not suffer from the subjectivity that plagues LoEss as a method of formal statistical inference.</p>
<p>In the subsequent sections, I present an introduction to GAMs and discuss the issue of uncertainty in model-estimated trends, the topic of posterior simulation from a regression model and how to identify periods of significant environmental change using the first derivative of the estimated trend. Two non-standard types of spline &#x2014; adaptive smoothers and Gaussian process splines &#x2014; that are especially applicable to GAMs in the palaeoenvironmental setting are subsequently described, followed by an assessment of the the impact of age-model uncertainty on trend estimation via GAMs. Finally, I briefly discuss the application of GAM trend analysis to multivariate species abundance and compositional data.</p>
<sec id="s1a">
<label>1.1</label>
<title>Example time series</title>
<p>To illustrate trend estimation in palaeoenvironmental data using GAMs, I use two proxy time series; a 150-year bulk organic matter &#x03B4;<sup>15</sup>N record from Small Water, and a 3000-year alkenone record from Braya-S&#x00F8;. Between them, the two examples, combine many of the features of interest to palaeoecologists that motivate the use of GAMs; non-linear trends and the question of when changes in the measured proxy occurred. The example analyses were all performed using the <italic>mgcv</italic> package (version 1.8.23; <xref ref-type="bibr" rid="c62">Wood, 2017</xref>) and R (version 3.4.4; <xref ref-type="bibr" rid="c43">R Core Team, 2018</xref>), and the supplementary material contains a fully annotated document showing the R code used to replicate all the analyses described in the remainder of the paper.</p>
</sec>
<sec id="s1a1">
<label>1.1.1</label>
<title>&#x03B4;<sup>15</sup>N time series from Small Water</title>
<p><xref ref-type="fig" rid="fig1">Figure 1a</xref> shows 48 nitrogen stable isotope measurements on the bulk organic matter of a sediment core collected from Small Water, a small corrie lake located in the English Lake District, UK. The data were collected to investigate disturbance of nitrogen (N) cycling in remote, olig-otrophic lakes by N deposited from the atmosphere (Simpson, unpublished data). The data are shown on a <sup>210</sup>Pb time scale. Questions that might be asked about this series are; what is the trend in &#x03B4;<sup>15</sup>N?, when do we first see evidence for a change in &#x03B4;<sup>15</sup>N&#x003F;, and is the reversal in &#x03B4;<sup>15</sup>N values in the uppermost section of the core a real change&#x003F;</p>
<fig id="fig1" position="float" fig-type="figure"><label>Figure 1:</label>
<caption><p>Example time series; a) Small Water bulk organic matter <italic>&#x03B4;</italic><sup>15</sup>N time series on a <sup>210</sup>Pb time scale, and b) Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline8.gif"/></alternatives></inline-formula> time series on a calibrated 14C time scale. The observations <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline9.gif"/></alternatives></inline-formula> time series have been joined by lines purely as a visual aid to highlight potential trends.</p></caption>
<graphic xlink:href="322248_fig1.tif"/>
</fig>
</sec>
<sec id="s1a2">
<label>1.1.2</label>
<title>Braya-S&#x00F8; alkenone time series</title>
<p>The second example time series is a 3,000 year record of alkenone unsaturation, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline1.gif"/></alternatives></inline-formula> from Braya-S&#x00F8;, a meromictic lake in West Greenland (<xref ref-type="bibr" rid="c15">D&#x2019;Andrea et al., 2011</xref>). Alkenones are long-chained unsaturated organic compounds that are produced by a small number of planktonic organisms known as haptophytes. The <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline2.gif"/></alternatives></inline-formula> unsaturation index is (<xref ref-type="bibr" rid="c9">Brassell, 1993</xref>)
<disp-formula id="ueqn1"><alternatives><graphic xlink:href="322248_ueqn1.gif"/></alternatives></disp-formula>
where [<italic>C</italic><sub>37:<italic>x</italic></sub>] is the concentration of the alkenone with 37 carbon atoms and <italic>x</italic> double carbon bonds. The relative abundance of these alkenones is known to vary with changes in water temperature (<xref ref-type="bibr" rid="c9">Brassell, 1993</xref>; <xref ref-type="bibr" rid="c10">Chu et al., 2005</xref>; <xref ref-type="bibr" rid="c52">Toney et al., 2010</xref>; <xref ref-type="bibr" rid="c65">Zink et al., 2001</xref>), and as a result <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline3.gif"/></alternatives></inline-formula> is used as a proxy for lake&#x002D; and sea-surface temperatures. For further details on the Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline4.gif"/></alternatives></inline-formula> record and age model see <xref ref-type="bibr" rid="c15">D&#x2019;Andrea et al. (2011)</xref>. Here I use the 3,000 year <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline5.gif"/></alternatives></inline-formula> record from the PAGES 2K database (<xref ref-type="bibr" rid="c37">PAGES 2K Consortium, 2013</xref>). The data are presented in <xref ref-type="fig" rid="fig1">Figure 1b</xref>.</p>
</sec>
</sec>
<sec id="s2">
<label>2</label>
<title>Regression models for palaeoenvironmental time series</title>
<p>A linear model for a trend in a series of <italic>T</italic> observations <italic>y</italic><sub><italic>t</italic></sub> at observation times <italic>x</italic><sub><italic>t</italic></sub> with <italic>t</italic> &#x003D; 1,2,&#x2026; <italic>T</italic> is
<disp-formula id="eqn1"><alternatives><graphic xlink:href="322248_eqn1.gif"/></alternatives></disp-formula>
where <italic>&#x03B2;</italic><sub>0</sub> is a constant term, the model <italic>intercept</italic>, representing the expected value of <italic>y</italic><sub><italic>t</italic></sub> where <italic>x</italic><sub><italic>t</italic></sub> is 0. <italic>&#x03B2;</italic><sub>1</sub> is the <italic>slope</italic> of the best fit line through the data; it measures the rate of change in <italic>y</italic> for a unit increase in <italic>x</italic>. The unknowns, the <italic>&#x03B2;</italic><sub><italic>j</italic></sub>, are commonly estimated using least squares by minimising the sum of squared errors, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline6.gif"/></alternatives></inline-formula>. If we want to ask if the estimated trend <italic>&#x03B2;</italic><sub>1</sub> is statistically significant we must make further assumptions about the data (conditional upon the fitted model) or the model errors (residuals); <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline7.gif"/></alternatives></inline-formula>. This notation indicates that the residuals <italic>&#x03B5;</italic><sub><italic>t</italic></sub> are <italic>independent</italic> and <italic>identically distributed</italic> Gaussian random variables with mean equal to 0 and constant variance <italic>&#x03C3;</italic><sup>2</sup>. In the time series setting, the assumption of independence of model residuals is often violated.</p>
<p>The linear model described above is quite restrictive in terms of the types of trend it can fit; essentially linear increasing or decreasing trends, or, trivially, a null trend of no change. This model can be extended to allow for non-linear trends by making <italic>y</italic><sub><italic>t</italic></sub> depend on polynomials of <italic>x</italic><sub><italic>t</italic></sub> for example
<disp-formula id="eqn2"><alternatives><graphic xlink:href="322248_eqn2.gif"/></alternatives></disp-formula>
where polynomials of <italic>x</italic><sub><italic>t</italic></sub> up to order <italic>P</italic> are used. This model allows for more complex trends but it remains a fully parametric model and suffers from several problems, especially the behaviour of the fitted trend at the start and end of the observed series.</p>
<p>Linear models using a range of polynomials fitted to the Small Water data set are shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. The low-order models (<italic>P</italic> &#x2208; {1,3}) result in very poor fit to the data. The model with <italic>P</italic> &#x003D; 5 does a reasonable job of capturing the gross pattern in the time series, but fails to adapt quickly enough to the decrease in &#x03B4;<sup>15</sup>N that begins &#x007E;1940 CE, and the estimated trend is quite biased as a result. The <italic>P</italic> &#x003D; 10th-order polynomial model is well able to capture this period of rapid change, but it does so at the expense of increased complexity in the estimated trend prior to &#x007E;1940. Additionally, this model (<italic>P</italic> &#x003D; 10) has undesirable behaviour at the ends of the series, significantly overfitting the data, a commonly observed problem in polynomial models such as these (<xref ref-type="bibr" rid="c16">Epperson, 1987</xref>; <xref ref-type="bibr" rid="c46">Runge, 1901</xref>). Finally, the choice of what order of polynomial to fit is an additional choice left for the analyst to specify; choosing the optimal <italic>P</italic> is not a trivial task when the data are a time series and residual autocorrelation is likely present.</p>
<fig id="fig2" position="float" fig-type="figure"><label>Figure 2:</label>
<caption><p>Linear models with various orders of polynomial of the covariate Year fitted using ordinary least squares to the <italic>&#x03B4;</italic><sup>15</sup>N time series from Small Water. The degree of polynomial is indicated, with the degree 1 line equal to a simple linear regression model.</p></caption>
<graphic xlink:href="322248_fig2.tif"/>
</fig>
<p>Can we do better than these polynomial fits? In the remainder, I hope to demonstrate that the answer to that question is emphatically &#x201C;yes&#x201D;&#x0021; Below I describe a coherent and consistent approach to modelling palaeoenvironmental time series using generalized additive models that builds upon the linear regression framework.</p>
</sec>
<sec id="s3">
<label>3</label>
<title>Generalized additive models</title>
<p>The GAM version of the linear model <xref ref-type="disp-formula" rid="eqn1">(1)</xref> is
<disp-formula id="eqn3"><alternatives><graphic xlink:href="322248_eqn3.gif"/></alternatives></disp-formula>
where the linear effect of time (the <italic>&#x03B2;</italic><sub>1</sub><italic>x</italic><sub><italic>t</italic></sub> part) has been replaced by a smooth function of time, <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>). The immediate advantage of the GAM is that we are no longer restricted to the shapes of trends that can be fitted via global polynomial functions such as <xref ref-type="disp-formula" rid="eqn2">(2)</xref>. Instead, the shape of the fitted trend will be estimated from the data itself.</p>
<p>The linear model is a special case of a broader class, known as the generalized linear model (GLM; <xref ref-type="bibr" rid="c32">McCullagh and Nelder, 1989</xref>). The GLM provides a common framework for modelling a wide range of types of data, such as count, proportions, or binary (presence/absence) data, that are not conditionally distributed Gaussian. GLMs are, like the linear model, parametric in nature; the types of trends that we can fit using a GLM are the linear or polynomial models. GAMs extend the GLM by relaxing this parametric assumption; in a GAM some, or all, of the parametric terms, the <italic>&#x03B2;</italic><sub><italic>p</italic></sub>, are replace by smooth functions <italic>f</italic><sub><italic>j</italic></sub> of the covariates <italic>x</italic><sub><italic>j</italic></sub>. For completeness then, we can write <xref ref-type="disp-formula" rid="eqn3">(3)</xref> as a GLM/GAM
<disp-formula id="eqn4a"><alternatives><graphic xlink:href="322248_eqn4a.gif"/></alternatives></disp-formula>
<disp-formula id="eqn4b"><alternatives><graphic xlink:href="322248_eqn4b.gif"/></alternatives></disp-formula>
<disp-formula id="eqn4c"><alternatives><graphic xlink:href="322248_eqn4c.gif"/></alternatives></disp-formula>
where <italic>&#x03BC;</italic><sub><italic>t</italic></sub> is the expected value (e.g. the mean count or the probability of occurrence) of the random variable <italic>Y</italic><sub><italic>t</italic></sub> (<italic>&#x03BC;</italic><sub><italic>t</italic></sub> &#x2261; &#x1D53c;(<italic>Y</italic><sub><italic>t</italic></sub>)) of which we have observations <italic>y</italic><sub><italic>t</italic></sub>. <italic>g</italic> is the link function, an invertible, monotonic function, such as the natural logarithm, and <italic>g</italic><sup>&#x2212;1</sup> is its inverse. The link function maps values from the response scale on to the scale of the linear predictor, whilst the inverse of the link function provides the reverse mapping. For example, count data are strictly non-negative integer values and are commonly modelled as a Poisson GLM/GAM using the natural log link function. On the log scale, the response can take any real value between &#x2212;&#x221E; and &#x002B;&#x221E;, and it is on this scale that model fitting actually occurs (i.e. using <xref ref-type="disp-formula" rid="eqn4b">equation (4b)</xref>). However we need to map these unbounded values back on to the non-negative response scale. The inverse of the log link function, the exponential function, achieves this and maps values to the interval 0&#x2013;&#x221E; (<xref ref-type="disp-formula" rid="eqn4c">equation (4c)</xref>).</p>
<p>In <xref ref-type="disp-formula" rid="eqn4a">(4a)</xref>, we further assume that the observations are drawn from a member of the exponential family of distributions &#x2014; such as the Poisson for count data, the binomial for presence/absence or counts from a total &#x2014; with expected value <italic>&#x03BC;</italic><sub><italic>t</italic></sub> and possibly some additional parameters &#x0398; (<italic>y</italic><sub><italic>t</italic></sub> &#x007E; EF(<italic>&#x03BC;</italic>, &#x0398;)). Additionally, many software implementations of the above model also allow for distributions that are not within the exponential family but which can be fitted using an algorithm superficially similar to the one used to fit GAMs to members of the exponential family (e.g. <xref ref-type="bibr" rid="c63">Wood et al., 2016</xref>). Common examples of such extended families include the negative binomial distribution (for overdispersed counts) and the beta distribution (for true proportions or other interval-bounded data).</p>
<sec id="s3a">
<label>3.1</label>
<title>Basis functions</title>
<p>It is clear from the plots of the data (<xref ref-type="fig" rid="fig1">Figure 1</xref>) that we require the fitted trends for the Small Water &#x03B4;<sup>15</sup>N and Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline10.gif"/></alternatives></inline-formula> time series to be non-linear functions, but it is less clear how to specify the actual shape require. Ideally, we&#x2019;d like to learn the shape of the trend from the data themselves. We will refer to these non-linear functions as <italic>smooth functions</italic>, or just <italic>smooths</italic> for short, and we will denote a smooth using <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>). Further, we would like to represent the smooths in a way that <xref ref-type="disp-formula" rid="eqn4a">(4)</xref> is represented parametrically so that it can be estimate within thewell-studied GLM framework. This is achieved by representing the smooth using a <italic>basis</italic>. A basis is a set of functions that collectively span a space of smooths that, we hope, contains the true <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>) or a close approximation to it. The functions in the basis are known as <italic>basis functions</italic>, and arise from a <italic>basis expansion</italic> of a covariate. Writing <italic>b</italic><sub><italic>j</italic></sub>(<italic>x</italic><sub>t</sub>) as the <italic>j</italic>th basis function of <italic>x</italic><sub><italic>t</italic></sub>, the smooth <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>) can be represented as a weighted sum of basis functions
<disp-formula id="ueqn2"><alternatives><graphic xlink:href="322248_ueqn2.gif"/></alternatives></disp-formula>
where <italic>&#x03B2;</italic><sub><italic>j</italic></sub> is the weight applied to the <italic>j</italic>th basis function.</p>
<p>The polynomial model is an example of a statistical model that uses a basis expansion. For the cubic polynomial (<italic>P</italic> &#x003D; 3) fit shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> there are in fact 4 basis functions: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline11.gif"/></alternatives></inline-formula>, <italic>b</italic><sub>2</sub>(<italic>x</italic><sub><italic>t</italic></sub>) &#x003D; <italic>x</italic><sub><italic>t</italic></sub>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline12.gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline13.gif"/></alternatives></inline-formula>. Note that <italic>b</italic><sub>1</sub>(<italic>x</italic><sub><italic>t</italic></sub>) is constant and is linked to the model intercept, <italic>&#x03b2;</italic><sub>0</sub>, in the linear model <xref ref-type="disp-formula" rid="eqn2">(2)</xref>, and further, that the basis function weights are the estimated coefficients in the model, the <italic>&#x03B2;</italic><sub><italic>j</italic></sub>.</p>
<p>As we have already seen, polynomial basis expansions do not necessarily lead to well-fitting models unless the true function <italic>f</italic> is itself a polynomial. One of the primary criticisms is that polynomial basis functions are global (<xref ref-type="bibr" rid="c28">Magee, 1998</xref>); the value of <italic>f</italic> at time point <italic>x</italic><sub><italic>t</italic></sub> affects the value of <italic>f</italic> at time point <italic>x</italic><sub><italic>t</italic>&#x002B;<italic>s</italic></sub> even if the two time points are at opposite ends of the series. There are many other bases we could use; here I discuss one such set of bases, that of splines.</p>
<p>There are a bewildering array of different types of spline. In the models discussed below we will largely restrict ourselves to cubic regression splines (CRS) and thin plate regression splines (TPRS). In addition, I also discuss two special types of spline basis, an adaptive spline basis and a Gaussian process spline basis.</p>
<p>A cubic spline is a smooth curve comprised of sections of cubic polynomials, where the sections are joined together at some specified locations &#x2014; known as <italic>knots</italic> &#x2014; in such a way that at the joins, the two sections of cubic polynomial that meet have the same value as well as the same first and second derivative. These properties mean that the sections join smoothly and differentiably at the knots (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>, 5.3.1).</p>
<p>The CRS can be parameterized in a number of different ways. One requires a knot at each unique data value in <italic>x</italic><sub><italic>t</italic></sub>, which is computationally inefficient. Another way of specifying a CRS basis is to parameterize in terms of the value of the spline at the knots. Typically in this parametrization there are many fewer knots than unique data, with the knots distributed evenly over the range of <italic>x</italic><sub><italic>t</italic></sub> or at the quantiles of <italic>x</italic><sub><italic>t</italic></sub>. Placing knots at the quantiles of <italic>x</italic><sub><italic>t</italic></sub> has the effect of placing a greater number of knots where the data is densest.</p>
<p>A CRS basis expansion comprised of 7 basis functions for the time covariate in the Small Water series, is shown in <xref ref-type="fig" rid="fig3">Figure 3a</xref>. The tick marks on the x-axis show the locations of the knots, which are located at the ends of the series and evenly in between. Notice that in this particular parametrization, the <italic>j</italic>th basis function takes a value of 1 at the <italic>j</italic>th knot and at all other knots a value of 0.</p>
<p>To estimate a model using this basis expansion each basis function forms a column in the model matrix <bold>X</bold> and the weights <italic>&#x03B2;</italic><sub><italic>j</italic></sub> can be found using least squares regression (assuming a Gaussian response). Note that in order to estimate a coefficient for each basis function the model has to be fitted without an intercept term. In practice we would include an intercept term in the model and therefore the basis functions are modified via an identifiability constraint (@ <xref ref-type="bibr" rid="c62">Wood, 2017</xref>). This has the effect of making the basis orthogonal to the intercept but results in more complicated basis functions than those shown in in <xref ref-type="fig" rid="fig3">Figure 3a</xref>.</p>
<fig id="fig3" position="float" fig-type="figure"><label>Figure 3:</label>
<caption><p>Basis functions for the time covariate and the Small Water <italic>&#x03B4;</italic><sup>15</sup>N time series. A rank (size) 7 cubic regression spline (CRS) basis expansion is show in a), with knots, indicated by tick marks on the x-axis, spread evenly through the rang of the data. b) shows the same CRS basis functions weighted by the estimated coefficients <italic>&#x03B2;</italic><sub><italic>j</italic></sub>, plus the resulting GAM trend line (black line drawn through the data). The grey points in both panels are the observed <italic>&#x03B4;</italic><sup>15</sup>N values. c) A rank 7 thin plate regression spline basis for the same data.</p></caption>
<graphic xlink:href="322248_fig3.tif"/>
</fig>
<p>Having estimated the weight for each basis function, the <italic>j</italic>th basis function <italic>b</italic><sub><italic>j</italic></sub> is scaled (weighted) by its coefficient <italic>&#x03B2;</italic><sub><italic>j</italic></sub>. The scaled CRS basis functions for the Small Water time series are shown in <xref ref-type="fig" rid="fig3">Figure 3b</xref>. The solid line passing through the data points is formed by summing up the values of the scaled basis functions (<italic>b</italic><sub><italic>j</italic></sub>(<italic>x</italic><sub><italic>t</italic></sub>)<italic>&#x03B2;</italic><sub><italic>j</italic></sub>) at any value of <italic>x</italic><sub><italic>t</italic></sub> (time).</p>
<p>Cubic regression splines, as well as many other types of spline, require the analyst to choose the number and location of the knots that parametrise the basis. Thin plate regression splines (TPRS) remove this element of subjectivity when fitting GAMs. Thin plate splines were introduced by <xref ref-type="bibr" rid="c13">Duchon (1977)</xref> and, as well as solving the knot selection problem, have several additional attractive properties in terms of optimality and their ability to estimate a smooth function of two or more variables, leading to smooth interactions between covariates. However, thin plate splines have one key disadvantage over CRS; thin plate splines have as many unknown parameters as there are unique combinations of covariate values in a data set (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>, 5.5.1). It is unlikely that any real data problem would involve functions of such complexity that they require as many basis functions as data. It is much more likely that the true functions that we attempt to estimate are far simpler than the set of functions representable by 1 basis function per unique data value. From a practical point of view, it is also highly inefficient to carry around all these basis functions whilst model fitting, and the available computational resources would become quickly exhausted for large time series with many observations.</p>
<p>To address this issue low rank thin plate regression splines (TPRS) have been suggested which truncate the space of the thin plate spline basis to some lower number of basis functions whilst preserving much of the advantage of the original basis as an optimally-fitting spline (<xref ref-type="bibr" rid="c59">Wood, 2003</xref>). A rank 7 TPRS basis (i.e. one containing 7 basis functions) is shown in <xref ref-type="fig" rid="fig3">Figure 3c</xref> for the Small Water time series. The truncation is achieved by performing an eigen-decomposition of the basis functions and retaining the eigenvectors associated with the <italic>k</italic> largest eigenvalues. This is similar to the way principal components analysis decomposes a data set into axes of variation (eigenvectors) in decreasing order of variance explained. The truncated basis can preserve much of the space of functions spanned by the original basis but at the cost of using far fewer basis functions (<xref ref-type="bibr" rid="c59">Wood, 2003</xref>, <xref rid="c62" ref-type="bibr">2017</xref>, 5.5.1). Note the horizontal TPRS basis function (at &#x03B4;<sup>15</sup>N &#x003D; 1) in <xref ref-type="fig" rid="fig3">Figure 3c</xref>; this basis function is confounded with the intercept term and, after the application of identifiability constraints, ends up being removed from the set of basis functions used to fit the model.</p>
<p>The truncation suggested by <xref ref-type="bibr" rid="c59">Wood (2003)</xref> is not without cost; the eigen-decomposition and related steps can be relatively costly for large data sets. For data sets of similar size to the two examples used here, the additional computational effort required to set up the TPRS basis over the CRS basis will not be noticeable. For highly resolved series containing more than &#x007E;1000 observations the truncation may be costly computationally. In such instances, little is lost by moving to the CRS basis with the same number of knots as the rank of the desired TPRS, with the benefit of considerably reduced set up time for the basis.</p>
<p>To fit a GAM using either of the two regression spline bases described above, the analyst is generally only required to the specify the size (rank) of the basis expansion required to represent or closely approximate the true function <italic>f</italic>. With practice and some knowledge of the system from which the observations arise, it can be relatively easy to put an upper limit on the expected complexity of the true trend in the data. Additionally, the number available data points places a constraint on the upper limit of the size of basis expansion that can be used.</p>
<p>In practice, the size of the basis is an upper limit on the expected complexity of the trend, and a simple test to check if the basis used was sufficiently large (<xref ref-type="bibr" rid="c41">Pya and Wood, 2016</xref>). This test is available via the <monospace>gam.check()</monospace> function in <italic>mgcv</italic> for example, which essentially looks at whether there is any additional nonlinearity or structure in the residuals that can be explained by a further smooth of <italic>x</italic><sub><italic>t</italic></sub>. Should a smooth term in the fitted model fail this test the model can be refitted using a larger basis expansion, say by doubling the value of <italic>k</italic> (the rank) used to fit the original. Note also that a smooth might fail this test whilst using fewer effective degrees of freedom than the maximum possible for the dimension of basis used. This may happen when the true function lies at the upper limit of the set of functions encompassed by the size of basis used. Additionally, a basis of size 2<italic>k</italic> encompasses a richer space of functions of a given complexity than a basis of size <italic>k</italic> (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>); increasing the basis dimension used to fit the model may unlock this additional function space resulting in a better fitting model whilst using a similar number of effective degrees of freedom.</p>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Smoothness selection</title>
<p>Having identified low rank regression splines as a useful way to represent <italic>f</italic>, we next need a way to decide how wiggly the fitted trend should be. A backwards elimination approach to sequentially remove knots or basis functions might seem appropriate, however such an approach would likely fail as the resulting sequence of models would not be strictly nested, precluding many forms of statistical comparison (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>). Alternatively, we could keep the basis dimension at a fixed size but guard against fitting very complex models through the use of a wiggliness penalty.</p>
<p>The default wiggliness penalty used in GAMs is on the second derivative of the spline, which measures the rate of change of the slope, or the curvature, of the spline at any infinitesimal point in the interval spanned by <italic>x</italic><sub><italic>t</italic></sub>. The actual penalty used is the integrated squared second derivative of the spline
<disp-formula id="eqn5"><alternatives><graphic xlink:href="322248_eqn5.gif"/></alternatives></disp-formula>.</p>
<p>The right hand side of <xref ref-type="disp-formula" rid="eqn5">(5)</xref> is the penalty in quadratic form. The convenience of the quadratic form is that it is a function of the estimated coefficients of <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>) where <bold>S</bold> is known as the penalty matrix. Notice that now both the weights for the basis functions and the wiggliness penalty are expressed as functions of the model coefficients.</p>
<p>Now that we have a convenient way to measure wiggliness, it needs to be incorporated into the objective function that will be minimised to fit the GAM. The likelihood of the model given the parameter estimates <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline14.gif"/></alternatives></inline-formula> is combined with the penalty to create the penalized likelihood <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline15.gif"/></alternatives></inline-formula>:
<disp-formula id="ueqn3"><alternatives><graphic xlink:href="322248_ueqn3.gif"/></alternatives></disp-formula>.</p>
<p>The fraction of a half is there simply to make the penalised likelihood equal the penalised sum of squares in the case of a Gaussian model. &#x03BB; is known as the smoothness parameter and controls the extent to which the penalty contributes to the likelihood of the model. In the extreme case of &#x03BB; &#x003D; 0 the penalty has no effect and the penalized likelihood equals the likelihood of the model given the parameters. At the other extreme, as &#x03BB; &#x2192; &#x221E; the penalty comes to dominate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline16.gif"/></alternatives></inline-formula> and the wiggliness of <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>) tends to 0 resulting in an infinitely smooth function. In the case of a second derivative penalty, this is a straight line, and we recover the simple linear trend from <xref ref-type="disp-formula" rid="eqn1">(1)</xref> when assuming a Gaussian response.</p>
<p><xref ref-type="fig" rid="fig4">Figure 4</xref> illustrates how the smoothness parameter &#x03BB; controls the degree of wiggliness in the fitted spline. Four models are shown, each fitted with a fixed value of &#x03BB;; 10000, 1, 0.01, and 0.00001. At &#x03BB; &#x003D; 10000 the model effectively fits a linear model through the data. As the value of &#x03BB; decreases, the fitted spline becomes increasingly wiggly. As &#x03BB; becomes very small, the resulting spline passes through most of the &#x03B4;<sup>15</sup>N observations resulting in a model that is clearly over fitted to the data.</p>
<fig id="fig4" position="float" fig-type="figure"><label>Figure 4:</label>
<caption><p>The effect of the smoothness parameter &#x03BB; on the resulting wiggliness of the estimated spline. Large values of &#x03BB; penalize wiggliness strongly, resulting in smooth trends (upper row), while smaller values allow increasingly wiggly trends. The aim of automatic smoothness selection is to find an optimal value of &#x03BB; that balances the fit of the model with model complexity to avoid overfitting.</p></caption>
<graphic xlink:href="322248_fig4.tif"/>
</fig>
<p>To fully automate smoothness selection for <italic>f</italic>(<italic>x</italic><sub><italic>t</italic></sub>) we need to estimate &#x03BB;. There are two main ways that &#x03BB; can be automatically chosen during model fitting. The first way is to choose &#x03BB; such that it minimises the prediction error of the model. This can be achieved by choosing &#x03BB; to minimise Akaike&#x2019;s information criterion (AIC) or via cross-validation (CV) or generalized cross-validation (GCV; <xref ref-type="bibr" rid="c12">Craven and Wahba, 1978</xref>). GCV avoids the computational overhead inherent to CV of having to repeatedly refit the model with one or more observations left out as a test set. Minimising the GCV score will, with a sufficiently large data set, find a model with the minimal prediction error (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>). The second approach is to treat the smooth as a random effect, in which &#x03BB; is now a variance parameter to be estimated using maximum likelihood (ML) or restricted maximum likelihood (REML; <xref ref-type="bibr" rid="c61">Wood, 2011</xref>; <xref ref-type="bibr" rid="c63">Wood et al., 2016</xref>).</p>
<p>Several recent results have shown that GCV, under certain circumstances, has a tendency to under smooth, resulting in fitted splines that are overly wiggly (<xref ref-type="bibr" rid="c45">Reiss and Ogden, 2009</xref>). Much better behaviour has been observed for REML and ML smoothness selection, in that order (<xref ref-type="bibr" rid="c61">Wood, 2011</xref>). REML is therefore the recommended means of fitting GAMs, though, where models have different fixed effects (covariates) they cannot be compared using REML, and ML selection should be used instead. In the sorts of data examples considered here there is only a single covariate <italic>x</italic><sub><italic>t</italic></sub> as our models contain a single estimated trend so REML smoothness selection is used throughout unless otherwise stated.</p>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Fitting GAMs</title>
<sec id="s4a">
<label>4.1</label>
<title>Small Water</title>
<p>The trend in &#x03B4;<sup>15</sup>N values is clearly non-linear but it would be difficult to suggest a suitable polynomial model that would allow for periods of relatively no change in &#x03B4;<sup>15</sup>N as well as rapid change. Instead, a GAM is ideally suited to modelling such trends; the data suggest a smoothly varying change in &#x03B4;<sup>15</sup>N between 1925 and 1975. It is reasonable to expect some autocorrelation in the model errors about the fitted trend. Therefore I fitted the following GAM to the &#x03B4;<sup>15</sup>N time series.
<disp-formula id="eqn6"><alternatives><graphic xlink:href="322248_eqn6.gif"/></alternatives></disp-formula>.</p>
<p>Now the i.i.d. assumption has been relaxed and a correlation matrix, &#x039B;, has been introduced that is used to model autocorrelation in the residuals. The &#x03B4;<sup>15</sup>N values are irregularly spaced in time and a correlation structure that can handle the uneven spacing is needed (<xref ref-type="bibr" rid="c38">Pinheiro and Bates, 2000</xref>). A continuous time first-order autoregressive process (CAR(1)) is a reasonable choice; it is the continuous-time equivalent of the first-order autoregressive process (AR(1)) and, simply stated, models the correlation between any two residuals as an exponentially decreasing function of <italic>h</italic> (<italic>&#x03D5;</italic><sup><italic>h</italic></sup>), where <italic>h</italic> is the amount of separation in time between the residuals (<xref ref-type="bibr" rid="c38">Pinheiro and Bates, 2000</xref>). <italic>h</italic> may be a real valued number in the CAR(1), which is how it can accommodate the irregular separation of samples in time. <italic>&#x03D5;</italic> controls how quickly the correlation between any two residuals declines as a function of their separation in time and is an additional parameter that will be estimated during model fitting. The model in <xref ref-type="disp-formula" rid="eqn6">(6)</xref> was fitted using the <monospace>gamm()</monospace> function (<xref ref-type="bibr" rid="c60">Wood, 2004</xref>) in the <italic>mgcv</italic> package (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>) for R (<xref ref-type="bibr" rid="c42">R Core Team, 2017</xref>).</p>
<p>The fitted trend is shown in <xref ref-type="fig" rid="fig5">Figure 5a</xref>, and well-captures the strong pattern in the data. The trend is statistically significant (estimated degrees of freedom &#x003D; 7.95; <italic>F</italic> &#x003D; 47.44, approximate <italic>p</italic> value &#x003D; &#x226A; 0.0001). However further analysis of the fitted model is required to answer the other questions posed earlier about the timing of change and whether features in the trend can be distinguished from random noise. I discuss these issues shortly.</p>
<fig id="fig5" position="float" fig-type="figure"><label>Figure 5:</label>
<caption><p>GAM-based trends fitted to the Small Water <italic>&#x03B4;</italic><sup>15</sup>N (a) and Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline17.gif"/></alternatives></inline-formula> (b) time series. The shaded bands surrounding the estimated trends are approximate 95&#x0025; across-the-function confidence intervals. For the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline18.gif"/></alternatives></inline-formula> series, two models are shown; the orange fit is the result of a GAM with a continuous-time AR(1) process estimated using REML smoothness selection, while the blue fit is that of a simple GAM with GCV-based smoothness selection. The REML-based fit significantly oversmooths the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline19.gif"/></alternatives></inline-formula> time series.</p></caption>
<graphic xlink:href="322248_fig5.tif"/>
</fig>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Braya-S&#x00F8;</title>
<p>The <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline20.gif"/></alternatives></inline-formula> data present a more difficult data analysis challenge than the &#x03B4;<sup>15</sup>N time series because of the much more complex variation present. Fitting the same model as the Small Water example, <xref ref-type="disp-formula" rid="eqn6">(6)</xref>, to the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline21.gif"/></alternatives></inline-formula> data resulted in the unsatisfactory fit shown as the very smooth line in <xref ref-type="fig" rid="fig5">Figure 5b</xref> (labelled GAMM (CAR(1))). Further problems were evident with this model fit &#x2014; the covariance matrix of the model was non-positive definite, a sure sign of problems with the fitted model. Refitting with a smaller basis dimension (<italic>k</italic> &#x003D; 20) for the trend term resulted in a model with a positive-definite covariance matrix for the model variance-covariance terms, but the estimated value of of the CAR(1) parameter <italic>&#x03D5;</italic> &#x003D; 0.2 was exceedingly uncertain (95&#x0025; confidence interval 0-1&#x0021;)</p>
<p>Fitting this model as a standard GAM with REML smoothness selection resulted in the same fitted trend as the GAM with CAR(1) errors (not shown), whilst using GCV smoothness selection resulted in a much more satisfactory fitted trend. There are two potential problems with the GCV-selected trend: i) GCV is sensitive to the profile of the GCV score and has been shown to under smooth data in situations where the profile is flat around the minimum GCV score, and ii) the model fitted assumes that the observations are independent, an assumption that is certainly violated in the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline23.gif"/></alternatives></inline-formula> time series.</p>
<p>To investigate the first issue, the GCV and REML scores for an increasing sequence of values of the smoothness parameter (&#x03BB;) were evaluated for the standard GAM (<xref ref-type="disp-formula" rid="eqn4a">equation (4)</xref>) fit to the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline24.gif"/></alternatives></inline-formula> time series. The resulting profiles are shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>, with the optimal value of the parameter shown by the vertical line. The GCV score profile suggests that the potential for under smoothing identified by <xref ref-type="bibr" rid="c45">Reiss and Ogden (2009)</xref> is unlikely to apply here as there is a well-defined minimum in profile.</p>
<fig id="fig6" position="float" fig-type="figure"><label>Figure 6:</label>
<caption><p>GCV and REML scores as a function of the smoothness parameter &#x03BB;. From left to right, GAMs were estimated using GCV and REML smoothness selection, and REML using a basis dimension of 40 and observational weights to account for heterogeneity in the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline22.gif"/></alternatives></inline-formula> times series. The selected value of &#x03BB; for each model is indicated by the vertical grey line.</p></caption>
<graphic xlink:href="322248_fig6.tif"/>
</fig>
<p>To understand the reason why the GAM plus CAR(1) and the simple GAM with REML smoothness selection performed poorly with the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline25.gif"/></alternatives></inline-formula> time series we need to delve a little deeper into what is happening when we are fitting these two models.</p>
<p>The primary issue leading to poor fit is that neither model accounts for the different variance (known as (heteroscedasticity) of each observation in the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline26.gif"/></alternatives></inline-formula> record. This seemingly isn&#x2019;t a problem for GCV which minimizes prediction error. The sediments in Braya-S&#x00F8; are not annually laminated and therefore the core was sliced at regular depth intervals. Owing to compaction of older sediments and variation in accumulation rates over time, each sediment slice represents a different number of &#x201C;lake years&#x201D;. We can think of older samples as representing some average of many years of sediment deposition, whilst younger samples are representative of fewer of these lake years. The average of a larger set of numbers is estimated more precisely than the average of a smaller set, all things equal. A direct result of this variable averaging of lake years it that some samples are more precise and therefore have lower variance than other samples and yet the model assumed that the variance was constant across samples.</p>
<p>Accounting for heteroscedasticity within the model is relatively simple via the use of observational weights. The number of lake years represented by each slice is estimated by assigning a date to the top and bottom of each sediment slice. The variance of each observation should be proportional to the inverse of the number of lake years each sample represents. In the <monospace>gam()</monospace> function used here, weights should be specified as the number of lake years each sample represents. Other software may require the weights to be specified in a different way.</p>
<p>A secondary problem is the size of the basis dimension used for the time variable. The main user selectable option when fitting a GAM in the penalised likelihood framework of <xref ref-type="bibr" rid="c60">Wood (2004)</xref> is how many basis functions to use. As described above, the basis should be large enough to contain the true, but unknown, function or a close approximation to it. For GCV selection the basis used contained 29 basis functions, whilst the CAR(1) model with REML smoothness selection would only converge with a basis containing 20 functions. The size of the basis appears to be sufficient for GCV smoothness selection, but following <xref rid="c61" ref-type="bibr">Wood (2011)</xref> REML smoothness selection is preferred. Using the test of <xref ref-type="bibr" rid="c41">Pya and Wood (2016)</xref>, the basis dimension for the models with REML smoothness selection was too small. To proceed therefore, we must drop the CAR(1) term and increase the basis dimension to 39 functions (by setting k &#x003D; 40; I set it larger than expected because the larger basis contains a richer family of functions and the excess complexity is reduced because of the smoothness penalty.)</p>
<p>With the larger basis dimension and accounting for the non-constant variance of the observations via weights, the model fitted using REML is indistinguishable from that obtained using GCV (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). The trace of the REML score for this model shows a pronounced minimum at a much smaller value of &#x03BB; than the original REML fit (<xref ref-type="fig" rid="fig6">Figure 6</xref>), indicating that a more wiggly trend provides a better fit to the Braya-S&#x00F8; time series. This example illustrates that some care and understanding of the underlying principles of GAMs is required to diagnose potential issues with the estimated model. After standard modelling choices (size of basis to use, correct selection of response distribution and link function, etc.) are checked, it often pays to think carefully about the properties of the data and ensure that the assumptions of the model are met. Here, despite increasing the basis size, it was the failure to appreciate the magnitude of the effect on fitting of the non-constant variance that lead to the initially poor fit and the problems associated with the estimation of the CAR(1) process. I return to the issue of why the GAM plus CAR(1) model encountered problems during fitting later (see Identifiability).</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Confidence intervals and uncertainty estimation</title>
<p>If we want to ask whether either of the estimated trends is statistically interesting or proceed to identifying periods of significant change, we must address the issue of uncertainty in the estimated model. What uncertainty is associated with the trend estimates? One way to visualise this is through a 1 - <italic>&#x03B1;</italic> confidence interval around the fitted trend, where <italic>&#x03B1;</italic> is say 0.05 leading to a 95&#x0025; interval. A 95&#x0025; interval would be drawn at <italic>&#x0177;</italic><sub><italic>t</italic></sub>&#x00B1;(<italic>m</italic><sub>1-&#x03B1;</sub>&#x00D7; SE(&#x0177;<sub><italic>t</italic></sub>)), with <italic>m</italic><sub>1-&#x03B1;</sub> &#x003D; 1.96, the 0.95 probability quantile of a standard normal distribution, and SE(&#x0177;<sub><italic>t</italic></sub>) is the standard error of the estimated trend at time <italic>x</italic><sub><italic>t</italic></sub>. This type of confidence interval would normally be described as <italic>pointwise</italic>; the coverage properties of the interval being correct for a single point on the fitted trend, but, if we were to consider additional points on the trend, the coverage would logically be lower than 1 - <italic>&#x03B1;</italic>. This is the traditional frequentist interpretation of a confidence interval. However, the GAM described here has a Bayesian interpretation (<xref ref-type="bibr" rid="c27">Kimeldorf and Wahba, 1970</xref>; <xref ref-type="bibr" rid="c48">Silverman, 1985</xref>; <xref ref-type="bibr" rid="c53">Wahba, 1983</xref>, <xref ref-type="bibr" rid="c54">1990</xref>) and therefore the typical frequentist interpretation does not apply. <xref ref-type="bibr" rid="c36">Nychka (1988)</xref> investigated the properties of a confidence interval created as described above using standard errors derived from the Bayesian posterior covariance matrix for the estimated mode parameters. Such intervals have the interesting property that they have good <italic>across-the-function</italic> coverage when considered from a frequentist perspective. This means that, when averaged over the range of the function, the Bayesian credible intervals shown in <xref ref-type="fig" rid="fig5">Figure 5</xref> have close to the expected 95&#x0025; coverage. However, to achieve this some parts of the function may have more or less than 95&#x0025;-coverage. <xref ref-type="bibr" rid="c31">Marra and Wood (2012)</xref> recently explained <xref rid="c36" ref-type="bibr">Nychka&#x2019;s (1988)</xref> surprising results and extended them to the case of generalized models (non-Gaussian responses).</p>
<p>Whilst the <italic>across-the-function</italic> frequentist interpretation of the Bayesian credible intervals is useful, if may be important to have an interval that contains the entirety of the true function with some state probability (1 - <italic>&#x03B1;</italic>). Such an interval is known as a <italic>simultaneous</italic> interval. A (1 - <italic>&#x03B1;</italic>)100&#x0025; simultaneous confidence interval contains <italic>in their entirety</italic> 1 - <italic>&#x03B1;</italic> of all random draws from the posterior distribution of the fitted model.</p>
<p>Fitting a GAM involves finding estimates for coefficients of the basis functions. Together, these coefficients are distributed multivariate normal with mean vector and covariance matrix specified by the model estimates of the coefficients and their covariances respectively. Random draws from this distribution can be taken, where each random draw represents a new trend that is consistent with the fitted trend but also reflects the uncertainty in the estimated trend. This process is known as <italic>posterior simulation</italic>.</p>
<p><xref ref-type="fig" rid="fig7">Figure 7</xref> shows 20 random draws from the posterior distribution of the GAMs fitted to the Small Water and Braya-S&#x00F8; data sets. In the early period of the &#x03B4;<sup>15</sup>N time series many of the posterior simulations exhibit short periods of increasing and decreasing trend, balancing out to the relatively flat trend estimated by the GAM (<xref ref-type="fig" rid="fig7">Fig. 7a</xref>). Reflecting this uncertainty, we might expect relatively wide simultaneous intervals during this period in order to contain the vast majority of the simulated trends. Conversely, the decreasing &#x03B4;<sup>15</sup>N trend starting at &#x007E;1945 is consistently reproduced in the posterior simulations, suggesting that this feature of the time series is both real and statistically significant, and that the rate of change in &#x03B4;<sup>15</sup>N is relatively precisely estimated. We see a similar pattern in <xref ref-type="fig" rid="fig7">Figure 7b</xref> for the Braya-S&#x00F8; record; the large peak in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline28.gif"/></alternatives></inline-formula> at &#x007E;250CE and the strong decline at &#x007E;1200CE are well defined in the posterior simulations, whereas most of the localised trends that are smaller magnitude changes in <italic>y</italic><sub><italic>t</italic></sub> are associated with posterior simulations that are less well constrained with the ends of the record in particular showing considerable variation in the strength, timing, and even sign of simulated trends, reflecting the greater uncertainty in estimated trend during these periods. For the random draws illustrated in <xref ref-type="fig" rid="fig7">Figure 7</xref>, a (1 - <italic>&#x03B1;</italic>)100&#x0025; simultaneous interval should contain the entire function for on average 19 of the 20 draws.</p>
<fig id="fig7" position="float" fig-type="figure"><label>Figure 7:</label>
<caption><p>Estimated trends (thick black lines) and 20 random draws (grey lines) from the posterior distribution of the GAM fitted to the Small Water <italic>&#x03B4;</italic><sup>15</sup>N (a) and Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline27.gif"/></alternatives></inline-formula> (b) time series.</p></caption>
<graphic xlink:href="322248_fig7.tif"/>
</fig>
<p>There are a number of ways in which a simultaneous interval can be computed. Here I follow the simulation approach described by <xref ref-type="bibr" rid="c47">Ruppert et al. (2003)</xref> and present only the basic detail; a fuller description is contained in <xref ref-type="app" rid="app1">Appendix 1</xref>. The general idea is that if we want to create an interval that contains the whole of the true function with 1 - <italic>&#x03B1;</italic>. probability, we need to increase the standard Bayesian credible interval by some amount. We could simulate a large number of functions from the posterior distribution of the model and then search for the value of <italic>m</italic><sub>1-<italic>&#x03B1;</italic></sub> that when multiplied by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline29.gif"/></alternatives></inline-formula> yielded an interval that contained the whole function for (1 - <italic>&#x03B1;</italic>) 100&#x0025; of the functions simulated. In practice, the simulation method of <xref ref-type="bibr" rid="c47">Ruppert et al. (2003)</xref> does not involve a direct search, but yields the critical value <italic>m</italic><sub>1-<italic>&#x03B1;</italic></sub> required.</p>
<p>Simultaneous intervals computed using the method described are show in <xref ref-type="fig" rid="fig8">Figure 8</xref> alongside the <italic>across-the-function</italic> confidence intervals for the trends fitted to both example data sets. As expected, the simultaneous interval is somewhat wider than the <italic>across-the-function</italic> interval. The critical value <italic>m</italic><sub>1-<italic>&#x03B1;</italic></sub> for the simultaneous interval of the estimated trend in &#x03B4;<sup>15</sup>N is 3.08, whilst the same value for the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline30.gif"/></alternatives></inline-formula> series is 3.42, leading to intervals that are approximately &#x00B1;50&#x0025; and &#x00B1;75&#x0025; wider than the equivalent across-the-function intervals.</p>
<fig id="fig8" position="float" fig-type="figure"><label>Figure 8:</label>
<caption><p>95&#x0025; simultaneous confidence intervals (light grey bands) and across-the-function confidence intervals (dark grey bands) on the estimated trends (black lines) for the Small Water <italic>&#x03B4;</italic><sup>15</sup>N (a) and Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline35.gif"/></alternatives></inline-formula> (b) time series.</p></caption>
<graphic xlink:href="322248_fig8.tif"/>
</fig>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Identifying periods change</title>
<p>In the simple linear trend model <xref ref-type="disp-formula" rid="eqn1">(1)</xref> whether the estimated trend constitutes evidence for or against a null hypothesis of no change rests on how large the estimated rate of change in <italic>y</italic><sub><italic>t</italic></sub> is <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline31.gif"/></alternatives></inline-formula> relative to its uncertainty. This is summarised in the <italic>t</italic> statistic. As the rate of change in <italic>y</italic><sub><italic>t</italic></sub> is constant over the fitted trend &#x2014; there is only a singe slope for the fitted trend <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline32.gif"/></alternatives></inline-formula> &#x2014; if the <italic>t</italic> statistic of the test that <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline33.gif"/></alternatives></inline-formula> is unusually extreme this would be evidence against the null hypothesis of no change. Importantly, this applies to the whole time series as the linear model implies a constant rate of change throughout. More formally, the estimate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline34.gif"/></alternatives></inline-formula> is the first derivative of the fitted trend.</p>
<p>In the GAM, the fitted trend need not be linear; the slope of the trend is potentially different at every point in the time series. As such we might reasonably ask <italic>where</italic> in the series the response <italic>y</italic><sub><italic>t</italic></sub> is changing, if at all? Mirroring the linear model we can answer this question by determining whether or not the first derivative at any time point <italic>x</italic><sub><italic>t</italic></sub> of the fitted trend at any time point is consistent with a null hypothesis of no change. We want to know whether or not the first derivative is indistinguishable from a value of 0 &#x2014; no trend &#x2014; given the uncertainty in the estimate of the derivative.</p>
<p>Derivatives of the fitted spline are not easily available analytically, but they can be estimated using the method of finite differences. Two values of the estimated trend, separated by a very small time-shift (&#x0394;<sub><italic>t</italic></sub>), are predicted from the model; the difference between the estimated values for the two time points is an approximation of the true first derivative of the trend. As &#x0394;<sub><italic>t</italic></sub> &#x2192; 0 the approximation becomes increasingly accurate. In practice, the first derivative of the fitted trend is evaluated using finite differences at a large number of points in the time series. An approximate (1 - <italic>&#x03B1;</italic>)100&#x0025; pointwise confidence interval can be calculated for the derivative estimates using standard theory (i.e. &#x00B1;1.96xSE(&#x0177;<sub><italic>t</italic></sub>) for a 85&#x0025; interval) and the covariance matrix of the spline coefficients. A (1 - &#x03B1;)100&#x0025; simultaneous interval for the derivatives can also be computed using the method described earlier. Periods of significant change are identified as those time points where the (simultaneous) confidence interval on the first derivative does not include zero.</p>
<p><xref ref-type="fig" rid="fig9">Figure 9</xref> shows the estimated first derivative of the fitted trend in the Small Water (9a) and Braya-S&#x00F8; (9b) time series. Although the estimated trend suggests a slight increase in &#x03B4;<sup>15</sup>N from the start of the record to &#x007E;1940, the estimated trend is sufficiently uncertain that the simultaneous interval on the first derivative includes 0 throughout. We can understand why this is so by looking at the posterior simulations in <xref ref-type="fig" rid="fig7">Figure 7a</xref>; there is considerable variation in the shape of the simulated trends throughout this period. From &#x007E;1925 the derivative of the trend becomes negative, however it is not until &#x007E;1940 that the simultaneous interval doesn&#x2019;t include 0. At this point we have evidence to reject the null hypothesis of no change. This time point may be taken as the first evidence for change in &#x03B4;<sup>15</sup>N in the Small Water core. The simultaneous interval on the first derivative of the trend in &#x03B4;<sup>15</sup>N is bounded away from 0 between &#x007E;1940 and &#x007E;1975, covering the major decline in values evident in the observations. The simultaneous interval includes 0 from &#x007E;1975 onward, suggesting that, whilst quite pronounced, the recent increase in &#x03B4;<sup>15</sup>N is not statistically significant. To determine whether or not the recent increase is real, we would require considerably more samples with which to (hopefully) more-precisely estimate the trend during this period. Alternatively, we might just have to wait until sufficient additional sedimentation has occurred to warrant recoring Small Water and reestimating the trend in &#x03B4;<sup>15</sup>N.</p>
<fig id="fig9" position="float" fig-type="figure"><label>Figure 9:</label>
<caption><p>Estimated first derivatives (black lines) and 95&#x0025; simultaneous confidence intervals of the GAM trends fitted to the Small Water &#x03B4;<sup>15</sup>N (a) and Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline39.gif"/></alternatives></inline-formula> (b) time series. Where the simultaneous interval does not include 0, the models detect significant temporal change in the response.</p></caption>
<graphic xlink:href="322248_fig9.tif"/>
</fig>
<p>The estimated trend at Braya-S&#x00F8; exhibited a number of oscillations in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline36.gif"/></alternatives></inline-formula>. As we saw previously in <xref ref-type="fig" rid="fig7">Figures 7b</xref> and 8b, many of these are subject to significant uncertainty and it is important therefore to discern which, if any, of the oscillations in the response can be identified given the model uncertainty. In <xref ref-type="fig" rid="fig9">Figure 9b</xref> only two features of the estimated trend are considered significant based on the derivatives of the smooth; one centred on &#x007E;250CE and a second at &#x007E;1150CE. In both these periods, the simultaneous interval for the first derivative of the trend does not include zero. In the first case we detect the large peak and subsequent decline in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline37.gif"/></alternatives></inline-formula> at &#x007E;250CE, whilst at &#x007E;1150CE the large trough is identified, but not the increasing trend immediately prior to this excursion to lower <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline38.gif"/></alternatives></inline-formula>. Recall that these intervals are simultaneous in nature, strongly guarding against false positives, and as such we can be confident in the estimation of these two features, whilst care must be taken to not over-interpret the remaining variations in the estimated trend.</p>
</sec>
<sec id="s4e">
<label>4.5</label>
<title>Residual autocorrelation and model identification</title>
<p>The GAM fitted to the &#x03B4;<sup>15</sup>N time series contained a CAR(1) process to model residual temporal autocorrelation in the residuals. The estimated magnitude of the autocorrelation is given by the parameter <italic>&#x03D5;</italic>. The estimated value of <italic>&#x03D5;</italic> for the &#x03B4;<sup>15</sup>N series is 0.6 with 95&#x0025; confidence interval 0.28&#x2013;0.85, indicating moderate to strong residual autocorrelation about the fitted trend. The correlation function is an exponentially decreasing function of temporal separation (&#x0394;<sub><italic>t</italic></sub>), and whilst observations that are a few years apart are quite strongly dependent on one another, this dependence drops off rapidly as &#x0394;<sub><italic>t</italic></sub> increases and is effectively zero when samples are separated by a decade or more (<xref ref-type="fig" rid="fig10">Figure 10</xref>).</p>
<fig id="fig10" position="float" fig-type="figure"><label>Figure 10:</label>
<caption><p>Estimated CAR(1) process from the GAM fitted to the Small Water <italic>&#x03B4;</italic><sup>15</sup>N time series. <italic>h</italic>(&#x0394;<sub><italic>t</italic></sub>, <italic>&#x03D5;</italic>) is the correlation between residuals separated by &#x0394;<sub><italic>t</italic></sub> years, where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline43.gif"/></alternatives></inline-formula> The shaded band is a 95&#x0025; pointwise confidence interval on the estimated correlation <italic>h</italic>.</p></caption>
<graphic xlink:href="322248_fig10.tif"/>
</fig>
<p>Failure to account for the dependencies in the &#x03B4;<sup>15</sup>N time series could lead to the estimation of a more wiggly trend than the one shown in <xref ref-type="fig" rid="fig5">Figure 5a</xref> which would negatively impact the confidence placed on the inferences we might draw from the fitted model. Importantly, failing to account for the strong dependency in the residuals would lead to smaller uncertainties in the estimated spline coefficients, which would propagate through to narrower confidence intervals on the fitted trend and on the first derivatives, and ultimately to the identification of significant periods of change. The end result would be a tendency toward anti-conservative identification of periods of change; the coverage probability would be lower than the anticipated 1 - <italic>&#x03B1;</italic>, leading to a greater chance of false positive results.</p>
<p>Problems estimating the GAM plus CAR(1) model were encountered when this was fitted to the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline40.gif"/></alternatives></inline-formula> time series; including both a smooth trend in the mean <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline41.gif"/></alternatives></inline-formula> and a CAR(1) process in the residuals lead to an unidentifiable model. What makes a model with a spline-based trend and an autocorrelation process like the CAR(1) potentially unidentifiable?</p>
<p>Consider again the basic GAM for a smooth trend, <xref ref-type="disp-formula" rid="eqn3">(3)</xref>. In that equation the correlation matrix &#x039B; was omitted for the sake of simplicity. As I did in <xref ref-type="disp-formula" rid="eqn6">(6)</xref>, I reintroduce it and restate the distributional assumptions of this model
<disp-formula id="eqn7"><alternatives><graphic xlink:href="322248_eqn7.gif"/></alternatives></disp-formula></p>
<p>In the basic GAM, &#x039B; &#x2261; <bold>I</bold> is an identity matrix, a matrix with 1s on the diagonal and 0s elsewhere
<disp-formula id="ueqn4"><alternatives><graphic xlink:href="322248_ueqn4.gif"/></alternatives></disp-formula>,
which is where the independence assumption of the model comes from; a model residual is perfectly correlated with itself (the 1s on the diagonal), but uncorrelated with any other residual (the off-diagonal 0s). In the GAM plus CAR(1) model, an alternative correlation function for &#x039B; was used &#x2014; the CAR(1) with correlation parameter <italic>&#x03D5;</italic>. <xref ref-type="bibr" rid="c17">Fahrmeir and Kneib (2008)</xref> show that where the stochastic structure of <italic>f</italic> and &#x039B; approach one another, i.e. where we have a potentially wiggly trend or strong autocorrelation as <italic>&#x03D5;</italic> &#x2192; 1, the two processes can quickly become unidentifiable (see also <xref ref-type="bibr" rid="c18">Fahrmeir et al., 2013</xref>). By unidentifiable, we mean that it becomes increasingly difficult to distinguish between a wiggly trend or strong autocorrelation because these two processes are very similar to one another in appearance. This leads to model estimation problems of the sort encountered with fitting the GAM plus CAR(1) model to the Braya-S&#x00F8; <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline42.gif"/></alternatives></inline-formula> series.</p>
<p>Why might this be so? Autocorrelation is the tendency for a large (small) value of <italic>y</italic><sub><italic>t</italic></sub> at time <italic>x</italic><sub><italic>t</italic></sub> to be followed by a likewise large (small) value at time <italic>x</italic><sub><italic>t</italic>&#x002B;1</sub>. This leads to runs of values that are consistently greater (less) than the overall mean. Short runs would indicate weaker autocorrelation whilst longer runs are associated with stronger autocorrelation, and long runs of values greater (less) than the mean would be evident as non-linear trends in the time series. As a result, a wiggly trend and an autocorrelation function with large <italic>&#x03D5;</italic> are two ways to describe the same pattern of values in a time series, and without any further information to constrain either the model is unable to distinguish both components uniquely.</p>
<p>Situations where it may be possible to uniquely identify separate wiggly trends and autocorrelation are exemplified by the Small Water &#x03B4;<sup>15</sup>N time series. The non-linear trend and the autocorrelation operate at very different scales; the trend represents decadal-scale variation in mean &#x03B4;<sup>15</sup>N, whilst the CAR(1) process represents the much smaller-scale tendency for values of the response to be followed in time by similar values. That such a pattern is observed in the Small Water core is the result of the high resolution of the sampling in time relative to the long-term trend. In contrast, the Braya-S&#x00F8; record is sampled at far lower resolution relative to the fluctuations in the mean response, and consequently the data do not contain sufficient information to separate trend and autocorrelation.</p>
</sec>
<sec id="s4f">
<label>4.6</label>
<title>Gaussian process smooths</title>
<p>In the world of machine learning, Gaussian processes (<xref ref-type="bibr" rid="c21">Golding and Purse, 2016</xref>; <xref ref-type="bibr" rid="c44">Rasmussen and Williams, 2006</xref>) are a widely-used method for fitting smooth non-parametric regression models. A Gaussian process is a distribution over all possible smooth functions <italic>f</italic>(<italic>x</italic>). In the field of spatial statistics, Gaussian processes are known by name <italic>kriging</italic>.</p>
<p>With a Gaussian process we are interested in fitting a smooth temporal trend by modelling the way the correlation between pairs of observations varies as a function of the distance, <italic>h</italic>, in time that separates the observations. The correlation between pairs of observations decreases with increasing separation, which is modelled using a correlation function, <italic>c</italic>(<italic>h</italic>).</p>
<p>Several functions can be used to represent <italic>c</italic>(<italic>h</italic>). Two common ones are the power exponential function and the Mat&#x00E9;rn family of correlation functions. The power exponential function at separation distance <italic>h</italic> is
<disp-formula id="ueqn5"><alternatives><graphic xlink:href="322248_ueqn5.gif"/></alternatives></disp-formula>
where 0 &#x003C; <italic>&#x03BA;</italic> &#x2264; 2. The Mat&#x00E9;rn correlation function is actually a family of functions with closed-forms only available for a subset of the family, distinguished by <italic>&#x03BA;</italic>. When <italic>&#x03BA;</italic> &#x003D; 1.5, the Mat&#x00E9;rn correlation function is
<disp-formula id="ueqn6"><alternatives><graphic xlink:href="322248_ueqn6.gif"/></alternatives></disp-formula>
whilst for <italic>&#x03BA;</italic> &#x003D; 2.5 it is
<disp-formula id="ueqn7"><alternatives><graphic xlink:href="322248_ueqn7.gif"/></alternatives></disp-formula>
and for <italic>&#x03BA;</italic> &#x003D; 3.5
<disp-formula id="ueqn8"><alternatives><graphic xlink:href="322248_ueqn8.gif"/></alternatives></disp-formula>.</p>
<p>In all cases, <italic>&#x03D5;</italic> is the effective range parameter, which sets the distance beyond which the correlation function is effectively zero.</p>
<p><xref ref-type="fig" rid="fig11">Figure 11</xref> shows examples of two different correlation functions; the <italic>power exponential</italic> (<xref ref-type="fig" rid="fig11">Figure 11a</xref>), and the Mat&#x00E9;rn (<xref ref-type="fig" rid="fig11">Figure 11b</xref>) correlation functions. These functions are smooth and monotonic-decreasing, meaning that the value of the correlation function decreases with increasing separation (<italic>h</italic>). When <italic>h</italic> &#x003D; 0, the correlation is equal to 1 (<italic>c</italic>(0) &#x003D; 1); two samples taken at exactly the same time point are perfectly correlated. As <italic>h</italic> &#x2192; &#x221E;, the correlation tends to zero (<italic>c</italic>(<italic>h</italic>) &#x2192; 0); two samples separated by a large amount of time tend to be uncorrelated. Often we are interested in learning how large the separation in time needs to be before, on average, a pair of observations is effectively uncorrelated (i.e. where <italic>c</italic>(<italic>h</italic>) is sufficiently close to zero).</p>
<fig id="fig11" position="float" fig-type="figure"><label>Figure 11:</label>
<caption><p>Power exponential (a) and Mat&#x00E9;rn (b) correlation functions for observation separation distance <italic>h</italic>. Two values of the effective range parameter (<italic>&#x03D5;</italic>)) are shown for each function. For the power exponential function, <italic>&#x03BA;</italic> is the power in the power exponential function. For the Mat&#x00E9;rn correlation function, <italic>&#x03BA;</italic> distinguishes the member of the Mat&#x00E9;rn family.</p></caption>
<graphic xlink:href="322248_fig11.tif"/>
</fig>
<p>Gaussian processes and GAMs share many similarities and we can fit a Gaussian process using the techniques already described above for splines (<xref ref-type="bibr" rid="c22">Handcock et al., 1994</xref>; <xref ref-type="bibr" rid="c26">Kammann and Wand, 2003</xref>). It can be shown (e.g. <xref ref-type="bibr" rid="c18">Fahrmeir et al., 2013</xref>) that the Gaussian process model has the same penalised likelihood form as the GAM that we discussed earlier; the observations are the knots of the smoother and each has a basis function in the form of a correlation function. The equivalence is only true if the basis functions do not depend on any other parameters of the model, which is only achievable if the value of <italic>&#x03D5;</italic> is fixed and known (<xref ref-type="bibr" rid="c18">Fahrmeir et al., 2013</xref>). In general, however, we would like to estimate <italic>&#x03D5;</italic> as part of model fitting. To achieve this we can maximise the profile likelihood or score statistic of the model over a range of values of <italic>&#x03D5;</italic> (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>, 362&#x2013;363). This involves proposing a value of <italic>&#x03D5;</italic> for the effective range of the correlation function and then estimating the resulting GAM by minimising the penalised log-likehood conditional upon this value of <italic>&#x03D5;</italic> and repeating for a range of values for <italic>&#x03D5;</italic>. The model, and its corresponding value of <italic>&#x03D5;</italic>, with lowest penalised log-likelihood or score statistic is then retained as the estimated GAM. <xref ref-type="fig" rid="fig12">Figure 12a</xref> shows the REML score for models estimated using a Gaussian process smooth with a Mat&#x00E9;rn correlation function (<italic>&#x03BA;</italic> &#x003D; 1.5) for a sequence of values of <italic>&#x03D5;</italic> between 15 and 1000 years. There is a clear minimum around 40 years separation, with the minimum REML score being observed at <italic>&#x03D5;</italic> &#x003D; 41.81). Also shown are the REML scores for models using the power exponential function (<italic>&#x03BA;</italic> &#x003D; 1) with the minimum score observed at a somewhat higher effective range of &#x03D5; &#x003D; 71.06.</p>
<fig id="fig12" position="float" fig-type="figure"><label>Figure 12:</label>
<caption><p>Gaussian process smooths fitted to the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline44.gif"/></alternatives></inline-formula> time series. REML score traces for GAMs fitted using power exponential (<italic>&#x03BA;</italic> &#x003D; 1) or Mat&#x00E9;rn (<italic>&#x03BA;</italic> &#x003D; 1.5) correlation functions as a function of the effective range parameter (<italic>&#x03D5;</italic>) are shown (a). The optimal model for each function is that with the lowest REML score. b) shows the resulting trends estimated using the respective correlation function with the value of <italic>&#x03D5;</italic> set to the optimal value.</p></caption>
<graphic xlink:href="322248_fig12.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig12">Figure 12b</xref> shows the estimated trends for the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline46.gif"/></alternatives></inline-formula> time series using Gaussian process smooths with exponential and Mat&#x00E9;rn correlations functions, both using <italic>&#x03D5;</italic> values at their respective optimal value as assessed using the REML score. The estimated trends are very similar to one another, although there is a noticeable difference in behaviour, with the power exponential (<italic>&#x03BA;</italic> &#x003D; 1) version being noticeably less-smooth than the Mat&#x00E9;rn version. This difference is attributable to the shapes of the respective correlation functions; the Mat&#x00E9;rn approaches a correlation of 1 smoothly as <italic>h</italic> approaches 0, whilst the power exponential with <italic>&#x03BA;</italic> &#x003D; 1 approaches a correlation of 1 increasingly quickly with decreasing <italic>h</italic>. The power exponential with <italic>&#x03BA;</italic> &#x003D; 2, like the Mat&#x00E9;rn, approaches <italic>&#x03D5;</italic> &#x003D; 1 smoothly, and consequently the trend estimated using this correlation function is qualitatively similar to that estimated using the Mat&#x00E9;rn correlation function.</p>
</sec>
<sec id="s4g">
<label>4.7</label>
<title>Adaptive smoothing</title>
<p>Each of the spline types that I have discussed so far share a common feature; the degree of wiggliness over the time series is fixed due to the use of a single smoothness parameter, &#x03BB;. The definition of wiggliness, as the integrated squared second derivative of the spline, ensures that the fitted smoother does not jump about wildly. This assumes that the data themselves are well described by a smoothly varying trend. If we anticipate abrupt change or step-like responses to environmental forcing this underlying assumption of the GAM would suggest that the method is ill-suited to modelling palaeo time series in which such features are evident or expected.</p>
<p>While there is not much we can do within the GAM framework to model a series that contains both smooth trends and step-like responses, an adaptive smoother can help address problems where the time series consists of periods of rapid change in the mean combined with periods of complacency or relatively little change. As suggested by their name, adaptive smoothers can adjust to changes in the wiggliness of the time series. This adaptive behaviour is achieved by making the smoothness parameter &#x03BB; itself depend smoothly on <italic>x</italic><sub><italic>t</italic></sub> (<xref ref-type="bibr" rid="c47">Ruppert et al., 2003</xref>, 17; <xref ref-type="bibr" rid="c62">Wood, 2017</xref>, 5.3.5); in other words, the adaptive smoother allows the wiggliness of the estimated trend to vary smoothly over time. Whilst this allows the estimated trend to adapt to periods of rapid change in the response, adaptive smoothers make significant demands on the data (<xref ref-type="bibr" rid="c62">Wood, 2017</xref>, 5.3.5); if we used <italic>m</italic> smoothness penalties to allow the wiggliness to vary over a time series, it would be like estimating <italic>m</italic> separate smooths from chunks of the original series each of length <italic>n/m</italic>. In a practical sense, this limits the use of adaptive splines in palaeoecology to proxies that are readily enumerated, such as the biogeochemical proxies used in the two example data sets.</p>
<p><xref ref-type="fig" rid="fig13">Figure 13</xref> compares trends for the Braya-S&#x00F8; time series estimated using GAMs with the three main types of spline discussed; i) TPRS, ii) Gaussian process smooths, and iii) an adaptive smoother using 45 basis functions and 5 smoothing parameters. There is a clear difference in the behaviour of the adaptive and non-adaptive smoothers for the first 1000 years of the record, with the adaptive smooth exhibiting much less variation compared with either the TPRS or Gaussian process splines. Over the remaining two thirds of the series, there is much closer agreement in the three smooths.</p>
<fig id="fig13" position="float" fig-type="figure"><label>Figure 13:</label>
<caption><p>Comparison of trends estimated using i) adaptive smooth, ii) Gaussian process, and iii) thin plate regression spline bases for the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline45.gif"/></alternatives></inline-formula> time series.</p></caption>
<graphic xlink:href="322248_fig13.tif"/>
</fig>
<p>The behaviour of the TPRS and Gaussian process splines for these data is the result of requiring a large amount of wiggliness (a small &#x03BB;) to adapt to the large oscillations in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline47.gif"/></alternatives></inline-formula> present around year 250CE and again at &#x007E;900&#x2013;1500CE. This large degree of wiggliness allows the splines to potentially over-fit individual data points much earlier in the record. Because the adaptive smoother, in contrast, can adapt to these periods of rapid change in the response it is much less susceptible to this &#x201C;chasing&#x201D; behaviour &#x2014; we don&#x2019;t need to waste effective degrees of freedom in periods with little or no change just to be able to fit the data well when there is a lot of change.</p>
<p>This potential for over-fitting in such situations is undesirable, yet if we recall <xref ref-type="fig" rid="fig9">Figure 9</xref> and the discussion around the use of the first derivative to identify periods of significant change, we would not interpret the oscillations in the early part of the <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline48.gif"/></alternatives></inline-formula> record as being statistically significant. Owing to the paucity of data in this part of the series the trends fitted using the non-adaptive smoothers are subject to such a large degree of uncertainty that the alternative of no trend through the first 1000 years of the record is also a plausible explanation of the data. The trend estimated using the adaptive smooth reflects this. Therefore, should we conclude that there is no trend in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline49.gif"/></alternatives></inline-formula> and thence climate in this period? I believe that to be too-strong a statement; those oscillations in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline50.gif"/></alternatives></inline-formula> may be real responses to climate forcing but may simply lack the statistical power to distinguish them from the null hypothesis of no trend through this period. The adaptive smoother is only adjusting to the data available to it; just because it does not detect a trend during this period does not lend itself to an interpretation of stable climate forcing or complacency in the lake&#x2019;s response to forcing. If there were particular interest in the climate of this particular period we might take from the Braya-S&#x00F8; record that there is potential early variation in climate forcing, but that additional data from this or other sites is required before any definitive conclusion can be drawn.</p>
</sec>
<sec id="s4h">
<label>4.8</label>
<title>Accounting for age model uncertainty</title>
<p>Thus far, the trend models that I have described and illustrated assumed that the time covariate (<italic>x</italic><sub><italic>t</italic></sub>) was fixed and known. In both examples, and more generally for most palaeoecological records, this assumption is violated. Unless the record is annually laminated, assigning an age to a sediment interval requires the development of an age model from observations of the relationship between depth down the sediment core and estimates of the age of the sample arrived at using any of a number of techniques, for example <sup>210</sup>Pb or <sup>14</sup>C radiometric dating. This age-depth relationship is itself uncertain, usually being derived from a mathematical or statistical model applied to point age estimates (e.g. <xref ref-type="bibr" rid="c8">Blaauw and Heegaard, 2012</xref>). Incorporating this additional component of uncertainty complicates the estimation of statistical models from palaeoenvironmental data. In this section I illustrate a simulation based approach to quantify and account for age-model uncertainty as part of the trend estimation using a GAM (see <xref ref-type="bibr" rid="c1">Anchukaitis and Tierney (2013)</xref> for a similar, non-GAM related idea).</p>
<p><xref ref-type="fig" rid="fig14">Figure 14a</xref> shows the estimated dates (in Years CE) for 12 levels in the Small Water core dated using <sup>210</sup>Pb. The vertical bars show the estimated age uncertainty of each level. The solid line through the data points is an additive model fitted to the observations, with prior weights given by the estimated age uncertainties. The fitted age-depth model is constrained to be monotonically decreasing with increasing depth, following the method of (<xref ref-type="bibr" rid="c40">Pya and Wood, 2015</xref>) using the <italic>scam</italic> package (<xref ref-type="bibr" rid="c39">Pya, 2017</xref>). Also shown are 25 simulations from the posterior distribution of the monotonically-constrained GAM. Each simulation from the posterior distribution of the age-model is itself a potential age-depth model, which can be used to assign dates to the Small Water core. The trend model in <xref ref-type="disp-formula" rid="eqn4a">(4)</xref> can be fitted to the &#x03B4;<sup>15</sup>N data using these new dates as <italic>x</italic><sub><italic>t</italic></sub>, and the whole process repeated for a large number of simulations from the age model.</p>
<fig id="fig14" position="float" fig-type="figure"><label>Figure 14:</label>
<caption><p>Accounting for uncertainty in age estimates whilst fitting a smooth trend to the Small Water <italic>&#x03B4;</italic><sup>15</sup>N time series. (a) Estimated age model using a monotonically-constrained spline fitted to <sup>210</sup>Pb inferred ages for selected depths in the sediment core (red points). The uncertainty in the <sup>210</sup>Pb inferred age is show by the red vertical bars. The fitted age model is illustrated by the solid black line. The faint grey lines are 25 random draws from the posterior distribution of the monotonically constrained GAM. The effect of age uncertainty on trend estimation is shown inb); for 100 simulations from the posterior distribution of the age model in a) a trend was estimated using a GAM with a thin plate regression spline basis and a CAR(1) process in the residuals. These trends are shown as grey lines. The combined effect of age model and fitted GAM uncertainty on the trends for the <italic>&#x03B4;</italic><sup>15</sup>N time series is shown in c). The grey lines in c) are based on 50 random draws from the model posterior distribution for each of the 100 trends shown in b). For both b) and c) the black line shows the trend estimated assuming the ages of each sediment sample are known and fixed.</p></caption>
<graphic xlink:href="322248_fig14.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig14">Figure 14b</xref> shows the trend in &#x03B4;<sup>15</sup>N for the observed age-depth model, plus trends estimated via the same model using 100 draws from the posterior distribution of the age model. In this case, the age-depth model is relatively simple with little variation in the posterior draws, resulting in trends that match closely that obtained from the estimated age-depth relationship. Even so, this additional uncertainty suggests that the timing of the decline in &#x03B4;<sup>15</sup>N covers the interval &#x007E;1935&#x2013;1945.</p>
<p>The uncertainty in the trend estimates illustrated in <xref ref-type="fig" rid="fig14">Figure 14b</xref> only reflects the variation in trends fitted to the uncertain dates of the sediment samples. To fully visualise the uncertainty in the trend estimates, incorporating both age model uncertainty <italic>and</italic> uncertainty in the estimated model coefficients themselves, 50 simulations from the posterior distribution of each of the 100 estimated trends shown in <xref ref-type="fig" rid="fig14">Figure 14b</xref> were performed, resulting in 5,000 trend estimates for the &#x03B4;<sup>15</sup>N series. These are shown in <xref ref-type="fig" rid="fig14">Figure 14c</xref>, where the two obvious changes over the same simulations without accounting for uncertainty in <italic>x</italic><sub><italic>t</italic></sub> (<xref ref-type="fig" rid="fig7">Figure 7a</xref>) are that the uncertainty band traced out by the simulations is approximately 50&#x0025; wider and, not surprisingly, the uncertainty in the estimated trend is most pronounced in the least accurately-dated section of the core. Despite this additional uncertainty however, the main result holds; a marked decline of &#x007E;1.5&#x0025;o that occurred between approximately 1930 and 1945, with mild evidence of a small increase in &#x03B4;<sup>15</sup>N post 2000 CE.</p>
</sec>
<sec id="s4i">
<label>4.9</label>
<title>Multivariate data</title>
<p>A large proportion of the palaeoenvironmental data generated today is multivariate in nature and yet the two examples used to illustrate GAMs were univariate. Can the approach described here be used for multivariate data? Yes, and no. With one main exception it is not possible to directly apply the GAM methodology described here to multivariate abundance data, where the aim is to model all species at once. The <italic>mgcv</italic> software, for example, is not able to estimate the penalized GAM for multiple non-Gaussian responses. The exception is for a small number of correlated Gaussian responses; these could be modelled as being distributed multivariate normal conditional upon the covariates. Such a model would estimate the expected values of each response and the correlations between them. For example, we could jointly model &#x03B4;<sup>15</sup>N and &#x03B4;<sup>13</sup>C series using this approach.</p>
<p>Formal multivariate versions of GLM or GAMs are currently an important area of research within ecology (see <xref ref-type="bibr" rid="c57">Warton et al. (2015)</xref> for a recent review), where they go by the name joint species distribution models (JSDMs). Whilst undoubtedly powerful, our knowledge regarding JSDMs and their availability in software are still in their relative infancy and they require considerable expertise to implement. As such, JSDMs are currently beyond the reach of most palaeoecologists. Despite this, we should be watching JSDM research as developments are ongoing and a degree of method maturation occurring.</p>
<p>One currently available avenue for fitting a multivariate GAM is via regularized sandwich estimators and GLMs (<xref ref-type="bibr" rid="c56">Warton, 2011</xref>), which involves fitting separate GLMs (or GAMs) to each response variable and subsequently using resampling-based hypothesis tests to determine which covariates are related to variation at the community level and for individual taxa (<xref ref-type="bibr" rid="c55">Wang et al., 2012</xref>; <xref ref-type="bibr" rid="c56">Warton, 2011</xref>; <xref ref-type="bibr" rid="c58">Warton et al., 2012</xref>). The <italic>mvabund</italic> package (<xref ref-type="bibr" rid="c55">Wang et al., 2012</xref>) implements this approach within R and can use <italic>mgcv</italic> to fit GAMs to each species.</p>
<p>A pragmatic although inelegant approach that has been used to estimate trends in multivariate palaeoecological data is to first summarise the response data using an unconstrained ordination via a PCA, CA, or principal curve and then fit separate GAM models to the site (sample) scores of the first few ordination axes or principal curve (<xref ref-type="bibr" rid="c2">Beck et al., 2018</xref>; <xref ref-type="bibr" rid="c3">Bennion et al., 2015</xref>). Whilst this two-step approach is relatively easy to implement and builds on approaches that palaeoecologists already use to summarise multivariate stratigraphic data, it is best thought of as modelling changes in abundance or relative composition at the community level. It is less well suited to unpicking taxon-specific trends however, because the ordination step combines individual species information into latent variables (axes) that are linear combinations of <italic>all</italic> species and it is these latent variables that are then modelled using GAM.</p>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Conclusions</title>
<p>Formal statistical estimation of trends in palaeoenvironmental data has been hampered by the nature of the data that comprise the time series; the uneven spacing of samples in time makes it, if not impossible, difficult to fit classical statistical time series models like ARIMA. This has lead palaeoecologists and palaeolimnologists to fall back on basic statistical methods such as linear parametric and non-parametric correlations or simple linear regression models, where the assumptions of the method are often grossly violated by the dependencies inherent to time series data. GAMs, whilst similar to the popular LOESS smoother, provide a superior alternative approach to trend estimation in palaeoenvironmental time series. GAMs can estimate non-linear trends, provide estimates of the magnitude of change as well as allow the identification of periods of change, can account for the lack of independence (either via autocorrelation processes or via the fitting of a wiggly trend), and provide a formal framework for statistical inference on each of these features.</p>
<p>In presenting the GAM with specific palaeoenvironmental examples and addressing the issues that arise in palaeoenvironmental time series, it is hoped that palaeoecologists and palaeolimnologists will be motivated to give greater consideration to the estimation of trends and the identification of change in stratigraphic time series.</p>
</sec>
<sec>
<title>Conflict of interest statement</title>
<p>The author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The ideas expressed in this paper are the result of many fruitful conversations with colleagues at the Environmental Change Research Centre, UCL, and the University of Regina. In particular I am indebted to Helen Bennion, Rick Battarbee, and Peter Leavitt for their collaborations on projects over many years, and to David Miller, Eric Pedersen, and Noam Ross, my GAM workshop partners in crime. Without Simon Wood&#x2019;s <italic>mgcv</italic> software and his research on GAMs, the application of these models to palaeo time series would not be as straight forward. This work was supported by a Natural Sciences and Engineering Council of Canada (NSERC) Discovery Grant to the author (RGPIN-2014-04032).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Anchukaitis</surname>, <given-names>K. J.</given-names></string-name>, and <string-name><surname>Tierney</surname>, <given-names>J. E.</given-names></string-name> (<year>2013</year>). <article-title>Identifying coherent spatiotemporal modes in time-uncertain proxy paleoclimate records</article-title>. <source>Climate Dynamics</source> <volume>41</volume>, <fpage>1291</fpage>&#x2013;<lpage>1306</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00382-012-1483-0</pub-id>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Beck</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Fletcher</surname>, <given-names>M.-S.</given-names></string-name>, <string-name><surname>Gadd</surname>, <given-names>P. S.</given-names></string-name>, <string-name><surname>Heijnis</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Saunders</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>G. L.</given-names></string-name>, <etal>et al.</etal> (<year>2018</year>). <article-title>Variance and Rate-of-Change as early warning signals for a critical transition in an aquatic ecosystem state: A test case from tasmania, australia</article-title>. <source>Journal of Geophysical Research: Biogeosciences</source> <volume>123</volume>, <fpage>2017JG004135</fpage>. doi:<pub-id pub-id-type="doi">10.1002/2017JG004135</pub-id>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Bennion</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>G. L.</given-names></string-name>, and <string-name><surname>Goldsmith</surname>, <given-names>B. J.</given-names></string-name> (<year>2015</year>). <article-title>Assessing degradation and recovery pathways in lakes impacted by eutrophication using the sediment record</article-title>. <source>Frontiers in Ecology and Evolution</source> <volume>3</volume>. doi:<pub-id pub-id-type="doi">10.3389/fevo.2015.00094</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Bergmeir</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hyndman</surname>, <given-names>R. J.</given-names></string-name>, and <string-name><surname>Koo</surname>, <given-names>B.</given-names></string-name> (<year>2018</year>). <article-title>A note on the validity of cross-validation for evaluating autoregressive time series prediction</article-title>. <source>Computational Statistics &#x0026; Data Analysis</source> <volume>120</volume>, <fpage>70</fpage>&#x2013;<lpage>83</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.csda.2017.11.003</pub-id>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Birks</surname>, <given-names>H. J. B.</given-names></string-name> (<year>1998</year>). <article-title>Numerical tools in palaeolimnology &#x2014; progress, potentialities, and problems</article-title>. <source>Journal of Paleolimnology</source> <volume>20</volume>, <fpage>307</fpage>&#x2013;<lpage>332</lpage>. doi:<pub-id pub-id-type="doi">10.1023/A:1008038808690</pub-id>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="book"><string-name><surname>Birks</surname>, <given-names>H. J. B.</given-names></string-name> (<year>2012a</year>). &#x201C;<chapter-title>Introduction and overview of part III</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>), <fpage>331</fpage>&#x2013;<lpage>353</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-94-007-2745-8\_10</pub-id>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="book"><string-name><surname>Birks</surname>, <given-names>H. J. B.</given-names></string-name> (<year>2012b</year>). &#x201C;<chapter-title>Overview of numerical methods in palaeolimnology</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>), <fpage>19</fpage>&#x2013;<lpage>92</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-94-007-2745-8\_2</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="book"><string-name><surname>Blaauw</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Heegaard</surname>, <given-names>E.</given-names></string-name> (<year>2012</year>). &#x201C;<chapter-title>Estimation of Age-Depth relationships</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>), <fpage>379</fpage>&#x2013;<lpage>413</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-94-007-2745-8\_12</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="book"><string-name><surname>Brassell</surname>, <given-names>S. C.</given-names></string-name> (<year>1993</year>). &#x201C;<chapter-title>Applications of biomarkers for delineating marine paleoclimatic fluctuations during the pleistocene</chapter-title>,&#x201D; <source>in Organic geochemistry: Principles and applications</source>, eds. <person-group person-group-type="editor"><string-name><given-names>M. H.</given-names> <surname>Engel</surname></string-name> and <string-name><given-names>S. A.</given-names> <surname>Macko</surname></string-name></person-group> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Springer US</publisher-name>), <fpage>699</fpage>&#x2013;<lpage>738</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-1-4615-2890-6\_34</pub-id>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Chu</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jia</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Lu</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal> (<year>2005</year>). <article-title>Long-chain alkenone distributions and temperature dependence in lacustrine surface sediments from china</article-title>. <source>Geochimica et Cosmochimica Acta</source> <volume>69</volume>, <fpage>4985</fpage>&#x2013;<lpage>5003</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.gca.2005.04.008</pub-id>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Cleveland</surname>, <given-names>W. S.</given-names></string-name> (<year>1979</year>). <article-title>Robust locally weighted regression and smoothing scatterplots</article-title>. <source>Journal of the American Statistical Association</source> <volume>74</volume>, <fpage>829</fpage>&#x2013;<lpage>836</lpage>. doi:<pub-id pub-id-type="doi">10.1080/01621459.1979.10481038</pub-id>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Craven</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Wahba</surname>, <given-names>G.</given-names></string-name> (<year>1978</year>). <article-title>Smoothing noisy data with spline functions</article-title>. <source>Numerische Mathematik</source> <volume>31</volume>, <fpage>377</fpage>&#x2013;<lpage>403</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BF01404567</pub-id>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><string-name><surname>Duchon</surname>, <given-names>J.</given-names></string-name> (<year>1977</year>). &#x201C;<chapter-title>Splines minimizing rotation-invariant semi-norms in sobolev spaces</chapter-title>,&#x201D; in <source>Constructive theory of functions of several variables</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>), <fpage>85</fpage>&#x2013;<lpage>100</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BFb0086566</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="book"><string-name><surname>Dutilleul</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Cumming</surname>, <given-names>B. F.</given-names></string-name>, and <string-name><surname>Lontoc-Roy</surname>, <given-names>M.</given-names></string-name> (<year>2012</year>). &#x201C;<chapter-title>Autocorrelogram and periodogram analyses of palaeolimnological Temporal-Series from lakes in central and western north america to assess shifts in drought conditions</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>), <fpage>523</fpage>&#x2013;<lpage>548</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-94-007-2745-8\_16</pub-id>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>D&#x2019;Andrea</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Fritz</surname>, <given-names>S. C.</given-names></string-name>, and <string-name><surname>Anderson</surname>, <given-names>N. J.</given-names></string-name> (<year>2011</year>). <article-title>Abrupt holocene climate change as an important factor for human migration in west greenland</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>108</volume>, <fpage>9765</fpage>&#x2013;<lpage>9769</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1101708108</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Epperson</surname>, <given-names>J. F.</given-names></string-name> (<year>1987</year>). <article-title>On the Runge example</article-title>. <source>The American Mathematical Monthly</source> <volume>94</volume>, <fpage>329</fpage>&#x2013;<lpage>341</lpage>. doi:<pub-id pub-id-type="doi">10.2307/2323093</pub-id>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="book"><string-name><surname>Fahrmeir</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Kneib</surname>, <given-names>T.</given-names></string-name> (<year>2008</year>). &#x201C;<chapter-title>On the identification of trend and correlation in temporal and spatial regression</chapter-title>,&#x201D; in <source>Recent advances in linear models and related areas</source> (<publisher-name>Physica-Verlag HD</publisher-name>), <fpage>1</fpage>&#x2013;<lpage>27</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-7908-2064-5\_1</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="book"><string-name><surname>Fahrmeir</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Kneib</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Lang</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Marx</surname>, <given-names>B.</given-names></string-name> (<year>2013</year>). <source>Regression: Models, methods and applications</source>. <publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc> doi:<pub-id pub-id-type="doi">10.1007/978-3-642-34333-9</pub-id>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Gautheir</surname>, <given-names>T. D.</given-names></string-name> (<year>2001</year>). <article-title>Detecting trends using spearman&#x2019;s rank correlation coefficient</article-title>. <source>Environmental Forensics</source> <volume>2</volume>, <fpage>359</fpage>&#x2013;<lpage>362</lpage>. doi:<pub-id pub-id-type="doi">10.1080/713848278</pub-id>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="book"><string-name><surname>Glew</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Smol</surname>, <given-names>J. P.</given-names></string-name>, and <string-name><surname>Last</surname>, <given-names>W. M.</given-names></string-name> (<year>2001</year>). &#x201C;<chapter-title>Sediment core collection and extrusion</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments: Basin analysis, coring, and chronological techniques</source>, eds. <person-group person-group-type="editor"><string-name><given-names>W. M.</given-names> <surname>Last</surname></string-name> and <string-name><given-names>J. P.</given-names> <surname>Smol</surname></string-name></person-group> (<publisher-loc>Dordrecht</publisher-loc>: <publisher-name>Springer Netherlands</publisher-name>), <fpage>73</fpage>&#x2013;<lpage>105</lpage>. doi:<pub-id pub-id-type="doi">10.1007/0-306-47669-X\_5</pub-id>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Golding</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Purse</surname>, <given-names>B. V.</given-names></string-name> (<year>2016</year>). <article-title>Fast and flexible bayesian species distribution modelling using gaussian processes</article-title>. <source>Methods in Ecology and Evolution</source>. doi:<pub-id pub-id-type="doi">10.1111/2041-210X.12523</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Handcock</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Meier</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Nychka</surname>, <given-names>D.</given-names></string-name> (<year>1994</year>). <article-title>Kriging and splines: An empirical comparison of their predictive performance in some applications: Comment</article-title>. <source>Journal of the American Statistical Association</source> <volume>89</volume>,<fpage>401</fpage>&#x2013;<lpage>403</lpage>. doi:<pub-id pub-id-type="doi">10.2307/2290838</pub-id>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="book"><string-name><surname>Hastie</surname>, <given-names>T. J.</given-names></string-name>, and <string-name><surname>Tibshirani</surname>, <given-names>R. J.</given-names></string-name> (<year>1990</year>). <source>Generalized additive models</source>. <publisher-loc>Boca Raton, Fl.</publisher-loc>: <publisher-name>Chapman &#x0026; Hall / CRC</publisher-name>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Hastie</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Tibshirani</surname>, <given-names>R.</given-names></string-name> (<year>1986</year>). <article-title>Generalized additive models</article-title>. <source>Statistical Science</source> <volume>1</volume>, <fpage>297</fpage>&#x2013;<lpage>310</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="book"><string-name><surname>Juggins</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Telford</surname>, <given-names>R. J.</given-names></string-name> (<year>2012</year>). &#x201C;<chapter-title>Exploratory data analysis and data display</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>), <fpage>123</fpage>&#x2013;<lpage>141</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-94-007-2745-8\_5</pub-id>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Kammann</surname>, <given-names>E. E.</given-names></string-name>, and <string-name><surname>Wand</surname>, <given-names>M. P.</given-names></string-name> (<year>2003</year>). <article-title>Geoadditive models</article-title>. <source>Journal of the Royal Statistical Society. Series C, Applied statistics</source> <volume>52</volume>,<fpage>1</fpage>&#x2013;<lpage>18</lpage>. doi:<pub-id pub-id-type="doi">10.1111/1467-9876.00385</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Kimeldorf</surname>, <given-names>G. S.</given-names></string-name>, and <string-name><surname>Wahba</surname>, <given-names>G.</given-names></string-name> (<year>1970</year>). <article-title>A correspondence between bayesian estimation on stochastic processes and smoothing by splines</article-title>. <source>Annals of Mathematical Statistics</source> <volume>41</volume>,<fpage>495</fpage>&#x2013;<lpage>502</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Magee</surname>, <given-names>L.</given-names></string-name> (<year>1998</year>). <article-title>Nonlocal behavior in polynomial regressions</article-title>. <source>The American Statistician</source> <volume>52</volume>, <fpage>20</fpage>&#x2013;<lpage>22</lpage>. doi:<pub-id pub-id-type="doi">10.2307/2685560</pub-id>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Mann</surname>, <given-names>M. E.</given-names></string-name> (<year>2004</year>). <article-title>On smoothing potentially non-stationary climate time series</article-title>. <source>Geophysical Research Letters</source> <volume>31</volume>, <fpage>L07214</fpage>. doi:<pub-id pub-id-type="doi">10.1029/2004GL019569</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Mann</surname>, <given-names>M. E.</given-names></string-name> (<year>2008</year>). <article-title>Smoothing of climate time series revisited</article-title>. <source>Geophysical Research Letters</source> <volume>35</volume>, <fpage>L16708</fpage>. doi:<pub-id pub-id-type="doi">10.1029/2008GL034716</pub-id>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Marra</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2012</year>). <article-title>Coverage properties of confidence intervals for generalized additive model components</article-title>. <source>Scandinavian Journal of Statistics, Theory and Applications</source> <volume>39</volume>, <fpage>53</fpage>&#x2013;<lpage>74</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9469.2011.00760.x</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="book"><string-name><surname>McCullagh</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Nelder</surname>, <given-names>J. A.</given-names></string-name> (<year>1989</year>). <source>Generalized linear models</source>, <edition>second edition</edition>. <publisher-name>CRC Press</publisher-name>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Mills</surname>, <given-names>T. C.</given-names></string-name> (<year>2006</year>). <article-title>Modelling current trends in Northern Hemisphere temperatures</article-title>. <source>International Journal of Climatology</source> <volume>26</volume>, <fpage>867</fpage>&#x2013;<lpage>884</lpage>. doi:<pub-id pub-id-type="doi">10.1002/joc.1286</pub-id>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Mills</surname>, <given-names>T. C.</given-names></string-name> (<year>2007</year>). <article-title>A note on trend decomposition: The &#x201C;classical&#x201D; approach revisited with an application to surface temperature trends</article-title>. <source>Journal of applied statistics</source> <volume>34</volume>, <fpage>963</fpage>&#x2013;<lpage>972</lpage>. doi:<pub-id pub-id-type="doi">10.1080/02664760701590418</pub-id>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Mills</surname>, <given-names>T. C.</given-names></string-name> (<year>2010</year>). <article-title>&#x201C;Skinning a cat&#x201C;: Alternative models of representing temperature trends</article-title>. <source>Climatic Change</source> <volume>101</volume>,<fpage>415</fpage>&#x2013;<lpage>426</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Nychka</surname>, <given-names>D.</given-names></string-name> (<year>1988</year>). <article-title>Bayesian confidence intervals for smoothing splines</article-title>. <source>Journal of the American Statistical Association</source> <volume>83</volume>,<fpage>1134</fpage>&#x2013;<lpage>1143</lpage>. doi:<pub-id pub-id-type="doi">10.1080/01621459.1988.10478711</pub-id>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><collab>PAGES 2K Consortium</collab> (<year>2013</year>). <article-title>Continental-scale temperature variability during the past two millennia</article-title>. <source>Nature Geoscience</source> <volume>6</volume>, <fpage>339</fpage>&#x2013;<lpage>346</lpage>. doi:<pub-id pub-id-type="doi">10.1038/ngeo1797</pub-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="book"><string-name><surname>Pinheiro</surname>, <given-names>J. C.</given-names></string-name>, and <string-name><surname>Bates</surname>, <given-names>D. M.</given-names></string-name> (<year>2000</year>). <source>Mixed-Effects models in S and S-PLUS</source>. <publisher-name>Springer Science &#x0026; Business Media</publisher-name>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Pya</surname>, <given-names>N.</given-names></string-name> (<year>2017</year>). <source>Scam: Shape constrained additive models</source>. Available at: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=scam">https://CRAN.R-project.org/package=scam</ext-link>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Pya</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2015</year>). <article-title>Shape constrained additive models</article-title>. <source>Statistics and Computing</source> <volume>25</volume>, <fpage>543</fpage>&#x2013;<lpage>559</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s11222-013-9448-7</pub-id>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Pya</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2016</year>). <article-title>A note on basis dimension selection in generalized additive modelling</article-title>. <source>ArXiv e-prints</source>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="book"><collab>R Core Team</collab> (<year>2017</year>). <source>R: A language and environment for statistical computing</source>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name> Available at: <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="book"><collab>R Core Team</collab> (<year>2018</year>). <source>R: A language and environment for statistical computing</source>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name> Available at: <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="book"><string-name><surname>Rasmussen</surname>, <given-names>C. E.</given-names></string-name>, and <string-name><surname>Williams</surname>, <given-names>C. K. I.</given-names></string-name> (<year>2006</year>). <source>Gaussian processes for machine learning</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Reiss</surname>, <given-names>P. T.</given-names></string-name>, and <string-name><surname>Ogden</surname>, <given-names>R. T.</given-names></string-name> (<year>2009</year>). <article-title>Smoothing parameter selection for a class of semipara-metric linear models</article-title>. <source>Journal of the Royal Statistical Society. Series B, Statistical methodology</source> <volume>71</volume>, <fpage>505</fpage>&#x2013;<lpage>523</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9868.2008.00695.x</pub-id>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Runge</surname>, <given-names>C.</given-names></string-name> (<year>1901</year>). <article-title>&#x00DC;ber empirische funktionen und die interpolation zwischen aquidistanten ordinaten</article-title>. <source>Zeitschrift fur Angewandte Mathematik und Physik</source> <volume>46</volume>,<fpage>224</fpage>&#x2013;<lpage>243</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="book"><string-name><surname>Ruppert</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Wand</surname>, <given-names>M. P.</given-names></string-name>, and <string-name><surname>Carroll</surname>, <given-names>R. J.</given-names></string-name> (<year>2003</year>). <source>Semiparametric Regression</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Silverman</surname>, <given-names>B. W.</given-names></string-name> (<year>1985</year>). <article-title>Some aspects of the spline smoothing approach to non-parametric regression curve fitting</article-title>. <source>Journal of the Royal Statistical Society. Series B, Statistical methodology</source> <volume>47</volume>, <fpage>1</fpage>&#x2013;<lpage>52</lpage></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="book"><string-name><surname>Smol</surname>, <given-names>J. P.</given-names></string-name> (<year>2008</year>). <source>Pollution of lakes and rivers: A paleoenvironmental perspective</source>. <publisher-name>Blackwell Pub</publisher-name>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="book"><string-name><surname>Smol</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Birks</surname>, <given-names>H. J. B.</given-names></string-name>, <string-name><surname>Lotter</surname>, <given-names>A. F.</given-names></string-name>, and <string-name><surname>Juggins</surname>, <given-names>S.</given-names></string-name> (<year>2012</year>). &#x201C;<chapter-title>The march towards the quantitative analysis of palaeolimnological data</chapter-title>,&#x201D; in <source>Tracking environmental change using lake sediments</source> (<publisher-name>Springer</publisher-name>, <publisher-loc>Dordrecht</publisher-loc>), <fpage>3</fpage>&#x2013;<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-94-007-2745-8\_1</pub-id>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Tian</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>D. M.</given-names></string-name>, and <string-name><surname>Hu</surname>, <given-names>F. S.</given-names></string-name> (<year>2011</year>). <article-title>How well do sediment indicators record past climate? An evaluation using annually laminated sediments</article-title>. <source>Journal of Paleolimnology</source> <volume>45</volume>, <fpage>73</fpage>&#x2013;<lpage>84</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10933-010-9481-x</pub-id>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Toney</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Fritz</surname>, <given-names>S. C.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Grimm</surname>, <given-names>E.</given-names></string-name>, and <string-name><surname>Nyren</surname>, <given-names>P.</given-names></string-name> (<year>2010</year>). <article-title>Climatic and environmental controls on the occurrence and distributions of long chain alkenones in lakes of the interior united states</article-title>. <source>Geochimica et Cosmochimica Acta</source> <volume>74</volume>,<fpage>1563</fpage>&#x2013;<lpage>1578</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.gca.2009.11.021</pub-id>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Wahba</surname>, <given-names>G.</given-names></string-name> (<year>1983</year>). <article-title>Bayesian &#x201C;confidence intervals&#x201D; for the Cross-Validated smoothing spline</article-title>. <source>Journal of the Royal Statistical Society. Series B, Statistical methodology</source> <volume>45</volume>,<fpage>133</fpage>&#x2013;<lpage>150</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="other"><string-name><surname>Wahba</surname>, <given-names>G.</given-names></string-name> (<year>1990</year>). <source>Spline models for observational data</source>. <publisher-name>SIAM</publisher-name>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Naumann</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>S. T.</given-names></string-name>, and <string-name><surname>Warton</surname>, <given-names>D. I.</given-names></string-name> (<year>2012</year>). <article-title>Mvabund&#x2012; an R package for model-based analysis of multivariate abundance data</article-title>. <source>Methods in Ecology and Evolution</source> <volume>3</volume>, <fpage>471</fpage>&#x2013;<lpage>474</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.2041-210X.2012.00190.x</pub-id>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Warton</surname>, <given-names>D. I.</given-names></string-name> (<year>2011</year>). <article-title>Regularized sandwich estimators for analysis of high-dimensional data using generalized estimating equations</article-title>. <source>Biometrics</source> <volume>67</volume>, <fpage>116</fpage>&#x2013;<lpage>123</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1541-0420.2010.01438.x</pub-id>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Warton</surname>, <given-names>D. I.</given-names></string-name>, <string-name><surname>Blanchet</surname>, <given-names>F. G.</given-names></string-name>, <string-name><surname>O&#x2019;Hara</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Ovaskainen</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Taskinen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Walker</surname>, <given-names>S. C.</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>). <article-title>So many variables: Joint modeling in community ecology</article-title>. <source>Trends in Ecology &#x0026; Evolution</source>. doi:<pub-id pub-id-type="doi">10.1016/j.tree.2015.09.007</pub-id>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Warton</surname>, <given-names>D. I.</given-names></string-name>, <string-name><surname>Wright</surname>, <given-names>S. T.</given-names></string-name>, and <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name> (<year>2012</year>). <article-title>Distance-based multivariate analyses confound location and dispersion effects</article-title>. <source>Methods in Ecology and Evolution</source> <volume>3</volume>, <fpage>89</fpage>&#x2013;<lpage>101</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.2041-210X.2011.00127.x</pub-id>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2003</year>). <article-title>Thin plate regression splines</article-title>. <source>Journal of the Royal Statistical Society. Series B, Statistical methodology</source> <volume>65</volume>, <fpage>95</fpage>&#x2013;<lpage>114</lpage>. doi:<pub-id pub-id-type="doi">10.1111/1467-9868.00374</pub-id>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2004</year>). <article-title>Stable and efficient multiple smoothing parameter estimation for generalized additive models</article-title>. <source>Journal of the American Statistical Association</source> <volume>99</volume>, <fpage>673</fpage>&#x2013;<lpage>686</lpage>. doi:<pub-id pub-id-type="doi">10.2307/27590439</pub-id>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2011</year>). <article-title>Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models</article-title>. <source>Journal of the Royal Statistical Society. Series B, Statistical methodology</source> <volume>73</volume>, <fpage>3</fpage>&#x2013;<lpage>36</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9868.2010.00749.x</pub-id>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="book"><string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name> (<year>2017</year>). <source>Generalized Additive Models: An Introduction with R</source>, <edition>Second edition</edition>. <publisher-name>CRC Press</publisher-name>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Pya</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>S&#x00E4;fken</surname>, <given-names>B.</given-names></string-name> (<year>2016</year>). <article-title>Smoothing parameter and model selection for general smooth models</article-title>. <source>Journal of the American Statistical Association</source> <volume>111</volume>, <fpage>1548</fpage>&#x2013;<lpage>1563</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Yee</surname>, <given-names>T. W.</given-names></string-name>, and <string-name><surname>Mitchell</surname>, <given-names>N. D.</given-names></string-name> (<year>1991</year>). <article-title>Generalized additive models in plant ecology</article-title>. <source>Journal of Vegetation Science</source> <volume>2</volume>, <fpage>587</fpage>&#x2013;<lpage>602</lpage>. doi:<pub-id pub-id-type="doi">10.2307/3236170</pub-id>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Zink</surname>, <given-names>K.-G.</given-names></string-name>, <string-name><surname>Leythaeuser</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Melkonian</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Schwark</surname>, <given-names>L.</given-names></string-name> (<year>2001</year>). <article-title>Temperature dependency of long-chain alkenone distributions in recent to fossil limnic sediments and in lake waters11Associate editor: J. b.fein</article-title>. <source>Geochimica et Cosmochimica Acta</source> <volume>65</volume>, <fpage>253</fpage>&#x2013;<lpage>265</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0016-70370000509-3</pub-id>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<label>Appendix 1&#x2014;</label>
<title>Simultaneous intervals</title>
<p>We proceed by considering a simultaneous confidence interval for a function <italic>f</italic>(<italic>x</italic>) at a set of <italic>M</italic> locations in <italic>x</italic>; we&#x2019;ll refer to these locations, following the notation of <xref ref-type="bibr" rid="c47">Ruppert et al. (2003)</xref> by
<disp-formula id="ueqn9"><alternatives><graphic xlink:href="322248_ueqn9.gif"/></alternatives></disp-formula></p>
<p>The true function over <bold>g</bold>, <bold>f</bold><sub><bold>g</bold></sub>, is defined as the vector of evaluations of<italic>f</italic> at each of the <italic>M</italic> locations
<disp-formula id="ueqn10"><alternatives><graphic xlink:href="322248_ueqn10.gif"/></alternatives></disp-formula>
and the corresponding estimate of the true function given by the fitted GAM denoted by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="322248_inline51.gif"/></alternatives></inline-formula>. The difference between the true function and our unbiased estimator is given by
<disp-formula id="ueqn11"><alternatives><graphic xlink:href="322248_ueqn11.gif"/></alternatives></disp-formula>,
where <bold>C</bold><sub><bold>g</bold></sub> is a matrix formed by the evaluation of the basis functions at locations <bold>g</bold>, and the part in square brackets is the bias in the estimated model coefficients, which we assume to be mean 0 and distributed, approximately, multivariate normal with mean vector <bold>0</bold> and covariance matrix <bold>V</bold><sub><bold>b</bold></sub>
<disp-formula id="ueqn12"><alternatives><graphic xlink:href="322248_ueqn12.gif"/></alternatives></disp-formula>,
where <bold>V</bold><sub><bold>b</bold></sub> is the Bayesian covariance matrix of the GAM coefficients.</p>
<p>Now, the (1 - <italic>&#x03B1;</italic>)100&#x0025; simultaneous confidence interval is
<disp-formula id="ueqn13"><alternatives><graphic xlink:href="322248_ueqn13.gif"/></alternatives></disp-formula>,
where m<sub>1-&#x03B1;</sub> is the 1 - &#x03B1; quantile of the random variable
<disp-formula id="ueqn14"><alternatives><graphic xlink:href="322248_ueqn14.gif"/></alternatives></disp-formula></p>
<p>The sup refers to the <italic>supremum</italic> or the <italic>least upper bound</italic>; this is the least value of <italic>&#x1D4B3;</italic>, the set of all values of which we observed subset <italic>x</italic>, that is <italic>greater</italic> than all of the values in the subset. Often this is the maximum value of the subset. This is what is indicated by the right-hand side of the equation; we want the maximum (absolute) value of the ratio over all values in <bold>g</bold>.</p>
<p>The fractions in both sides of the equation correspond to the standardized deviation between the true function and the model estimate, and we consider the <italic>maximum absolute</italic> standardized deviation. We don&#x2019;t usually know the distribution of the maximum absolute standardized deviation but we need this to access its quantiles. However, we can closely approximate the distribution via simulation. The difference here is that rather than simulating from the posterior of the model as we did earlier see section <italic>Confidence intervals</italic>, this time we simulate from the multivariate normal distribution with mean vector <bold>0</bold> and covariance matrix <bold>V</bold><sub><bold>b</bold></sub>. For each simulation we find the maximum absolute standardized deviation of the fitted function from the true function over the grid of <italic>x</italic> values we are considering. Then we collect all these maxima, sort them and either take the 1 - &#x03B1; probability quantile of the maxima, or the maximum with rank &#x2308;(1 - <italic>&#x03B1;</italic>)/<italic>N</italic>&#x2309;.</p>
</app>
</app-group>
</back>
</article>