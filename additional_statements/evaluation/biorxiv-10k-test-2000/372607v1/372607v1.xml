<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/372607</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The correlated state in balanced neuronal networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0829-4790</contrib-id>
<name>
<surname>Baker</surname>
<given-names>Cody</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ebsch</surname>
<given-names>Christopher</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lampl</surname>
<given-names>Ilan</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2105-9282</contrib-id>
<name>
<surname>Rosenbaum</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Applied and Computational Mathematics and Statistics, University of Notre Dame</institution>, Notre Dame, IN, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Neurobiology, Weizmann Institute of Science</institution>, Rehovot, 7610001, <country>Israel</country></aff>
<aff id="a3"><label>3</label><institution>Interdisciplinary Center for Network Science and Applications, University of Notre Dame</institution>, Notre Dame, IN, <country>USA</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>&#x002A;</label><p><email>Robert.Rosenbaum@nd.edu</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>372607</elocation-id>
<history>
<date date-type="received">
<day>19</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>19</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>19</day>
<month>7</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="372607.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Understanding the magnitude and structure of inter-neuronal correlations and their relationship to synaptic connectivity structure is an important and difficult problem in computational neuroscience. Early studies show that neuronal network models with excitatory-inhibitory balance naturally create very weak spike train correlations. Later work showed that, under some connectivity structures, balanced networks can produce larger correlations between some neuron pairs, even when the average correlation is very small. All of these previous studies assume that the local neuronal network receives feedforward synaptic input from a population of uncorrelated spike trains. We show that when spike trains providing feedforward input are correlated, the downstream recurrent neuronal network produces much larger correlations. We provide an in-depth analysis of the resulting &#x201C;correlated state&#x201D; in balanced networks and show that, unlike the asynchronous state of previous work, it produces &#x201C;tight&#x201D; excitatory-inhibitory balance, consistent with in vivo cortical recordings.</p>
<sec>
<title>Author summary</title>
<p>Correlation and synchrony between the activity of neurons in the brain is known to play a crucial role in the dynamics and coding properties of neuronal networks, and also mediates synaptic plasticity and learning. Therefore, it is important to understand the relationship between the structure of connectivity in a neuronal networks and the correlations between the activity of neurons in the network. Previous theoretical work shows that this relationship is constrained by the widely observed balance between excitatory (positive) and inhibitory (negative) input received by neurons in the network. We extend this previous theoretical work to account for the fact that inputs coming from outside the local neuronal network might come from neural populations that are themselves correlated or partially synchronous. Including this biologically realistic assumption changes the basic operating state of the network and produces a tighter balance between excitatory and inhibitory synaptic inputs that is consistent with in vivo recordings.</p>
</sec>
</abstract>
<counts>
<page-count count="34"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Correlations between the spiking activity of cortical neurons have important consequences for neural dynamics and coding [<xref ref-type="bibr" rid="c1">1</xref>&#x2013;<xref ref-type="bibr" rid="c3">3</xref>]. A quantitative understanding of how spike train correlations are generated and shaped by the connectivity structure of neural circuits is made difficult by the noisy and nonlinear dynamics of recurrent neuronal network models [<xref ref-type="bibr" rid="c4">4</xref>&#x2013;<xref ref-type="bibr" rid="c7">7</xref>]. Linear response and related techniques have been developed to overcome some of these difficulties [<xref ref-type="bibr" rid="c8">8</xref>&#x2013;<xref ref-type="bibr" rid="c14">14</xref>], but their accuracy typically require an assumption of sparse and/or weak connectivity and, in some models, an additional assumption that neurons receive uncorrelated, feedforward Gaussian white noise input. However, cortical circuits are densely connected and receive spatially and temporally correlated synaptic input from outside the local circuit [<xref ref-type="bibr" rid="c15">15</xref>&#x2013;<xref ref-type="bibr" rid="c18">18</xref>].</p>
<p>An alternative approach to analyzing correlated variability in recurrent neuronal network models is motivated in part by the widely observed balance between excitatory and inhibitory synaptic inputs in cortex [<xref ref-type="bibr" rid="c19">19</xref>&#x2013;<xref ref-type="bibr" rid="c26">26</xref>]. When synaptic weights are scaled like <inline-formula><alternatives><inline-graphic xlink:href="372607_inline1.gif"/></alternatives></inline-formula> where <italic>N</italic> is the size of a model network, a cortex-like balance between excitation and inhibition arises naturally at large network size, which defines the &#x201C;balanced state&#x201D; [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>]. Early work on balanced networks assumed sparse connectivity to produce weak spike train correlations, but it was later shown that keeping connection probabilities <italic>&#x1D4AA;</italic>(1) naturally produces weak, <italic>&#x1D4AA;</italic> (1<italic>/N</italic>), spike train correlations, defining the &#x201C;asynchronous state&#x201D; [<xref ref-type="bibr" rid="c29">29</xref>]. While these extremely weak spike train correlations are consistent with some cortical recordings [<xref ref-type="bibr" rid="c30">30</xref>], the magnitude of correlations in cortex can depend on stimulus, cortical area, layer, and behavioral or cognitive state, and can be much larger than predicted by the asynchronous state [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c31">31</xref>&#x2013;<xref ref-type="bibr" rid="c35">35</xref>]. This raises the question of how larger correlation magnitudes can arise in balanced cortical circuits. Later theoretical work showed that larger correlations can be obtained between some cell pairs in densely connected networks with specially constructed connectivity structure [<xref ref-type="bibr" rid="c36">36</xref>&#x2013;<xref ref-type="bibr" rid="c39">39</xref>], offering a potential explanation of the larger correlations often observed in recordings. These previous theoretical studies of correlated variability in balanced networks assume that the recurrent network receives feedforward synaptic input from an external population of uncorrelated spike trains, so feedforward input correlations arise solely from overlapping feedforward synaptic projections. In reality, feedforward synaptic input to a cortical population comes from thalamic projections, other cortical areas, or other cortical layers in which spike trains could be correlated.</p>
<p>We extend the theory of densely connected balanced networks to account for correlations between the spike trains of neurons in an external, feedforward input layer. We show that correlations between the feedforward synaptic input to neurons in the recurrent network are <italic>&#x1D4AA;</italic>(<italic>N</italic>) in this model, but cancel with <italic>&#x1D4AA;</italic>(<italic>N</italic>) correlations between recurrent synaptic input to produce <italic>&#x1D4AA;</italic> (1) total input correlation and <italic>&#x1D4AA;</italic> (1) spike train correlations on average, defining what we refer to as the &#x201C;correlated state&#x201D; in densely connected balanced networks. This correlated state offers an alternative explanation for the presence of moderately large spike train correlations in cortical recordings. We derive a simple, closed form approximation for the average cross-spectral density between neurons&#x2019; spike trains in the correlated state in term of synaptic parameters alone, without requiring the use of linear response theory or any other knowledge of neurons&#x2019; transfer functions. We show that the tracking of excitatory synaptic input currents by inhibitory currents is more precise and more similar to in vivo recordings [<xref ref-type="bibr" rid="c22">22</xref>] in the correlated state than in the asynchronous state. We also investigate the applicability of linear response approximations to correlated variability in densely connected balanced networks. Taken together, our results extend the theory of correlated variability in balanced networks to the biologically realistic assumption that presynaptic neural populations are themselves correlated.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We consider recurrent networks of <italic>N</italic> integrate-and-fire model neurons, <italic>N<sub>e</sub></italic> of which are excitatory and <italic>N<sub>i</sub></italic> inhibitory. Neurons are randomly and recurrently interconnected and also receive random feedforward synaptic input from an external population of <italic>N<sub>x</sub></italic> neurons whose spike trains are homogeneous Poisson processes with rate <italic>r<sub>x</sub></italic> (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1.</label>
<caption><title>The asynchronous state in densely connected balanced networks.</title>
<p><bold>A)</bold> Network diagram. An external population, <italic>X</italic>, of uncorrelated Poisson processes provides feedforward input to a randomly connected recurrent network of excitatory, <italic>E</italic>, and inhibitory, <italic>I</italic>, neurons. Feedforward input correlations are solely from overlapping projections from <italic>X</italic>. <bold>B,C)</bold> Raster plot of 200 randomly selected neurons from population <italic>X</italic> and <italic>E</italic> respectively. <bold>D)</bold> Histogram of external (<italic>X</italic>, green) recurrent (<italic>R</italic> &#x003D; <italic>E</italic> &#x002B; <italic>I</italic>, purple) and total (<italic>T</italic> &#x003D; <italic>X</italic> &#x002B; <italic>E</italic> &#x002B; <italic>I</italic>, black) to all excitatory neurons. Currents here and elsewhere are reported in units <italic>C<sub>m</sub>V/s</italic> where <italic>C<sub>m</sub></italic> is the arbitrary membrane capacitance. <bold>E)</bold> Mean external (green), recurrent (purple), and total (black) input to excitatory neurons for networks of different sizes, <italic>N</italic>. <bold>F)</bold> Mean excitatory (red) and inhibitory (blue) neuron firing rates for difference network sizes. Solid curves are from simulations and dashed curves are from <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref>. <bold>G)</bold> Mean covariance between pairs of excitatory neurons&#x2019; external inputs (green), recurrent inputs (purple), total inputs (black), and mean covariance between the recurrent input to one excitatory neuron and external input to the other (yellow) for different network sizes. Covariances were computed by integrating the inputs over 250ms windows then computing covariances between the integrals, which is proportional to zero-frequency CSD and has a closer relationship with spike count covariance (see <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref> and surrounding discussion). Integrated currents have units <italic>C<sub>m</sub>mV</italic>, so their covariances have units <inline-formula><alternatives><inline-graphic xlink:href="372607_inline2.gif"/></alternatives></inline-formula>. <bold>H)</bold> Zoomed in view of black curve from E on a log-log axis (mean total input covariance, black) plotted alongside the function <italic>c</italic>/<italic>N</italic> (dashed gray) where <italic>c</italic> was chosen so that the two curves match at the largest <italic>N</italic> value. <bold>I)</bold> Mean spike count covariance between excitatory neuron spike trains (red), between inhibitory neuron spike trains (blue), and between excitatory-inhibitory pairs of spike trains (purple). Counts were computed over 250ms time windows. Solid curves are from simulations, dashed from <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref> evaluated at zero frequency. Network size was <italic>N</italic> &#x003D; 10<sup>5</sup> in B-D.</p></caption>
<graphic xlink:href="372607_fig1.tif"/>
</fig>
<p>The membrane potential of neuron <italic>j</italic> in population <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic> obeys the exponential integrate-and-fire (EIF) dynamics
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn1.gif"/></alternatives></disp-formula>
with the added condition that each time <inline-formula><alternatives><inline-graphic xlink:href="372607_inline3.gif"/></alternatives></inline-formula> exceeds <italic>V<sub>th</sub></italic>, it is reset to <italic>V<sub>re</sub></italic> and a spike is recorded. We additionally set a lower bound on the membrane potential at <italic>V<sub>lb</sub></italic> &#x003D; <italic>&#x2212;</italic>100mV. Spike trains are represented as a sum of Dirac delta functions,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn2.gif"/></alternatives></disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="372607_inline4.gif"/></alternatives></inline-formula> is the <italic>n</italic>th spike time of neuron <italic>j</italic> in population <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic>. The total synaptic input current to neuron <italic>j</italic> in population <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic> is decomposed as
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn3.gif"/></alternatives></disp-formula>
where
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="372607_eqn1.gif"/></alternatives></disp-formula>
for <italic>B</italic> &#x003D; <italic>E</italic>, <italic>I</italic>, <italic>X</italic> and <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> respectively where &#x002A; denotes convolution, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline5.gif"/></alternatives></inline-formula> is the synaptic weight from neuron <italic>k</italic> in population <italic>b</italic> to neuron <italic>j</italic> in population <italic>a</italic>, and <italic>&#x03B1;<sub>b</sub></italic>(<italic>t</italic>) is a postsynaptic current (PSC) waveform. Without loss of generality, we assume that &#x222B; &#x03B1;b(t) &#x003D; 1. We use <inline-formula><alternatives><inline-graphic xlink:href="372607_inline6.gif"/></alternatives></inline-formula> where <italic>H</italic>(<italic>t</italic>) is the Heaviside step function, though our results do not depend sensitively on the precise neuron model or PSC kernel used. For calculations, it is useful to decompose the total synaptic input into its recurrent and external sources,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn4.gif"/></alternatives></disp-formula>
where
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn5.gif"/></alternatives></disp-formula>
is the recurrent synaptic input from the local circuit.</p>
<p>Local cortical circuits contain a large number of neurons and individual cortical neurons receive synaptic input from thousands of other neurons within their local circuit and from other layers or areas. Densely connected balanced networks have been proposed to model such large and densely interconnected neuronal networks [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c38">38</xref>]. In such models, one considers the limit of large <italic>N</italic> (with <italic>N<sub>x</sub></italic>, <italic>N<sub>e</sub></italic> and <italic>N<sub>i</sub></italic> scaled proportionally) with fixed connection probabilities and where synaptic weights are scaled like <inline-formula><alternatives><inline-graphic xlink:href="372607_inline7.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>]. This scaling naturally captures the balance of mean excitatory and mean inhibitory synaptic input, as well as the tracking of excitation by inhibition, observed in cortical recordings [<xref ref-type="bibr" rid="c29">29</xref>]. In particular, we consider a random connectivity structure in which
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="372607_eqn2.gif"/></alternatives></disp-formula>
where connections are statistically independent and <italic>j<sub>ab</sub></italic>, <italic>p<sub>ab</sub></italic> &#x007E; <italic>&#x1D4AA;</italic>(1) for <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> and <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic>. We furthermore define the proportions
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn6.gif"/></alternatives></disp-formula>
which are assumed <italic>&#x1D4AA;</italic>(1). For all examples we consider, <italic>q<sub>e</sub></italic> &#x003D; 0.8 and <italic>q<sub>i</sub></italic> &#x003D; <italic>q<sub>x</sub></italic> &#x003D; 0.2.</p>
<p>We next introduce notational conventions for quantifying the statistics of spike trains and synaptic inputs in the network. The mean firing rates of neurons in population <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> is defined by <italic>r<sub>a</sub></italic> for <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> and it is useful to define the 2 &#x00D7; 1 vector, <bold><italic>r</italic></bold> &#x003D; [<italic>r<sub>e</sub> r<sub>i</sub></italic>]<sup><italic>T</italic></sup>. The mean is technically interpreted as the expectation over realizations of the network connectivity, but for large <italic>N</italic> it is approximately equal to the sample mean over all neurons the network. Similarly, mean-field synaptic inputs to neurons in populations <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic> are defined by
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn7.gif"/></alternatives></disp-formula>
for <italic>U</italic> &#x003D; <italic>E</italic>, <italic>I</italic>, <italic>X</italic>, <italic>R</italic>, <italic>T</italic> and, in vector form, <bold><italic>U&#x0304;</italic></bold> &#x003D; [<italic>U<sub>e</sub> U<sub>i</sub></italic>]<sup><italic>T</italic></sup></p>
<p>For quantifying correlated variability, we use the cross-spectral density (CSD)
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn8.gif"/></alternatives></disp-formula>
between <inline-formula><alternatives><inline-graphic xlink:href="372607_inline8.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline9.gif"/></alternatives></inline-formula> for <italic>U</italic>, <italic>Z</italic> &#x003D; <italic>E</italic>, <italic>I</italic>, <italic>X</italic>, <italic>S</italic>, <italic>R</italic>, <italic>T</italic> and <italic>a</italic>, <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> where
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn9.gif"/></alternatives></disp-formula>
is the cross-covariance function. The argument, <italic>f</italic>, is the frequency at which the CSD is evaluated. The CSD is a convenient measure of correlated variability because it simplifies mathematical calculations due to the fact that it is a Hermitian operator and because most commonly used measures of correlated variability can be written as a function of the CSD. For example, the cross-covariance is the inverse Fourier transform of the CSD. Spike count covariances over large time windows can be written in terms of the CSD by first noting that the spike count is an integral of the spike train [<xref ref-type="bibr" rid="c4">4</xref>],
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn10.gif"/></alternatives></disp-formula></p>
<p>For large <italic>t</italic><sub>0</sub>, the cross-spectrum between two integrals is related to the zero-frequency CSD,
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="372607_eqn3.gif"/></alternatives></disp-formula></p>
<p>Hence,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn11.gif"/></alternatives></disp-formula></p>
<p>Following this result, we often quantify covariability between spike trains and between synaptic currents using the zero-frequency CSD, which we estimate by taking the covariance between integrals as in <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref> using <italic>t</italic><sub>0</sub> &#x003D; 250ms. This provides a simple, easily estimated quantity for quantifying covariance.</p>
<p>Most of our computations are performed at the level of population averages, so we define
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn12.gif"/></alternatives></disp-formula>
which is a scalar function of frequency, <italic>f</italic>, for each <italic>a</italic>, <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> and <italic>U</italic>, <italic>W</italic> &#x003D; <italic>E</italic>, <italic>I</italic>, <italic>X</italic>, <italic>S</italic>, <italic>R</italic>, <italic>T</italic>. It is also convenient to define the 2 <italic>&#x00D7;</italic> 2 mean-field matrix form,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn13.gif"/></alternatives></disp-formula>
for <bold><italic>U</italic></bold>, <bold><italic>W</italic></bold> &#x003D; <bold><italic>E</italic></bold>, <bold><italic>I</italic></bold>, <bold><italic>X</italic></bold>, <bold><italic>S</italic></bold>, <bold><italic>R</italic></bold>, <bold><italic>T</italic></bold>. We also define the recurrent and feedforward mean-field connectivity matrices,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn14.gif"/></alternatives></disp-formula>
where <italic>w<sub>ab</sub></italic>(<italic>f</italic>) &#x003D; <italic>p<sub>ab</sub>j<sub>ab</sub>q<sub>b</sub>&#x03B7;&#x0303;<sub>b</sub></italic>(<italic>f</italic>) &#x007E; <italic>&#x1D4AA;</italic>(1) with <italic>&#x03B7;&#x0303;<sub>b</sub></italic>(<italic>f</italic>) the Fourier transform of <italic>&#x03B7;<sub>b</sub></italic>(<italic>t</italic>). For the exponential kernels we use, <italic>&#x03B7;&#x0303;<sub>b</sub></italic>(<italic>f</italic>) &#x003D; 1<italic>/</italic>(1 &#x002B; 2<italic>&#x03C0;if&#x03C4;<sub>b</sub></italic>). The zero-frequency values, <italic>w&#x0304;<sub>ab</sub></italic> &#x003D; <italic>w<sub>ab</sub></italic> (0) &#x003D; <italic>p<sub>ab</sub>j<sub>ab</sub>q<sub>b</sub></italic>, define time-averaged interactions and mean-field connection matrices, <italic>W&#x0304;</italic> &#x003D; <italic>W&#x0304;</italic> (0) and <italic>W&#x0304;<sub>x</sub></italic> &#x003D; <italic>W<sub>x</sub></italic>(0).</p>
<p>This choice of notation allows us to perform computations on mean-field spike train and input statistics in a mathematically compact way. To demonstrate this, we first review the mean-field anal<underline>ys</underline>is of firing rates in the balanced state [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c40">40</xref>&#x2013;<xref ref-type="bibr" rid="c42">42</xref>]. Mean external input is given by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline10.gif"/></alternatives></inline-formula> and mean recurrent input by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline11.gif"/></alternatives></inline-formula> so that mean total synaptic input is given by
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn15.gif"/></alternatives></disp-formula></p>
<p>In the balanced state, <bold><italic>T&#x0302;</italic></bold>, <bold><italic>r &#x007E;</italic></bold> <italic>&#x1D4AA;</italic>(1), which can only be obtained by a cancellation between external and recurrent synaptic inputs. This cancellation requires <inline-formula><alternatives><inline-graphic xlink:href="372607_inline12.gif"/></alternatives></inline-formula> so that [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c40">40</xref>&#x2013;<xref ref-type="bibr" rid="c42">42</xref>]
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="372607_eqn4.gif"/></alternatives></disp-formula>
in the balanced state. Hence, the balanced state can only be realized when this solution has positive entries, <italic>r<sub>e</sub></italic>, <italic>r<sub>i</sub> &#x003E;</italic> 0, which requires that [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c40">40</xref>] <italic>X&#x0304;<sub>e</sub></italic>/<italic>X&#x0304;<sub>i</sub></italic> &#x003E; <italic>w<sub>ei</sub></italic>/<italic>w<sub>ii</sub></italic> &#x003E; <italic>w<sub>ee</sub></italic>/<italic>w<sub>ie</sub></italic>. Below, we perform analogous derivations of mean-field CSDs in balanced networks.</p>
<sec id="s2a">
<title>A review of the asynchronous balanced state</title>
<p>We first review prior theoretical work that derives mean-field CSDs when spike trains in the external population are uncorrelated Poisson processes (<xref ref-type="fig" rid="fig1">Fig. 1A,B</xref>), so
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn16.gif"/></alternatives></disp-formula></p>
<p>Since the derivations of these results [<xref ref-type="bibr" rid="c38">38</xref>] and analogous derivations for networks of binary neuron models [<xref ref-type="bibr" rid="c29">29</xref>] are presented elsewhere and since the derivations are similar to those presented below, we only review the results here and give the details of the derivation in Materials and Methods.</p>
<p>Since spike trains in the external population are uncorrelated, correlations between the external input to neurons in the recurrent network arise solely from overlapping feedforward synaptic projections with [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c38">38</xref>] (see Materials and Methods)
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="372607_eqn5.gif"/></alternatives></disp-formula>
where <italic>W<sub>x</sub></italic>&#x002A; is the conjugate transpose of <italic>W<sub>x</sub></italic>. If the spike trains in the external layer were uncorrelated, but not Poisson, then <italic>r<sub>x</sub></italic> in this equation could be replaced by the power spectral density of the spike trains.</p>
<p>It would at first seem that this <italic>&#x1D4AA;</italic>(1) external input correlation would lead to <italic>&#x1D4AA;</italic> (1) correlations between neurons&#x2019; spike trains, but this is prevented by a cancellation between positive and negative sources of input correlation. In particular, correlations between neurons&#x2019; recurrent synaptic inputs, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline13.gif"/></alternatives></inline-formula>, are also positive and <italic>&#x1D4AA;</italic>(1), but these positive sources of input correlations are canceled by negative correlations between neurons&#x2019; recurrent and external inputs, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline14.gif"/></alternatives></inline-formula>, in such a way that the total synaptic input correlation is weak,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn17.gif"/></alternatives></disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="372607_inline15.gif"/></alternatives></inline-formula>. This cancellation is realized when the mean-field CSD between spike trains satisfies [<xref ref-type="bibr" rid="c38">38</xref>]
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="372607_eqn6.gif"/></alternatives></disp-formula>
where <italic>N</italic> &#x00D7; <italic>o</italic>(1/<italic>N)</italic> &#x2192; 0 as <italic>N</italic> &#x2192; &#x221E;and <italic>W <sup>&#x2212;&#x002A;</sup></italic> is the inverse of <italic>W<sup>&#x002A;</sup></italic>. The first term in this equation represents spike train correlations inherited from external inputs, namely <inline-formula><alternatives><inline-graphic xlink:href="372607_inline16.gif"/></alternatives></inline-formula>. The second term, <italic>C</italic><sub>0</sub>, represents correlations generated intrinsically by chaotic or chaos-like dynamics in the network [<xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c43">43</xref>]. For example, a network with deterministic, constant external input, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline17.gif"/></alternatives></inline-formula>, generates correlated variability [<xref ref-type="bibr" rid="c40">40</xref>] despite the fact that such networks are deterministic once an initial condition is specified and therefore <inline-formula><alternatives><inline-graphic xlink:href="372607_inline18.gif"/></alternatives></inline-formula> for such networks. While an exact expression for <italic>C</italic><sub>0</sub> is unknown, we show empirically below that its effects are small compared to correlations inherited from external input, at least for the network parameters that we consider. Therefore, the following approximation is relatively accurate
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="372607_eqn7.gif"/></alternatives></disp-formula></p>
<p>To demonstrate these results, we first simulated a network of <italic>N</italic> &#x003D; 10<sup>4</sup> randomly and recurrently connected neurons receiving feedforward input from a population of <italic>N<sub>x</sub></italic> &#x003D; 2000 uncorrelated Poisson-spiking neurons (<xref ref-type="fig" rid="fig1">Fig. 1A,B</xref>). As predicted, spiking activity in the recurrent network was asynchronous and irregular (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>; mean spike count correlation between neurons with rates at least 1 Hz was 5.2 <italic>&#x00D7;</italic> 10<sup><italic>&#x2212;</italic>4</sup>) with approximate balance between external (<italic>X</italic>) and recurrent (<italic>R</italic>) synaptic input sources (<xref ref-type="fig" rid="fig1">Fig. 1D</xref>). Varying the network size, <italic>N</italic>, demonstrates the <inline-formula><alternatives><inline-graphic xlink:href="372607_inline19.gif"/></alternatives></inline-formula> growth of mean external (<bold><italic>X&#x0304;</italic></bold>) and recurrent (<bold><italic>R&#x0304;</italic></bold>) synaptic input currents that cancel to produce <italic>&#x1D4AA;</italic>(1) mean total input current (<bold><italic>T&#x0304;</italic></bold>) (<xref ref-type="fig" rid="fig1">Fig. 1E</xref>), as predicted by the mean-field theory of balance. As a result, firing rates converge to the limiting values predicted by <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref> (<xref ref-type="fig" rid="fig1">Fig. 1F</xref>).</p>
<p>As predicted by the analysis of the asynchronous state, the mean covariances between individual sources of synaptic inputs appear <italic>&#x1D4AA;</italic>(1) (<xref ref-type="fig" rid="fig1">Fig. 1G</xref>), but cancel to produce much smaller, <italic>&#x1D4AA;</italic> (1<italic>/N</italic>), total input covariance (<xref ref-type="fig" rid="fig1">Fig. 1G,H</xref>). Mean spike count covariances also appear <italic>&#x1D4AA;</italic> (1<italic>/N</italic>) and show good agreement with the closed form approximation from <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref> (<xref ref-type="fig" rid="fig1">Fig. 1I</xref>).</p>
<p>The fact that the approximation in <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref> accurately captures the scaling of spike count covariances from simulations implies that correlated variability inherited by overlapping synaptic inputs dominate intrinsic correlations, <italic>C</italic><sub>0</sub>, which are ignored in <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref>. Similar results were found in previous work [<xref ref-type="bibr" rid="c38">38</xref>]. This contrasts with previous findings in networks of binary neurons, in which intrinsic variability appeared to dominate [<xref ref-type="bibr" rid="c44">44</xref>].</p>
</sec>
<sec id="s2b">
<title>The correlated state in balanced networks</title>
<p>Above, we analyzed correlated variability when spike trains in the external population were uncorrelated, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline20.gif"/></alternatives></inline-formula>, which produced asynchronous spiking in the recurrent network, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline21.gif"/></alternatives></inline-formula>. We now relax this assumption by considering moderate correlations between neurons in the external layer (<xref ref-type="fig" rid="fig2">Fig. 2A</xref>),
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn18.gif"/></alternatives></disp-formula></p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2.</label>
<caption><title>The correlated state in densely connected balanced networks.</title>
<p><bold>A,B)</bold> Same as <xref ref-type="fig" rid="fig1">Fig. 1 B,C</xref> except spike trains in the external population, <italic>X</italic>, were correlated Poisson processes with spike count correlation <italic>c</italic> &#x003D; 0.1. <bold>C)</bold> Mean CSD between excitatory neuron spike trains (red), between inhibitory neuron spike trains (blue), and between excitatory-inhibitory pairs (purple). Solid curves are from simulations (each CSD averaged over 10<sup>5</sup> pairs) and dashed are from <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref>. <bold>D-I)</bold> Same as <xref ref-type="fig" rid="fig1">Fig. 1D-I</xref> except spike trains in the external population, <italic>X</italic>, were correlated Poisson processes with spike count correlation <italic>c</italic> &#x003D; 0.1. Dashed lines in I are from <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref> evaluated at zero frequency. Network size was <italic>N</italic> &#x003D; 10<sup>5</sup> in A-D.</p></caption>
<graphic xlink:href="372607_fig2.tif"/>
</fig>
<p>Most previous work analyzing spike train correlations in recurrent networks relies on knowledge of the &#x201C;correlation susceptibility&#x201D; or &#x201C;transfer&#x201D; function, which quantifies the mapping from synaptic input covariance to spike train covariance, <italic>e.g.</italic>, the mapping from <inline-formula><alternatives><inline-graphic xlink:href="372607_inline22.gif"/></alternatives></inline-formula>. However, susceptibility functions depend sensitively on the neuron model being used and their derivation typically relies on diffusion approximations that assume neurons&#x2019; input currents can be approximated by Gaussian white noise and are weakly correlated [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c11">11</xref>]. These assumptions are not valid for the densely connected, correlated networks with exponentially-decaying PSC kernels we consider here.</p>
<p>Instead of assuming knowledge of a covariance transfer or susceptibility function, our derivation relies only on an assumption that transfer of mean-field covariance is <italic>&#x1D4AA;</italic>(1), specifically that
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="372607_eqn8.gif"/></alternatives></disp-formula></p>
<p>In other words, mean-field spiking statistics are not drastically different in magnitude than mean-field input statistics because neurons transfer inputs to outputs in an <italic>&#x1D4AA;</italic>(1) fashion. Importantly, we do not need to know the value of the fraction in <xref ref-type="disp-formula" rid="eqn8">Eq. (8)</xref>.</p>
<p>In addition to this assumption, all of our derivations follow from a few simple arithmetical rules that rely on the bilinearity of the operator <inline-formula><alternatives><inline-graphic xlink:href="372607_inline23.gif"/></alternatives></inline-formula>. Specifically (see Materials and Methods for derivations),
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="372607_eqn9.gif"/></alternatives></disp-formula>
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="372607_eqn10.gif"/></alternatives></disp-formula>
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="372607_eqn11.gif"/></alternatives></disp-formula>
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="372607_eqn12.gif"/></alternatives></disp-formula>
for any <bold><italic>U</italic></bold>, <bold><italic>Z</italic></bold> &#x003D; <bold><italic>E</italic></bold>, <bold><italic>I</italic></bold>, <bold><italic>X</italic></bold>, <bold><italic>R</italic></bold>, <bold><italic>S</italic></bold>, <italic>S<sub>x</sub></italic>, <bold><italic>T</italic></bold> where <bold><italic>A&#x002A;</italic></bold> is the conjugate-transpose of <bold><italic>A</italic></bold> and where we omit smaller order terms here and below (see Materials and Methods for details). <xref ref-type="disp-formula" rid="eqn9">Eq. (9)</xref> follows from the fact that total input is composed of recurrent and external sources, <bold><italic>T</italic></bold> &#x003D; <bold><italic>R</italic></bold> &#x002B; <bold><italic>X</italic></bold>. <xref ref-type="disp-formula" rid="eqn10">Eqs. (10)</xref> and <xref ref-type="disp-formula" rid="eqn11">(11)</xref> follow from the fact that recurrent and external inputs are composed of linear combinations of <italic>&#x1D4AA;</italic>(<italic>N)</italic> spike trains, <italic>c.f.</italic> <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref>, and that synaptic weights are <inline-formula><alternatives><inline-graphic xlink:href="372607_inline24.gif"/></alternatives></inline-formula>. <xref ref-type="disp-formula" rid="eqn12">Eq. (12)</xref> is simply a property of the Hermitian cross-spectral operator.</p>
<p>We first derive the CSD between external inputs to neurons in the recurrent network. Applying of <xref ref-type="disp-formula" rid="eqn11">Eqs. (11)</xref> and <xref ref-type="disp-formula" rid="eqn12">(12)</xref> gives
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn19.gif"/></alternatives></disp-formula></p>
<p>Hence, <italic>&#x1D4AA;</italic>(1) covariance between the spike trains in the external population induces <italic>&#x1D4AA;</italic>(<italic>N)</italic> covariance between the external input currents to neurons in the recurrent network. This is a result of the effects of &#x201C;pooling&#x201D; on correlations and covariances, namely that the covariance between two sums of <italic>N</italic> correlated random variables is typically <italic>&#x1D4AA;</italic>(<italic>N</italic>) times larger than the covariances between the individual summed variables [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>].</p>
<p>We next derive the CSD between spike trains and external inputs. First note that
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="372607_eqn13.gif"/></alternatives></disp-formula></p>
<p>However, it follows from our assumption that neuronal transfer is <italic>&#x1D4AA;</italic>(1) (see <xref ref-type="disp-formula" rid="eqn8">Eq. (8)</xref>) that <inline-formula><alternatives><inline-graphic xlink:href="372607_inline25.gif"/></alternatives></inline-formula>. Therefore, we have
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn20.gif"/></alternatives></disp-formula>
which is only consistent if there is a cancellation between the two terms on the right hand side. Specifically, we must have that
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn21.gif"/></alternatives></disp-formula>
since <inline-formula><alternatives><inline-graphic xlink:href="372607_inline26.gif"/></alternatives></inline-formula> from above where we have omitted terms smaller than <inline-formula><alternatives><inline-graphic xlink:href="372607_inline27.gif"/></alternatives></inline-formula>. We can now calculate the CSD between spike trains in the recurrent network. First note that
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn22.gif"/></alternatives></disp-formula></p>
<p>However, our assumption of <italic>&#x1D4AA;</italic>(1) transfer implies that <inline-formula><alternatives><inline-graphic xlink:href="372607_inline28.gif"/></alternatives></inline-formula> so
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn23.gif"/></alternatives></disp-formula>
which is only consistent if there is cancellation between the terms on the right hand side. This cancellation can only be realized if
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="372607_eqn14.gif"/></alternatives></disp-formula>
which is <italic>&#x1D4AA;</italic>(1) and where we have omitted terms of smaller order. Notably, evaluating <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref> does not depend on knowledge of neurons&#x2019; correlation susceptibility functions or any other neuronal transfer properties, but only depends on synaptic parameters and input statistics.</p>
<p>In summary, <italic>&#x1D4AA;</italic>(1) covariance between spike trains in the external population produces <italic>&#x1D4AA;</italic>(<italic>N</italic>) covariance between neurons&#x2019; external inputs, but <italic>&#x1D4AA;</italic>(1) covariance between spike trains in the recurrent network on average. We hereafter refer to this state as the &#x201C;correlated state&#x201D; since it produces moderately strong spike train correlations in contrast to the asynchronous state characterized by extremely weak spike train correlations. The reduction from <italic>&#x1D4AA;</italic>(<italic>N</italic>) external input covariance to <italic>&#x1D4AA;</italic>(1) spike train covariance arises from a cancellation mechanism analogous to the one that reduces <italic>&#x1D4AA;</italic>(1) external input correlation to <italic>&#x1D4AA;</italic>(1<italic>/N</italic>) spike train correlations in the asynchronous state (see above).</p>
<p>To demonstrate these results, we simulated a network of <italic>N</italic> &#x003D; 10<sup>4</sup> neurons identical to the network from <xref ref-type="fig" rid="fig1">Fig. 1</xref> except that spike trains in the external population were correlated Poisson processes (<xref ref-type="fig" rid="fig2">Fig. 2A</xref>) with
<disp-formula id="eqn15">
<alternatives><graphic xlink:href="372607_eqn15.gif"/></alternatives></disp-formula></p>
<p>Here, <italic>r<sub>x</sub></italic> &#x003D; 10Hz is the same firing rate used in <xref ref-type="fig" rid="fig1">Fig. 1</xref> and <italic>c</italic> &#x003D; 0.1 quantifies the spike count correlation coefficient between the spike trains in the external population over large counting windows. See Materials and Methods for a description of the algorithm used to generate the spike trains.</p>
<p>The recurrent network exhibited moderately correlated spike trains in contrast to spike trains in the asynchronous state (<xref ref-type="fig" rid="fig2">Fig. 2B</xref>, compare to <xref ref-type="fig" rid="fig1">Fig. 1C</xref>; mean spike count correlation between neurons with rates at least 1 Hz was 0.077). The mean CSDs between spike trains in the recurrent network closely matched the theoretical predictions from <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref> (<xref ref-type="fig" rid="fig2">Fig. 2C</xref>). As in the asynchronous state, external and recurrent synaptic input sources approximately canceled (<xref ref-type="fig" rid="fig2">Fig. 2D</xref>), as predicted by balanced network theory.</p>
<p>Varying <italic>N</italic> demonstrates that the network exhibits the same cancellation between <italic>&#x1D4AA;</italic>(<italic>N</italic>) mean external and recurrent synaptic input sources and that <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref> for the mean firing rates is accurate (<xref ref-type="fig" rid="fig2">Fig. 2E,F</xref>). As predicted by the analysis of the correlated state, the covariance between individual sources of input currents appear <italic>&#x1D4AA;</italic>(<italic>N</italic>) (<xref ref-type="fig" rid="fig2">Fig. 2G</xref>), but cancel to produce much smaller, approximately <italic>&#x1D4AA;</italic>(1), total input covariance (<xref ref-type="fig" rid="fig2">Fig. 2G,H</xref>). Mean spike count covariances also appear <italic>&#x1D4AA;</italic>(1) and converge toward the limit predicted by <xref ref-type="disp-formula" rid="eqn14">Eq. (14)</xref> (<xref ref-type="fig" rid="fig2">Fig. 2I</xref>). Hence, despite the complexity of spike timing dynamics in densely connected balanced networks, mean-field spike train covariances is accurately predicted by a simple, linear equation in terms of synaptic parameters. The derivation of this equation does not require the use of linear response theory, which can be problematic for densely connected networks with synaptic kinetics and non-vanishing correlations.</p>
</sec>
<sec id="s2c">
<title>The correlated state produces tight balance between excitatory and inhibitory input fluctuations consistent with cortical recordings</title>
<p>We have so far considered cancellation between positive and negative sources of input correlations at the mean-field level, <italic>i.e.</italic>, averaged over pairs of postsynaptic neurons (<xref ref-type="fig" rid="fig1">Figs. 1G,H</xref> and <xref ref-type="fig" rid="fig2">2G,H</xref>). <italic>In vivo</italic> cortical recordings reveal that this cancellation occurs even at the level of single postsynaptic neuron pairs. When one neuron was clamped near its inhibitory reversal potential and another neuron is clamped near its excitatory reversal potential (with spiking suppressed), recorded membrane potential fluctuations are approximately mirror images of one another (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>, top). Similarly, if both neurons are held near their excitatory reversal potential (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>, middle) or both near their inhibitory reversal potential (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>, bottom), recorded membrane potential fluctuations are highly correlated. This implies that fluctuations in the excitatory and inhibitory synaptic input to one neuron are strongly correlated with fluctuations in the excitatory and inhibitory input to other nearby neurons (see [<xref ref-type="bibr" rid="c22">22</xref>] for more details and interpretation).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig 3.</label>
<caption><title>Excitatory-inhibitory tracking in vivo and in simulations.</title>
<p><bold>A)</bold> In vivo membrane potential recordings from neurons in rat barrel cortex, reproduced from [<xref ref-type="bibr" rid="c22">22</xref>]. Each pair of traces are simultaneously recorded membrane potentials. Red traces were recorded in current clamp mode near the reversal potential of inhibition and blue traces near the reversal potential of excitation (with action potentials pharmacologically suppressed), so red traces are approximately proportional to excitatory input current fluctuations and blue traces approximate inhibitory input current fluctuations. Vertical scale bars are 20mV. <bold>B,C)</bold> Excitatory (red) and inhibitory (blue) synaptic input currents to two randomly selected excitatory neurons in the asynchronous (B) and correlated (C) states. Simulations were the same as those in <xref ref-type="fig" rid="fig1">Figs. 1B-D</xref> and <xref ref-type="fig" rid="fig2">2A-D</xref> respectively. Currents are plotted with outward polarity negative and inward positive.</p></caption>
<graphic xlink:href="372607_fig3.tif"/>
</fig>
<p>To test whether this phenomenon occurred in our simulations, we randomly chose two neurons and decomposed their synaptic input into the total excitatory (<italic>E</italic> &#x002B; <italic>X</italic>) and the inhibitory (<italic>I</italic>) components. In the asynchronous state, input current fluctuations were fast and largely unshared between neurons or between current sources in the same neuron (<xref ref-type="fig" rid="fig3">Fig. 3B</xref>), in contrast to evidence from <italic>in vivo</italic> recordings. Input current fluctuations in the correlated state were slower, larger, and most importantly largely synchronized between neurons (<xref ref-type="fig" rid="fig3">Fig. 3C</xref>), consistent with evidence from <italic>in vivo</italic> recordings. This precise tracking of fluctuations in excitatory and inhibitory synaptic currents is referred to as &#x201C;tight balance&#x201D; [<xref ref-type="bibr" rid="c47">47</xref>] (as opposed to the &#x201C;loose balance&#x201D; of the asynchronous state). The results would be similar if we decomposed inputs into their external (<italic>X</italic>) and recurrent (<italic>R</italic> &#x003D; <italic>E</italic> &#x002B; <italic>I</italic>) sources instead of excitatory (<italic>E</italic> &#x002B; <italic>X</italic>) and inhibitory (<italic>I</italic>).</p>
<p>To better understand this striking difference between input currents in the asynchronous and correlated states, we first computed the average covariance between the excitatory and inhibitory input to pairs of (excitatory) neurons in the network. These averages have the same dependence on network size, <italic>N</italic>, as they do when input currents are broken into external and recurrent sources (compare <xref ref-type="fig" rid="fig4">Fig. 4A,B</xref> to <xref ref-type="fig" rid="fig1">Figs. 1G</xref> and <xref ref-type="fig" rid="fig2">2G</xref>). Specifically, in the asynchronous state, covariances between individual current sources are <italic>&#x1D4AA;</italic>(1) on average, but cancel to produce weak <italic>&#x1D4AA;</italic>(1/<italic>N</italic>) covariance between the total synaptic input to neurons on average (<xref ref-type="fig" rid="fig4">Fig. 4A</xref>). In the correlated state, the average covariance between individual input sources is <italic>&#x1D4AA;</italic> (<italic>N</italic>) and cancellation produces <italic>&#x1D4AA;</italic>(1) average total input covariance (<xref ref-type="fig" rid="fig4">Fig. 4B</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig 4.</label>
<caption><title>The scaling of mean and variance of excitatory and inhibitory input covariance in the asynchronous and correlated states.</title>
<p><bold>A,B)</bold> Same as <xref ref-type="fig" rid="fig1">Figs. 1G</xref> and <xref ref-type="fig" rid="fig2">2G</xref>, except inputs were decomposed into their excitatory (<italic>E</italic> &#x002B; <italic>X</italic>), and inhibitory (<italic>I</italic>) components instead of external and recurrent. Red curves show mean excitatory-excitatory input covariance, blue show inhibitory-inhibitory, purple show excitatory-inhibitory, and black curves show total (same as black curves in <xref ref-type="fig" rid="fig1">Figs. 1G</xref> and <xref ref-type="fig" rid="fig2">2G</xref>). <bold>C,D)</bold> Histogram of input current covariances across all excitatory cell pairs for a network of size <italic>N</italic> &#x003D; 10<sup>5</sup>. <bold>E,F)</bold> Same as A,B except we plotted the variance of covariances across cell pairs instead of the mean. As above, integrated currents have units <italic>C<sub>m</sub>mV</italic>, so input covariances have units <inline-formula><alternatives><inline-graphic xlink:href="372607_inline29.gif"/></alternatives></inline-formula> and the variance of covariances have units <inline-formula><alternatives><inline-graphic xlink:href="372607_inline30.gif"/></alternatives></inline-formula> where <italic>C<sub>m</sub></italic> is the arbitrary membrane capacitance.</p></caption>
<graphic xlink:href="372607_fig4.tif"/>
</fig>
<p>Hence, despite the precise cancellation of positive and negative sources of input covariance at the mean-field level in the asynchronous state (<xref ref-type="fig" rid="fig4">Fig. 4A</xref>), this cancellation is apparently not observed at the level of individual neuron pairs (<xref ref-type="fig" rid="fig3">Fig. 3B</xref>). To see why this is the case, we computed the distribution of input current covariances across all pairs of excitatory neurons. We found that these distributions were broad and the distribution of total input covariance was highly overlapping with the distributions of individual input current sources (<xref ref-type="fig" rid="fig4">Fig. 4C</xref>, the black distribution overlaps with the others). This implies that cancellation does not reliably occur at the level of individual pairs since, for example, the total input covariance for a pair of neurons can be similar in magnitude or even larger than the covariance between those neurons&#x2019; excitatory inputs.</p>
<p>The distributions of input covariances were strikingly difference in the correlated state. The distribution of total input covariances was far narrower than the distributions of individual input current sources and the distributions were virtually non-overlapping (<xref ref-type="fig" rid="fig4">Fig. 4D</xref>). Hence, a precise cancellation between positive and negative sources of input covariance must occur for every neuron pair, leading to the tight balance observed in <xref ref-type="fig" rid="fig3">Fig. 3C</xref>.</p>
<p>These results are more precisely understood by computing the variance across neuron pairs of input covariances as <italic>N</italic> is varied. In the asynchronous state, the variance of input covariances from all sources appear to scale like <italic>&#x1D4AA;</italic>(1) (<xref ref-type="fig" rid="fig4">Fig. 4E</xref>). Since the mean input covariance between individual sources are also <italic>&#x1D4AA;</italic> (1) (<xref ref-type="fig" rid="fig4">Fig. 4A</xref>), the overlap between distributions in <xref ref-type="fig" rid="fig4">Fig. 4C</xref> is expected. In the correlated state, the variances of input covariances appear to scale like <italic>&#x1D4AA;</italic>(<italic>N)</italic> except for the variance of the total input covariance, which appears to scale like <italic>&#x1D4AA;</italic>(1) (<xref ref-type="fig" rid="fig4">Fig. 4F</xref>). Since the variances scale like <italic>&#x1D4AA;</italic>(<italic>N</italic>), the standard deviations scale like <italic>&#x1D4AA;</italic>(<italic>N</italic>). This, combined with the fact that the mean input covariances between individual sources scale like <italic>&#x1D4AA;</italic> (<italic>N</italic>), implies that the distributions in <xref ref-type="fig" rid="fig4">Fig. 4E</xref> will be non-overlapping when <italic>N</italic> is large. The same conclusions would be reached if we decomposed inputs into their external (<italic>X</italic>) and recurrent (<italic>R</italic> &#x003D; <italic>E</italic> &#x002B; <italic>I</italic>) sources instead of total excitatory (<italic>X</italic> &#x002B; <italic>E</italic>) and inhibitory (<italic>I</italic>).</p>
</sec>
<sec id="s2d">
<title>Testing linear response approximations to pairwise spike train covariance</title>
<p>As discussed above, <xref ref-type="disp-formula" rid="eqn7">Eqs. (7)</xref> and <xref ref-type="disp-formula" rid="eqn14">(14)</xref> are appealing because, unlike many previous approximations of spike train CSD and spike count covariance in recurrent networks [<xref ref-type="bibr" rid="c8">8</xref>&#x2013;<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c13">13</xref>], they do not require knowledge of neurons&#x2019; correlation susceptibility functions or any other neuronal transfer properties. However, they are limited because they only give the population-averaged covariance or CSD.</p>
<p>Previous studies that provide approximations for the full <italic>N &#x00D7; N</italic> matrix of all spike train CSDs or spike count covariances use linear response approximations that rely on assumptions that the network is sparsely or weakly coupled and/or that external input is uncorrelated or weakly correlated Gaussian white noise [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>]. These assumptions permit the application of Fokker-Planck and linear response techniques. External input in our models is not weakly correlated and is not approximated well by Gaussian white noise, so these approaches are not fully justified in out model, but might nevertheless yield a useful approximation. We next derive and test a linear response approximation to spike train covariability in our model.</p>
<p>First define <inline-formula><alternatives><inline-graphic xlink:href="372607_inline31.gif"/></alternatives></inline-formula> to be the full <italic>N &#x00D7;</italic> 1 vector of spike trains in the recurrent network obtained by concatenating the excitatory and inhibitory spike train vectors. Define the <italic>N</italic> &#x00D7; 1 synaptic input vectors <inline-formula><alternatives><inline-graphic xlink:href="372607_inline32.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline33.gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline34.gif"/></alternatives></inline-formula> similarly. The total input vector can be written as
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn24.gif"/></alternatives></disp-formula>
with
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn25.gif"/></alternatives></disp-formula>
and
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn26.gif"/></alternatives></disp-formula></p>
<p>Here,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn27.gif"/></alternatives></disp-formula>
is the <italic>N &#x00D7; N</italic> recurrent connectivity matrix and
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn28.gif"/></alternatives></disp-formula>
is the <italic>N</italic> &#x00D7; <italic>N<sub>x</sub></italic> feedforward connectivity matrix with <italic>N<sub>a</sub></italic> &#x00D7; <italic>N<sub>b</sub></italic> blocks defined by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline35.gif"/></alternatives></inline-formula>. Note that the connection weights are time dependent and denotes the matrix product with multiplication replaced by convolution [<xref ref-type="bibr" rid="c11">11</xref>].</p>
<p>The linearity of transfer from <inline-formula><alternatives><inline-graphic xlink:href="372607_inline36.gif"/></alternatives></inline-formula> to <inline-formula><alternatives><inline-graphic xlink:href="372607_inline37.gif"/></alternatives></inline-formula> and from <inline-formula><alternatives><inline-graphic xlink:href="372607_inline38.gif"/></alternatives></inline-formula> to <inline-formula><alternatives><inline-graphic xlink:href="372607_inline39.gif"/></alternatives></inline-formula> implies that
<disp-formula id="eqn16">
<alternatives><graphic xlink:href="372607_eqn16.gif"/></alternatives></disp-formula>
and
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn29.gif"/></alternatives></disp-formula>
for <inline-formula><alternatives><inline-graphic xlink:href="372607_inline40.gif"/></alternatives></inline-formula> where <italic>J&#x0303;</italic>(<italic>f</italic>) is the element-wise Fourier transform of the matrix <italic>J</italic>(<italic>t</italic>) and similarly for <italic>J&#x0303;<sub>x</sub></italic>(<italic>f</italic>). This implies, for example, that the <italic>N</italic> &#x00D7; <italic>N</italic> matrix of external input CSDs is given by
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn30.gif"/></alternatives></disp-formula>
and similarly for the CSDs between recurrent inputs,
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn31.gif"/></alternatives></disp-formula></p>
<p>In summary, the transfer of spike train CSDs to input CSDs follows easily from the linearity of transfer from spike trains to inputs [<xref ref-type="bibr" rid="c4">4</xref>]. However, a closed expression for the matrix of spike train CSDs in the recurrent network, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline41.gif"/></alternatives></inline-formula>, requires knowledge of the transfer from total input to spike train CSDs.</p>
<p>If spike trains were related linearly to total input, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline42.gif"/></alternatives></inline-formula> for some diagonal matrix, <italic>A</italic>(<italic>t</italic>), then we could derive an exact closed equation for <inline-formula><alternatives><inline-graphic xlink:href="372607_inline43.gif"/></alternatives></inline-formula>. However, integrate-and-fire neuron models transfer their input currents to spike trains nonlinearly.</p>
<p>Nevertheless, we can obtain an approximation to spike train CSDs by assuming an approximate linear transfer of CSDs, specifically that [<xref ref-type="bibr" rid="c11">11</xref>]
<disp-formula id="eqn17">
<alternatives><graphic xlink:href="372607_eqn17.gif"/></alternatives></disp-formula>
where <italic>A&#x0303;</italic>(<italic>f</italic>) is a diagonal matrix with <italic>A&#x0303;<sub>jj</sub></italic>(<italic>f</italic>) the &#x201C;susceptibility function&#x201D; of neuron <italic>j</italic> [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c48">48</xref>&#x2013;<xref ref-type="bibr" rid="c50">50</xref>]. Note that these equations would be exactly true if neural transfer were linear, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline44.gif"/></alternatives></inline-formula>. It can be derived from these assumptions that (see Materials and Methods for derivation and [<xref ref-type="bibr" rid="c11">11</xref>] for similar derivations)
<disp-formula id="eqn18">
<alternatives><graphic xlink:href="372607_eqn18.gif"/></alternatives></disp-formula></p>
<p>One problem with testing the approximation in <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> is that we do not have an estimate of <italic>A&#x0303;<sub>jj</sub></italic>(<italic>f)</italic>. Spike count covariances over large windows are proportional to zero-frequency CSD (see <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref> and surrounding discussion). Evaluated at zero frequency, a neuron&#x2019;s susceptibility function is equal to its gain, <italic>i.e.</italic> the derivative of the neuron&#x2019;s firing rate with respect to its mean input [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>],
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn32.gif"/></alternatives></disp-formula></p>
<p>We therefore tested <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> for spike count covariances by estimating the gain empirically from simulations. In doing so, we found that <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> is only moderately accurate at approximating spike count covariances from simulations, both in the asynchronous state (<xref ref-type="fig" rid="fig5">Fig. 5A</xref>) and in the correlated state (<xref ref-type="fig" rid="fig5">Fig. 5B</xref>). We suspected that some of the error was due to numerical inaccuracies introduced by inverting the large, ill-conditioned matrices in <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref>. To test this hypothesis, we re-wrote <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> in a mathematically equivalent formulation that does not involve matrix inverses,
<disp-formula id="eqn19">
<alternatives><graphic xlink:href="372607_eqn19.gif"/></alternatives></disp-formula>
where <italic>Id</italic> is the <italic>N</italic> &#x00D7; <italic>N</italic> identity matrix. We tested the accuracy of <xref ref-type="disp-formula" rid="eqn19">Eq. (19)</xref> at zero frequency using the same empirically estimated values of the gains and using the matrix, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline45.gif"/></alternatives></inline-formula>, of spike count covariances estimated from simulations and found that it was very accurate, especially in the correlated state (<xref ref-type="fig" rid="fig5">Fig. 5C,D</xref>). Since <xref ref-type="disp-formula" rid="eqn18">Eqs. (18)</xref> and <xref ref-type="disp-formula" rid="eqn19">(19)</xref> are mathematically equivalent, this suggests that much of the observed inaccuracy of <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> is due to the presence of inverses of large, ill-conditioned matrices.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig 5.</label>
<caption><title>Testing the accuracy of linear response approximations in densely connected balanced networks in the asynchronous and correlated states.</title>
<p><bold>A,B)</bold> Spike count covariance from simulations of a network with <italic>N</italic> &#x003D; 10<sup>5</sup> in the asynchronous (A) and correlated (B) states plotted against the theoretical value given by evaluating <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> evaluated at zero frequency, with empirically estimated gains used for <italic>A&#x0303;<sub>j</sub></italic>(0). <bold>C,D)</bold> The left-hand-side (LHS) of <xref ref-type="disp-formula" rid="eqn19">Eq. (19)</xref> plotted against the right-hand-side (RHS) using <inline-formula><alternatives><inline-graphic xlink:href="372607_inline46.gif"/></alternatives></inline-formula> estimated from the same simulations as in A,B and using the same empirically estimated gains. <bold>E,F)</bold> Same as C,D except we used the mean gain for all values of <italic>A&#x0303;j</italic>(0).</p></caption>
<graphic xlink:href="372607_fig5.tif"/>
</fig>
<p>One shortcoming of <xref ref-type="disp-formula" rid="eqn18">Eqs. (18)</xref> and <xref ref-type="disp-formula" rid="eqn19">(19)</xref> is that they require an estimate of <italic>A&#x0303;</italic>. We obtained this estimate empirically by simulating the entire network and numerically estimating the gains, which greatly limits the utility of the equations. We next wondered whether the accuracy of the equations is sensitive to the accuracy of the gain estimate, or if a rough approximation to the gains would be sufficient. To answer this question, we tested <xref ref-type="disp-formula" rid="eqn19">Eq. (19)</xref> again, but replaced the individual estimated gains on the diagonal of <italic>A&#x0303;</italic> with their mean. In other words, we used <italic>A&#x0303;</italic> (0) &#x003D; <italic>g&#x0304;Id</italic> where <italic>g&#x0304;</italic> is the average gain estimated from simulations and <italic>Id</italic> is the <italic>N</italic> &#x00D7; <italic>N</italic> identity matrix. This replacement greatly decreased the accuracy of <xref ref-type="disp-formula" rid="eqn19">Eq. (19)</xref> (<xref ref-type="fig" rid="fig5">Fig. 5E,F</xref>), suggesting that an accurate estimate of the individual gains is necessary for applying and interpreting <xref ref-type="disp-formula" rid="eqn18">Eqs. (18)</xref> and <xref ref-type="disp-formula" rid="eqn19">(19)</xref>.</p>
<p>In summary, linear response approximations are fairly accurate in the densely connected balanced networks with spatially and temporally correlated noisy feedforward input studied here (<xref ref-type="fig" rid="fig5">Fig. 5C,D</xref>). However, their utility is limited by two factors: First, that using linear response theory to approximate spike train CSDs or spike count covariances requires the inversion of large, ill-conditioned matrices, which introduces substantial error (<xref ref-type="fig" rid="fig5">Fig. 5A,B</xref>). Secondly, that the application of linear response approximation requires estimates of neurons&#x2019; individual susceptibility functions or gains. The mean-field equations (7) and (14) do not have these shortcomings, but only give the population-averaged CSDs and covariances. It should also be noted that correlations were weak in our simulations, even in the correlated state (mean spike count correlations between neurons with firing rate above 1 Hz was 0.077). Stronger correlations can be obtained with alternative parameters, which could potentially make <xref ref-type="disp-formula" rid="eqn18">Eqs. (18)</xref> and <xref ref-type="disp-formula" rid="eqn19">(19)</xref> less accurate.</p>
</sec>
<sec id="s2e">
<title>Correlated variability from singular mean-field connectivity structure</title>
<p>We have shown that &#x1D4AA;(1) spike train correlations can be obtained in balanced networks by including correlations between neurons in an external layer <inline-formula><alternatives><inline-graphic xlink:href="372607_inline47.gif"/></alternatives></inline-formula>, defining what we refer to as the &#x201C;correlated state.&#x201D; Previous work shows that <italic>&#x1D4AA;</italic>(1) spike train correlations can be obtained in the recurrent network with uncorrelated external spike trains <inline-formula><alternatives><inline-graphic xlink:href="372607_inline48.gif"/></alternatives></inline-formula> when the mean-field connectivity matrix is constructed in such a way that the recurrent network cannot achieve the cancellation required for these states to be realized [<xref ref-type="bibr" rid="c37">37</xref>&#x2013;<xref ref-type="bibr" rid="c39">39</xref>]. This is most easily achieved using networks with several discrete sub-populations or networks with distance-dependent connectivity. For simplicity, we restrict our analysis to discrete sub-populations. We first extend the mean-field theory from above to such networks, then generalize and extend the analysis from previous work to understand the emergence of <italic>&#x1D4AA;</italic>(1) correlations when the mean-field connectivity matrix is singular.</p>
<p>The recurrent networks considered above have two statistically homogeneous sub-populations: one excitatory and one inhibitory and the external population is a single homogeneous population. Suppose instead that there are <italic>K</italic> sub-populations in the recurrent network, with the <italic>k</italic>th popualtion containing <italic>N<sub>k</sub></italic> &#x003D; <italic>q<sub>k</sub>N</italic> neurons where &#x03A3;<sub><italic>k</italic></sub> <italic>q<sub>k</sub></italic> &#x003D; 1. Connectivity is random with <italic>p<sub>j</sub>k</italic> donoting the connection probability from population <italic>k</italic> to <italic>j</italic>, and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline49.gif"/></alternatives></inline-formula> denoting the strengths of the connectons for <italic>j</italic>, <italic>k</italic> &#x003D; 1, &#x2026; <italic>K</italic>. All neurons in population <italic>k</italic> are assumed to have the PSC kernel <italic>&#x03B7;<sub>k</sub></italic>(<italic>t</italic>) which is again assumed to have integral 1. Similarly, suppose that the external network contains <italic>K<sub>x</sub></italic> sub-populations each with <inline-formula><alternatives><inline-graphic xlink:href="372607_inline50.gif"/></alternatives></inline-formula> neurons where <inline-formula><alternatives><inline-graphic xlink:href="372607_inline51.gif"/></alternatives></inline-formula>. Feedforward connection probabilities and strengths are given by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline52.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline53.gif"/></alternatives></inline-formula> for <italic>j</italic> &#x003D; 1, &#x2026; <italic>K</italic> and <italic>k</italic> &#x003D; 1, &#x2026;, <italic>K<sub>x</sub></italic>. Assume that <italic>q<sub>k</sub></italic>, <italic>p<sub>jk</sub></italic>, <italic>j<sub>jk</sub></italic>, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline54.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline55.gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline56.gif"/></alternatives></inline-formula> are all <italic>&#x1D4AA;</italic>(1). We then define the <italic>K</italic> &#x00D7; <italic>K</italic> mean-field recurrent connectivity matrix by [<italic>W</italic>]<sub><italic>jk</italic></sub> &#x003D; <italic>p<sub>jk</sub>j<sub>jk</sub>q<sub>k</sub>&#x03B7;&#x0303;<sub>k</sub></italic> and the mean-field feedforward connectivity matrix by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline57.gif"/></alternatives></inline-formula>. For all of the networks considered above, we had <italic>K</italic> &#x003D; 2 and <italic>K<sub>x</sub></italic> &#x003D; 1.</p>
<p>When <italic>W</italic> is an invertible matrix, <xref ref-type="disp-formula" rid="eqn4">Eqs. (4)</xref>, <xref ref-type="disp-formula" rid="eqn7">(7)</xref>, and <xref ref-type="disp-formula" rid="eqn14">(14)</xref> are equally valid for networks with several subpopulations as they are for the simpler networks considered above. Hence, the mean-field theory of firing rates and correlations extends naturally to networks with several populations [<xref ref-type="bibr" rid="c38">38</xref>&#x2013;<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c51">51</xref>]. However, when <italic>W</italic> is singular, <xref ref-type="disp-formula" rid="eqn4">Eqs. (4)</xref>, <xref ref-type="disp-formula" rid="eqn7">(7)</xref>, and <xref ref-type="disp-formula" rid="eqn14">(14)</xref> cannot be evaluated. Instead, <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref> can be re-written as
<disp-formula id="eqn20">
<alternatives><graphic xlink:href="372607_eqn20.gif"/></alternatives></disp-formula></p>
<p>When <italic>W</italic> is singular, this equation only has a solution, <bold><italic>r</italic></bold>, when <bold><italic>X&#x0304;</italic></bold> &#x003D; &#x2013;<italic>W<sub>x</sub></italic><bold><italic>r</italic></bold><sub><italic>x</italic></sub> is in the range or &#x201C;column space&#x201D; of <italic>W</italic>. Otherwise, balance is broken. An in-depth analysis of firing rates in such networks is provided in previous work [<xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c51">51</xref>] (and extended to spatially continuous networks in [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c51">51</xref>]), so we hereafter assume that <bold><italic>X&#x0304;</italic></bold> is in the range of <italic>W</italic> and balance is achieved.</p>
<p>A similar analysis may be applied to spike train CSDs. For simplicity, we assume here that spike trains in the external population are uncorrelated, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline58.gif"/></alternatives></inline-formula>, since this is the case considered in previous work and since this is the case in which a singular <italic>W</italic> breaks the asynchronous state. <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref> can be re-written as
<disp-formula id="eqn21">
<alternatives><graphic xlink:href="372607_eqn21.gif"/></alternatives></disp-formula>
where we have ignored smaller order terms. When <italic>W</italic> is singular, <xref ref-type="disp-formula" rid="eqn21">Eq. (21)</xref> is not guaranteed to have a solution, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline59.gif"/></alternatives></inline-formula>. More precisely, a solution can only exist when the <italic>K</italic> &#x00D7; <italic>K</italic> matrix, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline60.gif"/></alternatives></inline-formula>, is in the range of the linear operator <bold><italic>&#x2112;</italic></bold> defined by
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn33.gif"/></alternatives></disp-formula></p>
<p>In that case, <xref ref-type="disp-formula" rid="eqn21">Eq. (21)</xref> has a solution so that <inline-formula><alternatives><inline-graphic xlink:href="372607_inline61.gif"/></alternatives></inline-formula> and the asynchronous state is still realized. However, if <inline-formula><alternatives><inline-graphic xlink:href="372607_inline62.gif"/></alternatives></inline-formula> is not in the range of <bold><italic>&#x2112;</italic></bold>, the asynchronous state cannot be realized because <xref ref-type="disp-formula" rid="eqn21">Eq. (21)</xref> does not have a solution.</p>
<p>Darshan et al. [<xref ref-type="bibr" rid="c39">39</xref>] looked at a similar scenario except the singularity of their networks made them incapable of cancelling <italic>internally generated covariance</italic>, in contrast to the <italic>external input covariance</italic> considered here. Other work [<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c38">38</xref>] analyzed the scenario with external input covariance and singular connectivity, as well as the extension to spatially extended networks. However, this previous work did not completely analyze the structure of correlations, but only showed that the asynchronous state was broken. We next show that correlations in the recurrent network are <italic>&#x1D4AA;</italic>(1) and derive their structure.</p>
<p>Using <xref ref-type="disp-formula" rid="eqn9">Eqs. (9)</xref>, <xref ref-type="disp-formula" rid="eqn10">(10)</xref>, and <xref ref-type="disp-formula" rid="eqn12">(12)</xref>, we can write the mean-field total input CSD as
<disp-formula id="eqn22">
<alternatives><graphic xlink:href="372607_eqn22.gif"/></alternatives></disp-formula></p>
<p>If <italic>W</italic> is not invertible, then <italic>W<sup>&#x002A;</sup></italic> has a non-trivial nullspace. Let <italic>&#x03C5;</italic><sub>1</sub>, <italic>&#x03C5;</italic><sub>2</sub>, &#x2026;, <italic>&#x03C5;<sub>n</sub></italic> be a basis for the nullspace of <italic>W<sup>&#x002A;</sup></italic> and define
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn34.gif"/></alternatives></disp-formula>
which is a self-adjoint matrix that defines the orthogonal projection onto the nullspace of <italic>W<sup>&#x002A;</sup></italic>. Note that <italic>P</italic> is a Hermitian matrix (<italic>P</italic> &#x003D; <italic>P<sup>&#x002A;</sup></italic>) and <italic>PW</italic> &#x003D; <italic>W<sup>&#x002A;</sup>P</italic> &#x003D; 0 (the zero matrix). Define the projection <italic>A</italic><sub>0</sub> &#x003D; <italic>PAP</italic> for any matrix <italic>A</italic>. Unless <inline-formula><alternatives><inline-graphic xlink:href="372607_inline63.gif"/></alternatives></inline-formula> is carefully constructed otherwise, we can expect that
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn35.gif"/></alternatives></disp-formula></p>
<p>Then take the projection of both sides of <xref ref-type="disp-formula" rid="eqn22">Eq. (22)</xref> above to get
<disp-formula id="eqn23">
<alternatives><graphic xlink:href="372607_eqn23.gif"/></alternatives></disp-formula>
where we have omitted terms of order <inline-formula><alternatives><inline-graphic xlink:href="372607_inline64.gif"/></alternatives></inline-formula> (see Materials and Methods for more details). Hence, the total input CSD is <italic>&#x1D4AA;</italic>(1) when <inline-formula><alternatives><inline-graphic xlink:href="372607_inline65.gif"/></alternatives></inline-formula> is not in the range of <bold><italic>&#x2112;</italic></bold>, even though it is <inline-formula><alternatives><inline-graphic xlink:href="372607_inline66.gif"/></alternatives></inline-formula> when <italic>W</italic> is invertible (<italic>i.e.</italic>, in the asynchronous state). Moreover, the structure of <inline-formula><alternatives><inline-graphic xlink:href="372607_inline67.gif"/></alternatives></inline-formula> is given to highest order in <italic>N</italic> by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline68.gif"/></alternatives></inline-formula>, which can be computed exactly from knowledge of the structure of <inline-formula><alternatives><inline-graphic xlink:href="372607_inline69.gif"/></alternatives></inline-formula> and <italic>W</italic>.</p>
<p>When neural transfer from <bold><italic>T</italic></bold> to <bold><italic>S</italic></bold> is <italic>&#x1D4AA;</italic>(1) (see <xref ref-type="disp-formula" rid="eqn8">Eq. (8)</xref> and surrounding discussion), this implies that <inline-formula><alternatives><inline-graphic xlink:href="372607_inline70.gif"/></alternatives></inline-formula> so that the asynchronous state is broken when <inline-formula><alternatives><inline-graphic xlink:href="372607_inline71.gif"/></alternatives></inline-formula> is not in the range of <bold><italic>&#x2112;</italic></bold>. While we cannot be certain that <inline-formula><alternatives><inline-graphic xlink:href="372607_inline72.gif"/></alternatives></inline-formula> has the same structure as <inline-formula><alternatives><inline-graphic xlink:href="372607_inline73.gif"/></alternatives></inline-formula>, it should have a similar structure as long as neural transfer of correlations is similar for each sub-population.</p>
<p>To demonstrate these results, we consider the same network from above with re-wired feedforward projections from the external population. Specifically, divide the excitatory, inhibitory, and external populations each into two equal-sized sub-populations, labeled <italic>e</italic><sub>1</sub>, <italic>i</italic><sub>1</sub>, <italic>x</italic><sub>1</sub>, <italic>e</italic><sub>2</sub>, <italic>i</italic><sub>2</sub>, and <italic>x</italic><sub>2</sub> where population <italic>a<sub>k</sub></italic> contains <italic>N<sub>a</sub>/</italic>2 neurons. Hence the network has the same total number of neurons as before, but we have simply sub-divided the populations. To distinguish this network from the one considered in <xref ref-type="fig" rid="fig1">Figs. 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>, we refer to the previous network as the 3-population network and to this modified network as the 6-population network.</p>
<p>We re-wire the feedforward connections so that <italic>x</italic><sub>1</sub> only connects to <italic>e</italic><sub>1</sub> and <italic>i</italic><sub>1</sub>, and <italic>x</italic><sub>2</sub> only projects to <italic>e</italic><sub>2</sub> and <italic>i</italic><sub>2</sub>. Specifically, we set the connection probabilities to <inline-formula><alternatives><inline-graphic xlink:href="372607_inline74.gif"/></alternatives></inline-formula> if <italic>j</italic> &#x003D; <italic>k</italic> and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline75.gif"/></alternatives></inline-formula> if <italic>j</italic> &#x2260; <italic>k</italic> for <italic>a</italic>, <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic> and <italic>j</italic>, <italic>k</italic> &#x003D; 1, 2, where <italic>p<sub>ab</sub></italic> are the connection probabilities for the 3-population network and <italic>p<sub>a<sub>j</sub></sub> b<sub>k</sub></italic> for the 6-population network. This re-wiring assures that neurons in the recurrent network receive the same number of feedforward connections on average from the external population. The recurrent connectivity structure is not changed at all. Specifically, we set <inline-formula><alternatives><inline-graphic xlink:href="372607_inline76.gif"/></alternatives></inline-formula> for <italic>a</italic>, <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>. All connection strengths are unchanged, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline77.gif"/></alternatives></inline-formula> for <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic> and <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic> and all neurons in the external population have the same firing rate, <italic>r<sub>x</sub></italic>, as before. See <xref ref-type="fig" rid="fig6">Fig. 6A</xref> for a schematic of this network.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig 6.</label>
<caption><title>Correlated variability in a balanced network with singular mean-field connectivity matrix.</title>
<p><bold>A)</bold> Network schematic. The recurrent network is statistically identical to the networks considered previously, but there are two external populations that each connect to a different half of the neurons in the recurrent network. <bold>B)</bold> Same as <xref ref-type="fig" rid="fig1">Fig. 1F</xref>, but for the multi-population network from A. <bold>C)</bold> Same as <xref ref-type="fig" rid="fig1">Fig. 1G</xref>, but for the network in A and where input covariances are only averaged over postsynaptic neurons in the same group (both postsynaptic cells in <italic>e</italic><sub>1</sub> or both in <italic>e</italic><sub>2</sub>). The dashed gray curve shows the theoretical prediction for total input covariance (the black curve) from <xref ref-type="disp-formula" rid="eqn24">Eq. (24)</xref>. <bold>D)</bold> Same as <xref ref-type="fig" rid="fig1">Fig. 1I</xref>, but for the network in A and where spike count covariances are only averaged over postsynaptic neurons in the same group (first cell in <italic>a<sub>j</sub></italic> and second cell in <italic>b<sub>j</sub></italic> for <italic>a</italic>, <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic> and <italic>j</italic> &#x003D; 1, 2). <bold>E,F)</bold> Same as C and D, but covariances are computed between cells in opposite groups (one cell in <italic>a</italic><sub>1</sub> and the other cell in <italic>b</italic><sub>2</sub>).</p></caption>
<graphic xlink:href="372607_fig6.tif"/>
</fig>
<p>The feedforward mean-field connectivity matrix can be written in block form as
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn36.gif"/></alternatives></disp-formula>
where <bold>0</bold> is the 2 &#x00D7; 1 zero-matrix and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline78.gif"/></alternatives></inline-formula> is the 2 &#x00D7; 1 feedforward connectivity matrix for the 3-population network. Note that <italic>W<sub>x</sub></italic> is 4 &#x00D7; 2 since there are 4 populations in the recurrent network and 2 populations in the external population. The recurrent mean-field connectivity matrix is
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn37.gif"/></alternatives></disp-formula>
where
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn38.gif"/></alternatives></disp-formula>
is the 2 &#x00D7; 2 recurrent connectivity matrix for the 3-population network. Note that <italic>W</italic> is 4 &#x00D7; 4. Here, <italic>w<sub>ab</sub></italic> &#x003D; <italic>p<sub>ab</sub>j<sub>ab</sub>q<sub>b</sub>&#x03B7;&#x0303;<sub>b</sub></italic> are the same values used above for analyzing the 3-population network.</p>
<p>Even though <italic>W</italic> is non-invertible, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline79.gif"/></alternatives></inline-formula> is in the range of <italic>W</italic> for this example, so firing rates in the balanced state can be computed using <xref ref-type="disp-formula" rid="eqn20">Eq. (20)</xref>, and are identical to the firing rates for the 3-population networks considered above.</p>
<p>The nullspace of <italic>W<sup>&#x002A;</sup></italic> is spanned by the orthonormal vectors
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn39.gif"/></alternatives></disp-formula>
and
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn40.gif"/></alternatives></disp-formula>
so the projection matrix is given in block form by
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn41.gif"/></alternatives></disp-formula>
where <italic>I</italic><sub>2</sub> is the 2 &#x00D7; 2 identity matrix.</p>
<p>The external input CSD is determined by the average number of overlapping feedforward projections to any pair of neurons in the recurrent network (multiplied by their connection strength and <italic>r<sub>x</sub></italic>), which gives (in block form)
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn42.gif"/></alternatives></disp-formula>
where <bold>0</bold> is the 2 2 zero matrix and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline80.gif"/></alternatives></inline-formula> is the external input CSD from the 3-population network, given by <xref ref-type="disp-formula" rid="eqn5">Eq. (5)</xref>. Therefore, by <xref ref-type="disp-formula" rid="eqn23">Eq. (23)</xref>,
<disp-formula id="eqn24">
<alternatives><graphic xlink:href="372607_eqn24.gif"/></alternatives></disp-formula></p>
<p>In other words, the mean total input CSD between excitatory neurons in the same subgroup (two neurons in <italic>e</italic><sub>1</sub> or two neurons in <italic>e</italic><sub>2</sub>; diagonal blocks above) is positive and equal to half the mean external input between the same neurons. Hence, the cancellation by the recurrent network only reduces the external input CSD by a factor of 1/2, as opposed to the <italic>&#x1D4AA;</italic>(1<italic>/N</italic>) reduction realized in the asynchronous state (when <italic>W</italic> is invertible). In contrast, the mean total input CSD between excitatory neurons in opposite subgroups (one neuron in <italic>e</italic><sub>1</sub> and the other in <italic>e</italic><sub>2</sub>; off-diagonal blocks above) has the same magnitude as for same-subgroup pairs, but is negative. This represents a competitive dynamic between the two groups since they inhibit one another (recurrent connections are net-inhibitory in balanced networks [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c42">42</xref>]), but receive different feedforward input noise. Interestingly, the average CSD between all pairs of spike trains is still <italic>&#x1D4AA;</italic>(1<italic>/N</italic>) in this example, but it is easy to design examples with singular <italic>W</italic> in which this is not true. A similar example was considered in previous work [<xref ref-type="bibr" rid="c38">38</xref>], but external input was generated artificially instead of coming from an external population.</p>
<p>Simulating this network for varying values of <italic>N</italic> shows that firing rates approach those predicted by the balance equation (20) (<xref ref-type="fig" rid="fig6">Fig. 6B</xref>), confirming that balance is realized. Pairs of excitatory neurons in the same group (both neurons in <italic>e</italic><sub>1</sub> or both neurons in <italic>e</italic><sub>2</sub>) receive positively correlated external input and recurrent input (<xref ref-type="fig" rid="fig6">Fig. 6C</xref>, purple and green curves) that are partially canceled by negative correlations between their recurrent and excitatory input (<xref ref-type="fig" rid="fig6">Fig. 6C</xref>, yellow curve). Because the cancellation is only partial, the correlation between the neurons&#x2019; total inputs is <italic>&#x1D4AA;</italic>(1) (<xref ref-type="fig" rid="fig6">Fig. 6C</xref>, black curve) in contrast to the asynchronous state (compare to <xref ref-type="fig" rid="fig1">Fig. 1G,H</xref> where cancellation is perfect at large <italic>N</italic>). The total input covariance agrees well with the theoretical prediction from <xref ref-type="disp-formula" rid="eqn24">Eq. (24)</xref> (<xref ref-type="fig" rid="fig6">Fig. 6C</xref>, dashed gray line). As a result of this lack of cancellation between total input covariance, spike count covariances are also <italic>&#x1D4AA;</italic>(1) and positive between same-group pairs (<xref ref-type="fig" rid="fig6">Fig. 6D</xref>). For opposite group pairs (one neuron in <italic>e</italic><sub>1</sub> and the other in <italic>e</italic><sub>2</sub>), cancellation is also imperfect, but this leads to negative total input covariance, in agreement with the theoretical prediction from <xref ref-type="disp-formula" rid="eqn24">Eq. (24)</xref> (<xref ref-type="fig" rid="fig6">Fig. 6E</xref>), and leads to negative spike count covariances between neurons in opposite populations (<xref ref-type="fig" rid="fig6">Fig. 6F</xref>).</p>
<p>In summary, we have analyzed two mechanisms to generate <italic>&#x1D4AA;</italic>(1) spike train correlations in balanced networks. For the first mechanism (<xref ref-type="fig" rid="fig2">Fig. 2</xref>), spike trains in the external population are correlated so that external input correlations are <italic>&#x1D4AA;</italic>(<italic>N</italic>). Cancellation is achieved so that spike train correlations are reduced to <italic>&#x1D4AA;</italic>(1). For the other mechanism (<xref ref-type="fig" rid="fig6">Fig. 6</xref>), external input correlation is <italic>&#x1D4AA;</italic>(1), but precise cancellation cannot be achieved so that spike trains inherit the <italic>&#x1D4AA;</italic>(1) correlations from the input. How could these two mechanisms be distinguished in cortical recordings? Under the first mechanism, we showed that fluctuations of inhibitory input to individual neurons closely tracks fluctuations of other neurons&#x2019; excitatory inputs (<xref ref-type="fig" rid="fig3">Fig. 3C</xref>). This should not be the case under the second mechanism because precise cancellation is not realized. Indeed, plotting the excitatory and inhibitory input to three excitatory neurons (two in <italic>e</italic><sub>1</sub> and one in <italic>e</italic><sub>2</sub>) shows that input fluctuations are not closely tracked (<xref ref-type="fig" rid="fig7">Fig. 7</xref>). This provides a way to distinguish the two mechanisms from paired intracellular recordings. Indeed, the first mechanism (which we refer to as the &#x201C;correlated state&#x201D;) appears more consistent with the cortical recordings considered here (compare <xref ref-type="fig" rid="fig3">Fig. 3A</xref> to <xref ref-type="fig" rid="fig3">Figs. 3C</xref> and <xref ref-type="fig" rid="fig7">7</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Fig 7.</label>
<caption><title>Synaptic input currents in a balanced network with correlations from singular mean-field connectivity.</title>
<p>Same as <xref ref-type="fig" rid="fig3">Fig. 3A</xref> except for the network from <xref ref-type="fig" rid="fig6">Fig. 6</xref>. The left two traces are input currents to two excitatory neurons in population <italic>e</italic><sub>1</sub> (cells 1 and 2). The right traces are input currents to an excitatory neuron in population <italic>e</italic><sub>2</sub> (cell 3).</p></caption>
<graphic xlink:href="372607_fig7.tif"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We analyzed correlated variability in recurrent, balanced networks of integrate-and-fire neurons receiving correlated feedforward input from an external population. We showed that correlations between spike trains in the recurrent network are small (<italic>&#x1D4AA;</italic> (1<italic>/N</italic>)) when spike trains in the external population are uncorrelated, consistent with previous work on the asynchronous state [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c38">38</xref>], but much larger (<italic>&#x1D4AA;</italic>(1)) when spike trains in the external population are correlated, giving rise to a &#x201C;correlated state.&#x201D; In both states, strong correlations in the feedforward input are canceled by recurrent synaptic input due to the excitatory-inhibitory tracking that arises naturally in densely connected balanced networks. This cancellation allows for the derivation of a concise and accurate closed form expression for spike train CSDs in terms of synaptic parameters alone. Hence correlations in balanced networks are determined predominately by synaptic connectivity structure, not neuronal dynamics. The tracking of excitatory synaptic input by inhibition was observable on a pair-by-pair basis in the correlated state, but not the asynchronous state, suggesting that the correlated state is more consistent with in vivo recordings.</p>
<p>We only considered recurrent networks with two, statistically homogeneous neural populations: one excitatory and one inhibitory. Our analysis can be extended to multiple subpopulations as long as each sub-population contains <italic>&#x1D4AA;</italic>(<italic>N</italic>) neurons, and also extends to networks with connection probabilities that depend on distance, orientation tuning, or other continuous quantities. This analysis has been developed for the asynchronous state in previous work [<xref ref-type="bibr" rid="c38">38</xref>] and is easily extended to the correlated state as well. The primary difference is that <inline-formula><alternatives><inline-graphic xlink:href="372607_inline81.gif"/></alternatives></inline-formula> is <italic>&#x1D4AA;</italic>(<italic>N</italic>) instead of <italic>&#x1D4AA;</italic>(1).</p>
<p>Previous work has shown that networks with multiple sub-populations and networks with distance-dependent connectivity can break the asynchronous state in balanced networks when the network connectivity structure is constructed in such a way that the recurrent network cannot achieve the cancellation required for the asynchronous state [<xref ref-type="bibr" rid="c37">37</xref>&#x2013;<xref ref-type="bibr" rid="c39">39</xref>], leading to <italic>&#x1D4AA;</italic>(1) correlations between some cell pairs. We showed that the precise tracking of excitation by inhibition provides an experimentally testable prediction for distinguishing this mechanism from the one underlying the correlated state (see <xref ref-type="fig" rid="fig7">Fig. 7</xref> and surrounding discussion).</p>
<p>Another alternative mechanism for achieving larger correlations in balanced networks is through instabilities of the balanced state. Such instabilities, especially in spatially extended networks, can create pattern-forming dynamics that produce correlated spiking without hypersynchrony [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c52">52</xref>&#x2013;<xref ref-type="bibr" rid="c57">57</xref>]. Future studies should work towards experimentally testable predictions that distinguish correlations that arise from instabilities from those that arise through the mechanisms considered here. For example, since instabilities generate correlations internally, they should produce weak correlations between activity in the recurrent network and activity in the external population(s) providing input to that network [<xref ref-type="bibr" rid="c57">57</xref>], in contrast to the mechanisms we consider here. Indeed, some recordings show that local circuit connectivity can increase correlations [<xref ref-type="bibr" rid="c58">58</xref>], which is consistent with internally generated correlations, but inconsistent with the mechanisms that we consider here.</p>
<p>In the correlated state, spike train correlations in the recurrent network are essentially inherited from correlations between spike trains in the external population. Hence, the <italic>&#x1D4AA;</italic>(1) correlations realized by this mechanism require the presence of another local network with <italic>&#x1D4AA;</italic>(1) correlations. This raises the question of where the <italic>&#x1D4AA;</italic>(1) correlations are originally generated. One possibility is that they could be generated in a presynaptic cortical area or layer through the alternative mechanisms discussed in the previous paragraph. Another possibility is that they originate from a network that is not in the balanced state at all. Non-balanced networks can easily achieve <italic>&#x1D4AA;</italic>(1) spike train correlations simply from overlapping synaptic projections. While cortical circuits are commonly believed to operate in a balanced state, correlations could originate in thalamus, retina, or other sub-cortical neural populations then eventually propagate to cortex.</p>
<p>The cancellation between variances of covariances observed empirically in <xref ref-type="fig" rid="fig4">Fig. 4F</xref> is, to our knowledge, a novel observation, but we were unable to derive it analytically. Path integral approaches have recently been applied to compute variances of covariances in linear network models with uncorrelated external input [<xref ref-type="bibr" rid="c59">59</xref>] <inline-formula><alternatives><inline-graphic xlink:href="372607_inline82.gif"/></alternatives></inline-formula>, and could potentially be extended to the networks considered here. This previous work derives a simple relationship between a network&#x2019;s criticality and a parameter, &#x0394;, that represents the ratio between the variance of covariances and the mean spike count variance. Specifically, they showed that in their networks, the eigenvalue spectrum of the network dynamics is given to leading order in <italic>N</italic> by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline83.gif"/></alternatives></inline-formula>. In our model, where external input is correlated, the variance of covariances and spike count variances both appear to be <italic>&#x1D4AA;</italic>(1), so that &#x0394; &#x007E; <italic>&#x1D4AA;</italic>(1) and their expression for <italic>&#x03BB;<sub>max</sub></italic> would tend to zero regardless of the network&#x2019;s dynamical state. We interpret this to imply that their expression is not accurate for networks with correlated external input. Future work should consider the possibility of extending their analysis of criticality to such networks.</p>
<p>Our mean-field analysis applies to networks of integrate-and-fire neuron models, which are arguably more biologically realistic than networks of binary model neurons that are often used for mean-field analysis of neuronal networks. Binary neuron networks are appealing due to the mathematical tractability of their mean-field analysis, but our work demonstrates that integrate-and-fire networks are similarly tractable, calling into question the utility and appeal of binary network models.</p>
<p>Two unproven assumptions underly our mean-field analysis of the correlated state.</p>
<p>The first assumption is that neural transfer is <italic>&#x1D4AA;</italic>(1) (<xref ref-type="disp-formula" rid="eqn8">Eq. (8)</xref> and surrounding discussion). The second assumption is that individual connection strengths are not strongly correlated with individual CSD values so that the step from <xref ref-type="disp-formula" rid="eqn26">Eq. (26)</xref> to (27) is valid when ignoring smaller order terms. These assumptions are made in other work, even if not stated explicitly. We have been unable to prove these assumptions rigorously for the model studied here, leaving an open problem for future work.</p>
<p>We showed that linear approximations to spike train covariance developed for small, sparsely coupled networks [<xref ref-type="bibr" rid="c10">10</xref>&#x2013;<xref ref-type="bibr" rid="c12">12</xref>] can also be accurate for large, densely connected balanced networks (<xref ref-type="fig" rid="fig5">Fig. 5</xref>). However, their usefulness is limited by the need to invert large, ill-conditioned matrices and to approximate the susceptibility functions of individual neurons. The simpler equations we derived for mean-field spike train CSDs (<xref ref-type="disp-formula" rid="eqn7">Eqs. (7)</xref> and <xref ref-type="disp-formula" rid="eqn14">(14)</xref>) do not have these problems. Moreover, while linear response approximations require that neural transfer of input is approximately linear, our mean-field derivations did not depend on this assumption. Recent work has called for looking beyond linear analysis of neuronal networks [<xref ref-type="bibr" rid="c60">60</xref>]. Our analysis shows that, even in networks where neural transfer of inputs is nonlinear, linear mean-field analysis could still be accurate and useful.</p>
<p>In summary, we showed that correlations in balanced networks can be caused by feedforward input from a population of neurons with correlated spike trains, defining the &#x201C;correlated state&#x201D; that is quantitatively captured by a linear mean-field theory. In contrast to other mechanisms of correlation in balanced networks, the correlated state predicts a precise balance between the fluctuations in excitatory and inhibitory synaptic input to individual neuron pairs, consistent with some in vivo recordings [<xref ref-type="bibr" rid="c22">22</xref>].</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Details for the derivation of mean-field CSDs</title>
<p>We now provide details in the derivations of <xref ref-type="disp-formula" rid="eqn6">Eqs. (6)</xref> and <xref ref-type="disp-formula" rid="eqn14">(14)</xref>, which can both be written as
<disp-formula id="eqn25">
<alternatives><graphic xlink:href="372607_eqn25.gif"/></alternatives></disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="372607_inline84.gif"/></alternatives></inline-formula> scales smaller than <inline-formula><alternatives><inline-graphic xlink:href="372607_inline85.gif"/></alternatives></inline-formula> as <italic>N</italic> &#x2192; <italic>&#x221E;</italic> and where <italic>C</italic><sub>0</sub> &#x007E; <italic>&#x1D4AA;</italic>(1). Note that in the correlated state, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline86.gif"/></alternatives></inline-formula> so that the <italic>C</italic><sub>0</sub>/<italic>N</italic> term can be absorbed into the <inline-formula><alternatives><inline-graphic xlink:href="372607_inline87.gif"/></alternatives></inline-formula> term. A sketch of the derivation for the correlated state is given in Results, and the derivation is similar in the asynchronous state. Here, we give the details of this derivation.</p>
<p>We first derive <xref ref-type="disp-formula" rid="eqn5">Eq. (5)</xref> for <inline-formula><alternatives><inline-graphic xlink:href="372607_inline88.gif"/></alternatives></inline-formula> in the asynchronous state, <italic>i.e.</italic> when spike trains in the external population are uncorrelated Poisson processes, so <inline-formula><alternatives><inline-graphic xlink:href="372607_inline89.gif"/></alternatives></inline-formula>. In that case, the CSD between two neurons&#x2019; external input is given by
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn43.gif"/></alternatives></disp-formula>
for <italic>a</italic>, <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic> where we have used the fact that the cross-spectral operator, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline90.gif"/></alternatives></inline-formula> is a Hermitian operator. Since external spike trains are uncorrelated Poisson processes, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline91.gif"/></alternatives></inline-formula> when <italic>m</italic> &#x2260; <italic>n</italic> and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline92.gif"/></alternatives></inline-formula>. Therefore, we can rewrite the equation above as
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn44.gif"/></alternatives></disp-formula></p>
<p>From <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>, the expectation of the summand in this equation is
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn45.gif"/></alternatives></disp-formula></p>
<p>Hence, taking expectations across the <italic>N<sub>x</sub></italic> elements of the sum and the coefficient in front of the sum gives
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn46.gif"/></alternatives></disp-formula>
which, in matrix form, is equivalent to <xref ref-type="disp-formula" rid="eqn5">Eq. (5)</xref>.</p>
<p>We next derive <xref ref-type="disp-formula" rid="eqn10">Eq. (10)</xref>. Noting that recurrent input to neuron <italic>j</italic> in population <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic> is composed of excitatory and inhibitory components, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline93.gif"/></alternatives></inline-formula>, we have
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn47.gif"/></alternatives></disp-formula>
where we can compute
<disp-formula id="eqn26">
<alternatives><graphic xlink:href="372607_eqn26.gif"/></alternatives></disp-formula>
<disp-formula id="eqn27">
<alternatives><graphic xlink:href="372607_eqn27.gif"/></alternatives></disp-formula>
<disp-formula id="eqn28">
<alternatives><graphic xlink:href="372607_eqn28.gif"/></alternatives></disp-formula></p>
<p>Taking expectation over <italic>j</italic> and <italic>k</italic> as above gives
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn48.gif"/></alternatives></disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="372607_inline94.gif"/></alternatives></inline-formula> accounts for the diagonal terms not counted in the definition of <inline-formula><alternatives><inline-graphic xlink:href="372607_inline95.gif"/></alternatives></inline-formula>. Note that this step requires us to assume that individual values of the random variable, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline96.gif"/></alternatives></inline-formula>, are not strongly correlated with individual values of <inline-formula><alternatives><inline-graphic xlink:href="372607_inline97.gif"/></alternatives></inline-formula>, so that the expectation of their product can be replaced by the product of their expectations. This assumption is implicit in derivations in other studies [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c59">59</xref>], even though it is never proven and often not made explicit.</p>
<p>Rpeating this calculation for <inline-formula><alternatives><inline-graphic xlink:href="372607_inline98.gif"/></alternatives></inline-formula> and putting them together gives the average
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn49.gif"/></alternatives></disp-formula></p>
<p>In matrix form, this becomes
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn50.gif"/></alternatives></disp-formula></p>
<p>An identical calculation, replacing <bold><italic>R</italic></bold> with <bold><italic>X</italic></bold> and <bold><italic>S</italic></bold> with <italic>S<sub>x</sub></italic>, gives
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn51.gif"/></alternatives></disp-formula></p>
<p>For the correction terms, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline99.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="372607_inline100.gif"/></alternatives></inline-formula>, to contribute at largest order in <italic>N</italic>, it needs to be true that
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn52.gif"/></alternatives></disp-formula>
for <italic>c</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, or <italic>x</italic>. In the correlated state, this is never the case, so the correction term can be ignored, giving <xref ref-type="disp-formula" rid="eqn10">Eqs. (10)</xref> and <xref ref-type="disp-formula" rid="eqn11">(11)</xref>. In the asynchronous state, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline101.gif"/></alternatives></inline-formula> since spike train power spectral densities are <italic>&#x1D4AA;</italic>(1) due to intrinsically generated variability, but <inline-formula><alternatives><inline-graphic xlink:href="372607_inline102.gif"/></alternatives></inline-formula>. This causes the power spectral densities, <italic>i.e.</italic> auto-correlations, to contribute to correlated variability in the network at the largest order in <italic>N</italic> and ultimately leads to the presence of the <italic>C</italic><sub>0</sub> term in <xref ref-type="disp-formula" rid="eqn6">Eq. (6)</xref> where (1/<italic>N</italic>)<italic>C</italic><sub>0</sub> represents mean-field CSDs that would be obtained in the absence of external input correlations, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline103.gif"/></alternatives></inline-formula> (see other work [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c44">44</xref>] for an in-depth treatment of intrinsically generated correlations).</p>
</sec>
<sec id="s4b">
<title>Derivation of linear response approximation to pairwise spike train CSDs</title>
<p>We next give a derivation of <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> from <xref ref-type="disp-formula" rid="eqn16">Eqs. (16)</xref> and <xref ref-type="disp-formula" rid="eqn17">(17)</xref>. Similar derivations have previously been given for integrate-and-fire networks [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>] and other models [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c61">61</xref>]. First compute
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn53.gif"/></alternatives></disp-formula>
from <xref ref-type="disp-formula" rid="eqn16">Eqs. (16)</xref> and <xref ref-type="disp-formula" rid="eqn17">(17)</xref>. This can be solved for
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn54.gif"/></alternatives></disp-formula></p>
<p>Similarly, compute
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn55.gif"/></alternatives></disp-formula>
which can be solved to obtain
<disp-formula>
<alternatives><graphic xlink:href="372607_ueqn56.gif"/></alternatives></disp-formula></p>
<p>Finally, making the substitution <inline-formula><alternatives><inline-graphic xlink:href="372607_inline104.gif"/></alternatives></inline-formula>, which follows from <xref ref-type="disp-formula" rid="eqn17">Eqs. (17)</xref>, gives <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref>.</p>
</sec>
<sec id="s4c">
<title>Generation of correlated spike trains for external inputs</title>
<p>To generate correlated, Poisson spike trains for the external population in the correlated state we used the multiple interaction process (MIP) method [<xref ref-type="bibr" rid="c62">62</xref>] with jittering. Specifically, we generated one shared &#x201C;mother&#x201D; process with firing rate <italic>r<sub>m</sub></italic> &#x003D; <italic>r<sub>x</sub>/c</italic>. Then, for each of the <italic>N<sub>x</sub></italic> &#x201C;daughter&#x201D; processes, we randomly kept each spike in the mother process with probability <italic>c</italic>. As a result, each daughter process is a Poisson process with firing rate <italic>cr<sub>m</sub></italic> &#x003D; <italic>r<sub>x</sub></italic> and a proportion of <italic>c</italic> of the spikes are shared between any two daughter processes. To get rid of perfect synchrony between the daughter processes, we jittered each spike time in each daughter process by a normally distributed random variable with mean zero and standard deviation <italic>&#x03C4;<sub>c</sub></italic> &#x003D; 5ms. Upon jittering, the daughter processes remain Poisson and the resulting CSD between daughter processes is given by <xref ref-type="disp-formula" rid="eqn15">Eq. (15)</xref>. Spike count correlations between the daughter processes over large time windows are exactly <italic>c</italic>. The daughter processes were used as the spike trains, <inline-formula><alternatives><inline-graphic xlink:href="372607_inline105.gif"/></alternatives></inline-formula> in the external population in the correlated state. See [<xref ref-type="bibr" rid="c62">62</xref>] for a deeper analysis of this algorithm.</p>
</sec>
<sec id="s4d">
<title>Parameters for simulations</title>
<p>All connection probabilities were <italic>p<sub>ab</sub></italic> &#x003D; 0.1 for <italic>a</italic> &#x003D; <italic>e</italic>, <italic>i</italic> and <italic>b</italic> &#x003D; <italic>e</italic>, <italic>i</italic>, <italic>x</italic>. Synaptic timescales were <italic>&#x03C4;<sub>e</sub></italic> &#x003D; 8ms, <italic>&#x03C4;<sub>i</sub></italic> &#x003D; 4ms, and <italic>&#x03C4;<sub>x</sub></italic> &#x003D; 10ms. The firing rate of the external population was <italic>r<sub>x</sub></italic> &#x003D; 10Hz and, in the correlated state, the correlation was <italic>c</italic> &#x003D; 0.1 with a jitter of <italic>&#x03C4;<sub>c</sub></italic> &#x003D; 5ms. All covariances and correlations were computed by counting spikes or integrating continuous processes over a window of length 250ms. Membrane capacitance, <italic>C<sub>m</sub></italic>, is arbitrary so we report all current-based parameters in relation to <italic>C<sub>m</sub></italic>. For convenience, one can therefore set <italic>C<sub>m</sub></italic> &#x003D; 1. Unscaled connection strengths were <italic>j<sub>ee</sub>/C<sub>m</sub></italic> &#x003D; 25mV, <italic>j<sub>ei</sub>/C<sub>m</sub></italic> &#x003D; <italic>&#x2212;</italic>150mV, <italic>j<sub>ie</sub>/C<sub>m</sub></italic> &#x003D; 112.5mV, <italic>j<sub>ii</sub>/C<sub>m</sub> &#x003D; &#x2212;</italic>250mV, <italic>j<sub>ex</sub>/C<sub>m</sub></italic> &#x003D; 180mV, and <italic>j<sub>ix</sub>C<sub>m</sub></italic> &#x003D; 135mV. Note that <italic>j<sub>ab</sub></italic> was scaled by <inline-formula><alternatives><inline-graphic xlink:href="372607_inline106.gif"/></alternatives></inline-formula> to produce the true connection strengths, as indicated in Results. Neuron parameters are <italic>g<sub>L</sub></italic> &#x003D; <italic>C<sub>m</sub>/</italic>15, <italic>E<sub>L</sub></italic> &#x003D; <italic>&#x2212;</italic>72mV, <italic>V<sub>th</sub></italic> &#x003D; <italic>&#x2212;</italic>50mV, <italic>V<sub>re</sub></italic> &#x003D; <italic>&#x2212;</italic>75mV, <italic>V<sub>lb</sub></italic> &#x003D; <italic>&#x2212;</italic>100mV, &#x2206;<sub><italic>T</italic></sub> &#x003D; 1mV, and <italic>V<sub>T</sub></italic> &#x003D; &#x2013;55mV. Synaptic currents in figures are reported in units <italic>C<sub>m</sub>V/s</italic>. Covariances between synaptic currents are computed between integrals of the currents (see <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref> and surrounding discussion), so the covariances have units <inline-formula><alternatives><inline-graphic xlink:href="372607_inline107.gif"/></alternatives></inline-formula>.</p>
</sec>
<sec id="s4e">
<title>Details of computer simulations</title>
<p>All simulations and numerical computations were performed on a MacBook Pro running OS X 10.9.5 with a 2.3 GHz Intel Core i7 processor. All simulations were written in Matlab (Matlab R 2018a, MathWorks). The differential equations defining the neuron model were solved using a forward Euler method with time step 0.1ms. Statistics in <xref ref-type="fig" rid="fig1">Figs. 1D</xref>, <xref ref-type="fig" rid="fig2">2C,D</xref>, and <xref ref-type="fig" rid="fig4">4C,D</xref> were computed from a simulation of duration 50s. Statistics in <xref ref-type="fig" rid="fig1">Figs. 1E-I</xref>, <xref ref-type="fig" rid="fig2">2E&#x2013;I</xref>, and <xref ref-type="fig" rid="fig4">4A,B,E,F</xref> were computed by repeating a simulation of duration 50s over ten trials for each value of <italic>N</italic>, then averaging over trials. For each trial, network connectivity was generated with a different random seed, so the statistics are averaged over time and over realizations of the &#x201C;quenched&#x201D; variability of network connectivity. Statistics in <xref ref-type="fig" rid="fig5">Fig. 5</xref> were computed by repeating a simulation of duration 100s for 50 trials, with network connectivity the same for each trial. Statistics were then averaged over trials. Gains were estimated by fitting a rectified quadratic function to the relationship between all neurons&#x2019; firing rates and mean total inputs (<italic>r<sub>j</sub></italic> and <italic>T&#x0304;<sub>j</sub></italic>), then computing the derivative of the fitted quadratic at the input value for each neuron. The same approach was used in previous work [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c51">51</xref>] to estimate a mean-field gain. Matlab files to produce all figures are available from the XXX database (accession number(s) XXX, XXX).</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank Michael S. Okun for helpful comments on a draft of the manuscript and for his contribution to collecting the data used in <xref ref-type="fig" rid="fig3">Fig. 3A</xref>. RR was supported by National Science Foundation (<ext-link ext-link-type="uri" xlink:href="https://www.nsf.gov/">https://www.nsf.gov/</ext-link>) grant numbers DMS-1517828, DMS-1654268, and DBI-1707400. IL was supported by Deutsche Forschungsgemeinschaft Sonderforschungsbereiche (<ext-link ext-link-type="uri" xlink:href="http://www.dfg.de/sfb">www.dfg.de/sfb</ext-link>) grant number 1089, Israel Science Foundation (<ext-link ext-link-type="uri" xlink:href="https://www.isf.org.il/">https://www.isf.org.il/</ext-link>) grant numbers 326/07 and 1539/17, and Minerva (<ext-link ext-link-type="uri" xlink:href="http://www.minerva.mpg.de/weizmann/">http://www.minerva.mpg.de/weizmann/</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Renart</surname> <given-names>A</given-names></string-name>, <string-name><surname>Parga</surname> <given-names>N</given-names></string-name>. <article-title>Theory of input spike auto-and cross-correlations and their effect on the response of spiking neurons</article-title>. <source>Neural computation</source>. <year>2008</year>;<volume>20</volume>(<issue>7</issue>):<fpage>1651</fpage>&#x2013;<lpage>1705</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>, <string-name><surname>Beck</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE</given-names></string-name>. <article-title>Probabilistic brains: knowns and unknowns</article-title>. <source>Nature neuroscience</source>. <year>2013</year>;<volume>16</volume>(<issue>9</issue>):<fpage>1170</fpage>&#x2013;<lpage>1178</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Shamir</surname> <given-names>M</given-names></string-name>. <article-title>Emerging principles of population coding: in search for the neural code</article-title>. <source>Current opinion in neurobiology</source>. <year>2014</year>;<volume>25</volume>:<fpage>140</fpage>&#x2013;<lpage>148</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Tetzlaff</surname> <given-names>T</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S</given-names></string-name>, <string-name><surname>Stark</surname> <given-names>E</given-names></string-name>, <string-name><surname>Abeles</surname> <given-names>M</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>. <article-title>Dependence of neuronal correlations on filter characteristics and marginal spike train statistics</article-title>. <source>Neural Comput</source>. <year>2008</year>;<volume>20</volume>(<issue>9</issue>):<fpage>2133</fpage>&#x2013;<lpage>84</lpage>. doi:<pub-id pub-id-type="doi">101162/neco200805-07-525</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Tetzlaff</surname> <given-names>T</given-names></string-name>, <string-name><surname>Helias</surname> <given-names>M</given-names></string-name>, <string-name><surname>Einevoll</surname> <given-names>GT</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>. <article-title>Decorrelation of neural-network activity by inhibitory feedback</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>8</issue>):<fpage>e1002596</fpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>, <string-name><surname>Litwin-Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ocker</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Josi&#x0107;</surname> <given-names>K</given-names></string-name>. <article-title>The mechanics of state-dependent neural correlations</article-title>. <source>Nature Neuroscience</source>. <year>2016</year>;<volume>19</volume>(<issue>3</issue>):<fpage>383</fpage>&#x2013;<lpage>393</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Ocker</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Buice</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>, <string-name><surname>Josi&#x0107;</surname> <given-names>K</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <article-title>From the statistics of connectivity to the statistics of spike times in neuronal networks</article-title>. <source>Current opinion in neurobiology</source>. <year>2017</year>;<volume>46</volume>:<fpage>109</fpage>&#x2013;<lpage>119</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Lindner</surname> <given-names>B</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>, <string-name><surname>Longtin</surname> <given-names>A</given-names></string-name>. <article-title>Theory of oscillatory firing induced by spatially correlated noise and delayed inhibitory feedback</article-title>. <source>Phys Rev E</source>. <year>2005</year>;<volume>72</volume>(<issue>6</issue>):<fpage>061919</fpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Ostojic</surname> <given-names>S</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hakim</surname> <given-names>V</given-names></string-name>. <article-title>How connectivity, background activity, and synaptic properties shape the cross-correlation between spike trains</article-title>. <source>Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>33</issue>):<fpage>10234</fpage>&#x2013;<lpage>10253</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Pernice</surname> <given-names>V</given-names></string-name>, <string-name><surname>Staude</surname> <given-names>B</given-names></string-name>, <string-name><surname>Cardanobile</surname> <given-names>S</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S</given-names></string-name>. <article-title>How structure determines correlations in neuronal networks</article-title>. <source>PLoS Comput Biol</source>. <year>2011</year>;<volume>7</volume>(<issue>5</issue>):<fpage>e1002059</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1002059</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Trousdale</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shea-Brown</surname> <given-names>E</given-names></string-name>, <string-name><surname>Josi&#x0107;</surname> <given-names>K</given-names></string-name>. <article-title>Impact of network structure and cellular response on spike time correlations</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>3</issue>):<fpage>e1002408</fpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Hu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Trousdale</surname> <given-names>J</given-names></string-name>, <string-name><surname>Josi&#x0107;</surname> <given-names>K</given-names></string-name>, <string-name><surname>Shea-Brown</surname> <given-names>E</given-names></string-name>. <article-title>Motif statistics and spike correlations in neuronal networks</article-title>. <source>J Stat Mech</source>. <year>2013</year>;<volume>2013</volume>(<issue>03</issue>):<fpage>P03012</fpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Grytskyy</surname> <given-names>D</given-names></string-name>, <string-name><surname>Tetzlaff</surname> <given-names>T</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>, <string-name><surname>Helias</surname> <given-names>M</given-names></string-name>. <article-title>A unified view on weakly correlated recurrent networks</article-title>. <source>Front Comput Neurosci</source>. <year>2013</year>;<volume>7</volume>(<issue>October</issue>):<fpage>131</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fncom.2013.00131</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Dummer</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wieland</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lindner</surname> <given-names>B</given-names></string-name>. <article-title>Self-consistent determination of the spike-train power spectrum in a neural network with sparse connectivity</article-title>. <source>Frontiers in computational neuroscience</source>. <year>2014</year>;<volume>8</volume>:<fpage>104</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Ko</surname> <given-names>H</given-names></string-name>, <string-name><surname>Hofer</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Pichler</surname> <given-names>B</given-names></string-name>, <string-name><surname>Buchanan</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Sj&#x00F6;str&#x00F6;m</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></string-name>. <article-title>Functional specificity of local synaptic connections in neocortical networks</article-title>. <source>Nature</source>. <year>2011</year>;<volume>473</volume>(<issue>7345</issue>):<fpage>87</fpage>&#x2013;<lpage>91</lpage>. doi:<pub-id pub-id-type="doi">101038/nature09880</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Fino</surname> <given-names>E</given-names></string-name>, <string-name><surname>Yuste</surname> <given-names>R</given-names></string-name>. <article-title>Dense inhibitory connectivity in neocortex</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>69</volume>(<issue>6</issue>):<fpage>1188</fpage>&#x2013;<lpage>1203</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Levy</surname> <given-names>RB</given-names></string-name>, <string-name><surname>Reyes</surname> <given-names>AD</given-names></string-name>. <article-title>Spatial profile of excitatory and inhibitory synaptic connectivity in mouse primary auditory cortex</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>(<issue>16</issue>):<fpage>5609</fpage>&#x2013;<lpage>5619</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Oswald</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>, <string-name><surname>Rinzel</surname> <given-names>J</given-names></string-name>, <string-name><surname>Reyes</surname> <given-names>AD</given-names></string-name>. <article-title>Spatial profile and differential recruitment of GABAB modulate oscillatory activity in auditory cortex</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>(<issue>33</issue>):<fpage>10321</fpage>&#x2013;<lpage>10334</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Shu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hasenstaub</surname> <given-names>A</given-names></string-name>, <string-name><surname>McCormick</surname> <given-names>DA</given-names></string-name>. <article-title>Turning on and off recurrent balanced cortical activity</article-title>. <source>Nature</source>. <year>2003</year>;<volume>423</volume>(<issue>6937</issue>):<fpage>288</fpage>&#x2013;<lpage>293</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Wehr</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zador</surname> <given-names>AM</given-names></string-name>. <article-title>Balanced inhibition underlies tuning and sharpens spike timing in auditory cortex</article-title>. <source>Nature</source>. <year>2003</year>;<volume>426</volume>(<issue>6965</issue>):<fpage>442</fpage>&#x2013;<lpage>446</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Haider</surname> <given-names>B</given-names></string-name>, <string-name><surname>Duque</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hasenstaub</surname> <given-names>AR</given-names></string-name>, <string-name><surname>McCormick</surname> <given-names>DA</given-names></string-name>. <article-title>Neocortical network activity in vivo is generated through a dynamic balance of excitation and inhibition</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>(<issue>17</issue>):<fpage>4535</fpage>&#x2013;<lpage>4545</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Okun</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lampl</surname> <given-names>I</given-names></string-name>. <article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title>. <source>Nat Neurosci</source>. <year>2008</year>;<volume>11</volume>(<issue>5</issue>):<fpage>535</fpage>&#x2013;<lpage>537</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Dorrn</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Yuan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Barker</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>. <article-title>Developmental sensory experience balances cortical excitation and inhibition</article-title>. <source>Nature</source>. <year>2010</year>;<volume>465</volume>(<issue>7300</issue>):<fpage>932</fpage>&#x2013;<lpage>936</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Sun</surname> <given-names>YJ</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Bh</given-names></string-name>, <string-name><surname>Li</surname> <given-names>P</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>M</given-names></string-name>, <string-name><surname>Xiao</surname> <given-names>Z</given-names></string-name>, <etal>et al.</etal> <article-title>Fine-tuning of pre-balanced excitation and inhibition during auditory cortical development</article-title>. <source>Nature</source>. <year>2010</year>;<volume>465</volume>(<issue>7300</issue>):<fpage>927</fpage>&#x2013;<lpage>931</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname> <given-names>M</given-names></string-name>, <string-name><surname>Liang</surname> <given-names>F</given-names></string-name>, <string-name><surname>Xiong</surname> <given-names>XR</given-names></string-name>, <string-name><surname>Li</surname> <given-names>L</given-names></string-name>, <string-name><surname>Li</surname> <given-names>H</given-names></string-name>, <string-name><surname>Xiao</surname> <given-names>Z</given-names></string-name>, <etal>et al.</etal> <article-title>Scaling down of balanced excitation and inhibition by active behavioral states in auditory cortex</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>(<issue>6</issue>):<fpage>841</fpage>&#x2013;<lpage>50</lpage>. doi:<pub-id pub-id-type="doi">101038/nn3701</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Petersen</surname> <given-names>PC</given-names></string-name>, <string-name><surname>Vestergaard</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jensen</surname> <given-names>KHR</given-names></string-name>, <string-name><surname>Berg</surname> <given-names>RW</given-names></string-name>. <article-title>Premotor spinal network with balanced excitation and inhibition during motor patterns has high resilience to structural division</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>(<issue>8</issue>):<fpage>2774</fpage>&#x2013;<lpage>84</lpage>. doi:<pub-id pub-id-type="doi">101523/JNEUROSCI3349-132014</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <article-title>Chaotic balanced state in a model of cortical circuits</article-title>. <source>Neural Comput</source>. <year>1998</year>;<volume>10</volume>(<issue>6</issue>):<fpage>1321</fpage>&#x2013;<lpage>1371</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <article-title>Chaos in neuronal networks with balanced excitatory and inhibitory activity</article-title>. <source>Science</source>. <year>1996</year>;<volume>274</volume>(<issue>5293</issue>):<fpage>1724</fpage>&#x2013;<lpage>1726</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Renart</surname> <given-names>A</given-names></string-name>, <string-name><surname>de La Rocha</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bartho</surname> <given-names>P</given-names></string-name>, <string-name><surname>Hollender</surname> <given-names>L</given-names></string-name>, <string-name><surname>Parga</surname> <given-names>N</given-names></string-name>, <string-name><surname>Reyes</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>The Asynchronous State in Cortical Circuits</article-title>. <source>Science</source>. <year>2010</year>;<volume>327</volume>(<issue>5965</issue>):<fpage>587</fpage>&#x2013;<lpage>590</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Ecker</surname> <given-names>A</given-names></string-name>, <string-name><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name><surname>Keliris</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name><surname>Logothetis</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tolias</surname> <given-names>A</given-names></string-name>. <article-title>Decorrelated Neuronal Firing in Cortical Microcircuits</article-title>. <source>Science</source>. <year>2010</year>;<volume>327</volume>(<issue>5965</issue>):<fpage>584</fpage>&#x2013;<lpage>587</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>. <article-title>Measuring and interpreting neuronal correlations</article-title>. <source>Nat Neurosci</source>. <year>2011</year>;<volume>14</volume>(<issue>7</issue>):<fpage>811</fpage>&#x2013;<lpage>819</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Smith</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Jia</surname> <given-names>X</given-names></string-name>, <string-name><surname>Zandvakili</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>. <article-title>Laminar dependence of neuronal correlations in visual cortex</article-title>. <source>J Neurophysiol</source>. <year>2013</year>;<volume>109</volume>(<issue>4</issue>):<fpage>940</fpage>&#x2013;<lpage>947</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cotton</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Subramaniyan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Denfield</surname> <given-names>GH</given-names></string-name>, <string-name><surname>Cadwell</surname> <given-names>CR</given-names></string-name>, <etal>et al.</etal> <article-title>State dependence of noise correlations in macaque primary visual cortex</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>82</volume>(<issue>1</issue>):<fpage>235</fpage>&#x2013;<lpage>248</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Tan</surname> <given-names>AY</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Scholl</surname> <given-names>B</given-names></string-name>, <string-name><surname>Seidemann</surname> <given-names>E</given-names></string-name>, <string-name><surname>Priebe</surname> <given-names>NJ</given-names></string-name>. <article-title>Sensory stimulation shifts visual cortex from synchronous to asynchronous states</article-title>. <source>Nature</source>. <year>2014</year>;<volume>509</volume>(<issue>7499</issue>):<fpage>226</fpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>McGinley</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Vinck</surname> <given-names>M</given-names></string-name>, <string-name><surname>Reimer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Batista-Brito</surname> <given-names>R</given-names></string-name>, <string-name><surname>Zagha</surname> <given-names>E</given-names></string-name>, <string-name><surname>Cadwell</surname> <given-names>CR</given-names></string-name>, <etal>et al.</etal> <article-title>Waking state: rapid variations modulate neural and behavioral responses</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>87</volume>(<issue>6</issue>):<fpage>1143</fpage>&#x2013;<lpage>1161</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Mochol</surname> <given-names>G</given-names></string-name>, <string-name><surname>Hermoso-Mendizabal</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sakata</surname> <given-names>S</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>, <string-name><surname>de la Rocha</surname> <given-names>J</given-names></string-name>. <article-title>Stochastic transitions into silence cause noise correlations in cortical circuits</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2015</year>;<volume>112</volume>(<issue>11</issue>):<fpage>201410509</fpage>. doi:<pub-id pub-id-type="doi">101073/pnas1410509112</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Wimmer</surname> <given-names>K</given-names></string-name>, <string-name><surname>Compte</surname> <given-names>A</given-names></string-name>, <string-name><surname>Roxin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Peixoto</surname> <given-names>D</given-names></string-name>, <string-name><surname>Renart</surname> <given-names>A</given-names></string-name>, <string-name><surname>de la Rocha</surname> <given-names>J</given-names></string-name>. <article-title>The dynamics of sensory integration in a hierarchical network explains choice probabilities in MT</article-title>. <source>Nat Commun</source>. <year>2015</year>;<volume>6</volume>:<fpage>1</fpage>&#x2013;<lpage>13</lpage>. doi:<pub-id pub-id-type="doi">101038/ncomms7177</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rubin</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>. <article-title>The spatial structure of correlated neuronal variability</article-title>. <source>Nature Neurosci</source>. <year>2017</year>;<volume>20</volume>(<issue>1</issue>):<fpage>107</fpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="other"><string-name><surname>Darshan</surname> <given-names>R</given-names></string-name>, <string-name><surname>van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hansel</surname> <given-names>D</given-names></string-name>. <article-title>How strong are correlations in strongly recurrent neuronal networks</article-title>? <year>2018</year>;(<issue>1</issue>):<fpage>1</fpage>&#x2013;<lpage>22</lpage>. doi:<pub-id pub-id-type="doi">10.1101/274480</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>. <article-title>Balanced networks of spiking neurons with spatially dependent recurrent connections</article-title>. <source>Phys Rev X</source>. <year>2014</year>;<volume>4</volume>(<issue>2</issue>):<fpage>021039</fpage>. doi:<pub-id pub-id-type="doi">101103/PhysRevX4021039</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Landau</surname> <given-names>ID</given-names></string-name>, <string-name><surname>Egger</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dercksen</surname> <given-names>VJ</given-names></string-name>, <string-name><surname>Oberlaender</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <article-title>The impact of structural heterogeneity on excitation-inhibition balance in cortical networks</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>92</volume>(<issue>5</issue>):<fpage>1106</fpage>&#x2013;<lpage>1121</lpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Pyle</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>. <article-title>Highly connected neurons spike less frequently in balanced networks</article-title>. <source>Phys Rev E</source>. <year>2016</year>;<volume>93</volume>(<issue>4</issue>):<fpage>040302</fpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Monteforte</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wolf</surname> <given-names>F</given-names></string-name>. <article-title>Dynamic flux tubes form reservoirs of stability in neuronal circuits</article-title>. <source>Phys Rev X</source>. <year>2012</year>;<volume>2</volume>(<issue>4</issue>):<fpage>041007</fpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Helias</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tetzlaff</surname> <given-names>T</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>. <article-title>The correlation structure of local neuronal networks intrinsically results from recurrent dynamics</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>1</issue>):<fpage>e1003428</fpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Rosenbaum</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Trousdale</surname> <given-names>J</given-names></string-name>, <string-name><surname>Josi&#x0107;</surname> <given-names>K</given-names></string-name>. <article-title>Pooling and correlated neural activity</article-title>. <source>Front Comp Neurosci</source>. <year>2010</year>;<volume>4</volume>:<fpage>1</fpage>&#x2013;<lpage>14</lpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>, <string-name><surname>Trousdale</surname> <given-names>J</given-names></string-name>, <string-name><surname>Josi&#x0107;</surname> <given-names>K</given-names></string-name>. <article-title>The effects of pooling on spike train correlations</article-title>. <source>Front Neurosci</source>. <year>2011</year>;<volume>5</volume>(<issue>58</issue>):<fpage>1</fpage>&#x2013;<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Hennequin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Agnes</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>. <article-title>Inhibitory Plasticity: Balance, Control, and Codependence</article-title>. <source>Annu Rev Neurosci</source>. <year>2017</year>;<volume>40</volume>(<issue>1</issue>):<fpage>557</fpage>&#x2013;<lpage>579</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031005</pub-id>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="book"><string-name><surname>Risken</surname> <given-names>H</given-names></string-name>. <chapter-title>Fokker-planck equation</chapter-title>. In: <source>The Fokker-Planck Equation</source>. <publisher-name>Springer</publisher-name>; <year>1996</year>. p. <fpage>63</fpage>&#x2013;<lpage>95</lpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Lindner</surname> <given-names>B</given-names></string-name>. <article-title>Effects of noise in excitable systems</article-title>. <source>Phys Rep</source>. <year>2004</year>;<volume>392</volume>(<issue>6</issue>):<fpage>321</fpage>&#x2013;<lpage>424</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.physrep.2003.10.015</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>. <article-title>A Diffusion Approximation and Numerical Methods for Adaptive Neuron Models with Stochastic Inputs</article-title>. <source>Front Comput Neurosci</source>. <year>2016</year>;<volume>10</volume>(<issue>April</issue>):<fpage>1</fpage>&#x2013;<lpage>20</lpage>. doi:<pub-id pub-id-type="doi">10.3389/fncom.2016.00039</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Ebsch</surname> <given-names>C</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>. <article-title>Imbalanced amplification: A mechanism of amplification and suppression from local imbalance of excitation and inhibition in cortical circuits</article-title>. <source>PLoS computational biology</source>. <year>2018</year>;<volume>14</volume>(<issue>3</issue>):<fpage>e1006048</fpage>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Roxin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hansel</surname> <given-names>D</given-names></string-name>. <article-title>Role of delays in shaping spatiotemporal dynamics of neuronal activity in large networks</article-title>. <source>Physical review letters</source>. <year>2005</year>;<volume>94</volume>(<issue>23</issue>):<fpage>238103</fpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Kriener</surname> <given-names>B</given-names></string-name>, <string-name><surname>Helias</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>, <string-name><surname>Einevoll</surname> <given-names>GT</given-names></string-name>. <article-title>How pattern formation in ring networks of excitatory and inhibitory spiking neurons depends on the input current regime</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2014</year>;<volume>7</volume>(<issue>187</issue>). doi:<pub-id pub-id-type="doi">10.3389/fncom.2013.00187</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Ostojic</surname> <given-names>S</given-names></string-name>. <article-title>Two types of asynchronous activity in networks of excitatory and inhibitory spiking neurons</article-title>. <source>Nature neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>4</issue>):<fpage>594</fpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Keane</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gong</surname> <given-names>P</given-names></string-name>. <article-title>Propagating waves can explain irregular neural dynamics</article-title>. <source>Journal of Neuroscience</source>. <year>2015</year>;<volume>35</volume>(<issue>4</issue>):<fpage>1591</fpage>&#x2013;<lpage>1605</lpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Pyle</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>. <article-title>Spatiotemporal dynamics and reliable computations in recurrent spiking neural networks</article-title>. <source>Physical Rev Lett</source>. <year>2017</year>;<volume>118</volume>(<issue>1</issue>):<fpage>018103</fpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>Huang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ruff</surname> <given-names>D</given-names></string-name>, <string-name><surname>Pyle</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>BD</given-names></string-name>. <article-title>Circuit-based models of shared variability in cortical networks</article-title>. <source>bioRxiv</source>. <year>2017</year>; p. <fpage>217976</fpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Malina</surname> <given-names>KCK</given-names></string-name>, <string-name><surname>Mohar</surname> <given-names>B</given-names></string-name>, <string-name><surname>Rappaport</surname> <given-names>AN</given-names></string-name>, <string-name><surname>Lampl</surname> <given-names>I</given-names></string-name>. <article-title>Local and thalamic origins of correlated ongoing and sensory-evoked cortical activities</article-title>. <source>Nat Comm</source>. <year>2016</year>;<volume>7</volume>:<fpage>12740</fpage>.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>Dahmen</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gr&#x00FC;n</surname> <given-names>S</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>, <string-name><surname>Helias</surname> <given-names>M</given-names></string-name>. <source>Two types of criticality in the brain</source>. <year>2017</year>;(<issue>1</issue>):<fpage>1</fpage>&#x2013;<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Herfurth</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tchumatchenko</surname> <given-names>T</given-names></string-name>. <article-title>How linear response shaped models of neural circuits and the quest for alternatives</article-title>. <source>Current opinion in neurobiology</source>. <year>2017</year>;<volume>46</volume>:<fpage>234</fpage>&#x2013;<lpage>240</lpage>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="book"><string-name><surname>Gardiner</surname> <given-names>CW</given-names></string-name>. <chapter-title>Handbook of stochastic methods</chapter-title>. vol. <volume>3</volume>. <publisher-name>Springer, Berlin</publisher-name>; <year>1985</year>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Kuhn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S</given-names></string-name>. <article-title>Higher-order statistics of input ensembles and the response of simple model neurons</article-title>. <source>Neural Comput</source>. <year>2003</year>;<volume>15</volume>(<issue>1</issue>):<fpage>67</fpage>&#x2013;<lpage>101</lpage>. doi:<pub-id pub-id-type="doi">10.1162/089976603321043702</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
</article>