<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/363812</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioengineering</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Framework for Predicting Design Failures in Engineered Genetic Codes</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3490-3761</contrib-id>
<name>
<surname>Yu</surname>
<given-names>Bea</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x0002A;</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Murphy</surname>
<given-names>Matthew</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">&#x0002A;</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Carr</surname>
<given-names>Peter A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x0002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>MIT Lincoln Laboratory</institution>, Lexington, MA, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Synthetic Biology Center, Massachusetts Institute of Technology, Cambridge</institution>, Massachusetts, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Grinnell College, Grinnell</institution>, IA, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x0002A;</label>Corresponding authors E-mail: <email>bea.yu@ll.mit.edu</email>, <email>carr@ll.mit.edu</email></corresp>
<fn id="n1"><p>Approved for public release: distribution unlimited.</p></fn>
<fn id="n2" fn-type="supported-by"><p>This material is based upon work supported by the Assistant Secretary of Defense for Research and Engineering and MIT under Air Force Contract No. FA8721-05-C-0002 and/or FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Assistant Secretary of Defense for Research and Engineering and MIT.</p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>363812</elocation-id>
<history>
<date date-type="received">
<day>06</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>06</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>06</day>
<month>7</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="363812.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Extreme engineering of an organism&#x2019;s genetic code could impart true genetic incompatibility, even blocking effects of horizontal gene transfer and viral infection. Recent experiments exploring this possibility demonstrate that such radical genome engineering achievements are plausible. However, it is unclear when the modifications will compromise the fitness of an organism. Efforts to reformat an entire genome are difficult and expensive; computational methods predicting fruitful experimental trajectories could play a pivotal role in advancing such efforts. We present a framework for building <italic>in silico</italic> models to assist genome-scale engineering. Genetic code engineering requires choosing from many possible codon-usage schemes, to find a design that is viable and effective. We use machine learning to identify which alternative codon-usage schemes are likely to result in no observed viable cells. Our data-driven approach employs observations of how modifying codon usage in individual genes impacted observed viability in E. coli, revealing salient features for early identification of problematic genetic code designs. We achieved an average area under the receiver operating characteristic of 0.72 on out-ofsample data.</p>
<sec>
<title>Author Summary</title>
<p>As machine learning and artificial intelligence play an increasingly central role in science and engineering, it will be important to establish standardized techniques that facilitate the dialogue between experimentation and modeling. Biological experimental techniques are concurrently evolving at a rapid pace, providing unique opportunities to collect high-quality, novel information that was previously unobtainable. This work navigates the landscape of this vast, new territory, identifies interesting landmarks for exploration and posits new approaches towards advancing our research efforts in these areas. In this work, we show that, using a small dataset of 47 observations and rigorous nested cross validation techniques, we can build a model that makes better-than-random predictions of how codon usage changes in essential genes influence viability in <italic>E. coli.</italic> These predictions can be used to inform experimental trajectories in both genetic code and codon optimization experiments. We discuss ways to improve this model, iteratively, by performing high value experiments that decrease uncertainty in predictions and extrapolation error. Finally, we present novel visualization methods to aid in developing intuitions for how re-coding impacts groups of genes. These methods are also useful tools in building important insights into how well machine learning algorithms can generalize to new data.</p>
</sec>
</abstract>
<counts>
<page-count count="54"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>With the advent of new <italic>in vivo</italic> DNA editing techniques, engineering at the genome scale is not only achievable but an increasingly inevitable trajectory. In particular, the emerging discipline of genetic code engineering promises novel and far reaching applications in genetic containment, synthesis of proteins incorporating novel amino acids, and immunity to viral infection. Genetic code engineers seek to implement genome-scale changes algorithmically by modifying the rules underlying the genetic code (recoding) and implementing non-natural codes in particular organisms. These changes ultimately result in fundamentally altering how certain codons are recognized during translation. Such &#x201C;global&#x201D; changes offer unprecedented opportunities to explore the effect genetic information has on an organism&#x2019;s specific phenotypes. The first organism recoded genome-wide, C321.&#x0394;A (nicknamed r<italic>E. coli 1.0</italic>), has been engineered by completely removing one of the 64 codons from the genetic code of <italic>E. coli</italic> MG1655 [<xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref>]. The de-assigned codon has shown facility for being re-assigned to non-standard amino acids [<xref ref-type="bibr" rid="c2">2</xref>], for improving resistance to infection by bacteriophage [<xref ref-type="bibr" rid="c2">2</xref>] and for providing improved intrinsic biocontainment for engineered microbes [<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c4">4</xref>].</p>
<p>Notably, changes to codon usage throughout the DNA of an entire genome are not sufficient to completely implement the desired new genetic code&#x2014;the gene(s) for the corresponding translation machinery must also be engineered. In this particular case of genome-wide codon removal, deletion of the gene prfA (encoding the release factor protein RF1) was sufficient.</p>
<p>In general, engineering a genetic code genome-wide requires two major steps: 1) completely altering the usage of one or more of the 64 codons throughout the genome, and 2) altering the associated translation machinery to interpret those codons differently. For engineering <italic>rE. coli 1.0</italic>, step 1 required changing the stop codon UAG in all 321 known instances to UAA, a synonymous stop codon, in order to remove the UAG codon from usage throughout the entire genome. Step 2 required deletion of the gene encoding RF1 (release factor 1), removing the cell&#x2019;s ability to recognize the UAG codon at all.</p>
<p>To perform a similar process with a sense codon, one might alter all instances of the codon GUC (encoding the amino acid valine) to GUG (also encoding valine) and then delete the genes valV and valW, encoding the tRNAs that recognize the GUC codon. These are both examples of a reductionist genetic, i.e. where codons have been cleanly removed from the genetic code. In such cases, further effort would allow the removed codons to be re-assigned to a different amino acid, which again requires engineering both codon usage and the corresponding translation machinery. Importantly, either step 1 or step 2 may result in a growth defect, or lack of any observed growth, in the organism. Choosing codes that minimize this risk is essential when undertaking the long and difficult process of testing a code genome-wide, <italic>in vivo.</italic></p>
<p><italic>Lajoie et al.</italic> [<xref ref-type="bibr" rid="c5">5</xref>] experimentally explored the impact of step 1 on single genes in <italic>E. coli.</italic> 42 highly expressed genes were redesigned according to a new genetic code that disallowed the use of 13 codons. Individually, each redesigned gene was produced synthetically, inserted into the cell to replace the wild-type version, and doubling time was measured. These redesigned gene sequences also featured substitutions of one allowed synonymous codon for another. For example, instances of the forbidden AUA Isoleucine codon could be replaced with either of the allowed synonyms AUC or AUU, while AUC would be replaced by the only other remaining allowed synonym AUU, because AUA is forbidden. If no colony formation was observed with the altered genes, the impact of changing codon usage in the gene was tested further <italic>in vivo</italic> using alternative designs that departed less drastically from wild-type codon usages.</p>
<p>The experiments in [<xref ref-type="bibr" rid="c5">5</xref>] provide an important window into the effects on viability of changing codon usage in highly expressed genes. Other notable efforts by Ostorov et al. in [<xref ref-type="bibr" rid="c6">6</xref>] are pursuing the removal of a different, smaller subset of codons throughout the entire <italic>E. coli</italic> genome. This resulting strain, called <italic>rE. coli-57</italic>, would use 57 of the 64 canonical codons genome-wide and may demonstrate increased genetic containment and viral resistance relative to <italic>rE. coli</italic>-<italic>1.0</italic>, in which just one codon was removed genome-wide. Yet the degree of extensive genome engineering required to fully confer genetic containment and viral immunity remains unknown. Identifying the code(s) meeting these objectives&#x2014;and that can be feasibly engineered while maintaining cell viability&#x2014;is an extremely complex challenge. The number of codes to test seems unapproachably vast if one considers all possible permutations of codons for each amino acid. Furthermore, modeling the complex mapping of genotype to phenotype is currently limited by incomplete information. Even powerful technologies such as DNA synthesis, MAGE, and CRISPR enabling genetic-code engineering experiments are unlikely to reduce costs in the foreseeable future to the point that all genetic code designs of interest can be evaluated in the laboratory. Under these circumstances, computational methods can play in an important role in establishing an ongoing dialogue between experiment and theory. Results from <italic>in silico</italic> predictive models can be used to identify promising and feasible <italic>in vitro</italic> and <italic>in vivo</italic> experiments. Results from experiments can then be leveraged to increase fidelity and to test accuracy and precision of <italic>in silico</italic> simulations, cf. <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>The envisioned tight coupling of information flows among <italic>in silico</italic>, <italic>in vitro</italic> and <italic>in vivo</italic> experiments.</p></caption>
<graphic xlink:href="363812_fig1.tif"/>
</fig>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Depiction of data partitions for the nested cross-validation developed for the Gaussian and SVM classifiers. Two partitioning steps occur for each of the 1000 cross validation trials. The first one randomly selects a set of ten hold-out observations (five with no observed colonies, five with observed colonies) from the total set of 47 (blue dots in the diagram), without replacement. Next, from the remaining 37 data points, two are randomly selected, also without replacement, as an inner test sample (one with no observed colony, one with an observed colony) for exhaustive leave-pair-out cross-validation (LPOCV), depicted as green dots in the diagram. The other 35 (gray dots) are used for training the models in the LPOCV loop. This leave-pair-out cross validation is done to learn the optimal number of features allowed in the feature selection process &#x007B;4, 5, 6, 7&#x007D;, a classification threshold and whether to include correlated features. The number of features that produces the best AUC from the inner LPOCV is the number of features selected for training a model with the outer CV training set. For details about the nested CV pipeline, see <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption>
<graphic xlink:href="363812_fig2.tif"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Process diagram of the nested cross validation approach. Block colors correspond to data-type colors in <xref ref-type="fig" rid="fig2">Figure 2</xref> and mean the action described in the block pertains to that subset of data. The inner CV loop chooses the optimal number of features, M, to be used in the outer CV feature selection, which is done on outer CV training data only. Feature selection follows the rubric of choosing the M features with the largest magnitude Cohen&#x2019;s D effect size for discriminating feature distribution associated with observed and no observed colonies. The inner loop is also used to estimate a classification threshold and whether to include correlated features in the model. These features are then used to train a Gaussian classifier and an SVM. The resulting model is used to predict the class of the held-out ten observations. The outer loop executes 1000 times, resulting in 1000 area-under-the-ROC-curve estimates. To get an estimate of performance, we take the mean of the AUC distribution. KEY: &#x007B;FS :&#x003D; feature selection, ROC :&#x003D; Receiver operating characteristic, AUC :&#x003D; area under the ROC curve, GC :&#x003D; Gaussian Classifier, SVM :&#x003D; support vector machine&#x007D;.</p></caption>
<graphic xlink:href="363812_fig3.tif"/>
</fig>
<p><italic>In silico</italic> methods that can predict design failures in step 1 of genetic code engineering would be broadly useful in many genome engineering endeavors. The state of the art in biological computational modeling and analysis, though brimming with promise for explanatory purposes, to our knowledge, lacks the predictive capabilities necessary to address this particular need in genetic code engineering, however. As a baseline, models predicting whether changing codon usage designs in specific genes fail (in the sense that they are associated with no observed growth) in <italic>E. coli</italic> will be particularly useful for saving time and cost entailed in implementing difficult, genome-wide experiments with code designs that are likely compromise its viability. No existing models we know of have this specific capability.</p>
<p>Karr et al. recently published in [<xref ref-type="bibr" rid="c7">7</xref>] an <italic>in silico</italic>, whole-cell model of <italic>M. genitallium.</italic> While this type of model may provide useful insights into the effects of changing codon usage in step 1 of recoding, a similar model of <italic>E. coli</italic> is not currently available. Thiele et al. in [<xref ref-type="bibr" rid="c8">8</xref>] published a stoichiometric model of <italic>E. coli</italic>&#x2019;s transcription and translation machinery. This model, however, is not resolved to account for the codon-specific influences in transcription and translation necessary to understand the effects of step 1 on these processes. Lerman et al. in [<xref ref-type="bibr" rid="c9">9</xref>] combined the model from [<xref ref-type="bibr" rid="c8">8</xref>] with a metabolic model for <italic>E. coli</italic> to capture the influence of genetic information on both metabolism and transcription and translation and, through these processes, phenotype. While this model captures the important influence of metabolism on phenotype, because it uses the transcription and translation model from [<xref ref-type="bibr" rid="c8">8</xref>], it lacks the codon-specific resolution necessary to make inferences about phenotypic responses to changes in codon usage entailed by step 1 in the recoding process.</p>
<p>The <italic>in silico</italic> modeling and analysis approaches described above center on digital representations of biochemical and biophysical mechanisms in the cell. An alternative approach involves abstracting the genetic code in terms of its role in information storage and transmission in the cell. With this approach, established physical and mathematical models can be leveraged to explore questions about the driving forces that might have led to the code&#x2019;s specific topology, defined by its mapping of 61 codons to 20 amino acids. Tulsty et al. model the genetic code as a noisy communication channel and use rate-distortion theory to describe how the code might have evolved to balance the rate and distortion of the channel [<xref ref-type="bibr" rid="c10">10</xref>]. Constraints on the code as an information channel, such as &#x201C;error-load&#x201D; and amino acid &#x201C;diversity&#x201D; (both mapping to the &#x201C;distortion&#x201D; of the code &#x201C;channel&#x201D;), and the &#x201C;cost&#x201D; to the cell of specific binding between codons and anticodons to reduce translation errors (the &#x201C;rate&#x201D; of the code &#x201C;channel&#x201D;), are likely to influence which genetic code engineering trajectories maintain viability. However, this model does not address factors such as observed organism-specific (e.g. <italic>E. coli</italic> vs. <italic>Plasmodium</italic>) [<xref ref-type="bibr" rid="c11">11</xref>] and category-of-gene specific (e.g. highly expressed vs. not highly expressed) [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>] codon biases that are impacted when synonymous codons are substituted in step 1 of the recoding process. Modifications in step 1 that alter these biases are also likely to influence the viability of an organism.</p>
<p>To address this capability gap in the state of the art of <italic>in silico</italic> modeling, we developed a phenomenological model specifically to predict the consequences of different codon-usage changes on observed cell growth (one measure of a design success or failure). For the set of individual, highly-expressed, essential genes used in [<xref ref-type="bibr" rid="c5">5</xref>], we computed a set of features that address both physio-chemical and information-theoretic characteristics of each gene&#x2019;s DNA sequence. From these, leveraging accompanying observations of colony formation from [<xref ref-type="bibr" rid="c5">5</xref>] in binary form (i.e. &#x007B;yes, no&#x007D;), we determined a salient subset of features and learned a statistical model that predicts whether changing codon usage in a gene will impact <italic>E. coli</italic>&#x2019;s ability to form observable colonies when grown on agar plates. To assess generalizable performance of a model trained with this relatively small dataset, we devised a performance evaluation method using nested cross validation (CV) with random subsampling. The best model yielded an average AUC of 0.72 and a mean sensitivity of 0.80.</p>
<p>We used this model to make design success/failure predictions for <italic>E. coli</italic> genes with codon usage altered <italic>in silico</italic> according to several alternative, novel algorithms. The algorithms we chose incorporate domain knowledge about interesting edge-cases in possible genetic code designs. This model predicted that two out of nine re-coding algorithms are likely to fail upon <italic>in vivo</italic> implementation. The classifier provided information about the effects of changes in codon usage in <italic>individual genes</italic> on cell viability. To gain insights into the effects of algorithmically modifying codon usage in <italic>sets of genes</italic>, we produced scatter-plots of salient features computed for the genes, bounded by convex hulls. This visual representation provides a gestalt view of how different algorithms impact the same group of genes. It is possible with this technique to visually gauge similarity between algorithms in terms of how close their convex hulls are in the feature space and whether these convex hulls are similar in shape and size. With these plots, we also arrived at a qualitative representation of expected extrapolation error from models learned on the Lajoie gene/code dataset in [<xref ref-type="bibr" rid="c3">3</xref>].</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Nested CV results</title>
<p>The average AUC, sensitivity and specificity over the 1000 trials for the GC and SVM classifiers appear in <xref ref-type="table" rid="tbl4">Table 4</xref>. Thresholds determining sensitivity and specificity were learned on out of sample data from the inner CV loop. The AUC of the GC classifier, AUC &#x003D; 0.72, was significantly better than that of the SVM, AUC &#x003D; 0.68, at the 5&#x0025; level. Both AUC values were significantly better than random, at the 5&#x0025; level. The sensitivity of the GC classifier was 0.8; that of the SVM, 0.76. Specificity of the SVM was higher, 0.52, than that of the GC, 0.48. Given the problem space we are addressing with this model, the GC appears to be a better choice for discriminating design success/failure than the SVM because it has a higher true positive rate. We wanted to minimize the false negative rate (1 - true positive rate), e.g. falsely classifying a modification that would result in design failure as a modification the would result in a successful design, because <italic>in vivo</italic> experiments are expensive and only modifications with a high probability of viability are likely to be good candidates for full, <italic>in vivo</italic>, recoding experiments.</p>
</sec>
<sec id="s2b">
<title>Classifying the effect of the nine new codon-usage algorithms on the 40 genes in vivo</title>
<p><xref ref-type="fig" rid="fig7">Figure 7</xref> shows split bean plots of the features with the strongest Cohen&#x2019;s d selected using the uncorrelated feature selection method on the entire FCS and FC dataset, as described above.</p>
<p>Cyan and yellow lines indicate the log of the computed feature values, blue and orange contours are kernel density estimates of the log feature observations, dark blue and light brown solid lines indicate mean log feature values associated with design success and design failure, respectively, and the black dotted line indicates a grand mean over all log feature values plotted. For the SVM LPOCV parameter selection step, we achieved the best predictive performance using five uncorrelated features selected based on the magnitude of their Cohen&#x2019;s d, as opposed to using all features, including correlated ones. For the GC, five features chosen from all features, including correlated features, performed best in the LPOCV. Three of the five features selected for the GC were the same as those selected for the SVM: the Hamming distance between the base pair distribution of the WT and modified sequence (HammingBPS), the KL divergence between the codon distribution of the WT and modified sequence (KLdivCodons) and the ratio of CAI from the 31<sup>st</sup> codon to the final codon before the stop codon (ratioCAIend30codonsPlus). The remaining two CAI features selected for the GC were highly correlated with ratioCAIend30codonsPlus, had very similar bean plots and are therefore not shown.</p>
<p>Since the magnitude of the Cohen&#x2019;s d was used to select features, features with, on average, very different values for the design success/failure classes, and small, pooled standard deviation, were likely to be selected. In <xref ref-type="fig" rid="fig4">Figure 4</xref>, it is clear that the large mean difference between the ratioRNAFoldRBS30 of the two classes is offset by the large pooled standard deviation, making the magnitude of Cohen&#x2019;s d for this feature one of the lowest in the five selected features. This feature, as well as normMICodons, was not selected in the GC correlated variable feature selection routine. In contrast, ratioCAIend30codonsPlus has a large mean difference between the two classes paired with a relatively small, pooled standard deviation, making it the feature with the strongest Cohen&#x2019;s d of the five. The ratioCAIend30codonsPlus is the codon adaptation index ratio for the part of the gene following what has been called a &#x201C;codon ramp&#x201D; [<xref ref-type="bibr" rid="c19">19</xref>], the beginning of the gene characterized by, on average, codons that are translated more slowly. It is not clear why the CAI from the latter part of the gene was more discriminatory for design success classifcation in the FC and FCS modified dataset.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Split bean plots of the five uncorrelated features selected for the SVM classifier. Three of the five, the Hamming distance between the base pair distribution of the WT and modified sequence (HammingBPS), the KL divergence between the codon distribution of the WT and modified sequence (KLdivCodons) and the ratio of CAI from the 31<sup>st</sup> codon to the final codon before the stop codon (ratioCAIend30codonsPlus), were also selected for the GC correlated feature set. The other two features selected for the GC classifier are highly correlated with the CAIend30codonsPlus, have similar feature histograms and are therefore not shown. The blue envelope is the kernel density estimation of the feature histograms for the modified genes that resulted in a successful design while orange is that of the modified genes that did not. Cyan and yellow lines signify the log of feature values for the two classes of features, respectively. Dark blue and brown long lines indicate mean log values for features associated with design success and failure, respectively.</p></caption>
<graphic xlink:href="363812_fig4.tif"/>
</fig>
<p>The Hamming distance for the base pair distribution and the KL divergence for the codon distribution were also selected in both the GC and SVM feature selection methods. The Hamming distance between base-pair distributions measures the minimum number of base pair substitutions that would be required to change the modified sequence back to the wild-type sequence. Modifications that failed had, on average, more base pair substitutions than modifications succeeded. KL divergence can be interpreted as measuring the difference between two sets of observed data by quantifying the amount of extra information required to compress the information in one set using a scheme based on the generating distribution of the other set [<xref ref-type="bibr" rid="c31">31</xref>]. It is not a symmetric measure and therefore not a proper distance. The KL divergence between the codon histogram of the wild-type codon frequencies and the codon histogram of the modified gene codon frequencies is therefore the amount of extra information required to compress the codon frequency information from the wild-type sequence using a scheme optimized for the modified sequence. The strong, positive Cohen&#x2019;s d for this feature in this dataset entails that design failure is correlated with a higher wild-type KL divergence from modified versions of a gene. Thus, the amount of extra information required to compress the codon frequency information from the wild-type sequence using a scheme optimized for the modified sequence was higher on average in modified genes associated with design failure relative to modified genes associated design success.</p>
<p>In <xref ref-type="table" rid="tbl5">Table 5</xref>., the designed genes predicted by the SVM and/or the GC to fail are shown. Of the nine algorithms, implementation of two were predicted to fail for one or more modified genes. The Min<sub>weak</sub> algorithm had the biggest impact on viability-twenty-eight out of the forty genes modified with this algorithm were predicted using either the GC or SVM to fail. tRNA<sub>sub2</sub> was similarly predicted to fail for eleven out of forty genes. Sub-11 is not predicted to result in a design failure by either classifier for any of the forty genes. The codons removed in <italic>rE. coli</italic>-<italic>57</italic> are a subset of those removed in Sub-11 [<xref ref-type="bibr" rid="c6">6</xref>]. It is worth noting therefore that, when implemented individually in the forty genes in this study, the alternative genetic code in [<xref ref-type="bibr" rid="c6">6</xref>] would also be predicted by our models to succeed. Ostrov et al. plan to remove seven codons (cf. <xref ref-type="table" rid="tbl3">Table 3</xref>) from the entire <italic>E. coli</italic> genome, simultaneously. If there is no observed colony formation in <italic>rE. coli</italic>-<italic>57</italic>, our results suggest that this may to be due to interactions between the recoded genes and/or the individual effects of recoding genes not included in our study.</p>
<p>The GC is more conservative than the SVM in classifying failed modifications for this new set of algorithms. It performed significantly better, using the AUC metric, than the SVM in the nested cross-validation study on the FC &#x002B; FCS dataset (<xref ref-type="table" rid="tbl4">Table 4</xref>). Although the two classifiers agree that many of the Min<sub>weak</sub> modified genes will fail, there are discrepancies as well. All but two of the modified genes classified as failing under the GC were classified similarly by the SVM. Notably, rplL was the only gene modified with tRNA<sub>sub2</sub> that was classified as failing by the GC. This gene was not classified similarly by the SVM when modified by any of the algorithms we tested. Though the GC performs significantly better than the SVM in the validation results, the SVM still performs significantly better than random. Therefore, the SVM may provide complimentary information to the GC and the results from the two classifiers could be combined to provide more robust discrimination.</p>
<p>Existing methods could be applied to automatically combine classifier predictions. For example, a majority-rule-like, classifier combination could be defined such that, if the GC and the SVM each classify at least one gene as preventing colonies from forming for any algorithm, that algorithm should be eliminated from the suite of potential algorithms to test <italic>in vivo.</italic> This rule would eliminate both the Min<sub>weak</sub> and the tRNA<sub>sub2</sub> algorithms as candidates for <italic>in vivo</italic> genetic code engineering experiments. Such a rule could be honed to weigh the decision rule to throw-out a potential algorithms to test <italic>in vivo</italic> more heavily if multiple genes are classified by each classifier as failing for a given algorithm. Although not shown in <xref ref-type="table" rid="tbl4">Table 4</xref>., we tested random forest, gradient boosting and extra trees classifiers from Scikit Learn on this dataset as well. None of these approaches outperformed the SVM and GC classifiers, implemented in Matlab. In principle, however, with further parameter tuning, performance with these techniques might be improved and results combined with the SVM and GC classification outputs to further improve performance.</p>
<p>In the absence of an explicit model combining the predictions of the two classifiers there is enough consensus between them to suggest strongly that tRNA<sub>sub2</sub> and Min<sub>weak</sub> should be eliminated as candidate algorithms to be used in genetic code engineering experiments. Although extreme algorithms such as Min<sub>weak</sub> and tRNA<sub>sub2</sub> might confer strong viral resistance and genetic isolation to engineered organisms, they don&#x2019;t perform well in the colony-formation dimension of the multi-objective optimization genetic code engineering attempts to solve. Observed colony formation is a necessary condition that must be met before other dimensions in the problem space defining optimal algorithms, such as viral resistance, genetic isolation and non-natural amino acid and protein generation can be examined.</p>
<p>In <xref ref-type="table" rid="tbl5">Table 5</xref>., we also gain insights into which genes are most likely fail in <italic>E. coli</italic> when modified with any algorithm. We call these types of genes &#x201C;bellwether genes&#x201D; in reference to the idea that one or a few sensitive genes could be used as a first pass to evaluate algorithms <italic>in vivo</italic> before undertaking more comprehensive, expensive genome-scale modifications. If a modified bellwether gene fails when implemented <italic>in vivo</italic>, the algorithm can be discarded, if not, the algorithm can be evaluated further for suitability. rplB, rpsC, rplO, and rpsA appear to be promising &#x201C;bellwether gene&#x201D; candidates since changes to them are notably predicted to fail for tRNA<sub>sub2</sub>, by the SVM, and Min<sub>weak</sub>, by the SVM and GC. These genes are also from the set that resulted in no colony formation <italic>in vivo</italic> when modified with the FCS algorithm. Increasingly comprehensive models trained with more data will enable us to define this set with more confidence.</p>
</sec>
<sec id="s2c">
<title>Visualizing effects of changing codon usage on sets of genes</title>
<p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we present an example of a new visualization technique we developed to facilitate gestalt understanding the effects of algorithms used for genetic code engineering on groups of genes. The axes of the plots used in the visualization can be any features determined to be salient in genetic code or genome engineering. For this work, we focus on features useful for design success/failure classification, as measured by observation/no observation of colony growth, discovered using our feature selection routine described above. Two of the five selected features serve as axes in <xref ref-type="fig" rid="fig5">Figure 5</xref>. These two features can be plotted for each gene from the set of 40 genes in <xref ref-type="table" rid="tbl1">Table 1</xref>. modified with any number, N, of codon-usage algorithms, resulting in N points per gene, 40 points per algorithm and N<sup>&#x0002A;</sup>40 points in all. To reduce complexity as we describe components of the visualization, we show only features from genes modified with two of the nine novel algorithms presented above, Min<sub>weak</sub> and tRNA<sub>sub1</sub>. The 40 points from each algorithm are bound by line segments defining the convex hull (yellow for Min<sub>weak</sub> and blue for tRNA<sub>sub1</sub>) in order to visually group the influence of each algorithm on the set of genes in the salient feature space. Generally, the convex hull of a set of points in a Euclidean space is defined as the smallest convex set that contains that set.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>A data visualization method using convex hull plots in salient feature dimensions. Here, we show convex hulls circumscribing the feature values from 40 genes from <xref ref-type="table" rid="tbl1">Table 1</xref>, modified with two of the novel algorithms, Min<sub>weak</sub> and tRNA<sub>sub1</sub>. The features are two of the five selected in the feature selelction routine for design success/failure prediction. This visualization has two benchmarks to orient investigators-the &#x201C;wild-type origin&#x201D; and the convex hull plots of features for the the &#x201C;failed&#x201D; (red dashed) and &#x201C;successful&#x201D; (black dashed) training samples. The wild-type origin shows the feature value a gene would have if it was not modified. The amount the feature of an modified gene deviates from the wildtype origin provides insights into how &#x201C;different&#x201D; an modified gene is from the wild-type sequence. The training data convex hull plots show what parts of the feature space are inhabited by observations of successful and failed designs. If genes modified with a new algorithm have features near the training examples that resulted in a design failure, they have the potential to result in a design failure as well.</p></caption>
<graphic xlink:href="363812_fig5.tif"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Genes used in this work for model development and performance evaluation and for recoding with nine novel codes and generating predictions and visualizations with sequence data from [<xref ref-type="bibr" rid="c3">3</xref>] and EcoCyc. Genes in represented in bold, in the <bold>Design Success</bold> row, resulted in no observed colonies when modified with the FCS algorithm and implemented in <italic>E. coli</italic>, but resulted in observed colonies when modified with the less extreme FC algorithm [<xref ref-type="bibr" rid="c3">3</xref>]. These genes also appear in the <bold>Design Failure</bold> row, but in normal type. Normal type designates genes modified with the FCS algorithm, bold, genes modified with the FC algorithm. Genes represented in bold are in both the successful and failed design datasets because they were modified with two different algorithms in [<xref ref-type="bibr" rid="c3">3</xref>].</p></caption>
<graphic xlink:href="363812_tbl1.tif"/>
</table-wrap>
<p>This visualization approach contains several benchmarks to orient investigators to important features of the algorithms. First, a &#x201C;wild-type&#x201D; origin is depicted as a cyan triangle in each pairwise plot. This represents the feature values that an unmodified gene would have and can be used to measure how distant algorithms are from wild-type configurations. Because most of the features we used in this work are ratios or normalized distances, the &#x201C;wild-type origin&#x201D; for any given feature is 1 or 0. Because all of our features were distances or ratios, the wild-type origin is the same for every gene and can be represented as one point in the pairwise feature space. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, the Min<sub>weak</sub> algorithm, in which 43 codons are removed from the code, moves the set of 40 genes far from the wild-type origin at (1,0), whereas the same set modified with the less extreme tRNA<sub>sub1</sub> algorithm, in which 28 codons are removed, is relatively much closer to the origin.</p>
<p>Second, relevant groups of the training data are plotted using dashed convex hulls-one in red, to indicate examples resulting in design failure, the other in black, indicating examples of successful designs. These convex hulls demonstrate where in the feature space the model had information about colony formation from which to learn classifier-model parameters. Using this information, areas of the feature space lacking training examples can be identified and strategically populated with data in future experiments specifically designed to make the model more robust and comprehensive. Predictions for new examples far from the training data will likely have more extrapolation error and should be treated with more skepticism.</p>
<p>Third, feature landscapes of how modifications effected colony formation are defined with the dashed convex hulls, allowing investigators to immediately identify algorithms likely to result in a design failure by sight. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, the Min<sub>weak</sub> convex hull is close in the feature space to the red, dashed convex hull bounding the examples that resulted in a design failure in the training set. This was the novel algorithm predicted to fail in the greatest number of genes from the set of 40. On the other hand, the tRNA<sub>sub1</sub> algorithm convex hull lies far from that bounding the training examples associated with no observed colonies.</p>
<p>Finally, the relative placement and size of the convex hulls of different algorithms are also informative. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, the convex hull defining the features from the Min<sub>weak</sub> algorithm is quite far from that defining features from tRNA<sub>sub1</sub>, consistent with the fact that the two are different &#x201C;types&#x201D; of algorithms in the sense that they change the features of the same set of genes differently. Algorithms can also be distinguished by the sizes of their convex hulls. That of the Min<sub>weak</sub> algorithms is small compared to the convex hulls bounding the training data associated with observed colonies and the tRNA<sub>sub1</sub> algorithm. This means that, even though the Min<sub>weak</sub> algorithm is extreme in the number of codons it excludes, it changes all 40 genes away from wild-type configurations &#x201C;in the same way&#x201D; in the salient feature space. tRNA<sub>sub2</sub>, though less extreme, influences the genes in the set &#x201C;in different ways&#x201D; in the feature space, leading to more dispersion and a larger convex hull. In <xref ref-type="fig" rid="fig6">Figure 6a-c</xref>, we plot the convex hulls of all 9 algorithms applied to the set of 40 genes from <xref ref-type="table" rid="tbl1">Table 1</xref>. As would be expected, the convex hulls of the features of the forty genes recoded with the Min<sub>weak</sub> algorithm lies closest to the red, dashed convex hull bounding the examples from the FC algorithm that resulted in design failure in all three pairwise feature plots. Also, as would be expected, the convex hull bounding the gene set recoded with tRNA<sub>sub2</sub> inhabits parts of the feature space close to those inhabited by the genes recoded with Min<sub>weak</sub>. The convex hulls of these algorithms are plotted with thicker lines to indicate that they are predicted to fail if implemented in one or more of the genes. In particular, both of these algorithms result in a ratioCAIend30Plus less than 1 for all 40 genes, and less than 0.5 for most of the genes, indicating the CAIend30Plus for the modified genes is much reduced relative to that of the wild-type genes. Since the reference set for the CAI consists of highly expressed genes, the higher the CAI, the more likely it is that a gene is highly expressed. This set of 40 genes was selected based on the fact that they were essential and highly expressed. Therefore, the Min<sub>weak</sub> and tRNA<sub>sub2</sub> changed the codon composition of these highly-expressed genes in the wild-type organism so that their codon composition was more similar to that of poorly expressed genes, a change that would be intuitively be expected to fail. Furthermore, it is worth noting that the ratioCAIend30Plus had a higher Cohen&#x2019;s d than the ratioCAI, computed over the entire gene. While more data are needed to confirm this with significance, these results suggest that eliminating the &#x201C;codon ramp&#x201D; from the CAI computation may lead to a more sensitive metric for predicting design success.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figures 6 a-c.</label>
<caption><p>Pairwise convex hull plots in three feature dimensions selected in both the GC and SVM feature selection routines. Each convex hull circumscribes the same 40 genes but modified with each of the nine, novel algorithms. Note that the two algorithms predicted to fail when implemented in particular genes (bolded convex hulls), Min<sub>weak</sub> and tRNA<sub>sub2</sub>, have similar feature values for this set of genes. Also note that the more extreme the algorithm, the more features deviate from WT features (cyan triangles). In general, predictions for unseen data far from the data on which the model was learned (in the dashed convex hulls), should be treated with more caution than those for unobserved data in the domain of the training data. Note in 9a that rpsG is an extreme outlier for all algorithms in the KLdivCodon dimension (point in each algorithm&#x2019;s convex hull with largest KLdivCodon).</p></caption>
<graphic xlink:href="363812_fig6.tif"/>
</fig>
<fig id="fig7" position="float" fig-type="figure">
<label>Figures 7 a-c.</label>
<caption><p>Pairwise convex hull plots (blue) in the three feature dimensions, selected in both the GC and SVM feature selection routines, circumscribing the entire data set of 360 modifications of 40 genes (i.e. modified with the nine, novel algorithms). Features from rplU, rpsG, and rpsR, modified with the Min<sub>weak</sub> algorithm, and rplQ, modified with the Min-classII algorithm, lie at the corners of the convex hull bounding the data that requires predictions. <italic>In vivo</italic> experiments with <italic>E. coli</italic> to determine whether these genes with these changes impactimpact colony formation would provide new training data for the classifier that would span the feature domain more comprehensively and decrease extrapolation error for predictions made on this data set.</p></caption>
<graphic xlink:href="363812_fig7.tif"/>
</fig>
<p>The algorithms span a spectrum of extremity from Sub-11 in which only 11 codons are eliminated, to tRNA<sub>sub1</sub>, in which 28 codons are eliminated, to Min-GCmax and Min<sub>weak</sub>, in which 43 codons are eliminated. The extremity of the codon changes induced by the algorithms is reflected most in the convex hull&#x2019;s distance from the wild-type origin. As with Min<sub>weak</sub> and tRNA<sub>sub2</sub>, the extreme algorithms that are not predicted fail also have convex hulls similar to each other in the feature space. Because they all eliminate more than half of the available pool of codons, their convex hulls are farther away from the wild-type origin than the less extreme algorithms. These extreme codes have, on average, a lower KLdivCodons and a higher ratioCAIend30CodonsPlus, compared to the codes that are predicted to result in design failure. It is also interesting that one gene, rpsG, disproportionately impacts the shape of the convex hull plots for all algorithms when KLdivCodons is plotted (i.e. it is an outlier). The KLdivCodons of rpsG is much higher for each algorithm than any other modified gene. While changes to rpsG from the nine codes are not predicted to fail, according to our classifier, it is important to note that the area of the feature space occupied by these modifications of rpsG is distant from that occupied by the training set, implying increased likelihood of extrapolation error for these predictions. Better predictions for these modifications of rpsG might be obtained if the classifier&#x2019;s training set is expanded to include colony formation data in the area of the feature space its modifications occupy.</p>
<p>Conducting <italic>in vivo</italic> experiments to collect more training data is not a trivial endeavor, however. The <italic>in vivo</italic> experiments in [<xref ref-type="bibr" rid="c5">5</xref>] which produced the data used to train the classifiers in this work, though less difficult and expensive than full, genetic-code engineering <italic>in vivo</italic> experiments, were challenging and time consuming. In this context, discovering a minimal set of &#x201C;high-value,&#x201D; new examples that can be used to improve the model would be advantageous. Figures 10 a-c. are pairwise convex hull plots (blue) in the three feature dimensions, selected in both the GC and SVM feature selection routines, circumscribing the entire data set of 360 modifications of 40 genes (i.e. modified with the nine, novel algorithms). Features from rplU, rpsG, and rpsR, modified with the Min<sub>weak</sub> algorithm, and rplQ, modified with the Min-classII algorithm, lie at the corners of the convex hull bounding the data that requires predictions. <italic>In vivo</italic> experiments with <italic>E. coli</italic> to determine whether these genes with these changes impactimpact colony formation would provide new training data for the classifier that would span the feature domain more comprehensively and decrease extrapolation error for predictions made on this data set.</p>
<p>These convex hull visualizations intuitively determine and display minimal sets of informative data that expand the domain of the feature space covered by the training data. Other more commonly used metrics for determining valuable data to collect to improve classifier performance, such as uncertainty sampling and expected error reduction [<xref ref-type="bibr" rid="c32">32</xref>], could also be used in this visualization to improve researchers&#x2019; intuition about where valuable data defined by this metric lives in the feature space. In principal, this technique can be used to display good training data for any classifier and any set of genes modified under any set of algorithms.</p>
<p>In general, all of these visualizations can be used to gain a synoptic view of the impact of modifying codon-usage with different algorithms in large groups of genes. In particular, these plots can be used to answer the following questions: How do algorithms differ relative to each other in terms of size, shape, position of and data spread within their convex hulls? How different, on average for a large set of genes of interest, is a sequence modified with a particular algorithm from the wild-type sequence? Is the algorithm and set of genes we are interested in gauging close to or far away from the data used to train the design success/failure classification model (i.e. how good will model predictions be for a given algorithm implemented on a given set of genes)? What are the most valuable experiments to conduct to obtain training data that will improve model predictions? Answers to these questions augment and complement the information obtained in a binary classification based on codon modifications in a single gene. These plots can thus be used in tandem with the classification models to flesh-out the landscape of how different genetic code algorithms influence large numbers of salient genes in the genome.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>With a small dataset of 47 experimental examples, we have developed classifier models that estimate which re-coding algorithms, applied to a highly expressed, essential genes, will result in a design failure. These results are significantly better than random guessing at the 5&#x0025; level. Furthermore, the AUC values were determined using a nested cross validation approach to maximize generalizability to unseen data. Given the extensive resources required for <italic>in vivo</italic> recoding experiments, we will now use results from this simple model to help eliminate problematic experimental trajectories.</p>
<p>We anticipate that this model will improve as more <italic>in vivo</italic> data is collected for training. Future work will involve iteratively conducting promising experiments, based on model predictions, and using this data to train better models for predicting the next round of experiments. In particular, our training set was biased by the fact that only the FCS and FC algorithms were used on a set of 40 highly expressed, essential genes. In addition, data from different algorithms needs to be collected and used to make a more robust model. While data from the genes used here are likely to prove useful in determining whether a recoding algorithm is problematic, other highly expressed and/or essential genes should also be tested. Feature engineering efforts to develope new, promising features is expected to improve results as well.</p>
<p>Our classification methods predict effects of modifying codon usage on a gene-by-gene basis. It is possible that characteristics of the convex hulls plotted in Figures 9. and 10. could yield insights into how modifications in multiple genes <italic>in vivo</italic> would combine to impactimpact viability. To verify this, we will need <italic>in vivo</italic> data in which such multi-gene modifications have been engineered. Such experiments are ongoing in other research groups [<xref ref-type="bibr" rid="c6">6</xref>]. Finally, the other dimensions in the multi-objective optimization promised by genetic code engineering remain to be explored. How different does a recoded organism have to be to confer genetic isolation and viral resistance? What are the bounds on incorporating non-natural amino acids into an organism&#x2019;s protein repertoire? And, can the principles of recoding be successful in more complex organisms with much larger genomes?</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Model Testing and Training Data</title>
<p>The modeling and performance evaluation methodology when building predictive models differ from that involved in constructing explanatory/causal models [<xref ref-type="bibr" rid="c14">14</xref>]. We make no claims in this paper about causality or identifying mechanisms. The scope of the modeling in this work is focused on the pragmatic goal of building an <italic>in silico</italic> pipeline to help predict design success or failure, as a binary yes/no variable, when the codon usage in single genes is changed according to a specific recoding algorithm. In this sense, the tools we present here are decision-support tools for genetic code engineers. The intention of this work is not to build upon or infer biological mechanisms-it is to facilitate and inform the scientific experimentation process in genetic code engineering. This specific goal informed the types of features we examined, the validation methodology we used to estimate the performance of our model and our approach to correlated variables in the model.</p>
<p>When choosing the features we tested for predictive power, our focus was on whether the features were measurable and had predictive potential, rather than on whether such features described possible causal mechanisms derived from theory. Additionally, our validation metrics were empirically derived through nested cross-validation, instead of theoretically derived metrics of goodness-of-fit that are used for regression models when the magnitude and confidence of feature weights in the model are used to infer causal relationships. Finally, correlated predictors do not present the same problems in prediction as they do in explanatory modeling, where understanding the causal strength of a predictor is impacted if other variables being inspected are correlated with it [<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c15">15</xref>]. As a consequence, we did not preclude correlated features in our model; rather, we examined whether their presence had a consistent, significant effect on classifier performance.</p>
<p>For feature selection, model training and cross-validation, we used a dataset consisting of sequence data from altered genes, tested <italic>in vivo</italic>, and the associated observations of colony formation (e.g. failed or succeeded), from the experiments as described in [<xref ref-type="bibr" rid="c5">5</xref>]. 16 of 42 modified genes implemented <italic>in vivo</italic> in the experiments in [<xref ref-type="bibr" rid="c5">5</xref>] resulted in no observed colonies. As a result, a more conservative codon-usage algorithm was tested for these genes in which the 51 allowed codons remain unchanged in the coding sequence. Furthermore, any synonym that enabled successful colony formation from the allowed, synonymous codons was used to replace forbidden codons when sampled synonyms resulted in failed colony formation [<xref ref-type="bibr" rid="c5">5</xref>]. This codon-usage algorithm is referred to as the &#x201C;The Forbidden Codon&#x201D; (FC) algorithm in this work. All <italic>in vivo</italic> implementations of FC algorithm were viable.</p>
<p>Information was not available to us for all modified genes in [<xref ref-type="bibr" rid="c5">5</xref>]; therefore, data in our <italic>in silico</italic> work consists of a subset of the genes (40 out of 42) described in [<xref ref-type="bibr" rid="c5">5</xref>]. In this subset, forty of the modified genes were changed according to FCS algorithm in <xref ref-type="fig" rid="fig2">Figure 2</xref>. These genes are listed in <xref ref-type="table" rid="tbl1">Table 1</xref>. in regular type (e.g. not bolded). Of these, sixteen failed to produce colonies after <italic>in vivo</italic> implementation in [<xref ref-type="bibr" rid="c3">3</xref>], cf. <bold>Design Failure</bold> row in <xref ref-type="table" rid="tbl1">Table 1</xref>. Twenty-four resulted in successful colony formation, cf. <bold>Design Success</bold> row, regular type in <xref ref-type="table" rid="tbl1">Table 1</xref>. Seven of the sixteen genes in our dataset that were changed with the FCS algorithm and resulted in failure, were modified instead with the more conservative &#x201C;Forbidden Codon&#x201D; (FC) algorithm, in which only forbidden codons are replaced in subsets to test for viability, and implemented <italic>in vivo</italic> [<xref ref-type="bibr" rid="c3">3</xref>]. Modifications in this set of seven genes resulted in successful colony formation under the FC algorithm but failed colony formation under the FCS algorithm, which is why they appear in both the <bold>Design Failure</bold> and <bold>Design Success</bold> rows in <xref ref-type="table" rid="tbl1">Table 1</xref>.</p>
<p>To minimize potential sources of extrapolation error, we modified, <italic>in silico</italic>, the same set of forty genes with our nine, novel codon-usage algorithms. The sequence data for wild-type sequences that we used for our features was obtained from EcoCyc, an <italic>E. coli</italic> Database [<xref ref-type="bibr" rid="c16">16</xref>]. Because interactions between the initial protein coding sequence and the ribosomal binding site (RBS) in genes with modified codon usage could potentially influence viability, we included 19 base pairs prior to each start codon. We appended these sequences to the wild-type and codon-modified protein-coding sequences of all genes to compute features using these extended sequences.</p>
</sec>
<sec id="s4b">
<title>Feature Selection, Model Learning and Validation Methodology</title>
<p>We computed twenty-two features for each wild-type and codon-modified (e.g. by the FC, FCS, and the nine novel codes) sequence. We chose several features quantifying codon bias and mRNA folding free energy based on observed physiochemical consequences and proposed mechanisms identifying the role of synonymous codon changes in translation [<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c17">17</xref>-<xref ref-type="bibr" rid="c22">22</xref>]. These features were further partitioned and computed for salient subsets of codons in the genes. For example, several studies identify the first 30-60 base pairs of the coding sequence as a slowly-translated &#x201C;codon ramp&#x201D; relative to the remainder of the gene [<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c17">17</xref>-<xref ref-type="bibr" rid="c22">22</xref>]. Based on this information, we computed codon adaptation indices (CAI) for the first 30 codons of each gene and all subsequent codons prior to the stop codon, each as independent features. Since the estimated interval of codons included in this ramp is not precise and there are possibly other salient codon subsets within the gene, we also computed CAI for the 21<sup>st</sup> codon (including start) to the 21<sup>st</sup> codon before the stop codon and for the 13<sup>th</sup> codon (including start) to the codon before the stop codon. We choose these intervals to explore the influences of groups of codons approximately in the middle and at the end of the genes. A sliding window approach was leveraged in [<xref ref-type="bibr" rid="c23">23</xref>] to explore gene subsets for these types of features more comprehensively. To keep our feature space small, given our small dataset, we did not use the same approach here. Future studies with more data will be able to accommodate similar, more comprehensive feature spaces. Several reports, [<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c22">22</xref>-<xref ref-type="bibr" rid="c24">24</xref>], discuss the influences of mRNA structure around the ribosome binding site and the beginning of the codon sequence on gene-expression levels. Based on these results, we also computed mRNA folding free energy for the coding sequence alone, the coding sequence plus the RBS and the RBS plus the first ten codons in the coding sequence.</p>
<p>Other features were theoretical metrics of information changes in the modified genes, where information is measured using alphabets of codons or base pairs, relative to the wild-type gene sequence. Feature abbreviations and descriptions are given in <xref ref-type="table" rid="tbl2">Table 2</xref>. The KL divergence computations on codon histograms from each gene were computed using additive (Laplace) smoothing [<xref ref-type="bibr" rid="c25">25</xref>-<xref ref-type="bibr" rid="c27">27</xref>] to address the fact that not all possible codons were observed in every gene. All features, other than those comparing codon and base pair frequencies in the genes, were computed as a ratio of the feature from the modified sequence divided by the feature computed for the wild-type sequence. This was done to assure all features spanned a similar range. Dividing by the length of the gene normalized the Hamming distance and we used a normalized mutual information metric that bounds the values within [0 1]. KL divergence values remained within [0 3] for all genes changed with all codon-usage algorithms. Normalization was unnecessary for this feature.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><p>Feature descriptions. <sup>&#x0002A;</sup> CAI features are computed for subsets of the gene informed by observations of a &#x201C;codon-ramp&#x201D; about 30-60 base pairs into the coding sequence [<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c17">17</xref>-<xref ref-type="bibr" rid="c22">22</xref>] and by possibility of other salient subsequences. <sup>&#x0002A;&#x0002A;</sup> mRNA folding free energy features are computed for subsets of the genes informed by observations of the influence of secondary structure between the RBS and different parts of the coding sequence on expression levels and translation rates [<xref ref-type="bibr" rid="c22">22</xref>-<xref ref-type="bibr" rid="c24">24</xref>].</p></caption>
<graphic xlink:href="363812_tbl2.tif"/>
</table-wrap>
<p>To maximize generalizability of our performance estimates, we implemented a nested cross-validation (CV) involving two tiers (cf. <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>). In the outer tier, depicted in blue in both figures, a test set of ten was selected randomly without replacement from an exhaustive set of all unique combinations of ten observations including five sequence changes associated with a design failure and five sequence changes associated with a design success. This left thirty-seven observations for training the model in the outer tier and for use in an inner CV tier, green and gray in both figures, to learn optimal parameters for the model (meta-learning). The inner tier consisted of exhaustive leave-pair-out cross validation (LPOCV), holding out one observation with a design success and one with a design failure, on each iteration. This CV tier was used to optimize three meta-parameters: the number of features &#x007B;4,5,6,7&#x007D; to be included in the model, the threshold on the soft classification for binary design success/failure prediction and whether to include correlated features in the selected set or not.</p>
<p>To eliminate correlated features when testing whether their presence impactimpacts classifier performance, if two feature had a Spearman&#x2019;s correlation higher than |0.6|, we removed the feature with the smallest Cohen&#x2019;s d value from the set of features used in the feature selection process. Sets of four to seven features with the largest magnitude Cohen&#x2019;s d effect size in design success/failure discrimination were selected for each inner CV training set of 35 and the test pair was classified using selected features. The number of features with the best area under the ROC curve (AUC) from the LPOCV was used as the number of features to be selected in the outer CV step using the training set of 37.</p>
<p>Finally, from the ROC curve produced from the inner CV loop with the best AUC, we also identified a classification threshold. We chose this threshold to occur at the operating point at which we reach 90&#x0025; sensitivity with the fewest possible false alarms. We chose this point because this tool is intended to decrease the risk of running genetic code experiments with codon-usage modifications likely to result in design failure. Misclassifying a significant number of codes that would result design success as resulting in design failure does not entail as much risk in terms of lost time and money. In other words, type II errors are costlier than type I errors in this domain and the classification threshold was set to account for the asymmetric risk.</p>
<p>A Gaussian classifier and a soft-margin SVM with a linear kernel were trained using these data and these features. We chose simple classifiers because our dataset was small and complex classifiers are more likely to over-fit to spurious patterns in the training data. These models were then used to predict the classes of the ten held-out data points in the outer CV loop. This loop was iterated 1000 times for 1000 different subsets of 10 held-out observations. AUC, sensitivity and specificity was computed for each of the 1000 iterations and averages over each metric estimate overall performance of the SVM and GC on this dataset. The complexity and rigor of this validation methodology was necessary to achieve generalizable performance estimates with our small dataset.</p>
</sec>
<sec id="s4c">
<title>Definition of Nine Novel Codon-Usage Algorithms</title>
<p>As mentioned above, we used our model to predict <italic>E. coli</italic> viability when the set of forty genes from <xref ref-type="table" rid="tbl1">Table 1</xref>. were modified with nine novel codon-usage algorithms. All of the algorithms presented here are <italic>reductionist</italic> algorithms, i.e. some codon assignments to amino acids have been removed, leaving those codons blank&#x2014;unassigned to any amino acid. In contrast, a <italic>reconfigured</italic> algorithm would change the assignment from one amino acid to another. We consider reductionist algorithms an important step toward implementing more complex reconfigured algorithms in living cells.</p>
<p>Previous efforts [<xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref>]_reported the removal of one codon throughout the entire genome of MG1655, called the r<italic>E. coli</italic> algorithms. The algorithms designed and evaluated here sample greater extremes, from an intermediate number of changes (removing 11 codons) to bare minimum codes (leaving only one codon for each amino acid, removing roughly two-thirds of the natural 64 codons).</p>
<sec id="s4c1">
<title>Sub<sub>11</sub></title>
<p>This set subtracts 11 codons from the canonical genetic code. These codons are used at low frequencies within MG1655 genes. We hypothesize that this set would remove enough codons to provide benefits such as strong resistance to bacteriophage infection, while still providing enough choices of synonymous codons to retain flexibility for troubleshooting emergent challenges with genome design and implementation. Modification of the codon usage in the genome combined with deletion of the corresponding tRNA genes is expected to be sufficient for the genomic installation of this code.</p></sec>
<sec id="s4c2">
<title>tRNA<sub>sub1</sub></title>
<p>One version of a code that seeks to minimize the number of naturally-occurring tRNAs retained in the design. With 28 forbidden codons (i.e. 36 natural assignments retained) each amino acid is encoded by one or two codons.</p></sec>
<sec id="s4c3">
<title>tRNA<sub>sub2</sub></title>
<p>A stricter version of a code that minimizes the number of naturally-occurring tRNAs required to represent each amino acid. With 36 forbidden codons (i.e. 28 natural assignments retained) each amino acid is encoded by one or two codons (more often one codon, compared to <underline>tRNA<sub>sub1</sub></underline>).</p>
</sec>
<sec id="s4c4">
<title>Min<sub>curated</sub></title>
<p>The first of several designed codes that theoretically only use one codon to represent each of the standard 20 amino acids. In all such minimal codes (&#x201C;mincodes&#x201D;) 43 codons are forbidden (21 codons remaining, i.e. for natural amino acids plus one stop codon). The mincodes are thus deterministic in the sense that once a gene product is defined at the amino acid sequence, the DNA sequence for the gene is definitively known. Leaving the genome engineer with no choices of DNA sequence flexibility is a considerable drawback for any eventual troubleshooting processes. In this report, all mincodes described are subtractive, only removing codon assignments, not reassigning or re-organizing. The primary means to implement this code would be to extensively modify codon usage in the genome, followed by deleting a large proportion of tRNA genes to be used no longer. However, in order to cleanly remove all forbidden codons from the genetic code, the remaining tRNA genes would also have to be significantly engineered to recognize exactly one codon each (instead of two or three each, which is most typical). This first mincode, <underline>Min<sub>curated</sub></underline>, is labeled &#x201C;curated&#x201D; to denote that several different design principles were considered and integrated by the designer. First, the most commonly used codons in MG1655 were emphasized, with the intent of not disrupting translation of highly expressed essential genes. Several decisions were also made for the purpose of making this code more facile to implement using synthetic DNA. To minimize runs of homopolymers that can be more challenging for DNA synthesis and high throughput sequencing, codons TTT, CCC, and GGG were forbidden. Pairs of codons that could give rise to palindromic repeats were also minimized, to reduce unintended RNA secondary structures as well as to avoid mispriming events during <italic>de novo</italic> DNA synthesis.</p>
</sec>
<sec id="s4c5">
<title>Min<sub>classII</sub></title>
<p>The 21 codons retained in this mincode are those defined as most utilized in highly expressed <italic>E. coli</italic> genes, as categorized by H&#x00E9;naut and Danchin (&#x201C;Class II&#x201D;) [<xref ref-type="bibr" rid="c28">28</xref>].</p>
</sec>
<sec id="s4c6">
<title>Min<sub>sparse</sub></title>
<p>43 codons are forbidden, with the remaining allowed codon assignments chosen specifically to maximize the genetic distance between codons. Put another way, most single base mutations give rise to a forbidden codon. For example with the allowed alanine codon (GCG) only one of the possible nine single mutations gives rise to another allowed codon (to CCG, proline). Thus, the majority of spontaneous single-base mutations that arise would be expect to yield a null (i.e. unassigned) codon, disrupting translation and giving rise to defective protein products.</p>
</sec>
<sec id="s4c7">
<title>Min<sub>ATmax</sub></title>
<p>The 21 codons of this mincode were chosen in order to yield the highest possible content of A:T base pairs. This design principle was chosen in order to explore one extreme of thermodynamics (e.g. self-folding energies)</p>
</sec>
<sec id="s4c8">
<title>Min<sub>GCmax</sub></title>
<p>The 21 codons of this mincode were chosen in order to yield the highest possible content of G:C base pairs. This design principle was chosen in order to explore the other extreme of thermodynamics (e.g. self-folding energies)</p>
</sec>
<sec id="s4c9">
<title>Min<sub>weak</sub></title>
<p>The 21 codons of this mincode were chosen according to the codons least used in MG1655 for each amino acid. Thus genes modified according to Min<sub>weak</sub> are expected to require the most extensive degree of change from the wild-type sequence.</p>
<p>To be fully implemented in living cells, all minimal algorithms would also require extensive engineering not only of genome-wide codon usage in protein-coding reading frames, but also of the tRNAs that recognize these codons. Otherwise many forbidden codons would still be recognizable by the remaining tRNAs due to wobble base-pairing between codons and anticodons. See <xref ref-type="table" rid="tbl3">Table 3</xref>. for a synoptic depiction of these nine codes as well as the FC, FCS and <italic>rE. coli</italic> codes.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><p>Depiction of the nine, novel codes as well as the <italic>rE. coli</italic>-1.0, <italic>rE. coli</italic>-57, FC and FCS codes. Blacked out boxes indicate disallowed codons for a given amino acid and codes are shown in descending order, from the fewest to the most codons removed. Standard symbols for amino acids are used.</p></caption>
<graphic xlink:href="363812_tbl3.tif"/>
</table-wrap>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><p>Performance metrics along with 95&#x0025; confidence intervals for the SVM and GC classifiers. These results demonstrated that there was information in the selected features to predict design success/failure due to codon-usage modifications from the FCS and FC algorithms. Furthermore, at the 5&#x0025; significance level, the GC AUC was better than that of the SVM with a linear kernel.</p></caption>
<graphic xlink:href="363812_tbl4.tif"/>
</table-wrap>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5.</label>
<caption><p>Genes modified with particular codes that were classified as design failures using our model trained on the 40 genes modified with the FC and FCS algorithms. Of the nine algorithms we tested, only two are predicted fail, tRNA<sub>sub2</sub> and Min<sub>weak</sub>. Min<sub>weak</sub> was the most disruptive to colony formation, according to our model, since many genes modified with this algorithm were classified as failing by both the GC and SVM. Several genes (highlighted in blue) appear to be more sensitive being modified than others. These genes are predicted to result in a design failure under both tRNA<sub>sub2</sub> and Min<sub>weak</sub> for the SVM and are classified failing by the GC under Min<sub>weak</sub>. They also resulted in a design failure when modified with the FCS algorithm and implemented <italic>in vivo</italic> in [<xref ref-type="bibr" rid="c3">3</xref>]. These may be good &#x201C;bellwether&#x201D; gene candidates in the sense that different modifications to them appear more likely to fail.</p></caption>
<graphic xlink:href="363812_tbl5.tif"/>
</table-wrap>
<p>Next, we learned a model trained on the entire FC and FCS dataset to be used to classify the new data from the nine codes described above. We determined which features were most predictive design suc
cess/failure classification and trained SVM and GC classifiers. Model parameters, including the number of features to used for classification, whether to include correlated predictors or not and the classification threshold, were learned using a LPOCV, as in the nested cross-validation study described above.</p>
</sec>
</sec>
<sec id="s4d">
<title>Software/Hardware</title>
<p>We performed <italic>in silico</italic> codon usage modifications for the nine novel codes and most feature computations with scripts written in Python and packages from Scikit Learn (normalized_mutual_info_score) and Scipy (stats). To compute the mRNA folding free energy features, we used an open-source package called The Vienna RNA Package [<xref ref-type="bibr" rid="c29">29</xref>]. To efficiently implement the expensive nested cross validation pipeline for the SVM and GC, we used Matlab code and pMatlab [<xref ref-type="bibr" rid="c30">30</xref>], a capability enabling Matlab parallel processing across hundreds of cores, and the MIT/MIT Lincoln Lab supercomputing facilities at Holyoke, MA.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>All experimental data we used to test and train the classifier was collected during the experiments reported in [<xref ref-type="bibr" rid="c5">5</xref>] and shared with us by Dr. Marc Lajoie. We are extremely grateful for his contributions to this work. These also include extensive and very insightful feedback on the manuscript and results. We also thank Dr. Nicholas Guido for his detailed review of the work and helpful comments, Anna Shcherbina for providing a Python code template to use for substituting codons <italic>in silico</italic> and Siddharth Samsi for providing a code template for running the nested cross validation in parallel using pMatlab [<xref ref-type="bibr" rid="c30">30</xref>] on the MIT Lincoln Laboratory supercomputing cluster. This work is sponsored by the Assistant Secretary of Defense for Research &#x0026; Engineering under Air Force Contract no. FA8721-05-C-0002. Opinions, interpretations, conclusions and recommendations are those of the author and are not necessarily endorsed by the United States Government. Research reported in this publication was supported by the National Cancer Institute of the National Institutes of Health under award number R01CA173712.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Isaacs</surname>, <given-names>F. J.</given-names></string-name>, <string-name><surname>Carr</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>H. H.</given-names></string-name>, <string-name><surname>Lajoie</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Sterling</surname>, <given-names>B.</given-names></string-name>, <etal>et al.</etal> (<year>2011</year>). <article-title>Precise manipulation of chromosomes in vivo enables genome-wide codon replacement</article-title>. <source>Science</source>, <volume>333</volume>(<issue>6040</issue>), <fpage>348</fpage>&#x2013;<lpage>353</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Lajoie</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Rovner</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>D. B.</given-names></string-name>, <string-name><surname>Aerni</surname>, <given-names>H. R.</given-names></string-name>, <collab>Haimovich</collab>, <etal>et al.</etal> (<year>2013</year>). <article-title>Genomically recoded organisms expand biological functions</article-title>. <source>Science</source>, <volume>342</volume>(<issue>6156</issue>), <fpage>357</fpage>&#x2013;<lpage>360</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><collab>Mandell</collab>, <string-name><surname>Daniel</surname> <given-names>J.</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Biocontainment of genetically modified organisms by synthetic protein design.&#x201D;</article-title> <source>Nature</source> <volume>518.7537</volume> (<year>2015</year>): <fpage>55</fpage>&#x2013;<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><collab>Rovner</collab>, <string-name><surname>Alexis</surname> <given-names>J.</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Recoded organisms engineered to depend on synthetic amino acids.&#x201D;</article-title> <source>Nature</source> <volume>518.7537</volume> (<year>2015</year>): <fpage>89</fpage>&#x2013;<lpage>93</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Lajoie</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Kosuri</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mosberg</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Gregg</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>D.</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>). <article-title>Probing the limits of genetic recoding in essential genes</article-title>. <source>Science</source>, <volume>342</volume>(<issue>6156</issue>), <fpage>361</fpage>&#x2013;<lpage>363</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Ostrov</surname>, <given-names>Nili</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Design, synthesis, and testing toward a 57-codon genome.&#x201D;</article-title> <source>Science</source> <volume>353.6301</volume> (<year>2016</year>): <fpage>819</fpage>&#x2013;<lpage>822</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Karr</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Sanghvi</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Macklin</surname>, <given-names>D. N.</given-names></string-name>, <string-name><surname>Gutschow</surname>, <given-names>M. V.</given-names></string-name>, <string-name><surname>Jacobs</surname>, <given-names>J. M.</given-names></string-name>, <etal>et al.</etal> (<year>2012</year>). <article-title>A whole-cell computational model predicts phenotype from genotype</article-title>. <source>Cell</source>, <volume>150</volume>(<issue>2</issue>), <fpage>389</fpage>&#x2013;<lpage>401</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Thiele</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Jamshidi</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Fleming</surname>, <given-names>R. M.</given-names></string-name>, &#x0026; <string-name><surname>Palsson</surname>, <given-names>B. &#x00D8;.</given-names></string-name> (<year>2009</year>). <article-title>Genome-scale reconstruction of Escherichia coli&#x2019;s transcriptional and translational machinery: a knowledge base, its mathematical formulation, and its functional characterization</article-title>. <source>PLoS Computational Biology</source>, <volume>5</volume>(<issue>3</issue>), <fpage>e1000312</fpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Lerman</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Hyduke</surname>, <given-names>D. R.</given-names></string-name>, &#x0026; <string-name><surname>Palsson</surname>, <given-names>B. &#x00D8;.</given-names></string-name> (<year>2013</year>). <article-title>Genome-scale models of metabolism and gene expression extend and refine growth phenotype prediction</article-title>. <source>Molecular Systems Biology</source>, <volume>9</volume>(<issue>1</issue>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Tlusty</surname>, <given-names>Tsvi</given-names></string-name>. <article-title>&#x201C;A colorful origin for the genetic code: Information theory, statistical mechanics and the emergence of molecular codes.&#x201D;</article-title> <source>Physics of life reviews</source> <volume>7.3</volume> (<year>2010</year>): <fpage>362</fpage>&#x2013;<lpage>376</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><collab>Baca</collab>, <string-name><surname>Arthur</surname> <given-names>M.</given-names></string-name>, and <string-name><surname>Wim</surname> <given-names>GJ Hol</given-names></string-name>. <article-title>&#x201C;Overcoming codon bias: a method for high-level overexpression of Plasmodium and other AT-rich parasite genes in Escherichia coli.&#x201D;</article-title> <source>International journal for parasitology</source> <volume>30.2</volume> (<year>2000</year>): <fpage>113</fpage>&#x2013;<lpage>118</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Sharp</surname>, <given-names>P. M.</given-names></string-name>, &#x0026; <string-name><surname>Li</surname>, <given-names>W. H.</given-names></string-name> (<year>1987</year>). <article-title>The codon adaptation index-a measure of directional synonymous codon usage bias, and its potential applications</article-title>.<source>Nucleic Acids Research</source>, <volume>15</volume>(<issue>3</issue>), <fpage>1281</fpage>&#x2013;<lpage>1295</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><collab>Plotkin</collab>, <string-name><surname>Joshua</surname> <given-names>B.</given-names></string-name>, and <string-name><surname>Grzegorz</surname> <given-names>Kudla</given-names></string-name>. <article-title>&#x201C;Synonymous but not the same: the causes and consequences of codon bias.&#x201D;</article-title> <source>Nature Reviews Genetics</source> <volume>12.1</volume> (<year>2011</year>): <fpage>32</fpage>&#x2013;<lpage>42</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Shmueli</surname>, <given-names>Galit</given-names></string-name>. <article-title>&#x201C;To explain or to predict?.&#x201D;</article-title> <source>Statistical science</source> <volume>25.3</volume> (<year>2010</year>): <fpage>289</fpage>&#x2013;<lpage>310</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Makridakis</surname>, <given-names>Spyros</given-names></string-name>, <string-name><surname>Steven</surname> <given-names>C.</given-names></string-name> <collab>Wheelwright</collab>, and <string-name><surname>Rob</surname> <given-names>J. Hyndman</given-names></string-name>. <article-title>Forecasting methods and applications</article-title>. <source>John Wiley &#x0026; Sons</source>, <year>2008</year>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="website"><ext-link ext-link-type="uri" xlink:href="http://ecocyc.org/">http://ecocyc.org/</ext-link></mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Tuller</surname>, <given-names>Tamir</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Translation efficiency is determined by both codon bias and folding energy.&#x201D;</article-title> <source>Proceedings of the National Academy of Sciences</source> <volume>107.8</volume> (<year>2010</year>): <fpage>3645</fpage>&#x2013;<lpage>3650</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Bulmer</surname>, <given-names>Michael</given-names></string-name>. <article-title>&#x201C;Codon usage and intragenic position.&#x201D;</article-title> <source>Journal of theoretical biology</source> <volume>133.1</volume> (<year>1988</year>): <fpage>67</fpage>&#x2013;<lpage>71</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Novoa</surname>, <given-names>E. M.</given-names></string-name>, &#x0026; <string-name><surname>Ribas de Pouplana</surname>, <given-names>L.</given-names></string-name> (<year>2012</year>). <article-title>Speeding with control: codon usage, tRNAs, and ribosomes</article-title>. <source>Trends in Genetics</source>, <volume>28</volume>(<issue>11</issue>), <fpage>574</fpage>&#x2013;<lpage>581</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Qin</surname>, <given-names>Hong</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Intragenic spatial patterns of codon usage bias in prokaryotic and eukaryotic genomes.&#x201D;</article-title> <source>Genetics</source> <volume>168.4</volume> (<year>2004</year>): <fpage>2245</fpage>&#x2013;<lpage>2260</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Tuller</surname>, <given-names>Tamir</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;An evolutionarily conserved mechanism for controlling the efficiency of protein translation.&#x201D;</article-title> <source>Cell</source> <volume>141.2</volume> (<year>2010</year>): <fpage>344</fpage>&#x2013;<lpage>354</lpage></mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Kudla</surname>, <given-names>Grzegorz</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Coding-sequence determinants of gene expression in Escherichia coli.&#x201D;</article-title> <source>science</source> <volume>324.5924</volume> (<year>2009</year>): <fpage>255</fpage>&#x2013;<lpage>258</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Gu</surname>, <given-names>Wanjun</given-names></string-name>, <string-name><surname>Tong</surname> <given-names>Zhou</given-names></string-name>, and <string-name><given-names>Claus O.</given-names> <surname>Wilke</surname></string-name>. <article-title>&#x201C;A universal trend of reduced mRNA stability near the translation-initiation site in prokaryotes and eukaryotes.&#x201D;</article-title> <source>PLoS Comput Biol</source> <volume>6.2</volume> (<year>2010</year>): <fpage>e1000664</fpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Bo&#x00EB;l</surname>, <given-names>Gr&#x00E9;gory</given-names></string-name>, <etal>et al.</etal> <article-title>&#x201C;Codon influence on protein expression in E. coli correlates with mRNA levels.&#x201D;</article-title> <source>Nature</source> <volume>529.7586</volume> (<year>2016</year>): <fpage>358</fpage>&#x2013;<lpage>363</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Sch&#x00FC;tze</surname>, <given-names>Hinrich</given-names></string-name>. <article-title>&#x201C;Introduction to Information Retrieval.&#x201D;</article-title> <source>Proceedings of the international communication of association for computing machinery conference</source>. <year>2008</year>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Martin</surname>, <given-names>James H.</given-names></string-name>, and <string-name><surname>Daniel</surname> <given-names>Jurafsky</given-names></string-name>. <article-title>&#x201C;Speech and language processing.&#x201D;</article-title> <source>International Edition</source> <volume>710</volume> (<year>2000</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Russell</surname>, <given-names>Stuart Jonathan</given-names></string-name>, <etal>et al.</etal> <article-title>Artificial intelligence: a modern approach</article-title>. Vol. <volume>2</volume>. <source>Upper Saddle River: Prentice hall</source>, <year>2003</year>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="book"><string-name><surname>Henaut</surname>, <given-names>A.</given-names></string-name>, and <string-name><given-names>A.</given-names> <surname>Danchin</surname></string-name>. <chapter-title>&#x201C;Analysis and predictions from Escherichia coli sequences, or E. coli in silico.&#x201D;</chapter-title> <source>Escherichia coli and Salmonella: cellular and molecular biology</source>. <publisher-loc>ASM Press, Washington, DC</publisher-loc> (<year>1996</year>): <fpage>2047</fpage>&#x2013;<lpage>2066</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Steffen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Vo&#x00DF;</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Rehmsmeier</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Reeder</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Giegerich</surname>, <given-names>R.</given-names></string-name> (<year>2006</year>). <source>RNAshapes: an integrated R</source></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Bliss</surname>, <given-names>N. Travinin</given-names></string-name>, and <string-name><surname>Jeremy</surname> <given-names>Kepner</given-names></string-name>. <article-title>&#x201C;&#x2019;pMATLAB Parallel MATLAB Library&#x2019;.&#x201D;</article-title> <source>International Journal of High Performance Computing Applications</source> <volume>21.3</volume> (<year>2007</year>): <fpage>336</fpage>&#x2013;<lpage>359</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Kullback</surname>, <given-names>Solomon</given-names></string-name>. <source>&#x201C;Letter to the editor: The Kullback-Leibler distance.&#x201D;</source> (<year>1987</year>): <fpage>340</fpage>&#x2013;<lpage>341</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Settles</surname>, <given-names>Burr</given-names></string-name>. <article-title>&#x201C;Active learning literature survey.&#x201D;</article-title> <source>University of Wisconsin, Madison</source> <volume>52</volume>.<fpage>55</fpage>&#x2013;<lpage>66</lpage> (<year>2010</year>): 11.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<title>Appendix</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1.</label>
<caption><p>Convex hull plots for four of the nine novel codes we defined and investigated as possible candidates for genetic code engineering. All five features selected in the uncorrelated feature selection routine for the SVM are plotted pairwise. Note that the convex hulls of the genes recoded with the tRNA-sub2 algorithm, one of the two algorithms predicted to result in a design failure by the two classifiers, are consistently closest to the lethal training examples. Min-GCMax and Min-classII convex hulls overlap significantly in these plots, indicating that the two algorithms effect the forty genes similarly in the feature space salient for design failure prediction. The Sub-11 convex hull is separate from those of the other codes and closest to the wild type origin. It is also the smallest convex hull in all feature plots, signifying that all forty genes are similarly influenced by this code.</p></caption>
<graphic xlink:href="363812_figS1.tif"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2.</label>
<caption><p>Convex hull plots for the five of the nine novel codes not depicted in <xref ref-type="fig" rid="figS1">Figure S1</xref>. The Min-weak convex hull is closest to the lethal training examples and is the smallest in most of the feature plots. This indicates that, when recoded with this code, the forty genes are effected similarly each other and to the lethal training examples that were recoded using the FCS algorithm. There is significant overlap among the Min-sparse and Min-curated convex hulls. These codes effected the forty genes similarly in the salient feature space, both in terms of the absolute placement and of the size and shape of the convex hulls. Min-ATmax effects the genes in a somewhat similar fashion but, on average, has a smaller convex hull in the pair wise plots, indicating that the genes were more consistently effected in the same way relative to wild-type with this code. tRNA-sub1, the code with the fewest disallowed codons, is always the closest to the wild-type origin, relative to the other convex hull plots.</p></caption>
<graphic xlink:href="363812_figS2.tif"/>
</fig>
</app>
</app-group>
</back>
</article>
