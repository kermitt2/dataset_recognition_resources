<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/407072</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioengineering</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Frame Rate Up-Conversion in Echocardiography Images, Using Manifold-Learning and Image Registration</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Daneshi</surname><given-names>A.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Behnam</surname><given-names>H.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Sani</surname><given-names>Z. Alizadeh</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Electrical Engineering Department, Iran University of Science and Technology</institution>, Narmak, Tehran, <country>Iran</country>. <email>asiyehdaneshi@gmail.com</email></aff>
<aff id="a2"><label>2</label><institution>Rajaie Cardiovascular Medical &#x0026; Research Center, Tehran University of Medical Science</institution>, Tehran,<country>Iran</country></aff>
</contrib-group>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>407072</elocation-id>
<history>
<date date-type="received">
<day>03</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>03</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>03</day>
<month>9</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="407072.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract><title>ABSTRACT</title>
<p>In this paper, we propose a new temporal frame interpolation algorithm for frame rate up-conversion (FRUC) in echocardiography images. This algorithm employs a combination of dimension reduction techniques and image registration to increase frame rate.</p>
<p>If the distance between two successive frames of a video be great, motion jerkiness will appear between them and visual quality of the video will decrease. Some parts of heart have a very high speed motion, and echocardiography videos, obtained by available systems can&#x2019;t take enough number of frames to show them well. So, to achieve an echocardiography image set with a better visual quality, more frames are necessary between two frames at a great distance. Here, we use dimension reduction techniques to find out the number of suitable frames between two consecutive frames to show the fast motions better, but don&#x2019;t take much time. We project images to a 3-dimentional space by this way. Greater difference between the frames, results greater distance between corresponding embedded points. Thus, the distance between the embedded points is a scale for the suitable number of frames, needed between two successive frames. These frames are produced with the registration techniques.</p>
<p>On the other hand, heart doesn&#x2019;t have a constant speed during a cycle, but echocardiography images are recorded with constant speed. So, frames at a greater distance show fast motions of the heart, and frames at a lower distance show slow motions of the heart. While, we put unequal number of frames between successive frames, and in this way remove temporal coordination of the image set. To solve this problem, we put efficient number of linear average of available frames, in places that the number of inserted frames in between available frames is less than maximum to obtain an equal number of frames between all successive frames.</p>
</abstract>
<kwd-group kwd-group-type="author"><title>KEYWORDS</title>
<kwd>frame rate up-conversion</kwd>
<kwd>echocardiography</kwd>
<kwd>manifold learning</kwd>
<kwd>image registration</kwd>
</kwd-group>
<counts>
<page-count count="20"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><label>1.</label><title>Introduction</title>
<p>Echocardiography has become the predominant imaging modality in diagnostic cardiology, because it is noninvasive, inexpensive, and able to show moving parts in real-time. However, transient small motion of the heart wall and valves can&#x2019;t be shown properly using low frame-rate imaging techniques. High frame rate is especially important in studying intra-cardiac structures where valve closure times are on the order of micro seconds. Current of-the-shelf ultrasound imaging systems have a limited frame rate because of the time it takes to send and receive all of the ultrasound beams necessary to reconstruct an image. While this frame rate is sufficient for real time human observation of basic ventricular function and assessment valve ability, understanding cardiac dynamics requires greater frame rates.</p>
<p>Several alternative methods have been developed to increase the ultrasound frame rate such as coded-excitation ultrasound imaging [<xref ref-type="bibr" rid="c1">1</xref>]&#x2013;[<xref ref-type="bibr" rid="c7">7</xref>] and parallel processing techniques [<xref ref-type="bibr" rid="c8">8</xref>]&#x2013;[<xref ref-type="bibr" rid="c10">10</xref>]. Some others increased the frame rate by reducing the size of the field of view and the total number of beams [<xref ref-type="bibr" rid="c11">11</xref>], [<xref ref-type="bibr" rid="c12">12</xref>]. The echocardiogram (ECG)-gating technique in ultrasound imaging is another method, recently introduced [<xref ref-type="bibr" rid="c13">13</xref>]. It divides the total field of view to seven equal sectors, and takes ECG signal and echocardiography images of each sector simultaneously. Then, combines the individual sectors into a large field-of-view at high beam density and also attains high frame rates. This last method assumes all heart cycles during a breath are the same. Also, because the respiratory motion could affect the heart&#x2019;s position, breath-holding during the entire scan was required for higher composite imaging performance. Another is the digital scan converter (DSC) introduced by Chang et al. [<xref ref-type="bibr" rid="c14">14</xref>]. In this technique, a sparse beam array is send to the heart and a low quality image is produced in a short time. Then, a number of pixels are interpolated between available pixels. This method is useful for the small cases, such as mouse, which need a small depth of penetration.</p>
<p>Frame rate up-conversion (FRUC) is to increase the frame rate of a video by interpolating new frames and inserting them in between consecutive frames. Generally, FRUC can be classified into two groups. The first group interpolates the skipped frame along temporal axis without taking the object motion into account. Methods such as frame repetition (FR) and frame averaging (FA) belong to this group. These algorithms are very simple; but, produce &#x201C;jerkiness&#x201D; into the motion portrayal and blurriness on object boundaries [<xref ref-type="bibr" rid="c15">15</xref>]. The second group, named motion-compensated interpolation (MCI), interpolates the skipped frames along motion trajectory exploiting motion information between current successive frames [<xref ref-type="bibr" rid="c16">16</xref>]. Second group is more accurate than first group.</p>
<p>Fujiwara and Taguchi proposed a MCI method based on block matching algorithm (BMA). Since the property of the BMA is changed by the size of the blocks, it is desirable for small moving objects to set block size small, and in global motion region to set the block size large. Fujiwara and Taguchi used multi-size blocks and obtained less block artifact and more clear images [176].</p>
<p>Thaipanich and Wu proposed a MCI method for the cases that input video has abrupt illumination change and/or a very low frame rate [<xref ref-type="bibr" rid="c18">18</xref>]. However, because echocardiography images don&#x2019;t have sudden changes in illumination and also satisfy a low threshold for frame rate, this method is not practical in these images.</p>
<p>We present a low complexity technique for exploiting the relationship between successive frames using the manifold learning algorithm and then interpolating new frames between available frames using MCI and FA.</p>
<p>The remains of this paper are organized as follows. The <xref ref-type="sec" rid="s2">section 2</xref> gives a mathematical background of the manifold learning algorithm and registration technique used here. <xref ref-type="sec" rid="s3">Section 3</xref> shows the results and <xref ref-type="sec" rid="s4">section 4</xref> presents the discussions. Finally, <xref ref-type="sec" rid="s5">section 5</xref> concludes this paper.</p>
</sec>
<sec id="s2"><label>2.</label><title>Materials and Methods</title>
<sec id="s2a"><label>2.1</label><title>Materials</title>
<p>Used Manifold learning Algorithm (LLE)</p>
<p>Manifold learning algorithms attempt to expose intrinsic parameters in order to find a low-dimensional representation of the data.</p>
<p>Suppose that the original data consists of <italic>n</italic> data samples (observations) of the <italic>X</italic> data-set with dimension <italic>D</italic>. The Locally Linear Embedding (LLE) algorithm projects these observations into a new data-set <italic>Y</italic> consisting of <italic>n</italic> points with dimension <italic>d</italic> (where <italic>d</italic> &#x003C;<italic>D</italic> and often <italic>d</italic> &#x226A;<italic>D</italic>), while retaining the geometry of the data such as possible:
<disp-formula id="ueqn1"><alternatives><graphic xlink:href="407072_ueqn1.gif"/></alternatives></disp-formula></p>
<p>The embedding is optimized to preserve the local configurations of nearest neighbors. Keeping geometry of data is important in our proposed method, so, LLE algorithm is suitable here.</p>
<p>As shown in <xref ref-type="fig" rid="fig1">figure (1)</xref>, LLE can be represented in three main steps [<xref ref-type="bibr" rid="c19">19</xref>]:</p>
<fig id="fig1" position="float" fig-type="figure"><label>Figure 1:</label>
<caption><p>Summary of the LLE algorithm, mapping high dimensional inputs <inline-formula><alternatives><inline-graphic xlink:href="407072_inline5.gif"/></alternatives></inline-formula> to low dimensional outputs <inline-formula><alternatives><inline-graphic xlink:href="407072_inline6.gif"/></alternatives></inline-formula> via local linear reconstruction weights W<sub><italic>ij</italic></sub>. (The image is reproduced from [<xref ref-type="bibr" rid="c19">19</xref>]).</p></caption>
<graphic xlink:href="407072_fig1.tif"/>
</fig>
<p>Identify the <italic>k</italic> nearest neighbors for each data point. This can be done in two ways. (a) Having a constant <italic>k</italic>, find the <italic>k</italic> nearest neighbors as measured by Euclidian distance. (b) Determine data points which have a determined distance (radius of neighborhood) from that specific data point.</p>
<p>Model the manifold as a collection of linear patches and attempt to characterize the geometry of these linear patches. To do so, attempt to represent <italic>x<sub>i</sub></italic> as a weighted, convex combination of its nearest neighbors. These linear weights <italic>w<sub>ij</sub></italic>, must be chosen to minimize the following cost function
<disp-formula id="eqn1"><alternatives><graphic xlink:href="407072_eqn1.gif"/></alternatives></disp-formula></p>
<p>The weight matrix Wis used as a surrogate for the local geometry of the patches. Intuitively, <italic>W<sub>i</sub></italic> reveals the layout of the points around <italic>x<sub>i</sub></italic>. There are a couple of constraints on the weights: each row must sum to one <inline-formula><alternatives><inline-graphic xlink:href="407072_inline1.gif"/></alternatives></inline-formula> equivalently, each point is represented as a convex combination of its neighbors, and <italic>w<sub>ij</sub></italic> = 0 for <italic>j</italic> &#x003C; <italic>k</italic>. The second constraint reflects that LLE is a local method; the first makes the weights invariant to global translations: if each <italic>x<sub>i</sub></italic> is shifted by&#x03B1;, then
<disp-formula id="eqn2"><alternatives><graphic xlink:href="407072_eqn2.gif"/></alternatives></disp-formula></p>
<p>So <italic>W</italic> is unaffected. Moreover, <italic>W</italic> is invariant to global rotations and scalings. Fortunately, there is a closed form solution for <italic>W</italic>, which may be derived using Lagrange multipliers. In particular, the reconstruction weights for each point <italic>x<sub>i</sub></italic> are given by
<disp-formula id="ueqn2"><alternatives><graphic xlink:href="407072_ueqn2.gif"/></alternatives></disp-formula></p>
<p>Where <italic>C</italic> is the local covariance matrix with entries <inline-formula><alternatives><inline-graphic xlink:href="407072_inline2.gif"/></alternatives></inline-formula>, and <italic>&#x03B7;<sub>i</sub></italic> (and) <italic>&#x03B7;<sub>k</sub></italic> are neighbors of <inline-formula><alternatives><inline-graphic xlink:href="407072_inline3.gif"/></alternatives></inline-formula> is then transformed into the sparse <italic>n</italic> &#x00D7; <italic>n</italic> matrix <inline-formula><alternatives><inline-graphic xlink:href="407072_inline4.gif"/></alternatives></inline-formula> is the <italic>l</italic>th neighbor of <italic>x<sub>i</sub></italic>, and is 0 if <italic>j</italic> &#x2209; <italic>N</italic>(<italic>j</italic>)</p>
<p><italic>W<sub>i</sub></italic> is a characterization of the local geometry around <italic>x<sub>i</sub></italic> of the manifold. Since it is invariant to rotations, scaling, and translations, <italic>W<sub>i</sub></italic> will also characterize the local geometry around <italic>x<sub>i</sub></italic> for any linear mapping of the neighborhood patch surround <italic>x<sub>i</sub></italic>. We expect that the chart from this neighborhood patch to the parameter space should be approximately linear since the manifold is smooth. Thus, <italic>W<sub>i</sub></italic> should capture the local geometry of the parameter space as well. The next step of the algorithm finds a configuration in d-dimension (the dimensionality of the parameter space) whose local geometry is characterized well by <italic>W</italic>. <italic>d</italic> must be known a priori or estimated.</p>
<p>Learn embedding which preserves the reconstruction weights. In this step, each low dimensional output <italic>y<sub>i</sub></italic> is mapped by a high dimensional input xi quoting global internal coordinates on the manifold. This, however, is possible by selecting the d-dimensional coordinates of each output <italic>y<sub>i</sub></italic> to minimize the following cost function:
<disp-formula id="eqn3"><alternatives><graphic xlink:href="407072_eqn3.gif"/></alternatives></disp-formula></p>
<p>Where <inline-formula><alternatives><inline-graphic xlink:href="407072_ueqn3.gif"/></alternatives></inline-formula></p>
<p>There are a couple of constraints on <italic>Y</italic>. First, <italic>Y<sup>T</sup>Y</italic>= I which forces the solution to be of rank <italic>d</italic>. Second, &#x2211;<sub>i</sub> <italic>Y<sub>i</sub></italic>= 0; this constraint centers the embedding on the origin. This cost function is a form of Rayleigh&#x2019;s quotient, so it is minimized by setting the columns of <italic>Y</italic> to the bottom d eigenvectors of <italic>M</italic>. However, the bottom (eigenvector, eigenvalue) pair is (1,0), so the final coordinate of each point is identical. To avoid this degenerate dimension, the d-dimensional embedding is given by the bottom non-constant d eigenvectors [<xref ref-type="bibr" rid="c19">19</xref>].</p>
<p>Here, in the first step, the <italic>K</italic> nearest neighbors for each data sample are determined as measured by the Euclidean distance. The LLE algorithm&#x2019;s outcomes are normally stable over a range of neighborhood sizes [<xref ref-type="bibr" rid="c19">19</xref>]; in this study we chose <italic>k</italic> = 8 nearest neighbors for each data point.</p>
<p>While applying LLE algorithm on a specific image set, each pixel introduces one dimension. So, dimensionality of an image with <italic>N</italic> &#x00D7; <italic>N</italic> pixels is <italic>N</italic><sup>2</sup>. That is a very large number. Making use of manifold learning, we can expose main parameters of echocardiography images and project them into a very low dimensional feature space.</p>
<p>Registration technique</p>
<p>The goal of image registration is to find the optimal transformation <italic>T</italic>, which will map any pixel in the floating image <italic>I<sub>F</sub></italic>(<italic>X,Y</italic>) to its corresponding pixel in the reference image <italic>I<sub>R</sub></italic>(<italic>X,Y</italic>) Floating image should take geometry of reference image, retaining intensity of pixels. To solve this problem, one can consider a number of points in each image, and find their correspondence to each other. Then the problem is to find a mathematical equation which projects these points in the floating image into their corresponding points in the reference image.
<disp-formula id="ueqn4"><alternatives><graphic xlink:href="407072_ueqn4.gif"/></alternatives></disp-formula>
<disp-formula id="ueqn5"><alternatives><graphic xlink:href="407072_ueqn5.gif"/></alternatives></disp-formula></p>
<p>In above formulas, <italic>I<sub>F</sub></italic>(<italic>X,Y</italic>) is the floating image <italic>I<sub>R</sub></italic>(<italic>X,Y</italic>) is the reference image, <italic>N<sub>x</sub></italic> and <italic>N<sub>y</sub></italic> denote dimensions of the image, and <italic>T</italic>= (<italic>T<sub>x</sub></italic>, <italic>T<sub>y</sub></italic>) is the transformation that projects the floating image into the reference image. In reality, image registration transforms the floating image among a number of motion vectors (MVs) to produce an image with the most possible similarity to reference image.</p>
<p>The result of registration is an image which intensity values of its pixels are the same as the first image and its geometry is like the second image.</p>
</sec>
<sec id="s2b"><label>1.</label><title>Experiment</title>
<p>The 2-D apical four chamber image sequences of eight healthy volunteers and two patients (endocardit and prosthetic mitral valve) are acquired using an ultrasound machine (General Electric, vivid 3) with a 1.7 MHz probe, including the ECG recording Echocardiography images are recorded at Rajaie Cardiovascular Medical and Research Center. We processed our method using MATLAB (MathWorksInc, USA) with a standard laptop computer (2 GHz Pentium, 4 GB RAM).</p>
<p>LLE algorithm is executed on these ten volunteer cases echocardiography images. Frame-rates and heart-rates of these cases are shown in table (1). Each frame had 401&#x002A;461 pixels. Using LLE algorithm with k=8 nearest neighbors, a number of consecutive frames were projected into a three-dimensional space called &#x201C;feature space&#x201D;. Figures (2) show the image manifolds of one of the normal cases and endocardit case. Each &#x201C;&#x002A;&#x201D; sign remarks one frame embedded in three-dimensional space.</p>
<fig id="fig2" position="float" fig-type="figure"><label>Figure 2:</label>
<caption><p>left: The three dimensional non-linear embedding of 50 frames of a normal heart (case 1) using LLE algorithm (k=8). Right: The three dimensional non-linear embedding of 50 frames of a heart with endocardit disease using LLE algorithm (k=8).</p></caption>
<graphic xlink:href="407072_fig2.tif"/>
</fig>
<p>We set the dimension of the feature space equal three, because this is the least dimensionality that can catch all of the important elements making difference between frames.</p>
<p>The relationship of two consecutive images was retained during embedding; so, the distance between two successive &#x201C;&#x002A;&#x201D;s was a criterion of the difference between corresponding frames. The average of these lengths was calculated and all of them were divided into this value and rounded to the nearest integer less than or equal to. The result was called characteristic number. The maximum characteristic number showed the suitable number of frames to be inserted among original frames.</p>
<p>Image registration was used where the division and rounding operations yielded a nonzero value. In this cases, motion vectors (MVs) were calculated and cut into a number of smaller vectors with equal length, named as chopped vectors. <xref ref-type="fig" rid="fig3">Figure (3)</xref> illustrates this for the case that difference of two successive images was twofold of the mean difference.</p>
<fig id="fig3" position="float" fig-type="figure"><label>Figure 3:</label>
<caption><p>(a) Two successive frames and one of the motion vectors between them. (b) Sample motion vector divided to two vectors.</p></caption>
<graphic xlink:href="407072_fig3.tif"/>
</fig>
<p>Considering two frames of the cycle, first frame was added with chopped vectors to construct middle frames. Since the number of chopped vectors between each pair of frames was different, to retain timing properties of the cycle, we used linear average of available frames to reach an equal number of frames between each pair of original successive frames. Using registration to produce new frames between two successive frames with a small difference takes a lot of time, but don&#x2019;t give much more information than averaging. So, we don&#x2019;t use registration for all frames.</p>
<p>First, we found out the difference between each characteristic number and the maximum characteristic number. Then, we used below algorithm.</p>
<p>Since maximum characteristic number of echocardiography images was less than three, there was four possible difference numbers. When the difference was zero, linear averaging wasn&#x2019;t applied and all of unoriginal frames were produced using registration algorithm. When the difference was one, we inserted linear average of first frame and first registered frame between these two frames. When the difference was two, we had one registered frame, and inserted the linear average of this frame and two original frames before and after it. When the difference was three, we had no registered frame. So we inserted linear average of the two original frames between them; then, inserted average of this new frame and original frames before and after it.</p>
<p><xref ref-type="fig" rid="fig4">Figure (4)</xref> illustrates this for the case that maximum characteristic number was three. Applying above algorithm on 50 frames of normal cases and endocardit and prosthetic mitral valve cases resulted different number of frames, shown in table (1).</p>
<fig id="fig4" position="float" fig-type="figure"><label>Figure 4:</label>
<caption><p>(a) difference= zero. (b) difference= one. (c) difference= two. (d) difference= three.</p></caption>
<graphic xlink:href="407072_fig4.tif"/>
</fig>
</sec>
</sec>
<sec id="s3"><label>3.</label><title>Results</title>
<p>Information about original echocardiography images and the frame rate up converted images is shown in table (1). To obtain proper frame rate, the number of result frames should be divided to the number of embedded frames and multiplied to the original frame rate. But, frame rates higher than 100 frames per second need special software and hardware.</p>
<p>Since maximum characteristic number of echocardiography cycle was less than three, and number of original frames used evaluate presented algorithm was 50, the number of result frames is less than 200.
<disp-formula id="ueqn6"><alternatives><graphic xlink:href="407072_ueqn6.gif"/></alternatives></disp-formula></p>
<p>To evaluate registration algorithm, half of the frames of a normal cardiac cycle were removed. Indeed, even indexed frames were removed. Then, using mentioned registration algorithm, eliminated frames were reproduced. <xref ref-type="fig" rid="fig5">Figure (5)</xref> shows some original and reproduced frames and <xref ref-type="fig" rid="fig6">Figure (6)</xref> shows the squared difference values and the normalized cross correlation values between the first 50 even indexed original and reproduced frames.</p>
<fig id="fig5" position="float" fig-type="figure"><label>Figure 5:</label>
<caption><p>(a) One frame of the normal heart echocardiography. Left: original frame, Right: reproduced frame. (b) One frame of the endocardit case echocardiography. Left: original frame, Right: reproduced frame. (c) One frame of echocardiography of the heart with prosthetic valve. Left: original frame, Right: reproduced frame.</p></caption>
<graphic xlink:href="407072_fig5.tif"/>
</fig>
</sec>
<sec id="s4"><label>4.</label><title>Discussion</title>
<p>Frames shown in <xref ref-type="fig" rid="fig5">figure (5)</xref> are original and reproduced frames using registration technique only. Produced videos, using proposed algorithm are available here.</p>
<p><xref ref-type="fig" rid="fig6">Figure (6)</xref> shows the squared difference values and the normalized cross correlation values between the first 50 even indexed original and reproduced frames. It can be observed that squared differences are very low (close to zero) and the normalized cross correlation is very close to one. So, the frames obtained by mentioned registration algorithm, are very similar to original eliminated frames.</p>
<fig id="fig6" position="float" fig-type="figure"><label>Figure 6:</label>
<caption><p>(a) the squared difference values between the first 50 even indexed original and reproduced frames, (b): the normalized cross correlation values between the first 50 even indexed original and reproduced frames.</p></caption>
<graphic xlink:href="407072_fig6.tif"/>
</fig>
<p>As shown in <xref rid="tbl1" ref-type="table">table 1</xref>, frame rate of original echocardiography sets is usually more than 40 (f/s). So, increasing the number of frames, it is also ordinary to increase the show rate, the same number of times, to achieve an echocardiography set with a rate familiar for the heart specialists. For example, if the frame rate of the original set is 40 (f/s), and the number of frames in the new set is threefold of that in the original set, the frame rate of the new set should be 120 (f/s). However, with the available monitors it is not possible to show frames with a rate more than 100 (f/s). But nonetheless, heart specialists could see more details in echocardiography sets developed with the algorithm proposed in this paper. They do not need to resize echocardiography window to survey valves and other small parts of the heart. In <xref rid="fig4" ref-type="fig">figure 4</xref>, green circles show one of the most important parts for diagnosis. It is clear that produced frame shows this part much better.</p>
<table-wrap id="tbl1" orientation="portrait" position="float"><label>Table 1:</label>
<caption><p>Total information about the three cases participated in this research.</p></caption>
<graphic xlink:href="407072_tbl1.tif"/>
</table-wrap>
</sec>
<sec id="s5"><label>5.</label><title>Conclusion</title>
<p>In this paper, a low complexity FRUC method for echocardiography images is proposed. Our method finds the motion trajectory of echocardiography images and the relationship between consecutive frames. Then uses image registration techniques to find motion vectors among successive frames. Considering these motion vectors, a number of frames are inserted between available frames. At last, to retain timing properties of the image set, some original frames are repeated and the number of inserted frames between each pair if original frames is set equal.</p>
</sec>
</body>
<back>
<ref-list><title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Shen</surname></string-name> and <string-name><given-names>E. S.</given-names> <surname>Ebbini</surname></string-name>, &#x201C;<article-title>Filter-based coded-excitation system for high-speed ultrasonic imaging</article-title>,&#x201D; <source>IEEE Trans. Med. Imaging</source>, vol. <volume>17</volume>, no. <issue>6</issue>, pp. <fpage>923</fpage>&#x2013;<lpage>934</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>J. A.</given-names> <surname>Shen</surname></string-name> and <string-name><given-names>E. S.</given-names> <surname>Ebbini</surname></string-name>, &#x201C;<article-title>A new coded-excitation ultrasound imaging system. Basic principles</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>43</volume>, no. <issue>1</issue>, pp. <fpage>131</fpage>&#x2013;<lpage>140</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>J. A.</given-names> <surname>Shen</surname></string-name> and <string-name><given-names>E. S.</given-names> <surname>Ebbini</surname></string-name>, &#x201C;<article-title>A new coded-excitation ultrasound imaging system. Operator design</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>43</volume>, no. <issue>1</issue>, pp. <fpage>141</fpage>&#x2013;<lpage>148</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>M. J.</given-names> <surname>Bennett</surname></string-name>, <string-name><given-names>S.</given-names> <surname>McLaughlin</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Anderson</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>McDicken</surname></string-name>, &#x201C;<article-title>The use of the fractional Fourier transform with coded excitation in ultrasound imaging</article-title>,&#x201D; <source>IEEE Trans. Biomed. Eng.</source>, vol. <volume>53</volume>, no. <issue>4</issue>, pp. <fpage>754</fpage>&#x2013;<lpage>756</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Misaridis</surname></string-name> and <string-name><given-names>J. A.</given-names> <surname>Jensen</surname></string-name>, &#x201C;<article-title>Use of modulated excitation signals in medical ultrasound. Part I: Basic concepts and expected benefits</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>52</volume>, no. <issue>2</issue>, pp. <fpage>177</fpage>&#x2013;<lpage>191</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Misaridis</surname></string-name> and <string-name><given-names>J. A.</given-names> <surname>Jensen</surname></string-name>, &#x201C;<article-title>Use of modulated excitation signals in medical ultrasound. Part II: Design and performance for medical imaging applications</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>52</volume>, no. <issue>2</issue>, pp. <fpage>192</fpage>&#x2013;<lpage>207</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Misaridis</surname></string-name> and <string-name><given-names>J. A.</given-names> <surname>Jensen</surname></string-name>, &#x201C;<article-title>Use of modulated excitation signals in medical ultrasound. Part III: High frame rate imaging</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>52</volume>, no. <issue>2</issue>, pp. <fpage>208</fpage>&#x2013;<lpage>219</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>D. P.</given-names> <surname>Shattuck</surname></string-name>, <string-name><given-names>M. D.</given-names> <surname>Weinshenker</surname></string-name>, <string-name><given-names>S. W.</given-names> <surname>Smith</surname></string-name>, and <string-name><given-names>O. T.</given-names> <surname>Vonramm</surname></string-name>, &#x201C;<article-title>Explososcan&#x2014;A parallel processing technique for high-speed ultrasound imaging with linear phased-arrays</article-title>,&#x201D; <source>J. Acoust. Soc. Am.</source>, vol. <volume>75</volume>, no. <issue>4</issue>, pp. <fpage>1273</fpage>&#x2013;<lpage>1282</lpage>, <year>1984</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Kaluzynski</surname></string-name>, <string-name><given-names>X. C.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>S. Y.</given-names> <surname>Emelianov</surname></string-name>, <string-name><given-names>A. R.</given-names> <surname>Skovoroda</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>O&#x2019;Donnell</surname></string-name>, &#x201C;<article-title>Strain rate imaging using two-dimensional speckle tracking</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>48</volume>, o. <issue>4</issue>, pp. <fpage>1111</fpage>&#x2013;<lpage>1123</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>C. M.</given-names> <surname>Fabian</surname></string-name>, <string-name><given-names>K. N.</given-names> <surname>Ballu</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Hossack</surname></string-name>, <string-name><given-names>T. N.</given-names> <surname>Blalock</surname></string-name>, and <string-name><given-names>W. F.</given-names> <surname>Walker</surname></string-name>, &#x201C;<article-title>Development of a parallel acquisition system for ultrasound research</article-title>,&#x201D; <source>Proc. SPIE</source>, vol. <volume>4325</volume>, pp. <fpage>54</fpage>&#x2013;<lpage>62</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>E. E.</given-names> <surname>Konofagou</surname></string-name>, <string-name><given-names>J.</given-names> <surname>D&#x2019;Hooge</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Ophir</surname></string-name>, &#x201C;<article-title>Myocardial elastography&#x2014; A feasibility study in vivo</article-title>,&#x201D; <source>Ultrasound Med. Biol.</source>, vol. <volume>28</volume>, no. <issue>4</issue>, pp. <fpage>475</fpage>&#x2013;<lpage>482</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>D&#x2019;hooge</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Konofagou</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Jamal</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Heimdal</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Barrios</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Bijnens</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Thoen</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Van de Werf</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Sutherland</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>Suetens</surname></string-name>, <article-title>Twodimensional ultrasonic strain rate measurement of the human heart in vivo</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>49</volume>, no. <issue>2</issue>, pp. <fpage>281</fpage>&#x2013;<lpage>286</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>W.-N.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Provost</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Luo</surname></string-name>, and <string-name><given-names>E. E.</given-names> <surname>Konofagou</surname></string-name>, &#x201C;<article-title>A composite high-frame-rate system for clinical cardiovascular imaging</article-title>,&#x201D; <source>IEEE Trans. Ultrason. Ferroelectr. Freq. Control</source>, vol. <volume>55</volume>, o. <issue>10</issue>, pp. <fpage>2221</fpage>&#x2013;<lpage>2233</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>J. H.</given-names> <surname>Chang</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>Yen</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Sun</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Luo</surname></string-name>, and <string-name><given-names>K. K.</given-names> <surname>Shung</surname></string-name>, &#x201C;<article-title>Implementation of high frame rate digital scan converter for high frequency ultrasound mechanical sector scanner</article-title>,&#x201D; <source>IEEE International Ultrasonic Symposium</source>, <year>2006</year>, pp. <fpage>2226</fpage>&#x2013;<lpage>2229</lpage>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>K.A.</given-names> <surname>Bugwadia</surname></string-name>, <string-name><given-names>E.D.</given-names> <surname>Petajan</surname></string-name>, and <string-name><given-names>N.N.</given-names> <surname>Puri</surname></string-name>, &#x201C;<article-title>Progressive-scan rate up-conversion of 24/30 source materials for HDTV</article-title>,&#x201D; <source>IEEE Trans. Consum. Electron.</source> vol. <volume>42</volume>, no. <issue>3</issue>, pp. <fpage>312</fpage>&#x2013;<lpage>321</lpage>, Aug. <year>1996</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>S.C.</given-names> <surname>Han</surname></string-name> and <string-name><given-names>J.W</given-names>. <surname>Woods</surname></string-name>, &#x201C;<article-title>Frame-rate up-conversion using transmitted motion and segmentation fields for very low bit-rate video coding</article-title>,&#x201D; <source>in Proc. Int. Conf. Image Processing</source>, vol. <volume>1</volume>, pp.<fpage>747</fpage>&#x2013;<lpage>750</lpage>, Oct. <year>1997</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Fujiwara</surname></string-name> and <string-name><given-names>A</given-names>.<surname>Taguchi</surname></string-name>, &#x201C;<article-title>Motion-compensation frame rate up-conversion based on block matching algorithm with multi-size blocks</article-title>,&#x201D; <source>IEEE International Symposium on Intelligent Signal Processing and Communication Systems, Hong Kong, Dec</source>. <volume>13&#x2013;16</volume>, <year>2005</year>, pp. <fpage>353</fpage>&#x2013;<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>T.</given-names> <surname>Thaipanich</surname></string-name> and <string-name><given-names>P.-H.</given-names> <surname>Wu</surname></string-name>, &#x201C;<article-title>Low complexity algorithm for robust video frame rate up-conversion (FRUC) technique</article-title>,&#x201D; <source>IEEE Trans. Consum. Electron.</source> vol. <volume>55</volume>, no. <issue>1</issue>, pp. <fpage>220</fpage>&#x2013;<lpage>228</lpage>, Feb. <year>2009</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>L.K.</given-names> <surname>Saul</surname></string-name> and <string-name><given-names>S.T.</given-names> <surname>Roweis</surname></string-name>, &#x201C;<article-title>Think Globally, Fit Locally: Unsupervised Learning of Low-Dimensional Manifolds</article-title>,&#x201D; <source>J. Machine Learning Research</source>, vol. <volume>4</volume>, pp. <fpage>119</fpage>&#x2013;<lpage>155</lpage>, <year>2003</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>