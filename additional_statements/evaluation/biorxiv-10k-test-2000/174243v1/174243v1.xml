<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/174243</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Immunology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>MHCflurry: open-source class I MHC binding affinity prediction</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9949-069X</contrib-id>
<name><surname>O&#x2019;Donnell</surname><given-names>Timothy</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2839-2870</contrib-id>
<name><surname>Rubinsteyn</surname><given-names>Alex</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Bonsack</surname><given-names>Maria</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Riemer</surname><given-names>Angelika</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6596-8563</contrib-id>
<name><surname>Hammerbacher</surname><given-names>Jeff</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai</institution>, New York, New York, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Immunotherapy &#x0026; Immunoprevention, German Cancer Research Center (DKFZ)</institution>, Heidelberg, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Molecular Vaccine Design, German Center for Infection Research (DZIF)</institution>, partner site Heidelberg, <country>Germany</country></aff>
<aff id="a4"><label>4</label><institution>Department of Microbiology and Immunology, Medical University of South Carolina</institution>, Charleston, South Carolina, <country>USA</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><p><email>tim@hammerlab.org</email>, <email>alex@hammerlab.org</email>, <email>m.bonsack@dkfz.de</email>, <email>a.riemer@dkfz.de</email>, <email>hammer@hammerlab.org</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>174243</elocation-id>
<history>
<date date-type="received">
<day>09</day>
<month>8</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>09</day>
<month>8</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>09</day>
<month>8</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="174243.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Machine learning prediction of the interaction between major histocompatibility complex I (MHC I) proteins and their small peptide ligands is important for vaccine design and other applications in adaptive immunity. We describe and benchmark a new open-source MHC I binding prediction package, MHCflurry. The software is a collection of allele-specific binding predictors incorporating a novel neural network architecture and adhering to software development best practices. MHCflurry outperformed the standard predictors NetMHC 4.0 and NetMHCpan 3.0 on a benchmark of mass spec-identified MHC ligands and showed competitive accuracy on a benchmark of affinity measurements. The accuracy improvement was due to substantially better prediction of non-9-mer peptide ligands, which offset a narrowly lower accuracy on 9-mers. MHCflurry was on average 8.6X faster than NetMHC and 44X faster than NetMHCpan; performance is further increased when a graphics processing unit (GPU) is available. MHCflurry is freely available to use, retrain, or extend, includes Python library and command line interfaces, and may be installed using standard package managers.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>MHC</kwd>
<kwd>HLA</kwd>
<kwd>epitope prediction</kwd>
<kwd>neural network</kwd>
</kwd-group>
<counts>
<page-count count="26"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Background</title>
<p>Adaptive immunity against intracellular infections and cancers depends on T cell recognition of small protein fragments (peptides) bound to major histocompatibility complex I (MHC I) proteins on cell surfaces. There are thousands of variants, or alleles, of MHC I proteins in the human population, each with specificity for binding a distinct set of peptides, which, when displayed by MHC, can potentially be the target of an immune response. Computational prediction of the binding affinity between a specified peptide and MHC allele has found wide application in infectious diseases, autoimmunity, vaccine design, cancer immunotherapy [<xref rid="c1" ref-type="bibr">1</xref>&#x2013;<xref rid="c4" ref-type="bibr">4</xref>].</p>
<p>The NetMHC family of tools, which includes NetMHC[<xref rid="c5" ref-type="bibr">5</xref>] and NetMHCpan[<xref rid="c6" ref-type="bibr">6</xref>], are considered the state of the art predictive models for this task[<xref rid="c7" ref-type="bibr">7</xref>]. Both NetMHC and NetMHCpan are ensembles of shallow neural networks trained on binding affinity measurements deposited in the immune epitope database (IEDB)[<xref rid="c8" ref-type="bibr">8</xref>]. NetMHC uses an &#x201C;allele-specific&#x201D; approach, in which separate predictors are trained for each MHC allele; the input to the neural network is the peptide of interest. NetMHCpan uses a &#x201C;pan-allele&#x201D; approach, in which a single neural network takes as input both the peptide and a representation of the MHC allele. The impressive accuracy of these tools has resulted in wide adoption, despite certain limitations: they are closed source, may be trained (fit) only by their developers, and do not make available their training data.</p>
<p>Here we describe and benchmark a new package of allele-specific class I MHC binding predictors, MHCflurry version 0.9.1. MHCflurry predictors show competitive accuracy with the NetMHC tools and a significant speed improvement while addressing a number of limitations of the NetMHC software. In particular, MHCflurry is open source, retrainable, precisely documents the data and workflow used to train the released models on measurements in IEDB, exposes both a Python API and a command line interface, is installed using standard Python package management tools, and applies software development best practices such as unit tests, continuous integration, and code documentation.</p>
<p>MHCflurry is freely available under the Apache License 2.0. It may be installed from the Python package index. Source code is maintained at <ext-link ext-link-type="uri" xlink:href="https://github.com/hammerlab/mhcflurry">https://github.com/hammerlab/mhcflurry</ext-link>. All data and scripts used to train the models are available in this repository.</p>
</sec>
<sec id="s2">
<title>Implementation</title>
<p>MHCflurry is implemented in Python (versions 2.7 and 3.4&#x002B; are supported) using the Keras neural network library (<ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link>). Model training and prediction use a graphics processing unit (GPU) when available.</p>
<p>Similar to NetMHC, MHCflurry is an ensemble of MHC I allele-specific predictors. Separate models are trained for each allele. The input to each model is a peptide. No representation of the MHC allele, such as its amino acid sequence, is used. The models are trained independently and no information is shared between alleles. For each allele, MHCflurry includes an ensemble of eight models. The final nanomolar affinity prediction is taken to be the geometric mean of the individual model outputs. The variance of the individual model predictions gives an indication of the uncertainty of the prediction and is also made available to users.</p>
<p>We arrived at the MHCflurry input representation, architecture, and training approach through an informal, iterative process using data held out from the training dataset. The final predictors were trained on the full training dataset and validated on the two benchmarks presented here.</p>
<sec id="s2a">
<title>Peptide representation</title>
<p>MHCflurry introduces a novel peptide representation, in which variable-length peptides of length 8-15 are encoded as fixed-length vectors. Unlike the averaging scheme implemented in NetMHC and NetMHCpan, in which non-9mer peptides are encoded as 9-mers by adding or removing amino acids, this approach makes the full peptide available to the network. It also avoids the need for more complex neural network architectures, such as recurrent networks, that would be required to explicitly support variable length model inputs.</p>
<p>The motivation for the encoding is to preserve the positionality of the residues that make the most important stabilizing contacts with the MHC molecule. These are known as anchor positions, and generally occur toward the beginning or end of the peptide for most alleles. For example, the anchor positions of HLA-A&#x002A;02:01 and many other alleles are at the second and last positions in the peptide, i.e. positions 2 and 9 for a 9-mer peptide. While overhangs, in which longer peptides protrude from the end of the binding groove, have been reported [<xref rid="c9" ref-type="bibr">9</xref>&#x2013;<xref rid="c12" ref-type="bibr">12</xref>], it is thought that the most common conformation adopted by longer peptides is a bulged or zigzag conformation of the middle residues [<xref rid="c13" ref-type="bibr">13</xref>&#x2013;<xref rid="c15" ref-type="bibr">15</xref>]. In this case the positions of the anchor residues remain intact relative to the nearest end of the peptide.</p>
<p>The peptide encoding is performed as follows (<xref rid="fig1" ref-type="fig">Figure 1a</xref>). Each peptide of length 8-15 is transformed to a length 15 string, in which missing residues are filled with an <italic>X</italic> character, which is treated as a 21st amino acid. The first four and last four residues in the peptide always map to the first four and last four positions in the representation. The middle seven residues are filled as needed depending on the length of the peptide: an 8-mer leaves all middle positions as an <italic>X</italic> whereas a 15-mer fills all positions. In this way, the positions most likely to contain anchor residues are consistently mapped to the same positions in the representation relative to the end of the peptide.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>MHCflurry peptide representation and neural network architecture.</title>
<p><bold>(a)</bold> Variable length peptides (8-15mers) are encoded as length-15 sequences. The four N-terminal and four C-terminal residues map to fixed positions (N1-N4 and C1-C4) in this encoding. The seven middle residues are filled according to the length of the peptide, with unfilled positions set to the special character <italic>X</italic>. <bold>(b)</bold> Example encodings for three peptides. <bold>(c)</bold> Neural network architecture. The length-15 encoded peptide is supplied as a 1-hot vector, with entries for the 20 amino acids plus the <italic>X</italic> special character. Two locally connected layers are applied with a hyperbolic tangent (tanh) activation, followed by a fully connected layer with rectified linear (ReLU) activation, and an output neuron with sigmoidal activation.</p></caption>
<graphic xlink:href="174243_fig1.tif"/>
</fig>
</sec>
<sec id="s2b">
<title>Output encoding</title>
<p>As in NetMHC and NetMHCpan, MHCflurry transforms binding affinities to values between 0.0 and 1.0, where 0.0 is a non-binder and 1.0 is a strong binder. The neural networks are trained using the transformed values and the inverse transform is used to return prediction results as nanomolar affinities. The transform is given by 1 - log<sub>50000</sub>(x) where x is the nanomolar affinity. Affinities are capped at 50,000 nM.</p>
</sec>
<sec id="s2c">
<title>Neural network architecture</title>
<p>The MHCflurry predictors are feedforward neural networks composed of the following layers: the peptide representation (described previously) encoded as a 1-hot (binary) vector, two locally connected layers, a fully connected layer, and a sigmoidal output (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). Locally connected layers are one dimensional convolutional layers without weight sharing. Each neuron receives a neighborhood of adjacent points, instead of the full input from the previous layer as in a fully connected layer. The locally connected layers use hyperbolic tangent (tanh) activations, and the fully connected layer uses a rectified linear (ReLU) activation. The weights of the fully connected layer are L1 regularized.</p>
<p>In preliminary investigations (data not shown), we observed that models using more than one fully connected layer performed poorly and that using an amino acid embedding layer did not significantly outperform a 1-hot encoded peptide. We additionally tested two recent ideas from the deep learning literature, dropout[<xref rid="c16" ref-type="bibr">16</xref>] and batch normalization[<xref rid="c17" ref-type="bibr">17</xref>], which also did not significantly improve performance. While the downloadable MHCflurry models do not use these features, the MHCflurry software includes support for them to enable experimentation.</p>
</sec>
<sec id="s2d">
<title>Construction of the training dataset</title>
<p>The training dataset was assembled from a snapshot of IEDB MHC ligands downloaded on May 17, 2017 augmented with the BD2013 dataset published in ref. [<xref rid="c18" ref-type="bibr">18</xref>].</p>
<p>IEDB entries with non-class I, non-specific, mutant, or unparseable allele names were dropped, as were those with peptides containing post-translational modifications or noncanonical amino acids. To avoid the potential for bias in favor of MHCflurry on the mass-spec validation dataset, entries deriving from mass-spec studies were removed from the training data. This yielded an IEDB dataset of 147,716 quantitative and 43,704 qualitative affinity measurements. We assigned nanomolar affinities to the qualitative measurements as follows: <italic>positive-high</italic>, 50; <italic>positive-intermediate</italic>, 500; <italic>positive-low</italic>, 5000; <italic>positive</italic>, 100; <italic>negative</italic>, 50000.</p>
<p>Of 179,692 measurements in the BD2013 dataset published in ref. [<xref rid="c18" ref-type="bibr">18</xref>], 55,473 were not also present in the IEDB dataset. After selecting peptides of length 8-15 and dropping alleles with fewer than 200 measurements, the combined training dataset consists of 235,597 measurements across 101 alleles (<xref rid="tblS1" ref-type="table">Table S1</xref>).</p>
</sec>
<sec id="s2e">
<title>Neural network training</title>
<p>The MHCflurry models are trained (fit) using a procedure similar to NetMHC. Eight models are trained for each allele. Each model is trained on a random 80&#x0025; sample of the data for the allele; the remaining 20&#x0025; is used as a test set for early stopping. Training proceeds using the RMSprop optimizer[<xref rid="c19" ref-type="bibr">19</xref>] until the accuracy on the test set has not improved for ten epochs. Mean squared error is used as both the training loss and test set accuracy metric. At each epoch, 25 synthetic negative peptides for each length 8-15 are randomly generated. These random negative peptides are sampled so as to have the same amino acid distribution as the training peptides and are assigned uniformly random affinities between 20,000 nM and 50,000 nM. No model selection is performed.</p>
<p>The models within an ensemble thus differ from each other due to several sources of randomness. The most important factor is that each model is trained on a different 80&#x0025; sample of the data. Lesser factors include random initial model weights, the nondeterminacy of stochastic gradient descent, and the random negative peptides.</p>
<p>Training the models described here took 311 minutes on a machine with eight 2.30 GHz Intel Xeon CPUs, one NVIDIA Tesla K80 GPU, and 52 GB memory.</p>
</sec>
</sec>
<sec id="s3">
<title>Benchmark approach</title>
<p>As the NetMHC tools are fit to binding data in IEDB, new datasets not included in IEDB are required to assess the performance of these tools. We use two datasets for this purpose: (1) a published dataset of peptides eluted from cell-surface MHC and identified by mass-spec[<xref rid="c20" ref-type="bibr">20</xref>], which we refer to as the ABELIN dataset, and (2) an unpublished dataset of affinity measurements generated through an HPV vaccine development project, referred to as the HPV dataset. All entries in both the ABELIN and HPV benchmarks are distinct from entries in the TRAIN dataset.</p>
<p>The ABELIN dataset was derived from 20,451 sequences of MHC-displayed ligands eluted from a B cell line and identified by mass spec by [<xref rid="c20" ref-type="bibr">20</xref>]. Each experiment was performed in cells engineered to express a single MHC I allele. We excluded 2/16 alleles (HLA-A&#x002A;02:04 and HLA-A&#x002A;02:07; <xref rid="tblS1" ref-type="table">Table S1</xref>) not supported by MHCflurry due to insufficient representation in the TRAIN dataset (fewer than 200 measurements) and discarded peptides with post-translational modifications or lengths outside the supported range (8-15 residues). To create the benchmark, we sampled unobserved sequences (decoys) from the protein-coding transcripts that contained the identified peptides (hits) based on protein sequences in the UCSC hg19 proteome [<xref rid="c21" ref-type="bibr">21</xref>] and transcript quantifications from RNA sequencing of the relevant cell line (b721221) downloaded from the Gene Expression Omnibus (accession GSE93315). For an allele with n hits, we sampled 100n decoys, weighting transcripts by the number of hits and sampling an equal number of decoys of each length 8-15. This yielded 2,045,100 decoys for 20,451 hits, from which we removed 118 (0.005&#x0025;) entries also present in the TRAIN dataset, for a benchmark of 20,361 hits and 2,045,072 decoys. We assessed the accuracy of each predictor at differentiating hits from decoys in terms of positive predictive value (PPV). To compute PPV for an allele with n hits, we ranked the n &#x002B; 100n hits and decoys from tightest to weakest predicted binding affinity and calculated the fraction of the top n peptides that were hits.</p>
<p>In addition to the standard MHCflurry, NetMHC, and NetMHCpan predictors, we considered seven variations on the MHCflurry architecture in the ABELIN benchmark. The variants changed one or two aspects of the architecture or training data and were otherwise identical to MHCflurry 0.9.1 (<xref rid="tbl1" ref-type="table">Table 1</xref>). For each architecture, we evaluated both a single predictor and an ensemble of eight models.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>MHCflurry architectural variants tested.</title>
<p>Each variant differs from the standard MHCflurry 0.9.1 predictor as indicated.</p></caption>
<graphic xlink:href="174243_tbl1.tif"/>
</table-wrap>
<p>The HPV benchmark dataset consists of 194 affinity measurements across seven alleles. Peptides derived from the E6 and E7 proteins of HPV16 were assayed using a cell-based competitive binding assay [<xref rid="c22" ref-type="bibr">22</xref>, <xref rid="c23" ref-type="bibr">23</xref>] (Supplemental Methods). We assessed accuracy on this benchmark using three well-known metrics, area under the receiver operator characteristic curve (AUC), F1, and Kendall rank correlation coefficient (Kendall&#x2019;s tau). The AUC score estimates the probability that a strong binding peptide (measured affinity 500 nM or less) will have a stronger predicted affinity than a weak- or non-binding peptide (measured affinity greater than 500 nM). The F1 score summarizes a predictor&#x2019;s precision and recall at classifying peptides as having affinity less or greater than 500 nM. The Kendall tau score measures the correlation in rank when peptides are sorted by measured or predicted affinity; it uses no cutoff and assesses agreement across the affinity spectrum.</p>
</sec>
<sec id="s4">
<title>Results</title>
<p>MHCflurry 0.9.1 exhibited a modest improvement in accuracy over NetMHC 4.0 and NetMHCpan 3.0 in the ABELIN mass spec benchmark, outperforming NetMHC on 14/14 alleles tested and NetMHCpan on 12/14 alleles (<xref rid="fig2" ref-type="fig">Figure 2a</xref>). On average across alleles, MHCflurry showed a 10.9&#x0025; (range 3.3 &#x2013; 25.3) and 3.3&#x0025; (-0.6 &#x2013; &#x002B;10.0) higher PPV than NetMHC and NetMHCpan, respectively.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>ABELIN mass-spec benchmark.</title>
<p><bold>(a)</bold> Positive predictive value (PPV) of NetMHC, NetMHCpan, and MHCflurry for each allele in the benchmark. <bold>(b)</bold> MHCflurry accuracy relative to NetMHCpan aggregated across alleles and split by peptide length. The median line is indicated, boxes show the quartiles, and points indicate individual alleles outside the interquartile region. The &#x003E;12-mers category includes peptides of length 13, 14, and 15. <bold>(c)</bold> Relative accuracy of NetMHC, MHCflurry, and several variants of the MHCflurry architecture aggregated across alleles: <italic>quantitative</italic> is the standard architecture trained only on quantitative measurements in IEDB; <italic>noL1</italic> is an architecture with no L1 regularization on the fully connected layer; <italic>0local</italic> and <italic>1local</italic> indicate architectures with zero or one locally connected layers instead of two as in the standard MHCflurry architecture; <italic>dense16</italic> and <italic>dense64</italic> are architectures with a fully connected layer size of 16 or 64 instead of 32. Bars and points are as in (b). <bold>(d)</bold> Prediction speed. Indicated separately are timing measurements for MHCflurry when using only the CPU and when an NVIDIA Tesla K80 graphics processing unit (GPU) is available.</p></caption>
<graphic xlink:href="174243_fig2.tif"/>
</fig>
<p>The accuracy advantage of MHCflurry over the NetMHC tools was due to better performance on non-9-mer peptides, which offset slightly lower accuracy on 9-mers (<xref rid="fig2" ref-type="fig">Figure 2b</xref>). On non-9-mers (i.e. peptides of lengths 8 and 10-15), MHCflurry outperformed both NetMHC and NetMHCpan on 14/14 alleles, with a median 38.4&#x0025; (8.6 &#x2013; 72.1) and 16.0&#x0025; (range 6.9 &#x2013; 29.9) improvement in PPV compared to NetMHC and NetMHCpan, respectively. On 9-mer peptides, MHCflurry underperformed NetMHCpan on 13/14 alleles, with a median difference in PPV of &#x2212;1.7&#x0025; (&#x2212;7.7 &#x2013; &#x002B;2.4); relative to NetMHC the deficit was &#x2212;1.0&#x0025; (&#x2212;3.0 &#x2013; &#x002B;5.0; underperforming on 10/14 alleles).</p>
<p>The architectural variants of MHCflurry tested showed overall similar performance, with all ensembles outperforming NetMHCpan in terms of median improvement in PPV across the 14 alleles in the ABELIN benchmark (<xref rid="fig2" ref-type="fig">Figure 2c</xref>). Similarly to the standard predictor, the architectures variants also showed a consistent advantage on non-9-mer peptides (<xref rid="figS1" ref-type="fig">Figure S1</xref>). The best performing architecture overall was the <italic>1local</italic> variant that incorporated a single locally connected layer instead of the two layers used in the standard MHCflurry 0.9.1 predictor. This variant obtained a median 4.0&#x0025; (-1.0 &#x2013; 10.0) higher PPV than NetMHCpan across alleles. Two other variants narrowly outperformed the standard predictor as well: the <italic>quantitative</italic> ensemble that was trained on only quantitative (not qualitative) IEDB data, and the <italic>0local-noL1</italic> predictor which used no locally connected layers and no regularization. While these three architectures outperformed the standard predictor in terms of median improvement in PPV, they also showed lower accuracy on their worst-performing alleles. The worst-performing allele relative to NetMHCpan for the standard MHCflurry 0.9.1 architecture was HLA-B&#x002A;44:02, with a 0.6&#x0025; lower PPV than NetMHCpan. For the <italic>1local</italic>, <italic>0local-noL1</italic>, and <italic>quantitative</italic> variants the worst performing alleles scored 1.0&#x0025; (HLA-B&#x002A;35:01), 5.8&#x0025; (HLA-A&#x002A;02:01), and 3.1&#x0025; (HLA-B&#x002A;35:01) lower PPV than NetMHCpan, respectively. This suggests that, while there is likely room for improvement, the MHCflurry 0.9.1 architecture and training strategy is a reasonable compromise between median and minimum performance across alleles.</p>
<p>Ensembles showed a consistent improvement in accuracy over single models, although even a single MHCflurry 0.9.1 model was on par with the NetMHCpan ensemble (median improvement=0.3&#x0025;, range=-3.9 &#x2013; &#x002B;8.6). Ensembles also appeared to smooth out some of the difference between the architecture variants. For example, the <italic>noL1</italic> ensemble performed respectably (median=2.3&#x0025;, range=-3.1 &#x2013; 10.1) but a single <italic>noL1</italic> model performed much worse than the other models (median=-2.4&#x0025;, range=-11.0 &#x2013; &#x002B;7.1), consistent with the idea that both regularization and ensembles can mitigate overfitting.</p>
<p>On the HPV benchmark, MHCflurry narrowly outperformed the other predictors in terms of AUC (MHCflurry=0.74, NetMHC=0.66, NetMHCpan=0.72) and F1 (MHCflurry=0.21, NetMHC=0.21, NetMHCpan=0.15). The NetMHCpan predictors outperformed MHCflurry in Kendall rank correlation (MHCflurry=0.15, NetMHC=0.17, NetMHCpan=0.19; <xref rid="fig3" ref-type="fig">Figure 3</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>HPV affinity measurement benchmark.</title>
<p><bold>(a)</bold> Predictions for the three predictors on the HPV affinity dataset. The 500 nM threshold used in calculation of area under the receiver operating characteristic curve (AUC) and F1 scores is indicated. <bold>(b)</bold> AUC, F1, and Kendall rank correlation coefficient on the HPV dataset.</p></caption>
<graphic xlink:href="174243_fig3.tif"/>
</fig>
<p>MHCflurry was substantially faster than the other predictors (<xref rid="fig2" ref-type="fig">Figure 2d</xref>). Using only the CPU, MHCflurry was on average 8.6X faster than NetMHC and 44X faster than NetMHCpan. Use of a GPU improved MHCflurry performance by about 75&#x0025;, or 15X and 77X faster than NetMHC and NetMHCpan, respectively.</p>
</sec>
<sec id="s5">
<title>Discussion</title>
<p>Here, we introduce a package of single-allele Class I MHC affinity predictors that achieves performance competitive with the well-known NetMHC and NetMHCpan tools. Our predictor, MHCflurry, supports several improvements over the neural network architecture and training approach used by NetMHC, including explicit support for variable length peptides, locally connected hidden layers, a regularized dense hidden layer, and incorporation of qualitative training data.</p>
<p>On the ABELIN mass-spec benchmark, MHCflurry outperformed the NetMHC tools overall and in particular on non-9mer peptides, suggesting that the peptide representation introduced here is a useful approach for training feedforward neural networks on variable-length MHC I peptide ligands. The non-9-mer accuracy improvement is interesting given that the IEDB training dataset is highly biased toward 9-mer peptides and contains very few peptides of length greater than 11 (1.4&#x0025; of total). The case of 12-mer peptides is representative. In the ABELIN benchmark, the allele with the most 12-mer peptides is A&#x002A;68:02, with 163 mass-spec identified 12-mers out of 1,986 total detected peptides. On this allele, the PPV scores were 0.20, 0.11, and 0.13 for MHCflurry, NetMHC, and NetMHCpan, respectively, suggesting that, while no predictor performs well in this context, MHCflurry learned something the other predictors did not. In the IEDB training data, there were only nine 12-mer peptides with affinity measurements for this allele, and all except one (TLVGLAIGLVLL with 542 nM affinity) had non-binder affinities.</p>
<p>This suggests that the MHCflurry models generalized to 12-mer prediction for this allele by learning from peptides of other lengths.</p>
<p>In contrast, MHCflurry narrowly underperformed the NetMHC tools on predictions for 9-mers, with a median 1.7&#x0025; lower PPV than NetMHCpan across alleles on 9-mers. Addressing this deficit is important future work. As one possible explanation, we note that, unlike the NetMHC predictors, the MHCflurry training strategy performs no model selection; models for all alleles use an identical architecture. Model selection may be required for the last several percent in accuracy on 9-mers, a class of peptides for which the NetMHC tools are expected to be extremely well tuned.</p>
<p>MHCflurry has other important limitations. As a single allele predictor, MHCflurry cannot be expected to perform well on alleles with little training data in IEDB. NetMHCpan remains the best tool for such alleles. Furthermore, as only limited validation has been performed on MHCflurry models at this point, for clinical and other sensitive applications we recommend comparing MHCflurry predictions to existing predictors. In an effort to ease such comparisons, our group has developed the mhctools package (<ext-link ext-link-type="uri" xlink:href="https://github.com/hammerlab/mhctools">https://github.com/hammerlab/mhctools</ext-link>, manuscript in preparation), which provides a standard interface to running MHCflurry as well as popular binding predictors from other groups, including NetMHC and NetMHCpan.</p>
<p>MHCflurry&#x2019;s prediction speed and convenient implementation may make it especially attractive for high-throughput epitope discovery efforts, such as neoantigen identification from high throughput sequencing of tumors. MHCflurry running on a CPU achieves nearly an order of magnitude speed improvement over NetMHC; this figure is greater still with respect to NetMHCpan or when using a GPU. Additionally, MHCflurry is readily integrated into scientific workflows as it may be installed using standard Python package infrastructure and includes both a command-line and a Python library API.</p>
</sec>
<sec id="s6">
<title>Conclusion</title>
<p>MHCflurry is an open source Python package implementing MHC I affinity prediction for 101 alleles. On two benchmarks, it achieved accuracy competitive with the closed-source NetMHC and NetMHCpan tools and ran significantly faster. In contrast to these tools, MHCflurry supports training predictors on new datasets, is installed using standard package management infrastructure, provides a Python library API in addition to a command-line interface, includes automated unit tests and adheres to other software development best practices, and is distributed under a license that enables all users, including commercial entities, to use and improve the software free of charge. Epitope discovery efforts may consider integrating MHCflurry into their pipelines.</p>
</sec>
</body>
<back>
<sec id="s7">
<title>Declarations</title>
<sec id="s7a">
<title>Ethics approval and consent to participate</title>
<p>Not applicable.</p>
</sec>
<sec id="s7b">
<title>Consent for publication</title>
<p>Not applicable.</p>
</sec>
<sec id="s7c">
<title>Availability of data and material</title>
<p>The MHCflurry source code and training workflow, data, and models are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hammerlab/mhcflurry">https://github.com/hammerlab/mhcflurry</ext-link>. The TRAIN and ABELIN datasets (including predictions from all tools) may be downloaded at the following addresses:</p>
<p>TRAIN: <ext-link ext-link-type="uri" xlink:href="http://github.com/hammerlab/mhcflurry/releases/download/0.9.1/data_curated.tar.bz2">http://github.com/hammerlab/mhcflurry/releases/download/0.9.1/data_curated.tar.bz2</ext-link></p>
<p>ABELIN: <ext-link ext-link-type="uri" xlink:href="http://github.com/hammerlab/mhcflurry/releases/download/0.9.1/abelin_peptides.all_predictions.csv.bz2">http://github.com/hammerlab/mhcflurry/releases/download/0.9.1/abelin_peptides.all_predictions.csv.bz2</ext-link></p>
<p>The HPV dataset includes unpublished affinity measurements (Hoppe, Bonsack et al., manuscript in preparation) and are available upon request from A. Riemer to not-for-profit enterprises for research purposes only.</p>
</sec>
<sec id="s7d">
<title>Competing interests</title>
<p>The authors declare that they have no competing interests.</p>
</sec>
<sec id="s7e">
<title>Funding</title>
<p>This research was supported by the Parker Institute for Cancer Immunotherapy.</p>
</sec>
<sec id="s7f">
<title>Authors&#x0027; contributions</title>
<p>T.O. and A. Rubinsteyn developed MHCflurry. T.O. benchmarked the software and wrote the manuscript. M.B. and A. Riemer performed the HPV peptide binding experiments and advised on benchmarking approaches. J.H. supervised the project. All authors critically reviewed the manuscript.</p>
</sec>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Mike Rooney and Jenn Abelin for helpful discussions on binding predictor evaluation.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Lundegaard</surname> <given-names>C</given-names></string-name>, <string-name><surname>Lund</surname> <given-names>O</given-names></string-name>, <string-name><surname>Kemir</surname> <given-names>C</given-names></string-name>, <string-name><surname>Brunak</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>M</given-names></string-name>: <article-title>Modeling the adaptive immune system: Predictions and simulations</article-title>. <source>Bioinformatics</source> <year>2007</year>, <volume>23</volume>:<fpage>3265</fpage>&#x2013;<lpage>3275</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Patronov</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doytchinova</surname> <given-names>I</given-names></string-name>: <article-title>T-cell epitope vaccine design by immunoinformatics</article-title>. <source>Open Biol.</source> <year>2013</year>, <volume>3</volume>:<fpage>120139</fpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Gubin</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Artyomov</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Mardis</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Schreiber</surname> <given-names>RD</given-names></string-name>: <article-title>Tumor neoantigens: building a framework for personalized cancer immunotherapy</article-title>. <source>J. Clin. Invest.</source> <year>2015</year>, <volume>125</volume>:<fpage>3413</fpage>&#x2013;<lpage>3421</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Ott</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Keskin</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Shukla</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Sun</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bozym</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Luoma</surname> <given-names>A</given-names></string-name>, <string-name><surname>Giobbie-Hurder</surname> <given-names>A</given-names></string-name>, <string-name><surname>Peter</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>C</given-names></string-name>, <string-name><surname>Olive</surname> <given-names>O</given-names></string-name>, <string-name><surname>Carter</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Li</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lieb</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Eisenhaure</surname> <given-names>T</given-names></string-name>, <string-name><surname>Gjini</surname> <given-names>E</given-names></string-name>, <string-name><surname>Stevens</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lane</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Javeri</surname> <given-names>I</given-names></string-name>, <string-name><surname>Nellaiappan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Salazar</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Daley</surname> <given-names>H</given-names></string-name>, <string-name><surname>Seaman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Buchbinder</surname> <given-names>EI</given-names></string-name>, <string-name><surname>Yoon</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Harden</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lennon</surname> <given-names>N</given-names></string-name>, <string-name><surname>Gabriel</surname> <given-names>S</given-names></string-name>, <string-name><surname>Rodig</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Barouch</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Aster</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Getz</surname> <given-names>G</given-names></string-name>, <string-name><surname>Wucherpfennig</surname> <given-names>K</given-names></string-name>, <string-name><surname>Neuberg</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ritz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lander</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Fritsch</surname> <given-names>EF</given-names></string-name>, <string-name><surname>Hacohen</surname> <given-names>N</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>CJ</given-names></string-name>: <article-title>An immunogenic personal neoantigen vaccine for patients with melanoma</article-title>. <source>Nature</source> <year>2017</year>, <volume>547</volume>:<fpage>217</fpage>&#x2013;<lpage>221</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Lundegaard</surname> <given-names>C</given-names></string-name>, <string-name><surname>Lamberth</surname> <given-names>K</given-names></string-name>, <string-name><surname>Harndahl</surname> <given-names>M</given-names></string-name>, <string-name><surname>Buus</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lund</surname> <given-names>O</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>M</given-names></string-name>: <article-title>NetMHC-3.0: accurate web accessible predictions of human, mouse and monkey MHC class I affinities for peptides of length 8&#x2013;11</article-title>. <source>Nucleic Acids Res.</source> <year>2008</year>, <volume>36</volume>:<fpage>W509</fpage>&#x2013;<lpage>W512</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Hoof</surname> <given-names>I</given-names></string-name>, <string-name><surname>Peters</surname> <given-names>B</given-names></string-name>, <string-name><surname>Sidney</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pedersen</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Sette</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lund</surname> <given-names>O</given-names></string-name>, <string-name><surname>Buus</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>M</given-names></string-name>: <article-title>NetMHCpan, a method for MHC class i binding prediction beyond humans</article-title>. <source>Immunogenetics</source> <year>2009</year>, <volume>61</volume>:<fpage>1</fpage>&#x2013;<lpage>13</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Trolle</surname> <given-names>T</given-names></string-name>, <string-name><surname>Metushi</surname> <given-names>IG</given-names></string-name>, <string-name><surname>Greenbaum</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Sidney</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lund</surname> <given-names>O</given-names></string-name>, <string-name><surname>Sette</surname> <given-names>A</given-names></string-name>, <string-name><surname>Peters</surname> <given-names>B</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>M</given-names></string-name>: <article-title>Automated benchmarking of peptide-MHC class I binding</article-title> <source>predictions Bioinformatics</source> <year>2015</year>, <volume>31</volume>:<fpage>2174</fpage>&#x2013;<lpage>2181</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Vita</surname> <given-names>R</given-names></string-name>, <string-name><surname>Overton</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Greenbaum</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Ponomarenko</surname> <given-names>J</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Cantrell</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Wheeler</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Gabbard</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Hix</surname> <given-names>D</given-names></string-name>, <string-name><surname>Sette</surname> <given-names>A</given-names></string-name>, <string-name><surname>Peters</surname> <given-names>B</given-names></string-name>: <article-title>The immune epitope database (IEDB) 3. 0</article-title>. <source>Nucleic Acids Res.</source> <year>2015</year>, <volume>43</volume>:<fpage>D405</fpage>&#x2013;<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Collins</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Garboczi</surname> <given-names>DN</given-names></string-name>, <string-name><surname>Wiley</surname> <given-names>DC</given-names></string-name>: <article-title>Three-dimensional structure of a peptide extending from one end of a class I MHC binding site</article-title>. <source>Nature</source> <year>1994</year>, <volume>371</volume>:<fpage>626</fpage>&#x2013;<lpage>629</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Stryhn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Pedersen</surname> <given-names>LO</given-names></string-name>, <string-name><surname>Holm</surname> <given-names>A</given-names></string-name>, <string-name><surname>Buus</surname> <given-names>S</given-names></string-name>: <article-title>Longer peptide can be accommodated in the MHC class I binding site by a protrusion mechanism</article-title>. <source>Eur. J. Immunol.</source> <year>2000</year>, <volume>30</volume>:<fpage>3089</fpage>&#x2013;<lpage>3099</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>McMurtrey</surname> <given-names>C</given-names></string-name>, <string-name><surname>Trolle</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sansom</surname> <given-names>T</given-names></string-name>, <string-name><surname>Remesh</surname> <given-names>SG</given-names></string-name>, <string-name><surname>Kaever</surname> <given-names>T</given-names></string-name>, <string-name><surname>Bardet</surname> <given-names>W</given-names></string-name>, <string-name><surname>Jackson</surname> <given-names>K</given-names></string-name>, <string-name><surname>McLeod</surname> <given-names>R</given-names></string-name>, <string-name><surname>Sette</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zajonc</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Blader</surname> <given-names>IJ</given-names></string-name>, <string-name><surname>Peters</surname> <given-names>B</given-names></string-name>, <string-name><surname>Hildebrand</surname> <given-names>W</given-names></string-name>: <article-title>Toxoplasma gondii peptide ligands open the gate of the HLA class I binding groove</article-title>. <source>Elife</source> <year>2016</year>, <fpage>5</fpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Pymm</surname> <given-names>P</given-names></string-name>, <string-name><surname>Illing</surname> <given-names>PT</given-names></string-name>, <string-name><surname>Ramarathinam</surname> <given-names>SH</given-names></string-name>, <string-name><surname>O&#x2032;Connor</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Hughes</surname> <given-names>VA</given-names></string-name>, <string-name><surname>Hitchen</surname> <given-names>C</given-names></string-name>, <string-name><surname>Price</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Ho</surname> <given-names>BK</given-names></string-name>, <string-name><surname>McVicar</surname> <given-names>DW</given-names></string-name>, <string-name><surname>Brooks</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Purcell</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Rossjohn</surname> <given-names>J</given-names></string-name>, <string-name><surname>Vivian</surname> <given-names>JP</given-names></string-name>: <article-title>MHC-I peptides get out of the groove and enable a novel mechanism of HIV-1 escape</article-title>. <source>Nat. Struct. Mol. Biol.</source> <year>2017</year>, <volume>24</volume>:<fpage>387</fpage>&#x2013;<lpage>394</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Fremont</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Matsumura</surname> <given-names>M</given-names></string-name>, <string-name><surname>Stura</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Peterson</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>IA</given-names></string-name>: <article-title>Crystal structures of two viral peptides in complex with murine MHC class I H-2Kb</article-title>. <source>Science</source> <year>1992</year>, <volume>257</volume>:<fpage>919</fpage>&#x2013;<lpage>927</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Speir</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Stevens</surname> <given-names>J</given-names></string-name>, <string-name><surname>Joly</surname> <given-names>E</given-names></string-name>, <string-name><surname>Butcher</surname> <given-names>GW</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>IA</given-names></string-name>: <article-title>Two different, highly exposed, bulged structures for an unusually long peptide bound to</article-title> <source>rat MHC class I RT1-Aa Immunity</source> <year>2001</year>, <volume>14</volume>:<fpage>81</fpage>&#x2013;<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Tynan</surname> <given-names>FE</given-names></string-name>, <string-name><surname>Borg</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Miles</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Beddoe</surname> <given-names>T</given-names></string-name>, <string-name><surname>El-Hassen</surname> <given-names>D</given-names></string-name>, <string-name><surname>Silins</surname> <given-names>SL</given-names></string-name>, <string-name><surname>van Zuylen</surname> <given-names>WJM</given-names></string-name>, <string-name><surname>Purcell</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Kjer-Nielsen</surname> <given-names>L</given-names></string-name>, <string-name><surname>McCluskey</surname> <given-names>J</given-names></string-name>, <article-title>Others: High resolution structures of highly bulged viral epitopes bound to major histocompatibility complex class I Implications for T-cell receptor engagement and T-cell immunodominance</article-title>. <source>J. Biol. Chem.</source> <year>2005</year>, <volume>280</volume>:<fpage>23900</fpage>&#x2013;<lpage>23909</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Srivastava</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hinton</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Krizhevsky</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sutskever</surname> <given-names>I</given-names></string-name>, <string-name><surname>Salakhutdinov</surname> <given-names>R</given-names></string-name>: <article-title>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</article-title>. <source>J. Mach. Learn. Res.</source> <year>2014</year>, <volume>15</volume>:<fpage>1929</fpage>&#x2013;<lpage>1958</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="other"><string-name><surname>Ioffe</surname> <given-names>S</given-names></string-name>, <string-name><surname>Szegedy</surname> <given-names>C</given-names></string-name>: <article-title>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</article-title>. <source>Arxiv</source> <year>2015</year>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Sidney</surname> <given-names>J</given-names></string-name>, <string-name><surname>Buus</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sette</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Peters</surname> <given-names>B</given-names></string-name>: <article-title>Dataset size and composition impact the reliability of performance benchmarks for peptide-MHC binding predictions</article-title>. <source>BMC Bioinformatics</source> <year>2014</year>, <volume>15</volume>:<fpage>241</fpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="other"><string-name><surname>Dauphin</surname> <given-names>YN</given-names></string-name>, <string-name><surname>de Vries</surname> <given-names>H</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>Y</given-names></string-name>: <article-title>Equilibrated adaptive learning rates for non-convex optimization</article-title>. <source>arXiv [cs.LG]</source> <year>2015</year>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Abelin</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Keskin</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Sarkizova</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hartigan</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Sidney</surname> <given-names>J</given-names></string-name>, <string-name><surname>Stevens</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lane</surname> <given-names>W</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Eisenhaure</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Clauser</surname> <given-names>KR</given-names></string-name>, <string-name><surname>Hacohen</surname> <given-names>N</given-names></string-name>, <string-name><surname>Rooney</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Carr</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>CJ</given-names></string-name>: <article-title>Mass Spectrometry Profiling of HLA-Associated Peptidomes in Mono-allelic Cells Enables More Accurate Epitope Prediction</article-title>. <source>Immunity</source> <year>2017</year>, <volume>46</volume>:<fpage>315</fpage>&#x2013;<lpage>326</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Hsu</surname> <given-names>F</given-names></string-name>, <string-name><surname>Kent</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Clawson</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kuhn</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Diekhans</surname> <given-names>M</given-names></string-name>, <string-name><surname>Haussler</surname> <given-names>D</given-names></string-name>: <article-title>The UCSC Known Genes</article-title>. <source>Bioinformatics</source> <year>2006</year>, <volume>22</volume>: <fpage>1036</fpage>&#x2013;<lpage>1046</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Kessler</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Benckhuijsen</surname> <given-names>WE</given-names></string-name>, <string-name><surname>Mutis</surname> <given-names>T</given-names></string-name>, <string-name><surname>Melief</surname> <given-names>CJM</given-names></string-name>, <string-name><surname>van der Burg</surname> <given-names>SH</given-names></string-name>, <string-name><surname>Drijfhout</surname> <given-names>JW</given-names></string-name>: <article-title>Competition-Based Cellular Peptide Binding Assay for HLA Class I. Curr. Protoc</article-title>. <source>Immunol.</source> <year>2004</year>:<fpage>18</fpage>&#x2013;<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Kessler</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Mommaas</surname> <given-names>B</given-names></string-name>, <string-name><surname>Mutis</surname> <given-names>T</given-names></string-name>, <string-name><surname>Huijbers</surname> <given-names>I</given-names></string-name>, <string-name><surname>Vissers</surname> <given-names>D</given-names></string-name>, <string-name><surname>Benckhuijsen</surname> <given-names>WE</given-names></string-name>, <string-name><surname>Schreuder</surname> <given-names>GMT</given-names></string-name>, <string-name><surname>Offringa</surname> <given-names>R</given-names></string-name>, <string-name><surname>Goulmy</surname> <given-names>E</given-names></string-name>, <string-name><surname>Melief</surname> <given-names>CJM</given-names></string-name>, <string-name><surname>Van der Burg</surname> <given-names>SH</given-names></string-name>, <string-name><surname>Drijfhout</surname> <given-names>JW</given-names></string-name>: <article-title>Competition-based cellular peptide binding assays for 13 prevalent HLA class I alleles using fluorescein-labeled synthetic peptides</article-title>. <source>Hum. Immunol.</source> <year>2003</year>, <volume>64</volume>:<fpage>245</fpage>&#x2013;<lpage>255</lpage>.</mixed-citation></ref>
</ref-list>
<sec id="s8">
<title>Supplemental methods</title>
<sec id="s8a">
<title>Competitive binding assay (HPV benchmark)</title>
<p>The binding affinity of HPV16 E6 and E7 derived peptides to selected HLA class I molecules was tested in competition-based binding assays as described in [<xref rid="c22" ref-type="bibr">22</xref>, <xref rid="c23" ref-type="bibr">23</xref>]. Briefly, test peptides in 1:2 serial dilutions (final concentrations from 100 &#x2013; 0.78 &#x03BC;M) compete with 150mM fluorescein-labeled reference peptide with a known high affinity for binding to the HLA class I molecule of interest on B-LCL cells, which were previously stripped from natural bound peptides and &#x03B2;2-microglobulin using ice cold citric acid buffer. After stripping, the cells were washed with culture medium and dissolved in culture medium containing 2&#x03BC;g/mL &#x03B2;2-microglobulin (MP Biomedicals) to reconstitute the HLA class I complex. B-LCL cells were diluted to 6x10<sup>4</sup> cells/100&#x03BC;l per test peptide concentration and pipetted to a well-plate containing the mixes of test and reference peptide. After 24h incubation at 4&#x00B0;C the cells were washed, fixed in 1&#x0025; PFA and suspended in 0.5&#x0025; BSA in 1x PBS. The mean fluorescence intensity <italic>Fmix</italic> at each test peptide concentration was measured by flow cytometry (Accuri C6, BD Biosciences). The binding of each test peptide was calculated as the percent inhibition of reference peptide binding relative to the minimal response (without reference; <italic>Fmin</italic>) and the maximal response (reference only; <italic>Fmax</italic>) as:
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="174243_ueqn1.gif"/></alternatives>
</disp-formula>
</p>
<p>The binding affinity of the test peptide was determined by non-linear regression analysis as the concentration that inhibits 50&#x0025; binding of the fluorescein-labeled reference peptide (IC50).</p>
<p>Peptides with an IC50 above 100&#x03BC;M were defined as non-binders. For confirmation and statistical significance the assay was performed at least three times for binders and twice for non-binders.</p>
</sec>
<sec id="s8b">
<title>Supplemental tables and figures</title>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1:</label>
<caption><title>Training and validation dataset sizes by MHC allele.</title></caption>
<graphic xlink:href="174243_tblS1.tif"/>
</table-wrap>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><title>ABELIN mass-spec benchmark for NetMHC and several variants of the MHCflurry architecture for non-9-mer peptides (a) and 9-mer peptides (b).</title>
<p>The bars and points are as in main text <xref rid="fig2" ref-type="fig">Figure 2(c)</xref>.</p></caption>
<graphic xlink:href="174243_figS1.tif"/>
</fig>
</sec>
</sec>
</back>
</article>