<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/418756</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Reward-driven changes in striatal pathway competition shape evidence evaluation in decision-making</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7857-5133</contrib-id>
<name><surname>Dunovan</surname><given-names>Kyle</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Vich</surname><given-names>Catalina</given-names></name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Clapp</surname><given-names>Matthew</given-names></name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Verstynen</surname><given-names>Timothy</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
<xref ref-type="author-notes" rid="n2">&#x00B6;</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Rubin</surname><given-names>Jonathan</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
<xref ref-type="author-notes" rid="n2">&#x00B6;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Dept.of Psychology, Carnegie Mellon University</institution></aff>
<aff id="a2"><label>2</label><institution>Center for the Neural Basis of Cognition</institution></aff>
<aff id="a3"><label>3</label><institution>Dept.de Matem&#x00E0;tiques i Inform&#x00E0;tica, Universitat de les Illes Balears</institution></aff>
<aff id="a4"><label>4</label><institution>Dept.of Biomedical Engineering, University of South Carolina</institution></aff>
<aff id="a5"><label>5</label><institution>Dept.of Mathematics, University of Pittsburgh</institution></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label><bold>For correspondence:</bold> <email>timothyv@andrew.cmu.edu</email> (TV); <email>jonrubin@pitt.edu</email> (JR)</corresp>
<fn fn-type="equal" id="n1"><label>&#x2020;</label><p>These authors contributed equally to this work</p></fn>
<fn fn-type="equal" id="n2"><label>&#x00B6;</label><p>These authors also contributed equally to this work</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>418756</elocation-id>
<history>
<date date-type="received">
<day>14</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>14</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>9</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="418756.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Cortico-basal-ganglia-thalamic (CBGT) networks are critical for adaptive decision-making, yet how changes to circuit-level properties impact cognitive algorithms remains unclear. Here we explore how dopaminergic plasticity at corticostriatal synapses alters competition between striatal pathways, impacting the evidence accumulation process during decision-making. Spike-timing dependent plasticity simulations showed that dopaminergic feedback based on rewards modified the ratio of direct and indirect corticostriatal weights within opposing action channels. Using the learned weight ratios in a full spiking CBGT network model, we simulated neural dynamics and decision outcomes in a reward-driven decision task and fit them with a drift-diffusion model. Fits revealed that the rate of evidence accumulation varied with inter-channel differences in direct pathway activity while boundary height varied with overall indirect pathway activity. This multi-level modeling approach demonstrates how complementary learning and decision computations emerge from corticostriatal plasticity.</p>
</abstract>
<counts>
<page-count count="34"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The flexibility of mammalian behavior showcases the dynamic range over which neural circuits can be modified by experience and the robustness of the emergent cognitive algorithms that guide goal-directed actions. Decades of research in cognitive science has independently detailed the algorithms of decision-making (e.g., accumulation-to-bound models, <italic><xref ref-type="bibr" rid="c59">Ratcliff (1978)</xref></italic>) and reinforcement learning (RL; <italic><xref ref-type="bibr" rid="c71">Sutton et al. (1998)</xref></italic>; <italic><xref ref-type="bibr" rid="c62">Rescorla et al. (1972)</xref></italic>), providing foundational insights into the computational principles of adaptive decision-making. In parallel, research in neuroscience has shown how the selection of actions, and the use of feedback to modify selection processes, both rely on a common neural substrate: cortico-basal ganglia-thalamic (CBGT) circuits (<italic><xref ref-type="bibr" rid="c18">Doya, 2008</xref>; <xref ref-type="bibr" rid="c7">Bogacz and Gurney, 2007</xref>; <xref ref-type="bibr" rid="c4">Balleine et al., 2007</xref>; <xref ref-type="bibr" rid="c22">Dunovan and Verstynen, 2016</xref></italic>).</p>
<p>Understanding how the cognitive algorithms for adaptive decision-making emerge from the circuit-level dynamics of CBGT pathways requires a careful mapping across levels of analysis (<italic><xref ref-type="bibr" rid="c52">Marr and Poggio, 1976</xref></italic>), from circuits to algorithm (see also <italic><xref ref-type="bibr" rid="c44">Krakauer et al. (2017)</xref>; <xref ref-type="bibr" rid="c69">Simen et al. (2006)</xref></italic>). Previous simulation studies have demonstrated how the specific circuit-level computations of CBGT pathways map onto sub-components of the multiple sequential probability ratio test (MSPRT; <italic>Bogacz and Gurney</italic> (2007); <italic>Bogacz</italic> (2007)), a simple algorithm of information integration that selects single actions from a competing set of alternatives based on differences in input evidence (<italic><xref ref-type="bibr" rid="c19">Draglia et al., 1999</xref>; <xref ref-type="bibr" rid="c5">Baum and Veeravalli, 1994</xref></italic>). Allowing a simplified form of RL to modify corticostriatal synpatic weights results in an adaptive variant of the MSPRT that approximates the optimal solution to the action selection process based on both sensory signals and feedback learning (<italic><xref ref-type="bibr" rid="c8">Bogacz and Larsen, 2011</xref>; <xref ref-type="bibr" rid="c10">Caballero et al., 2018</xref></italic>). Previous attempts at multi-level modeling have largely adopted a &#x2033;downwards mapping&#x2033; approach, whereby the stepwise operations prescribed by computational or algorithmic models are intuitively mapped onto plausible neural substrates. Recently, <italic><xref ref-type="bibr" rid="c28">Frank (2015)</xref></italic> proposed an alternative &#x2033;upwards mapping&#x2033; approach for bridging levels of analysis, where biologically detailed models are used to simulate behavior that can be fit to a particular cognitive algorithm. Rather than ascribing different neural components with explicit computational roles, this variant of multi-level modeling examines how cognitive mechanisms are influenced by changes in the functional dynamics or connectivity of those components. A key assumption of the upwards mapping approach is that variability in the configuration of CBGT pathways should drive systematic changes in specific sub-components of the decision process, expressed by the parameters of the drift-diffusion model (DDM;<xref ref-type="bibr" rid="c59">Ratcliff <italic>(1978)</italic></xref>). Indeed, by fitting the DDM to synthetic choice and response time data generated by a rate-based CBGT network, <italic><xref ref-type="bibr" rid="c60">Ratcliff and Frank (2012)</xref></italic> showed how variation in the height of the decision threshold tracked with changes in the strength of subthalamic nulceus (STN) activity. Thus, this example shows how simulations that map up the levels of analysis can be used to investigate the emergent changes in information processing that result from targeted modulation of the underlying neural circuitry.</p>
<p>Motivated by the predictions of a recently proposed Believer-Skeptic hypothesis of CBGT pathway function (<italic><xref ref-type="bibr" rid="c22">Dunovan and Verstynen, 2016</xref></italic>), we utilize the upwards mapping approach to modeling adaptive choice behavior across neural and cognitive levels of analysis (<xref ref-type="fig" rid="fig1"><italic>Figure</italic> 1</xref>). The Believer-Skeptic hypothesis posits that competition between the direct (Believer) and indirect (Skeptic) pathways within an action channel encodes the degree of uncertainty for that action. This competition is reflected in the drift rate of an accumulation-to-bound process (see <italic><xref ref-type="bibr" rid="c21">Dunovan et al. (2015)</xref></italic>). Over time, dopaminergic (DA) feedback signals can sculpt the Believer-Skeptic competition to bias decisions towards the behaviorally optimal target (<italic><xref ref-type="bibr" rid="c8">Bogacz and Larsen, 2011</xref></italic>). To explicitly test this prediction, we first modeled how phasic DA feedback signals (<italic><xref ref-type="bibr" rid="c66">Schultz et al., 1992</xref></italic>) can modulate the relative balance of corticostriatal synapses via spike-timing dependent plasticity (STDP;<xref ref-type="bibr" rid="c34">Gurney <italic>et al. (2015)</italic></xref>; <italic><xref ref-type="bibr" rid="c3">Baladron et al. (2017)</xref></italic>), thereby promoting or deterring action selection. The effects of learning on the synaptic weights were subsequently implemented in a spiking model of the full CBGT network meant to accurately capture the known physiological properties and connectivity patterns of the constituent neurons in these circuits (<italic><xref ref-type="bibr" rid="c75">Wei et al., 2015</xref></italic>). The performance (i.e., accuracy and response times) of the CBGT simulations were then fit using a hierarchical DDM (<italic><xref ref-type="bibr" rid="c77">Wiecki and Frank, 2013</xref></italic>). This progression from synapses to networks to behavior, allows us to explicitly test the mechanistic predictions of the Believer-Skeptic hypothesis by mapping how specific features of striatal activity that result from reward-driven changes in corticostriatal synaptic weights could underlie parameters of the fundamental cognitive algorithms of decision-making.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>STDP network results</title>
<p>To evaluate how dopaminergic plasticity impacts the efficacy of corticostriatal synapses, we modeled learning using a spike-timing dependent plasticity (STDP) paradigm in a simulation of corticostriatal networks implementing a simple two artificial forced choice task. In this scenario, one of two available actions, which we call left (L) and right (R), was selected by the spiking of model striatal medium spiny neurons (MSNs; <italic>Action and rewards</italic> subsection of <italic>Methods</italic>). These model MSNs were grouped into action channels receiving inputs from distinct cortical sources (<italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic>, left). Every time an action was selected, dopamine was released, after a short delay, at an intensity proportional to a reward prediction error (<italic><xref ref-type="disp-formula" rid="eqn9">Equation 9</xref></italic> and <italic><xref ref-type="disp-formula" rid="eqn10">Equation 10</xref></italic>). All neurons in the network experienced this non-targeted increase in dopamine, emulating striatal release of dopamine by substantia nigra pars compacta neurons, leading to plasticity of corticostriatal synapses (<italic><xref ref-type="disp-formula" rid="eqn8">Equation 8</xref>;</italic> see <xref rid="fig10" ref-type="fig">Figure 10</xref>).</p>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><p>Evolution of the learning rule variables for particular dMSNs, one promoting the <italic>L</italic> action (black, actual reward value 0.7) and one promoting the <italic>R</italic> action (red, actual reward value 0.1). Each panel represents corresponding variables for both neurons except <italic>K</italic><sub><italic>DA</italic></sub>(<italic>t</italic>), which is common across all neurons. For each example neuron, the top panel shows its membrane potential (dark trace) and the cortical spike trains it receives (light trace with many spikes). This panel also represents the action onset times: green and orange dots if actions <italic>L</italic> and <italic>R</italic> occur, respectively. Different example cases labeled with letters (A,B,C,D,E,F) are described in the text in the <italic>Example implementation</italic> subsection.</p></caption>
<graphic xlink:href="418756_fig10.tif"/>
</fig>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Multi-level modeling design. Left: An STDP model of DA effects on Ctx-dMSN and Ctx-iMSN synapses is used to determine how phasic DA signals affect the balance of these synapses. Middle: A spiking model of the CBGT pathways simulates behavioral responses, under different conditions of Ctx-MSN efficacy based on the STDP simulations. Right: The simulated behavioral responses from the full CBGT network model are then fit to a DDM of two-alternative choice behavior. Notation: <italic>j &#x2212; Ctx</italic> &#x2212; cortical population, <italic>j &#x2212; dMSN</italic> &#x2212; direct pathway striatal neurons, <italic>j &#x2212; iMSN</italic> &#x2212; indirect pathway striatal neurons (j &#x2208; {<italic>L, R</italic>}); DA - dopamine signal; STR - striatum; GPe - globus pallidus external segment;STN - subthalamic nucleus;GPi - globus pallidus internal segment;FSI - fast spiking interneuron;RT - reaction time;&#x03BC; - DDM drift rate;&#x201D; - separation between boundaries in DDM;z - bias in starting height of DDM;tr - time after which evidence accumulation begins in DDM.</p></caption>
<graphic xlink:href="418756_fig1.tif"/>
</fig>
<p>The model network was initialized so that it did not a priori distinguish between <italic>L</italic> and <italic>R</italic> actions. We first performed simulations in which a fixed reward level was associated with each action, to assist in parameter tuning and verify effective model operation. In this scenario, where the rewards for each action did not change over time (i.e., one action always elicited a larger reward than the other), a gradual change in corticostriatal synaptic weights occurred (<xref ref-type="fig" rid="figS1">Supplementary <italic>Figure</italic> 1A</xref>) in parallel with the learning of the actions&#x2019; values (<xref ref-type="fig" rid="figS1">Supplementary <italic>Figure</italic> 1B</xref>). These changes in synaptic weights induced altered MSN firing rates (<xref ref-type="fig" rid="figS1">Supplementary <italic>Figure</italic> 1C,D</xref>), reflecting changes in the sensitivity of the MSNs to cortical inputs in a way that allowed the network to learn over time to select the more highly rewarded action (<xref ref-type="fig" rid="fig2"><italic>Figure</italic> 2A</xref>). That is, firing rates in the direct pathway MSNs (dMSNs; <italic>D</italic><sub><italic>L</italic></sub> and <italic>D</italic><sub><italic>R</italic></sub><italic>)</italic> associated with the more highly rewarded action increased, lead to a more frequent selection of that action. On the other hand, firing rates of the indirect pathway MSNs (iMSNs; <italic>I</italic><sub><italic>L</italic></sub> and <italic>I</italic><sub><italic>R</italic></sub><italic>)</italic> remained quite similar (<xref ref-type="fig" rid="figS1">Supplementary <italic>Figure</italic> 1C,D</xref>). This similarity is consistent with recent experimental results (<italic><xref ref-type="bibr" rid="c17">Donahue et al., 2018</xref></italic>), while the finding that dMSNs and iMSNs associated with a selected action are both active has also been reported in several experimental works (<italic><xref ref-type="bibr" rid="c14">Cui et al., 2013</xref>; <xref ref-type="bibr" rid="c73">Tecuapetla et al., 2014</xref>, <xref ref-type="bibr" rid="c72">2016</xref></italic>).</p>
<p>In this model, indirect pathway activity counters action selection by cancelling direct pathway spiking <italic>(Action and rewards</italic> subsection of <italic>Methods</italic>). This serves as a proxy in this simplified framework for indirect pathway competition with the direct pathway in the full network simulations (see <italic>CBGT Dynamics and Choice Behavior</italic> subsection of <italic>Results</italic>). Based on the cancellation framework, the ratio of direct pathway weights to indirect pathway weights provides a reasonable representation of the extent to which each action is favored or disfavored. In our simulations, after a long period of gradual evolution of weights and action values, the direct pathway versus indirect pathway weight ratio of the channel for the less favored action started to drop more rapidly, indicating the emergence of certainty about action values and a clearer separation between frequencies with which the two actions were selected (<italic><xref rid="fig2" ref-type="fig">Figure 2</xref></italic>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Constant reward task. A: Frequency of performance of <italic>L</italic> (black) and <italic>R</italic> (red) actions over time (discretized each 50ms) when the rewards are held constant <italic>(r</italic><sub><italic>L</italic></sub> = 0.7,<italic>r</italic><sub><italic>R</italic></sub> = 0.1). Both traces are averaged across 7 different realizations. The transparent regions depict standard deviations. B: Estimates of the value of <italic>L (Q</italic><sub><italic>L</italic></sub>, left panel) and <italic>R (Q</italic><sub><italic>R</italic></sub>, right panel) versus the ratio of the corticostriatal weights to those dMSN neurons that facilitate the action and those iMSN that interfere with the action. Each trajectory is colored to show the progression of time. Even without full convergence of the action values <italic>Q</italic><sub><italic>R</italic></sub> and <italic>Q</italic><sub><italic>L</italic></sub> to their respective actual reward levels (B), a clear separation of action selection rates emerges (A).</p></caption>
<graphic xlink:href="418756_fig2.tif"/>
</fig>
<p>To show that the network remained flexible after learning a specific action value relation, we ran additional simulations using a variety of reward schedules in which the reward values associated with the two actions were swapped after the performance of a certain number of actions. Once values switched, the network was always able to learn the new values. Specifically, <italic>Q</italic><sub><italic>L</italic></sub> and <italic>Q</italic><sub><italic>R</italic></sub> began evolving toward the new reward levels, switching their relative magnitudes along the way; the weights of corticostriatal synapses to L-dMSN (R-dMSN) weakened (strengthened) (e.g., <xref ref-type="fig" rid="figA1"><italic>Appendix1 Figure</italic> 1</xref>), and the relative performance frequencies of the two actions also reversed. Thus the network was able to adaptively learn immediate reward contingencies, without being restricted by previously learned contingencies.</p>
<p>While these simulations show that applying a dopaminergic plasticity rule to corticostriatal synapses allows for a simple network to learn action values linked to reward magnitude, many reinforcement learning tasks rely on estimating reward probability (e.g., two armed bandit tasks). To evaluate the network&#x2019;s capacity to learn from probabilistic rewards, we simulated a variant of a probabilistic reward task and compared the network performance to previous experimental results on action selection with probabilistic rewards in human subjects (<italic><xref ref-type="bibr" rid="c29">Frank et al., 2015</xref></italic>). For consistency with experiments, we always used <italic>p</italic><sub><italic>L</italic></sub> <italic>&#x002B; p</italic><sub><italic>R</italic></sub> <italic>=</italic> 1, where <italic>p</italic><sub><italic>L</italic></sub> and <italic>p</italic><sub><italic>R</italic></sub> were the probabilities of delivery of a reward of size <italic>r</italic><sub><italic>i</italic></sub> = 1 when actions <italic>L</italic> and <italic>R</italic> were performed, respectively. Moreover, as in the earlier work, we considered the three cases <italic>p</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.65 (high conflict), <italic>p</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.75 (medium conflict) and <italic>p</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.85 (low conflict).</p>
<p>As in the constant reward case, the corticostriatal synaptic weights onto the two dMSN populations clearly separated out over time (<xref ref-type="fig" rid="fig3"><italic>Figure</italic> 3</xref>). The separation emerged earlier and became more drastic as the conflict between the rewards associated with the two actions diminished, i.e., as reward probabilities became less similar. Interestingly, for relatively high conflict, corresponding to relatively low <italic>p</italic><sub><italic>L</italic></sub>, the weights to both dMSN populations rose initially before those onto the less rewarded population eventually diminished. This initial increase likely arises because both actions yielded a reward of 1, leading to a significant dopamine increase, on at least some trials. The weights onto the two iMSN populations remained much more similar. One general trend was that the weights onto the L-iMSN neurons decreased, contributing to the bias toward action <italic>L</italic> over action R.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Corticostriatal synaptic weights when the reward traces are probabilistic. First column: <italic>p</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.65; second column: <italic>p</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.75; third column: <italic>p</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.85 case. A, B, and C: Averaged weights over each of four specific populations of neurons, which are dMSN neurons selecting action <italic>L</italic> (solid black);dMSN neurons selecting action <italic>R</italic> (solid red);iMSN neurons countering action <italic>L</italic> (dashed black);iMSN neurons countering action <italic>R</italic> (dashed red). D, E, and F: Evolution of the estimates of the value <italic>L (Q</italic><sub><italic>L</italic></sub>, left panel) and <italic>R (Q</italic><sub><italic>R</italic></sub>, right panel) versus the ratio of the corticostriatal weights to those dMSN neurons that facilitate the action versus the weights to those iMSN that interfere with the action. Both the weights and the ratios have been averaged over 8 different realizations.</p></caption>
<graphic xlink:href="418756_fig3.tif"/>
</fig>
<p>In all three cases, the distinction in synaptic weights translated into differences across the dMSNs&#x2019; firing rates (<italic><xref rid="fig4" ref-type="fig">Figure 4</xref></italic>, first row), with L-dMSN firing rates (D<sub>L</sub>) increasing over time and R-dMSN firing rates (D<sub>R</sub>) decreasing, resulting in a greater difference that emerged earlier when <italic>p</italic><sub><italic>L</italic></sub> was larger and hence the conflict between rewards was weaker. Notice that the <italic>D</italic><sub><italic>L</italic></sub> firing rate reached almost the same value for all three probabilities. In contrast, the <italic>D</italic><sub><italic>R</italic></sub> firing rate tended to smaller values as the conflict decreased. As expected based on the changes in corticostriatal synaptic weights, the iMSN population firing rates remained similar for both action channels, although the rates were slightly lower for the population corresponding to the action that was more likely to yield a reward (<xref ref-type="fig" rid="fig4"><italic>Figure</italic> 4F</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Firing rates when the reward traces are probabilistic. First column: <bold><italic>p</italic><sub><italic>L</italic></sub></bold> = 0.65; second column: <bold><italic>p</italic><sub><italic>L</italic></sub></bold> = 0.75; third column: <bold><italic>p</italic><sub><italic>L</italic></sub></bold> = 0.85 case. A, B and C: Time courses of firing rates of the dMSNs selecting the <bold><italic>L</italic></bold> (black) and <bold><italic>R</italic></bold> (red) actions (50 <bold><italic>ms</italic></bold> time discretization). D, E, and F: Time courses of firing rates of the iMSNs countering the <bold><italic>L</italic></bold> (black) and <bold><italic>R</italic></bold> (red) actions (50<bold><italic>ms</italic></bold> time discretization). In all cases, we depict the mean averaged across 8 different realizations, and the transparent regions represent standard deviations.</p></caption>
<graphic xlink:href="418756_fig4.tif"/>
</fig>
<p>Similar trends across conflict levels arose in the respective frequencies of selection of action L. Over time, as weights to L-dMSN neurons grew and their firing rates increased, action <italic>L</italic> was selected more often, becoming gradually more frequent than action R. Not surprisingly, a significant difference between frequencies emerged earlier, and the magnitude of the difference became greater, for larger <italic>p</italic><sub><italic>L</italic></sub> (<italic><xref rid="fig5" ref-type="fig">Figure 5</xref></italic>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Action frequencies when reward delivery is probabilistic. All panels represent the number of <bold><italic>L</italic></bold> (black) and <bold><italic>R</italic></bold> (red) actions performed across time (discretized each 50ms) when action selection is rewarded with probability <bold><italic>p</italic><sub><italic>L</italic></sub></bold> = 0.65 (A), <bold><italic>p</italic><sub><italic>L</italic></sub></bold> = 0.75 (B), or <bold><italic>p</italic><sub><italic>L</italic></sub></bold> = 0.85 (C) with <bold><italic>p</italic><sub><italic>L</italic></sub></bold> &#x002B; <bold><italic>p</italic><sub><italic>R</italic></sub></bold> = 1. Traces represent the means over 8 different realizations, while the transparent regions depict standard deviations.</p></caption>
<graphic xlink:href="418756_fig5.tif"/>
</fig>
<p>To show that this feedback learning captured experimental observations, we performed additional probabilistic reward simulations to compare with behavioral data in forced-choice experiments with human subjects (<italic><xref ref-type="bibr" rid="c29">Frank et al., 2015</xref></italic>). Each of these simulations represented an experimental subject, and each action selection was considered as the outcome of one trial performed by that subject. After each trial, a time period of 50 <italic>ms</italic> was imposed during which no cortical inputs were sent to striatal neurons such that no actions would be selected, and then the full simulation resumed. For these simulations, we considered the evolution of the value estimates for the two actions either separately for each subject (<xref ref-type="fig" rid="fig6"><italic>Figure</italic> 6A</xref>) or averaged over all subjects experiencing the same reward probabilities (<xref ref-type="fig" rid="fig6"><italic>Figure</italic> 6B</xref>), as well as the probability of selection of action <italic>L</italic> averaged over subjects (<xref ref-type="fig" rid="fig6"><italic>Figure</italic> 6C</xref>). The mean in the difference between the action values gradually tended toward the difference between the reward probabilities for all conflict levels. Although convergence to these differences was generally incomplete over the number of trials we simulated (matched to the experiment duration), these differences were close to the actual values for many individual subjects as well as in mean (<xref ref-type="fig" rid="fig6"><italic>Figure</italic> 6A,B</xref>). These results agree quite well with the behavioral data in <italic><xref ref-type="bibr" rid="c29">Frank et al. (2015)</xref></italic> obtained from 15 human subjects, as well as with observations from similar experiments with rats (<italic><xref ref-type="bibr" rid="c74">Tort et al., 2009</xref></italic>). Also as in the experiments, the probability of selection of the more rewarded action grew across trials for all three reward probabilities, with less separation in action selection probability than in action values across different reward probability regimes (<xref ref-type="fig" rid="fig6"><italic>Figure</italic> 6C</xref>). Although our actual values for the probabilities of selection of higher value actions did not reach the levels seen experimentally, this likely reflected the non-biological action selection rule in our STDP model (see <italic>Action and rewards</italic> subsection of <italic>Methods</italic>), whereas the agreement of our model performance with experimental time courses of value estimation (<xref ref-type="fig" rid="fig6"><italic>Figure</italic> 6A,B</xref>) and our model&#x2019;s general success in learning to select more valuable actions (<italic>Figure</italic> 1C-Suppl. figure and <xref ref-type="fig" rid="fig5"><italic>Figure</italic> 5</xref>) justify the incorporation of our results on corticostriatal synaptic weights into a spiking network with a more biologically-based decision-making mechanism, which we next discuss.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Relative action value estimates and action selection probabilities over simulated action selection trials with probabilistic reward schedules, with <italic>p</italic><sub><italic>L</italic></sub> = 0.65 (dark blue), <italic>p</italic><sub><italic>L</italic></sub> = 0.75 (cyan), <italic>p</italic><sub><italic>L</italic></sub> = 0.85 (yellow) and <italic>p</italic><sub><italic>L</italic></sub> &#x002B; <italic>p</italic><sub><italic>R</italic></sub> = 1. A: Difference in action value estimates over trials in a collection of individual simulations. B: Means and standard deviations of difference in action value estimates across 8 simulations. C: Percent of trials on which the <italic>L</italic> action with higher reward probability was selected.</p></caption>
<graphic xlink:href="418756_fig6.tif"/>
</fig>
</sec>
<sec id="s2b">
<title>CBGT Dynamics and Choice Behavior</title>
<p>A key observation from our STDP model is that differences in rewards associated with different actions lead to differences in the ratios of corticostriatal synaptic weights to dMSN and iMSNs across action channels. Using weight ratios adapted from the STDP model, obtained by varying weights to dMSNs with fixed weights to iMSNs (<xref rid="fig3" ref-type="fig">Figure 3</xref>), we next performed simulations with a full spiking CBGT network to study the effects of this corticostriatal imbalance on the emergent neural dynamics and choice behavior following feedback-dependent learning in the context of low, medium, and high probability reward schedules (2500 trials/condition; see <italic>Neural dynamics</italic> subsection of <italic>Methods</italic> for details). In each simulation, cortical inputs featuring gradually increasing firing rates were supplied to both action channels, with identical statistical properties of inputs to both channels. These inputs led to evolving firing rates in nuclei throughout the basal ganglia, also partitioned into action channels, with an eventual action selection triggered by the thalamic firing rate in one channel reaching 30<italic>Hz</italic> (<italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic>, center and <xref ref-type="fig" rid="fig7"><italic>Figure</italic> 7</xref>). We found that both dMSN and iMSN firing rates gradually increased in response to cortical inputs. Consistent with our STDP simulations (<xref ref-type="fig" rid="fig4"><italic>Figure</italic> 4</xref>), dMSN firing rates became higher in the channel for the selected action. Interestingly, iMSN firing rates also became higher in the selected channel, consistent with recent experiments (see <italic><xref ref-type="bibr" rid="c56">Parker et al. (2018)</xref></italic>, among others). Similar to the activity patterns observed in the striatum, higher firing rates were also observed in the selected channel&#x2019;s STN and thalamic populations, whereas GPe and GPi firing rates were higher in the unselected channel (<xref ref-type="fig" rid="fig7"><italic>Figure</italic> 7</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Single trial example of CBGT dynamics. Population firing rates of CBGT nuclei, computed as the average of individual unit firing rates within each nucleus in <italic>L</italic> (black) and <italic>R</italic> (red) action channels are shown for a single representative trial in the high reward probability condition. The selected action <italic>(L)</italic> and corresponding RT (324<italic>ms)</italic> are determined by the first action channel to raise its thalamic firing rate to 30 Hz.</p></caption>
<graphic xlink:href="418756_fig7.tif"/>
</fig>
<p>More generally across all weight ratio conditions, dMSNs and iMSNs exhibited a gradual ramping in population firing rates (<italic><xref ref-type="bibr" rid="c79">Yartsev et al., 2018</xref></italic>) that eventually saturated around the average RT in each condition (<xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8A</xref>). To characterize the relevant dimensions of striatal activity that contributed to the network&#x2019;s behavior, we extracted several summary measures of dMSN and iMSN activity, shown in <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B-C</xref>. Summary measures of dMSN and iMSN activity in the <italic>L</italic> and <italic>R</italic> channels were calculated by estimating the area under the curve (AUC) of the population firing rate between the time of stimulus onset (200<italic>ms)</italic> and the RT on each trial. Trialwise AUC estimates were then normalized between values of 0 and 1, including estimates from all trials in all conditions in the normalization. As expected, increasing the disparity of left and right Ctx-dMSN weights led to greater differences in direct pathway activation between the two channels (i.e., <italic>D</italic><sub><italic>L</italic></sub> <italic>&#x003E; D</italic><sub><italic>R</italic></sub>; <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B</xref>). The increase in <italic>D</italic><sub><italic>L</italic></sub> &#x2212; <italic>D</italic><sub><italic>R</italic></sub> reflects a form of competition <italic>between</italic> action channels, where larger values indicate stronger dMSN activation in the optimal channel and/or a weakening of dMSN activity in the suboptimal channel. Similarly, increasing the weight of Ctx-dMSN connections caused a shift in the competition between dMSN and iMSN populations <italic>within</italic> the left action channel (i.e., <italic>D</italic><sub><italic>L</italic></sub> &#x003E; <italic>I</italic><sub><italic>L</italic></sub>). Thus, manipulating the weight of Ctx-dMSN connections to match those predicted by the STDP model led to both between- and within-channel biases favoring firing of the direct pathway of the optimal action channel in proportion to its expected reward value.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Striatal pathway dynamics and behavioral effects of reward probability in full CBGT network. A: Time courses show the average population firing rates for <italic>L</italic> (black) and <italic>R</italic> (red) dMSNs (top) and iMSNs (bottom) over the the trial window. Shaded areas reflect 95&#x0025; CI. Colored vertical lines depict the average RT in the low (blue), medium (cyan), and high (yellow) reward conditions. B and C: Summary statistics of dMSN and iMSN population firing rates were extracted on each trial and later included as trial-wise regressors on parameters of the DDM, allowing specific hypotheses to be tested about the mapping between neural and cognitive mechanisms. In B, lighter colored bars show the difference between dMSN firing rates in the <italic>L</italic> and <italic>R</italic> action channels whereas darker colored bars show the difference between dMSN and iMSN firing rates in the <italic>L</italic> action channel, both computed by summing the average firing rate of each population between trial onset and the RT on each trial. In C, lighter colored bars show the difference between iMSN firing rates in the <italic>L</italic> and <italic>R</italic> action channels and darker colored bars show the average iMSN firing rate (combined across left and right channels). Error bars show the bootstrapped 95&#x0025; CI. D: Average accuracy (probability of choosing L) and RT (L choices only) of CBGT choices across levels of reward probability. E: RT distributions for correct choices across levels of reward probability; note that higher reward yields more correct trials. Error bars in B-D show the bootstrapped 95&#x0025; CI.</p></caption>
<graphic xlink:href="418756_fig8.tif"/>
</fig>
<p>Interestingly, although the weights of Ctx-iMSN connections were kept constant across conditions, iMSN populations showed reliable differences in activation between channels (<xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8C</xref>). Similar to the observed effects on direct pathway activation, higher reward conditions were associated with progressively greater differences in the AUC of L and <italic>R</italic> indirect pathway firing rates <italic>(I</italic><sub><italic>L</italic></sub> &#x2212; <italic>I</italic><sub>R</sub>). At first glance, greater indirect pathway activation in higher compared to lower valued action channels differs from the similarity of activation levels of both indirect pathway channels that we obtained in the STDP model and also appears to be at odds with canonical theories of the roles of the direct and indirect pathways in RL and decision-making. This finding can be explained, however, based on a certain feature represented in the connections within the CBGT network but not within the STDP network, namely thalamo-striatal feedback between channels. That is, the strengthening and weakening of Ctx-dMSN weights in the <italic>L</italic> and <italic>R</italic> channels, respectively, translated into relatively greater downstream disinhibition of the thalamus in the <italic>L</italic> channel, which increased excitatory feedback to L-dMSNs and L-iMSNs while reducing thalamo-striatal feedback to R-MSNs in both pathways.</p>
<p>Finally, we examined the effects of reward probability on the AUC of all iMSN firing rates <italic>(I</italic><sub>all</sub>; combining across action channels). Observed differences in <italic>I</italic><sub><italic>all</italic></sub> across reward conditions were notably more subtle than those observed for other summary measures of striatal activity, with greatest activity in the medium reward condition, followed by the high and low reward conditions, respectively.</p>
<p>In addition to analyzing the effects of altered Ctx-dMSN connectivity strength on the functional dynamics of the CBGT network, we also studied how the decision-making behavior of the CBGT network was influenced by this manipulation. Consistent with previous studies of value-based decision-making in humans (<italic><xref ref-type="bibr" rid="c51">Manohar et al., 2015</xref>; <xref ref-type="bibr" rid="c58">Polan&#x00ED;a et al., 2014</xref>;</italic> <xref ref-type="bibr" rid="c1">Afacan-Seref et al., 2018</xref>; <xref ref-type="bibr" rid="c30">Gardner et al., 2017</xref>; <xref ref-type="bibr" rid="c38">Jahfari et ai., 2017</xref>), weobserveda positive effect of reward probability on both the frequency and speed of correct (e.g., leftward, associated with higher reward probability) choices (<xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8D</xref>). Bootstrap sampling (10,000 samples) was performed to estimate 95&#x0025; confidence intervals (CI<sub>95</sub>) around RT and accuracy means (&#x03BC;) in each condition, and to assess the statistical significance of pairwise comparisons between conditions. Choice accuracy increased across low (&#x03BC; <italic>=</italic> 64&#x0025;, CI<sub>95</sub> = [62,65]), medium (&#x03BC; = 85&#x0025;, CI<sub>95</sub> = [84,86]), and high (&#x03BC; = 100&#x0025;, CI<sub>95</sub> = [100,100]) reward probabilities. Pairwise comparisons revealed that the increase in accuracy observed between low and medium conditions, as well as that observed between medium and high conditions, reached statistical significance (both <italic>p</italic> &#x003C; 0.0001). Along with the increase in accuracy across conditions, we observed a concurrent decrease in the RT of correct (L) choices in the low (&#x03BC; = 477ms, CI<sub>95</sub> = [472,483]), medium (&#x03BC; = 467ms, CI<sub>95</sub> = [462,471]), and high (&#x03BC; = 460ms, CI<sub>95</sub> = [456,464]) reward probability conditions. Notably, our manipulation of Ctx-dMSN weights across conditions manifested in stronger effects on accuracy (i.e., probability of choosing the more valuable action), with subtler effects on RT. Specifically, the decrease in RT observed between the low and medium conditions reached statistical significance (p &#x003C; .0001);however, the RT decrease observed between the medium and high conditions did not (<italic>p</italic> = .13).</p>
<p>We also examined the distribution of RTs for <italic>L</italic> responses across reward conditions (<xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8E</xref>). All conditions showed a rightward skew in the distribution of RTs, an empirical hallmark of simple choice behavior and a useful check of the suitability of accumulation-to-bound models like the DDM for modeling a particular behavioral data set. Moreover, the degree of skew in the RT distributions for <italic>L</italic> responses became more pronounced with increasing reward probability, suggesting that the observed decrease in the mean RT at higher levels of reward was driven by a change in the shape of the distribution, and not, for instance, a temporal shift in its location.</p>
</sec>
<sec id="s2c">
<title>CBGT-DDM Mapping</title>
<p>We performed fits of a normative DDM to the CBGT network&#x2019;s decision-making performance (i.e., accuracy and RT data) to understand the effects of corticostriatal plasticity on emergent changes in decision behavior. This process was implemented in three stages. First, we compared models in which only one free DDM parameter was allowed to vary across levels of reward probability (single parameter DDMs). Next, a second round of fits was performed in which a second free DDM parameter was included in the best-fitting single parameter model identified in the previous stage (dual parameter DDMs). Finally, the two best-fitting dual parameter models were submitted to a third and final round of fits with the inclusion of trialwise measures of striatal activity (see <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B-C</xref>) as regressors on designated parameters of the DDM.</p>
<p>All models were evaluated according to their relative improvement in performance compared to a null model in which all parameters were fixed across conditions. To identify which single parameter of the DDM best captured the behavioral effects of alterations in reward probability as represented by Ctx-dMSN connectivity strength, we compared the deviance information criterion (DIC) of models in which either the boundary height (a), the onset delay (<italic>tr</italic>), the drift rate (v), or the starting-point bias (z) was allowed to vary across conditions. <italic><xref rid="fig9" ref-type="fig">Figure 9A</xref></italic> shows the difference between the DIC score of each model (DIC<sub>M</sub>) and that of the null model (ADIC = DIC<sub>M</sub> &#x2212; DIC<sub>ra</sub>"), with lower values indicating a better fit to the data (see <italic><xref rid="tbl1" ref-type="table">Table 1</xref></italic> for additional fit statistics). Conventionally, a DIC difference (ADIC) of magnitude 10 or more is regarded as strong evidence in favor of the model with the lower DIC value (<italic><xref ref-type="bibr" rid="c9">Burnham and Anderson, 1998</xref></italic>). Compared to the null model as well as alternative single parameter models, allowing the drift rate <italic>v</italic> to vary across conditions afforded a significantly better fit to the data (ADIC = &#x2212;960.79). Examination of posterior distributions of <italic>v</italic> in the best-fitting single parameter model revealed a significant increase in <italic>v</italic> with successively higher levels of reward probability <italic>(v</italic><sub><italic>Low</italic></sub> = .35; <italic>v</italic><sub><italic>Mei</italic></sub> = 1.61; <italic>v</italic><sub><italic>High</italic></sub> = 2.71), capturing the observed increase in speed and accuracy across conditions by increasing the rate of evidence accumulation toward the upper (<italic>L</italic>) decision threshold.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Single- and dual-parameter DDM goodness-of-fit statistics. DIC is a complexity-penalized measure of model fit, DIC = D(&#x03B8;) &#x002B; <italic>pD</italic>, where D(&#x03B8;) is the deviance of model fit under the optimized parameter set <italic>6</italic> and <italic>pD</italic> is the effective number of parameters. ADIC is the difference between each model&#x2019;s DIC and that of the null model for which all parameters are fixed across conditions. Asterisks denote models providing best fits within the single-parameter group (&#x002A;) and across both groups (&#x002A;&#x002A;).</p></caption>
<graphic xlink:href="418756_tbl1.tif"/>
</table-wrap>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><p>DDM fits to CBGT-simulated behavior reveals pathway-specific effects on drift rate and threshold mechanisms. A: ADIC scores, showing the relative goodness-of-fit of all single- and dual-parameter DDMs considered (top) and all DDM regression models considered (bottom) compared to that of the null model (all parameters held constant across conditions;see <italic><xref rid="tbl2" ref-type="table">Table 2</xref></italic>). The ADIC score of the best-fitting model at each stage is plotted in green. The best overall fit was provided by DDM regression model III. B: DDM schematic showing the change in <italic>v</italic> and <italic>a</italic> across low (blue), medium (cyan), and high (yellow) reward conditions, with the threshold for <italic>L</italic> and <italic>R</italic> represented as the upper and lower boundaries, respectively. C: Posterior distributions showing the estimated weights for neural regressors on <italic>a</italic>, which was estimated on each trial as a function of the average iMSN firing rate across left and right action channels (see <italic>I</italic><sub><italic>all</italic></sub> in <italic><xref ref-type="fig" rid="fig8">Figure 8C</xref></italic>), and v, which was estimated on each trial as a function of the the difference between dMSN firing rates in the left and right channels (see <italic>D</italic><sub><italic>L</italic></sub> <italic>- D</italic><sub><italic>R</italic></sub> in <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B</xref>). D: Histograms and kernel density estimates showing the CBGT-simulated and DDM-predicted RT distributions, respectively. E: Point plots showing the CBGT network&#x2019;s average accuracy and RT across reward conditions overlaid on bars showing the DDM-predicted averages.</p></caption>
<graphic xlink:href="418756_fig9.tif"/>
</fig>
<p>To investigate potential interactions between the drift rate and other parameters of the DDM, we performed another round of fits in which a second free parameter (either <italic>a, tr</italic>, or <italic>z</italic>), in addition to v, was allowed to vary across conditions (<xref ref-type="fig" rid="fig9"><italic>Figure</italic> 9A</xref>). Compared to alternative dual-parameter models, the combined effect of allowing <italic>v</italic> and <italic>a</italic> to vary across conditions (Fig. <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B,C</xref>) provided the greatest improvement in model fit over the null model (ADIC = &#x2212;1174.07), as well as over the best-fitting single parameter model (DIC<sub><italic>v,a</italic></sub> &#x2212; DIC<sub><italic>v</italic></sub> = &#x2212;213.27). While the dual <italic>v</italic> and <italic>a</italic> model significantly outperformed both alternatives (DIC<sub><italic>v,a</italic></sub> &#x2212; DIC<sub><italic>v,t</italic></sub> = &#x2212;205.89; DIC<sub><italic>v,a</italic></sub> &#x2212; DIC<sub><italic>v,z</italic></sub> = &#x2212;184.05), the second best-fitting dual parameter model, in which <italic>v</italic> and <italic>z</italic> were left free across conditions, also afforded a significant improvement over the drift-only model (DIC<sub><italic>v,z</italic></sub> &#x2212; DIC<sub><italic>v</italic></sub> = &#x2212;29.23). Thus, both <italic>v, a</italic> and <italic>v, z</italic> dual parameter models were considered in a third and final round of fits. The third round was motivated by the fact that, while behavioral fits can yield reliable and informative insights about the cognitive mechanisms engaged by a given experimental manipulation, recent studies have effectively combined behavioral observations with coincident measures of neural activity to test more precise hypotheses about the neural dynamics involved in regulating different cognitive mechanisms (<italic><xref ref-type="bibr" rid="c36">Herz et al., 2016</xref>, <xref ref-type="bibr" rid="c35">2018</xref>; <xref ref-type="bibr" rid="c29">Frank et al., 2015</xref></italic>). To this end, we refit the <italic>v,a</italic> and <italic>v, z</italic> models to the same simulated behavioral dataset (i.e., accuracy and RTs produced by the CBGT network) as in the previous rounds, with the addition of different trialwise measures of striatal activity included as regressors on one of the two free parameters in the DDM.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><p>DDM regression models and goodness-of-fit statistics. Asterisk denotes best performing model.</p></caption>
<graphic xlink:href="418756_tbl2.tif"/>
</table-wrap>
<p>For each regression DDM (N=24 models, corresponding to 24 ways to map 2 of 6 striatal activity measures to the <italic>v,a</italic> and <italic>v,z</italic> models), one of the summary measures shown in <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B-C</xref> was regressed on v, and another regressed on either <italic>a</italic> or z, with separate regression weights estimated for each level of reward probability. Model fit statistics are shown for each of the 24 regression models in <italic><xref rid="tbl2" ref-type="table">Table 2</xref></italic>, along with information about the neural regressors included in each model and their respective parameter dependencies. The relative goodness-of-fit afforded by all 24 regression models is visualized in <xref ref-type="fig" rid="fig9"><italic>Figure</italic> 9A</xref> (lower panel), identifying what we have labelled as model III as the clear winner with an overall DIC = &#x2212;18860.37 and with ADIC = &#x2212;9716.17 compared to the null model. In model III, the drift rate <italic>v</italic> on each action selection trial depended on the relative strength of direct pathway activation in <italic>L</italic> and <italic>R</italic> action channels (e.g., <italic>D</italic><sub><italic>L</italic></sub> &#x2212; <italic>D</italic><sub><italic>R</italic></sub>), whereas the boundary height <italic>a</italic> on that trial was computed as a function of the overall strength of indirect pathway activation across both channels (e.g., <italic>I</italic><sub><italic>all</italic></sub>). To determine how these parameter dependencies influenced levels of <italic>v</italic> and <italic>a</italic> across levels of reward probability, the following equations were used to transform intercept and regression coefficient posteriors into posterior estimates of <italic>v</italic> and <italic>a</italic> for each condition <italic>j</italic>:
<disp-formula id="eqn1"><alternatives><graphic xlink:href="418756_eqn1.gif"/></alternatives></disp-formula>
<disp-formula id="eqn2"><alternatives><graphic xlink:href="418756_eqn2.gif"/></alternatives></disp-formula>
where <italic>&#x0394;D</italic><sub><italic>j</italic></sub> and <italic>I</italic><sub><italic>j</italic></sub> are the mean values of <italic>D</italic><sub><italic>L</italic></sub> &#x2212; <italic>D</italic><sub><italic>R</italic></sub> and <italic>I</italic><sub><italic>all</italic></sub> in condition <italic>j</italic> (see <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B-C</xref>), <inline-formula><alternatives><inline-graphic xlink:href="418756_inline1.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="418756_inline2.gif"/></alternatives></inline-formula> are posterior distributions for <italic>v</italic> and <italic>a</italic> intercept terms, and <inline-formula><alternatives><inline-graphic xlink:href="418756_inline3.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="418756_inline4.gif"/></alternatives></inline-formula> are the posterior distributions estimated for the linear weights relating <italic>D</italic><sub><italic>L</italic></sub> &#x2212; <italic>D</italic><sub><italic>R</italic></sub> and <italic>I</italic><sub><italic>all</italic></sub> to <italic>v</italic> and a, respectively. The observed effects of reward probability on <italic>v</italic> and a, as mediated by trialwise changes in <italic>D</italic><sub><italic>L</italic></sub> &#x2212; <italic>D</italic><sub><italic>R</italic></sub> and <italic>I</italic><sub><italic>all</italic></sub>, are schematized in <xref ref-type="fig" rid="fig9"><italic>Figure</italic> 9B</xref>, with conditional posteriors for each parameter plotted in <xref ref-type="fig" rid="fig9"><italic>Figure</italic> 9C</xref>. Consistent with best-fitting single and dual parameter models (e.g., without striatal regressors included), the weighted effect of <italic>D</italic><sub><italic>L</italic></sub> &#x2212; <italic>D</italic><sub><italic>R</italic></sub> on <italic>v</italic> in model III led to a significant increase in <italic>v</italic> across <inline-formula><alternatives><inline-graphic xlink:href="418756_inline5.gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xlink:href="418756_inline6.gif"/></alternatives></inline-formula> conditions. Thus, increasing the disparity of dMSN activation between <italic>L</italic> and <italic>R</italic> action channels led to faster and more frequent leftward actions by increasing the rate of evidence accumulation towards the correct decision boundary. Also consistent with parameter estimates from the best-fitting dual parameter model (i.e., <italic>v</italic>, a), inclusion of trialwise values of <italic>I</italic><sub><italic>all</italic></sub> led to an increase in the boundary height in the medium <inline-formula><alternatives><inline-graphic xlink:href="418756_inline7.gif"/></alternatives></inline-formula> and high <inline-formula><alternatives><inline-graphic xlink:href="418756_inline8.gif"/></alternatives></inline-formula> conditions compared to estimates in the low condition <inline-formula><alternatives><inline-graphic xlink:href="418756_inline9.gif"/></alternatives></inline-formula>. However, in contrast with boundary height estimates derived from behavioral data alone (not shown), <italic>a</italic> estimates in model III showed no significant difference between medium and high levels of reward probability.</p>
<p>Next, we evaluated the extent to which the best-fitting regression model (i.e., model III) was able to account for the qualitative behavioral patterns exhibited by the CBGT network in each condition. To this end, we simulated 20,000 trials in each reward condition (each trial producing a response and RT given a parameter set sampled from the model posteriors) and compared the resulting RT distributions, along with mean speed and accuracy measures, with those produced by the CBGT model (<xref ref-type="fig" rid="fig9"><italic>Figure</italic> 9D,E</xref>). Parameter estimates from the best-fitting model captured both the increasing rightward skew of RT distributions, as well as the concurrent increase in mean decision speed and accuracy with increasing reward probability.</p>
<p>In summary, by leveraging trialwise measures of simulated striatal MSN subpopulation dynamics to supplement RT and choice data generated by the CBGT network, we were able to 1) substantially improve the quality of DDM fits to the network&#x2019;s behavior across levels of reward probability compared to models without access to neural observations and 2) identify dissociable neural signals underlying observed changes in <italic>v</italic> and <italic>a</italic> across varying levels of reward probability associated with available choices.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Reinforcement learning in mammals alters the mapping from sensory evidence to action decisions. Here we set out to understand how this adaptive decision-making process emerges from underlying neural circuits using a modeling approach that bridges across levels of analysis, from plasticity at corticostriatal synapses to CBGT network function to quantifiable behavioral parameters (<italic><xref ref-type="bibr" rid="c69">Simen et al., 2006</xref>; <xref ref-type="bibr" rid="c60">Ratcliff and Frank, 2012</xref>;</italic> <xref ref-type="bibr" rid="c6">Bogacz, 2007</xref>; <xref ref-type="bibr" rid="c8">Bogacz and Larsen, 2011</xref>). We show how a simple, DA-mediated STDP rule can modulate the sensitivity of both dMSN and iMSN populations to cortical inputs. This learning allows for the network to discover which target in a two-alternative forced-choice task is more likely to deliver a reward by modifying the ratio of direct and indirect pathway corticostriatal weights within each action channel. With this result in hand, we simulated the network-level dynamics of CBGT circuits, as well as behavioral responses, under different levels of conflict in reward probabilities, by extrapolating from the learned corticostriatal weights from the STDP simulations. As reward probability for the optimal target increased, the asymmetry of dMSN firing rates between action channels grew, as did the overall activity of iMSNs across both action channels. By fitting the DDM to the simulated decision behavior of the CBGT network, we found that changes in the rate of evidence accumulation tracked with the difference in dMSN population firing rates across action channels, while the the level of evidence required to trigger a decision tracked with the overall iMSN population activity. These findings show how, at least within this specific framework, plasticity at corticostriatal synapses induced by phasic changes in DA can have a multifaceted effect on cognitive decision processes.</p>
<p>A critical assumption of our theoretical experiments is that the CBGT pathways accumulate sensory evidence for competing actions in order to identify the most contextually appropriate response. This assumption is supported by a growing body of empirical and theoretical evidence. For example, <italic><xref ref-type="bibr" rid="c79">Yartsev et al. (2018)</xref></italic> recently showed that, in rodents performing an auditory discrimination task, the anterior dorsolateral striatum satisfied three fundamental criteria for establishing causality in the evidence accumulation process: (1) inactivation of the striatum ablated the animal&#x2019;s discrimination performance on the task, (2) perturbation of striatal neurons during the temporal window of evidence accumulation had predictable and reliable effects on trial-wise behavioral reports, and (3) gradual ramping, proportional to the strength of evidence, was observed in both single unit and population firing rates of the striatum (however, see also <italic><xref ref-type="bibr" rid="c16">Ding and Gold (2010)</xref></italic>). Consistent with these empirical findings, <italic><xref ref-type="bibr" rid="c10">Caballero et al. (2018)</xref></italic> recently proposed a novel computational framework, capturing perceptual evidence accumulation as an emergent effect of recurrent activation of competing action channels. This modeling work builds on previous studies showing how the architecture of CBGT loops is ideal for implementing a variant of the sequential probability ratio test (<italic><xref ref-type="bibr" rid="c7">Bogacz and Gurney, 2007</xref>; <xref ref-type="bibr" rid="c6">Bogacz, 2007</xref></italic>). Taken together, these converging lines of evidence point to CBGT pathways as being causally involved in the accumulation of evidence for decision-making.</p>
<p>The idea that an accumulation of evidence algorithm can be implemented via network-level dynamics within looped circuit architectures stands in sharp contrast to cortical models of decisionmaking that presume a more direct isomorphism between accumulators and neural activity (for review see <italic><xref ref-type="bibr" rid="c32">Gold and Shadlen (2007)</xref></italic>). Early experimental work showed how population-level firing rates in area LIP displayed the same ramp-to-threshold dynamics as predicted by an evidence accumulation process (<italic><xref ref-type="bibr" rid="c67">Shadlen and Newsome, 2001</xref>; <xref ref-type="bibr" rid="c41">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="c11">Churchland et al., 2008</xref></italic>). This simple relation between algorithm and implementation has now come into question. Follow-up electrophysiological experiments showed how this population-level accumulation may, in fact, reflect the aggregation of step-functions across neurons that resemble an accumulator when summed together yet lack accumulation properties at the level of individual units (<italic><xref ref-type="bibr" rid="c46">Latimer et al., 2015</xref></italic>). In addition, recent results from intervention studies are inconsistent with the causal role of cortical areas in the accumulation of evidence. For instance, <italic><xref ref-type="bibr" rid="c39">Katz et al. (2016)</xref></italic> found that inactivation of area LIP in macaques had no effect on the ability of monkeys to discriminate the direction of motion stimuli in a standard random dot motion task. In contrast to the presumed centrality of LIP in sensory evidence accumulation, these findings and supporting reports from <italic><xref ref-type="bibr" rid="c47">Licata et al. (2017)</xref></italic> and <italic><xref ref-type="bibr" rid="c23">Erlich et al. (2015)</xref></italic> suggest that cortical areas like LIP provide a useful proxy for the deliberation process but are unlikely to have a causal role in the decision itself.</p>
<p>The recent experimental <italic>(Yartsevet al., 2018)</italic> and theoretical (<italic><xref ref-type="bibr" rid="c10">Caballero et al., 2018</xref></italic>) revelations of CBGT involvement in decision-making are particularly exciting, not only for the purposes of identifying a likely neural substrate of perceptual choice, but also for their implications for integrating accumulation-to-bound models (e.g., action selection mechanisms) with theories of RL (e.g., feedback-dependent learning of action values). We previously proposed a Believer-Skeptic framework (<italic><xref ref-type="bibr" rid="c22">Dunovan and Verstynen, 2016</xref></italic>) to capture the complementary roles played by the direct and indirect pathways in the feedback-dependent learning and the moment-to-moment evidence accumulation leading up to action selection. This competition between opposing control pathways can be characterized as a debate between a Believer (direct pathway) and a Skeptic (indirect pathway), reflecting the instantaneous probability ratio of evidence in favor of executing and suppressing a given action respectively. Because the default state of the basal ganglia pathways is motor-suppressing (e.g., <italic><xref ref-type="bibr" rid="c2">Alexander and Crutcher (1990)</xref>; <xref ref-type="bibr" rid="c76">Wichmann and DeLong (1996)</xref></italic>), the burden of proof falls on the Believer to present sufficient evidence for selecting a particular action. In accumulation-to-bound models like the DDM, this sequential sampling of evidence is parameterized by the drift rate. Therefore, the Believer-Skeptic model specifically predicts that this competition should be reflected, at least in part, in the rate of evidence accumulation. As for the role of learning in the Believer-Skeptic competition, multiple lines of evidence suggest that dopaminergic feedback during learning systematically biases the direct-indirect competition in a manner consistent with increasing the drift rate for more rewarding actions (<italic><xref ref-type="bibr" rid="c57">Pedersen et al., 2017</xref>;</italic> <xref ref-type="bibr" rid="c51">Manohar et al., 2015</xref>; <xref ref-type="bibr" rid="c13">Collins and Frank, 2014</xref>; <xref ref-type="bibr" rid="c22">Dunovan and Verstynen, 2016</xref>; <xref ref-type="bibr" rid="c29">Frank et al., 2015</xref>; <xref ref-type="bibr" rid="c1">Afacan-Seref et al., 2018</xref>). Indeed, the STDP simulations in the current study showed opposing effects of dopaminergic feedback on corticostriatal synapses in the direct pathway for both the optimal and suboptimal action channels, with the post-learning difference between the direct pathway synaptic weights in the two channels proportional to the difference in expected action values. This provides testable predictions at multiple levels for how feedback learning should influence the decision process over time.</p>
<p>In support of the biological assumptions underlying the CBGT network, several important empirical properties naturally emerged from our simulations. First, both dMSN and iMSN striatal populations were concurrently activated on each trial (see <italic><xref ref-type="bibr" rid="c15">Cui et al. (2015)</xref>; <xref ref-type="bibr" rid="c42">Klaus et al. (2017)</xref>;<xref ref-type="bibr" rid="c17">Donahue et al. (2018)</xref></italic>) and exhibited gradually ramping firing rates that often saturated before the response on each trial (<italic><xref ref-type="bibr" rid="c79">Yartsev et al., 2018</xref>;</italic> <xref ref-type="bibr" rid="c16">Ding and Gold, 2010</xref>). Second, in contrast with the relatively early onset of ramping activity in the striatum, recipient populations in the GPi sustained high tonic firing rates throughout most of the trial, with activity in the selected channel showing a precipitous decline near the recorded RT (<italic><xref ref-type="bibr" rid="c65">Schmidt et al., 2013</xref>;</italic> <xref ref-type="bibr" rid="c48">Lo and Wang, 2006</xref>; <italic><xref ref-type="bibr" rid="c75">Wei et al., 2015</xref></italic>). This delayed change in GPi activation is likely due to the opposing influence of concurrently active dMSN and iMSN populations in each channel, such that the influence of the direct pathway on the GPi is temporarily balanced out by activation of the indirect pathway (see <italic><xref ref-type="bibr" rid="c75">Wei et al. (2015)</xref></italic>). To represent low, medium, and high levels of reward probability conflict, we manipulated the weights of cortical input to dMSNs in each channel (see <xref ref-type="table" rid="tbl4"><italic>Table</italic> 4</xref>), increasing and decreasing the ratio of direct pathway weights to indirect pathway weights for <italic>L</italic> and <italic>R</italic> actions, respectively. As expected, increasing the difference in the associated reward for <italic>L</italic> and <italic>R</italic> actions led to stronger firing in L-dMSNs and weaker firing of R-dMSNs. Consistent with recently reported electrophysiological findings (<italic><xref ref-type="bibr" rid="c17">Donahue et al., 2018</xref>; <xref ref-type="bibr" rid="c42">Klaus et al., 2017</xref></italic>), we also observed an increase in the firing of iMSNs in the <italic>L</italic> action channel, which in our simulations may arise from channel-specific feedback from the <italic>L</italic> component of the thalamus. Behaviorally, the choices of the CBGT network became both faster and more accurate (e.g., higher percentage of <italic>L</italic> responses) at higher levels of reward, suggesting that the observed increase in L-iMSN firing did not serve to delay or suppress <italic>L</italic> selections. These changes in neural dynamics also produced consequent changes in value-based decision behavior consistent with previous studies linking parameters of the DDM with experiential feedback.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><p>Corticostriatal weights in the CBGT network across levels of reward probability. Values of <italic>w</italic> were used to scale the synaptic efficacy of corticostriatal inputs (g<sub>Ctx-</sub>M<sub>SN</sub>) to the direct (D) and indirect (I) pathways within the left (L) and right (R) action channels.</p></caption>
<graphic xlink:href="418756_tbl4.tif"/>
</table-wrap>
<p>One of the critical outcomes of the current set of experiments is the mechanistic prediction of how variation in specific neural parameters relates to changes in parameters of the DDM. Consistent with past work (see <italic><xref ref-type="bibr" rid="c22">Dunovan and Verstynen (2016)</xref>; <xref ref-type="bibr" rid="c29">Frank et al. (2015)</xref></italic>), the DDM fits to the CBGT-simulated behavior showed an increase in drift rate toward the higher valued decision boundary with increasing expected reward. Additionally, we found that greater disparity in the expected values of alternative actions led to an increase in the boundary height. Indeed, the co-modulation of drift rate and boundary parameters observed here has also been found in human and animal experimental studies of value-based choice (<italic><xref ref-type="bibr" rid="c1">Afacan-Seref et al., 2018</xref>; <xref ref-type="bibr" rid="c51">Manohar et al., 2015</xref>; <xref ref-type="bibr" rid="c29">Frank et al., 2015</xref></italic>). For example, experiments with human subjects in a value-based learning task showed that selection and response speed patterns were best described by an increase in the rate of evidence for more valued targets, coupled with an upwards shift in the boundary height for all targets (<italic><xref ref-type="bibr" rid="c51">Manohar et al., 2015</xref></italic>). Moreover, in healthy human subjects, but not Parkinson&#x2019;s disease patients, reward feedback was found to drive increases in both rate and boundary height parameters, effectively breaking the speed-accuracy tradeoff <italic><xref ref-type="bibr" rid="c51">Manohar et al. (2015)</xref></italic>. To identify more precise links between the relevant neural dynamics underlying the observed drift rate and boundary height effects we performed another round of model fits with striatal summary measures included as regressors to describe trial-by-trial variability. Behavioral fits were substantially improved by estimating trialwise values of drift rate as a function of the difference between L- and R-dMSN activation and trialwise values of boundary height as a function of the iMSN activation across both channels. These relationships stand both as novel predictions arising from the current study and as refinements to the Believer-Skeptic framework, implying that the Believer component relies on a competition between action channels while the Skeptic involves a cooperative aspect.</p>
<p>While our present findings provide key insights into the links between implementation mechanisms and cognitive algorithms during adaptive decision-making, they are constrained by the nature of the multi-level modeling approach itself. When considering the potential benefits of multi-level modeling to investigations mapping across levels of analysis, it is important to understand the kinds of questions that this approach is poised to address as well as some of its limitations. For instance, because the CBGT network is substantially more complex (i.e., has more parameters) than the DDM, it is necessarily more flexible in terms of the empirical phenomena that it is capable of fitting.</p>
<p>Thus, given this disparity in the degrees of freedom at the neural and cognitive levels, it becomes exceedingly likely that multiple parameter mappings exist between them. That is, many different properties of the CBGT network, aside from corticostriatial weights and measures of striatal activity, could potentially be manipulated to cause analogous behavioral patterns and inferred effects on the drift rate and boundary height parameters in the DDM. Importantly, our goal in using multi-level modeling was not to arbitrate between alternative, mutually exclusive biological implementations of a given parameter that appears at the cognitive level, but rather to understand how specific neural features related to the Believer-Skeptic framework contribute to cognitive computations by examining which parameters they influence when perturbed. We do not presume that the impacts of dopaminergic plasticity at corticostriatal synapses on striatal activity are singularly responsible for setting the drift rate during value-based decision-making, for example. Rather, our simulations demonstrate that strengthening corticostriatal synapses is one way that the brain can adjust striatal firing to shape the drift rate and accumulation threshold, promoting faster and more frequent selection of actions with a higher expected value.</p>
<p>Our simulations make several novel predictions for future experiments. The STDP simulations described in the <italic>STDP network results</italic> section suggest that feedback-dependent reward learning should drive more salient changes in cortical synaptic weights to dMSN populations than to iMSN populations. At the same time, while the learning-related changes in <italic>L</italic> and <italic>R</italic> direct pathway corticostriatal weights were mirrored by the relative firing rates of L- and R-dMSNs in the CBGT network, iMSN firing rates are also predicted to show channel-specific differences, despite constancy in their corticostriatal weights across conditions. The observed increase in iMSN firing disparity between the <italic>L</italic> and <italic>R</italic> channels in our simulations emerged due to the thalamostriatal feedback assumed in the CBGT network, where dMSN activation leads to disinhibition of the thalamus, thereby increasing excitatory feedback to both MSN subtypes within a given channel. This represents another novel model prediction that can be tested empirically. Since it is currently unclear whether these feedback connections actually adhere to a channel-specific (e.g., focal) topology, we hope that our work will motivate future experiments to explore the topology of thalamostriatal inputs. Finally, our study predicts that the difference in dMSN activity across action channels modulates the rate of value-based evidence accumulation. This could be directly tested by applying different magnitudes of optogenetic stimulation to dMSNs in L- and R-lateralized dorsolateral striatum to effectively manipulate the strength of evidence for <italic>L</italic> and <italic>R</italic> lever presses. According to our simulations, increasing the relative magnitude of dMSN stimulation in the R, compared to L, dorsolateral striatum should speed and facilitate the selection of contralateral lever presses. Choice and RT data could then be ft with the DDM to determine if the behavioral effects of laterally-biased dMSN stimulation were best described by a change in the drift rate. Analogous experiments targeting iMSNs but without channel specificity could be used similarly to evaluate our prediction that overall iMSN activity level modulates DDM boundary height.</p>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>Here we characterize the effects of dopaminergic feedback on the competition between direct and indirect CBGT pathways and how this plasticity impacts the evaluation of evidence for alternative actions during value-based choice. Using simulated neural dynamics to generate behavioral data for fitting by the DDM and determining how measures of striatal activity influence this ft, we show how the rate of evidence accumulation and the decision boundary height are modulated by the direct and indirect pathways, respectively. This multi-level modeling approach affords a unique combination of biological plausibility and mechanistic interpretability, providing a rich set of testable predictions for guiding future experimental work at multiple levels of analysis.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<p>Our work involves three distinct model systems, a <italic>spike-timing dependent plasticity (STDP)</italic> network consisting of striatal neurons and their cortical inputs, with corticostriatal synaptic plasticity driven by phasic reward signals resulting from simulated actions and their consequent dopamine release; a spiking <italic>cortico-basalganglia-thalamic (CBGT)</italic> network, comprising neurons and synaptic connections from the key cortical and subcortical areas within the CBGT computational loops that take sensory evidence from cortex and make a decision to select one of two available responses; and the <italic>drift diffusion model (DDM)</italic>, a cognitive model of decision-making that describes the accumulation-to-bound dynamics underlying the speed and accuracy of simple choice behavior (<italic><xref ref-type="bibr" rid="c59">Ratcliff, 1978</xref></italic>).</p>
<p>In this section, we present the details of each of these models along with some computational approaches that we use in simulating and analyzing them. The three models are simulated separately, but outputs of specific models are critical for the tuning of other models, as we shall describe.</p>
<sec id="s5a">
<title>STDP network</title>
<sec id="s5a1">
<title>Neural model</title>
<p>We consider a computational model of the striatum consisting of two different populations that receive different inputs from the cortex (see <italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic>, left). Although they do not interact directly, they compete with each other to be the first to select a corresponding action.</p>
<p>Each population contains two different types of units: (i) dMSNs, which facilitate action selection, and (ii) iMSNs, which suppress action selection. Each of these neurons is represented with the exponential integrate-and-fire model (<italic><xref ref-type="bibr" rid="c27">Fourcaud-Trocme et al., 2003</xref></italic>), such that each neural membrane potential obeys the differential equation
<disp-formula id="eqn3"><alternatives><graphic xlink:href="418756_eqn3.gif"/></alternatives></disp-formula>
where <italic>g</italic><sub><italic>L</italic></sub> is the leak conductance and <italic>V</italic><sub><italic>L</italic></sub> the leak reversal potential. In terns of a neural <italic>I &#x2212; V</italic> curve, <italic>V</italic><sub><italic>T</italic></sub> denotes the voltage that corresponds to the largest input current to which the neuron does not spike in the absence of synaptic input, while &#x0394;<sub>T</sub> stands for the spike slope factor, related to the sharpness of spike initialization. <italic>I</italic><sub><italic>syn</italic></sub>(<italic>t</italic>) is the synaptic current, given by <italic>I</italic><sub><italic>Syn</italic></sub>(<italic>t</italic>) = <italic>g</italic><sub><italic>syn</italic></sub>(<italic>t</italic>)(<italic>V</italic>(<italic>t</italic>) &#x2212; <italic>V</italic><sub><italic>syn</italic></sub>), where the synaptic conductance <italic>g</italic><sub><italic>syn</italic></sub><italic>(t)</italic> changes via a learning procedure (see <italic>Learning rule</italic> subsection). A reset mechanism is imposed that represents the repolarization of the membrane potential after each spike. Hence, when the neuron reaches a boundary value <italic>V</italic><sub><italic>b</italic></sub>, the membrane potential is reset to <italic>V</italic><sub><italic>r</italic></sub>.</p>
<p>The inputs from the cortex to each MSN neuron within a population are generated using a collection of oscillatory Poisson processes with rate <italic>v</italic> and pairwise correlation <italic>c</italic>. Each of these cortical spike trains, which we refer to as daughters, is generated from a baseline oscillatory Poisson process {<italic>X</italic>(<italic>t<sub>n</sub></italic>)}<sub><italic>n</italic></sub>, the mother train, which has intensity function <italic>&#x03BB;</italic> (1 &#x002B; <italic>A</italic> sin(2<italic>&#x03B8;t</italic>)) such that the spike probability at time point <italic>t</italic><sub><italic>n</italic></sub> is
<disp-formula id="ueqn1"><alternatives><graphic xlink:href="418756_ueqn1.gif"/></alternatives></disp-formula>
where <italic>A</italic> and <italic>&#x03B8;</italic> are the amplitude and the frequency of the underlying oscillation, respectively; <italic>t</italic><sub><italic>n&#x002B;l</italic></sub> &#x2212; <italic>t</italic><sub><italic>n</italic></sub> =: <italic>&#x03B4;t</italic> is the time step; and <italic>&#x03BB;</italic> is the mother train rate. After the mother train is computed, each mother spike is transferred to each daughter with probability p, checked independently for each daughter. To fix the daughters&#x2019; rates and the correlation between the daughter trains, the mother train&#x2019;s rate is given by <italic>&#x03BB;</italic>= <italic>v</italic>/(<italic>p</italic> &#x002A; <italic>&#x03B4;t</italic>) where
<disp-formula id="eqn4"><alternatives><graphic xlink:href="418756_eqn4.gif"/></alternatives></disp-formula>
</p>
<p>In the STDP network (see <italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic>, left) we consider two different mother trains to generate the cortical daughter spike trains for the two different MSN populations. Each dMSN neuron or iMSN neuron receives input from a distinct daughter train, with the corresponding transfer probabilities <italic>p</italic><sup><italic>D</italic></sup> and <italic>p</italic><sup>I</sup>, respectively. As shown in <italic><xref ref-type="bibr" rid="c45">Kreitzer and Malenka (2008)</xref></italic>, the cortex to iMSN release probability exceeds that of cortex to dMSN. Hence, we set <italic>p</italic><sup><italic>D</italic></sup> <italic>&#x003C; p</italic><sup>1</sup>.</p>
</sec>
<sec id="s5a2">
<title>Striatal neuron parameters</title>
<p>We set the exponential integrate-and-fire model parameter values as <italic>C</italic> = 1 <italic>&#x03BC;F</italic>/cm<sup>2</sup>, <italic>g</italic><sub><italic>L</italic></sub> =0.1 <italic>&#x03BC;S</italic>/cm<sup>2</sup>, <italic>V</italic><sub><italic>L</italic></sub> = &#x2212;65<italic>mV, V</italic><sub><italic>T</italic></sub> = &#x2212;59.9 <italic>mV</italic>, and &#x0394;<sub>T</sub> = 3.48 <italic>mV</italic> (see <italic>Fourcaud-Trocme et al.</italic> (2003)). The reset parameter values are <italic>V</italic><sub><italic>b</italic></sub> = &#x2212;40<italic>mV</italic> and <italic>V</italic><sub><italic>r</italic></sub> = &#x2212;75<italic>mV</italic>. The synaptic current derives entirely from excitatory inputs from the cortex, so <italic>V</italic><sub><italic>syn</italic></sub> = 0<italic>mV</italic>. For these specific parameters, synaptic inputs are required for MSN spiking to occur.</p>
</sec>
<sec id="s5a3">
<title>Cortical neuron parameters</title>
<p>To compute p, we set the daughter Poisson process parameter values as <italic>v</italic> = 0.002 and <italic>c</italic> = 0.5 and apply <italic><xref ref-type="disp-formula" rid="eqn4">Equation 4</xref></italic>. Once the mother trains are created using these values, we set the iMSN transfer probability to <italic>p</italic><sup><italic>I</italic></sup> = <italic>p</italic> and the dMSN transfer probability to <italic>p</italic><sup><italic>D</italic></sup> = 2/3<italic>p</italic><sup>1</sup>. In most simulations, we set <italic>A</italic> = 0 to consider non-oscillatory cortical activity. We have also tested the learning rule when <italic>A</italic> = 0.06 and &#x03B8;= 25 <italic>Hz</italic> and obtained similar results.</p>
<p>The network has been integrated computationally by using the Runge-Kutta (4,5) method in Matlab (ode45) with time step <italic>&#x03B4;t</italic> = 0.01 <italic>ms</italic>. Different realizations lasting 15 <italic>s</italic> were computed to simulate variability across different subjects in a learning scenario.</p>
<p>Every time that an action is performed (see <italic>Action and rewards</italic> and <italic>Example implementation</italic> subsections), all populations stop receiving inputs from the cortex until all neurons in the network are in the resting state for at least 50<italic>ms</italic>. During these silent periods, no MSN spikes occur and hence no new actions are performed (i.e., they are action refractory periods). After these 50<italic>ms</italic>, the network starts receiving synaptic inputs again and we consider a new trial to be underway.</p>
</sec>
<sec id="s5a4">
<title>Learning rule</title>
<p>During the learning process, the corticostriatal connections are strengthened or weakened according to previous experiences. In this subsection, we will present equations for a variety of quantities, many of which appear multiple times in the model. Specifically, there are variables <italic>g</italic><sub><italic>syn</italic></sub>, <italic>w</italic> for each corticostriatal synapse, <italic>A</italic><sub><italic>PRE</italic></sub> for each daughter train, <italic>A</italic><sub><italic>POST</italic></sub> and <italic>E</italic> for each MSN. For all of these, to avoid clutter, we omit subscripts that would indicate explicitly that there are many instances of these variables in the model.</p>
<p>We suppose that the conductance for each corticostriatal synapse onto each MSN neuron, <italic>g</italic> (<italic>t</italic>), obeys the differential equation
<disp-formula id="eqn5"><alternatives><graphic xlink:href="418756_eqn5.gif"/></alternatives></disp-formula>
where <italic>t</italic><sub><italic>}</italic></sub> denotes the time of the jth spike in the cortical daughter spike train pre-synaptic to the neuron, <italic>S(t)</italic> is the Dirac delta function, <italic>&#x03C4;</italic><sub><italic>g</italic></sub> stands for the decay time constant of the conductance, and w(t) is a weight associated with that train at time t. The weight is updated by dopamine release and by the neuron&#x2019;s role in action selection based on a similar formulation to one proposed previously (<italic><xref ref-type="bibr" rid="c3">Baladron et al., 2017</xref></italic>), which descends from earlier work (<italic><xref ref-type="bibr" rid="c37">Izhikevich, 2007</xref></italic>). The idea of this plasticity scheme is that an eligibility trace <italic>E</italic> (cf. <italic><xref ref-type="bibr" rid="c68">Shindou et al. (2018)</xref></italic>) represents a neuron&#x2019;s recent spiking history and hence its eligibility to have its synapses modified, with changes in eligibility following a spike timing-dependent plasticity (STDP) rule that depends on both the pre- and the post-synaptic firing times. Plasticity of corticostriatal synaptic weights depends on this eligibility together with dopamine levels, which in turn depend on the reward consequences that follow neuronal spiking.</p>
<p>To describe the evolution of neuronal eligibility, we first define <italic>A</italic><sub><italic>PRE</italic></sub> and <italic>A</italic><sub><italic>POST</italic></sub> to represent a record of pre- and post-synaptic spiking, respectively. Every time that a spike from the corresponding cell occurs, the associated variable increases by a fixed amount, and otherwise, it decays exponentially. That is,
<disp-formula id="eqn6"><alternatives><graphic xlink:href="418756_eqn6.gif"/></alternatives></disp-formula>
where <italic>X</italic><sub><italic>PRE</italic></sub>(<italic>t</italic>) and <italic>X</italic><sub><italic>POST</italic></sub>(<italic>t</italic>) are functions set to 1 at times t when, respectively, a neuron that is pre-synaptic to the post-synaptic neuron, or the post-synaptic neuron itself, fires a spike, and are zero otherwise, while <italic>&#x0394;</italic><sub><italic>PRE</italic></sub> and <italic>&#x0394;</italic><sub><italic>POST</italic></sub> are the fixed increments to <italic>A</italic><sub><italic>PRE</italic></sub> and <italic>A</italic><sub><italic>POST</italic></sub> due to this firing. The additional parameters <italic>&#x03C4;</italic><sub><italic>PRE</italic></sub>, <italic>&#x03C4;</italic><sub><italic>POST</italic></sub> denote the decay time constants for <italic>A</italic><sub><italic>PRE</italic></sub>, <italic>A</italic><sub><italic>POST</italic></sub>, respectively.</p>
<p>The spike time indicators <italic>X</italic><sub><italic>PRE</italic></sub>, <italic>X</italic><sub><italic>POST</italic></sub> and the variables <italic>A</italic><sub><italic>PRE</italic></sub>, <italic>A</italic><sub><italic>POST</italic></sub> are used to implement an STDP-based evolution equation for the eligibility trace, which takes the form
<disp-formula id="eqn7"><alternatives><graphic xlink:href="418756_eqn7.gif"/></alternatives></disp-formula>
implying that if a pre-synaptic neuron spikes and then its post-synaptic target follows, such that <italic>A</italic><sub><italic>PRE</italic></sub> <italic>&#x003E;</italic> 0 and <italic>X</italic><sub><italic>POST</italic></sub> becomes 1, the eligibility <italic>E</italic> increases, while if a post-synaptic spike occurs followed by a pre-synaptic spike, such that <italic>A</italic><sub><italic>POST</italic></sub> <italic>&#x003E;</italic> 0 and <italic>X</italic><sub><italic>PRE</italic></sub> becomes 1, then <italic>E</italic> decreases; at times without spikes, the eligibility decays exponentially with rate <italic>&#x03C4;</italic><sub><italic>E</italic></sub>.</p>
<p>In contrast to previous work (<italic><xref ref-type="bibr" rid="c3">Baladron et al., 2017</xref></italic>), we propose an update scheme for the synaptic weight <italic>w(t)</italic> that depends on the type of MSN neuron involved in the synapse. It has been observed (<italic><xref ref-type="bibr" rid="c20">Dreyer et al., 2010</xref>; <xref ref-type="bibr" rid="c63">Richfield et al., 1989</xref>;</italic> <xref ref-type="bibr" rid="c33">Gonon, 1997</xref>; <xref ref-type="bibr" rid="c40">Keeler et al., 2014</xref>) that dMSNs tend to have less activity than iMSNs at resting states, consistent with our assumption that <italic>p</italic><sup><italic>D</italic></sup> &#x003C; <italic>p</italic><sup>I</sup>, and are more responsive to phasic changes in dopamine than iMSNs. In contrast, iMSNs are largely saturated by tonic dopamine. In both cases, we assume that the eligibility trace modulates the extent to which a synapse can be modified by the dopamine level relative to a tonic baseline (which we without loss of generality take to be 0), consistent with previous models. Hence, we take <italic>w(t)</italic> to change according to the equation
<disp-formula id="eqn8"><alternatives><graphic xlink:href="418756_eqn8.gif"/></alternatives></disp-formula>
where the function
<disp-formula id="ueqn2"><alternatives><graphic xlink:href="418756_ueqn2.gif"/></alternatives></disp-formula>
represents sensitivity to phasic dopamine, <italic>&#x03B1;</italic> <sub><italic>w</italic></sub> refers to the learning rate, <italic>K</italic><sub><italic>DA</italic></sub> denotes the level of dopamine available at the synapses, <inline-formula><alternatives><inline-graphic xlink:href="418756_inline10.gif"/></alternatives></inline-formula> is an upper bound for the weight <italic>w</italic> that depends on whether the postsynaptic neuron is a dMSN (X = D) or an iMSN (X = <italic>I</italic>), <italic>c</italic> controls the saturation of weights to iMSNs, and &#x007C; &#x2022; &#x007C; denotes the absolute value function. The dopamine level <italic>K</italic><sub><italic>DA</italic></sub> itself
<disp-formula id="eqn9"><alternatives><graphic xlink:href="418756_eqn9.gif"/></alternatives></disp-formula>
where the sum is taken over the times {t<sub>i</sub>} when actions are performed, leading to a change in <italic>K</italic><sub><italic>DA</italic></sub> that we treat as instantaneous, and &#x03C4;<sub><italic>DOP</italic></sub> is the dopamine decay constant. The DA update value <italic>DA</italic><sub><italic>inc</italic></sub> (<italic>t</italic><sub><italic>i</italic></sub>) depends on the performed action as follows:
<disp-formula id="eqn10"><alternatives><graphic xlink:href="418756_eqn10.gif"/></alternatives></disp-formula>
where <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the reward associated to action <italic>i</italic> at time <italic>t</italic>, <italic>Q</italic>,(<italic>t</italic>) is an estimate of the value of action <italic>i</italic> at time <italic>t</italic> such that <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>)-<italic>Q</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the subtractive reward prediction error (<italic><xref ref-type="bibr" rid="c25">Eshel et al., 2015</xref></italic>), and <italic>a</italic> e [0,1] is the value learning rate. This rule for action value updates and dopamine release resembles past work (<italic><xref ref-type="bibr" rid="c53">Mikhael and Bogacz, 2016</xref></italic>) but uses a neurally tractable maximization operation (see <italic><xref ref-type="bibr" rid="c64">Roesch et al. (2007)</xref></italic>; <xref ref-type="bibr" rid="c43">Kozlov and Gentner (2013)</xref> and references therein) to take into account that reward expectations may be measured relative to optimal past rewards obtained in similar scenarios (<italic><xref ref-type="bibr" rid="c12">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="c54">Morris et al., 2006</xref></italic>). The evolution of these variables is illustrated in <italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic>, which is discussed in more detail in the <italic>Example implementation</italic> subsection.</p>
</sec>
</sec>
<sec id="s5b">
<title>Actions and rewards</title>
<sec id="s5b1">
<title>Actions</title>
<p>Each dMSN facilitates performance of a specific action. We specify that an action occurs, and so a decision is made by the model, when at least three different dMSNs of the same population spike in a small time window of duration &#x0394;<sub><italic>DA</italic></sub>. When this condition occurs, a reward is delivered and the dopamine level is updated correspondingly, impacting all neurons in the network, depending on eligibility. Then, the spike counting and the initial window time are reset, and cortical spikes to all neurons are turned off over the next 50 <italic>ms</italic> before resuming again as usual.</p>
<p>We assume that iMSN activity within a population counters the performance of the action associated with that population. We implement this effect by specifying that when an iMSN in a population fires, the most recent spike fired by a dMSN in that population is suppressed. Note that this rule need not contradict observed activation of both dMSNs and iMSNs preceding a decision (<italic><xref ref-type="bibr" rid="c14">Cui et al., 2013</xref></italic>), see <italic>Results</italic> section. We also implemented a version of the network in which each iMSN spike cancels the previous spike from both MSN populations. Preliminary simulations of this variant gave similar results to our primary version but with slower convergence (data not shown).</p>
<p>For convenience, we refer to the action implemented by one population of neurons as &#x2033;left&#x2033; or <italic>L</italic> and the action selected by the other population as &#x2033;right&#x2033; or R.</p>
</sec>
<sec id="s5b2">
<title>Rewards</title>
<p>In our simulations, to test the learning rule, we present results from different reward scenarios. In one case, we use constant rewards, with <italic>r</italic><sub><italic>L</italic></sub> = 0.7 and <italic>r</italic><sub><italic>R</italic></sub> = 0.1. In another case, we implement probabilistic rewards: every time that an action occurs, the reward <italic>r</italic><sub><italic>i</italic></sub> is set to be 1 with probability <italic>p</italic><sub><italic>i</italic></sub> or <italic>0</italic> otherwise, <italic>i</italic> &#x2208; {<italic>L,R</italic>}. For this case, we consider three different probabilities such that <italic>p</italic><sub><italic>L</italic></sub> <italic>&#x002B; p</italic><sub><italic>R</italic></sub> = 1 and <italic>p</italic><sub><italic>L</italic></sub> &#x003E; <italic>p<sub>R</sub></italic>, keeping the action <italic>L</italic> as the preferred one. Specifically, we take <italic>P<sub>L</sub></italic> = 0.85, <italic>p<sub>L</sub></italic> = <italic>0.75</italic>, and <italic>p</italic><sub><italic>L</italic></sub> = 0.65 to allow comparison with previous results (<italic><xref ref-type="bibr" rid="c29">Frank et al., 2015</xref></italic>). In tuning the model, we also considered a regime with reward switches: reward values were as in the constant reward case but after a certain number of actions occurred, the reward-action associations were exchanged. Although the model gave sensible results, we did not explore this case thoroughly, and we simply show one example in <xref ref-type="app" rid="app1"><italic>Appendix 1</italic></xref>.</p>
</sec>
<sec id="s5b3">
<title>Example implementation</title>
<p>The algorithm for the learning rule simulations is as follows:</p>
<p>First, compute cortical mother spike trains and extract daughter trains to be used as inputs to each MSN from the mother trains.</p>
<p>Next, while <italic>t &#x003C; t</italic><sub>end</sub>,</p>
<list list-type="order">
<list-item><p>use RK45, with step size <italic>dt =</italic> 0.01 ms, to compute the voltages of the MSNs in the network at the current time <italic>t</italic> from <italic><xref ref-type="disp-formula" rid="eqn3">Equation 3</xref></italic> and <italic><xref ref-type="disp-formula" rid="eqn5">Equation 5</xref></italic>,</p></list-item>
<list-item><p>for each MSN, set the corresponding <italic>X</italic><sub><italic>POST</italic></sub><italic>(t)</italic> equal to 1 if a spike is performed or 0 otherwise and set the corresponding <italic>X</italic><sub><italic>PRE</italic></sub><italic>(t)</italic> to 1 if an input spike arrives or 0 otherwise,</p></list-item>
<list-item><p>update the <italic>action</italic> condition by checking sequentially for the following two events:
<list list-type="bullet">
<list-item><p>if any iMSN neuron in population <italic>i</italic> &#x2208; {<italic>L,R</italic>} spikes, then the most recent spike performed by any of the dMSNs of population <italic>i</italic> is cancelled;</p></list-item>
<list-item><p>for each <italic>i</italic> &#x2208; {<italic>L,R</italic>}, countthe number of spikes of the dMSNs in the ith population inside a time window consisting of the last <italic>A</italic><sub><italic>DA</italic></sub><italic>ms;</italic> if at least <italic>n</italic><sub><italic>act</italic></sub> spikes have occurred in this window, then action <italic>i</italic> has occurred and we update <italic>DA</italic><sub><italic>inc</italic></sub> and <italic>Q</italic>, according to <italic><xref ref-type="disp-formula" rid="eqn10">Equation 10</xref></italic>,</p></list-item>
</list></p>
</list-item>
<list-item><p>use RK45, with step size <italic>dt =</italic> 0.01 <italic>ms</italic>, to solve <italic><xref ref-type="disp-formula" rid="eqn6">Equation 6</xref>-<xref ref-type="disp-formula" rid="eqn8">Equation 8</xref></italic> for each synapse, along with <italic><xref ref-type="disp-formula" rid="eqn9">Equation 9</xref></italic>, yielding an update of DA and synaptic weight levels, for neurons that have <italic>X</italic><sub><italic>PRE</italic></sub>(<italic>t</italic>) = 1, update synaptic conductance using <italic>g</italic>(<italic>t</italic>) = <italic>g</italic>(<italic>t</italic>) &#x002B; <italic>w</italic>(<italic>t</italic>),</p></list-item>
<list-item><p>set <italic>t</italic> = <italic>t</italic> &#x002B; <italic>dt</italic>.</p></list-item>
</list>
<p><italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic> illustrates the evolution of all of the learning rule variables over a brief time window. Cortical spikes (thin straight light lines, top panel) can drive voltage spikes of dMSNs (dark curves, top panel), which in turn may or may not contribute to action selection (green - for <italic>L</italic> - and orange - for <italic>R</italic> - dots, top panel). Each time a dMSN fires, its eligibility trace will deviate from baseline according to the STDP rule in <xref ref-type="disp-formula" rid="eqn7"><italic>Equation</italic> 7</xref>. In this example, the rewards are <italic>r</italic><sub><italic>L</italic></sub> = 0.7 and <italic>r</italic><sub><italic>R</italic></sub> <italic>=</italic> 0.1, such that every performance of <italic>L</italic> leads to an appreciable surge in <italic>K</italic><sub><italic>DA</italic></sub>, with an associated rise in <italic>Q</italic><sub>l</sub>, but performances of <italic>R</italic> do not cause such large increases in <italic>K</italic><sub><italic>DA</italic></sub> and <italic>Q</italic><sub><italic>R</italic></sub>.</p>
<p>Various time points are labeled in the top panel of <italic><xref rid="fig10" ref-type="fig">Figure 10</xref></italic>. At time A, <italic>R</italic> is selected. The illustrated R-dMSN fires just before this time and hence its eligibility increases. There is a small increase in <italic>K</italic><sub><italic>DA</italic></sub> leading to a small increase in the <italic>w</italic> for this dMSN. At time B, <italic>L</italic> is selected. Although it is difficult to detect at this resolution, the illustrated L-dMSN fires just after the action, such that its <italic>E</italic> becomes negative and the resulting large surge in <italic>K</italic><sub><italic>DA</italic></sub> causes a sizeable drop in <italic>w</italic><sub><italic>L</italic></sub>. At time C, <italic>R</italic> is selected again. This time, the R-dMSN fired well before time C, so its eligibility is small, and this combines with the small <italic>K</italic><sub><italic>DA</italic></sub> increase to lead to a negligible increase in <italic>w</italic><sub><italic>R</italic></sub>. At time D, action <italic>L</italic> is selected but the firing of the L-dMSN is sufficiently late after this that no change in <italic>w</italic><sub><italic>L</italic></sub> results. At time E, <italic>L</italic> is selected again. This time, the L-dMSN fires just before the action leading to a large eligilibity and corresponding increase in <italic>w</italic><sub><italic>L</italic></sub>. Finally, at time F, <italic>L</italic> is selected. In this instance, the R-dMSN fired just before selection and hence is eligible, causing <italic>w</italic><sub><italic>R</italic></sub> to increase when <italic>K</italic><sub><italic>DA</italic></sub> goes up. Although this weight change does not reflect correct learning, it is completely reasonable, since the physiological synaptic machinery has no way to know that firing of the R-dMSN did not contribute to the selected action <italic>L</italic>.</p>
</sec>
<sec id="s5b4">
<title>Learning rule parameters</title>
<p>The learning rule parameters have been chosen to capture various experimental observations, including some differences between dMSN and iMSNs. First, it has been shown that cortical inputs to dMSNs yield more prolonged responses with more action potentials than what results from cortical inputs to iMSNs (<italic><xref ref-type="bibr" rid="c26">Flores-Barrera et al., 2010</xref></italic>). Moreover, dMSNs spike more than iMSNs when both types receive similar cortical inputs (<italic><xref ref-type="bibr" rid="c24">Escande et al., 2016</xref></italic>). Hence, the effective weights of cortical inputs to dMSNs should be able to become stronger than those to iMSNs, which we encode by selecting <inline-formula><alternatives><inline-graphic xlink:href="418756_inline11.gif"/></alternatives></inline-formula>. This choice is also consistent with the observation that dMSNs are more sensitive to phasic dopamine than are iMSNs (<italic><xref ref-type="bibr" rid="c20">Dreyer et al., 2010</xref>; <xref ref-type="bibr" rid="c63">Richfield et al., 1989</xref>;</italic> <xref ref-type="bibr" rid="c33">Gonon, 1997</xref>; <xref ref-type="bibr" rid="c40">Keeler et al., 2014</xref>). On the other hand, the baseline firing rates of iMSNs exceed the baseline of dMSNs (<italic><xref ref-type="bibr" rid="c49">Mallet et al., 2006</xref></italic>), and hence we take the initial condition for w(t) for the iMSNs greater than that for the dMSNs.</p>
<p>The relative values of other parameters are largely based on past computational work (<italic><xref ref-type="bibr" rid="c3">Baladron et al., 2017</xref></italic>), albeit with different magnitudes to allow shorter simulation times. The learning rate <italic>a</italic><sub><italic>w</italic></sub> for the dMSNs is chosen to be positive and larger than the absolute value of the negative rate value for the iMSNs. The parameters &#x0394; <sub>PRE</sub>, <italic>&#x0394;</italic> <sub><italic>POST</italic></sub>, <italic>&#x03C4;</italic> <sub><italic>E</italic></sub>, <italic>&#x03C4;</italic> <sub><italic>PRE</italic></sub>, and <italic>T</italic><sub><italic>POST</italic></sub> have been assigned the same values for both types of neurons, keeping the relations &#x0394;<sub><italic>PRE</italic></sub> <italic>&#x003E; &#x0394;</italic> <sub><italic>POST</italic></sub> and <italic>&#x03C4;</italic> <sub><italic>PRE</italic></sub> <italic>&#x003E; &#x03C4;</italic> <sub><italic>POST</italic></sub>. Finally, the rest of the parameters have been adjusted to give reasonable learning outcomes.</p>
</sec>
<sec id="s5b5">
<title>Parameter values</title>
<p>We use the following parameter values in all of our simulations: <italic>&#x03C4;</italic> <sub><italic>DOP</italic></sub> = 2ms, <italic>A</italic><sub><italic>DA</italic></sub> = 6 ms, <italic>&#x03C4;</italic> <sub><italic>g</italic></sub> = 3 ms, <italic>&#x03B1;</italic> = 0.05 and <italic>c</italic> = 2.5. For both dMSNs and iMSNs, we set <italic>A</italic><sub><italic>PRE</italic></sub> = 10 (instead of <italic>A</italic><sub><italic>PRE</italic></sub> = 0.1; <italic><xref ref-type="bibr" rid="c3">Baladron etal. (2017)</xref>), A</italic><sub><italic>POST</italic></sub> = 6 (instead of <italic>A</italic><sub><italic>POST</italic></sub> = 0.006; <italic>Baladron etal. (2017)), &#x03C4;</italic> <sub><italic>E</italic></sub> = 3 (instead of <italic>&#x03C4;</italic> <sub><italic>E</italic></sub> = 150; <italic>Baladron etal. (2017)), &#x03C4;</italic> <sub><italic>PRE</italic></sub> = 9 (instead of <italic>&#x03C4;</italic> <sub><italic>PRE</italic></sub> = 3; <italic>Baladron etal. (2017))</italic>, and <italic>&#x03C4;</italic> <sub><italic>POST</italic></sub> = 1.2(instead of <italic>&#x03C4;</italic> <sub><italic>POST</italic></sub> = 3; <italic>Baladron etal. (2017))</italic>. Finally, <italic>&#x03B1;</italic> <sub><italic>w</italic></sub> = {80, &#x2212;55} (instead of <italic>&#x03B1;</italic> <sub><italic>w</italic></sub> = {12, &#x2212;11}; <italic><xref ref-type="bibr" rid="c3">Baladron et al. (2017)</xref></italic>) and <italic>w</italic><sub><italic>max</italic></sub> = {0.1, 0.03} (instead of <italic>w</italic><sub><italic>max</italic></sub> = {0.00045, 0}; <italic><xref ref-type="bibr" rid="c3">Baladron et al. (2017)</xref></italic>), where the first value refers to dMSNs and the second to iMSNs. Note that different reward values, <italic>r<sub>i</sub></italic>, were used in different types of simulations, as explained in the associated text.</p>
</sec>
<sec id="s5b6">
<title>Learning rule initial conditions</title>
<p>The initial conditions used to numerically integrate the system are <italic>w</italic> = 0.015 for weights of synapses to dMSNs and <italic>w</italic> = 0.018 for iMSNs, with the rest of the variables relating to value estimation and dopamine modulation initialized to 0.</p>
</sec>
</sec>
<sec id="s5c">
<title>CBGT network</title>
<p>The spiking CBGT network is adapted from previous work (<italic><xref ref-type="bibr" rid="c75">Wei et al., 2015</xref></italic>). Like the STDP model described above, the CBGT network simulation is designed to decide between two actions, a left or right choice, based on incoming sensory signals (<xref ref-type="fig" rid="fig1"><italic>Figure</italic> 1</xref>). The full CBGT network was comprised of six interconnected brain regions (see <xref rid="tbl3" ref-type="table"><italic>Table</italic> 3</xref>), including populations of neurons in the cortex, striatum (STR), external segment of the globus pallidus (GPe), internal segment of the globus pallidus (GPi), subthalamic nucleus (STN), and thalamus. Because the goal of the full spiking network simulations was to probe the consequential effects of corticostriatal plasticity on the functional dynamics and emergent choice behavior of CBGT networks after learning has already occurred, CBGT simulations were conducted in the absence of any trial-to-trial plasticity, and did not include dopaminergic projections from the subtantia nigra pars compacta. Rather, corticostriatal weights were manipulated to capture the outcomes of STDP learning as simulated with the learning network <italic>(STDP network</italic> section) under three different probabilistic feedback schedules (see <xref rid="tbl4" ref-type="table"><italic>Table</italic> 4</xref>), each maintained across all trials for that condition (N=2500 trials each).</p>
<sec id="s5c1">
<title>Neural dynamics</title>
<p>To build on previous work on a two-alternative decision-making task with a similar CBGT network and to endow neurons in some BG populations with bursting capabilities, all neural units in the CBGT network were simulated using the integrate-and-fire-or-burst model (<italic><xref ref-type="bibr" rid="c70">Smith et al., 2000</xref></italic>). Each neuron&#x2019;s membrane dynamics were determined by:
<disp-formula id="eqn11"><alternatives><graphic xlink:href="418756_eqn11.gif"/></alternatives></disp-formula>
</p>
<p>In <italic><xref ref-type="disp-formula" rid="eqn11">Equation 11</xref></italic>, parameter values are <italic>C</italic> = 0.5 <italic>nF, g</italic><sub><italic>L</italic></sub> = 25 nS, <italic>V</italic><sub><italic>L</italic></sub> = &#x2212;70<italic>mV, V</italic><sub><italic>h</italic></sub> = &#x2212;0.60<italic>mV</italic>, and <italic>V</italic><sub><italic>T</italic></sub> = 120<italic>mV</italic>. When the membrane potential reaches a boundary <italic>V</italic><sub><italic>b</italic></sub>, it is reset to V<sub>r</sub>. We take V = &#x2212;50<italic>mV</italic> and <italic>V</italic><sub><italic>r</italic></sub> = &#x2212;55 <italic>mV</italic>.</p>
<p>The middle term in the right hand side of <italic><xref ref-type="disp-formula" rid="eqn11">Equation 11</xref></italic> represents a depolarizing, low-threshold T-type calcium current that becomes available when <italic>h</italic> grows and when <italic>V</italic> is depolarized above a level <italic>V</italic><sub><italic>h</italic></sub>, since <italic>H</italic>(V) is the Heaviside step function. For neurons in the cortex, striatum (both MSNs and FSIs), GPi, and thalamus, we set <italic>g</italic><sub><italic>T</italic></sub> = 0, thus reducing the dynamics to the simple leaky integrate-and-fire model. For bursting units in the GPe and STN, rebound burst firing is possible, with <italic>g</italic><sub><italic>T</italic></sub> set to 0.06 <italic>nS</italic> for both nuclei. The inactivation variable, <italic>h</italic>, adapts over time, decaying when <italic>V</italic> is depolarized and rising when <italic>V</italic> is hyperpolarized according to the following equations:
<disp-formula id="eqn12"><alternatives><graphic xlink:href="418756_eqn12.gif"/></alternatives></disp-formula>
and
<disp-formula id="eqn13"><alternatives><graphic xlink:href="418756_eqn13.gif"/></alternatives></disp-formula>
with <inline-formula><alternatives><inline-graphic xlink:href="418756_inline12.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="418756_inline13.gif"/></alternatives></inline-formula> for both GPe and STN.</p>
<p>For all units in the model, the synaptic current <italic>I</italic><sub><italic>syn</italic></sub>, reflects both the synaptic inputs from other explicitly modeled populations of neurons within the CBGT network, as well as additional background inputs from sources that are not explicitly included in the model. This current is computed using the equation
<disp-formula id="eqn14"><alternatives><graphic xlink:href="418756_eqn14.gif"/></alternatives></disp-formula>
</p>
<p>The reversal potentials are set to <italic>V</italic><sub><italic>E</italic></sub> = 0<italic>mV</italic> and <italic>V<sub>I</sub></italic> = &#x2212;70<italic>mV</italic>. The synaptic current components correspond to AMPA(<italic>g</italic><sub>1</sub>), NMDA(<italic>g</italic><sub>2</sub>), and GABAa (<italic>g</italic><sub>3</sub>) synapses. The gating variables <italic>s</italic><sub><italic>i</italic></sub> for AMPA and GABAa receptor-mediated currents satisfy:
<disp-formula id="eqn15"><alternatives><graphic xlink:href="418756_eqn15.gif"/></alternatives></disp-formula>
while NMDA receptor-mediated current gating obeys:
<disp-formula id="eqn16"><alternatives><graphic xlink:href="418756_eqn16.gif"/></alternatives></disp-formula>
</p>
<p>In <italic><xref ref-type="disp-formula" rid="eqn15">Equation 15</xref></italic> and <italic><xref ref-type="disp-formula" rid="eqn16">Equation 16</xref></italic>, <italic>t<sub>j</sub></italic> is the time of the <italic>j<sup>th</sup></italic> spike and <italic>&#x03B2;</italic> = 0.63. The decay constant, <italic>&#x03C4;</italic>, was 2<italic>ms</italic> for AMPA, 5 <italic>ms</italic> for GABA_A, and 100<italic>ms</italic> for NMDA-mediated currents. A time delay of 0.2<italic>ms</italic> was used for synaptic transmission.</p>
</sec>
<sec id="s5c2">
<title>Network architecture</title>
<p>The CBGT network includes six of the nodes shown in <italic><xref rid="fig1" ref-type="fig">Figure 1</xref></italic>, excluding the dopaminergic projections from the substantia nigra pars compacta that are simulated in the STDP model. The membrane dynamics, projection probabilities, and synaptic weights of the network (see <italic><xref rid="tbl3" ref-type="table">Table 3</xref></italic>) were adjusted to reflect empirical knowledge about local and distal connectivity associated with different populations, as well as resting and task-related firing patterns (<italic><xref ref-type="bibr" rid="c75">Wei et al., 2015</xref>;</italic> <xref ref-type="bibr" rid="c48">Lo and Wang, 2006</xref>).</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><p>Synaptic efficacy (g) and probability (P) of connections between populations in the CBGT network, as well as postsynaptic receptor types (AMPA, NMDA, and GABA). The topology of each connection is labeled as either diffuse, to denote connections with a <italic>P &#x003E;</italic> 0 of projecting to left and right action channels, or focal, to denote connections that were restricted to within each channel.</p></caption>
<graphic xlink:href="418756_tbl3.tif"/>
</table-wrap>
<p>The cortex included separate populations of neurons representing sensory information for <italic>L</italic> (N=270) and <italic>R</italic> (N=270) actions that approximate the processing in the intraparietal cortex or frontal eye fields. On each trial, <italic>L</italic> and <italic>R</italic> cortical populations received excitatory inputs from an external source, sampled from a truncated normal distribution with a mean and standard deviation of 2.5 <italic>Hz</italic> and 0.06, respectively, with lower and upper limits of 2.4<italic>Hz</italic> and 2.6<italic>Hz</italic>. Critically, <italic>L</italic> and <italic>R</italic> cortical populations received the same strength of external stimulation on each trial to ensure that any observed behavioral effects across conditions were not the result of biased cortical input. Excitatory cortical neurons also formed lateral connections with other cortical neurons with a diffuse topology, or a non-zero probability of projecting to recipient neurons within and between action channels (see <italic><xref rid="tbl3" ref-type="table">Table 3</xref></italic> for details). The cortex also included a single population of inhibitory interneurons (Ctxl; N=250 total) that formed reciprocal connections with left and right sensory populations. Along with external inputs, cortical populations received diffuse ascending excitatory inputs from the thalamus (Th; N=100 per input channel).</p>
<p><italic>L</italic> and <italic>R</italic> cortical populations projected to dMSN (N=100/channel) and iMSN (N=100/channel) populations in the corresponding action channel; that is, cortical signals for a <italic>L</italic> action projected to dMSN and iMSN cells selective for <italic>L</italic> actions. Both cortical populations also targeted a generic population of FSI (N=100 total) providing widespread but asymmetric inhibition to MSNs, with stronger FSI-dMSN connections than FSI-iMSN connections (<italic><xref ref-type="bibr" rid="c31">Gittis et al., 2010</xref></italic>). Within each channel, dMSN and iMSN populations also formed recurrent and lateral inhibitory connections, with stronger inhibitory connections from iMSNtodMSN populations (<italic><xref ref-type="bibr" rid="c31">Gittis et al., 2010</xref></italic>). Striatal MSN populations also received channel-specific excitatory feedback from corresponding populations in the thalamus. Inhibitory efferent projections from the iMSNs terminated on populations of cells in the GPe, while the inhibitory efferent connections from the dMSNs projected directly to the GPi.</p>
<p>In addition to the descending inputs from the iMSNs, the GPe neurons (N=1000/channel) received excitatory inputs from the STN. GPe cells also formed recurrent, within channel inhibitory connections that supported stability of activity. Inhibitory efferents from the GPe terminated on corresponding populations in the the STN (i.e., long indirect pathway) and GPi (i.e., short indirect pathway). We did not include arkypalldal projections (i.e., feedback projections from GPe to the striatum; <italic><xref ref-type="bibr" rid="c50">Mallet et al. (2012)</xref></italic>) as it is not currently well understood how this pathway contributes to basic choice behavior.</p>
<p>Similar to the GPe, STN populations were composed of bursing neurons (N=1000/channel) with channel-specific inhibitory inputs from the GPe as well as excitatory inputs from cortex (the hyperdirect pathway). The since no cancellation signals were modeled in the experiments (see <italic>Simulations of experimental scenarios</italic> subsection), the hyperdirect pathway was simplified to background input to the STN. Unlike the striatal MSNs and the GPe, the STN did not feature recurrent connections. Excitatory feedback from the STN to the GPe was assumed to be sparse but channel-specific, whereas projections from the STN to the GPi were channel-generic and caused diffuse excitation in both L- and R-encoding populations.</p>
<p>Populations of cells in the GPi (N=100/channel) received inputs from three primary sources: channel-specific inhibitory afferents from dMSNs in the striatum (i.e., direct pathway) and the corresponding population in the GPe (i.e., short indirect pathway), as well as excitatory projections from the STN shared across channels (i.e., long indirect and hyperdirect pathways; see <italic><xref rid="tbl3" ref-type="table">Table 3</xref></italic>). The GPi did not include recurrent feedback connections. All efferents from the GPi consisted of inhibitory projections to the motor thalamus. The efferent projections were segregated strictly into pathways for <italic>L</italic> and <italic>R</italic> actions.</p>
<p>Finally, L- and R-encoding populations in the thalamus were driven by two primary sources of input, integrating channel-specific inhibitory inputs from the GPi and diffuse (i.e., channel-spanning) excitatory inputs from cortex. Outputs from the thalamus delivered channel-specific excitatory feedback to corresponding dMSN and iMSN populations in the striatum as well as diffuse excitatory feedback to cortex.</p>
</sec>
<sec id="s5c3">
<title>Simulations of experimental scenarios</title>
<p>Because the STDP simulations did not reveal strong differences in Ctx-iMSN weights across reward I conditions, only Ctx-dMSN weights were manipulated across conditions in the full CBGT network simulations. In all conditions the Ctx-dMSN weights were higher in the left (higher/optimal reward) than in the right (lower/suboptimal reward) action channel (see <xref rid="tbl4" ref-type="table"><italic>Table</italic> 4</xref>). On each trial, external; input was applied to L- and &#x03BC;-encoding cortical populations, each projecting to corresponding populations ofdMSNsandiMSNsin the striatum, as well as to a generic population of FSIs. Critically, all MSNs also received input from the thalamus, which was reciprocally connected with cortex. Due to the suppressive effects of FSI activity on MSNs, sustained input from both cortex and thalamus was required to raise the firing rates of striatal projection neurons to levels sufficient to produce an action output. Due to the convergence of dMSN and iMSN inputs in the GPi, and their opposing influence over BG output, co-activation of these populations within a single action channel served to delay action output until activity within the direct pathway sufficiently exceeded the opposing effects of the indirect pathway (<xref ref-type="bibr" rid="c75">Wei et al., 2015</xref>). The behavioral choice, as well as the time of that decision (i.e., the RT) were determined by a winner-take-all rule with the first action channel to cause the average firing rate of its thalamic population to rise above a threshold of <italic>30Hz</italic> being selected.</p>
</sec>
</sec>
<sec id="s5d">
<title>Drift Diffusion Model</title>
<p>To understand how altered corticostriatal weights influence decision-making behavior, we fit the simulated behavioral data from the CBGT network with a DDM (<italic><xref ref-type="bibr" rid="c61">Ratcliff et al. (2016)</xref></italic>; <italic><xref ref-type="bibr" rid="c59">Ratcliff (1978)</xref></italic>) and compared alternative models in which different parameters were allowed to vary across reward probability conditions. The DDM is an established model of simple two-alternative choice behavior, providing a parsimonious account of both the speed and accuracy of decision-making in humans and animal subjects across a wide variety of binary choice tasks (<italic><xref ref-type="bibr" rid="c61">Ratcliff et al., 2016</xref></italic>). It assumes that input is stochastically accumulated as the log-likelihood ratio of evidence for two alternative choices until reaching one of two decision thresholds, representing the criterion evidence for committing to a choice. Importantly, this accumulation-to-bound process affords predictions about the average accuracy, as well as the distribution of response times, under a given set of model parameters. The core parameters of the DDM include the rate of evidence accumulation, or drift rate (v), the distance between decision boundaries, also referred to as the threshold (a), the bias in the starting-point between boundaries for evidence accumulation (z), and a non-decision time parameter that determines when accumulation of evidence begins (tr), accounting for sensory and motor delays.</p>
<p>To narrow the subset of possible DDM models considered, DDM fits to the CBGT model behavior were conducted in three stages using a forward stepwise selection process. First, we compared models in which a single parameter in the DDM was free to vary across reward conditions. For these simulations all the DDM parameters were tested. Next, additional model fits were performed with the best-fitting model from the previous stage, but with the addition of a second free parameter. Finally, the two best fitting dual parameter models were submitted to a final round of fits in which trial-wise measures of striatal activity (see <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B-C</xref>) were included as regressors on the two designated parameters of the DDM. All CBGT regressors were normalized between values of 0 and 1. Each regression model included one regression coefficient capturing the linear effect of a given measure of neural activity on one of the free parameters (e.g., <italic>a, v</italic>, or <italic>z</italic>), as well as an intercept term for that parameter, resulting in a total of four free parameters per selected DDM parameter or 8 free parameters altogether. For example, in a model where drift rate is estimated as function of the difference between dMSN firing rates in the left and right action channels, the drift rate on trial <italic>t</italic> is given by <inline-formula><alternatives><inline-graphic xlink:href="418756_inline14.gif"/></alternatives></inline-formula>, where <inline-formula><alternatives><inline-graphic xlink:href="418756_inline15.gif"/></alternatives></inline-formula> is the drift rate intercept, <italic><inline-formula><alternatives><inline-graphic xlink:href="418756_inline16.gif"/></alternatives></inline-formula></italic>. is the beta coefficient for reward condition j, and <italic>Xj</italic>(t) is the observed difference in dMSN firing rates between action channels on trial <italic>t</italic> in condition <italic>j</italic>. A total of 24 separate regression models were fit, testing all possible combinations between the two best-fitting dual parameter models and the four measures of striatal activity summarized in <xref ref-type="fig" rid="fig8"><italic>Figure</italic> 8B-C</xref>.</p>
<p>Fits of the DDM were performed using HDDM (see <italic><xref ref-type="bibr" rid="c78">Wiecki et al. (2013)</xref></italic> for details), an open source Python package for Bayesian estimation of DDM parameters. Each model was fit by drawing 2000 Markov Chain Monte-Carlo (MCMC) samples from the joint posterior probability distribution over all parameters, with acceptance based on the likelihood (see <italic><xref ref-type="bibr" rid="c55">Navarro and Fuss (2009)</xref></italic>) of the observed accuracy and RT data given each parameter set. A burn-in period of 1200 samples was implemented to ensure that model selection was not influenced by samples drawn prior to convergence. Sampling chains were also visually inspected for signs of convergence failure; however, parameters in all models showed normally distributed posterior distributions with little autocorrelation between samples suggesting that sampling parameters were sufficient for convergence. The prior distributions used to initialize all DDM parameters included in the fits can be found in <italic><xref ref-type="bibr" rid="c78">Wiecki et al. (2013)</xref></italic>.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>C. Vich is supported by the Ministerio de Econom&#x00ED;a, Industria y Competitividad (MINECO), the Agencia Estatal de Investigaci&#x00F3;n (AEI), and the European Regional Development Funds (ERDF) through projects MTM2014-54275-P, MTM2015-71509-C2-2-R and MTM2017-83568-P (AE/ERDF,EU). JR received support from NSF awards DMS 1516288,1612913 (CRCNS), and 1724240 (CRCNS). TV received support from NSF CAREER award 1351748. The research was sponsored in part by the U.S. Army Research Laboratory, including work under Cooperative Agreement Number W911NF-10-2-0022, and the views espoused are not official policies of the U.S. Government.</p>
</ack>
<sec id="s8">
<title>Competing Interests</title>
<p>The authors declare no financial or non-financial competing interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Afacan-Seref</surname> <given-names>K</given-names></string-name>, <string-name><surname>Steinemann</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Blangero</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kelly</surname> <given-names>SP</given-names></string-name>. <article-title>Dynamic Interplay of Value and Sensory Information in High-Speed Decision Making</article-title>. <source>Current Biology</source>. <year>2018</year>; <volume>28</volume>(<issue>5</issue>):<fpage>795</fpage>&#x2013;<lpage>802</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Alexander</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Crutcher</surname> <given-names>MD</given-names></string-name>. <article-title>Functional architecture of basal ganglia circuits: neural substrates of parallel processing</article-title>. <source>Trends Neurosci</source>. <year>1990</year> <month>Jul</month>; <volume>13</volume>(<issue>7</issue>):<fpage>266</fpage>&#x2013;<lpage>271</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Baladron</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nambu</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hamker</surname> <given-names>FH</given-names></string-name>. <article-title>The subthalamic nucleus-external globus pallidus loop biases exploratory decisions towards known alternatives: a neuro-computational study</article-title>. <source>European Journal of Neuroscience</source>. <year>2017</year>; p. <fpage>1</fpage>&#x2013;<lpage>14</lpage>. doi: <pub-id pub-id-type="doi">10.1111/ejn.13666</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Balleine</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Delgado</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Hikosaka</surname> <given-names>O.</given-names></string-name> <article-title>The role of the dorsal striatum in reward and decision-making</article-title>. <source>J Neurosci</source>. <year>2007</year> <month>Aug</month>; <volume>27</volume>(<issue>31</issue>):<fpage>8161</fpage> &#x2013;<lpage>8165</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Baum</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Veeravalli</surname> <given-names>VV</given-names></string-name>. <article-title>A sequential procedure for multihypothesis testing</article-title>. <source>IEEE Transactions on Information Theory</source>. <year>1994</year>; <volume>40</volume>(<issue>6</issue>).</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bogacz</surname> <given-names>R.</given-names></string-name> <article-title>Optimal decision-making theories: linking neurobiology with behaviour</article-title>. <source>Trends in cognitive sciences</source>. <year>2007</year>; <volume>11</volume>(<issue>3</issue>):<fpage>118</fpage>&#x2013;<lpage>125</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gurney</surname> <given-names>K.</given-names></string-name> <article-title>The basal ganglia and cortex implement optimal decision making between alternative actions</article-title>. <source>Neural computation</source>. <year>2007</year>; <volume>19</volume>(<issue>2</issue>):<fpage>442</fpage>&#x2013;<lpage>477</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Larsen</surname> <given-names>T.</given-names></string-name> <article-title>Integration of reinforcement learning and optimal decision-making theories of the basal ganglia</article-title>. <source>Neural computation</source>. <year>2011</year>; <volume>23</volume>(<issue>4</issue>):<fpage>817</fpage>&#x2013;<lpage>851</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Burnham</surname> <given-names>KP</given-names></string-name>, <string-name><surname>Anderson</surname> <given-names>DR</given-names></string-name>. <source>Model Selection and Inference: A Practical Information-Theoretic Approach</source>, vol. <volume>80</volume>; <year>1998</year>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Caballero</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Humphries</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Gurney</surname> <given-names>KN</given-names></string-name>. <article-title>A probabilistic, distributed, recursive mechanism for decision-making in the brain</article-title>. <source>PLoS Comput Biol</source>. <year>2018</year> <month>Apr</month>; <volume>14</volume>(<issue>4</issue>):<fpage>e1006033</fpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Decision-making with multiple alternatives</article-title>. <source>Nat Neurosci</source>. <year>2008</year> <month>Jun</month>; <volume>11</volume>(<issue>6</issue>):<fpage>693</fpage>&#x2013;<lpage>702</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname> <given-names>JY</given-names></string-name>, <string-name><surname>Haesler</surname> <given-names>S</given-names></string-name>, <string-name><surname>Vong</surname> <given-names>L</given-names></string-name>, <string-name><surname>Lowell</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N.</given-names></string-name> <article-title>Neuron-type-specific signals for reward and punishment in the ventral tegmental area</article-title>. <source>Nature</source>. <year>2012</year> <month>Jan</month>; <volume>482</volume>(<issue>7383</issue>):<fpage>85</fpage>&#x2013;<lpage>88</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Collins</surname> <given-names>AGE</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <article-title>Opponent actor learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive</article-title>. <source>Psychol Rev</source>. <year>2014</year> <month>Jul</month>; <volume>121</volume>(<issue>3</issue>):<fpage>337</fpage>&#x2013;<lpage>366</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Cui</surname> <given-names>G</given-names></string-name>, <string-name><surname>Jun</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Jin</surname> <given-names>X</given-names></string-name>, <string-name><surname>Pham</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Vogel</surname> <given-names>SS</given-names></string-name>, <string-name><surname>Lovinger</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RM</given-names></string-name>. <article-title>Concurrent activation of striatal direct and indirect pathways during action initiation</article-title>. <source>Nature</source>. <year>2013</year> <month>Feb</month>; <volume>494</volume>(<issue>7436</issue>):<fpage>238</fpage>&#x2013;<lpage>242</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Cui</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Paille</surname> <given-names>V</given-names></string-name>, <string-name><surname>Xu</surname> <given-names>H</given-names></string-name>, <string-name><surname>Genet</surname> <given-names>S</given-names></string-name>, <string-name><surname>Delord</surname> <given-names>B</given-names></string-name>, <string-name><surname>Fino</surname> <given-names>E</given-names></string-name>, <string-name><surname>Berry</surname> <given-names>H</given-names></string-name>, <string-name><surname>Venance</surname> <given-names>L.</given-names></string-name> <article-title>Endocannabinoids mediate bidirectional striatal spike-timing-dependent plasticity</article-title>. <source>Journal of Physiology</source>. <year>2015</year>; <volume>593</volume>(<issue>13</issue>):<fpage>2833</fpage>&#x2013;<lpage>2849</lpage>. doi: <pub-id pub-id-type="doi">10.1113/JP270324</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Ding</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name>. <article-title>Caudate encodes multiple computations for perceptual decisions</article-title>. <source>J Neurosci</source>. <year>2010</year> <month>Nov</month>; <volume>30</volume>(<issue>47</issue>):<fpage>15747</fpage>&#x2013;<lpage>15759</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="website"><string-name><surname>Donahue</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kreitzer</surname> <given-names>A.</given-names></string-name> <article-title>Distinct value encoding in striatal direct and indirect pathways during adaptive learning</article-title>. <source>bioRxiv</source>. <year>2018</year>; <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2018/03/07/277855">https://www.biorxiv.org/content/early/2018/03/07/277855</ext-link>, doi: <pub-id pub-id-type="doi">10.1101/277855</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Doya</surname> <given-names>K.</given-names></string-name> <article-title>Modulators of decision making</article-title>. <source>Nat Neurosci</source>. <year>2008</year> <month>Apr</month>; <volume>11</volume>(<issue>4</issue>):<fpage>410</fpage>&#x2013;<lpage>416</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Draglia</surname> <given-names>V</given-names></string-name>, <string-name><surname>Tartakovsky</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Veeravalli</surname> <given-names>VV</given-names></string-name>. <article-title>Multihypothesis sequential probability ratio tests. I. Asymptotic optimality</article-title>. <source>IEEE Transactions on Information Theory</source>. <year>1999</year>; <volume>45</volume>(<issue>7</issue>):<fpage>2448</fpage>&#x2013;<lpage>2461</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Dreyer</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Herrik</surname> <given-names>KF</given-names></string-name>, <string-name><surname>Berg</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Hounsgaard</surname> <given-names>JD</given-names></string-name>. <article-title>Influence of Phasic and Tonic Dopamine Release on Receptor Activation</article-title>. <source>Journal of Neuroscience</source>. <year>2010</year>; <volume>30</volume>(<issue>42</issue>):<fpage>14273</fpage>&#x2013;<lpage>14283</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUR0SCI.1894-10.2010</pub-id>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Dunovan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Lynch</surname> <given-names>B</given-names></string-name>, <string-name><surname>Molesworth</surname> <given-names>T</given-names></string-name>, <string-name><surname>Verstynen</surname> <given-names>T.</given-names></string-name> <article-title>Competing basal ganglia pathways determine the difference between stopping and deciding not to go</article-title>. <source>eLife</source>. <year>2015</year>; <volume>4</volume>:<fpage>e08723</fpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Dunovan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Verstynen</surname> <given-names>T.</given-names></string-name> <article-title>Believer-Skeptic meets Actor-Critic: Rethinking the role of basal ganglia pathways during decision-making and reinforcement learning</article-title>. <source>Frontiers in neuroscience</source>. <year>2016</year>; <volume>10</volume>:<fpage>106</fpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Erlich</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Brunton</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Duan</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Hanks</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Brody</surname> <given-names>CD</given-names></string-name>. <article-title>Distinct effects of prefrontal and parietal cortex inactivations on an accumulation of evidence task in the rat</article-title>. <source>eLife</source>. <year>2015</year>; <volume>4</volume>:<fpage>e05457</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Escande</surname> <given-names>MV</given-names></string-name>, <string-name><surname>Taravini</surname> <given-names>IRE</given-names></string-name>, <string-name><surname>Zold</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Belforte</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Murer</surname> <given-names>MG</given-names></string-name>. <article-title>Loss of Homeostasis in the Direct Pathway in a Mouse Model of Asymptomatic Parkinson&#x2019;s Disease</article-title>. <source>Journal of Neuroscience</source>. <year>2016</year>; <volume>36</volume>(<issue>21</issue>):<fpage>5686</fpage>&#x2013;<lpage>5698</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUR0SCI.0492-15.2016</pub-id>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Eshel</surname> <given-names>N</given-names></string-name>, <string-name><surname>Bukwich</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rao</surname> <given-names>V</given-names></string-name>, <string-name><surname>Hemmelder</surname> <given-names>V</given-names></string-name>, <string-name><surname>Tian</surname> <given-names>J</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N.</given-names></string-name> <article-title>Arithmetic and local circuitry underlying dopamine prediction errors</article-title>. <source>Nature</source>. <year>2015</year>; <volume>525</volume>(<issue>7568</issue>):<fpage>243</fpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Flores-Barrera</surname> <given-names>E</given-names></string-name>, <string-name><surname>Vizcarra-Chacon</surname> <given-names>B</given-names></string-name>, <string-name><surname>Tapia</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bargas</surname> <given-names>J</given-names></string-name>, <string-name><surname>Galarraga</surname> <given-names>E.</given-names></string-name> <article-title>Different corticostriatal integration in spiny projection neurons from direct and indirect pathways</article-title>. <source>Frontiers in Systems Neuroscience</source>. <year>2010</year>; <volume>4</volume>:<fpage>15</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fnsys.2010.00015</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Fourcaud-Trocme</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hansel</surname> <given-names>D</given-names></string-name>, <string-name><surname>van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N.</given-names></string-name> <article-title>How spike generation mechanisms determine the neuronal response to fluctuating inputs</article-title>. <source>J Neurosci</source>. <year>2003</year> <month>Dec</month>; <volume>23</volume>(<issue>37</issue>):<fpage>11628</fpage>&#x2013;<lpage>11640</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="book"><string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <chapter-title>Linking Across Levels of Computation in Model-Based Cognitive Neuroscience</chapter-title>. In: <source>An Introduction to Model-Based Cognitive Neuroscience</source> <publisher-name>Springer</publisher-name>, <publisher-loc>New York, NY</publisher-loc>; <year>2015</year>. p. <fpage>159</fpage>&#x2013;<lpage>177</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Gagne</surname> <given-names>C</given-names></string-name>, <string-name><surname>Nyhus</surname> <given-names>E</given-names></string-name>, <string-name><surname>Masters</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wiecki</surname> <given-names>TV</given-names></string-name>, <string-name><surname>Cavanagh</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Badre</surname> <given-names>D.</given-names></string-name> <article-title>fMRI and EEG predictors of dynamic decision parameters during human reinforcement learning</article-title>. <source>J Neurosci</source>. <year>2015</year> <month>Jan</month>; <volume>35</volume>(<issue>2</issue>):<fpage>485</fpage>&#x2013;<lpage>494</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Gardner</surname> <given-names>MPH</given-names></string-name>, <string-name><surname>Conroy</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Shaham</surname> <given-names>MH</given-names></string-name>, <string-name><surname>Styer</surname> <given-names>CV</given-names></string-name>, <string-name><surname>Schoenbaum</surname> <given-names>G.</given-names></string-name> <article-title>Lateral Orbitofrontal Inactivation Dissociates Devaluation-Sensitive Behavior and Economic Choice</article-title>. <source>Neuron</source>. <year>2017</year> <month>Dec</month>; <volume>96</volume>(<issue>5</issue>):<fpage>1192</fpage>&#x2013;<lpage>1203.e4</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Gittis</surname> <given-names>AH</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Thwin</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Palop</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Kreitzer</surname> <given-names>AC</given-names></string-name>. <article-title>Distinct roles of GABAergic interneurons in the regulation of striatal output pathways</article-title>. <source>J Neurosci</source>. <year>2010</year>; <volume>30</volume>(<issue>6</issue>):<fpage>2223</fpage>&#x2013;<lpage>2234</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Gold</surname> <given-names>JI</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>The neural basis of decision making</article-title>. <source>Annu Rev Neurosci</source>. <year>2007</year> <month>Jan</month>; <volume>30</volume>(<issue>30</issue>):<fpage>535</fpage>&#x2013;<lpage>561</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Gonon</surname> <given-names>F.</given-names></string-name> <article-title>Prolonged and Extrasynaptic Excitatory Action of Dopamine Mediated by D1 Receptors in the Rat Striatum In Vivo</article-title>. <source>Journal of Neuroscience</source>. <year>1997</year>; <volume>17</volume>(<issue>15</issue>):<fpage>5972</fpage>&#x2013;<lpage>5978</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Gurney</surname> <given-names>KN</given-names></string-name>, <string-name><surname>Humphries</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Redgrave</surname> <given-names>P.</given-names></string-name> <article-title>A New Framework for Cortico-Striatal Plasticity: Behavioural Theory Meets In Vitro Data at the Reinforcement-Action Interface</article-title>. <source>PLoS Biology</source>. <year>2015</year> 01; <volume>13</volume>(<issue>1</issue>):<fpage>1</fpage>&#x2013;<lpage>25</lpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pbio.1002034</pub-id>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Herz</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Little</surname> <given-names>S</given-names></string-name>, <string-name><surname>Pedrosa</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Tinkhauser</surname> <given-names>G</given-names></string-name>, <string-name><surname>Cheeran</surname> <given-names>B</given-names></string-name>, <string-name><surname>Foltynie</surname> <given-names>T</given-names></string-name>, <string-name><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>P.</given-names></string-name> <article-title>Mechanisms Underlying Decision-Making as Revealed by Deep-Brain Stimulation in Patients with Parkinson&#x2019;s Disease</article-title>. <source>Current Biology</source>. <year>2018</year>; <volume>28</volume>(<issue>8</issue>):<fpage>1169</fpage>&#x2013;<lpage>1178</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Herz</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Zavala</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>P.</given-names></string-name> <article-title>Neural correlates of decision thresholds in the human subthalamic nucleus</article-title>. <source>Current Biology</source>. <year>2016</year>; <volume>26</volume>(<issue>7</issue>):<fpage>916</fpage>&#x2013;<lpage>920</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="book"><string-name><surname>Izhikevich</surname> <given-names>EM</given-names></string-name>. <chapter-title>Dynamical systems in neuroscience: the geometry of excitability and bursting</chapter-title>. <source>Computational Neuroscience</source>, <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Jahfari</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ridderinkhof</surname> <given-names>KR</given-names></string-name>, <string-name><surname>Collins</surname> <given-names>AGE</given-names></string-name>, <string-name><surname>Knapen</surname> <given-names>T</given-names></string-name>, <string-name><surname>Waldorp</surname> <given-names>L</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <article-title>Cross-task contributions of fronto-basal ganglia circuitry in response inhibition and conflict-induced slowing</article-title>. <source>bioRxiv</source>. <year>2017</year>; p. <fpage>199299</fpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Katz</surname> <given-names>LN</given-names></string-name>, <string-name><surname>Yates</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Pillow</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Huk</surname> <given-names>AC</given-names></string-name>. <article-title>Dissociated functional significance of decision-related activity in the primate dorsal stream</article-title>. <source>Nature</source>. <year>2016</year> <month>Jul</month>; <volume>535</volume>(<issue>7611</issue>):<fpage>285</fpage>&#x2013;<lpage>288</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Keeler</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pretsell</surname> <given-names>D</given-names></string-name>, <string-name><surname>Robbins</surname> <given-names>T.</given-names></string-name> <article-title>Functional implications of dopamine D1 vs. D2 receptors: a &#x2018;prepare and select&#x2019;model of the striatal direct vs. indirect pathways</article-title>. <source>Neuroscience</source>. <year>2014</year>; <volume>282</volume>:<fpage>156</fpage>&#x2013;<lpage>175</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source>. <year>2009</year>; <volume>324</volume>(<issue>5928</issue>):<fpage>759</fpage>&#x2013;<lpage>764</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Klaus</surname> <given-names>A</given-names></string-name>, <string-name><surname>Martins</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Paixao</surname> <given-names>VB</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>P</given-names></string-name>, <string-name><surname>Paninski</surname> <given-names>L</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RM</given-names></string-name>. <article-title>The Spatiotemporal Organization of the Striatum Encodes Action Space</article-title>. <source>Neuron</source>. <year>2017</year>; <volume>95</volume>(<issue>5</issue>):<fpage>1171</fpage>&#x2013;<lpage>1180.e7</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016Z.neuron.2017.08.015">https://doi.org/10.1016Z.neuron.2017.08.015</ext-link>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Kozlov</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Gentner</surname> <given-names>TQ</given-names></string-name>. <article-title>Central auditory neurons display flexible feature recombination functions</article-title>. <source>Journal of Neurophysiology</source>. <year>2013</year>; <volume>111</volume>(<issue>6</issue>):<fpage>1183</fpage>&#x2013;<lpage>1189</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Krakauer</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Ghazanfar</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Gomez-Marin</surname> <given-names>A</given-names></string-name>, <string-name><surname>MacIver</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Poeppel</surname> <given-names>D.</given-names></string-name> <article-title>Neuroscience needs behavior: correcting a reductionist bias</article-title>. <source>Neuron</source>. <year>2017</year>; <volume>93</volume>(<issue>3</issue>):<fpage>480</fpage>&#x2013;<lpage>490</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Kreitzer</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Malenka</surname> <given-names>RC</given-names></string-name>. <article-title>Striatal Plasticity and Basal Ganglia Circuit Function</article-title>. <source>Neuron</source>. <year>2008</year>; <volume>60</volume>(<issue>4</issue>):<fpage>543</fpage> &#x2013;<lpage>554</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2008.11.005">https://doi.org/10.1016/j.neuron.2008.11.005</ext-link>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Latimer</surname> <given-names>KW</given-names></string-name>, <string-name><surname>Yates</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Meister</surname> <given-names>MLR</given-names></string-name>, <string-name><surname>Huk</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Pillow</surname> <given-names>JW</given-names></string-name>. <article-title>Single-trial spike trains in parietal cortex reveal discrete steps during decision-making</article-title>. <source>Science</source>. <year>2015</year> <month>Jul</month>; <volume>349</volume>(<issue>6244</issue>):<fpage>184</fpage>&#x2013;<lpage>187</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Licata</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Raposo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ryan</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Sheppard</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>. <article-title>Posterior Parietal Cortex Guides Visual Decisions in Rats</article-title>. <source>J Neurosci</source>. <year>2017</year> <month>May</month>; <volume>37</volume>(<issue>19</issue>):<fpage>4954</fpage>&#x2013;<lpage>4966</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Lo</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>XJ</given-names></string-name>. <article-title>Cortico-basal ganglia circuit mechanism for a decision threshold in reaction time tasks</article-title>. <source>Nat Neurosci</source>. <year>2006</year> <month>Jun</month>; <volume>9</volume>(<issue>7</issue>):<fpage>956</fpage>&#x2013;<lpage>963</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Mallet</surname> <given-names>N</given-names></string-name>, <string-name><surname>Ballion</surname> <given-names>B</given-names></string-name>, <string-name><surname>Le Moine</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gonon</surname> <given-names>F.</given-names></string-name> <article-title>Cortical Inputs and GABA Interneurons Imbalance Projection Neurons in the Striatum of Parkinsonian Rats</article-title>. <source>Journal of Neuroscience</source>. <year>2006</year>; <volume>26</volume>(<issue>14</issue>):<fpage>3875</fpage>&#x2013;<lpage>3884</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4439-05.2006</pub-id>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Mallet</surname> <given-names>N</given-names></string-name>, <string-name><surname>Micklem</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Henny</surname> <given-names>P</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bolam</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Nakamura</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Magill</surname> <given-names>PJ</given-names></string-name>. <article-title>Dichotomous Organization of the External Globus Pallidus</article-title>. <source>Neuron</source>. <year>2012</year>; <volume>74</volume>(<issue>6</issue>):<fpage>1075</fpage>&#x2013;<lpage>1086</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Manohar</surname> <given-names>SG</given-names></string-name>, <string-name><surname>Chong</surname> <given-names>TTJ</given-names></string-name>, <string-name><surname>Apps</surname> <given-names>MAJ</given-names></string-name>, <string-name><surname>Batla</surname> <given-names>A</given-names></string-name>, <string-name><surname>Stamelou</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jarman</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Bhatia</surname> <given-names>KP</given-names></string-name>, <string-name><surname>Husain</surname> <given-names>M.</given-names></string-name> <article-title>Reward Pays the Cost of Noise Reduction in Motor and Cognitive Control</article-title>. <source>Curr Biol</source>. <year>2015</year> <month>Jun</month>; <volume>25</volume>(<issue>13</issue>):<fpage>1707</fpage>&#x2013;<lpage>1716</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Marr</surname> <given-names>D</given-names></string-name>, <string-name><surname>Poggio</surname> <given-names>T.</given-names></string-name> <source>From understanding computation to understanding neural circuitry</source>. <year>1976</year>;.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Mikhael</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Bogacz</surname> <given-names>R.</given-names></string-name> <article-title>Learning Reward Uncertainty in the Basal Ganglia</article-title>. <source>PLoS Comput Biol</source>. <year>2016</year> <month>Sep</month>; <volume>12</volume>(<issue>9</issue>):<fpage>e1005062</fpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Morris</surname> <given-names>G</given-names></string-name>, <string-name><surname>Nevet</surname> <given-names>A</given-names></string-name>, <string-name><surname>Arkadir</surname> <given-names>D</given-names></string-name>, <string-name><surname>Vaadia</surname> <given-names>E</given-names></string-name>, <string-name><surname>Bergman</surname> <given-names>H.</given-names></string-name> <article-title>Midbrain dopamine neurons encode decisions for future action</article-title>. <source>Nature Neuroscience</source>. <year>2006</year>; <volume>9</volume>:<fpage>1057</fpage>&#x2013;<lpage>1063</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Navarro</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Fuss</surname> <given-names>IG</given-names></string-name>. <article-title>Fast and accurate calculations for first-passage times in Wiener diffusion models</article-title>. <source>J Math Psychol</source>. <year>2009</year> <month>Aug</month>; <volume>53</volume>(<issue>4</issue>):<fpage>222</fpage>&#x2013;<lpage>230</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Parker</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Marshall</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Ahanonu</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>YW</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Grewe</surname> <given-names>BF</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Li</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Ehlers</surname> <given-names>MD</given-names></string-name>, <etal>et al.</etal> <article-title>Diametric neural ensemble dynamics in parkinsonian and dyskinetic states</article-title>. <source>Nature</source>. <year>2018</year>; <volume>557</volume>(<issue>7704</issue>):<fpage>177</fpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Pedersen</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Biele</surname> <given-names>G.</given-names></string-name> <article-title>The drift diffusion model as the choice rule in reinforcement learning</article-title>. <source>Psychonomic bulletin &#x0026; review</source>. <year>2017</year>; <volume>24</volume>(<issue>4</issue>):<fpage>1234</fpage>&#x2013;<lpage>1251</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Polan&#x00ED;a</surname> <given-names>R</given-names></string-name>, <string-name><surname>Krajbich</surname> <given-names>I</given-names></string-name>, <string-name><surname>Grueschow</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ruff</surname> <given-names>CC</given-names></string-name>. <article-title>Neural Oscillations and Synchronization Differentially Support Evidence Accumulation in Perceptual and Value-Based Decision Making</article-title>. <source>Neuron</source>. <year>2014</year>; <volume>82</volume>(<issue>3</issue>):<fpage>709</fpage>&#x2013;<lpage>720</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Ratcliff</surname> <given-names>R.</given-names></string-name> <article-title>A theory of Memory Retrival</article-title>. <source>Psychol Rev</source>. <year>1978</year>; <volume>85</volume>(<issue>2</issue>):<fpage>59</fpage>&#x2013;<lpage>108</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Ratcliff</surname> <given-names>R</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <article-title>Reinforcement-Based Decision Making in Corticostriatal Circuits: Mutual Constraints by Neurocomputational and Diffusion Models</article-title>. <source>Neural Comput</source>. <year>2012</year>; <volume>24</volume>:<fpage>1186</fpage>&#x2013;<lpage>1229</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Ratcliff</surname> <given-names>R</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>PL</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>SD</given-names></string-name>, <string-name><surname>McKoon</surname> <given-names>G.</given-names></string-name> <article-title>Diffusion Decision Model: Current Issues and History</article-title>. <source>Trends Cogn Sci</source>. <year>2016</year> <month>Apr</month>; <volume>20</volume>(<issue>4</issue>):<fpage>260</fpage>&#x2013;<lpage>281</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Rescorla</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Wagner</surname> <given-names>AR</given-names></string-name>, <etal>et al.</etal> <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>. <source>Classical conditioning II: Current research and theory</source>. <year>1972</year>; <volume>2</volume>:<fpage>64</fpage>&#x2013;<lpage>99</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Richfield</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Penney</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Young</surname> <given-names>AB</given-names></string-name>. <article-title>Anatomical and affinity state comparisons between dopamine D1 and D2 receptors in the rat central nervous system</article-title>. <source>Neuroscience</source>. <year>1989</year>; <volume>30</volume>(<issue>3</issue>):<fpage>767</fpage> &#x2013;<lpage>777</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0306-4522(89)90168-1">https://doi.org/10.1016/0306-4522(89)90168-1</ext-link>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Roesch</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Calu</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Schoenbaum</surname> <given-names>G.</given-names></string-name> <article-title>Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards</article-title>. <source>Nature Neuroscience</source>. <year>2007</year>; <volume>10</volume>:<fpage>1615</fpage>&#x2013;<lpage>1624</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Schmidt</surname> <given-names>R</given-names></string-name>, <string-name><surname>Leventhal</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Mallet</surname> <given-names>N</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>F</given-names></string-name>, <string-name><surname>Berke</surname> <given-names>JD.</given-names></string-name> <article-title>Canceling actions involves a race between basal ganglia pathways</article-title>. <source>Nat Neurosci</source>. <year>2013</year> <month>Aug</month>; <volume>16</volume>(<issue>8</issue>):<fpage>1118</fpage>&#x2013;<lpage>1124</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Schultz</surname> <given-names>W</given-names></string-name>, <string-name><surname>Apicella</surname> <given-names>P</given-names></string-name>, <string-name><surname>Scarnati</surname> <given-names>E</given-names></string-name>, <string-name><surname>Ljungberg</surname> <given-names>T.</given-names></string-name> <article-title>Neuronal activity in monkey ventral striatum related to the expectation of reward</article-title>. <source>J Neurosci</source>. <year>1992</year>; <volume>12</volume>(<issue>12</issue>):<fpage>4595</fpage>&#x2013;<lpage>4610</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title>. <source>Journal of neurophysiology</source>. <year>2001</year>; <volume>86</volume>(<issue>4</issue>):<fpage>1916</fpage>&#x2013;<lpage>1936</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Shindou</surname> <given-names>T</given-names></string-name>, <string-name><surname>Shindou</surname> <given-names>M</given-names></string-name>, <string-name><surname>Watanabe</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wickens</surname> <given-names>J.</given-names></string-name> <article-title>A silent eligibility trace enables dopamine-dependent synaptic plasticity for reinforcement learning in the mouse striatum</article-title>. <source>EurJ Neurosci</source>. <year>2018</year> <month>Mar</month>;.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Simen</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Holmes</surname> <given-names>P.</given-names></string-name> <article-title>Rapid decision threshold modulation by reward rate in a neural network</article-title>. <source>Neural Netw</source>. <year>2006</year> <month>Oct</month>; <volume>19</volume>(<issue>8</issue>):<fpage>1013</fpage>&#x2013;<lpage>1026</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname> <given-names>GD</given-names></string-name>, <string-name><surname>Cox</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Sherman</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Rinzel</surname> <given-names>J.</given-names></string-name> <article-title>Fourier analysis of sinusoidally driven thalamocortical relay neurons and a minimal integrate-and-fire-or-burst model</article-title>. <source>J Neurophysiol</source>. <year>2000</year> <month>Jan</month>; <volume>83</volume>(<issue>1</issue>):<fpage>588</fpage>&#x2013;<lpage>610</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Sutton</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Barto</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Booka</surname> <given-names>B.</given-names></string-name> <source>Reinforcement Learning: An Introduction</source>. <year>1998</year>;.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Tecuapetla</surname> <given-names>F</given-names></string-name>, <string-name><surname>Jin</surname> <given-names>X</given-names></string-name>, <string-name><surname>Lima</surname> <given-names>SQ</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RM</given-names></string-name>. <article-title>Complementary contributions of striatal projection pathways to action initiation and execution</article-title>. <source>Cell</source>. <year>2016</year>; <volume>166</volume>(<issue>3</issue>):<fpage>703</fpage>&#x2013;<lpage>715</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Tecuapetla</surname> <given-names>F</given-names></string-name>, <string-name><surname>Matias</surname> <given-names>S</given-names></string-name>, <string-name><surname>Dugue</surname> <given-names>GP</given-names></string-name>, <string-name><surname>Mainen</surname> <given-names>ZF</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RM</given-names></string-name>. <article-title>Balanced activity in basal ganglia projection pathways is critical for contraversive movements</article-title>. <source>Nature communications</source>. <year>2014</year>; <volume>5</volume>:<fpage>4315</fpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Tort</surname> <given-names>ABL</given-names></string-name>, <string-name><surname>Komorowski</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Manns</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Kopell</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Eichenbaum</surname> <given-names>H.</given-names></string-name> <article-title>Theta-gamma coupling increases during the learning of item-context associations</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2009</year>; <volume>106</volume>(<issue>49</issue>):<fpage>20942</fpage>&#x2013;<lpage>20947</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.0911331106</pub-id>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Wei</surname> <given-names>W</given-names></string-name>, <string-name><surname>Rubin</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>XJ</given-names></string-name>. <article-title>Role of the indirect pathway of the basal ganglia in perceptual decision making</article-title>. <source>J Neurosci</source>. <year>2015</year>; <volume>35</volume>(<issue>9</issue>):<fpage>4052</fpage>&#x2013;<lpage>4064</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Wichmann</surname> <given-names>T</given-names></string-name>, <string-name><surname>DeLong</surname> <given-names>MR</given-names></string-name>. <article-title>Functional and pathophysiological models of the basal ganglia</article-title>. <source>Current Opinion in Neurobiology</source>. <year>1996</year>; <volume>6</volume>(<issue>6</issue>):<fpage>751</fpage> &#x2013;<lpage>758</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0959-4388(96)80024-9">https://doi.org/10.1016/S0959-4388(96)80024-9</ext-link>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><string-name><surname>Wiecki</surname> <given-names>TV</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <article-title>A computational model of inhibitory control in frontal cortex and basal ganglia</article-title>. <source>Psychol Rev</source>. <year>2013</year> <month>Apr</month>; <volume>120</volume>(<issue>2</issue>):<fpage>329</fpage>&#x2013;<lpage>355</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Wiecki</surname> <given-names>TV</given-names></string-name>, <string-name><surname>Sofer</surname> <given-names>I</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <article-title>HDDM: hierarchical bayesian estimation of the drift-diffusion model in python</article-title>. <source>Frontiers in neuroinformatics</source>. <year>2013</year>; <volume>7</volume>:<fpage>14</fpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><string-name><surname>Yartsev</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Hanks</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Yoon</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Brody</surname> <given-names>CD</given-names></string-name>. <article-title>Causal contribution and dynamical encoding in the striatum during evidence accumulation</article-title>. <source>eLife</source>. <year>2018</year> <month>Aug</month>; <volume>7</volume>:<fpage>e34929</fpage>.</mixed-citation></ref>
</ref-list>
<sec id="s9">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><p>Time courses of corticostriatal synapse weights and firing rates when the rewards are constant in time <italic>(r</italic><sub><italic>L</italic></sub><italic>(t) = 0.7</italic> and <italic>r</italic><sub><italic>R</italic></sub><italic>(t) =</italic> 0.1). A: Averaged weights over 7 different realizations and over each of the four specific populations of neurons, which are dMSN selecting action <italic>L</italic> (solid black); dMSN selecting action <italic>R</italic> (solid red); iMSN countering action <italic>L</italic> (dashed black); iMSN countering action <italic>R</italic> (dashed red). B: Averaged evolution of the action values <italic>Q</italic><sub><italic>L</italic></sub> (black trace) and <italic>Q</italic><sub><italic>R</italic></sub> (red trace) over 7 different realizations. C: Firing rates of the dMSN populations selecting actions <italic>L</italic> (black) and <italic>R</italic> (red) over time. D: Firing rates of the iMSN populations countering actions <italic>L</italic> (black) and <italic>R</italic> (red) over time. Data in C,D was discretized into 50 <italic>ms</italic> bins. The transparent regions depict standard deviations.</p></caption>
<graphic xlink:href="418756_figS1.tif"/>
</fig>
</sec>
<app-group>
<app id="app1">
<sec id="s6">
<title>Appendix 1</title>
<sec id="s6a">
<title>Results with step changes in action values</title>
<p>In <italic>Appendix 1 <xref rid="fig1" ref-type="fig">Figure 1</xref></italic> we show the results of a simulation experiment with the STDP model in which the rewards associated with the <italic>L</italic> and <italic>R</italic> actions are switched after 5 sec. During the L-action consolidation period (from second 2 to 5), the firing rate for the L-dMSNs <italic>(D</italic><sub><italic>l</italic></sub><italic>)</italic> becomes higher than that for the R-dMSNs <italic>(D</italic><sub><italic>R</italic></sub>). After 5s, 20 <italic>L</italic> actions have been performened and the learning is almost consolidated, with <italic>Q</italic><sub><italic>L</italic></sub><italic>(t)</italic> and <italic>Q</italic><sub><italic>R</italic></sub><italic>(t)</italic> near <italic>r</italic><sub><italic>L</italic></sub> = 0.7 and <italic>r</italic><sub><italic>L</italic></sub> <italic>=</italic> 0.1 respectively (see first panel).</p>
<p>After the switch, there is a period of confusion where, even though <italic>L</italic> action is no longer the most rewarded, the network still shows a preference for <italic>L</italic> over R. Subsequently, the network learns that the <italic>R</italic> action is now more valuable than the <italic>L</italic> action, and the <italic>D</italic><sub><italic>R</italic></sub> grows while <italic>D</italic><sub><italic>L</italic></sub> decreases, such that eventually <italic>D</italic><sub><italic>R</italic></sub> <italic>&#x003E; D</italic><sub><italic>l</italic></sub>. After 10.5 seconds or so, the rate of seleciton of <italic>R</italic> consistently that for L, showing the network&#x2019;s capacity for adjusting to reward changes.</p>
<fig id="figA1" position="float" orientation="portrait" fig-type="figure">
<label>Appendix 1 Figure 1.</label>
<caption><p>STDP results when the rewards associated with <italic>L</italic> and <italic>R</italic> actions are exchanged after learning is underway. The first three panels represent, from top to bottom, the action values (Q(t)), the firing rates of dMSN neurons for each action (L, black; R, red), and the action frequency for the dMSN population of neurons that produces the <italic>L</italic> action (black) and the <italic>R</italic> action (red). The bottom panel represents the actual reward values for <italic>L</italic> (black) and <italic>R</italic> (red). The reward values switch when 20 <italic>L</italic> actions have occurred.</p></caption>
<graphic xlink:href="418756_figA1.tif"/>
</fig>
</sec>
</sec>
<sec id="s7">
<title>Appendix 2</title>
<sec id="s7a">
<title>Definitions of quantities computed from the STDP model</title>
<sec id="s7a1">
<title>Averaged population firing rate</title>
<p>We compute the firing rate of a neuron by adding up the number of spikes the neuron fires within a time window and dividing by the duration of that window. The averaged population firing rate is compute as the average of all neurons&#x2019; firing rates over a population, given by
<disp-formula id="ueqn3"><alternatives><graphic xlink:href="418756_ueqn3.gif"/></alternatives></disp-formula>
where &#x0394;<sub><italic>t</italic></sub>, is the time window in ms, <italic>s</italic><sub><italic>i</italic></sub> is the spike train corresponding to neuron <italic>i</italic>, and &#x27E8; <italic>&#x2022; &#x27E9;</italic> <sub><italic>n</italic></sub> denotes the mean over the <italic>n</italic> neurons in the population, The time course of the population firing rate is computed this way, using a disjoint sequence of time windows with <italic>&#x0394;, = 500 ms</italic>.</p>
</sec>
<sec id="s7a2">
<title>Action frequency</title>
<p>We compute the rate of a specific action <italic>i</italic> in a small window of A = <italic>500ms</italic> as the number of occurrences of action <italic>i</italic> within that window divided by A.</p>
</sec>
<sec id="s7a3">
<title>Mean behavioral learning curves across subjects</title>
<p>The behavioral learning curves indicate, as functions of trial number, the fraction of trials on which the more highly rewarded action is selected. Within a realization, using a sliding trial count window of 5 trials, we computed fraction of preferred actions selected (number of preferred actions divided by the total number of actions). Then we averaged over <italic>N</italic> realizations.</p>
</sec>
<sec id="s7a4">
<title>Evolution of the mean (across subjects) difference in model-estimated action values</title>
<p>Using <italic>N</italic> different realizations (simulating subjects in a behavioral experiment), we computed the difference of the expected reward of action <italic>L</italic> and the expected reward of action <italic>R</italic> at the time of each action selection (that is, <italic>Q</italic><sub><italic>L</italic></sub><italic>(t&#x002A;) &#x2212; Q</italic><sub><italic>R</italic></sub>(<italic>t&#x002A;</italic>), where <italic>t&#x002A;</italic> is the time of action selection). Notice that <italic>Q</italic><sub><italic>i</italic></sub>(<italic>t&#x002A;</italic>), for <italic>i</italic> &#x2208; {<italic>L, R</italic>}, only changes when an action occurs. Moreover, to average across realizations, we only considered the action number rather than the action onset time.</p>
</sec>
</sec>
</sec>
</app>
</app-group>
</back>
</article>