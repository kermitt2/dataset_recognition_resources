<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/320309</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioinformatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Floating search methodology for combining classification models for site recognition in DNA sequences</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>P&#x00E9;rez-Rodr&#x00ED;guez</surname>
<given-names>Javier</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x262F;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>de Haro-Garc&#x00ED;a</surname>
<given-names>Aida</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x262F;</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4488-6849</contrib-id>
<name>
<surname>Garc&#x00ED;a-Pedrajas</surname>
<given-names>Nicol&#x00E1;s</given-names>
</name>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x262F;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Computing and Numerical Analysis, University of C&#x00F3;rdoba</institution>, <country>Spain</country></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>&#x262F;</label><p>All of the authors contributed equally to this work.</p></fn>
<fn id="n2"><label>&#x002A;</label><p><email>npedrajas@uco.es</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>320309</elocation-id>
<history>
<date date-type="received">
<day>11</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>11</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="320309.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Recognition of the functional sites of genes, such as translation initiation sites, donor and acceptor splice sites and stop codons, is a relevant part of many current problems in bioinformatics. Recognition of the functional sites of genes is also a fundamental step in gene structure predictions in the most powerful programs. The best approaches to this type of recognition use sophisticated classifiers, such as support vector machines. However, with the rapid accumulation of sequence data, methods for combining many sources of evidence are necessary as it is unlikely that a single classifier can solve this type of problem with the best possible performance.</p>
<p>A major issue is that the number of possible models to combine is large and the use of all of these models is impractical. In this paper, we present a framework that is based on floating search for combining as many classifiers as needed for the recognition of any functional sites of a gene. The methodology can be used for the recognition of translation initiation sites, donor and acceptor splice sites and stop codons. Furthermore, we can combine any number of classifiers that are trained on any species. The method is also scalable to large datasets, as is shown in experiments in which the whole human genome is used. The method is also applicable to other recognition tasks.</p>
<p>We present experiments on the recognition of these four functional sites in the human genome, which is used as the target genome, and use another 20 species as sources of evidence. The proposed methodology shows significant improvement over state-of-the-art methods for use in a thorough evaluation process. The proposed method is also able to improve heuristic selection of species to be used as sources of evidence as the search finds the most useful datasets.</p>
<sec>
<title>Author summary</title>
<p>In this paper we present a methodology for combining many sources of information to recognize some of the most important functional sites in a genomic sequence. The functional sites of the sequences, such as, translation start sites, translation initiation sites, acceptor and donor splice sites and stop codons, play a very relevant role in many Bioinformatics tasks. Their accurate recognition is an important task by itself and also as part of gene structure prediction programs.</p>
<p>Our approach uses a methodology usually termed in Computer Science as &#x201C;floating search&#x201D;. This is a powerful heuristics applicable when the cost of evaluating each possible solution is high. The methodology is applied to the recognition of four different functional sites in the human genome using as additional sources of evidence the annotated genomes of other twenty different species.</p>
<p>The results show an advantage of the proposed method and also challenge the standard assumption of using only genomes not very close and not very far from the human to improve the recognition of functional sites in the human genome.</p>
</sec>
</abstract>
<counts>
<page-count count="84"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><title>Introduction</title>
<p>The recognition of functional sites within the genome is one of the most important problems in bioinformatics research. Determining where different functional sites, such as promoters, translation start sites, translation initiation sites (TISs), donors, acceptors and stop codons are located provides useful information for many tasks [<xref ref-type="bibr" rid="c1">1</xref>]. For instance, the recognition of translation initiation sites, donors, acceptors and stop codons [<xref ref-type="bibr" rid="c2">2</xref>] is one of the most critical tasks for gene structure prediction.</p>
<p>Many of the most successful gene recognizers that are currently in use implement an initial step of site recognition [<xref ref-type="bibr" rid="c3">3</xref>], which is followed by a process of combining the sites into meaningful gene structures. Accurate recognition is of the utmost importance for the whole gene structure prediction process. Actual sites that are not found by the classification models likely result in exons not being considered by the remaining steps of the recognition program. Furthermore, many false positives might inundate the second step, thereby making it difficult to predict gene structures accurately. State-of-the-art approaches use powerful classifiers, such as support vector machines (SVMs), and consider moderately large sequences around the functional site of interest [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c4">4</xref>&#x2013;<xref ref-type="bibr" rid="c6">6</xref>].</p>
<p>In recent years, information about the genomes of many species has been accumulated. This information can be used to improve the recognition of functional sites. However, the arbitrary selection of species using the widely assumed hypothesis that we must consider moderately distant evolutionary relatives is clearly a suboptimal procedure [<xref ref-type="bibr" rid="c7">7</xref>]. In addition, the classifier models are chosen a priori, without considering the possible benefits of combining various models.</p>
<p>It would be more efficient to learn all of the available classification models and obtain the best combination using an automatic method. The problem of finding the best combination can be tackled as a search problem over all possible combinations. An exhaustive search is unfeasible even for a small number of models. Other common search heuristics, such as evolutionary computation and swarm intelligence, are also prohibitively costly in terms of running time.</p>
<p>In cases when those heuristics cannot be used, floating search is an inexpensive yet sufficiently powerful methodology that is able to achieve very good solutions. Floating search has been used when the cost of each search step is high [<xref ref-type="bibr" rid="c8">8</xref>]. Thus, in this work, we propose using floating search to obtain a near-optimal combination of classification models, in which we can consider as many sources of evidence as are available and use as many classifiers as needed using various floating search methods, namely, Sequential Forward Selection, Sequential Backward Selection, Plus-<italic>l</italic> Minus-<italic>r</italic> Selection, Sequential Forward Floating Selection, Sequential Backward Floating Selection, Random Sequential Forward Floating Selection and Random Sequential Backward Floating Selection. Although the first two methods are not actually floating search methods but sequential greedy approaches, we included them for completeness.</p>
<p>To evaluate the proposed method, we show results for the recognition of the four functional sites that are cited above in five chromosomes of the human genome. To demonstrate the ability of our method to combine many classifiers we used for TIS and stop codon recognition 6 models for each of the 21 complete genomes, for a total of 126 classifiers. For donor and acceptor recognition, we used 5 models for the same 21 genomes, for a total of 105 classifiers.</p></sec>
<sec id="s2"><title>Materials and methods</title>
<p>As stated in the introduction, our major aim is to develop a combination method for obtaining optimal, or near-optimal, subsets of classification models that are trained for site recognition in DNA sequences. An exhaustive search would require the evaluation of 2<italic><sup>N</sup> &#x2212;</italic> 1 combinations of models given a set of <italic>N</italic> trained classifiers. This type of search is infeasible even for a small value of <italic>N</italic>. Therefore, we must use a search algorithm to find the best possible model combination efficiently. Many powerful metaheuristics are available in the machine learning literature, such as evolutionary computation [<xref ref-type="bibr" rid="c9">9</xref>], particle swarm optimization [<xref ref-type="bibr" rid="c10">10</xref>], ant colonies [<xref ref-type="bibr" rid="c11">11</xref>] and differential evolution [<xref ref-type="bibr" rid="c12">12</xref>]. However, all of these methodologies require the repetitive evaluation of many solutions to achieve their optimization goal. In the problem of site recognition, the evaluation of a possible solution is a costly process due to the large datasets that are involved. Thus, these metaheuristics are not feasible.</p>
<p>Instead, we propose a simpler approach, namely, floating search, which has obtained successful results in other research fields, such as feature selection [<xref ref-type="bibr" rid="c13">13</xref>&#x2013;<xref ref-type="bibr" rid="c16">16</xref>]. Floating search, which will be described in depth in the following section, is a set of stepwise search methods that are fast and efficient at solving problems in which the evaluation of many possible candidate solutions is too computationally expensive.</p>
<p>The process for obtaining the best combination of classifiers for various species is composed of two steps: a training step and validation step. Before starting the learning process, we need to obtain the training datasets, testing dataset and validation dataset. Without a loss of generality and to provide the necessary focus for our description, we use the same setup as in the experiments that are reported below. We address the problem of site recognition in the human genome. To solve this problem, we use a test set of sites of a specific chromosome, which we denote as <italic>T</italic>. The training set includes all of the remaining human chromosomes and genomes of all of the species we choose to evaluate. For validation, we use one of the human chromosomes in the training set, which we denote as <italic>V</italic> and remove it from the training set.</p>
<sec id="s2a"><title>Floating search</title>
<p>As stated above, the use of complex heuristics for combining tens or hundreds of models would incur an infeasible computational cost. Thus, we propose the use of simpler, yet still powerful, heuristics. We state our problem as a search problem to enable the application of those heuristics. We have <italic>N</italic> trained classifiers <italic>C</italic> &#x003D; &#x007B;<italic>c</italic><sub>1</sub>, <italic>c</italic><sub>2</sub>,&#x2026;, <italic>c<sub>N</sub></italic>&#x007D;, which are trained using any types of sequences that could be useful, and use any genome that we consider interesting. Our aim is to obtain a subset of classifiers <italic>C&#x2032;</italic> &#x2282; <italic>C</italic> that is the best possible combination. Evaluation of the combination of models is carried out using cross-validation. Thus, our objective function for maximization is the accuracy of the combination of classifiers over a validation set <italic>V</italic>, which is denoted as <italic>J</italic>(<italic>V</italic>).</p>
<p>Among the simplest methods, Sequential Forward Selection (SFS) [<xref ref-type="bibr" rid="c17">17</xref>] (see Algorithm 1) and Sequential Backward Selection (SBS) [<xref ref-type="bibr" rid="c18">18</xref>] (see Algorithm 2) are widely used because of their easy implementation and speed. The SFS method starts with an empty set and adds one classifier at a time to the selected subset by choosing the classifier that maximizes <italic>J</italic>(<italic>V</italic>). The method terminates when the value of <italic>J</italic>(<italic>V</italic>) is no longer improving or a desired number of classifiers has been reached. SBS starts from the opposite side by considering all of the classifiers and removing one classifier at a time. For classifier removal, <italic>J</italic>(<italic>V</italic>) is evaluated and the model that maximizes <italic>J</italic>(<italic>V</italic>) is removed. The stop criterion could be a number of classifiers that are removed or a decrease of <italic>J</italic>(<italic>V</italic>) is observed. In our experiments, we removed classifiers while <italic>J</italic>(<italic>V</italic>) does not decrease. These two methods can be generalized to add or remove <italic>r</italic> &#x2265; 1 classifiers in every iteration. These methods are fast and can obtain good results, but have two major problems: They easily become trapped in local minima and suffer from the &#x201C;nesting effect&#x201D; [<xref ref-type="bibr" rid="c19">19</xref>]. The nesting effect means that to obtain an optimal solution of size <italic>M</italic>, it must contain the optimal solution of size <italic>M &#x2212;</italic> 1, which is not often the case in practice.</p>
<statement><title>Algorithm 1</title>
<p>Sequential Forward Selection (SFS).</p>
</statement>
<fig id="ufig1" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="320309_ufig1.tif"/>
</fig>
<statement><title>Algorithm 2</title>
<p>Sequential Backward Selection (SBS).</p>
</statement>
<fig id="ufig2" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="320309_ufig2.tif"/>
</fig>
<p>The nesting problem can be avoided using the Plus-<italic>l</italic> Minus-<italic>r</italic> Selection (LRS) search method [<xref ref-type="bibr" rid="c20">20</xref>]. LRS adds backtracking capabilities by using SFS to add <italic>l</italic> models and SBS to remove <italic>r</italic> models. However, one major problem is that there is no rule for choosing the best values of <italic>l</italic> and <italic>r</italic>. The LRS method is shown as Algorithm 3.</p>
<p>A more advanced approach is floating search. In floating search, we let the size of the solution &#x201C;float&#x201D; and adapt to the problem using a backtracking mechanism. In that way, Sequential Forward Floating Selection (SFFS) and Sequential Backward Floating Selection (SBFS) [<xref ref-type="bibr" rid="c8">8</xref>] overcome the nesting problem and the local minimum problem by backtracking after adding (or removing) a new model. SFFS starts with an empty set and proceeds as SFS. However, after adding a new model, SFFS allows any of the previously added models to be removed until the value of <italic>J</italic> worsens. SBFS does the opposite: it follows the SBS method and allows removed models to be added. Algorithms 4 and 5 show the SFFS and SBFS methods, respectively. The comparisons [<xref ref-type="bibr" rid="c21">21</xref>] usually demonstrate better performances of SFFS and SBFS compared to SFS and SBS.</p>
<p>Somole et al. [<xref ref-type="bibr" rid="c13">13</xref>] proposed an adaptive version for feature selection in which the number of models to add or remove was incremented when the desired number of features was small. However, the method achieved only marginal improvement and required a longer execution time.</p>
<statement><title>Algorithm 3</title>
<p>Plus-<italic>l</italic> Minus-<italic>r</italic> Selection (LRS).</p>
</statement>
<fig id="ufig3" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="320309_ufig3.tif"/>
</fig>
<statement><title>Algorithm 4</title>
<p>Sequential Forward Floating Selection (SFFS).</p>
</statement>
<fig id="ufig4" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="320309_ufig4.tif"/>
</fig>
<statement><title>Algorithm 5</title>
<p>Sequential Backward Floating Selection (SBFS).</p>
</statement>
<fig id="ufig5" position="float" orientation="portrait" fig-type="figure">
<graphic xlink:href="320309_ufig5.tif"/>
</fig>
<p>We can also consider randomized versions of SFFS and SFBS as possible improvements. These algorithms are a combination of the random generation of a subset of models and a floating search selection algorithm. We propose the use of Random Sequential Forward Floating Selection (RSFFS) and Random Sequential Backward Floating Selection (RSBFS). Both algorithms start with a random subset of models<xref ref-type="fn" rid="fn1"><sup>1</sup></xref>, and with this random subset, an SFFS or SBFS algorithm is implemented. Thus, in the experiment, we will consider the SFS, SBS, LRS (with <italic>l</italic> &#x003D; 3, <italic>r</italic> &#x003D; 1 and <italic>l</italic> &#x003D; 1, <italic>r</italic> &#x003D; 3), SFFS, SBFS, RSFFS and RSBFS algorithms.</p>
<p>As we are combining various models, there are many ways of combining the outputs of those models. For the combination, we use three simple methods as our major aim is efficient execution. Although there are more complex approaches [<xref ref-type="bibr" rid="c22">22</xref>], their advantage is not large due to over-fitting problems. These methods are: i) the sum of the outputs of the classifiers; ii) the majority voting; and iii) the maximum output, where the sequence is classified using only the model with the highest output. In the machine learning literature, combining different sources of evidence for a classification problem is a common task [<xref ref-type="bibr" rid="c23">23</xref>]. Although various sophisticated methods have been developed for combining many classifiers [<xref ref-type="bibr" rid="c24">24</xref>&#x2013;<xref ref-type="bibr" rid="c27">27</xref>]; in practice, none of them are able to significantly outperform the simpler methods on a regular basis.</p>
<p>Two of the problems of combining many different classification models that are trained on different datasets are that their outputs may not be in the same range and the optimal classification threshold might be different for each model. The problem of the different ranges is solved by scaling all of the outputs to the interval [&#x2212;1, 1]. Regarding the threshold, we obtain the optimal threshold for each model, which is denoted as &#x0398;<italic><sub>opt</sub></italic>, using the validation set, and for the inclusion of the model in any combination, we use <italic>y</italic>(<bold>x</bold>) &#x2212; <bold>&#x0398;</bold><italic><sub>opt</sub></italic>, where <italic>y</italic>(<bold>x</bold>) is the actual output of the model for sequence <bold>x</bold>.</p>
<p>For the training stage, we can select as many species as we deem useful for our problem. We need not select the most appropriate species because the floating search will discard the useless classifiers. Once we have selected the set of species whose genomes we are going to use, we train as many classifiers as we want from those species. For every organism, we can train various classifiers, such as support vector machines (SVMs), neural networks (NNs), decision trees (DTs), and the <italic>k-</italic>Nearest Neighbor (<italic>k</italic>-NN) rule, and the same classifiers with different parameters. Because the validation stage can consider hundreds of classifiers, any method of potential interest can be used. Again, the floating search process will remove unneeded classifiers.</p></sec>
<sec id="s2b"><title>Experimental setup</title>
<p>To test our model, we chose the human genome together with those of other 20 species. Our aim was to test whether any species, regardless of the similarity of its genome with the human genome, could be useful. The following species were considered: <italic>Anolis carolinensis, Bos primigenius taurus, Caenorhabditis elegans, Callithrix jacchus, Canis lupus familiaris, Danio rerio, Drosophila melanogaster, Equus caballus, Ficedula albicollis, Gallus gallus, Homo sapiens, Macaca mulatta, Monodelphis domestica, Mus musculus, Ornithorhynchus anatinus, Oryctolagus cuniculus, Pan troglodytes, Rattus norvegicus, Schistosoma mansoni, Sus scrofa</italic> and <italic>Takifugu rubripes</italic>. These genomes were selected to consider a wide variety of organisms whose genomes are fully annotated.</p>
<p>Five classifiers were trained from every dataset for the four functional sites: a decision tree, a <italic>k-</italic>nearest neighbor rule, a positional weight matrix, a support vector machine with a string kernel and a support vector machine with a spectrum kernel. Additionally, for TIS and stop codon recognition, we used the stop codon method [<xref ref-type="bibr" rid="c28">28</xref>]. The parameters for every classifier were obtained using 10-fold cross-validation.</p>
<p>To evaluate our approach, we used five human chromosomes for testing purposes, namely, chromosomes 1, 3, 13, 19 and 21, and we used chromosome 16 for validation purposes. For each chromosome, we trained the classifiers with all of the remaining chromosomes except 16 and obtained the best combination method using our approach, and we used chromosome 16 for validation. We tested the selected models with all of the true TIS, donor and acceptor sites and stop codons and all of the negative samples of the given chromosome. That is, for chromosome 1, we trained the models with chromosomes 2 to 22 and X and Y, leaving out chromosome 16. Then, we chose the best combination method using chromosome 16 and tested this combination of models using chromosome 1. A summary of these datasets is shown in <xref ref-type="table" rid="tbl1">Table 1</xref>. The chromosomes were selected with the aim of choosing chromosomes of different lengths and coding densities. Chromosome 16 was chosen as a validation set because it is a chromosome of average length and coding density. We used the CCDS Update Released for Human of September 7, 2011. This update uses Human NCBI build 37.3 and includes a total of 26,473 CCDS IDs, which correspond to 18,471 GeneIDs. The validation set consisted of 836 positives samples and 2,721,460 negative samples for TIS, 28,567 positive samples and 8,011,785 negative samples for donor sites, 28,567 positive samples and 11,448,673 negative samples for acceptor sites and 838 positive samples and 7,480,457 negative samples for stop codons.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Summary of datasets for chromosomes 1, 3, 13, 19 and 21.</title>
<p>Random undersampling was used for training; thus, the number of negative instances was equal to the number of positive instances for the training dataset.</p></caption>
<graphic xlink:href="320309_tbl1.tif"/>
</table-wrap>
<p>One of the key aspects of the evaluation of any newly proposed method is the set of previous methods that are considered in the comparison. Many methods have been proposed for recognizing functional sites [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c28">28</xref>&#x2013;<xref ref-type="bibr" rid="c30">30</xref>]. However, these previous works and our own research [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c31">31</xref>] have shown that an SVM with a string kernel is the best state-of-the-art method for TISs, stop codons and splice sites [<xref ref-type="bibr" rid="c6">6</xref>]. To evaluate the general advantage of SVMs with string kernels, we performed a preliminary study of the available methods, which included position weight matrices, decision trees, <italic>k-</italic>nearest neighbors, the stop codon method [<xref ref-type="bibr" rid="c28">28</xref>], Wang et al.&#x2019;s method [<xref ref-type="bibr" rid="c30">30</xref>], Salzberg&#x2019;s method [<xref ref-type="bibr" rid="c32">32</xref>] and SVMs with linear and Gaussian kernels and four string kernels: the locality improved (LI) kernel, the weighted degree kernel (WD), the weighted degree kernel with shifts [<xref ref-type="bibr" rid="c33">33</xref>] (WDS) and the spectrum kernel [<xref ref-type="bibr" rid="c34">34</xref>]. SVMs with WD kernels consistently provided the best results. Thus, we chose this method as the method to be compared with our proposed method. WDS provided marginally better results than WD, but with a far higher computational complexity. To ensure a fair comparison, we considered not only these methods but also all of the others that were used as classifiers. Then, for every experiment, we compared our approach to the best performing method in terms of the validation performance. SVM with WD kernel was always the best individual classifier.</p>
<p>Another key parameter of the learning process is the window around the functional site that is used to train the classifiers. An additional advantage of our approach is that it allows the use of a suitable window for each dataset and even the combination of models that are trained using different windows. The value of the window for each classifier was obtained by cross-validation. We considered the site to be offset by 0 and tested the performance of the following windows: [&#x2212;100, 0], [&#x2212;75, 25], [&#x2212;50, 0], [&#x2212;50, 50], [&#x2212;25, 0], [&#x2212;25, 25], [&#x2212;25, 75], [&#x2212;10, 15], [&#x2212;10, 40], [&#x2212;10, 90], [0, 25], [0, 50] and [0, 100]. For each trained classifier, the best window was chosen. For the stop codon method, we used the additional window values of [0, 200], [0, 300], [0, 400] and [0, 500] for TIS recognition and the window values of [&#x2212;200, 0], [&#x2212;300, 0], [&#x2212;400, 0] and [&#x2212;500, 0] for stop codon recognition. For donor and acceptor sites, due to the many training instances, validation of the window around the site was not feasible. Thus, we chose a fixed window for both sites of [&#x2212;25, 25].</p>
<p>Furthermore, SVMs are very sensitive to the learning parameters; thus, we also performed cross-validation to obtain their values. The WD kernel has two parameters: the standard <italic>C</italic> parameter of any SVM and the window width of the string kernel. We tested values of 1, 10, 100 and 1000 for C and 12 and 24 for the window width. All 8 combinations were evaluated using 10-fold cross-validation, and the best combinations was chosen. Although it can be argued that this method might result in suboptimal parameters, it represents a good compromise between the high performance of SVM and the high computational cost of evaluating each set of parameters. The spectrum kernel is too time consuming for cross-validation of the parameters in the same way as the WD kernel. Therefore, we fixed the values of the kernel to the values that are recommended by the authors [<xref ref-type="bibr" rid="c34">34</xref>] and only validated the value of <italic>C</italic> using the same values as for the WD kernel.</p>
<p>For PWM and C4.5, there are no parameters that have a significant effect on their performance. For <italic>k-</italic>NN, the number of neighbors <italic>k</italic> was chosen by cross-validation in the interval [<xref ref-type="bibr" rid="c1">1</xref>, 100].</p>
<p>To train the models, we used random undersampling [<xref ref-type="bibr" rid="c35">35</xref>] because previous studies have demonstrated its usefulness for TIS recognition [<xref ref-type="bibr" rid="c31">31</xref>]. For random undersampling, we used a ratio of 1, which means that the majority class was randomly undersampled until both classes had the same number of instances. To avoid any contamination of the experiments, for every training set, regardless of the species, we removed the genes that were shared with the test chromosome for all the training datasets.</p>
<p>To evaluate the obtained classifiers, we used the standard measures for imbalanced data. Given the number of true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN), we used the sensitivity (Sn):<disp-formula id="eqn1">
<alternatives><graphic xlink:href="320309_eqn1.gif"/></alternatives>
</disp-formula>and the specificity (Sp):<disp-formula id="eqn2">
<alternatives><graphic xlink:href="320309_eqn2.gif"/></alternatives>
</disp-formula></p>
<p>The geometric mean of these two measures, namely, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="320309_inline1.gif"/></alternatives></inline-formula>, was our first classification metric. As a second measure, we used the area under the receiver operating characteristic (ROC) curve (auROC). However, auROC is independent of the class ratios and can be less meaningful when we have very unbalanced datasets [<xref ref-type="bibr" rid="c6">6</xref>]. In such cases, the area under the precision-recall curve (auPRC) can be used. The recall measure is equivalent to the sensitivity measure that was defined above. The precision (P) is given by:<disp-formula id="eqn3">
<alternatives><graphic xlink:href="320309_eqn3.gif"/></alternatives>
</disp-formula></p>
<p>The auPRc measure is especially relevant if we are mainly interested in the positive class. However, the auPRc measure can be very sensitive to subsampling. In our results, we use all the positive and negative instances for each of the five tested chromosomes; thus, no subsampling is used. This also yields small auPRC values.</p>
<p>We use these three metrics because they provide two views of the performance of the classifiers. The auROC and auPRC values describe the general behavior of the classifier. However, when used in practice, we must establish a threshold for the classification of a query pattern. <italic>G-</italic>mean provides the required snapshot of the performance of the classifier when we set the required threshold.</p>
<p>The recognition of sites is usually a first step within a larger task, such as a gene structure prediction program. Therefore, depending on the subsequent steps, our focus was centered on obtaining models that perform well in terms of various accuracy measures. Thus, we performed experiments that were aimed at optimizing the three measures that were described above. We carried out experiments with eight search algorithms, namely, SFS, SBS, LRS (with <italic>l</italic> &#x003D; 3, <italic>r</italic> &#x003D;1 and <italic>l</italic> &#x003D; 1, <italic>r</italic> &#x003D; 3), SFFS, SBFS, RSFFS and RSBFS; three combination methods, namely, the sum of outputs, majority voting and maximum; and three measures as optimization objectives, namely, <italic>G-</italic>mean, auROC and auPRC. The best model was always selected using the validation set.</p></sec></sec>
<sec id="s3"><title>Results and Discussion</title>
<p>We performed experiments on the recognition of TISs, donor and acceptor sites and stop codons to address the four most important sites in any gene recognition task. However, our approach is applicable to other recognition tasks, such as promoter and transcription start site (TSS) prediction. Our method has two main advantages: First, it has the ability to improve the performance of previous methods. Second, the chosen combination of classifiers that are trained on different genomes can provide information on which species are more interesting for human site recognition. In the following four sections, we discuss the results of the recognition of the four sites.</p>
<p>One of the main advantages of our approach is that we can optimize the performance measure in which we are interested, which can be the <italic>G-</italic>mean, auROC, auPRC or any other measure that is useful for our application. Thus, we conducted our experiments using three performance measures: <italic>G-</italic>mean, auROC and auPRC. The first relevant result is that the combination of the best models that was obtained for each measure was different. This result means that, depending on the aim of the work, different combinations of classifiers are needed. For each of the five studied chromosomes, we obtained three combinations of models, each optimized for one of the three measures that are discussed above.</p>
<sec id="s3a"><title>Results for TIS recognition</title>
<p>The results for the recognition of TISs for human chromosomes 1, 3, 13, 19 and 21 are shown in <xref ref-type="table" rid="tbl2">Table 2</xref>. Regarding the search method, the results for TIS support our approach of using different methods and selecting the best method for each case, as there is no clear winner. Although SFFS achieved the best results most often, SFS, LRS and RSFBS also perform well. For the combination method, the sum of outputs was always the best method for auROC and auPRC, with the exception of auROC for chromosome 13. For <italic>G-</italic>mean, majority voting was always the best-performing approach.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Results for TIS recognition for human chromosomes 1, 3, 13, 19 and 21.</title>
<p>The table shows the results for the three considered measures, auROCm auPRC and <italic>G-</italic>mean. The best search method, the best combination method and the classification performance values are shown.</p></caption>
<graphic xlink:href="320309_tbl2.tif"/>
</table-wrap>
<p>In terms of auROC, our approach achieved a clear improvement over the SVM method alone. The improvement ranged from 3.32&#x0025; for the worst case, namely, chromosome 19, to 5.74&#x0025; for the best case, namely, chromosome 21. We must take into account that improvement refers to many sites being correctly classified compared to the standard approach. The standard approach obtained a total of 1,536,902 FPs; this number was reduced to 299,766, which means more than one million fewer FPs. For any gene recognition program, that would mean a far better point from which to start for constructing correct genes.</p>
<p>For auPRC, the improvement was more dramatic<xref ref-type="fn" rid="fn2"><sup>2</sup></xref>. The improvement is greater than 10&#x0025; for all five chromosomes. This is a remarkable result if we take into account the low values of auPRC for all methods. For <italic>G-</italic>mean, the results also showed a clear advantage of our method with an improvement of over 5&#x0025; for the worst case.</p>
<p>The reported reduction is relevant because most current gene recognizers heavily rely on the classification of sites as a basic step; therefore, it is very likely that those genes whose TIS is not recognized would be completely missed by any gene recognizer. Our approach has the potential to significantly improve the accuracy of any annotation system.</p>
<p>Another interesting result is that the behaviors of the TPs, FNs, TNs and FPs values depended on the measure that we were optimizing. Thus, if we are interested in obtaining the best TP and FN results, we should select the optimization of <italic>G-</italic>mean. If our interest is in TNs and FPs, auPRC should be our objective. If we want a satisfactory overall behavior of the four measures, we should use auROC as our objective. The ability of our proposed method to offer such flexibility is an important asset in any practical application.</p>
<p>Once we established the usefulness of our proposed method in terms of performance, we examined the results in terms of the species that were involved in the best combinations. <xref ref-type="table" rid="tbl3">Table 3</xref> shows the models that were selected for the best combination for each measure and each chromosome. Regardless of the optimized measure, there was no species that never appeared in the best combination. This result indicates that although the contributions of some species are more relevant than those of others, the information of all of the genomes was useful for the prediction of human TISs, even those species that are very distant relatives of humans. Another interesting result is that for the three measures, namely, auROC, auPRC and <italic>G-</italic>mean, the obtained combinations of models were substantially different. This result indicates that we must consider our aims before designing our classifier. In most previous works, that is not taken into account.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>Models selected for TIS recognition.</title></caption>
<graphic xlink:href="320309_tbl3.tif"/>
<graphic xlink:href="320309_tbl3a.tif"/>
<graphic xlink:href="320309_tbl3b.tif"/>
</table-wrap>
<p>Regarding the classification models, all methods were selected at least once. The <italic>k-</italic>NN rule and SVM with a string kernel were the most frequently selected methods. The case of <italic>k-</italic>NN is remarkable as this approach is not usually used for this task [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c28">28</xref>&#x2013;<xref ref-type="bibr" rid="c30">30</xref>]. It appears that the diversity that <italic>k-</italic>NN introduced into the models was useful for the overall performance of the combinations, despite that <italic>k-</italic>NN alone showed a worse performance than SVM alone. The explanation of this result may be found in the behavior of the ensembles of classifiers. It is well known [<xref ref-type="bibr" rid="c36">36</xref>] that a diverse ensemble of classifiers improves the performance of the set of classifiers.</p>
<p>The five most frequently used genomes were <italic>Macaca mulatta, Pan troglodytes, Equus caballus, Callithrix jacchus</italic> and <italic>Rattus norvegicus. Homo sapiens</italic> was not among the most often used genomes. Moreover, other genomes that are further removed from the human genome, such as <italic>Takifugu rubripes</italic>, were also frequently used.</p>
<p>With respect to the three objectives, optimizing the <italic>G-</italic>mean yielded the most stable results. For the five chromosomes, the selected models were always the SVM method for <italic>Macaca mulatta</italic> and <italic>Pan troglodytes</italic>, with the exception of chromosome 13,where <italic>Pan troglodytes</italic> was replaced with <italic>Bos primigenius taurus</italic>. For chromosome 1, another two classification models were used. For auROC, six or seven models were usually selected, with chromosome 13 requiring 28. The SVM method was always chosen for <italic>Macaca mulatta</italic> and <italic>Pan troglodytes</italic>, but the remaining methods and species depended on the chromosome. This is another interesting result because most TIS recognition programs mainly rely on common models for any task. Finally, for auPRC, significantly more models were selected, from 28 to 34, with a significant variation among the chromosomes. Here, the large number of negative samples made this task harder than optimizing the other two criteria.</p>
<p>The ROC and PRC curves are shown in <xref ref-type="fig" rid="fig1">Figs. 1</xref>&#x2013;<xref ref-type="fig" rid="fig5">5</xref>. These figures show that our approach improved the auROC and auPRC for all five studied chromosomes. These results demonstrate that the proposed method outperformed the best model overall. The ROC and PRC curves show that the curves that correspond to our proposed method are always above the curves of the best model. This result indicates better performance for all the possible thresholds of classification.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>ROC and PRC curves for TIS and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 1 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig1.tif"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>ROC and PRC curves for TIS and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 3 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig2.tif"/>
</fig>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>ROC and PRC curves for TIS and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 13 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig3.tif"/>
</fig>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>ROC and PRC curves for TIS and chromosome 19.</title>
<p>ROC and PRC curves for chromosome 19 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig4.tif"/>
</fig>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>ROC and PRC curves for TIS and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 21 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig5.tif"/>
</fig></sec>
<sec id="s3b"><title>Results for donor site recognition</title>
<p>The results for the recognition of donor sites for human chromosomes 1, 3, 13, 19 and 21 are shown in <xref ref-type="table" rid="tbl4">Table 4</xref>. For auROC, the achieved results were close to or above 99&#x0025;, so there was little room for improvement. A similar trend was followed by <italic>G-</italic>mean, with an improvement of approximately 1&#x0025;. auPRC was significantly improved, from 5&#x0025; in the worst case to 11&#x0025; in the best case. However, since the number of negative samples was large, these small improvements corresponded to the correction of many erroneous predictions. For example, the standard approach obtained 3,616,750 FPs, while our approach for auROC optimization reduced this number by almost one million to 2,796,742 FPs.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><title>Results for donor site recognition for human chromosomes 1, 3, 13, 19 and 21.</title></caption>
<graphic xlink:href="320309_tbl4.tif"/>
</table-wrap>
<p><xref ref-type="table" rid="tbl5">Table 5</xref> shows the classification models and genomes that were selected for every case. There are several differences with TIS recognition. First, there are a few genomes that were not used at all in any final best model, namely, <italic>Anolis carolinensis, Drosopila melanogaster, Takifugu rubripes, Danio rerio, Monodelphis domestica</italic> and <italic>Ornithorhynchus anatinus</italic>. Second, <italic>G-</italic>mean and auROC optimization required more models, whereas auPRC used significantly fewer models for TIS prediction. The models that were selected for every optimized measure showed a large variety, thereby supporting the claim of our work that as many genomes as available should be used instead of selecting some of them <italic>a priori</italic>.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5.</label>
<caption><title>Models selected for donor site recognition.</title></caption>
<graphic xlink:href="320309_tbl5.tif"/>
<graphic xlink:href="320309_tbl5a.tif"/>
<graphic xlink:href="320309_tbl5b.tif"/>
</table-wrap>
<p>Regarding the classification models, the behavior was more similar. <italic>k-</italic>NN and SVM with a string kernel were the models that were more frequently used, with a large difference with the remaining methods. PWM was never used, and C4.5 and the SVM with the spectrum kernel were used only on a few occasions. The ROC and PRC curves for our approach and the standard method are shown in <xref ref-type="fig" rid="fig6">Figs. 6</xref> to <xref ref-type="fig" rid="fig10">10</xref>.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>ROC and PRC curves for the donor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 1 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig6.tif"/>
</fig>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>ROC and PRC curves for the donor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 3 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig7.tif"/>
</fig>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>ROC and PRC curves for the donor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 13 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig8.tif"/>
</fig>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><title>ROC and PRC curves for the donor site and chromosome 19.</title>
<p>ROC and PRC curves for chromosome 19 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig9.tif"/>
</fig>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><title>ROC and PRC curves for the donor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 21 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig10.tif"/>
</fig></sec>
<sec id="s3c"><title>Results for acceptor site recognition</title>
<p>The results for the recognition of acceptor sites for human chromosomes 1, 3, 13, 19 and 21 are shown in <xref ref-type="table" rid="tbl6">Table 6</xref>. The results for the acceptor site prediction were similar to those for the donor site prediction. The improvement in terms of auROC was small due to the little room for increasing the values of the standard method. However, the small improvement corresponded to many negative instances being correctly classified. The standard method obtained 6,053,645 FPs, whereas our approach when optimizing the auROC measure achieved 4,345,285 FPs, reducing by more than 1.5 million the total FPs.</p>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6.</label>
<caption><title>Results for acceptor site recognition for human chromosomes 1, 3, 13, 19 and 21.</title></caption>
<graphic xlink:href="320309_tbl6.tif"/>
</table-wrap>
<p>The models that were selected for every chromosome are shown in <xref ref-type="table" rid="tbl7">Table 7</xref>. The selected classification methods and genomes were similar to those in the previous donor site recognition. The number of models for every measure was also similar, with the exception of auPRC for chromosome 21, which required more models, namely, 46. <italic>Anolis carolinensis</italic> was the only genome that was never used, although <italic>Danio rerio, Drosophila melanogaster</italic> and <italic>Schistosoma mansoni</italic> appeared only rarely. As in previous results, <italic>k-</italic>NN and SVM with a string kernel were the most commonly selected classification methods.</p>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7.</label>
<caption><title>Models selected for acceptor site recognition.</title></caption>
<graphic xlink:href="320309_tbl7.tif"/>
<graphic xlink:href="320309_tbl7a.tif"/>
<graphic xlink:href="320309_tbl7b.tif"/>
</table-wrap>
<p>The ROC and PRC curves for our approach and standard method are shown in <xref ref-type="fig" rid="fig11">Figs. 11</xref> to <xref ref-type="fig" rid="fig15">15</xref>. These results demonstrate that the overall performance of the proposed method was better than the performance of the best model.</p>
<fig id="fig11" position="float" orientation="portrait" fig-type="figure">
<label>Figure 11.</label>
<caption><title>ROC and PRC curves for the acceptor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 1 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig11.tif"/>
</fig>
<fig id="fig12" position="float" orientation="portrait" fig-type="figure">
<label>Figure 12.</label>
<caption><title>ROC and PRC curves for the acceptor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 3 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig12.tif"/>
</fig>
<fig id="fig13" position="float" orientation="portrait" fig-type="figure">
<label>Figure 13.</label>
<caption><title>ROC and PRC curves for the acceptor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 13 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig13.tif"/>
</fig>
<fig id="fig14" position="float" orientation="portrait" fig-type="figure">
<label>Figure 14.</label>
<caption><title>ROC and PRC curves for the acceptor site and chromosome 19.</title>
<p>ROC and PRC curves for chromosome 19 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig14.tif"/>
</fig>
<fig id="fig15" position="float" orientation="portrait" fig-type="figure">
<label>Figure 15.</label>
<caption><title>ROC and PRC curves for the acceptor site and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 21 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig15.tif"/>
</fig></sec>
<sec id="s3d"><title>Results for stop codon recognition</title>
<p>Stop codon recognition is the most difficult task of the four types of recognition. One of the major sources of this increased complexity is the number of negative instances, which means a much larger minority:majority ratio. The global majority:minority ratio for TISs is 1:4,155, for donors 1:326, for acceptors 1:455 and for stop codons 1:12,237. <xref ref-type="table" rid="tbl8">Table 8</xref> shows the results for the five chromosomes and the three optimization measures.</p>
<table-wrap id="tbl8" orientation="portrait" position="float">
<label>Table 8.</label>
<caption><title>Results for stop codon recognition for human chromosomes 1, 3, 13, 19 and 21.</title></caption>
<graphic xlink:href="320309_tbl8.tif"/>
</table-wrap>
<p>For auROC, the results showed a clear improvement. In the worst case, our approach improved the results by more than 4&#x0025; and in the best case by more than 6&#x0025;. These improvements were also achieved for the auPRC and <italic>G-</italic>mean measures. The usefulness of our approach can be corroborated by comparing the number of FPs between the standard method and our proposed method. Overall, for the five chromosomes, the standard approach obtained 6,739,588 FPs, whereas our method reduced that number to 1,459,923, which means that more than five million FPs were removed. The effect of that dramatic improvement on the recognition ability for stop codons must be significant over any gene structure prediction program.</p>
<p>As in previous results, the most common combination method was to sum the outputs, although majority voting was selected as a general rule for the <italic>G-</italic>mean measure, with the exception of chromosome 1. The searching strategies that obtained the best results depended on the experiment, which demonstrates the advantage of using all of them.</p>
<p>The numbers of models and selected classifiers and genomes for every case are shown in <xref ref-type="table" rid="tbl9">Table 9</xref>. <italic>G-</italic>mean, as in the previous results, was the measure that required fewer models, from 2 for chromosome 13 to 6 for chromosomes 1, 3 and 21. auROC selected from 7 to 15 models. Again, auPRC required a comparatively large number of models, from 31 to 58 selected models.</p>
<table-wrap id="tbl9" orientation="portrait" position="float">
<label>Table 9.</label>
<caption><title>Models selected for stop codon recognition.</title></caption>
<graphic xlink:href="320309_tbl9.tif"/>
<graphic xlink:href="320309_tbl9a.tif"/>
<graphic xlink:href="320309_tbl9b.tif"/>
<graphic xlink:href="320309_tbl9c.tif"/>
</table-wrap>
<p><italic>Caenorhabditis elegans</italic> was the only genome that was never used. The use of all the genomes was more balanced for the recognition of stop codons, using even genomes that were far removed from the human genome, such as those of <italic>Takifugu rubripes</italic> of <italic>Danio rerio</italic>. The use of classifiers was also more equally distributed among the six methods, with the exception of PWM, which was never used.</p>
<p>With respect to the three objectives, optimizing the <italic>G-</italic>mean required fewer models, from 2 to 6. For the five chromosomes, the SVM method for <italic>Macaca mulatta</italic> and <italic>Pan troglodytes</italic> was always selected. <italic>Callithrix jacchus</italic> and <italic>Canis lupus familiaris</italic> were also selected in most chromosomes. For auROC, more models were selected, from 7 to 15. The SVM method for <italic>Macaca mulatta</italic> and <italic>Pan troglodytes</italic> was always chosen, but the remaining methods depended on the chromosome. This is another interesting result because most stop codon recognition programs rely on common models for any task. Finally, for auPRC, significantly more models were selected, from 31 to 58, with a significant variation among the chromosomes.</p>
<p>The actual ROC and PRC curves, which are shown in <xref ref-type="fig" rid="fig16">Figs. 16</xref>&#x2013;<xref ref-type="fig" rid="fig20">20</xref>, show that the curves that correspond to our proposed method are always above the curves of the best model. This indicates better performance for all the possible thresholds of classification.</p>
<fig id="fig16" position="float" orientation="portrait" fig-type="figure">
<label>Figure 16.</label>
<caption><title>ROC and PRC curves for the STOP codon and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 1 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig16.tif"/>
</fig>
<fig id="fig17" position="float" orientation="portrait" fig-type="figure">
<label>Figure 17.</label>
<caption><title>ROC and PRC curves for the STOP codon and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 3 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig17.tif"/>
</fig>
<fig id="fig18" position="float" orientation="portrait" fig-type="figure">
<label>Figure 18.</label>
<caption><title>ROC and PRC curves for the STOP codon and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 13 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig18.tif"/>
</fig>
<fig id="fig19" position="float" orientation="portrait" fig-type="figure">
<label>Figure 19.</label>
<caption><title>ROC and PRC curves for the STOP codon and chromosome 19.</title>
<p>ROC and PRC curves for chromosome 19 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig19.tif"/>
</fig>
<fig id="fig20" position="float" orientation="portrait" fig-type="figure">
<label>Figure 20.</label>
<caption><title>ROC and PRC curves for the STOP codon and chromosome 1.</title>
<p>ROC and PRC curves for chromosome 21 and the standard approach and our proposed method when auROC and auPRC are optimized.</p></caption>
<graphic xlink:href="320309_fig20.tif"/>
</fig></sec></sec>
<sec id="s4"><title>Summary of the comparison</title>
<p>As a summary of the comparison for the five chromosomes and four sites, <xref ref-type="fig" rid="fig21">Figs. 21</xref>, <xref ref-type="fig" rid="fig22">22</xref>, <xref ref-type="fig" rid="fig23">23</xref>, <xref ref-type="fig" rid="fig24">24</xref> and <xref ref-type="fig" rid="fig25">25</xref> show the improvements for all four sites and five chromosomes. The figures show the relative improvement of our approach in terms of <italic>G-</italic>mean, auROC and auPRC. All of the figures show the improvement that obtained using the floating search strategy.</p>
<fig id="fig21" position="float" orientation="portrait" fig-type="figure">
<label>Figure 21.</label>
<caption><title>Chromosome 1 result comparison.</title>
<p>Relative improvement in the chromosome 1 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig21.tif"/>
</fig>
<fig id="fig22" position="float" orientation="portrait" fig-type="figure">
<label>Figure 22.</label>
<caption><title>Chromosome 3 result comparison.</title>
<p>Relative improvement in the chromosome 3 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig22.tif"/>
</fig>
<fig id="fig23" position="float" orientation="portrait" fig-type="figure">
<label>Figure 23.</label>
<caption><title>Chromosome 13 result comparison.</title>
<p>Relative improvement in the chromosome 13 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig23.tif"/>
</fig>
<fig id="fig24" position="float" orientation="portrait" fig-type="figure">
<label>Figure 24.</label>
<caption><title>Chromosome 19 result comparison.</title>
<p>Relative improvement in the chromosome 19 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig24.tif"/>
</fig>
<fig id="fig25" position="float" orientation="portrait" fig-type="figure">
<label>Figure 25.</label>
<caption><title>Chromosome 21 result comparison.</title>
<p>Relative improvement in the chromosome 21 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig25.tif"/>
</fig>
<p>Finally, to study the effect on the performance of the proposed method of the optimization measure, we show in <xref ref-type="fig" rid="fig26">Figs. 26</xref>, <xref ref-type="fig" rid="fig27">27</xref> and <xref ref-type="fig" rid="fig28">28</xref> the overall improvements in terms of TPs, FNs, TNs and FNs for all of the chromosomes and the four sites. The first conclusion is that the optimization objective has a relevant impact on the distribution of the errors. That is a very important aspect if we plan to use site recognition as an initial step in a gene structure prediction task, as our prediction program might be more sensitive to a specific type of errors.</p>
<fig id="fig26" position="float" orientation="portrait" fig-type="figure">
<label>Figure 26.</label>
<caption><title>TP, FN, TN, and FP improvements for all four sites using auROC as the optimization objective.</title>
<p>Overall improvement results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig26.tif"/>
</fig>
<fig id="fig27" position="float" orientation="portrait" fig-type="figure">
<label>Figure 27.</label>
<caption><title>TP, FN, TN, and FP improvements for all four sites using auPRC as the optimization objective.</title>
<p>Overall improvement results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig27.tif"/>
</fig>
<fig id="fig28" position="float" orientation="portrait" fig-type="figure">
<label>Figure 28.</label>
<caption><title>TP, FN, TN, and FP improvements for all four sites using <italic>G-</italic>mean as the optimization objective.</title>
<p>Overall improvement results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig28.tif"/>
</fig>
<p>For positive site prediction, the best results were obtained using <italic>G-</italic>mean as theobjective, whereas auROC only showed a minor improvement and auPRC was even worse than the standard approach for TIS and stop codon prediction. For negative instances, auROC and auPRC performed very well, with a small advantage of auPRC for TISs and stop codons and of auROC for donors and acceptors. <italic>G-</italic>mean achieved a marked improvement over the standard method but not as dramatic as those of auROC and auPRC. The best overall performance on both positive and negative samples was achieved by <italic>G-</italic>mean, which showed a more balanced behavior.</p>
<sec id="s4a"><title>Effect on gene prediction</title>
<p>We stated in the introduction that the improvement of the site prediction that was introduced by our method would have a significant impact on the prediction of the complete structure of genes, as site prediction is a relevant step in most current gene structure prediction programs. To test that statement, we performed a final experiment on gene prediction for chromosome 21. We constructed a very simple predictor that searched for exons using the sites that were found by the recognition program, which was either the standard approach or our proposed method, and constructed a gene using these exons. This simple program is not intended for gene structure prediction but only to test the ability of our proposed method in improving gene recognition.</p>
<p>To evaluate gene predictor performance over a test sequence, the predicted gene structure is compared with the annotated gene structure on the target sequence. The accuracy is evaluated at different levels of resolution. Commonly, these levels are the nucleotide, exon and gene levels. Due to the use of a very simple program, no gene-level accuracy is reported. Regarding nucleotide-level performance, we used as comparison measures Sensitivity (Sn):<disp-formula id="eqn4">
<alternatives><graphic xlink:href="320309_eqn4.gif"/></alternatives>
</disp-formula>which is a relevant measure if we are interested only in the performance on the positive class, and Specificity (<italic>Sp</italic>), in its traditional machine learning form, which is defined as:<disp-formula id="eqn5">
<alternatives><graphic xlink:href="320309_eqn5.gif"/></alternatives>
</disp-formula></p>
<p>In bioinformatics, and particularly in gene prediction, specificity is usually defined in a different way. Specificity (<italic>Sp</italic>(<italic>BIO</italic>)) is calculated by dividing the number of correct predictions by the total number of predictions:<disp-formula id="eqn6">
<alternatives><graphic xlink:href="320309_eqn6.gif"/></alternatives>
</disp-formula></p>
<p>However, neither sensitivity nor specificity by itself constitutes a measure of global accuracy. A good measure that summarizes both at the nucleotide level is the Correlation Coefficient (CC):<disp-formula id="eqn7">
<alternatives><graphic xlink:href="320309_eqn7.gif"/></alternatives>
</disp-formula>where <italic>PP</italic> is the number of predicted positives, <italic>AP</italic> the actual positives, <italic>PN</italic> the predicted negatives and <italic>AN</italic> the actual negatives. We also calculate the Average Conditional Probability (ACP) measure:<disp-formula id="eqn8">
<alternatives><graphic xlink:href="320309_eqn8.gif"/></alternatives>
</disp-formula>and the Approximate Correlation (AC):<disp-formula id="eqn9">
<alternatives><graphic xlink:href="320309_eqn9.gif"/></alternatives>
</disp-formula></p>
<p>At the exon level, an exon is considered to have been correctly predicted when both boundaries are correctly predicted. If a predicted exon contains at least one actual base, it will be considered a partially correct exon. At the exon level, we show Sp, Sn and the numbers of missed exons (ME), which are exons that are not found by the program, and wrong exons (WE), which are predicted exons that do not correspond to any actual exon. As a representative of our proposed method, we used the model that was obtained when optimizing <italic>G-</italic>mean, as the previous section showed that it achieved the best overall behavior.</p>
<p><xref ref-type="fig" rid="fig29">Fig 29</xref> shows the performances of our proposed method and the standard method for the ten measures that are presented above. <xref ref-type="fig" rid="fig30">Fig 30</xref> shows the relative improvementof our method with respect to the standard approach. Our approach improved the results of the standard method in terms of all measures. At the nucleotide level, CC and AC were improved by over 100&#x0025;. At the exon level, Sn and Sp were improved significantly, while the numbers of ME and WE were also improved, but only marginally. These results show how our approach can be used to improve gene structure prediction.</p>
<fig id="fig29" position="float" orientation="portrait" fig-type="figure">
<label>Figure 29.</label>
<caption><title>Chromosome 21 gene structure prediction.</title>
<p>Chromosome 21 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig29.tif"/>
</fig>
<fig id="fig30" position="float" orientation="portrait" fig-type="figure">
<label>Figure 30.</label>
<caption><title>Chromosome 21 gene structure prediction.</title>
<p>Relative improvement for chromosome 21 results of our method against a state-of-the-art standard method.</p></caption>
<graphic xlink:href="320309_fig30.tif"/>
</fig></sec></sec>
<sec id="s5"><title>Conclusions</title>
<p>In this paper, we presented a floating-search-based strategy for functional site recognition in genomic sequences. The use of floating search enables an efficient search for the best combination of more than a hundred of classification models that are trained on the genomes of many species. The presented approach can also be used for other combination tasks.</p>
<p>The proposed method also enabled the optimization of various performance measures. In the reported experiments, we showed results on searching for the best combination that optimizes three measures: auROC, auPRC and <italic>G-</italic>mean. The method was successfully applied to the recognition of TIS, donor and acceptor sites and stop codons. The reported experiments showed a clear improvement over the current best methods. The reported results also showed that to obtain the best classification rates, many species should be used. Our approach efficiently improved the performance of a very simple program for gene structure prediction.</p></sec>
</body>
<back>
<ack><title>Acknowledgments</title>
<p>This work has been financed in part by Project TIN-2011-22967 of the Spanish Ministry of Science and Innovation and Excellence in Research Projects P09-TIC-4623 and P07-TIC-2682 of the Junta de Andaluc&#x00ED;a.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Hyatt</surname> <given-names>D</given-names></string-name>, <string-name><surname>LoCascio</surname> <given-names>PF</given-names></string-name>, <string-name><surname>Hauser</surname> <given-names>LJ</given-names></string-name>, <string-name><surname>Uberbacher</surname> <given-names>EC</given-names></string-name>. <article-title>Gene and translation initiation site prediction in metagenomic sequences</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>:<fpage>2223</fpage>&#x2013;<lpage>2230</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Zien</surname> <given-names>A</given-names></string-name>, <string-name><surname>R&#x00E4;tsch</surname> <given-names>G</given-names></string-name>, <string-name><surname>Mika</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sch&#x00F6;lkopf</surname> <given-names>B</given-names></string-name>, <string-name><surname>Lengauer</surname> <given-names>T</given-names></string-name>, <string-name><surname>M&#x00FC;ller</surname> <given-names>KR</given-names></string-name>. <article-title>Engineering support vector machines kernels that recognize translation initiation sites</article-title>. <source>Bioinformatics</source>. <year>2000</year>; <volume>16</volume>(<issue>9</issue>):<fpage>799</fpage>&#x2013;<lpage>807</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Gross</surname> <given-names>SS</given-names></string-name>, <string-name><surname>Do</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Sirota</surname> <given-names>M</given-names></string-name>, <string-name><surname>Batzoglou</surname> <given-names>S</given-names></string-name>. <article-title>CONTRAST: a discriminative, phylogeny-free approach to multiple informant de novo gene prediction</article-title>. <source>Genome Biology</source>. <year>2007</year>;<volume>8</volume>(<issue>12</issue>):<fpage>R269.1</fpage>&#x2013;<lpage>R269.16</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Degroeve</surname> <given-names>S</given-names></string-name>, <string-name><surname>Saeys</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Baets</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Rouz&#x00E9;</surname> <given-names>P</given-names></string-name>, <string-name><surname>de Peer</surname> <given-names>YV</given-names></string-name>. <article-title>SpliceMachine: predicting splice sites from high-dimensional local context representations</article-title>. <source>Bioinformatics</source>. <year>2005</year>;<volume>21</volume>(<issue>8</issue>):<fpage>1332</fpage>&#x2013;<lpage>1338</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Baten</surname> <given-names>A</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>B</given-names></string-name>, <string-name><surname>Halgamuge</surname> <given-names>S</given-names></string-name>, <string-name><surname>Li</surname> <given-names>J</given-names></string-name>. <article-title>Splice site identification using probabilistic parameters and SVM classification</article-title>. <source>BMC Bioinformatics</source>. <year>2006</year>;<volume>7</volume>:<fpage>1</fpage>&#x2013;<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Sonnenburg</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schweikert</surname> <given-names>G</given-names></string-name>, <string-name><surname>Philips</surname> <given-names>P</given-names></string-name>, <string-name><surname>Behr</surname> <given-names>J</given-names></string-name>, <string-name><surname>R&#x00E4;tsch</surname> <given-names>G</given-names></string-name>. <article-title>Accurate splice site prediction using support vector machines</article-title>. <source>BMC Bioinformatics</source>. <year>2007</year>;<volume>8</volume>(<issue>Suppl 10</issue>) (S7): <fpage>1</fpage>&#x2013;<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>P&#x00E9;rez-Rodr&#x00ED;guez</surname> <given-names>J</given-names></string-name>, <string-name><surname>Garc&#x00ED;a-Pedrajas</surname> <given-names>N</given-names></string-name>. <article-title>Stepwise approach for combining many sources of evidence for site-recognition in genomic sequences</article-title>. <source>BMC Bioinformatics</source>. <year>2016</year>;<volume>17</volume>:<fpage>117</fpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Pudil</surname> <given-names>P</given-names></string-name>, <string-name><surname>Novovi&#x010D;ov&#x00E1;</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kittler</surname> <given-names>J</given-names></string-name>. <article-title>Floating search methods in feature selection</article-title>. <source>Pattern Recognition Letters</source>. <year>1994</year>;<volume>15</volume>:<fpage>1119</fpage>&#x2013;<lpage>1125</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Pal</surname> <given-names>SK</given-names></string-name>, <string-name><surname>Bandyopadhyay</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ray</surname> <given-names>SS</given-names></string-name>. <article-title>Evolutionary Computation in Bioinformatics: A Review</article-title>. <source>IEEE Transactions on Systems, Man, and Cybernetics&#x2014;Part B: Cybernetics</source>. <year>2006</year>;<volume>36</volume>:<fpage>601</fpage>&#x2013;<lpage>615</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Khare</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rangnekar</surname> <given-names>S</given-names></string-name>. <article-title>A review of particle swarm optimization and its applications in Solar Photovoltaic system</article-title>. <source>Applied Soft Computing</source>. <year>2013</year>;<volume>13</volume>:<fpage>2997</fpage>&#x2013;<lpage>3006</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Cord&#x00F3;n</surname> <given-names>O</given-names></string-name>, <string-name><surname>Herrera</surname> <given-names>F</given-names></string-name>, <string-name><surname>St&#x00FC;tzle</surname> <given-names>T</given-names></string-name>. <article-title>A review of the ant colony optimization metaheuristic: Basis, models and new trends</article-title>. <source>Mathware &#x0026; Soft Computing</source>. <year>2002</year>;<volume>9</volume>:<fpage>141</fpage>&#x2013;<lpage>175</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Das</surname> <given-names>S</given-names></string-name>, <string-name><surname>Suganthan</surname> <given-names>PN</given-names></string-name>. <article-title>Differential Evolution: A Survey of the State-of-the-Art</article-title>. <source>IEEE Transactions on Evolutionary Computation</source>. <year>2011</year>;<volume>15</volume>:<fpage>4</fpage>&#x2013;<lpage>31</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Somol</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pudil</surname> <given-names>P</given-names></string-name>, <string-name><surname>Novocicova</surname> <given-names>J</given-names></string-name>, <string-name><surname>Paclik</surname> <given-names>P</given-names></string-name>. <article-title>Adaptive floating search methods in feature selection</article-title>. <source>Pattern Recognition Letters</source>. <year>1999</year>;<volume>20</volume>:<fpage>1157</fpage>&#x2013;<lpage>1163</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="book"><string-name><surname>Devakumari</surname> <given-names>D</given-names></string-name>, <string-name><surname>Thangavel</surname> <given-names>K</given-names></string-name>. <chapter-title>Analysis of Adaptive Floating Search Feature Selection Algorithm</chapter-title>. In: <source>Computer Networks and Information Technologies</source>. vol. <volume>142</volume> of Communications in Computer and Information Science. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2011</year>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Shirbani</surname> <given-names>F</given-names></string-name>, <string-name><surname>Zadeh</surname> <given-names>HS</given-names></string-name>. <article-title>Fass SFFS-Based Algorithm for Feature Selection in Biomedical Datasets</article-title>. <source>Amirkabir International Journal of Electrical and Electronics Engineering</source>. <year>2013</year>;<volume>45</volume>:<fpage>43</fpage>&#x2013;<lpage>56</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Homsapaya</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sornil</surname> <given-names>O</given-names></string-name>. <article-title>Improving Floating Search Feature Selection using Genetic Algorithm</article-title>. <source>Journal of ICT Research and Applications</source>. <year>2017</year>;<volume>11</volume>:<fpage>299</fpage>&#x2013;<lpage>317</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Whitney</surname> <given-names>AW</given-names></string-name>. <article-title>A direct method of nonparametric measurement selection</article-title>. <source>IEEE Transactions on Computing</source>. <year>1971</year>;<volume>20</volume>:<fpage>1100</fpage>&#x2013;<lpage>1103</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Marill</surname> <given-names>T</given-names></string-name>. <article-title>On the effectiveness of receptors in recognition system</article-title>. <source>IEEE Transactions on Information Theory</source>. <year>1963</year>;<volume>9</volume>:<fpage>917</fpage>&#x2013;<lpage>922</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Jain</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zongker</surname> <given-names>D</given-names></string-name>. <article-title>Feature selection: Evaluation, application, and small sample performance</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>1997</year>;<volume>19</volume>:<fpage>153</fpage>&#x2013;<lpage>158</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="other"><string-name><surname>Stearns</surname> <given-names>SD</given-names></string-name>. <article-title>On selecting features for pattern classifiers</article-title>. In: <source>Proceedings of the 3rd International Conference on Pattern Recognition</source>; <year>1976</year>. p. <fpage>71</fpage>&#x2013;<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Kudo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sklansky</surname> <given-names>J</given-names></string-name>. <article-title>Comparison of algorithms that select features for pattern classifiers</article-title>. <source>Pattern Recognition</source>. <year>2000</year>;<volume>33</volume>:<fpage>25</fpage>&#x2013;<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Tulyakov</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jaeger</surname> <given-names>S</given-names></string-name>, <string-name><surname>Govindaraju</surname> <given-names>V</given-names></string-name>, <string-name><surname>Doermann</surname> <given-names>D</given-names></string-name>. <article-title>Review of classifier combination methods</article-title>. <source>Studies in Computational Intelligence</source>. <year>2008</year>;<volume>90</volume>:<fpage>361</fpage>&#x2013;<lpage>386</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Kuncheva</surname> <given-names>L</given-names></string-name>. <article-title>A theoretical study of six classifier fusion strategies</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>2002</year>;<volume>24</volume>(<issue>2</issue>):<fpage>281</fpage>&#x2013;<lpage>286</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Woods</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kegelmeyer</surname> <given-names>W</given-names></string-name>, <string-name><surname>Bowyer</surname> <given-names>K</given-names></string-name>. <article-title>Combination of multiple classifiers using local accuracy estimates</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>1997</year>;<volume>19</volume>:<fpage>405</fpage>&#x2013;<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Merz</surname> <given-names>CJ</given-names></string-name>. <article-title>Using Correspondence Analysis to Combine Classifiers</article-title>. <source>Machine Learning</source>. <year>1999</year>;<volume>36</volume>(<issue>1</issue>):<fpage>33</fpage>&#x2013;<lpage>58</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="book"><string-name><surname>Kuncheva</surname> <given-names>LI</given-names></string-name>. <chapter-title>Combining classifiers: Soft computing solutions</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Pal</surname> <given-names>SK</given-names></string-name>, <string-name><surname>Pal</surname> <given-names>A</given-names></string-name></person-group>, editors. <source>Pattern Recognition: From Classical to Modern Approaches</source>. <publisher-loc>Singapore</publisher-loc>: <publisher-name>World Scientific</publisher-name>; <year>2001</year>. p. <fpage>427</fpage>&#x2013;<lpage>451</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Rodr&#x00ED;guez</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Maudes</surname> <given-names>J</given-names></string-name>. <article-title>Boosting Recombined Weak Classifiers</article-title>. <source>Pattern Recognition Letters</source>. <year>2008</year>;<volume>29</volume>:<fpage>1049</fpage>&#x2013;<lpage>1059</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Saeys</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Abeel</surname> <given-names>T</given-names></string-name>, <string-name><surname>Degroeve</surname> <given-names>S</given-names></string-name>, <string-name><surname>de Peer</surname> <given-names>YV</given-names></string-name>. <article-title>Translation initiation site prediction on a genomic scale: beauty in simplicity</article-title>. <source>Bioinformatics</source>. <year>2007</year>;<volume>23</volume>:<fpage>418</fpage>&#x2013;<lpage>423</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Zeng</surname> <given-names>F</given-names></string-name>, <string-name><surname>Yap</surname> <given-names>RHC</given-names></string-name>. <article-title>Using Feature Generation and Feature Selection for Accurate Prediction of Translation Initiation Sites</article-title>. <source>Genome Bioinformatics</source>. <year>2002</year>;<volume>13</volume>:<fpage>192</fpage>&#x2013;<lpage>200</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ji</surname> <given-names>Q</given-names></string-name>. <article-title>Recognizing translation initiation sites of eukaryotic genes based on the cooperatively scanning model</article-title>. <source>Bioinformatics</source>. <year>2003</year>;<volume>19</volume>:<fpage>1972</fpage>&#x2013;<lpage>1977</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Garc&#x00ED;a-Pedrajas</surname> <given-names>N</given-names></string-name>, <string-name><surname>P&#x00E9;rez-Rodr&#x00ED;guez</surname> <given-names>J</given-names></string-name>, <string-name><surname>Garc&#x00ED;a-Pedrajas</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Ortiz-Boyer</surname> <given-names>D</given-names></string-name>, <string-name><surname>Fyfe</surname> <given-names>C</given-names></string-name>. <article-title>Class imbalance methods for translation initiation site recognition in DNA sequences</article-title>. <source>Knowledge-Based Systems</source>. <year>2012</year>;<volume>25</volume>(<issue>1</issue>):<fpage>22</fpage>&#x2013;<lpage>34</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Salzberg</surname> <given-names>SL</given-names></string-name>. <article-title>A method for identifying splice sites and translational start sites in eukaryotic mRNA</article-title>. <source>Computational Applied Bioscience</source>. <year>1997</year>;<volume>13</volume>:<fpage>365</fpage>&#x2013;<lpage>376</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>R&#x00E4;tsch</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sonnenburg</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sch&#x00F6;lkopf</surname> <given-names>B</given-names></string-name>. <article-title>RASE: Recognition of Alternative Spliced Exons in <italic>C. elegans</italic></article-title>. <source>Bioinformatics</source>. <year>2005</year>;<volume>21</volume>(<issue>Suppl 1</issue>):<fpage>i369</fpage>&#x2013;<lpage>i377</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Melvin</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ie</surname> <given-names>E</given-names></string-name>, <string-name><surname>Weston</surname> <given-names>J</given-names></string-name>, <string-name><surname>Noble</surname> <given-names>WS</given-names></string-name>, <string-name><surname>Leslie</surname> <given-names>C</given-names></string-name>. <article-title>Multi-class protein classification using adaptive codes</article-title>. <source>Journal of Machine Learning Research</source>. <year>2007</year>;<volume>8</volume>:<fpage>1557</fpage>&#x2013;<lpage>1581</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Hulse</surname> <given-names>JV</given-names></string-name>, <string-name><surname>Khoshgoftaar</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Napolitano</surname> <given-names>A</given-names></string-name>. <article-title>An empirical evaluation of repetitive undersampling techniques</article-title>. <source>International Journal of Software Engineering and Knowledge Engineering</source>. <year>2010</year>;<volume>20</volume>(<issue>2</issue>):<fpage>173</fpage>&#x2013;<lpage>195</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Kuncheva</surname> <given-names>L</given-names></string-name>, <string-name><surname>Whitaker</surname> <given-names>CJ</given-names></string-name>. <article-title>Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy</article-title>. <source>Machine Learning</source>. <year>2003</year>;<volume>51</volume>(<issue>2</issue>):<fpage>181</fpage>&#x2013;<lpage>207</lpage>.</mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn1"><label>1</label><p>In our experiment, this subset was obtained selecting each classifier with a probability of 0.5.</p></fn>
<fn id="fn2"><label>2</label><p>We always tested all the methods with all the negative samples, which means that the ratio of the minority/majority class was more than 1:3200 for the worst case, namely, stop codon recognition for chromosome 13 (see <xref ref-type="table" rid="tbl1">Table 1</xref>), which yielded low auPRC values. We must take into account that with only a few thousand FPs among several million TNs, we obtain a very low precision value. The situation for stop codon recognition is even worse, as the number of TNs is multiplied by three.</p></fn>
</fn-group>
</back>
</article>