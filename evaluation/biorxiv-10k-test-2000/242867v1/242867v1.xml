<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/242867</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Efficient neural decoding of spatial location with a deep recurrent network</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Tampuu</surname>
<given-names>Ardi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Matiisen</surname>
<given-names>Tambet</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>&#x00D3;lafsd&#x00F3;ttir</surname>
<given-names>H. Freyja</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Barry</surname>
<given-names>Caswell</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n2">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Vicente</surname>
<given-names>Raul</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Computational Neuroscience Lab, Institute of Computer Science, University of Tartu</institution>, Tartu, <country>Estonia</country></aff>
<aff id="a2"><label>2</label><institution>Department of Cell and Developmental Biology, University College London</institution>, London, <country>United Kingdom</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>&#x002A;</label><p><email>raul.vicente.zafra@ut.ee</email></p></fn>
<fn id="n2"><label>&#x002A;</label><p><email>caswell.barry@ucl.ac.uk</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>242867</elocation-id>
<history>
<date date-type="received">
<day>04</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>04</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>04</day>
<month>1</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="242867.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Place cells in the mammalian hippocampus signal self-location with sparse spatially stable firing fields. Based on observation of place cell activity it is possible to accurately decode an animal&#x2019;s location. The precision of this decoding sets a lower bound for the amount of information that the hippocampal population conveys about the location of the animal. In this work we use a novel recurrent neural network (RNN) decoder to infer the location of freely moving rats from single unit hippocampal recordings. RNNs are biologically plausible models of neural circuits that learn to incorporate relevant temporal context without the need to make complicated assumptions about the use of prior information to predict the current state. When decoding animal position from spike counts in 1D and 2D-environments, we show that the RNN consistently outperforms a standard Bayesian model with flat priors. In addition, we also conducted a set of sensitivity analysis on the RNN decoder to determine which neurons and sections of firing fields were the most influential. We found that the application of RNNs to neural data allowed flexible integration of temporal context, yielding improved accuracy relative to a commonly used Bayesian approach and opens new avenues for exploration of the neural code.</p>
<sec>
<title>Author summary</title>
<p>Being able to accurately self-localize is critical for most motile organisms. In mammals, place cells in the hippocampus appear to be a central component of the brain network responsible for this ability. In this work we recorded the activity of a population of hippocampal neurons from freely moving rodents and carried out neural decoding to determine the animals&#x2019; locations. We found that a machine learning approach using <italic>recurrent neural networks</italic> (RNNs) allowed us to predict the rodents&#x2019; true positions more accurately than a standard Bayesian method with flat priors. The RNNs are able to take into account past neural activity without making assumptions about the statistics of neuronal firing. Further, by analyzing the representations learned by the network we were able to determine which neurons, and which aspects of their activity, contributed most strongly to the accurate decoding.</p>
</sec>
</abstract>
<counts>
<page-count count="20"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Place cells, pyramidal neurons found in CA1 and CA3 of the mammalian hippocampus [<xref ref-type="bibr" rid="c1">1</xref>&#x2013;<xref ref-type="bibr" rid="c4">4</xref>], exhibit spatially constrained receptive fields, referred to as place fields. In general, the activity of place cells is considered to be stable [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>]; place fields are typically robust to the removal of specific environmental cues [<xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c8">8</xref>], persist between visits to a location [<xref ref-type="bibr" rid="c9">9</xref>], and in the open field do not strongly depend upon an animal&#x2019;s behaviour [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c5">5</xref>]. Upon exposure to a novel enclosure the firing correlates of place cells rapidly &#x2018;remap&#x2019;; place fields change their firing rate and relative position, forming a distinct representation for the new space [<xref ref-type="bibr" rid="c10">10</xref>&#x2013;<xref ref-type="bibr" rid="c12">12</xref>]. For these reasons place cells are widely held to provide the neural basis of self-location, signalling the position of an animal relative to its environment and thus being a necessary element for the control of spatial behaviours, such as navigation, and the retention of spatial memories [<xref ref-type="bibr" rid="c2">2</xref>]. Unsurprisingly then, given information about the activity of a population of place cells, it is possible to decode the location of an animal with a relatively high degree of accuracy [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>].</p>
<p>However, although place cell activity is strongly modulated by self-location this relationship is non-trivial and not exclusive. For example, during rest and brief pauses, but also during motion, the place code can decouple from an animal&#x2019;s current location and recapitulate trajectories through the enclosure [<xref ref-type="bibr" rid="c15">15</xref>]; &#x2018;replaying&#x2019; previous experience [<xref ref-type="bibr" rid="c16">16</xref>] or, perhaps, foreshadowing future actions [<xref ref-type="bibr" rid="c17">17</xref>]. Similarly, when animals run on linear runways or perform constrained navigational tasks, such as T-maze alternation, place cell activity becomes strongly modulated by behaviour, disambiguating direction of travel [<xref ref-type="bibr" rid="c18">18</xref>], prospective and retrospective trajectories [<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref>], and the degree of engagement with a task [<xref ref-type="bibr" rid="c21">21</xref>]. Furthermore, although place fields are repeatable they are not static. Even though remapping occurs rapidly in a novel environment, the newly formed firing fields continue to be refined during subsequent experience, a process that appears to persist for several hours [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>]. Even in familiar environments, that animals have visited many times, the spatial activity of place cells is known to exhibit incremental changes that can result in the generation of distinct spatial codes [<xref ref-type="bibr" rid="c23">23</xref>&#x2013;<xref ref-type="bibr" rid="c26">26</xref>], which might be important for encoding goal locations [<xref ref-type="bibr" rid="c27">27</xref>] or other non-spatial variables [<xref ref-type="bibr" rid="c28">28</xref>]. As such, although hippocampal activity provides considerable information about an animal&#x2019;s self-location the representation is dynamic: accumulating changes and sometimes encoding other variables both spatial and non-spatial.</p>
<p>A common approach used to interrogate neural representations, such as that of place cells, is decoding; the accuracy with which a variable, such as self-location, can be decoded from the brain, places a useful lower limit on the amount of information present [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>]. In the case of place cells, decoding methodologies typically apply a Bayesian framework to calculate a probability distribution over the the animal&#x2019;s position, given the observed neural data [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c16">16</xref>]. Decoding to a specific location is then accomplished via a maximum likelihood estimator applied to the probability distribution. However, the accuracy of Bayesian methods depends on accurate information about the expected activity of neurons. For place cells, activity recorded over the course of tens of minutes is typically used to estimate the firing rate of each cell at different points in the animal&#x2019;s enclosure, with instantaneous rates assumed to exhibit Poisson dynamics. However, for the reasons outlined above, it is not clear that hippocampal activity can be modelled in this way. Indeed, the variability of place cell firing rates is known to greatly exceed that expected from a Poisson process [<xref ref-type="bibr" rid="c29">29</xref>]. As such, it is likely that Bayesian methods, as currently applied, do not provide an accurate reflection of the accuracy with which the hippocampus encodes self-location.</p>
<p>To better understand these constraints, we trained a deep recurrent neural network (RNN) [<xref ref-type="bibr" rid="c30">30</xref>&#x2013;<xref ref-type="bibr" rid="c32">32</xref>] to decode rodent location from the firing rate of CA1 neurons. At each time step the network was presented with a vector corresponding to the spike counts of hippocampal cells within a given time window. After accumulating information for 100 time-steps the network was required to predict the animal&#x2019;s location &#x2013; supervision being provided in the form of the animal&#x2019;s true location. We found that decoding with the trained RNN was consistently more accurate than a standard Bayesian approach [<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c16">16</xref>]. This demonstrates that RNNs are able to capture the relationship between a temporal sequence of neural activity and an encoded variable without the necessity of explicit assumptions about the underlying noise model or complicated hand-coded priors. Further, inspection of the trained network allowed us to identify both the relative importance of individual neurons for accurate decoding and the locations at which they were most informative. Thus, not only does the accuracy of the RNN set a new limit for the amount of information about self-location encoded by place cells but more generally this work suggests that RNNs provide a useful approach for neural decoding and provide a means to explore the neural code.</p></sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>High accuracy decoding of self-location in 2D environments</title>
<p>To test the RNN&#x2019;s ability to decode rodent location based on hippocampal activity we first characterized the decoding error for a single animal foraging in a 2D arena (1m x 1m square). Single unit recordings were made using tetrodes from region CA1 of five rats. Rat R2192 yielded the greatest number of simultaneously recorded hippocampal neurons (n&#x003D;63). Since the number of recorded neurons is expected to correlate with decoding accuracy, we first focused on this particular animal.</p>
<p>Neural data was processed to extract action potentials and these were assigned to individual neurons using the amplitude difference between tetrode channels [<xref ref-type="bibr" rid="c33">33</xref>] (see Methods). The input features for the RNN-decoder then consisted of spike counts for each neuron within a set of time windows. The length of time windows was parametrically varied between 200 ms and 4000 ms in 200 ms increments. Each consecutive window started 200 ms later than previous one (this means 0&#x0025; overlap for 200 ms windows, 50&#x0025; overlap for 400 ms windows, 80&#x0025; overlap for 1000 ms windows, etc. See &#x201D;Feature extraction&#x201D; in Methods). The network was presented with spike counts from 100 windows before being asked to predict the animal&#x2019;s location at the center of the latest window.</p>
<p>As the RNN training process is stochastic, 10-fold cross validation (CV) procedure was run multiple times for each window size. For each of these runs we trained 10 models (for each fold of CV) and extracted the mean and median results across the folds. Black dots on <xref ref-type="fig" rid="fig1">Fig 1</xref> correspond to these different realizations of the 10-fold CV procedure (notice multiple dots per window size). 10-fold cross validation was also applied to the Bayesian decoder.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1.</label>
<caption>
<title>Accurate decoding of position with a RNN.</title>
<p>Location decoding errors based on CA1 neural data recorded from 1m square open field environment as a function of time window size (mean error in left panel, median error in right panel). Blue lines represent errors from the RNN decoder and red lines from a Bayesian approach. Results for the RNN approach are averaged over different independent realizations of the training algorithm. Black dots depict the mean/median error of each individual model. Results shown are for animal R2192.</p></caption>
<graphic xlink:href="242867_fig1.tif"/>
</fig>
<p>For both the mean (<xref ref-type="fig" rid="fig1">Fig 1a</xref>) and median (<xref ref-type="fig" rid="fig1">Fig 1b</xref>) of the validation errors, the error curve was convex with lowest errors obtained at intermediate values. Best median decoding accuracy was achieved with time window of 1200 ms (median error &#x003D; 10.18 &#x00B1; 0.23 cm). Best mean decoding was achieved for a timewindow of 1400 ms (mean error &#x003D; 12.50 &#x00B1; 0.39) cm). Using longer or shorter time windows lead to higher errors &#x2013; likely because spike counts from shorter windows are increasingly noisy, while the animal&#x2019;s CA1 activity is less specific to a particular location for longer windows. For all time windows, the accuracy of the RNN considerably exceeded that of the Bayesian decoder (red line). The lowest median decoding error with Bayesian decoder was 12.16 cm (19.5&#x0025; higher than for the RNN; this best accuracy could be obtained with multiple different window sizes for Bayesian), lowest mean error was 15.83 cm with 2800 ms windows.</p>
<p>The RNN has the ability to flexibly use information from all 100 input vectors and thus integrates contextual information over time. This results in lower mean and median errors as compared to a baseline Bayesian approach that does not have access to information about past activity. In particular, that RNN approach achieves its best results for shorter time windows than the Bayesian approach. We hypothesize that having access to contextual information helps to overcome the stochastic noise in the spike counting obtained for shorter time windows.</p>
<p>Beyond the global descriptors of mean and median error, we also inspected the distribution of decoding error sizes (<xref ref-type="fig" rid="fig2">Fig 2a</xref>). For the RNN the distribution followed a unimodal curve with most predictions deviating from the rat&#x2019;s true position by 6&#x2013;8 cm. Few errors were larger than 35 cm (1.7 &#x0025; of errors &#x003E; 35 cm). The simple Bayesian classifier achieves more very low (&#x003C; 2 cm) errors, but also an abundance of very large (&#x003E; 50 cm) errors (7.9 &#x0025; of errors &#x003E; 35 cm, 2.8 &#x0025; &#x003E; 50 cm).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2.</label>
<caption>
<title>Comparison of RNN and Bayesian decoders</title>
<p>(a) Histogram of error sizes, generated in each case with the best performing time window (1400 ms for RNN, 2800 ms for Bayesian). The Bayesian decoder makes more very large errors (0.02&#x0025; vs 2.8&#x0025; of errros &#x003E; 50 cm). Errors are grouped into 2 cm bins, the last bin shows all errors above 50 cm. (b) Downsampling analysis demonstrates the RNN decoder is more robust to small dataset sized. Data from R2192 was downsampled such that both decoders were trained with a random subset of the available neurons. For each sample size, 10 random sets of neurons were selected and independent models trained as before using 10-fold cross validation. Dots represents median error for each downsampled dataset. Lines indicate the mean over sets of the same size.</p></caption>
<graphic xlink:href="242867_fig2.tif"/>
</fig>
<p>In many cases single unit recordings yield fewer than the 63 neurons identified from R2192. We hypothesised that the RNN&#x2019;s ability to use contextual information would be increasingly important in scenarios where neural data was more scarce. To test this prediction we randomly downsampled the dataset available from R2192, repeating the training and decoding procedure for populations of neurons varying in size from 5 to 55 in increments of 5. As expected we saw that decoding accuracy reduced as the size of the dataset reduced. However the RNN was considerably more robust to small sample sizes, decoding with an error of 30.9 cm with only 5 neurons vs. 46.0 cm error for the Bayesian decoder (<xref ref-type="fig" rid="fig2">Fig 2b</xref>).</p></sec>
<sec id="s2b">
<title>Population-level results in 2D and 1D environments</title>
<p>In total we analyzed recordings gathered during 2D open field free foraging task from five animals (1m x 1m square). For each of these 5 datasets, we determined the best performing time window size for the RNN and Bayesian decoder (similarly to <xref ref-type="fig" rid="fig1">Fig 1</xref>). The optimal time window sizes for the five 2D foraging datasets are given in <xref ref-type="table" rid="tbl1">Table 1</xref> along with the length of the recording and the number of identified neurons.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption>
<title>Datasets for 2D and 1D decoding tasks.</title>
<p>Number of data points, number of recorded neurons, and the optimal time window for the RNN decoder for each of the 5 analyzed animals and for both decoding tasks.</p></caption>
<graphic xlink:href="242867_tbl1.tif"/>
</table-wrap>
<p>In the 2D decoding task, for different animals, the mean error across cross validation folds ranges between 12.5-16.3 cm and median between 10.3-13.1 cm (<xref ref-type="fig" rid="fig3">Fig 3a-b</xref>). Interestingly, despite some recordings yielding as few as 26 or 33 cells, the decoding accuracy using RNNs is roughly similar. In all cases the mean and median decoding results from the 2-layer LSTM RNN outperformed the standard Bayesian approach.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig 3.</label>
<caption>
<title>Spatial decoding across animals in 2D and 1D environments.</title>
<p>(a-b) Decoding results in a 1m square environment. RNN consistently outperforms the standard Bayesian approach in all 5 data sets. Mean and median errors across cross validation folds, respectively. (c-d) Decoding errors from a 600 cm long Z-shaped track. RNN consistently yields lower decoding errors than a Bayesian approach, the difference is more marked when mean (c) as oppose to median (d) errors are considered.</p></caption>
<graphic xlink:href="242867_fig3.tif"/>
</fig>
<p>We also performed decoding on 1D datasets recorded while the same 5 animals shuttled back and forwards on a 600 cm long Z-shaped track for reward placed at the corners and ends (<xref ref-type="table" rid="tbl1">Table 1</xref>) [<xref ref-type="bibr" rid="c34">34</xref>]. As before we applied RNN and Bayesian decoders to 10-fold cross validated data, selecting in each case the optimal time window size (<xref ref-type="table" rid="tbl1">Table 1</xref>). The RNN decoder greatly outperformed the baseline Bayesian decoder in all 5 data sets when comparing mean errors (<xref ref-type="fig" rid="fig3">Fig 3c</xref>). However, notice that the Bayesian decoder is a classifier &#x2014; it is penalized as much for small mistakes as it is for large ones, making it by design more prone to very large mistakes. In the 2D task the largest possible error was 141.7 cm (if the predicted location is in the corner diagonally opposite to the true location), whereas in 1D task it is 600cm (if the opposite end of the track is predicted). In the 1D task a small number of extremely large errors will inflate the mean error, whereas the median will be less affected (<xref ref-type="fig" rid="fig3">Fig 3c-d</xref>). Examining the median errors we found that RNN outperformed the Bayesian decoder in all cases. However for four of the five animals the difference in error was relatively small (<xref ref-type="fig" rid="fig3">Fig 3d</xref>). For the fifth rat with the fewest cells (R2117, n&#x003D;40), the RNN clearly outperformed the Bayesian approach, having a median decoding error that was almost half that of the Bayesian decoder.</p></sec>
<sec id="s2c">
<title>Analysis of results obtained with RNN-decoder</title>
<p>Next to understand how behavioural and neural variability influenced decoding accuracy we focused on the results obtained from rat R2192 in the 1m square &#x2014; the animal with the greatest number of neurons and the lowest decoding error).</p>
<p>First we examined the decoding error as a function of the rat&#x2019;s location. It is important to note that the animals&#x2019; behaviour is non-uniform &#x2014; the rats visits some parts of the arena more often than others (see <xref ref-type="fig" rid="fig4">Fig 4a</xref>). Since more training data is available for frequently visited regions it is expected that any decoding approach would be most accurate in those locations. The spatial distribution of decoding error for R2192 seems to confirm this conjecture &#x2014; well sampled bins in the center of the enclosure and portions of its borders are more accurately decoded (<xref ref-type="fig" rid="fig4">Fig 4b</xref>). To confirm this, we calculated the correlation between the decoding error and the number of training data points located within 10 cm radius of the predicted data point, finding a significant negative correlation (Spearman&#x2019;s Rank Order, <italic>r</italic> &#x003D; &#x2212;0.16, <italic>p<sub>val</sub></italic> &#x003C;&#x003C; 0.001, <italic>dof</italic> &#x003D; 4412).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig 4.</label>
<caption>
<title>Analysis of the errors in function of location and neural activity for rat R2192.</title>
<p>(a) The trajectory of the rat during the entire trial. Not all parts of the arena are visited with equal frequently. (b) The average size of errors made in different regions of space. Color of each hexagon depicts the average euclidean error of data points falling into the hexagon. More frequently visited areas (as seen from (a)) tend to have lower mean error. (c) Sum neural activity in different regions of space. For each data point we sum the spike counts of all 63 neurons in a 1400 ms period centered around the moment the location was recorded. The color of the hexagon corresponds to the average over all data points falling into the hexagon. Areas where sum neural activity is high have lower prediction error. (d) Prediction error of a coordinate decreases if the animal is closer to the wall perpendicular to that coordinate.</p></caption>
<graphic xlink:href="242867_fig4.tif"/>
</fig>
<p>Another important factor influencing the decoding accuracy is the distribution of neural activity across the 2D enclosure. In particular, place fields of the recorded hippocampal cells do not cover the enclosure uniformly. Clearly it would be difficult for the algorithm to differentiate between locations where no cell is active. As such, it is likely that areas where more neurons are activated are decoded with higher precision. Our results confirm that the sum of spike counts across neurons at a given location is strongly anti-correlated with the prediction error made at that location (<xref ref-type="fig" rid="fig4">Fig 4c</xref>, Spearman&#x2019;s Rank Order, <italic>r</italic> &#x003D; &#x2212;0.31, <italic>p<sub>val</sub></italic> &#x003C;&#x003C; 0.001, <italic>dof</italic> &#x003D; 4412).</p>
<p>We also inspected the <italic>x</italic> and <italic>y</italic> components of the decoding error separately. Previous work suggests that, in the case of grid cells, contact with an environmental boundary results in a reduction of error in the representation of self-location perpendicular to that wall [<xref ref-type="bibr" rid="c35">35</xref>]. Such a relationship would be expected if boundaries function as an elongated spatial cue, used by animals to update their representation of self-location relative to it&#x2019;s surface. Accordingly, we found that for RNN decoding based on CA1 neurons, the decoding accuracy orthogonal to environmental boundaries increased with proximity to that boundary (<xref ref-type="fig" rid="fig4">Fig 4d</xref>, Spearman&#x2019;s Rank Order between error and distance to wall in the region up to 25cm from the wall, <italic>r</italic> &#x003D; 0.31, <italic>p</italic> &#x003C;&#x003C; 0.001, <italic>dof</italic> &#x003D; 3968. The result also held for <italic>x</italic> (<italic>r</italic> &#x003D; 0.35, <italic>p</italic> &#x003C;&#x003C; 0.001, <italic>dof</italic> &#x003D; 2101) and <italic>y</italic> (<italic>r</italic> &#x003D; 0.25, <italic>p</italic> &#x003C;&#x003C; 0.001<italic>, dof</italic> &#x003D; 1855) coordinates separately. Conversely, decoding error parallel to the boundary was not modulated by proximity.</p>
<p>Furthermore, an additional factor that seemed to influence prediction accuracy was the animal&#x2019;s motion speed. Predictions were more reliable when the rat was moving as opposed to stationary. The mean prediction error for speeds below 0.5 cm/s being 16.5 cm, higher than the 12.1 cm average error for all speeds above 0.5 cm/s (two-sided Welch&#x2019;s t-test, <italic>t</italic> &#x003D; 10.62, <italic>p</italic> &#x003C;&#x003C; 0.001, median errors 8.68 cm and 7.74 cm accordingly). It seems plausible that the lower prediction accuracy during stationary periods might be due to place cells preferentially replaying non-local trajectories during these periods [<xref ref-type="bibr" rid="c36">36</xref>]. A second interesting observation is that the prediction error does not increase at higher speeds (two-sided Welch&#x2019;s t-test between errors in data points where speed is in range from 0.5 cm/s to 10.5cm/s and errors in data points with speed above 10.5cm/s, <italic>t</italic> &#x003D; 0.31, <italic>p</italic> &#x003D; 0.76)</p></sec>
<sec id="s2d">
<title>Sensitivity analysis</title>
<p>The accuracy of any neural decoder represents a useful lower bound on the information about the decoded state contained by the recorded neurons. Thus, a biologically relevant question is how such information is distributed among the neurons, across space and time. In short we asked which features of the neuronal activity are the most informative at predicting the animal&#x2019;s position. To this end we conducted two different types of sensitivity analyses to measure robustness to different types of perturbations.</p></sec>
<sec id="s2e">
<title>Knockout approach</title>
<p>A simple way to estimate the relevance of a specific input in a predictive model is to remove it (to <italic>knock out</italic>) and observe how the prediction accuracy changes. If the input is removed before training, the model can learn to compensate for the missing information &#x2014; knockout with retraining. However, if the input is removed after training &#x2014; knockout without retraining &#x2014; the model cannot adapt or compensate.</p>
<p>Here we used knockout without retraining. The RNN was applied, as before, to predict locations based on a validation dataset in which the activity of a single neuron was set to zero. The knock-out procedure was repeated for each input neuron separately and mean prediction error calculated. Thus we were able to rank neurons by sensitivity - the greater the error increase due to the knocking-out the more crucial the neuron was for the model.</p>
<p>The most influential neuron (neuron &#x0023;55) was visually identified as an inhibitory neuron based on the lack of clear firing fields and high firing rate 5. In someways it is surprising that this neuron was identified as having the greatest influence on the model &#x2014; prior work suggests that inhibitory cells do not provide much information about self-location. However, the model&#x2019;s sensitivity to this neuron is likely due to its high firing rate. Neuron &#x0023;55 had a firing rate 4 times higher than any other neuron, meaning its removal eliminates the largest number of spikes from the analysis. The other 4 most influential neurons appear to typical pyramidal place cells characterized by clear place fields [<xref ref-type="bibr" rid="c2">2</xref>]. The knocking out of these top neurons induced a sizable decrease (&#x003E; 1<italic>cm</italic>) in the prediction accuracy.</p>
<p>For more than half of the neurons knocking them out decreased the prediction accuracy only very slightly (less than the standard deviation of accuracy, calculated over 10 realizations of the complete model). Among those less influential neurons we found both putative inhibitory interneurons and pyramidal cells with no clear place fields and a lower than average firing rate. For example, the rate map of the least influential neuron, was characterized by a low firing rate &#x0023;9 (<xref ref-type="fig" rid="fig5">Fig 5f</xref>). As suggested by the most and least influential neurons, importance according to knock-out analysis correlated strongly with firing rate (Spearman&#x2019;s Rank Order, <italic>r</italic> &#x003D; 0.50, <italic>p<sub>val</sub></italic> &#x003C; 0.001, <italic>dof</italic> &#x003D; 61).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig 5.</label>
<caption>
<title>Results of knockout analysis.</title>
<p>The firing rate maps of the most (a-e) and least (f) influential neurons according to the knockout analysis. Colour bar to the right of each plot indicates the firing rate in Hz. With the complete dataset the mean error was 12.50 &#x00B1; 0.28 cm. When knocking out neurons 55, 26, 41, 17, 23 (the five most influential) and 9 (the least influential), the mean error increased to 14.72 cm, 13.80 cm, 13.66 cm, 13.50 cm, 13.49 cm and 12.58 cm respectively.</p></caption>
<graphic xlink:href="242867_fig5.tif"/>
</fig></sec>
<sec id="s2f">
<title>Gradients with respect to input</title>
<p>A different way to investigate which neurons most strongly influence decoding accuracy is a gradient analysis. In this analysis we calculate the derivatives of the loss function (mean squared prediction error) of the RNN with respect to the inputs (spike counts of neurons) at different time points. By definition these derivatives show how much a small change in a spike count influences the error. This type of sensitivity analysis is quite different from the knock out analysis &#x2014; knockout sensitivity measures the impact of silencing a neuron, gradient sensitivity measures the impact of a neurons activity deviating from the expected value.</p>
<p>For each predicted location we asked how sensitive the model was to each of the input spike counts. Since our RNN input is a set of 100 spike count vectors (length of time series), each of length 63 (number of neurons), this amounts to 63&#x00D7;100 gradients per sample. Considering that the whole data set contains around 4400 samples we obtain a 4400&#x00D7;63&#x00D7;100 cubic array of gradient values. To reveal different aspects of the sensitivity of the model, we can average this array of gradients across three dimensions &#x2014; samples, neurons, or position in the input sequence.</p>
<p>Averaging gradients across all samples and all time windows provided one average gradient value per neuron. Similarly to the knock-out analysis this indicated how relevant the neuron is for the prediction. The two sensitivity measures (knock-out and gradient) were strongly correlated (Spearman&#x2019;s Rank Order, <italic>&#x03C1;</italic> &#x003D; 0.57, <italic>p</italic> &#x003C;&#x003C; 0.001, <italic>dof</italic> &#x003D; 61), but not equivalent. The tests ranked some neurons very differently. For example, the high-firing inhibitory neuron &#x0023;55 which influences the accuracy most strongly according to knock-out analysis is ranked 47th out of 63 neurons by the gradient sensitivity analysis. Thus illustrating, that despite that fact both measures broadly concur, the gradient and knockout analyses capture different notions of robustness with respect to input perturbations. Interestingly, neither of the two sensitivity measures correlated with the spatial information theoretic measure proposed by Skaggs et al. [<xref ref-type="bibr" rid="c37">37</xref>] (Spearman&#x2019;s Rank Order, gradient-vs-Skaggs: <italic>&#x03C1;</italic> &#x003D; &#x2212;0.22<italic>, pval</italic> &#x003D;0.08<italic>, dof</italic> &#x003D; 61; knock-vs-Skaggs: <italic>&#x03C1;</italic> &#x003D; &#x2212;0.09, <italic>p</italic> &#x003D;0.48<italic>, dof</italic> &#x003D; 61) &#x2014; likely suggesting that the Skaggs Information Score is not a reliable indication of a neuron&#x2019;s influence when considered in the context of a population of place cells.</p>
<p>In a second step, we investigate how sensitivity with respect to a neuron&#x2019;s spike count depends on whether the animal is within its place field or not. Place fields are of variable shape and size and, moreover, a small proportion of the recorded cells have no distinct place fields. Also the firing rates and gradient strengths vary greatly between neurons. Thus, we used firing rate as a proxy to indicate proximity of the animal to a given neuron&#x2019;s place field &#x2014; firing rate being maximal when the animal is near the centre of a place field, diminishing the further is moves away from that point. Hence after normalizing both the firing rates and the strength of gradients we averaged over all recorded cells (see the Sensitivity measures subsection in Methods). We saw that sensitivity decreases when the firing rate increases (<xref ref-type="fig" rid="fig6">Fig 6</xref>). Hence, indicating that at maximal firing rate &#x2014; near the center of place field, for example &#x2014; small changes in firing rate are less influential than they are towards the edges of the firing field. Broadly this accords with theoretical considerations which indicate that, in general, neural responses are most informative in the regions of their coding space where the firing rate changes most rapidly for a given change in the encoded variable [<xref ref-type="bibr" rid="c38">38</xref>]. In the case of place cells this corresponds to the edges of the place field. Conversely, outside of the place field, where firing rates fall close to 0 Hz, the sensitivity of the RNN to the neuron is again slightly lower (<xref ref-type="fig" rid="fig6">Fig 6</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig 6.</label>
<caption>
<title>Gradient analysis: sensitivity decreases with activity.</title>
<p>(a) Place field of an example neuron. (b) <italic>Sensitivity field</italic> - absolute values of gradients in different locations for the same neuron. (c) Normalized sensitivity as a function of normalized activity across neurons.</p></caption>
<graphic xlink:href="242867_fig6.tif"/>
</fig></sec></sec>
<sec id="s3">
<title>Discussion</title>
<p>We have shown that the sequential processing afforded by an artificial recurrent neural network (RNN) provides a flexible methodology able to efficiently decode information from a population of neurons. Moreover, since a RNN decoder is a neural network, it represents a biologically relevant model of how neural information is processed. Specifically, when applied to hippocampal neural data from freely moving rats [<xref ref-type="bibr" rid="c2">2</xref>], the network made use of the past neural activity to improve the decoding accuracy of the animals&#x2019; positions. In a 2D open field arena (1m x 1m), the RNN decoder was able to infer position with a median error of between 10.3 cm to 13.1 cm for 5 different rats. These results represented a marked improvement over a standard a Bayesian decoder [<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c16">16</xref>] which bases its decision solely on spike counts from a single time window centered around the moment of position measurement. Bayesian methods are known to be optimal decoders when using appropriate priors [<xref ref-type="bibr" rid="c39">39</xref>]. However, when applied to neural decoding it is difficult to determine these appropriate priors - as a result sub-optimal approximations are commonly used. Hence we propose that RNNs offer a practical methodology to incorporate sequential context without the need to choose or estimate specific priors over high-dimensional spaces. The improvement in 2D position decoding observed for the RNN was mirrored by similar results from a 1D decoding task using hippocampal recordings made while animals ran on a 6 meter track. Here again, the RNN decoder achieved equal or better results than a standard Bayesian approach.</p>
<p>Making use of the past neural activity as contextual information, the RNN seems more robust to noise than Bayesian classifier. In particular when using shorter time windows the spike counts become noisier and the Bayesian model&#x2019;s prediction accuracy degraded rapidly. In contrast the RNN decoder was more resistant to the variability of spike counts, likely due to its ability to combine information over the complete sequence of past inputs. Similarly, in situations were fewer neurons were available and hence the total amount information was reduced, the RNN exhibited a pronounced advantage over the Bayesian decoder. Equally, in the 1D task the benefit of the RNN was most evident for animal R2217, which had the fewest recorded neurons. Nevertheless notice that fewer recorded neurons does not necessarily mean lower accuracy. As described in Section 2.3.1, the error depends strongly on the amount of training data available (length of recording) and the quality of the cells (amount and location of firing). Taken together these results suggest that RNN decoding of neural data may prove to be particular useful in situations where large populations of neurons are not available or are difficult to stably maintain.</p>
<p>Beyond quality and amount of data available, the size of error the RNN decoder maed was also seen to depend on the distance of the animal from the walls and its instantaneous speed. At higher speeds (above 10.5 cm/s) the decoding accuracy does not decrease, but when the animal is imobile (&#x00A1;0.5 cm/s) the error was significantly higher than when in motion. We hypothesize that while stationary hippocampal activity may reflect non-local activity associated with sharp-wave ripple states [<xref ref-type="bibr" rid="c36">36</xref>].</p>
<p>Beyond providing more accurate decoding, the neural network approach also provides a new approach to sensitivity analyses. While knockout-type sensitivity analyses can be applied to both Bayesian and RNN decoders, the latter approach also supports gradient analyses. The two types of sensitivity - knockout and gradient - are correlated, but not identical. By design knockout analyses answers how the system behaves if an input is completely removed, while gradient analyses investigated how the system behaves in response to small perturbations to that input. Having access to the gradients with respect to each spike count makes is possible to pose new questions about the dynamic variability of the information content of individual neurons.</p></sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Data collection</title>
<sec id="s4a1">
<title>Animals and surgery</title>
<p>Eight male Lister Hooded rats were used in this study. All procedures were approved by the UK Home Office, subject to the restrictions and provisions contained in the Animals Scientific Procedures Act of 1986. All rats (330 &#x2212; 400<italic>g</italic> / 13 &#x2212; 18 weeks old at implantation) received two microdrives, each carrying eight tetrodes of twisted 17<italic>&#x00B5;m</italic> HM-L coated platinum iridium wire (90&#x0025; and 10&#x0025;, respectively; California Fine Wire), targeted to the right CA1 (ML: 2.2<italic>mm</italic>, AP: 3.8<italic>mm</italic> posterior to Bregma) and left medial entorhinal cortex (MEC) (ML &#x003D; 4.5<italic>mm</italic>, AP &#x003D; 0.3 &#x2212; 0.7 anterior to the transverse sinus, angled between 8 &#x2212; 10&#x00B0;). Wires were platinum plated to reduce impedance to 200 &#x2212; 300<italic>k</italic>&#x03A9; at 1<italic>kHz</italic>. After rats had recovered from surgery they were maintained at 90&#x0025; of free-feeding weight with <italic>ad libitum</italic> access to water, and were housed individually on a 12 &#x2212; <italic>hr</italic> light/dark cycle. MEC data was not analysed for this study.</p></sec>
<sec id="s4a2">
<title>Recording</title>
<p>Screening was performed post-surgically after a 1-week recovery period. An Axona recording system (Axona Ltd., St Albans, UK) was used to acquire the single-units and positional data (for details of the recording system and basic recording protocol see Barry et al(2007). The position and head direction of the animals was inferred using an overhead video camera to record the location of two light-emitting diodes (LEDs) mounted on the animals&#x2019; head-stages (50<italic>Hz</italic>). Tetrodes were gradually advanced in 62.5<italic>&#x00B5;m</italic> steps across days until place cells (CA1) and grid cells (MEC) were identified.</p></sec>
<sec id="s4a3">
<title>Experimental apparatus and protocol</title>
<p>The experiment was run during the animals&#x2019; light period. First, animals ran on a Z-shaped track, elevated 75<italic>cm</italic> off the ground with 10<italic>cm</italic> wide runways. The two parallel tracks of the Z (190 cm each) were connected by a diagonal section (220<italic>cm</italic>). The entire track was surrounded by plain black curtains with no distal cues. During each track session, animals were required to complete laps on the elevated Z-track. Specifically, the animals were required to run from the start of Arm1 to the end of Arm3, stopping at the track corners and ends in order to receive a food reward. If the animals made a wrong turn at the corners, reward was withheld. Four animals (R2142, R2192, R2198, and R2217) were trained to run on the track for 3 days before recording commenced. For the other animals (R2242, R2335, R2336, R2337), recordings were made from the first day of exposure to the Z-track task. These recordings constitute the dataset we refer to as the 1D decoding task. Not all animals&#x2019; recordings were used.</p>
<p>Following the track session the same animals completed a 20min random foraging session in a square (1m x 1m) enclosure. Coverage of the enclosure was encouraged by rewarding animals with sweetened rice. These recordings constitute the dataset we refer to as the 2D decoding task. Not all animals&#x2019; recordings were used.</p></sec></sec>
<sec id="s4b">
<title>Decoder based on recurrent neural networks</title>
<p>Deep learning is a class of algorithms that learn a hierarchy of representations or transformations of the data that make the problem of classification or regression easier [<xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. In particular, deep neural networks, inspired by biological neural circuits, consist of layers of computational units called neurons or nodes. The deepness means that there are multiple &#x201D;hidden&#x201D; layers between the input and output. By tuning the connection weights between its layers a neural network can learn to approximate a function from a set of examples, i.e., pairs of related input and output data. In this work we are interested in training a neural network to decode the rat spatial coordinates from the activity recorded from its hippocampal cells.</p>
<p>Whereas feed-forward neural networks learn to predict an output based on a single input, recurrent neural networks (RNNs) can deal with series of inputs and/or outputs [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. In particular, a recurrent network can preserve information from previous inputs by means of feedback connections (loops between its units). Having access to past information can be useful to minimize errors in certain tasks. Such memory of past inputs also means that the order in which the inputs are presented to the network may change the eventual predictions, and thus integrate contextual information over time. A naive implementation of RNNs can only maintain information from a few past inputs, making it possible for the network to detect only immediate trends, but not long timescale dependencies. Advanced realizations of recurrent networks, such as long-short term memory (LSTM) [<xref ref-type="bibr" rid="c40">40</xref>] and gated recurrent units (GRU) [<xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c42">42</xref>] have specific architecture and sets of parameters that control to what extent past activity should be remembered or overwritten by a new input [<xref ref-type="bibr" rid="c42">42</xref>]. This makes them capable of integrating knowledge over a longer sequence. Through using past inputs as contextual information these networks have achieved outstanding performance with noisy sequential data such as text and speech.</p>
<sec id="s4b1">
<title>Network architecture</title>
<p>A RNN can be made to predict (i) a series of outputs based on a series of inputs, (ii) a series of outputs given only one input, and (iii) one output given a series of inputs. For our location prediction task we are interested in the latter - given hippocampal activity (spike counts) over a longer period of time, we aim to predict one set of spatial coordinates - the animal location.</p>
<p>The architecture, illustrated in <xref ref-type="fig" rid="fig7">Fig 7c</xref>, of the RNN used in this work consists of an input layer (same size as the number of recorded neurons) followed by two 512-node LSTM layers, and an output layer (2 nodes, one for each spatial coordinate <italic>x</italic> and <italic>y</italic>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Fig 7.</label>
<caption>
<title>Feature extraction from spiking data and neural network architecture.</title>
<p>(a) Extracting a sequence of spike count vectors from spiking data. Each subsequent input originates from an overlapping time period, shifted 200 ms forward in time. (b) The input data that the RNN decoder will use is a sequence of spike count vectors from these time windows. (c) The network used for decoding consists of an input layer (size equals number of recorded neurons), two hidden layers containing 512 long-short term memory (LSTM) units and an output layer of size 2 (<italic>x</italic> and <italic>y</italic> coordinates). The spike count vectors are inserted to the input layer one by one at each timestep. The network produces a prediction for <italic>x</italic> and <italic>y</italic> coordinates only at the end of the sequence, at <italic>t</italic> &#x003D; 100.</p></caption>
<graphic xlink:href="242867_fig7.tif"/>
</fig></sec></sec>
<sec id="s4c">
<title>Feature extraction</title>
<p>The features of neural data used for decoding are the spike counts of all <italic>N</italic> cells recorded (forming a <italic>spike count vector</italic>, as shown in <xref ref-type="fig" rid="fig7">Fig 7a</xref> and <xref ref-type="fig" rid="fig7">7b</xref>). In particular, the recurrent neural network is presented with a series of 100 of such spike count vectors, corresponding to activity of all cells in 100 overlapping time windows. The shift between consecutive time windows was fixed to 200 ms for all window sizes (this means 0&#x0025; overlap in 200 ms windows, 50&#x0025; overlap in 400 ms windows, 80&#x0025; overlap in 1000 ms windows). Across the 100 time steps we consider activity from approximately 20 seconds.</p>
<p>Based on this series of 100 spike count vectors the recurrent network was trained to predict the rat&#x2019;s location in the center of the last (100th) time window. Thus, each sequence of 100 vectors plus the correct location of the rat at the center of the last time window forms one data point for training the RNN.</p>
<p>During the training procedure the network aims to minimize an objective function, in our case the mean squared error of the coordinates. The learning is done for 50 epochs (full cycles of training data) using RMSprop optimizer (variant of stochastic gradient descent), with a mini-batch size equal to 64. All computations were performed with custom-made scripts using Keras neural network library [<xref ref-type="bibr" rid="c43">43</xref>].</p></sec>
<sec id="s4d">
<title>Bayesian decoder</title>
<p>Spatial decoding was also implemented using a Bayesian framework [<xref ref-type="bibr" rid="c44">44</xref>] subject to 10-fold cross validation (see also the next subsection). Specifically, for each fold, 90&#x0025; of the data was used to generate ratemaps for hippocampal neurons -spike and dwell time data were binned into 2 cm square bins, smoothed with a Gaussian kernel (<italic>&#x03C3;</italic>&#x003D;1.5 bins), and rates calculated by dividing spike numbers by dwell time. Note, for the Z-maze only, positional data was linearised before binning.</p>
<p>Next, with the remaining 10&#x0025; of the data, using temporal windows (200 ms to 1000 ms) each of which overlapped with its neighbours by half, we calculate the probability of the animal&#x2019;s presence in each spatial bin given the observed spikes &#x2013; the posterior probability matrix [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c16">16</xref>].</p>
<p>Specifically during a time window (T) the spikes generated by <italic>N</italic> place cells was <italic>K</italic> &#x003D; (<italic>k</italic><sub>1</sub>,&#x2026;,<italic>k<sub>i</sub></italic>,&#x2026;,<italic>k<sub>N</sub></italic>), where <italic>k<sub>i</sub></italic> was the number of spikes fired by the <italic>i</italic> &#x2212; <italic>th</italic> cell. The probability of observing <italic>K</italic> in time T given position (<italic>x</italic>) was taken as:<disp-formula>
<alternatives><graphic xlink:href="242867_ueqn1.gif"/></alternatives></disp-formula>where <italic>x</italic> indexes the 2 cm spatial bins defined on the Z-track/foraging environment and <italic>&#x03B1;<sub>i</sub></italic>(<italic>x</italic>) is the firing rate of the <italic>i</italic> &#x2212; <italic>th</italic> place cell at position <italic>x</italic>, derived from the ratemaps.</p>
<p>To compute the probability of the animal&#x2019;s position given the observed spikes we applied Bayes&#x2019; rule, assuming a flat prior for position (<italic>P</italic> (<italic>x</italic>)), to give:<disp-formula>
<alternatives><graphic xlink:href="242867_ueqn2.gif"/></alternatives></disp-formula>where <italic>R</italic> is a normalizing constant depending on <italic>T</italic> and the number of spikes emitted. Note we do not use the historic position of the animals&#x2019; to constrain <italic>P</italic>(<italic>x</italic>|<italic>K</italic>) thus the probability estimate in each <italic>T</italic> is independent of its neighbours. Finally, position was decoded from the posterior probability matrix using a maximum likelihood method - selecting the bin with the highest probability value. Decoding error was then taken as the Euclidean distance between the centre of the decoded bin and the centre of the bin closest to the animal&#x2019;s true location.</p></sec>
<sec id="s4e">
<title>Cross validation and averaging of results</title>
<p>The reported errors for both Bayesian and RNN approach are measured using a 10-fold cross validation method that divides the <italic>D</italic> data points between training and validation sets. Due to the overlap between consecutive time windows a random assignment of data points to training and validation sets would imply that for most of the validation data points a highly correlated neighbouring sample can be found in the training set. This would result in an artificially high validation accuracy that does not actually reflect the model&#x2019;s ability to generalize to new, unseen data.</p>
<p>Instead, in our analysis the first fold in cross validation simply corresponds to leaving out the first 10&#x0025; of the recording time and training the model on the last 90&#x0025; of data. The second fold, accordingly, assigns the second tenth of recordings to the validation set, and so on. For RNNs we need to additionally discard 99 samples at each border between training and validation sets. Remind that the input for RNNs is a series of 100 spike count vectors - to avoid any overlap between training and test data we remove validation data points that have at least one shared spike count vector with any training data point.</p>
<p>For each fold we train a model on the training set and calculate the error on the validation set. All reported errors are the validation errors - errors that the models make on the one tenth of data that was left out of the training procedure. To increase the reliability of the results, we perform 10-fold cross validation procedure multiple times and report the mean and median of the errors. This is done only for the RNN decoder, because the Bayesian decoder is deterministic and repeating cross-validation procedure multiple times is not necessary.</p></sec>
<sec id="s4f">
<title>Analysis of decoding results</title>
<sec id="s4f1">
<title>Quantifying prediction errors</title>
<p>When decoding rat locations in the 2D arena, prediction errors in the animal position were quantified by the mean Euclidean distance (MED) between the predicted and true positions:<disp-formula>
<alternatives><graphic xlink:href="242867_ueqn3.gif"/></alternatives></disp-formula>where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="242867_inline1.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="242867_inline2.gif"/></alternatives></inline-formula> are the locations predicted by the decoder, <italic>y</italic> and <italic>x</italic> are the true locations and <italic>N</italic> is the number of data points.</p>
<p>The training procedure of recurrent neural networks is stochastic and always ends up with slightly different solutions. We repeat the 10-fold cross-validation 10 times, giving us 10 independent predictions for each data point. We report the average of errors over these 10 realizations (and not the error of the averaged prediction).</p>
<p>For evaluating the <italic>x</italic>-coordinate (<italic>y</italic>-coordinate) errors only the <italic>x</italic> (<italic>y</italic>) component of the positions were used in the above formula:<disp-formula>
<alternatives><graphic xlink:href="242867_ueqn4.gif"/></alternatives></disp-formula></p>
<p>In an additional experiment, we also decode the rat locations on a 600 cm long Z-shaped track. The position of the rat along the track is considered as a 1D coordinate ranging from 0 in one end of the track to 600 in the other end of the Z-shape. To obtain these 1D coordinates the actual locations extracted from camera images are projected to the nearest point on a Z-shaped ideal trajectory. The prediction error of the model is quantified by absolute distance between the predicted and true position along this 1D coordinate.</p></sec>
<sec id="s4f2">
<title>Sensitivity measures</title>
<p>In knock-out analysis we set the activity of a neuron to zero in all validation data points and then calculate the validation errors. The activity is not annulled during training of the model, so the system can not learn to compensate or adapt. We repeat this knock-out procedure for each neuron one by one. We compare how much the prediction error increased when different neurons were knocked out.</p>
<p>The gradient of the loss function with respect to inputs was calculated using back-propagation through time [<xref ref-type="bibr" rid="c45">45</xref>], similarly to how gradients with respect to weights are found. Indeed, for updating the connection weights of the network at training time, the algorithm needs to calculate the gradients of the loss function with respect to the weights [<xref ref-type="bibr" rid="c30">30</xref>]. These gradients tell us how a small change in a particular weight would influence the final output error. In here we ask a similar question - how much would a small deviation in a certain input change the final loss. Important is to notice that when talking about sensitivity we disregard the sign of the gradient, in all results we use the absolute values (magnitudes) of gradients. We compute gradient strengths for each validation set data point and separately for each neuron&#x2019;s spike count for each position in the time series of <italic>T</italic> inputs (<italic>T</italic> &#x003D; 100). This results in a <italic>D</italic> &#x00D7; <italic>N</italic> &#x00D7; <italic>T</italic> matrix of gradient values. To draw further conclusions from the gradient values, we need to average or manipulate this 3D matrix along different dimensions. For example, when calculating the neurons that the model is most sensitive to, we need to average across all data points and all time steps, so we are left with one value per neuron.</p>
<p>When investigating the relationship between sensitivity and location on the place field (on <xref ref-type="fig" rid="fig6">Fig 6c</xref>), we also need to normalize the spike counts and gradient magnitudes of different neurons, so that we could aggregate them. To do this one would usually divide the spike count with the maximum value, resulting in measures between 0 and 1 for all cells. In the case or low-firing neurons, however, the noisiness of the data means that the maximum value can be an outlier (we can have maximum count of 4, whereas no other value is above 2). We therefore choose to divide the spike counts with the 99th percentile of the spike count values instead. A few values end up being above 1, but the normalized value distributions of low and high firing neurons look more similar. We do a similar 99-th percentile normalization on the absolute values of gradients. For each normalized firing rate we have one corresponding normalized gradient size. We can then plot how the normalized gradient size depends on normalized firing rate.</p></sec>
</sec></sec>
</body>
<back>
<sec id="s5">
<title>Supporting information</title>
<p><bold>S1 Text. Temporal gradient analysis</bold>. A third way to investigate the gradients is to average only across the samples. We thus obtain an averaged gradient for each neuron at each different position in the input sequence of 100 time windows. These averages reveal, for example, how sensitive the model is to changes in spike counts of the same neuron at different points of time. Unfortunately recurrent network architecture and training procedures favour information contained in more recent inputs (due to vanishing gradients further back in time). We therefore judge that it is not fair to draw conclusions from comparing sensitivity to spike counts at different positions in the sequence - inputs in the later time steps would show up as more important not necessarily due to information content but due to the algorithm we used. It is however fair to compare the contributions of different neurons at the same time step. We propose to compare the model&#x2019;s sensitivity to a certain spike count with average of sensitivity across all neurons at the same point of the temporal context sequence. Intuitively such gradient analysis reveals if neuron N&#x2019;s activity at time window T within the temporal context, was more informative than the activity of other neurons at that time point. This comparison is not distorted by the network architecture, because inputs from different neurons are treated symmetrically (order of neurons could be changed) by the network. No bias exists with respect to either particular neurons or data samples.</p>
<p>As a summary of the analysis described above, <xref ref-type="fig" rid="fig2">Fig 2</xref> shows the normalized gradients of several neurons at different positions within the temporal context. The analysis reveals different profiles of relative sensitivity within the temporal context. In particular, we note that several neurons have a peak in their normalized sensitivity around one second before the last time window for which the animal position is predicted. Nevertheless, our time windows last 1400ms and therefore the temporal resolution is very low. We restrain ourselves from drawing conclusions from this analysis due to lack of temporal precision. We believe that when using smaller, non-overlapping time windows, this type of investigation can reveal interesting temporal aspects of information processing in the brain.</p>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1. S1 Fig.</label>
<caption>
<title>Mean prediction error for different instantaneous movement speeds.</title>
<p>Movement speed is based on the distance covered in 200 ms. The first bar is the average over the errors for speeds in range [0, 0.5] cm/s, the second for (0.5, 1.5] cm/s, etc. The error is highest when the rat is not moving or moving very slowly. Notice that speeds in the range of 1-2 cm/s can also be the results of head movements. At higher speeds the exact velocity does not seem to influence accuracy. Note that the bars do not contain the same amount of data points. Apparent changes in the mean error at higher velocities can be attributed to noise as we have less data points there.</p></caption>
<graphic xlink:href="242867_figS1.tif"/>
</fig>
<fig id="figS2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2.</label>
<caption>
<title>Gradient analysis.</title>
<p>a-e) Temporal profiles of relative importance for 5 selected neurons among the highest contributing neurons according to gradient analysis. Notice that the profiles peak at different time steps. f) Temporal profile of the least important neuron according to gradient analysis.</p></caption>
<graphic xlink:href="242867_figS2.tif"/>
</fig>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Zurab Bzhalava, Sander Tanni and Jaan Aru for early work and useful discussions. We also thank Jack Kelly for useful discussions. R.V. also thanks the financial support from the Estonian Research Council through the personal research grant PUT1476. This work was supported by the Estonian Centre of Excellence in IT (EXCITE), funded by the European Regional Development Fund. C.B. was funded by the Royal Society and Wellcome Trust. We gratefully acknowledge the support of NVIDIA Corporation with the donation of one GeForce GTX TITAN X GPU used for this research. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Keefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dostrovsky</surname> <given-names>J.</given-names></string-name> <article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title>. <source>Brain research</source>. <year>1971</year>;<volume>34</volume>(<issue>1</issue>):<fpage>171</fpage>&#x2013;<lpage>175</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="book"><string-name><surname>O&#x2019;keefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nadel</surname> <given-names>L.</given-names></string-name> <source>The hippocampus as a cognitive map</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>; <year>1978</year>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Ulanovsky</surname> <given-names>N</given-names></string-name>, <string-name><surname>Moss</surname> <given-names>CF</given-names></string-name>. <article-title>Hippocampal cellular and network activity in freely moving echolocating bats</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>2</issue>):<fpage>224</fpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Ekstrom</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Kahana</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Caplan</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Fields</surname> <given-names>TA</given-names></string-name>, <etal>et al.</etal> <article-title>Cellular networks underlying human spatial navigation</article-title>. <source>Nature</source>. <year>2003</year>;<volume>425</volume>(<issue>6954</issue>):<fpage>184</fpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Muller</surname> <given-names>RU</given-names></string-name>, <string-name><surname>Kubie</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Ranck</surname> <given-names>JB</given-names></string-name>. <article-title>Spatial firing patterns of hippocampal complex-spike cells in a fixed environment</article-title>. <source>Journal of Neuroscience</source>. <year>1987</year>;<volume>7</volume>(<issue>7</issue>):<fpage>1935</fpage>&#x2013;<lpage>1950</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Muller</surname> <given-names>RU</given-names></string-name>, <string-name><surname>Kubie</surname> <given-names>JL</given-names></string-name>. <article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title>. <source>Journal of Neuroscience</source>. <year>1987</year>;<volume>7</volume>(<issue>7</issue>):<fpage>1951</fpage>&#x2013;<lpage>1968</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;keefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Conway</surname> <given-names>D.</given-names></string-name> <article-title>Hippocampal place units in the freely moving rat: why they fire where they fire</article-title>. <source>Experimental brain research</source>. <year>1978</year>;<volume>31</volume>(<issue>4</issue>):<fpage>573</fpage>&#x2013;<lpage>590</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Quirk</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>RU</given-names></string-name>, <string-name><surname>Kubie</surname> <given-names>JL</given-names></string-name>. <article-title>The firing of hippocampal place cells in the dark depends on the rat&#x2019;s recent experience</article-title>. <source>Journal of Neuroscience</source>. <year>1990</year>;<volume>10</volume>(<issue>6</issue>):<fpage>2008</fpage>&#x2013;<lpage>2017</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Thompson</surname> <given-names>L</given-names></string-name>, <string-name><surname>Best</surname> <given-names>P.</given-names></string-name> <article-title>Long-term stability of the place-field activity of single units recorded from the dorsal hippocampus of freely behaving rats</article-title>. <source>Brain research</source>. <year>1990</year>;<volume>509</volume>(<issue>2</issue>):<fpage>299</fpage>&#x2013;<lpage>308</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Bostock</surname> <given-names>E</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>RU</given-names></string-name>, <string-name><surname>Kubie</surname> <given-names>JL</given-names></string-name>. <article-title>Experience-dependent modifications of hippocampal place cell firing</article-title>. <source>Hippocampus</source>. <year>1991</year>;<volume>1</volume>(<issue>2</issue>):<fpage>193</fpage>&#x2013;<lpage>205</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Anderson</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Jeffery</surname> <given-names>KJ</given-names></string-name>. <article-title>Heterogeneous modulation of place cell firing by changes in context</article-title>. <source>Journal of Neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>26</issue>):<fpage>8827</fpage>&#x2013;<lpage>8835</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Leutgeb</surname> <given-names>S</given-names></string-name>, <string-name><surname>Leutgeb</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Treves</surname> <given-names>A</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>. <article-title>Distinct ensemble codes in hippocampal areas CA3 and CA1</article-title>. <source>Science</source>. <year>2004</year>;<volume>305</volume>(<issue>5688</issue>):<fpage>1295</fpage>&#x2013;<lpage>1298</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>. <article-title>Dynamics of the hippocampal ensemble code for space</article-title>. <source>Science</source>. <year>1993</year>;<volume>261</volume>(<issue>5124</issue>):<fpage>1055</fpage>&#x2013;<lpage>1059</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>K</given-names></string-name>, <string-name><surname>Ginzburg</surname> <given-names>I</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Sejnowski</surname> <given-names>TJ</given-names></string-name>. <article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title>. <source>Journal of neurophysiology</source>. <year>1998</year>;<volume>79</volume>(<issue>2</issue>):<fpage>1017</fpage>&#x2013;<lpage>1044</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <etal>et al.</etal> <article-title>Reactivation of hippocampal ensemble memories during sleep</article-title>. <source>Science</source>. <year>1994</year>;<volume>265</volume>(<issue>5172</issue>):<fpage>676</fpage>&#x2013;<lpage>679</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Davidson</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Kloosterman</surname> <given-names>F</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>. <article-title>Hippocampal replay of extended experience</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>63</volume>(<issue>4</issue>):<fpage>497</fpage>&#x2013;<lpage>507</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Pfeiffer</surname> <given-names>BE</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>. <article-title>Hippocampal place cell sequences depict future paths to remembered goals</article-title>. <source>Nature</source>. <year>2013</year>;<volume>497</volume>(<issue>7447</issue>):<fpage>74</fpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Navratilova</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Hoang</surname> <given-names>LT</given-names></string-name>, <string-name><surname>Schwindel</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Tatsuno</surname> <given-names>M</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>. <article-title>Experience-dependent firing rate remapping generates directional selectivity in hippocampal place cells</article-title>. <source>Frontiers in neural circuits</source>. <year>2012</year>;<volume>6</volume>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Wood</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Dudchenko</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Robitsek</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Eichenbaum</surname> <given-names>H.</given-names></string-name> <article-title>Hippocampal neurons encode information about different types of memory episodes occurring in the same location</article-title>. <source>Neuron</source>. <year>2000</year>;<volume>27</volume>(<issue>3</issue>):<fpage>623</fpage>&#x2013;<lpage>633</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Ferbinteanu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shapiro</surname> <given-names>ML</given-names></string-name>. <article-title>Prospective and retrospective memory coding in the hippocampus</article-title>. <source>Neuron</source>. <year>2003</year>;<volume>40</volume>(<issue>6</issue>):<fpage>1227</fpage>&#x2013;<lpage>1239</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Markus</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Qin</surname> <given-names>YL</given-names></string-name>, <string-name><surname>Leonard</surname> <given-names>B</given-names></string-name>, <string-name><surname>Skaggs</surname> <given-names>WE</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Barnes</surname> <given-names>CA</given-names></string-name>. <article-title>Interactions between location and task affect the spatial and directional firing of hippocampal neurons</article-title>. <source>Journal of Neuroscience</source>. <year>1995</year>;<volume>15</volume>(<issue>11</issue>):<fpage>7079</fpage>&#x2013;<lpage>7094</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Karlsson</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM</given-names></string-name>. <article-title>Network dynamics underlying the formation of sparse, informative representations in the hippocampus</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>52</issue>):<fpage>14271</fpage>&#x2013;<lpage>14281</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ginzberg</surname> <given-names>LL</given-names></string-name>, <string-name><surname>O&#x2019;Keefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N.</given-names></string-name> <article-title>Grid cell firing patterns signal environmental novelty by expansion</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2012</year>;<volume>109</volume>(<issue>43</issue>):<fpage>17687</fpage>&#x2013;<lpage>17692</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Ziv</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Burns</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Cocker</surname> <given-names>ED</given-names></string-name>, <string-name><surname>Hamel</surname> <given-names>EO</given-names></string-name>, <string-name><surname>Ghosh</surname> <given-names>KK</given-names></string-name>, <string-name><surname>Kitch</surname> <given-names>LJ</given-names></string-name>, <etal>et al.</etal> <article-title>Long-term dynamics of CA1 hippocampal place codes</article-title>. <source>Nature neuroscience</source>. <year>2013</year>;<volume>16</volume>(<issue>3</issue>):<fpage>264</fpage>&#x2013;<lpage>266</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Hayman</surname> <given-names>R</given-names></string-name>, <string-name><surname>Chakraborty</surname> <given-names>S</given-names></string-name>, <string-name><surname>Anderson</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Jeffery</surname> <given-names>KJ</given-names></string-name>. <article-title>Context-specific acquisition of location discrimination by hippocampal place cells</article-title>. <source>European Journal of Neuroscience</source>. <year>2003</year>;<volume>18</volume>(<issue>10</issue>):<fpage>2825</fpage>&#x2013;<lpage>2834</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Lever</surname> <given-names>C</given-names></string-name>, <string-name><surname>Wills</surname> <given-names>T</given-names></string-name>, <string-name><surname>Cacucci</surname> <given-names>F</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N</given-names></string-name>, <string-name><surname>O&#x2019;keefe</surname> <given-names>J</given-names></string-name>. <article-title>Long-term plasticity in hippocampal place-cell representation of environmental geometry</article-title>. <source>Nature</source>. <year>2002</year>;<volume>416</volume>(<issue>6876</issue>):<fpage>90</fpage>&#x2013;<lpage>94</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Dupret</surname> <given-names>D</given-names></string-name>, <string-name><surname>O&#x2019;neill</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pleydell-Bouverie</surname> <given-names>B</given-names></string-name>, <string-name><surname>Csicsvari</surname> <given-names>J.</given-names></string-name> <article-title>The reorganization and reactivation of hippocampal maps predict spatial memory performance</article-title>. <source>Nature neuroscience</source>. <year>2010</year>;<volume>13</volume>(<issue>8</issue>):<fpage>995</fpage>&#x2013;<lpage>1002</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Eichenbaum</surname> <given-names>H</given-names></string-name>, <string-name><surname>Dudchenko</surname> <given-names>P</given-names></string-name>, <string-name><surname>Wood</surname> <given-names>E</given-names></string-name>, <string-name><surname>Shapiro</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tanila</surname> <given-names>H.</given-names></string-name> <article-title>The hippocampus, memory, and place cells: is it spatial memory or a memory space</article-title>? <source>Neuron</source>. <year>1999</year>;<volume>23</volume>(<issue>2</issue>):<fpage>209</fpage>&#x2013;<lpage>226</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Fenton</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Muller</surname> <given-names>RU</given-names></string-name>. <article-title>Place cell discharge is extremely variable during individual passes of the rat through the firing field</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1998</year>;<volume>95</volume>(<issue>6</issue>):<fpage>3182</fpage>&#x2013;<lpage>3187</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Rumelhart</surname> <given-names>DE</given-names></string-name>, <string-name><surname>Hinton</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>RJ</given-names></string-name>, <etal>et al.</etal> <article-title>Learning representations by back-propagating errors</article-title>. <source>Cognitive modeling</source>. <year>1988</year>;<volume>5</volume>(<issue>3</issue>):<fpage>1</fpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Elman</surname> <given-names>JL</given-names></string-name>. <article-title>Finding structure in time</article-title>. <source>Cognitive science</source>. <year>1990</year>;<volume>14</volume>(<issue>2</issue>):<fpage>179</fpage>&#x2013;<lpage>211</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="other"><string-name><surname>Goodfellow</surname> <suffix>I</suffix>, <given-names>Bengio Y</given-names></string-name>, <string-name><surname>Courville</surname> <given-names>A.</given-names></string-name> <source>Deep Learning. MIT Press</source>; <year>2016</year>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hayman</surname> <given-names>R</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>N</given-names></string-name>, <string-name><surname>Jeffery</surname> <given-names>KJ</given-names></string-name>. <article-title>Experience-dependent rescaling of entorhinal grids</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>6</issue>):<fpage>682</fpage>&#x2013;<lpage>684</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>&#x00D3;lafsd&#x00F3;ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Carpenter</surname> <given-names>F</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C.</given-names></string-name> <article-title>Coordinated grid and place cell replay during rest</article-title>. <source>Nature neuroscience</source>. <year>2016</year>;<volume>19</volume>(<issue>6</issue>):<fpage>792</fpage>&#x2013;<lpage>794</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Hardcastle</surname> <given-names>K</given-names></string-name>, <string-name><surname>Ganguli</surname> <given-names>S</given-names></string-name>, <string-name><surname>Giocomo</surname> <given-names>LM</given-names></string-name>. <article-title>Environmental boundaries as an error correction mechanism for grid cells</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>86</volume>(<issue>3</issue>):<fpage>827</fpage>&#x2013;<lpage>839</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>&#x00D3;lafsd&#x00F3;ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Carpenter</surname> <given-names>F</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C.</given-names></string-name> <article-title>Task Demands Predict a Dynamic Switch in the Content of Awake Hippocampal Replay</article-title>. <source>Neuron</source>. <year>2017</year>;<volume>96</volume>(<issue>4</issue>):<fpage>925</fpage>&#x2013;<lpage>935</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="other"><string-name><surname>Skaggs</surname> <given-names>WE</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Gothard</surname> <given-names>KM</given-names></string-name>. <chapter-title>An information-theoretic approach to deciphering the hippocampal code</chapter-title>. In: <conf-name>Advances in neural information processing systems</conf-name>; <year>1993</year>. p. <fpage>1030</fpage>&#x2013;<lpage>1037</lpage>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>, <string-name><surname>Deneve</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ducom</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE</given-names></string-name>. <article-title>Narrow versus wide tuning curves: What&#x2019;s best for a population code?</article-title> <source>Neural computation</source>. <year>1999</year>;<volume>11</volume>(<issue>1</issue>):<fpage>85</fpage>&#x2013;<lpage>90</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="book"><string-name><surname>Mitchell</surname> <given-names>TM</given-names></string-name>, <etal>et al.</etal>. <source>Machine learning</source>. <publisher-name>WCB</publisher-name>; <year>1997</year>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Hochreiter</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname> <given-names>J.</given-names></string-name> <article-title>Long short-term memory</article-title>. <source>Neural computation</source>. <year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>&#x2013;<lpage>1780</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="other"><string-name><surname>Cho</surname> <given-names>K</given-names></string-name>, <string-name><surname>Van Merri&#x00EB;nboer</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bahdanau</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>Y.</given-names></string-name> <article-title>On the properties of neural machine translation: Encoder-decoder approaches</article-title>. arXiv preprint arXiv:<pub-id pub-id-type="arxiv">14091259</pub-id>. <year>2014</year>;.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="other"><string-name><surname>Chung</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gulcehre</surname> <given-names>C</given-names></string-name>, <string-name><surname>Cho</surname> <given-names>K</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>Y.</given-names></string-name> <article-title>Empirical evaluation of gated recurrent neural networks on sequence modeling</article-title>. arXiv preprint arXiv:<pub-id pub-id-type="arxiv">14123555</pub-id>. <year>2014</year>;.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="website"><string-name><surname>Chollet</surname> <given-names>F</given-names></string-name>, <etal>et al.</etal>. <article-title>Keras</article-title>; <year>2015</year>. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>&#x00D3;lafsd&#x00F3;ttir</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Barry</surname> <given-names>C</given-names></string-name>, <string-name><surname>Saleem</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Hassabis</surname> <given-names>D</given-names></string-name>, <string-name><surname>Spiers</surname> <given-names>HJ</given-names></string-name>. <article-title>Hippocampal place cells construct reward related sequences through unexplored space</article-title>. <source>Elife</source>. <year>2015</year>;<volume>4</volume>:<fpage>e06063</fpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Werbos</surname> <given-names>PJ</given-names></string-name>. <article-title>Backpropagation through time: what it does and how to do it</article-title>. <source>Proceedings of the IEEE</source>. <year>1990</year>;<volume>78</volume>(<issue>10</issue>):<fpage>1550</fpage>&#x2013;<lpage>1560</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>