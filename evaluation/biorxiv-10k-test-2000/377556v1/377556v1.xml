<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/377556</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Confirmatory Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Bioengineering</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>COMPASS: An Open-Source, General-Purpose Software Toolkit for Computational Psychiatry</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Yousefi</surname>
<given-names>Ali</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Paulk</surname>
<given-names>Angelique C.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Basu</surname>
<given-names>Ishita</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dougherty</surname>
<given-names>Darin D.</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Eskandar</surname>
<given-names>Emad N.</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Eden</surname>
<given-names>Uri T.</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Widge</surname>
<given-names>Alik S.</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="corresp" rid="cor2">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label>Instructor, <institution>Department of Psychiatry, Harvard Medical School</institution>, Boston, <country>MA</country>
<institution>Research Scientist, Department of Mathematics and Statistics, Boston University</institution>, Boston, <country>MA</country></aff>
<aff id="a2"><label>2</label>Instructor, <institution>Department of Neurology, Harvard Medical School</institution>, Boston, <country>MA</country></aff>
<aff id="a3"><label>3</label>Instructor, <institution>Department of Psychiatry, Harvard Medical School</institution>, Boston, <country>MA</country></aff>
<aff id="a4"><label>4</label>Associate Professor, <institution>Department of Psychiatry, Harvard Medical School</institution>, Boston, <country>MA</country></aff>
<aff id="a5"><label>5</label>Professor, <institution>Department of Neurosurgery, Harvard Medical School</institution>, Boston, <country>MA</country> Currently at: <institution>Department of Neurological Surgery, Albert Einstein College of Medicine</institution>, Bronx, <country>NY</country></aff>
<aff id="a6"><label>6</label>Professor of Statistics, <institution>Department of Mathematics and Statistics, Boston University</institution>. Boston, <country>MA</country></aff>
<aff id="a7"><label>7</label>Assistant Professor, <institution>Department of Psychiatry, Harvard Medical School</institution>, Boston, <country>MA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>first corresponding author: <email>ayousefi@mghharvard.edu</email></corresp>
<corresp id="cor2"><label>&#x002A;</label>second corresponding author: <email>awidge@partners.org</email></corresp>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>377556</elocation-id>
<history>
<date date-type="received">
<day>25</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>25</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>27</day>
<month>7</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="377556.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Mathematical modeling of behavior during psychophysical tasks, referred to as &#x201C;computational psychiatry&#x201D;, could greatly improve our understanding of mental disorders. One barrier to broader adoption of computational methods is that they often require advanced programming skills. We developed the Computational Psychiatry Adaptive State-Space (COMPASS) toolbox, an open-source MATLAB-based software package. After specifying a few parameters in a small set of user-friendly functions, COMPASS allows the user to efficiently fit of a wide range of computational behavioral models. The model output can be analyzed as an experimental outcome or used as a regressor for neural data, and can be tested using goodness-of-fit methods. Here, we demonstrate that COMPASS can replicate two computational behavior analyses from different groups. COMPASS replicates and, in one case, slightly improves on the original modeling results. This flexible, general-purpose toolkit should accelerate the use of computational modeling in psychiatric neuroscience.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Computational Psychiatry</kwd>
<kwd>Mathematical Behavioral Analysis</kwd>
<kwd>Computational Methods</kwd>
<kwd>State-Space Modeling</kwd>
<kwd>Open Source Software</kwd>
<kwd>Cognitive Neuroscience</kwd>
</kwd-group>
<counts>
<page-count count="28"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>There is a growing need for advanced computational methods within psychiatric neuroscience (<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>). One particularly important aspect of that work is the development of quantitative, reproducible models that link patients&#x2019; symptoms to circuits, behaviors, and/or underlying psychological constructs (<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c4">4</xref>). Such models have been used to quantify measurements of psychiatric disease processes relative to healthy subjects or to design experiments based on theoretical predictions (<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref>). Computational models are also expected to improve the reliability and utility of human neuroscience. For example, psychiatric neuroscience investigations usually classify subjects through categorical diagnoses and subjective rating scales. This, in turn, leads to poor signal-to-noise ratios (SNR) and difficulty in identifying reliable neural biomarkers of psychiatric illness (<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>). A more reliable approach may be to classify patients based on models of (ab)normal functioning. For instance, both patients and controls could perform the same standard psychophysical task, and patients&#x2019; degree of abnormality could be quantified based on the parameters of a model fit to their task behavior. Such models&#x2019; output(s) can become independent (regressor) variables in neuro-imaging or electrophysiologic analyses (<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>), potentially reducing inter-subject variability and improving SNR. Computational modeling also provides a framework for another major goal of psychiatric neuroscience: the identification of cross-diagnostic phenotypes and the circuits subserving those phenotypes (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>).</p>
<p>Modeling analyses of psychophysical task behavior often follow a common workflow. They cast the observed behavior as a function of an underlying theoretical construct, formalize that function in a system of parameterized equations, then identify parameters consistent with each experimental subject&#x2019;s observed data. A challenge arises because each laboratory does this differently, often using custom-developed computer programs optimized for the modeling approach at hand. The resulting programs may not be well suited to analyzing slightly different datasets. Peer reviewers who are not modeling/programming experts are not readily able to assess whether the models were correctly implemented (<xref ref-type="bibr" rid="c15">15</xref>). Many researchers also do not have the mathematical/computational expertise to design such modeling systems <italic>de novo.</italic> Similar problems arose in the early days of neuro-imaging, and have been ameliorated at least in part by the development of freely available analysis packages that make it easier to apply best practices (<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c22">22</xref>). Efforts exist to create similar analysis packages for behavior, e.g. hBayesDM (<xref ref-type="bibr" rid="c22">22</xref>) and KFAS (<xref ref-type="bibr" rid="c23">23</xref>). The available packages, however, do not work well with multiple behavior outputs (e.g., reaction times plus choices) and do not fully handle missing information in datasets (<xref ref-type="bibr" rid="c24">24</xref>).</p>
<p>Here, we present a general-purpose, open-source toolbox for fitting a wide variety of computational models to an equally wide variety of behavioral data. COMPASS is based on the state-space formalism, which assumes that behavior is influenced both by the parameters of individual task trials and by an underlying &#x201C;cognitive state&#x201D; that varies smoothly from trial to trial. This framework has successfully modeled behavior and neural activity in many contexts (<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c27">27</xref>), and fits the general concept that psychiatric symptoms arise from disruptions in basic underlying cognitive processes. Continuous (reaction times, physiologic measurements), binary (correct/incorrect, yes/no choices), and multinomial (learning of multiple stimulus-response contingencies) behavioral outputs can all be integrated into models, making the toolbox applicable to almost any laboratory task. To increase the applicability to &#x201C;real world&#x201D; data, COMPASS includes methods we recently developed to more optimally handle missing observations in these computational approaches (<xref ref-type="bibr" rid="c28">28</xref>).</p>
<p>We first provide a general overview of COMPASS, then demonstrate its application on two examples of associative learning behavior from published literature. In prior work, we showed how an early version of this toolbox could model reaction times in conflict tasks (<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c28">28</xref>). These examples illustrate the flexibility and generality of our approach. As a further illustration, the Supplementary Material shows the process of building a new model for a hypothetical decision task. Finally, a detailed user manual and code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/COMPASS">https://github.com/Eden-Kramer-Lab/COMPASS</ext-link>.</p>
<sec id="s1a">
<title>Overview of the state-space toolbox approach</title>
<p>Each step of the COMPASS analysis pipeline is implemented as a high-level function in MATLAB (MathWorks, Natick, MA; <xref ref-type="fig" rid="fig1">Figure 1</xref>). Because these steps are separated and scriptable, they can be configured to explore multiple models on a pilot dataset and determine which fits best before proceeding to hypothesis-driven analyses. The core assumption is that behavior is driven by a (potentially multivariate) cognitive state <italic>X</italic>, which varies over time according to its inherent dynamics and exogenous inputs:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="377556_eqn1.gif"/></alternatives>
</disp-formula></p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1</label>
<caption><p>Pipeline of data analysis in COMPASS. The user manual at (<ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/COMPASS/blob/master/compass_manual_march18_2018.pdf">https://github.com/Eden-Kramer-Lab/COMPASS/blob/master/compass_manual_march18_2018.pdf</ext-link>) describes each of these functions and how to use them.</p></caption>
<graphic xlink:href="377556_fig1.tif"/>
</fig>
<p>That is, at time/trial <italic>k</italic>, the stated will evolve to its next value <italic>X</italic><sub><italic>k</italic>&#x002B;1</sub> based on innate transition dynamics <italic>A</italic> and its responsiveness <italic>B</italic> to an &#x201C;input&#x201D; <italic>U<sub>k</sub></italic>. That evolution is driven by Gaussian noise with covariance equal to <italic>Q</italic>. The parameters for this model (<italic>A, B, Q</italic>) can be assigned by the investigator or inferred from the behavioral data. For instance, by assigning <italic>Q</italic> to have small diagonal elements and <italic>A</italic> to be a diagonal matrix with elements close to 1, we would obtain a state whose components are independent of each other and which will change very little trial-to-trial unless acted upon by <italic>U<sub>k</sub></italic>. This might model a more &#x201C;trait-like&#x201D; process. Making <italic>Q</italic> elements larger would favor a process that changes substantially during an experiment, more &#x201C;state-like&#x201D;. The input <italic>U<sub>k</sub></italic> may represent anything that would impact a subject&#x2019;s performance, including features of the current trial, the outcomes of past trials (e.g., a running total of reward earned or punishments delivered), or the presence/absence of an external manipulation such as a drug or neural stimulation.</p>
<p>We cannot directly observe <italic>X<sub>k</sub></italic>, but we observe its effects on the set of task-related behaviors <italic>Y<sub>k</sub></italic>, which again may include non-conscious &#x201C;behaviors&#x201D; such as a physiologic response. This &#x201C;observation process&#x201D; follows a parametric distribution <italic>g</italic>:
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="377556_eqn2.gif"/></alternatives>
</disp-formula>
where <italic>H<sub>k</sub></italic> represents the past history of the observations up to time <italic>k</italic>, and <italic>I<sub>k</sub></italic>, like <italic>U<sub>k</sub></italic>, may encode any other variables that can influence the behaviors <italic>Y<sub>k</sub></italic> without having a persistent effect on the internal cognitive state <italic>X<sub>k</sub></italic>. An example might be a conflict decision-making task, where trials with higher conflict/difficulty increase reaction times <italic>Y</italic>, but do not change the patient&#x2019;s underlying decisional bias <italic>X</italic>(<xref ref-type="bibr" rid="c26">26</xref>). Many possible <italic>Y</italic> are not normally distributed. Binary choices usually follow a Bernoulli distribution, and both reaction times and physiologic outputs often follow a gamma or log-normal distribution (<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c29">29</xref>). The COMPASS observation model thus allows us to model <italic>Y</italic> using a wide range of parametric distributions <italic>g</italic>, with parameters given by <italic>&#x03B8;</italic>. We assume that <italic>g</italic> and <italic>&#x03B8;</italic> do not vary trial-to-trial, and thus <italic>&#x03B8;</italic> can be estimated directly from the data as with <italic>A, B</italic>, and <italic>Q</italic>. Further, <italic>Y</italic> may be multivariate, as in decision-making tasks where both the decision and the time needed to reach it may be experimentally relevant. In that situation, each element of the vector <italic>Y<sub>k</sub></italic> may have its own distribution, described by a <italic>g /&#x03B8;</italic> pair.</p>
<p>Choosing a model and assessing the goodness-of-fit of that model are critical components of any statistical analysis. Therefore, the toolbox provides a collection of different goodness-of-fit methods to help identify and refine models of the data. These include methods based on the covariance of the estimated parameters and the model deviance/likelihood. The online manual includes an example of those assessments for one of the task examples given below.</p>
<p>Another important analysis issue relates to the common experimental problem of missing data (<xref ref-type="bibr" rid="c30">30</xref>). Some data may be missing at random (MAR), such that the fact that a given datum is missing provides no new information. For example, response recording devices are subject to noise that may obscure some trials, such as muscle artifact in EEG or sensor failure for skin conductance. In such cases, trials with missing data are often removed prior to analysis. In other cases, features of the experiment influence the probability of data being missing. We identify these data as censored, or missing not completely at random. For example, in trial-based behavioral studies, subjects often fail to respond on individual trials within some designated time window, and this may be worse in patients taking psychotropic medications that slow processing. In such cases, it is inadvisable to simply remove trials with missing data, since these trials provide information about behavior. With censored reaction time (RT) data, we know that the subject&#x2019;s RT was larger than a threshold, and this may affect the probability of a correct decision (<xref ref-type="bibr" rid="c28">28</xref>). When fitting a model with COMPASS, each observation in the matrix <italic>Y</italic> may be marked as observed, missing at random, or censored. COMPASS then incorporates this information in its state estimation and model identification processes, using algorithms described in (<xref ref-type="bibr" rid="c28">28</xref>).</p>
</sec>
<sec id="s1b">
<label>Example 1:</label>
<title>Multivariate Associative Learning</title>
<p>Associative learning tasks are one of the most common models used to assess psychiatric deficits (<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c31">31</xref>) and have been well-described using state-space models. In tasks where subjects must learn multiple associations simultaneously (<xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c33">33</xref>), Prerau and colleagues described a method for inferring a single &#x201C;learning state&#x201D; (<xref ref-type="bibr" rid="c25">25</xref>). The learning state variable estimates how well the overall set of associations has been learned, optimally integrating performance over all available stimuli (<xref ref-type="bibr" rid="c25">25</xref>). The Prerau method also infers learning from both correct/incorrect choices and reaction times (RT), maximizing the information extracted from the available data (<xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c35">35</xref>).</p>
<p>We analyzed a sample learning dataset from Williams &#x0026; Eskandar (<xref ref-type="bibr" rid="c32">32</xref>) with both the original Prerau et al. code and an equivalent model set up in COMPASS (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Here, we show an example from one behavior session, comprising 61 trials. On each trial, the subject (a rhesus macaque) attempted to learn/perform an arbitrary association between one of four stimulus pictures and four joystick directions. On 39 of the 61 trials, the subject indicated a choice within the required response window. For this example, the 22 non-response trials are excluded from the analysis. In the COMPASS user manual (see Supplementary Material) we show how to impute responses on non-observed trials. Thus, the behavioral signal processed in the toolbox includes the reaction time and decision over 39 trials (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The complete model is specified in only 10 lines of code, takes less than 20 seconds to run, and shows almost complete overlap with the output of the original authors&#x2019; custom code. We observe an inflection point around trial 15, where the subject&#x2019;s learning state climbs rapidly as associations begin to be performed correctly (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The time to reach this or any other criterion point, or the slope of the learning curve around that point, could be used as a subject-level measurement of learning.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2</label>
<caption><p>Sample learning behavior and learning state estimation using the method of Prerau et al. (<xref ref-type="bibr" rid="c26">26</xref>) and the COMPASS toolbox. (a) Correct (green) and incorrect (red) trial outcomes and reaction times (blue) over the course of a single task block. The behavior shows an abrupt change after 20 trials, with the subject beginning to match most stimuli correctly. The animal learns the task with an accuracy above 90&#x0025; by the end of the trial block; the decision accuracy at the beginning of the block is less than 30&#x0025;. (b) The estimated learning curve using the Prerau code (red) and the COMPASS toolbox (blue). The slight difference between the toolbox and Prerau et al. result relates to the different stopping criterion used in these methods. Prerau&#x2019;s method sets a preset threshold on the likelihood growth and stops when the likelihood growth falls below the threshold. In COMPASS, <italic>compass_em</italic> stops after a user-specified number of iterations.</p></caption>
<graphic xlink:href="377556_fig2.tif"/>
</fig>
</sec>
<sec id="s1c">
<label>Example 2:</label>
<title>Negative Symptoms and Reward Motivation in Schizophrenia</title>
<p>Another major use of computational modeling is to tease out differential sensitivity to reward and loss, as in learning, gambling, and approach-avoidance tasks (<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c36">36</xref>). In one compelling example, Gold et al. (<xref ref-type="bibr" rid="c5">5</xref>) demonstrated this approach in schizophrenia, showing that patients with prominent negative symptoms were impaired at learning from gains, but not from losses. This was reflected in behavioral modeling, where high-negative-symptom patients specifically showed lower values of a model parameter reflecting how well they could compare gain-seeking to loss-avoiding options. The resulting analysis blended two common reinforcement-learning models, &#x201C;actor-critic&#x201D; and &#x201C;Q-learning&#x201D;, with the key parameter being how much each model drove or reflected behavior.</p>
<p>Appendix A shows how each term of the Gold et al. hybrid model can be captured in the state-space framework. In brief, the Gold et al. (<xref ref-type="bibr" rid="c5">5</xref>) task involves learning the correct option in four stimulus-action contingencies. We represent that learning progression by nine state variables; two state variables per contingency to represent the actor-critic learning process and one global state variable that represents the Q-learning process. The overall progress of learning for a given stimulus is given by a weighted combination of the state variables representing the actor-critic and Q-learning processes.</p>
<p>We analyzed a shared dataset, graciously provided by the authors, that is a subset of the original Gold et al. (<xref ref-type="bibr" rid="c5">5</xref>) dataset. On those data, using the Appendix A model, COMPASS replicated the original paper&#x2019;s result. The data comprise 63 study subjects: 26 were healthy controls (HC) and the remaining 37 were clinically stable patients with schizophrenia or schizoaffective disorder. The latter were divided into high negative symptom (HNS, 19 patients) and low negative symptom (LNS, 18 patients) groups. Each subject performed 160 task trials, divided into 4 learning blocks of 40 trials. Behavioral outcomes included response accuracy (correct/incorrect), reaction time, money gained per trial, and trial type (Gain vs. Loss Avoidance).</p>
<p>Gold et al. (<xref ref-type="bibr" rid="c5">5</xref>) reported that HC and LNS subjects were more able to learn from gains than losses, while HNS subjects&#x2019; learning was more influenced by loss. This was reflected empirically in a greater accuracy on Gain than on Loss Avoidance trials (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). It also was reflected in modeling and simulation of patients&#x2019; behavior at the end of task acquisition. When Gold et al. simulated data based on model parameters fit to each individual subject&#x2019;s behavior, HC and LNS subjects were again more able to learn by obtaining gains rather than by avoiding losses (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). We replicated this finding using COMPASS. Subjects&#x2019; behavior on our sample dataset showed the same pattern as in the original paper (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). We then fit subject-level models to that behavior and plotted the individual subjects&#x2019; Gain vs. Loss Avoidance coefficients for accuracy prediction. This replicated the pattern of HC/LNS showing gain sensitivity and HNS showing primarily loss sensitivity (<xref ref-type="fig" rid="fig3">Figure 3d</xref>; Appendix A provides a detailed explanation of the Gold et al. computational model using COMPASS). In fact, the COMPASS modeling result is slightly more faithful to the empirical behavior pattern than the original Gold et al. simulation. The modeled performance of the HNS group (<xref ref-type="fig" rid="fig3">Figure 3d</xref>) is below the X-axis (as it is in the original empirical performance, <xref ref-type="fig" rid="fig3">Figure 3a</xref>), whereas the original simulations of Gold et al. produced mean Gain-Loss difference close to 0 (<xref ref-type="fig" rid="fig3">Figure 3b</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3</label>
<caption><p>Observed (a, c) and simulated (c, d) end acquisition performance across patient and healthy control groups (HC, LNS, HNS). The HC group has a preference for learning from Gains (reward) relative to learning from avoided losses. This preference is reduced in the LNS group and inverted in the HNS group. The performance (&#x0025; Gain accuracy - Loss Avoidance accuracy) is defined as the difference between the probability of picking the correct response on Gain trials and the probability of picking the correct response on the Loss Avoidance trials. (a) Observed performance and (b) simulated end of acquisition performance originally reported in Figure 4A-B of <xref ref-type="bibr" rid="c5">Gold et al. (2012)</xref>. Simulated performance is generated from individual patients&#x2019; estimated model parameters, as described in the original paper. (c) Observed performance in the dataset shared by Gold et al. and (d) simulated result using an equivalent behavior analysis conducted in COMPASS. For (d), we run the equivalent hybrid model - described in Appendix A - per each patient. This gives, for each patient, an estimate (logistic regression coefficient) of the probability of making the correct choice on Gain vs. Loss Avoidance trials. The plot shows the average of these differences for each patient group. The pattern of HC &#x003E; LNS &#x003E; HNS on Gain-Loss Avoidance is replicated. Further, the COMPASS modeling simulation (d) matches the empirical behavior pattern (c) more closely than the original authors&#x2019; simulation.</p></caption>
<graphic xlink:href="377556_fig3.tif"/>
</fig>
</sec>
</sec>
<sec id="s2">
<title>Discussion</title>
<p>We developed an open-source toolbox for state-space modeling and demonstrated its utility in analyzing dynamical behavioral signals relevant to computational psychiatry. In two examples from the learning literature, we showed that COMPASS replicates the results of prior modeling studies. In one of those examples, COMPASS estimated model parameters that more faithfully reproduced empirical results. The state-space modeling framework is a core tool in many research fields, especially engineering (<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c38">38</xref>). It is paving its way into neuroscience, psychiatry, and other medical research (<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c41">41</xref>). COMPASS is the first attempt to provide unified and high-level functions that make a range of state-space models straightforward to implement and use for a wide variety of behavioral signals. Users can build a wide range of models to analyze behavioral data and compare their results in a principled way. A further explanation and guideline for building and comparing model forms can be found in the toolbox manual. The functions <italic>compass_deviance</italic> and <italic>compass_param_covariance_info</italic> enable model comparison. Further, COMPASS includes &#x201C;on-line mode&#x201D; functions that can continuously update state variables in real time as new data are acquired. The toolbox function <italic>compass_filtering</italic> addresses this, and examples of its use are given in the toolbox manual. In on-line operation, one can also call the learning algorithm periodically to re-update model parameters. Thus, COMPASS can also be used to construct experiments with adaptive behavior paradigms, where the stimuli presented to each subject are adjusted based on past performance. This approach could more efficiently sample regions of behavioral interest, e.g. the equipoise boundary of a choice task as modeled in (<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>). It could also drive real-time application of a study intervention, e.g. brain stimulation or optogenetic (in)activation (<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c44">44</xref>).</p>
<p>The state-space modeling framework is not limited to normally distributed signals or discrete binary observations. COMPASS includes methods for highly skewed observation distributions (gamma and log-normal distributions) and for optimally imputing missing/censored data (<xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c28">28</xref>). The distribution assumption is defined by arguments to the <italic>compass_em</italic> function, as are methods for censored data. These additions make COMPASS a powerful and versatile package for analysis of many different classes of dynamical signals. The main limitation of the state-space modeling framework is that prior to now, development and debugging of these models has been difficult. Development requires tedious work and extensive time, and involves statistical and programming skills that are not yet common in the field of cognitive neuroscience. We hope that by providing this toolbox, we can help other researchers delve into computational behavior analysis with a much lower barrier to entry.</p>
</sec>
<sec id="s3">
<title>Financial Disclosures</title>
<p>Dr. Yousefi, Dr. Paulk, Dr. Widge, Dr. Eskandar, Dr. Dougherty, and Dr. Eden have a patent application on &#x201C;System and methods for monitoring and improving cognitive flexibility&#x201D; - WO2017004362 A1. Dr. Dougherty and Dr. Widge reported research support and consulting/honoraria from Medtronic. Dr. Dougherty reported research support from Eli Lilly, Roche, and Cyberonics. Dr. Yousefi reported consulting income from Kernel. Drs. Basu, Eden, Eskandar, and Paulk reported no biomedical financial interests or potential conflicts of interest.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Dr. Jim Gold, Dr. Michael Prerau, and their research teams for providing the data used in this manuscript. This research was funded by the Defense Advanced Research Projects Agency (DARPA) under Cooperative Agreement Number W911NF-14-2-0045 issued by ARO contracting office in support of DARPA&#x2019;s SUBNETS Program. The views, opinions, and/or findings expressed are those of the authors and should not be interpreted as representing the official views or policies of the Department of Defense, the U.S. Government, or any other funder. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Paulus</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Huys</surname>, <given-names>Q. J.</given-names></string-name>, &#x0026; <string-name><surname>Maia</surname>, <given-names>T. V.</given-names></string-name> (<year>2016</year>). <article-title>A Roadmap for the Development of Applied Computational Psychiatry</article-title>. <source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source>, <volume>1</volume>(<issue>5</issue>), <fpage>386</fpage>&#x2013;<lpage>392</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name>, &#x0026; <string-name><surname>Krystal</surname>, <given-names>J. H.</given-names></string-name> (<year>2014</year>). <article-title>Computational Psychiatry</article-title>. <source>Neuron</source>, <volume>84</volume>(<issue>3</issue>), <fpage>638</fpage>&#x2013;<lpage>654</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="book"><string-name><surname>Redish</surname>, <given-names>A. D.</given-names></string-name>, &#x0026; <string-name><surname>Gordon</surname>, <given-names>J. A.</given-names></string-name> (Eds.). (<year>2016</year>). <source>Computational Psychiatry: New Perspectives on Mental Illness</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Widge</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Ellard</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Paulk</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Basu</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Yousefi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zorowitz</surname>, <given-names>S.</given-names></string-name>, &#x2026; &#x0026; <string-name><surname>Kramer</surname>, <given-names>M. A.</given-names></string-name> (<year>2017</year>). <article-title>Treating Refractory Mental Illness with Closed-loop Brain Stimulation: Progress Towards a Patient-specific Transdiagnostic Approach</article-title>. <source>Experimental Neurology</source>, <volume>287</volume>, <fpage>461</fpage>&#x2013;<lpage>472</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Gold</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Waltz</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Matveeva</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Kasanova</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Strauss</surname>, <given-names>G. P.</given-names></string-name>, <string-name><surname>Herbener</surname>, <given-names>E. S.</given-names></string-name>, &#x2026; &#x0026; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name> (<year>2012</year>). <article-title>Negative Symptoms and the Failure to Represent the Expected Reward Value of Actions: Behavioral and Computational Modeling Evidence</article-title>. <source>Archives of General Psychiatry</source>, <volume>69</volume>(<issue>2</issue>), <fpage>129</fpage>&#x2013;<lpage>138</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>J. D.</given-names></string-name>, &#x0026; <string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name> (<year>2015</year>). <article-title>Bridging Levels of Understanding in Schizophrenia Through Computational Modeling</article-title>. <source>Clinical Psychological Science</source>, <volume>3</volume>(<issue>3</issue>), <fpage>433</fpage>&#x2013;<lpage>459</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Voon</surname>, <given-names>V.</given-names></string-name>, &#x0026; <string-name><surname>Fox</surname>, <given-names>S. H.</given-names></string-name> (<year>2007</year>). <article-title>Medication-related Impulse Control and Repetitive Behaviors in Parkinson Disease</article-title>. <source>Archives of Neurology</source>, <volume>64</volume>(<issue>8</issue>), <fpage>1089</fpage>&#x2013;<lpage>1096</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Widge</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Deckersbach</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Eskandar</surname>, <given-names>E. N.</given-names></string-name>, &#x0026; <string-name><surname>Dougherty</surname>, <given-names>D. D.</given-names></string-name> (<year>2016</year>). <article-title>Deep Brain Stimulation for Treatment-Resistant Psychiatric Illnesses: What Has Gone Wrong and What Should We Do Next</article-title>? <source>Biological Psychiatry</source>, <volume>79</volume>(<issue>4</issue>), <fpage>e9</fpage>&#x2013;<lpage>e10</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Insel</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Cuthbert</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Marjorie Garvey MB</surname>, <given-names>B. C. H.</given-names></string-name>, <string-name><surname>Heinssen</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Pine</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Quinn</surname>, <given-names>K.</given-names></string-name>, &#x2026; &#x0026; <string-name><surname>Philip Wang MD</surname>, <given-names>D. R. P. H.</given-names></string-name> (<year>2010</year>). <article-title>Research Domain Criteria (RDoC): Toward a New Classification Framework for Research on Mental Disorders</article-title>. <source>The American Journal of Psychiatry</source>, <volume>167</volume>(<issue>7</issue>), <fpage>748</fpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Doherty</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Hampton</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Kim</surname>, <given-names>H.</given-names></string-name> (<year>2007</year>). <article-title>Model-Based fMRI and Its Application to Reward Learning and Decision Making</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1104</volume>, <fpage>35</fpage>&#x2013;<lpage>53</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Webb</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Dillon</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Pechtel</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Goer</surname>, <given-names>F. K.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Huys</surname>, <given-names>Q. J.</given-names></string-name>, &#x2026; &#x0026; <string-name><surname>Kurian</surname>, <given-names>B. T.</given-names></string-name> (<year>2016</year>). <article-title>Neural Correlates of Three Promising Endophenotypes of Depression: Evidence from the EMBARC Study</article-title>. <source>Neuropsychopharmacology</source>, <volume>41</volume>(<issue>2</issue>), <fpage>454</fpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Cavanagh</surname>, <given-names>J. F.</given-names></string-name> (<year>2015</year>). <article-title>Cortical Delta Activity Reflects Reward Prediction Error and Related Behavioral Adjustments, but at Different Times</article-title>. <source>NeuroImage</source>, <volume>110</volume>, <fpage>205</fpage>&#x2013;<lpage>216</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cole</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Corlett</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name>, &#x0026; <string-name><surname>Krystal</surname>, <given-names>J. H.</given-names></string-name> (<year>2012</year>). <article-title>The Role of Default Network Deactivation in Cognition and Disease</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>16</volume>(<issue>12</issue>), <fpage>584</fpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Huys</surname>, <given-names>Q. J.</given-names></string-name>, <string-name><surname>Maia</surname>, <given-names>T. V.</given-names></string-name>, &#x0026; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name> (<year>2016</year>). <article-title>Computational Psychiatry as a Bridge from Neuroscience to Clinical Applications</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>(<issue>3</issue>), <fpage>404</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Blackford</surname>, <given-names>J. U.</given-names></string-name> (<year>2017</year>). <article-title>Leveraging Statistical Methods to Improve Validity and Reproducibility of Research Findings</article-title>. <source>JAMA Psychiatry</source>, <volume>74</volume>(<issue>2</issue>), <fpage>119</fpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>C. I.</given-names></string-name>, <string-name><surname>Durnez</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Matthews</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Munaf&#x00F2;</surname>, <given-names>M. R.</given-names></string-name>, &#x0026; <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name> (<year>2017</year>). <article-title>Scanning the Horizon: Towards Transparent and Reproducible Neuroimaging Research</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>18</volume>(<issue>2</issue>), <fpage>115</fpage>&#x2013;<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name> (<year>2012</year>). <article-title>FreeSurfer</article-title>. <source>Neuroimage</source>, <volume>62</volume>(<issue>2</issue>), <fpage>774</fpage>&#x2013;<lpage>781</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name> (<year>2012</year>). <article-title>AFNI: What a Long Strange Trip It&#x2019;s Been</article-title>. <source>Neuroimage</source>, <volume>62</volume>(<issue>2</issue>), <fpage>743</fpage>&#x2013;<lpage>747</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Ashburner</surname>, <given-names>J.</given-names></string-name> (<year>2012</year>). <article-title>SPM: a History</article-title>. <source>Neuroimage</source>, <volume>62</volume>(<issue>2</issue>), <fpage>791</fpage>&#x2013;<lpage>800</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Oostenveld</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Schoffelen</surname>, <given-names>J. M.</given-names></string-name> (<year>2011</year>). <article-title>FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data</article-title>. <source>Computational Intelligence and Neuroscience</source>, <volume>2011</volume>, <fpage>1</fpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Luessi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Engemann</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Strohmeier</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Brodbeck</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>). <article-title>MNE Software for Processing MEG and EEG data</article-title>. <source>Neuroimage</source>, <volume>86</volume>, <fpage>446</fpage>&#x2013;<lpage>460</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Ahn</surname>, <given-names>W. Y.</given-names></string-name>, <string-name><surname>Haines</surname>, <given-names>N.</given-names></string-name>, &#x0026; <string-name><surname>Zhang</surname>, <given-names>L.</given-names></string-name> (<year>2017</year>). <article-title>Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Package</article-title>. <source>Computational Psychiatry</source>, <volume>1</volume>, <fpage>24</fpage>&#x2013;<lpage>57</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Helske</surname>, <given-names>J.</given-names></string-name> (<year>2016</year>). <source>KFAS: Exponential Family State Space Models in R</source>. <comment>arXiv preprint arXiv: 1612.01907</comment>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Petris</surname>, <given-names>G.</given-names></string-name>, &#x0026; <string-name><surname>Petrone</surname>, <given-names>S.</given-names></string-name> (<year>2011</year>). <article-title>State Space Models in R</article-title>. <source>Journal of Statistical Software</source>, <volume>41</volume>(<issue>4</issue>), <fpage>1</fpage>&#x2013;<lpage>25</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Prerau</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name>, <string-name><surname>Kubota</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yanike</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Suzuki</surname>, <given-names>W.</given-names></string-name>, .<etal>et al.</etal> (<year>2009</year>). <article-title>Characterizing Learning by Simultaneous Analysis of Continuous and Binary Measures of Performance</article-title>. <source>Journal of Neurophysiology</source>, <volume>102</volume>(<issue>5</issue>), <fpage>3060</fpage>&#x2013;<lpage>3072</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Yousefi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Paulk</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Deckersbach</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Dougherty</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Eskandar</surname>, <given-names>E. N.</given-names></string-name>, <string-name><surname>Widge</surname>, <given-names>A. S.</given-names></string-name>, &#x0026; <string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name> (<year>2015</year>, <month>August</month>). <article-title>Cognitive State Prediction Using an EM Algorithm Applied to Gamma Distributed Data</article-title>. <source>In Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual International Conference of the IEEE</source> (pp. <fpage>7819</fpage>&#x2013;<lpage>7824</lpage>). <comment>IEEE</comment>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Barbieri</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Solo</surname>, <given-names>V.</given-names></string-name>, &#x0026; <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name> (<year>2004</year>). <article-title>Dynamic Analysis of Neural Encoding by Point Process Adaptive Filtering</article-title>. <source>Neural Computation</source>, <volume>16</volume>(<issue>5</issue>), <fpage>971</fpage>&#x2013;<lpage>998</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Yousefi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dougherty</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Eskandar</surname>, <given-names>E. N.</given-names></string-name>, <string-name><surname>Widge</surname>, <given-names>A. S.</given-names></string-name>, &#x0026; <string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name> (<year>2017</year>). <article-title>Estimating Dynamic Signals From Trial Data With Censored Values</article-title>. <source>Computational Psychiatry</source>, <volume>1</volume>, <fpage>58</fpage>&#x2013;<lpage>81</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Palmer</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Horowitz</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Torralba</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Wolfe</surname>, <given-names>J. M.</given-names></string-name> (<year>2011</year>). <article-title>What Are the Shapes of Response Time Distributions in Visual Search?</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>37</volume>(<issue>1</issue>), <fpage>58</fpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="book"><string-name><surname>Little</surname>, <given-names>R. J.</given-names></string-name>, &#x0026; <string-name><surname>Rubin</surname>, <given-names>D. B.</given-names></string-name> (<year>2014</year>). <source>Statistical Analysis with Missing Data</source>. <publisher-name>John Wiley &#x0026; Sons</publisher-name>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Diwadkar</surname>, <given-names>V. A.</given-names></string-name>, <string-name><surname>Flaugher</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Zal&#x00E1;nyi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ujfalussy</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Keshavan</surname>, <given-names>M. S.</given-names></string-name>, &#x0026; <string-name><surname>Erdi</surname>, <given-names>P.</given-names></string-name> (<year>2008</year>). <article-title>Impaired Associative Learning in Schizophrenia: Behavioral and Computational Studies</article-title>. <source>Cognitive Neurodynamics</source>, <volume>2</volume>(<issue>3</issue>), <fpage>207</fpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Williams</surname>, <given-names>Z. M.</given-names></string-name>, &#x0026; <string-name><surname>Eskandar</surname>, <given-names>E. N.</given-names></string-name> (<year>2006</year>). <article-title>Selective Enhancement of Associative Learning by Microstimulation of the Anterior Caudate</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>(<issue>4</issue>), <fpage>562</fpage>&#x2013;<lpage>568</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Katnani</surname>, <given-names>H. A.</given-names></string-name>, <string-name><surname>Patel</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Kwon</surname>, <given-names>C. S.</given-names></string-name>, <string-name><surname>Abdel-Aziz</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gale</surname>, <given-names>J. T.</given-names></string-name>, &#x0026; <string-name><surname>Eskandar</surname>, <given-names>E. N.</given-names></string-name> (<year>2016</year>). <article-title>Temporally Coordinated Deep Brain Stimulation in the Dorsal and Ventral Striatum Synergistically Enhances Associative Learning</article-title>. <source>Scientific Reports</source>, <volume>6</volume>, <fpage>18806</fpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="book"><string-name><surname>Coleman</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Yanike</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Suzuki</surname>, <given-names>W. A.</given-names></string-name>, &#x0026; <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name> (<year>2011</year>). <chapter-title>A Mixed-Filter Algorithm for Dynamically Tracking Learning from Multiple Behavioral and Neurophysiological Measures</chapter-title>. <source>The Dynamic Brain: An Exploration of Neuronal Variability and Its Functional Significance</source>, <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Veit</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Pidpruzhnykova</surname>, <given-names>G.</given-names></string-name>, &#x0026; <string-name><surname>Nieder</surname>, <given-names>A.</given-names></string-name> (<year>2015</year>). <article-title>Associative Learning Rapidly Establishes Neuronal Representations of Upcoming Behavioral Choices in Crows</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>112</volume>(<issue>49</issue>), <fpage>15208</fpage>&#x2013;<lpage>15213</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Bogacz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Moehlis</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Holmes</surname>, <given-names>P.</given-names></string-name>, &#x0026; <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name> (<year>2006</year>). <article-title>The Physics of Optimal Decision Making: a Formal Analysis of Models of Performance in Two-alternative Forced-choice Tasks</article-title>. <source>Psychological Review</source>, <volume>113</volume>(<issue>4</issue>), <fpage>700</fpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Ogata</surname>, <given-names>K.</given-names></string-name>, &#x0026; <string-name><surname>Yang</surname>, <given-names>Y.</given-names></string-name> (<year>1970</year>). <source>Modern Control Engineering, Prentice Hall</source>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Aoki</surname>, <given-names>M.</given-names></string-name> (<year>2013</year>). <article-title>State Space modeling of time series</article-title>. <source>Springer Science &#x0026; Business Media</source>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Barbieri</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>D. P.</given-names></string-name>, <string-name><surname>Quirk</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Solo</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>M. A.</given-names></string-name>, &#x0026; <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name> (<year>2004</year>). <article-title>Dynamic Analyses of Information Encoding in Neural Ensembles</article-title>. <source>Neural Computation</source>, <volume>16</volume>(<issue>2</issue>), <fpage>277</fpage>&#x2013;<lpage>307</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Barbieri</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name> (<year>2010</year>). <article-title>State Space Modeling of Neural Spike Train and Behavioral Data</article-title>. <source>In Statistical Signal Processing for Neuroscience and Neurotechnology</source> (pp. <fpage>175</fpage>&#x2013;<lpage>218</lpage>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ahmadian</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Ferreira</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Koyama</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rad</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Vidne</surname>, <given-names>M.</given-names></string-name>, &#x2026; &#x0026; <string-name><surname>Wu</surname>, <given-names>W.</given-names></string-name> (<year>2010</year>). <article-title>A New Look at State-Space Models for Neural Data</article-title>. <source>Journal of Computational Neuroscience</source>, <volume>29</volume>(<issue>1-2</issue>), <fpage>107</fpage>&#x2013;<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Amemori</surname>, <given-names>K. I.</given-names></string-name>, <string-name><surname>Amemori</surname>, <given-names>S.</given-names></string-name>, &#x0026; <string-name><surname>Graybiel</surname>, <given-names>A. M.</given-names></string-name> (<year>2015</year>). <article-title>Motivation and Affective Judgments Differentially Recruit Neurons in the Primate Dorsolateral Prefrontal and Anterior Cingulate Cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>(<issue>5</issue>), <fpage>1939</fpage>&#x2013;<lpage>1953</lpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Karmali</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Chaudhuri</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Yi</surname>, <given-names>Y.</given-names></string-name>, &#x0026; <string-name><surname>Merfeld</surname>, <given-names>D. M.</given-names></string-name> (<year>2016</year>). <article-title>Determining Thresholds Using Adaptive Procedures and Psychometric Fits: Evaluating Efficiency Using Theory, Simulations, and Human Experiments</article-title>. <source>Experimental Brain Research</source>, <volume>234</volume>(<issue>3</issue>), <fpage>773</fpage>&#x2013;<lpage>789</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Grosenick</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Marshel</surname>, <given-names>J. H.</given-names></string-name>, &#x0026; <string-name><surname>Deisseroth</surname>, <given-names>K.</given-names></string-name> (<year>2015</year>). <article-title>Closed-loop and Activity-guided Optogenetic Control</article-title>. <source>Neuron</source>, <volume>86</volume>(<issue>1</issue>), <fpage>106</fpage>&#x2013;<lpage>139</lpage>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<label>Appendix A</label>
<title>Reformulating the Hybrid Learning Model Using the State-Space Modeling Framework</title>
<p>Gold et al&#x2019;s. goal was to provide a quantitative fit to the pattern of data observed in patients and healthy controls. They investigated both a standard Actor-Critic architecture and a Q-learning architecture. They argue that neither taken alone could account qualitatively for both healthy control and patient data. They thus investigated a mixture model of Actor-Critic and Q-learning, which led to better qualitative and quantitative fits for all groups and explained key features of the data. The actor-critic model uses reward prediction errors to modify the probability of selecting an action, while the Q-learning model predicts sensitivity to actual outcome values. That is, Q-learning is more focused on maximizing total value, and therefore predicts that subjects will choose a high chance of gain over a high chance of avoiding a loss. Actor-critic would value those two choices equally, because they have similar chances for prediction error. Given that different patient groups showed a mixture of these strategies in responding to the task, the hybrid model should be able to better account for observed results in patients and healthy subjects.</p>
<p>Here, we show how the model of Gold et al. (<xref ref-type="bibr" rid="c5">5</xref>) can be implemented using the state-space modeling framework and thus the COMPASS toolbox. <xref ref-type="table" rid="tblA1">Table A.1</xref> shows a line-by-line comparison between two models. Here, we focus on the Hybrid model proposed in the paper. The pure actor-critic or Q-learning processes are special cases of this model with parameter <italic>c</italic> (see below) set to 0 or 1, respectively.</p>
<table-wrap id="tblA1" orientation="portrait" position="float">
<label>Table A.1</label>
<caption><p>Hybrid model of actor-critic and Q-learning and its equivalent state-space model</p></caption>
<graphic xlink:href="377556_tblA1.tif"/>
</table-wrap>
<p>The model is cast in terms of the trial type &#x2013; <italic>s</italic> &#x2013; and the possible actions within that trial type &#x2013; <italic>a. a</italic> can be seen as picking one of two actions, where a correct action on the gain trials corresponds to picking the item associated with winning the reward. The correct action on the loss-avoidance trials corresponds to picking the item that is not associated with a penalty. Note that we only need to represent one of these two actions per category with a state variable; this is because not taking an action implies that the other action is being taken. We assign two state variables to each task&#x2019;s category to represent the value of being in a state and of taking action 1 during that state. That is, we need <italic>x</italic><sub><italic>s</italic><sub>1</sub></sub> and <italic>x</italic><sub><italic>a</italic><sub>1</sub><italic>s</italic><sub>1</sub></sub> to present the probability of the stimulus being category 1 and the probability of taking the action <italic>a</italic> when in category 1. We assign one state variable to represent the global value of taking action 1 across all possible states/trial types &#x2013; <italic>x</italic><sub><italic>a</italic><sub>1</sub></sub> (<italic>k</italic>). Now, we can define the state-transition process for the task by (note that action <italic>a</italic><sub>1</sub> will be common across states):
<disp-formula id="eqnA1">
<alternatives><graphic xlink:href="377556_eqnA1.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnA2">
<alternatives><graphic xlink:href="377556_eqnA2.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnA3">
<alternatives><graphic xlink:href="377556_eqnA3.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnA4">
<alternatives><graphic xlink:href="377556_eqnA4.gif"/></alternatives>
</disp-formula>
where, <italic><sub>s<sub>i</sub></sub></italic> is an indicator function which is 1 when the current trial type corresponds to stimulus category <italic>i</italic>. In <xref ref-type="disp-formula" rid="eqnA1">equation (A.1.c)</xref>, the probability of taking each action is defined as a function of the learning, captured in the vector <italic>X<sub>k</sub></italic>. <italic>X<sub>k</sub></italic> represents both actor-critic and Q-learning values - the first 8 entries describe actor-critic learning for each trial type, while the 9<sup>th</sup> element represents the global Q-learning process that focuses solely on the action regardless of the trial type. As Gold et al. did, we represent the relative weight of these two learning processes (actor-critic and Q-learning) through a mixing parameter <italic>c.</italic> Using the Logit function defined in (A.1.d), the probability of taking action <italic>a</italic><sub>1</sub> is defined by <italic>c x</italic><sub><italic>a</italic><sub>1</sub></sub>(<italic>k</italic>) in the absence of the actor-critic model. The probability of taking action <italic>a</italic><sub>1</sub> when presented with trial type <italic>s</italic><sub>1</sub>, in the actor-critic model, is defined by (1 &#x2013; <italic>c</italic>)<italic>x</italic><sub><italic>a</italic><sub>1</sub><italic>s</italic><sub>1</sub></sub>(<italic>k</italic>). The overall probability of taking action <italic>a</italic><sub>1</sub> when presented with <italic>s</italic><sub>1</sub> is thus defined by <italic>c x</italic><sub><italic>a</italic><sub>1</sub></sub>(<italic>k</italic>) &#x002B; (1 &#x2013; <italic>c</italic>)<italic>x</italic><sub><italic>a</italic><sub>1</sub><italic>s</italic><sub>1</sub></sub>(<italic>k</italic>). We can similarly define the probability of both actions for the other 3 trial types. Given the model definition, an increase in <italic>x</italic><sub><italic>a</italic><sub>1</sub></sub>(<italic>k</italic>) implies a global preference for <italic>a</italic><sub>1</sub> in all trial types, while an increase in <italic>x</italic><sub><italic>a</italic><sub>1</sub><italic>s</italic><sub>1</sub></sub>(<italic>k</italic>) implies a specific preference for <italic>a</italic><sub>1</sub> when presented with <italic>s</italic><sub>1</sub>.</p>
<p>The model of <xref ref-type="table" rid="tblA1">Table A.1</xref> translates directly into MATLAB code, as shown in <xref ref-type="fig" rid="figA1">Figure A1</xref>. This close mapping between model specification and computer code makes COMPASS easier to use and interpret.</p>
<fig id="figA1" position="float" fig-type="figure">
<label>Figure A.1</label>
<caption><p>Analysis script for the hybrid learning task</p></caption>
<graphic xlink:href="377556_figA1.tif"/>
</fig>
<p>In the script, RATE&#x005F;A and RATE&#x005F;B define initial values for <italic>w<sub>v,s<sub>i</sub></sub></italic> and <italic>w</italic><sub><italic>c,s</italic><sub><italic>i</italic></sub><italic>a</italic><sub>1</sub></sub> <italic>i</italic> &#x003D; 1 &#x00B7;&#x00B7;&#x00B7; 4. RATE&#x005F;C defines an initial value for <italic>w</italic><sub><italic>q</italic>, <italic>a</italic><sub>1</sub></sub>. The initial values for RATE&#x005F;A, RATE&#x005F;B, and RATE&#x005F;C are set to 0.1. This setting defines initial values for elements of <italic>A</italic> and <italic>B</italic> matrices, which defines how new reward information are combined with the previous estimation of state variables. The optimal values for <italic>w<sub>v,s<sub>i</sub></sub></italic>, <italic>w</italic><sub><italic>c,s</italic><sub><italic>i</italic></sub><italic>a</italic><sub>1</sub></sub> and <italic>w</italic><sub><italic>q,a</italic><sub>1</sub></sub> are smaller than 1 and preferably close to zero, if the values for the critics&#x2019; weights and values dynamics (<bold><xref ref-type="table" rid="tblA1">Table A.1</xref></bold>) reasonably replicate the task participant behavior. As a result, we initialize these parameters with a small number and then allow the E-M algorithm to drive them to their optimal values. The <italic>c</italic> parameter, defined in (A.1.d), is set to 0.5 in the script and then updated by being learned from each subject&#x2019;s data. We define a covariance matrix for <italic>W<sub>k</sub></italic> using <italic>Param. Wk</italic>. This is set to be a diagonal matrix with a small variance, because the terms are independent of each other and there is an overall assumption that we can predict behavior accurately if these variables are known. Values of <italic>Param.Ek</italic> are set to either 0 or 0.5; it is set 0 for index 1, 3, 5, and 7 and it is set to 0.5 for index 2, 4, 6, 8 and 9. Note that <italic>Param.Ek</italic> is fixed and it is not adjusted in <italic>compass_em.</italic> The settings suggest that a mixture model (actor-critic and learning) is being trained in the model. If we set <italic>Param.Ek</italic>(<xref ref-type="bibr" rid="c9">9</xref>) to 0, we then have a model solely based on actor-critic. If we set all elements of <italic>Param.Ek</italic> zero except <italic>Param.Ek</italic>(<xref ref-type="bibr" rid="c9">9</xref>), we then build a model based on Q-learning. The input vectors <italic>Ib</italic> and <italic>Uk</italic> represent the stimulus information and obtained reward on each trial for the subject being analyzed.</p>
<p>The behavioral signal analyzed in Gold et al. is solely the action &#x2013; or decision &#x2013;taken on each trial. However, there is also a reaction time signal, which might carry extra information about the learning evolution or attribute, as in the Prerau et al. papers discussed in section 4. For instance, we might expect to see a shorter reaction time as the correct actions are learned and the subject gains confidence in his/her decisions. It would be straightforward to add reaction time to the model as a function of the learning variables, <italic>X<sub>k</sub></italic>, or to add the previous decision outcome as a history term. We can define how the reaction time is linked to the model state variables or input in the function <italic>compass&#x005F;create&#x005F;state&#x005F;space</italic>, and pass both continuous and discrete inputs to the <italic>compass&#x005F;em</italic> routine. We can also define how parameters of the reaction time model will be trained using <italic>compass&#x005F;set&#x005F;learning&#x005F;param</italic>. We even can define the censoring criteria if some data points are censored due to long response times, <italic>compass&#x005F;set&#x005F;censor&#x005F;threshold&#x005F;proc&#x005F;mode</italic>.</p>
</app>
</app-group>
</back>
</article>