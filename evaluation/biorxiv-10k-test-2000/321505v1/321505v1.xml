<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/321505</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Animal Behavior and Cognition</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Learning list concepts through program induction</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Rule</surname>
<given-names>Joshua</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Schulz</surname>
<given-names>Eric</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Piantadosi</surname>
<given-names>Steven T.</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Tenenbaum</surname>
<given-names>Joshua B.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology</institution></aff>
<aff id="a2"><label>2</label><institution>Department of Psychology, Harvard University</institution></aff>
<aff id="a3"><label>3</label><institution>Department of Brain and Cognitive Sciences, University of Rochester</institution></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>&#x002A;</label><p>Contributed equally</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>321505</elocation-id>
<history>
<date date-type="received">
<day>13</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>13</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>14</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="321505.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Humans master complex systems of interrelated concepts like mathematics and natural language. Previous work suggests learning these systems relies on iteratively and directly revising a language-like conceptual representation. We introduce and assess a novel concept learning paradigm called <italic>Martha&#x2019;s Magical Machines</italic> that captures complex relationships between concepts. We model human concept learning in this paradigm as a search in the space of term rewriting systems, previously developed as an abstract model of computation. Our model accurately predicts that participants learn some transformations more easily than others and that they learn harder concepts more easily using a bootstrapping curriculum focused on their compositional parts. Our results suggest that term rewriting systems may be a useful model of human conceptual representations.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Concept learning</kwd>
<kwd>Program Induction</kwd>
<kwd>Induction</kwd>
<kwd>Function learning</kwd>
<kwd>Curriculum learning</kwd>
<kwd>Bootstrap learning</kwd>
</kwd-group>
<counts>
<page-count count="6"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Human learning is astonishing, quickly mastering complex systems of interrelated concepts using surprisingly little data (<xref ref-type="bibr" rid="c24">Tenenbaum, Kemp, Griffiths, &#x0026; Goodman, 2011</xref>). Understanding what concepts are and how humans learn them has thus long been a key challenge for cognitive science (<xref ref-type="bibr" rid="c3">Bruner, Goodnow, &#x0026; Austin, 1956</xref>; <xref ref-type="bibr" rid="c4">Carey, 2009</xref>; <xref ref-type="bibr" rid="c13">Margolis &#x0026; Laurence, 1999</xref>, <xref ref-type="bibr" rid="c14">2015</xref>; <xref ref-type="bibr" rid="c16">Murphy, 2002</xref>; <xref ref-type="bibr" rid="c22">Smith &#x0026; Medin, 1981</xref>). The challenge remains open, but this work builds on the hypotheses that: 1) concepts can be modeled as expressions in a mental language or Language of Thought (LOT; e.g. <xref ref-type="bibr" rid="c7">Fodor, 1975</xref>); and 2) learning iteratively refines the LOT both by naming compositions of smaller parts and developing truly new representations (e.g. <xref ref-type="bibr" rid="c4">Carey, 2009</xref>).</p>
<p>Computational models have long worked to implement these hypotheses using algorithms that learn program-like structures from observations (<xref ref-type="bibr" rid="c8">Goodman, Tenenbaum, Feldman, &#x0026; Griffiths, 2008</xref>; <xref ref-type="bibr" rid="c11">Lake, Salakhutdinov, &#x0026; Tenenbaum, 2015</xref>; <xref ref-type="bibr" rid="c12">Lenat, 1983</xref>; <xref ref-type="bibr" rid="c17">Newell, Shaw, &#x0026; Simon, 1959</xref>; <xref ref-type="bibr" rid="c20">Piantadosi, Tenenbaum, &#x0026; Goodman, 2016</xref>; <xref ref-type="bibr" rid="c23">Sussman, 1973</xref>), a technique known as inductive programming (<xref ref-type="bibr" rid="c6">Flener &#x0026; Schmid, 2008</xref>; <xref ref-type="bibr" rid="c15">Muggleton &#x0026; De Raedt, 1994</xref>), part of the broader field of program synthesis (<xref ref-type="bibr" rid="c9">Gulwani, Polozov, &#x0026; Singh, 2017</xref>). The language in which learning takes place is typically fixed: primitives cannot be added or removed and each primitive has a predetermined semantics, often based on combinatory logic (CL; <xref ref-type="bibr" rid="c5">Dechter, Malmaud, Adams, &#x0026; Tenenbaum, 2013</xref>; <xref ref-type="bibr" rid="c18">Piantadosi, 2017</xref>), &#x03BB;-calculus (LC; <xref ref-type="bibr" rid="c19">Piantadosi, Tenenbaum, &#x0026; Goodman, 2012</xref>), or first-order logic (FOL; <xref ref-type="bibr" rid="c8">Goodman et al., 2008</xref>; <xref ref-type="bibr" rid="c20">Piantadosi et al., 2016</xref>; <xref ref-type="bibr" rid="c25">Ullman, Goodman, &#x0026; Tenenbaum, 2012</xref>). Learning searches through the (potentially infinite) space of programs in the language to find some to name and add to a library of expressions that help explain observations. This library acts as an inductive bias sitting on top of the base language, but crucially, the base language itself never changes.</p>
<p>Humans undoubtedly reuse existing concepts, but they also introduce placeholder concepts that acquire meaning through conceptual role (<xref ref-type="bibr" rid="c2">Block, 1987</xref>; <xref ref-type="bibr" rid="c4">Carey, 2009</xref>). This is especially important as the scope of learning grows and primitives for one domain (e.g. color concepts like <italic>red</italic> or <italic>blue</italic>) work poorly in another (e.g. Newtonian mechanics). Rather than only revising a <italic>library</italic> implemented in terms of some fixed language, human learning is thus thought to also revise the <italic>language</italic> itself. Models learning libraries over fixed languages cannot easily capture this second type of learning.</p>
<p>This paper makes two contributions toward resolving this discrepancy. The first contribution is to introduce and assess a novel concept learning paradigm called <italic>Martha&#x2019;s Magical Machines</italic>, inspired by <xref ref-type="bibr" rid="c20">Piantadosi et al. (2016)</xref>. This paradigm uses a game that lends itself well to studying complex relationships between concepts and which participants report to be fun and engaging. Participants predict how machines, each representing a concept, transform sequences of numbered packages. Using this paradigm, we find that some concepts are learned more easily than others and that a hard concept is learned more easily when preceded by a bootstrapping compositional curriculum.</p>
<p>The second contribution is to explore Term Rewriting Systems (TRSs) as a model of conceptual representations. TRSs define a space of formal languages, specifying for each which primitives exist and how they behave. We use this to provide a model of concept learning similar to and inspired by existing models, but in which hypotheses represent not different libraries atop a fixed LOT but completely different LOTs. We model learning as a search directly among languages defined by a probabilistic grammar over TRS rules. Other work has learned TRSs to solve inductive programming tasks (e.g. <xref ref-type="bibr" rid="c10">Kitzelmann &#x0026; Schmid, 2006</xref>; <xref ref-type="bibr" rid="c21">Rao, 2004</xref>), but ours is the first, to our knowledge, to directly compare a TRS-based learning system with humans. Our model accurately predicts human learning trajectories for different list concepts and explains how a curriculum helps when learning challenging concepts.</p>
<p>Concepts come in diverse forms (e.g. objects, agents, magnitudes, categories and kinds, relationships, and events). Here, we focus on and use <italic>concept</italic> to refer to relationships over objects, specifically, functions over data structures. It would be surprising if these techniques failed to apply to other types of concepts, but we do not explore that here.</p>
</sec>
<sec id="s2">
<label>Experiment 1:</label>
<title>Mapping the order of difficulty</title>
<p>Experiment 1 studied how people learn concepts from examples. In this experiment, participants sequentially predicted how a concept would transform an input sequence into an output sequence. To better understand what sorts of concepts are easy or difficult for humans to learn, we created a set of 12 list concepts of varying complexity (see <xref ref-type="fig" rid="figS1">Listing 1</xref>).</p>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>listing 1:</label><caption><title>Rewrite rules for the concepts in Experiment 1. See <xref ref-type="table" rid="tbl1">Table 1</xref> for an explanation of the assumed background concepts.</title></caption>
<graphic xlink:href="321505_figS1.tif"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Background concepts used in the simulations. In the descriptions, <italic>x</italic> is the first argument, <italic>y</italic> the second, and <italic>z</italic> the third.</p></caption>
<graphic xlink:href="321505_tbl1.tif"/>
</table-wrap>
<p><bold>Participants and Design</bold> We recruited 149 participants (61 female, mean age &#x003D; 36.93, SD &#x003D; 12.20) from Amazon Mechanical Turk. Participants were paid a flat fee of &#x0024;1. The experiment took 16 minutes on average to complete.</p>
<p><bold>Materials and Procedure</bold> Participants played a game called <italic>Martha&#x2019;s Magical Machines</italic> inspired by the paradigm in <xref ref-type="bibr" rid="c20">Piantadosi et al. (2016)</xref>. They helped a scientist, Martha (<xref ref-type="fig" rid="fig1">Fig. 1a</xref>), study magical machines. Magical machines (e.g. <xref ref-type="fig" rid="fig1">Fig. 1b</xref>) take numbered packages (i.e. a sequence of numbers) as input and return numbered packages as output (<xref ref-type="fig" rid="fig1">Fig. 1c</xref>). Participants were asked to predict outputs for different inputs. Each participant interacted with five magical machines, one in each of five rounds. For each participant round, we uniformly sampled a concept from a pool of twelve (see <xref ref-type="fig" rid="figS1">Listing 1</xref>) without replacement. If the sampled concept returned a single natural number rather than a sequence, participants saw a singleton sequence. Within each round, participants completed 10 consecutive trials sampled randomly without replacement from a pool of per-concept inputs.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label><caption><title>Experiment graphics. a: Martha, the scientist. b: A magical machine. c: Packages display 0&#x2013;9. d: Participants predicted outputs (right side) for different inputs (left side). &#x002B; makes another package appear. Right-clicks remove packages. d: Input/output history. P shows past predictions. Try it at: <ext-link ext-link-type="uri" xlink:href="https://git.io/vNbKc">https://git.io/vNbKc</ext-link>.</title></caption>
<graphic xlink:href="321505_fig1.tif"/>
</fig>
<p>On each trial, participants saw a sequence of one to five packages waiting to be submitted to the machine (<xref ref-type="fig" rid="fig1">Fig. 1d</xref>) and attempted to predict the machine&#x2019;s corresponding output sequence. After clicking <italic>Test</italic>, the input would be submitted to the machine and the actual output produced. The history of inputs, outputs, and participants&#x2019; responses was displayed next to the machine (<xref ref-type="fig" rid="fig1">Fig. 1e</xref>). Once a participant submitted 10 predictions for a machine, they were asked to briefly describe what they thought the machine did, and then moved to the next round to interact with a new (visually distinct) machine. The game finished after 5 rounds (i.e. 5 machines).</p>
<p><bold>Results</bold> <xref ref-type="fig" rid="fig2">Figure 2</xref> shows mean performance on the last 5 predictions for each block. Participants generally performed best for concepts involving arithmetical operations (e.g. total, increment). These concepts are likely already well-known; learning then means recognizing that a particular machine matches a pre-existing concept. We treat this recognition as a simple form of induction, one which identifies a newly-named concept with a pre-existing name rather than a newly-discovered compositional expression. Concepts indexing the sequence (e.g. index-in-head, head-or-tail) were generally harder to learn. Mean within-participant performance on the first 5 trials strongly correlated with performance during the last 5 trials over all rounds (<italic>r</italic> (148) &#x003D; 0.80, <italic>p</italic> &#x003C; .001); some people consistently learned the concepts faster than others. Performance weakly correlated with round number (<italic>r</italic> (148) &#x003D; 0.04, <italic>p</italic> &#x003D; .019), but more strongly correlated with trial number within a round (<italic>r</italic> (148) &#x003D; 0.36, <italic>p</italic> &#x003C; .001). Mean scores on the first 5 trials were indeed significantly different from mean scores on the last 5 trials over all problems (<italic>t</italic> (149) &#x003D; 22.04, <italic>p</italic> &#x003C; .001, <italic>d</italic> &#x003D; 1.8).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label><caption><title>Experiment 1 performance with concepts ordered by difficulty. Error bars represent the standard error of the mean. <bold>Left:</bold> Average probability of a successful prediction over the last 5 trials. Red triangles mark model predictions. <bold>Right:</bold> Average quality of concept descriptions (0: no match; 2: perfect description).</title></caption>
<graphic xlink:href="321505_fig2.tif"/>
</fig>
<p>Participants learned the concepts, and additional trials led to better performance. We thus analyzed how performance evolved over trials using per-concept learning curves that we also compare to the learning curves produced by our model (<xref ref-type="fig" rid="fig3">Fig 3</xref>). For some concepts (e.g. total, const), participants only needed 1&#x2013;2 examples to perform near ceiling. Other concepts (e.g. length or filter odd) show more graded, even slow (e.g. count3, index-in-head) progress. Nonetheless, we found significant positive correlations between trial number and performance for all problems (all <italic>p</italic> &#x003C; .001, <italic>d f</italic> &#x003D; 149); participants learn the concepts in this task, improving their performance over time for every concept tested.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label><caption><title>Experiment 1 concept learning curves ordered from easy to difficult. Error bars represent the standard error. Solid curves are human learners, dashed are model learners. Pearson correlations between human and model learners are reported for each concept.</title></caption>
<graphic xlink:href="321505_fig3.tif"/>
</fig>
<p>We also analyzed the verbal descriptions given for each concept. Descriptions were coded as 0 if they did not reflect the concept (e.g. &#x201C;it&#x2019;s random&#x201D;, &#x201C;I don&#x2019;t know&#x201D;), 1 for partial correctness (e.g. &#x201C;removes frequent numbers&#x201D; for deduplicate) and 2 for an exact match (e.g. &#x201C;removes duplicates&#x201D; for deduplicate). <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the average quality of participant descriptions by concept. Description codes correlate strongly with performance on the last 5 trials (<italic>r</italic> (148) &#x003D; 0.84, <italic>p</italic> &#x003C; .001), suggesting that participants generated good predictions primarily by referencing the underlying concepts rather than by guessing or using other heuristics.</p>
<p>Finally, we analyzed whether the order in which participants learned concepts influenced overall performance. We compared the correlations between the block in which a concept appeared and mean performance for the 3 hardest (count3, head-or-tail, index-in-head) and 3 easiest (const, total, increment) concepts. Block and performance were significantly correlated for the hard concepts (<italic>r</italic> (149) &#x003D; 0.13, <italic>p</italic> &#x003C; .01), but not for the easiest concepts (<italic>r</italic> (149) &#x003D; 0.04. <italic>p</italic> &#x003D; .24). The difference between these correlations was significant (<italic>z</italic> &#x003D; 2.07, <italic>p</italic> &#x003C; .05). Participants thus might benefit by reserving harder problems for later rounds of the experiment, an effect which we explore by examining how curriculum design affects performance in Experiment 2.</p>
</sec>
<sec id="s3">
<label>Experiment 2:</label>
<title>Curriculum learning</title>
<p>Experiment 2 studied to what extent a difficult concept could be made more learnable with a curriculum from which learners could bootstrap the difficult concept.</p>
<p><bold>Participants and Design</bold> We recruited 91 participants (46 males, mean age &#x003D; 34.51, SD &#x003D; 10.57) from Amazon Mechanical Turk and paid a flat fee of &#x0024;1. The task took 12 minutes on average to complete. Participants were randomly assigned to one of two conditions (<italic>random</italic> or <italic>curriculum</italic>) in a between-subjects design. Random learners attempted three randomly chosen concepts before attempting the target concept. Curriculum learners attempted concepts (count3, head, &#x0026; tail) relevant to the compositional structure of the target. Both groups had the same target concept: count-head-in-tail.</p>
<p><bold>Material and Procedure</bold> Participants played <italic>Martha&#x2019;s Magical Machines</italic> as in Experiment 1. However, whereas curriculum learners saw three fixed concepts (order counter-balanced; <xref ref-type="fig" rid="figS2">Listing 2</xref>) before attempting the target concept, random learners interacted with three randomly chosen concepts from Experiment 1 (matched in complexity and excluding the curriculum; <xref ref-type="fig" rid="figS1">Listing 1</xref>) before attempting the target concept.</p>
<fig id="ufig1" position="anchor" orientation="portrait" fig-type="figure">
<graphic xlink:href="321505_ufig1.tif"/>
</fig>
<fig id="figS2" position="float" orientation="portrait" fig-type="figure">
<label>listing 2:</label><caption><title>Rewrite rules for the concepts in Experiment 2. See <xref ref-type="table" rid="tbl1">Table 1</xref> for an explanation of the assumed background concepts.</title></caption>
<graphic xlink:href="321505_figS2.tif"/>
</fig>
<p><bold>Results</bold> We first analyzed performance during the last 5 trials of the target concept (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>). Curriculum learners performed significantly better than random learners (<italic>t</italic> (89) &#x003D; 3.02, <italic>p</italic> &#x003C; 0.01, <italic>d</italic> &#x003D; 0.34). We again coded the quality of participant descriptions for the target concept, using the scheme from Experiment 1. Curriculum learners wrote better descriptions than random learners (<italic>t</italic> (89) &#x003D; 2.51, <italic>p</italic> &#x003D; 0.01, <italic>d</italic> &#x003D; 0.53, <xref ref-type="fig" rid="fig4">Fig. 4b</xref>), although both scored weakly. More curriculum learners scored 1 or 2 than random learners (&#x03C7;<sup>2</sup>(2,91) &#x003D; 8.46, <italic>p</italic> &#x003D; .01). Six participants correctly described the concept; four were curriculum learners. Of 19 participants with partially correct descriptions, 15 were curriculum learners. 66 participants were completely incorrect; 38 were random learners. Participant learning curves during the last round (<xref ref-type="fig" rid="fig4">Fig. 4c</xref>) suggest that curriculum learners learned faster and more accurately than random learners, in particular during later trials. Finally, we analyzed how the first three rounds affected performance in the target round. Curriculum learners should be influenced more strongly by past performance, because the curriculum concepts are relevant to the target concept. Performance on the first three rounds correlated significantly with performance on the target round for curriculum learners (<italic>r</italic> (49) &#x003D; 0.53 <italic>p</italic> &#x003C; .001), but not for random learners (<italic>r</italic> (38) &#x003D; 0.23, <italic>p</italic> &#x003D; .08); only curriculum learners benefited by learning earlier concepts.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label><caption><title>Experiment 2, by condition. a: mean number of correct predictions during last 5 trials. b: Average description quality for last round. c: Learning curves (i.e. mean proportion of correct predictions over trials). d: Standardized b-estimate regressing total correct predictions in the first 3 rounds onto total correct predictions in the target round. Error bars represent the standard error.</title></caption>
<graphic xlink:href="321505_fig4.tif"/>
</fig>
</sec>
<sec id="s4">
<title>Model</title>
<p>Instead of searching over possible libraries for a fixed LOT, some theories suggest that humans search directly over possible LOTs (e.g. <xref ref-type="bibr" rid="c4">Carey, 2009</xref>). We discuss Term Rewriting Systems (TRSs) as a formalism for modeling this idea, treating learning as searching through a space of TRSs defined by a probabilistic grammar over TRS rules. Model code is available at: <ext-link ext-link-type="uri" xlink:href="http://git.io/vNbK6">http://git.io/vNbK6</ext-link>.</p>
<p><bold>Representing Concepts with Term Rewriting Systems</bold> TRSs, developed and studied as an abstract model of computation, formalize the idea that symbolic forms of computation can be described by trees of symbols, called terms, and rules for how those terms compute. Other work describes TRSs in detail (<xref ref-type="bibr" rid="c1">Bezem, Klop, &#x0026; de Vrijer, 2003</xref>); we focus on applications to cognitive modeling.</p>
<p>A TRS has two parts: a set of operators (symbols with a fixed arity) called a <italic>signature</italic>, and a set of <italic>rewrite rules</italic>. In this work, each operator is also associated with a type to constrain search, preventing constructions which humans would be unlikely to consider (e.g. computing the successor of a list rather than of a number). For example, we could define an operator for addition, plus, with arity 2 and type Nat &#x2013;&#x003E; Nat &#x2013;&#x003E; Nat (take two natural numbers, Nats, as input and give a Nat as output). Other examples include the number 0, 0, with arity 0 and type Nat, and the successor function, succ, with arity 1 and type Nat &#x2013;&#x003E; Nat. Combined with a countably infinite set of unique variables (written here with trailing underscores), the signature recursively defines the set of possible terms to include: 1) variables; and 2) operators applied to <italic>n</italic> subterms, where <italic>n</italic> is the arity of the operator. A simple theory of unary addition might have the following signature:</p>
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="321505_eqn1.gif"/></alternatives>
</disp-formula>
<p>In that case, the following are valid (&#x2217;invalid) terms. Assuming that plus represents addition, s represents the successor function, and 0 represents 0, the valid terms represent 0, 2, and <italic>x</italic> &#x002B; 1 &#x002B; <italic>y</italic>, respectively; invalid terms mean nothing:<disp-formula id="eqn2"><alternatives><graphic xlink:href="321505_eqn2.gif"/></alternatives>
</disp-formula></p>
<p>A rewrite rule, <italic>l</italic> &#x003D; <italic>r</italic>, equates terms <italic>l</italic> and <italic>r</italic>, called the <italic>left-hand-side</italic> (LHS) and <italic>right-hand-side</italic> (RHS), respectively. A term <italic>t</italic> can be rewritten to <italic>t</italic> <sup>&#x2032;</sup> under some TRS if: 1) <italic>t</italic> matches against the LHS of a TRS rule to create a substitution (a structural mapping from variables in the LHS to subterms of <italic>t</italic>); and 2) <italic>t</italic> <sup>&#x2032;</sup> is the result of applying the substitution to the RHS. Consider these rules for unary addition:<disp-formula id="eqn3"><alternatives><graphic xlink:href="321505_eqn3.gif"/></alternatives></disp-formula>plus(succ(succ(0)) succ(0)) rewrites with these rules to succ(succ(succ(0))) as follows (i.e. 2&#x002B;1 &#x003D; 3):<disp-formula id="eqn4">
<alternatives><graphic xlink:href="321505_eqn4.gif"/></alternatives></disp-formula></p>
<p>See <xref ref-type="fig" rid="figS1">Listings 1</xref> &#x0026; 2 for more examples of rewrite rules.</p>
<p>When using TRSs to model LOTs, each term expresses a (potentially compositional) concept; the signature defines the space of possible terms and thus the space of possible expressions. By themselves, however, these expressions are nearly meaningless. succ(succ(succ(0))), for example, might express 3, a procedure for shaking someone&#x2019;s hand, or a picture of a cat. Relating terms with rewrite rules constrains their meaning. succ(succ(succ(0))) expresses 3 (or something isomorphic to 3) only when coupled with rules that <italic>use</italic> it as 3. In the toy example given here, it expresses 3 only with respect to addition. As additional operators and rules are added which constrain its behavior more tightly, its meaning can be further constrained to that of the familiar concept 3.</p>
<p><bold>Learning Concepts with Stochastic Search</bold> Like many existing models of concept learning as program induction, we model learning as a Bayesian stochastic search (<xref ref-type="bibr" rid="c11">Lake et al., 2015</xref>; <xref ref-type="bibr" rid="c19">Piantadosi et al., 2012</xref>,1; <xref ref-type="bibr" rid="c25">Ullman et al., 2012</xref>). To ease search, we fixed the set of operators and provided rules constraining the behavior of several background concepts (<xref ref-type="table" rid="tbl1">Table 1</xref>). The hypothesis space is then the space of TRSs containing these operators and at least these rules. Crucially, however, the behavior of key operators in each simulation was entirely determined by learned rewrite rules. Search thus directly revises our LOT representation, rather than revising a library implemented in terms of some fixed LOT.</p>
<p>Our model uses a description length prior; the log prior probability of a TRS is the total number of subterms in the rules. It uses an evaluation-based likelihood; the log likelihood of an input/output pair is the log probability of the output appearing as a normal form in a 50-step evaluation trace rooted at the input. Search uses two types of proposals; one deletes a rule uniformly at random from the hypothesis, and the other samples a new rule and adds it to the hypothesis.</p>
<p>We sample new rules using a generative procedure that relies heavily on types. It first creates a type variable to represent the type of the rule. It then unifies this type variable against existing operators and variables, as well as a newly created variable (though the LHS cannot be a lone variable; such a rule would match every term). Of those elements whose types unify, one is selected uniformly at random. If the element is an operator with positive arity, the argument types are computed, and the process recurses. Once the LHS has been sampled, its final type is computed, and the RHS is sampled using the same process, with two modifications: 1) RHS sampling can use variables bound by the LHS but cannot create new variables (this would allow rewrites to invent arbitrary terms); and 2) the type of the RHS is fixed to match the type of the LHS. This procedure defines and samples from a context-sensitive (the set of variables changes during sampling) grammar over rewrite rules.</p>
<p><bold>Simulation Details</bold> The simulations mimic Experiments 1 and 2 (See <xref ref-type="table" rid="tbl1">Table 1</xref> for the assumed primitives). Each simulation for Experiment 1 (2) began by running search for 1500 (500) iterations as described above. The likelihood was initially computed over an empty dataset (i.e. search was sensitive only to the prior). After 1500 (500) iterations, the top ten posterior hypotheses were evaluated on the first input, and the most likely output returned as the prediction. After the model had made its prediction, the correct input/output pair was added to the model&#x2019;s dataset, and another round of search began, using this extended dataset when computing the likelihood of each hypothesis. Inputs were sampled from a generative model of natural number lists, and outputs were computed by evaluating a ground-truth implementation of the function on the sampled input. The number of iterations for this new round was changed to 150&#x0025;(3/2) of the previous round&#x2019;s iterations if an incorrect prediction was recorded and to 67&#x0025;(2/3) for a correct prediction, mimicking patterns of cautiousness and confidence in human subjects. This pattern repeated until 10 responses had been recorded (i.e. maximum dataset size &#x003D; 9). Thirty simulations were run for each concept, simulating 30 unique subjects. Any learning effects that might appear in Experiment 1 due to a randomly sampled but nonetheless useful curriculum are being ignored here. Also, unlike human participants, the simulation setup allowed us to distinguish between outputs that were natural numbers and outputs that were singleton lists; we thus did not require the model to convert natural number outputs into singleton lists.</p>
<p><bold>Results</bold> Our Experiment 1 simulations captured the difficulty of learning across concepts, predicting mean human performance with a mean correlation of (<italic>r</italic> (11) &#x003D; 0.73, <italic>p</italic> &#x003C;.001, <xref ref-type="fig" rid="fig2">Fig 2</xref>). Importantly, our model produces averaged learning curves that correlated strongly with participant learning curves (<italic>r</italic> &#x003D; 0.78 <italic>p</italic> &#x003C; .001, <xref ref-type="fig" rid="fig3">Fig 3</xref>). The partial correlation between model predictions and participant learning curves, controlled for the simple baseline of linear improvement over time, was <italic>r</italic> &#x003D; 0.42 with <italic>p</italic> &#x003C; .01, suggesting that our model produces human-like behavior for Experiment 1, even when compared to a baseline model with a constant learning rate.</p>
<p>Our Experiment 2 simulations suggest a similar conclusion. Mean simulation performance was significantly higher for the curriculum condition than the random condition (30 runs, 2 conditions tracking up to 10 most likely hypotheses, <italic>t</italic> (590) &#x003D; 5.25, <italic>p</italic> &#x003C; .001, <italic>d</italic> &#x003D; 0.43, <xref ref-type="fig" rid="fig4">Fig 4a</xref>). Curriculum condition simulations discovered correct implementations of count-head-in-tail in 9 out of 30 runs; random condition simulations succeeded in just 1 of 30 runs. These results suggest that our model helps account for the benefit of a bootstrapping curriculum in learning difficult concepts.</p>
</sec>
<sec id="s5">
<title>Discussion &#x0026; Conclusion</title>
<p>We modeled human concept learning as program induction. Our model searches directly in the space of LOTs (here, Term Rewriting Systems) rather than in the space of libraries defined over a single, fixed LOT as is common in other program-induction-based models. This shift is small, but showing that this approach can explain traditional concept learning tasks sets the stage for future work. Conceptual change, whereby a learner abandons one primitive basis in favor of another, is a key component of learning (<xref ref-type="bibr" rid="c4">Carey, 2009</xref>). Library-learning models, however, cannot easily model conceptual change; their primitive basis&#x2013;the underlying language&#x2013;is fixed. Searching directly over languages, as in the model discussed here, is more appropriate. In this initial and exploratory work, the identity of the primitives and much of their semantics were fixed. Future work must extend the model so that it can introduce placeholder primitives, infer their types, and quickly relate them to existing primitives to constrain their meaning.</p>
<p>We also introduced <italic>Martha&#x2019;s Magical Machines</italic> as a paradigm for studying list concepts. We intend to develop this paradigm to better explore what makes concepts easy or hard to learn and how curricula can better bootstrap difficult concepts. We also plan to explore active learning in this paradigm, giving participants control over which inputs to test to better understand what they find informative. Our findings suggest that the rich structure of list concepts provides a versatile domain for studying concept learning in humans. Other richly structured domains, including commonsense theories (e.g. Mendelian genetics, number grammars) and textual manipulations (e.g. 12 January 2009 &#x2192; 09/01/12), may also be interesting to explore in this paradigm.</p>
<p>Achieving these objectives will require sophisticated search strategies which better exploit available data and the program-like structure of conceptual representations. Effective strategies for manipulating computer programs may be similar to strategies which human learners use to manipulate program-like concepts in the mind; it may be useful to explore the strategies programmers use when actually programming. Learning-to-learn strategies, allowing the programmer to learn more efficaciously over time, are of particular interest. Our models, like humans, should not only learn to model the world around them, but they ought to simultaneously improve the language they use to describe those models and the tools by which both are learned.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>JR and JBT are supported by the Center for Minds, Brains and Machines (CBMM), funded by NSF STC award CCF-1231216, and a grant from the Air Force Office of Scientific Research. JR is supported by an NSF Graduate Research Fellowship. ES is supported by the Harvard Data Science Initiative.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="book"><string-name><surname>Bezem</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Klop</surname>, <given-names>J. W.</given-names></string-name>, &#x0026; <string-name><surname>de Vrijer</surname>, <given-names>R.</given-names></string-name> (<year>2003</year>). <source>Term rewriting systems</source>. <publisher-name>Cambridge U. Press</publisher-name>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Block</surname>, <given-names>N.</given-names></string-name> (<year>1987</year>). <article-title>Advertisement for a semantics for psychology</article-title>. <source>Midwest Studies in Philosophy</source>, <volume>10</volume> (<issue>1</issue>), <fpage>615</fpage>&#x2013;<lpage>678</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="book"><string-name><surname>Bruner</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Goodnow</surname>, <given-names>J. J.</given-names></string-name>, &#x0026; <string-name><surname>Austin</surname>, <given-names>G. A.</given-names></string-name> (<year>1956</year>). <source>A study of thinking</source>. <publisher-name>Science Editions</publisher-name>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="book"><string-name><surname>Carey</surname>, <given-names>S.</given-names></string-name> (<year>2009</year>). <source>The origin of concepts</source>. <publisher-name>Oxford U. Press</publisher-name>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="other"><string-name><surname>Dechter</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Malmaud</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>R. P.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2013</year>). <chapter-title>Bootstrap learning via modular concept discovery</chapter-title>. In <source>IJCAI</source>, (pp. <fpage>1302</fpage>&#x2013;<lpage>1309</lpage>).</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Flener</surname>, <given-names>P.</given-names></string-name>, &#x0026; <string-name><surname>Schmid</surname>, <given-names>U.</given-names></string-name> (<year>2008</year>). <article-title>An introduction to inductive programming</article-title>. <source>AI Review</source>, <volume>29</volume> (<issue>1</issue>), <fpage>45</fpage>&#x2013;<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="book"><string-name><surname>Fodor</surname>, <given-names>J. A.</given-names></string-name> (<year>1975</year>). <source>The language of thought</source>. <publisher-name>Harvard U. Press</publisher-name>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Feldman</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name> (<year>2008</year>). <article-title>A rational analysis of rule-based concept learning</article-title>. <source>Cognitive Science</source>, <volume>32</volume> (<issue>1</issue>), <fpage>108</fpage>&#x2013;<lpage>154</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Gulwani</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Polozov</surname>, <given-names>O.</given-names></string-name>, &#x0026; <string-name><surname>Singh</surname>, <given-names>R.</given-names></string-name> (<year>2017</year>). <article-title>Program synthesis</article-title>. <source>Foundations and Trends in Programming Languages</source>, <volume>4</volume> (<issue>1&#x2013;2</issue>).</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Kitzelmann</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Schmid</surname>, <given-names>U.</given-names></string-name> (<year>2006</year>). <article-title>Inductive synthesis of functional programs: An explanation based generalization approach</article-title>. <source>J. Machine Learning Research</source>, <volume>7</volume>, <fpage>429</fpage>&#x2013;<lpage>454</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Lake</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Salakhutdinov</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2015</year>). <article-title>Human-level concept learning through probabilistic program induction</article-title>. <source>Science</source>, <volume>350</volume> (<issue>6266</issue>), <fpage>1332</fpage>&#x2013;<lpage>1338</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Lenat</surname>, <given-names>D. B.</given-names></string-name> (<year>1983</year>). <article-title>EURISKO: A program that learns new heuristics and domain concepts&#x2013;the nature of heuristics III: Program design and results</article-title>. <source>AI</source>, <volume>21</volume>, <fpage>61</fpage>&#x2013;<lpage>98</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><string-name><surname>Margolis</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Laurence</surname>, <given-names>S.</given-names></string-name> (<year>1999</year>). <source>Concepts: core readings</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="book"><string-name><surname>Margolis</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Laurence</surname>, <given-names>S.</given-names></string-name> (<year>2015</year>). <source>The conceptual mind: new directions in the study of concepts</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Muggleton</surname>, <given-names>S.</given-names></string-name>, &#x0026; <string-name><surname>De Raedt</surname>, <given-names>L.</given-names></string-name> (<year>1994</year>). <article-title>Inductive logic programming: Theory and methods</article-title>. <source>J. of Logic Programming</source>, <volume>19</volume>, <fpage>629</fpage>&#x2013;<lpage>679</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="other"><string-name><surname>Murphy</surname>, <given-names>G. L.</given-names></string-name> (<year>2002</year>). <chapter-title>The big book of concepts (bradford books)</chapter-title>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Newell</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Shaw</surname>, <given-names>J. C.</given-names></string-name>, &#x0026; <string-name><surname>Simon</surname>, <given-names>H. A.</given-names></string-name> (<year>1959</year>). <article-title>Report on a general problem solving program</article-title>. In <source>IFIP Congress</source>, <volume>vol. 256</volume>,(p. <fpage>64</fpage>).</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Piantadosi</surname>, <given-names>S. T.</given-names></string-name> (<year>2017</year>). <article-title>The computational origin of representation and conceptual change</article-title>. <source>under revision</source>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Piantadosi</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2012</year>). <article-title>Bootstrapping in a language of thought: A formal model of numerical concept learning</article-title>. <source>Cognition</source>, <volume>123</volume> (<issue>2</issue>), <fpage>199</fpage>&#x2013;<lpage>217</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Piantadosi</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2016</year>). <article-title>The logical primitives of thought: Empirical foundations for compositional cognitive models</article-title>. <source>Psych. Review</source>, <volume>123</volume> (<issue>4</issue>), <fpage>392</fpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="book"><string-name><surname>Rao</surname>, <given-names>M. K.</given-names></string-name> (<year>2004</year>). <chapter-title>Inductive inference of term rewriting systems from positive data</chapter-title>. In <source>International Conference on Algorithmic Learning Theory</source>, (pp. <fpage>69</fpage>&#x2013;<lpage>82</lpage>). <publisher-name>Springer</publisher-name>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="book"><string-name><surname>Smith</surname>, <given-names>E. E.</given-names></string-name>, &#x0026; <string-name><surname>Medin</surname>, <given-names>D. L.</given-names></string-name> (<year>1981</year>). <source>Categories and concepts</source>. <publisher-name>Harvard U. Press</publisher-name>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="other"><string-name><surname>Sussman</surname>, <given-names>G. J.</given-names></string-name> (<year>1973</year>). <chapter-title>A computational model of skill acquisition</chapter-title>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Kemp</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &#x0026; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name> (<year>2011</year>). <article-title>How to grow a mind: Statistics, structure, and abstraction</article-title>. <source>Science</source>, <volume>331</volume> (6022), <fpage>1279</fpage>&#x2013;<lpage>1285</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Ullman</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2012</year>). <article-title>Theory learning as stochastic search in the language of thought</article-title>. <source>Cognitive Development</source>, <volume>27</volume> (<issue>4</issue>), <fpage>455</fpage>&#x2013;<lpage>480</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>