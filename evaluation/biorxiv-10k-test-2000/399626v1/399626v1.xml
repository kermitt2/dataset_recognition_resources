<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/399626</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Laminar Segregation of Sensory Coding and Behavioral Readout in Macaque V4</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Pettine</surname>
<given-names>Warren W.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7029-2908</contrib-id>
<name>
<surname>Steinmetz</surname>
<given-names>Nicholas A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3345-2930</contrib-id>
<name>
<surname>Moore</surname>
<given-names>Tirin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Neurobiology and Howard Hughes Medical Institute, Stanford University School of Medicine</institution>, Stanford CA 94305</aff>
</contrib-group>
<author-notes>
<corresp id="cor1">Correspondence to: Tirin Moore, Department of Neurobiology, Fairchild Bldg., Campus Drive West Stanford University, Stanford CA, 94305</corresp>
<fn id="n1" fn-type="present-address"><label>1</label><p>Current address: Center for Neural Science, New York University, 4 Washington Pl #809, New York, NY 10003</p></fn>
<fn id="n2" fn-type="present-address"><label>2</label><p>Current address: University College, London, The Cruciform Building, Gower Street, London WC1E 6AE</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>399626</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>8</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>24</day>
<month>8</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>8</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="399626.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Summary</title>
<p>Neurons in sensory areas of the neocortex are known to represent information both about sensory stimuli and behavioral state, but how these two disparate signals are integrated across cortical layers is poorly understood. To study this issue, we measured the coding of visual stimulus orientation and of behavioral state by neurons within superficial and deep layers of area V4 in monkeys while they covertly attended or prepared eye movements to visual stimuli. We show that single neurons and neuronal populations in superficial layers convey more information about the orientation of visual stimuli, whereas single neurons and neuronal populations in deep layers convey greater information about the behavioral relevance of those stimuli. In particular, deep layer neurons encode greater information about the direction of prepared eye movements. These results reveal a division of labor between laminae in the coding of visual input and visually guided behavior.</p>
</abstract>
<counts>
<page-count count="30"/>
</counts>
</article-meta>
<ack>
<title>Acknowledgements.</title>
<p>This work was supported by NEI grant EY014924 to T.M., a National Science Foundation graduate fellowship to N.A.S., and an HHMI medical research fellowship to W.W.P. We thank S. Hyde for valuable assistance with animal care, and B. Schneeveis for designing and building the 3D electrode angler.</p>
</ack>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Visual area V4 comprises an intermediate processing stage in the primate visual hierarchy<sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c2" ref-type="bibr">2</xref></sup>. V4 neurons exhibit selectivity to color<sup><xref rid="c3" ref-type="bibr">3</xref>,<xref rid="c4" ref-type="bibr">4</xref></sup>, orientation<sup><xref rid="c5" ref-type="bibr">5</xref>,<xref rid="c6" ref-type="bibr">6</xref></sup>, and contour<sup><xref rid="c7" ref-type="bibr">7</xref>,<xref rid="c8" ref-type="bibr">8</xref></sup>, and appear to be segregated according to some of these properties across the cortical surface<sup><xref rid="c9" ref-type="bibr">9</xref></sup>. Distinct from their purely sensory properties, V4 neurons are also known to encode information about behavioral and cognitive factors, particularly covert attention<sup><xref rid="c10" ref-type="bibr">10</xref></sup>, but also reward value<sup><xref rid="c11" ref-type="bibr">11</xref></sup>, and the direction of planned saccadic eye movements<sup><xref rid="c12" ref-type="bibr">12</xref>&#x2013;<xref rid="c14" ref-type="bibr">14</xref></sup>. As with other neocortical areas, V4 is organized by a characteristic laminar structure, in which granular Layer 4 neurons receive feedforward sensory input from hierarchically &#x2018;lower&#x2019; visual cortical areas, namely area V1 and V2<sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c15" ref-type="bibr">15</xref>&#x2013;<xref rid="c17" ref-type="bibr">17</xref></sup>. Projections from area V4 to hierarchically &#x2018;higher&#x2019; visual areas, such as TEO and posterior inferotemporal (IT) cortex, originate largely from layers II-III <sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c18" ref-type="bibr">18</xref></sup>, whereas layer 5 neurons project back to V1 and V2 and subcortically to the superior colliculus<sup><xref rid="c18" ref-type="bibr">18</xref>&#x2013;<xref rid="c20" ref-type="bibr">20</xref></sup>.</p>
<p>Recent studies have found laminar differences in attention-related modulation of neural activity. <xref ref-type="bibr" rid="c21">Buffalo et al., (2011)</xref><sup><xref rid="c21" ref-type="bibr">21</xref></sup> observed that changes in LFP power due to the deployment of covert attention differed between superficial and deep layers; gamma-band increases were found in superficial layers and alpha-band decreases were found in deep layers. Increases in firing rate with attention were observed to be similar in both laminar divisions. <xref ref-type="bibr" rid="c22">Nandy et al. (2017)</xref><sup><xref rid="c22" ref-type="bibr">22</xref></sup> compared attention-driven changes in spiking activity across three laminar compartments of V4 and observed significant firing rate modulation in superficial, granular and deep layers. In addition, they observed subtle, but reliable, differences in other aspects of activity across layers (e.g. spike count correlations). However, no previous studies have compared stimulus tuning properties, or looked for differences in other types of behavioral modulation across layers.</p>
<p>To investigate the layer dependence of stimulus and behavioral modulation in area V4, we measured the selectivity of V4 neurons to both factors in monkeys performing an attention-demanding task that dissociated covert attention from eye movement preparation. We then compared orientation tuning and behavioral modulation in superficial and deep layer individual units, and populations.</p>
</sec>
<sec id="s2">
<title>Results and Discussion</title>
<p>Two monkeys (G and B) were trained to perform an attention-demanding task<sup><xref rid="c23" ref-type="bibr">23</xref></sup> that required them to detect orientation changes in one of four peripheral oriented grating stimulus patches while maintaining central fixation (<xref rid="fig1" ref-type="fig">Figure 1a</xref>; see Experimental Procedures)<sup><xref rid="c12" ref-type="bibr">12</xref></sup>. Upon detection of a change, monkeys were rewarded for saccadic eye movements to the patch opposite the orientation change. Both monkeys performed well above chance. We recorded the activity of 698 units (277 single-units and 421 multi-units) at 421 sites using 16-channel linear array electrodes while monkeys performed the task. Electrodes were delivered perpendicular, or nearly perpendicular, to the cortical surface as guided by magnetic resonance imaging, and confirmed by receptive field (RF) alignment (<xref rid="fig1" ref-type="fig">Figure 1b</xref>). In each recording session, data from the 16 electrode channels were assigned laminar depths, relative to a common current source density (CSD) marker (<xref rid="fig1" ref-type="fig">Figure 1c</xref>, see Methods).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Behavioral task and perpendicular recordings in area V4.</title>
<p>A) Panels depict phases of the attention task, and lower left dashed circle denote RF position of recorded neurons, and was not seen by subjects. Receptive fields of recorded neurons was always in the lower left, as indicated by the dashed circle outline. Task began with fixation at a central fixation point. Following fixation, randomly oriented Gabor gratings appeared at four positions. After an additional period, a cue (white diagonal line) appeared near the fixation point and indicated which grating was the target. A blank period followed in which the gratings disappeared, and then the stimuli reappeared on the screen with the target presented either at the same orientation or at a new orientation. Monkeys were rewarded for making saccadic eye movements to the stimulus opposite the changed target (arrow) or for maintaining fixation when the orientation did not change. B) Colored contours and corresponding dots respectively show the RF borders and RF centers mapped at electrode channels across difference cortical depths for an example V4 recording. C) Example current source density (CSD) with alignment feature for the two monkey subjects. The delineation between superficial and deep layers is indicated by the gray line.</p></caption>
<graphic xlink:href="399626_fig1.tif"/>
</fig>
<sec id="s2a">
<title>Orientation Selectivity</title>
<p>We first examined the proportion of units exhibiting significant orientation tuning and compared that proportion across layers (see Methods). Overall, 63.75&#x0025; (445/698; P &#x003C; 0.001) of units were significantly tuned for stimulus orientation (<xref rid="fig2" ref-type="fig">Figure 2a</xref>). Of these, we found that a significantly higher proportion of superficial units (74.9&#x0025;) were tuned compared to deep units (58.3&#x0025;; Chisquared, P = 9.7&#x00D7;10<sup>-6</sup>). Next, we fit Gaussian functions to the normalized mean firing rates elicited by the eight orientations for each of the 698 units (<xref rid="fig2" ref-type="fig">Figure 2b</xref>, see Methods). Across superficial and deep layers, 35.5&#x0025; (248) of units were well-fit (R<sup>2</sup> &#x003E; 0.7). Among the well-fit units, 98 were recorded in superficial layers (36.6&#x0025; of superficial units) and 150 were recorded in deep layers (35&#x0025; of deep neurons). These proportions were not significantly different from each other (Chi-squared, P &#x003E; 0.05). Comparing fit parameters, we observed no significant differences in width or baseline between superficial and deep layers (width, superficial = 0.84, deep = 0. 67, P &#x003E; 0.05; baseline, superficial = 0.10, deep = 0.10, P &#x003E; 0.05). However, the mean amplitude of superficial layer units was significantly greater than that of deep layer units (superficial = 0.17; deep = 0.13; P = 0.0179).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Orientation tuning in superficial and deep layers of area V4.</title>
<p>A) Left, distribution of tuned units (red) among total units recorded (black) across cortical depth, relative to the superficial/deep CSD border. Right, the same data plotted as a proportion. B) Average Gaussian tuning fits, and definitions of fit parameters, for superficial (green) and deep (blue) neurons. Line thicknesses denote &#x00B1;SEM. C) Left, performance of a Random Forest classifier at decoding stimulus orientation across different population sizes of superficial (green) and deep blue) neurons, along with shuffled controls for both (red and purple). Points indicate median values, and bars indicate the SEM for the 100 decoder cycles at each size. Solid lines indicate the fit saturating function. Right, multidimensional scaling (MDS) of classification for one cycle at the maximum population size (210 neurons). Each color/shape combination is associated with a unique orientation. Inset depicts the same MDS analysis after shuffling stimulus orientation labels.</p></caption>
<graphic xlink:href="399626_fig2.tif"/>
</fig>
<p>Measurements of orientation tuning in individual units indicate that superficial layer units in our dataset were better tuned to stimulus orientation than their deep layer counterparts. However, we considered that these measurements might not capture all of the information conveyed about stimulus orientation. We therefore took a population decoding approach<sup><xref rid="c24" ref-type="bibr">24</xref></sup> to measure the information available about orientation in the activity of all units within superficial or deep layers (see Methods). Decoder performance was computed as a function of neuronal population size. We then fit a &#x201C;neuron-dropping&#x201D; curves (NDCs)<sup><xref rid="c25" ref-type="bibr">25</xref></sup> to the values, and compared the confidence intervals of the fit parameters for slope (b) and asymptote (c) for superficial and deep populations. Both superficial and deep units performed significantly above chance for all population sizes greater than zero. The NDS curve for superficial populations had a significantly greater slope (superficial b = 0.03071, 95&#x0025; CI: 0.03002, 0.0314; deep b = 0.01976, 95&#x0025; CI: 0.01925, 0.02026), and asymptotic performance was about 7&#x0025; higher than deep units (superficial, c = 0.9622, 95&#x0025; CI: 0.9597, 0.9647; deep, c = 0. 8969, 95&#x0025; CI: 0.8931, 0.9008). Thus, as with the single-unit analysis, we found that stimulus orientation was more accurately encoded by populations of superficial layer neurons.</p>
<p>The robust differences in orientation selectivity we observed between the superficial and deep layer units raise important questions, such as whether those differences result simply from the known compartmentalization of orientation versus color tuning across V4<sup><xref rid="c9" ref-type="bibr">9</xref></sup>. However, even if we had oversampled one compartment or the other (e.g. more color compartments), doing so would not be expected to introduce an overall bias between upper and lower layers. It is also worth noting that since the primary evidence of feature-specific compartments in V4 comes from optical imaging, where much of the signal derives from superficial layers<sup><xref rid="c26" ref-type="bibr">26</xref></sup>, those compartments may be less well-defined within infragranular layers. Indeed, anatomical evidence indicates that intrinsic horizontal connections in V4, which appear to reciprocally connect columns across millimeters of cortex, exist predominantly in superficial layers, similar to earlier (e.g., V1, V2) and later stages of visual cortex<sup><xref rid="c27" ref-type="bibr">27</xref></sup>.</p>
<p>Second, our results raise the important question of whether the selectivity to other features, e.g. color or contour, is also greater in superficial layers. For example, substantial previous evidence suggests that neurons in V4 are unique in the computation of stimulus contour, not orientation, the former deriving from the orientation-specific input they receive from V1 and V2<sup><xref rid="c7" ref-type="bibr">7</xref>,<xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c28" ref-type="bibr">28</xref>,<xref rid="c29" ref-type="bibr">29</xref></sup>. In such a case, our observations within orientation selectivity might not generalize to all other types of selectivity. Instead, the results might only generalize to features computed at earlier stages. Nonetheless, our results reveal the importance of assessing the laminar dependence of stimulus selectivity across visual cortex.</p>
</sec>
<sec id="s2b">
<title>Coding of Eye Movement Preparation and Covert Attention</title>
<p>We next examined activity across superficial and deep layers when monkeys covertly attended the visual stimulus, prepared a saccade to that stimulus, or ignored it. We first compared the average modulation for individual neuronal recordings made at varying laminar depths aligned to the superficial/deep boundary (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). Overall, modulation across depth was significantly greater during eye movement preparation than during covert attention (P = 0.0024), a result we reported previously<sup><xref rid="c10" ref-type="bibr">10</xref></sup>. However, we observed no significant main effect of depth (P &#x003E; 0.05), or an interaction of attention type and depth (P &#x003E; 0.05). Nonetheless, movement-related modulation appeared to peak within the deep layers, suggesting that the difference in attention type was due to greater eye movement modulation in those layers. Thus, we directly compared the magnitude of modulation in the two attention types collapsed within superficial or deep layers. This revealed that while there was no significant difference in modulation in superficial layers (P &#x003E; 0.05), saccade modulation was significantly greater within deep layers (P = 0.0041).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Behavioral modulation in superficial and deep layers of V4.</title>
<p>A) Modulation indices across cortical depth. Individual medians and SEMs are plotted at each depth for covert attention (yellow) and saccade preparation (red), along with the total number of units recorded (grey). Depths with fewer than five neurons were removed. B) Performance of Random Forest decoder at distinguishing between the three behavioral conditions (covert attention, saccade preparation or control) from superficial and deep neurons, as a function of neuronal population size. C) Performance of the decoder at distinguishing between pairs of conditions: (top) saccade preparation from control; (middle) saccade preparation from covert attention; (bottom) covert attention from control.</p></caption>
<graphic xlink:href="399626_fig3.tif"/>
</fig>
<p>Next, as with stimulus orientation, we decoded the behavioral condition using population activity from superficial (277 units) or deep (419 units) layers (<xref rid="fig3" ref-type="fig">Figure 3b</xref>), and classified activity as occurring during covert attention, saccade preparation, or control trials. The performance of decoding deep populations was significantly greater than superficial at all populations of &#x003E;30 units. Although the slopes of the NDS fits were not significantly different, (superficial b = 0.01918, 95&#x0025; CI: 0.01842, 0.01993; deep b = 0.01849, 95&#x0025; CI: 0.01773, 0.01925), the asymptotic performance for deep units exceeded that of superficial units by more than 5&#x0025; (superficial, c = 0.6073, 95&#x0025; CI: 0.6053, 0.6092; deep, c = 0.6534, 95&#x0025; CI: 0.6509, 0.6559). Thus, the behavioral condition was more accurately encoded by populations of deep layer units.</p>
<p>To investigate the conditions driving performance, we then conducted pairwise decoding of attentional conditions (<xref rid="fig3" ref-type="fig">Figure 3c</xref>). When decoding covert attention versus control, we found that although the NDC slope for deeper populations was greater than that of superficial populations, (superficial b = 0.01974, 95&#x0025; CI: 0.01882, 0.02066; deep b = 0.02671, 95&#x0025; CI: 0.0255, 0.02792), asymptotic performances were not significantly different (superficial, c = 0.7565, 95&#x0025; CI: 0.7544, 0.7586; deep, c = 0.758, 95&#x0025; CI: 0.7564, 0.7596). In decoding saccade preparation versus covert attention, we found a greater slope for superficial layer units, (superficial b = 0.01739, 95&#x0025; CI: 0.01646, 0.01832; deep b = 0.01446, 95&#x0025; CI: 0.01361, 0.01531), but a greater asymptotic performance for deep layer populations (superficial, c = 0.7475, 95&#x0025; CI: 0.7448, 0.7503; deep, c = 0.7785, 95&#x0025; CI: 0.7745, 0.7825). Lastly, when decoding saccade preparation versus control, we found that although the slopes were not significantly different, (superficial b = 0.02765, 95&#x0025; CI: 0.02639, 0.02891; deep b = 0.0286, 95&#x0025; CI: 0.02714, 0.03006), the asymptotic performance was &#x223C;3&#x0025; greater for deep units (superficial, c = 0.7295, 95&#x0025; CI: 0.7282, 0.7308; deep, c = 0.7651, 95&#x0025; CI: 0.7634, 0.7668). Thus, coding of attentional state, covert or overt, was greatest for units in the deep layers, where eye movement preparation was most strongly encoded.</p>
<p>Few studies have examined the influence of motor preparation on the responses of neurons in visual cortex, yet it is nonetheless clear that visually driven activity is affected by impending eye movements at many stages of the primate visual system<sup><xref rid="c30" ref-type="bibr">30</xref>&#x2013;<xref rid="c33" ref-type="bibr">33</xref></sup>. Moreover, we have shown previously<sup><xref rid="c12" ref-type="bibr">12</xref></sup>, and in the present study, that the movement-related modulation of V4 activity is not only dissociable from modulation by covert attention, but it is more reliable. Those findings are consistent with the hypothesis that visual cortical areas contribute directly to visually guided saccades, particularly the refinement of saccadic plans according to features coded by particular visual areas (e.g. shape in area V4)<sup><xref rid="c34" ref-type="bibr">34</xref>&#x2013;<xref rid="c36" ref-type="bibr">36</xref></sup>.</p>
<p>Our observation of stronger eye movement-related modulation in deep layers is also consistent with the fact that projections to the superior colliculus emanate principally from layer V pyramidal neurons throughout extrastriate visual cortex<sup><xref rid="c37" ref-type="bibr">37</xref></sup>. Moreover, deep layer neurons are a major source of feedback projections<sup><xref rid="c1" ref-type="bibr">1</xref></sup>, and thus the relative robustness of behavioral signals within deep layers may reflect the projection of those signals to earlier stages of visual processing. Consistent with this notion, a previous study of attentional effects in areas V1, V2 and V4 found evidence of a &#x201C;backward&#x201D; progression of modulation in these areas that begins in V4 and proceeds to V1<sup><xref rid="c21" ref-type="bibr">21</xref></sup>. Thus, the unique contributions of deep layer neurons to oculomotor output and in top-down influences may account for their superior coding of behavioral variables.</p>
</sec>
</sec>
<sec id="s3">
<title>Conclusion</title>
<p>We observed significantly greater orientation selectivity among units within the superficial layers of V4 using both tuning measures in single neurons and decoding of population activity. In contrast, using both single-unit and population activity, we observed that deeper layers conveyed more information about the behavioral relevance of visual stimuli. In particular, we found that neurons within deep layers conveyed more information than superficial neurons about the planning of saccadic eye movements. These results suggest a division of labor between superficial and deep layer neurons in the feedforward processing of stimulus features and the application of sensory information to behavior.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Subjects, Behavioral task, Visual Stimuli and Neuronal Recordings</title>
<p>Details of the subjects, the task, the stimuli and recording techniques are described in <sup><xref rid="c12" ref-type="bibr">12</xref></sup>. In brief, two male rhesus macaques were surgically implanted with recording chambers. Monkeys were trained on an attention task that dissociated covert attention from saccade preparation. Trials were initiated when the monkey fixated a central point. After 100 ms of central fixation, a 300-500ms &#x201C;stimulus epoch,&#x201D; occurred, where four oriented Gabor patches appeared at four locations equidistant from the fixation point. This was followed by the &#x201C;cue epoch,&#x201D; lasting 600-2,200 ms. During this epoch, a line appeared near the central fixation point, directed toward one of the Gabor patches, indicating that it would potentially change orientations. After a variable interval, the array of stimuli disappeared briefly (270 ms) and then reappeared. Monkeys were trained to detect changes in orientation of any of the four stimuli upon reappearance. To dissociate the direction of covert attention from that of saccade preparation, monkeys were given a reward for responding to an orientation change with a saccade to the stimulus opposite the changed stimulus (i.e. antisaccade). If no change occurred at the cued location (50&#x0025; of trials), the monkey was rewarded for maintaining fixation. Monkey G correctly responding on 69&#x0025; of trials (77&#x0025;, change trials; 62&#x0025;, catch trials) and Monkey B correctly responding on 67&#x0025; of trials, (62&#x0025;, change trials; 70&#x0025;, catch trials).</p>
<p>Electrophysiological recordings were made from area V4 on the surface of the prelunate gyrus with 16-channel, linear array U-Probes (Plexon, Inc., Dallas, TX). Electrodes were cylindrical in shape (180 mm diameter) with a row of 16 circular platinum/iridium electrical contacts (15 &#x00B5;m diameter) at 150 &#x00B5;m center-to-center spacing (total length of array = 2.25 mm). Recorded waveforms were classified as either &#x201C;single neurons,&#x201D; (277) or multi-neuron clusters (421). We use &#x201C;units,&#x201D; to refer to activity of both types.</p>
</sec>
<sec id="s4b">
<title>Cortical Column Laminar Recordings</title>
<sec id="s4b1">
<title>Electrode targeting: Use of MRI guidance to achieve perpendicularity</title>
<p>We sought to achieve simultaneous recordings at sites located within a single cortical column. In particular, the topographic organization of extrastriate visual cortex suggests that vertically separated neurons should have overlapping RFs, so we sought to record from a column principally by this definition. Since the cortical magnification factor (an estimate of how much cortical tissue corresponds to units of retinal space) is approximately 1 deg/mm <sup><xref rid="c38" ref-type="bibr">38</xref></sup>, we could measure the approximate angle with the cortex by the distance between receptive fields measured on the deepest and most superficial recording contacts, and sought to keep this angle at 10 degrees or less, corresponding to a RF shift of &#x223C;0.5 degrees, given 2 mm thickness of cortex.</p>
<p>In order to achieve these perpendicular penetrations we employed an MRI targeting technique <sup><xref rid="c39" ref-type="bibr">39</xref></sup>. We implanted the monkeys with custom built recording chambers made from PEEK-type plastic, rather than from titanium, to avoid shadows in the MRI images. While we did not employ ceramic skull screws, we took some care to ensure that the titanium skull screws and plates were not located close to the recording chamber and brain areas of interest. We filled a custom-made plastic cylinder with copper sulfate solution. We anesthetized the monkey and inserted this cylinder into the recording chamber, into which it fit snugly. We performed structural MRI imaging (1.5 Tesla; T-1 weighted image) to visualize the location and orientation of the recording chamber (visible due to the high-contrast copper sulfate solution within it) relative to the position of the prelunate gyrus within the brain. By manually identifying the contours of the prelunate gyrus, we could compute perpendicular vectors to it and project these back to the level of the electrode stage, thus identifying which penetration approach vectors were likely to yield perpendicular penetrations.</p>
</sec>
<sec id="s4b2">
<title>Achieving desired approach vectors</title>
<p>We employed a custom-built targeting device to angle and rotate the electrode into any desired orientation and position in three dimensions. The device consisted of a &#x201C;double-eccentric&#x201D; mechanism for positioning the electrode in the x-y plane of the well, a tilting mechanism, and a rotating mechanism. All four coordinates could be set with sub-millimeter precision using notches engraved in the device. The V4 recording chambers on both monkeys projected from the monkeys&#x2019; heads at an angle such that there was a unique point on the chamber&#x2019;s perimeter at the lowest elevation. This point was identified computationally in the MRI images and was identified on the chamber itself by filling the chamber with saline solution until the liquid first contacted the lip of the chamber. With this point of alignment between the MRI images and the physical well, the exact X, Y, tilt, and rotation coordinates for an approach vector specified by the MRI images were geometrically determined.</p>
</sec>
<sec id="s4b3">
<title>Electrode targeting: Assessing perpendicularity with RF overlap</title>
<p>RF positions and extents were estimated by computing the number of multi-unit spikes recorded on each channel in the 200ms period following stimulus onset for each of probe location in a RF-mapping task. During this task, subjects fixated a small (&#x223C;0.3 d.v.a.) white dot against a medium gray background. On each trial the six flash positions were selected from one of the rows of the grid in random order. A horizontally oriented grating was flashed for 50 ms at each position, with a 150-250ms variable delay between flashes. The flashes occurred at a total of 36 locations on a 6&#x00D7;6 grid with 3 d.v.a. spacing (total coverage 15&#x00D7;15 d.v.a.). If the subject maintained fixation within a 1.8 d.v.a. square window until after the sixth flash, he received a juice reward.</p>
<p>The upper right position of the grid was at the fovea such that only the lower left visual field was covered by the mapping. This 6&#x00D7;6 matrix of response counts was cubic spline interpolated to produce the full &#x201C;RF map&#x201D; and a 75&#x0025;-of-max contour was determined, defining the RF border. The center of mass of the portion of the RF map within the RF border was defined as the RF center. This analysis was performed after recording RF-mapping task responses but before the change-detection task, so that a stimulus position could be chosen at a location that fell within the RF borders for all channels. If such a position was found, the recording was included in further analyses.</p>
</sec>
<sec id="s4b4">
<title>Electrode targeting: Depth alignment</title>
<p>We lowered electrodes into the brain rapidly (&#x223C;25&#x03BC;m/sec) until one channel was in the cortex, based on visual examination of LFP and spiking activity being recorded concurrently. Then we advanced the electrode slowly (&#x223C;5&#x03BC;m/sec) until the uppermost electrode contact was near the point of entering the brain, being recorded during advancement. We withdrew the electrode 500&#x03BC;m to release compression of the brain caused by the electrode. During this brief withdrawal, no apparent change in the LFP or spiking activity was observed, confirming that this served to relax the cortex rather than change the position of the electrode relative to the brain. This manipulation qualitatively improved stability and recording quality. After reaching this position, the full-field flash task was run to assess the depth.</p>
<p>During the full-field flash task, monkeys fixated a small (&#x223C;0.3 d.v.a.) white dot against a black background. The monitor turned maximal white for one frame (&#x223C;8ms) then back to black. The flash occurred six times per trial with variable delays in the range of 150-250ms. If the monkey maintained fixation within a 1.8 d.v.a. square window until after the sixth flash, he received a juice reward. Approximately 30 trials, or 180 flashes, were completed per day. We computed the current source density (CSD) response to the full-field flashes. The CSD reflects the spatial and temporal position of current sources and sinks (i.e. where current flows into and out of the extracellular space, respectively) along the length of the electrode, given certain assumptions likely to be true for our recordings (Mitzdorf, 1985). The CSD can be computed discretely as the second spatial derivative of the LFP for each point in time, that is:
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="399626_ueqn1.gif"/></alternatives>
</disp-formula>
where z is the position in depth, h is the distance between potential measurements (in our case, 150&#x03BC;m), and <bold><italic>&#x03A6;</italic></bold> (z) is the potential measured as a function of depth. We also calculated the CSD according to the inverse estimation method <sup><xref rid="c40" ref-type="bibr">40</xref></sup>, and display the results of this calculation, which produces smoother, higher resolution plots of CSD, in figures for clarity. However, results were qualitatively indistinguishable with both methods. Borders between current sinks of interest were manually identified and channel depths were computed, in mm, relative to these borders.</p>
</sec>
<sec id="s4b5">
<title>Depth registration</title>
<p>In all included recordings, a prominent current sink was identified near the middle of the electrode, approximately 40-50ms after flash onset. This was often followed by another sink just below the first, peaking approximately 100ms after flash onset. These two sinks appeared in every included recording, and we therefore aligned the recordings on these functional markers of cortical laminae. In many recordings, further sinks were observed near the top of the probe at &#x223C;150ms and near the bottom of the probe at &#x223C;50ms. Because the widths of all four of these sinks, when present, were highly consistent from recording to recording, we assigned each channel a depth relative to this central feature.</p>
<p>Depths were measured in millimeters, and positive depths indicate channels superficial relative to the CSD feature. In some sessions, further CSD recordings at deeper locations revealed that no further current sources or sinks of comparable magnitude could be identified below these CSD features, assuring us that our electrode covered the depth of cortex. Two alignments of these functionally defined layers with anatomical cortical layers seem possible. The uppermost sink could correspond to layer 2/3 (together), and the larger sink to layer 4 (<xref rid="fig1" ref-type="fig">Figure 1c</xref>). Alternately, the four visible sinks could correspond to layer 2, 3, 4, and 5 in order from superficial to deep. On the one hand, the first assignment seems reasonable as the thickness of the layers known histologically matches the thickness of these CSD features reasonably well, and our expectation from primary sensory areas is that layers 4 and 6 will have the earliest responses <sup><xref rid="c41" ref-type="bibr">41</xref>&#x2013;<xref rid="c43" ref-type="bibr">43</xref></sup>. However, the cortex may well be compressed around the electrode as it is inserted thus skewing the measured layer thicknesses. Layer 2 and 3 are well-differentiated cytoarchitecturally in V4 unlike in V1, suggesting they may not appear as a single sink. Furthermore, the earliest driving visual inputs into V4 are probably not from the ventral stream <sup><xref rid="c44" ref-type="bibr">44</xref></sup>, which project into layer 4 <sup><xref rid="c15" ref-type="bibr">15</xref></sup>, and may instead arrive from the pulvinar nucleus of the thalamus <sup><xref rid="c45" ref-type="bibr">45</xref>,<xref rid="c46" ref-type="bibr">46</xref></sup>, which synapses into deep layer 3 <sup><xref rid="c47" ref-type="bibr">47</xref></sup> (Jones, 2007). This would indicate that the lower sink may correspond with the N95 marker used in previous studies to identify the granular layer <sup>42,48&#x2013;50</sup>.</p>
</sec>
</sec>
<sec id="s4c">
<title>Data Analysis</title>
<sec id="s4c1">
<title>Tuning and Modulation Indices</title>
<p>To determine the tuning of each single neuron, we calculated the firing rate on each trial during a 300ms block, from 50ms to 350ms relative to stimulus onset. We then labeled the trials by stimulus orientation, and used a Kruskal-Wallis test to compare orientation distributions. If the p&#x003C;0.001, we categorized the neuron as tuned. We then used a Chi-squared test to compare the proportion tuned in superficial versus deep layers. We also fit a Gaussian tuning function to the each neurons average firing rate for the eight stimuli using parameters for amplitude (a), preferred orientation (b), width (c) and baseline (d). The formula was given by:
<disp-formula id="ueqn2">
<alternatives><graphic xlink:href="399626_ueqn2.gif"/></alternatives>
</disp-formula>
</p>
<p>To obtain the parameters and goodness of fit measures, we used the Matlab fit function with nonlinear least squares, and constraints of 0 for the lower bound of all variables, and an upper bound of &#x03C0; for b and 8 for c. To determine if the neuron was well fit by the function, we used an adjusted R<sup>2</sup> cutoff of 0.70. For each neuron, the averaged firing rates were rotated around &#x03C0; until the optimal fit was achieved. We then compared the function parameters of superficial and deep layer neurons. As the sample sizes of superficial and deep neurons were unequal, we used bootstrapping without replacement to match the sample sizes, and repeated each test 1000 times. The reported p-values are the mean of those produced by a Wilcox signed-rank test.</p>
</sec>
<sec id="s4c2">
<title>Attention Modulation</title>
<p>For each neuronal unit, we calculated the mean firing rate during the cue epoch from -500ms to 0ms relative to the blank period. For each unit, we then calculated the attention modulation indices for eye movement preparation and covert attention relative to the orthogonal control, using the standard formula:
<disp-formula id="ueqn3">
<alternatives><graphic xlink:href="399626_ueqn3.gif"/></alternatives>
</disp-formula>
</p>
<p>We then used a mixed effects model with fixed effects for neural depth, attention condition and an interaction term (implemented with the R package nlme<sup><xref rid="c51" ref-type="bibr">51</xref></sup>). To make layer comparisons within this omnibus model, we used three orthogonal contrasts: superficial attention conditions, deep attention conditions and superficial neuronal units versus deep neuronal units. In all tests, we included a random intercept for each neuronal unit, to control for repeat measures.</p>
</sec>
</sec>
<sec id="s4d">
<title>Stimulus and Attention Classification</title>
<sec id="s4d1">
<title>Feature Matrix</title>
<p>We assembled a dataset composed of neuronal firing rates recorded across the columnar arrays and across multiple experimental sessions (23 sessions from Monkey G; 20 sessions from Monkey B; 86 superficial neurons; 181 deep neurons) for all units for which we recorded a minimum number of trials per orientation (20), or attention condition (200). Each column of the feature matrix was a specific neuron&#x2019;s firing rate, and each row of that column was the neuron&#x2019;s firing rate on a specific trial. The rows of each column were aligned, so that they shared the same label for orientation or attention condition (depending on the epoch). The number of rows associated with each orientation or attention condition were matched, so that chance level was 12.5&#x0025; for the orientation epoch and 33&#x0025; for the cue epoch. Each neuronal unit had multiple columns in the feature matrix, corresponding to the number of bins in which firing rates were calculated. The firing rates for the orientation and cue epochs were calculated in two 150ms time bins, from 50ms following stimulus onset to 350ms following stimulus onset. This provided a gross temporal pattern which was noted to improve performance in <xref rid="c24" ref-type="bibr">Nandy et al. (2016)</xref><sup><xref rid="c24" ref-type="bibr">24</xref></sup>. When building feature matrices with variable population sizes, we randomly sampled a population that size from all available units. This process was repeated 100 times, generating a unique of feature matrix for each run of the decoder.</p>
</sec>
<sec id="s4d2">
<title>Random Forest Classification</title>
<p>We used a Random Forest decoder, similar to that used in <xref rid="c24" ref-type="bibr">Nandy et al. (2016)</xref><sup><xref rid="c24" ref-type="bibr">24</xref></sup>, as implemented by Matlabs (Mathworks TM) treebagger function. In addition to decoding based on firing rate, Random Forest can decode based on differences in firing rate variability, even when mean firing rates are equal<sup><xref rid="c52" ref-type="bibr">52</xref>,<xref rid="c53" ref-type="bibr">53</xref></sup>. Furthermore, rather than comparing each orientation to the others in turn, the decoder simultaneously considers all orientations. The decoder&#x2019;s decision trees were trained on bags of trials (matrix rows), selected through bootstrapping with replacement, and tested each decision tree on trials not included in the training bag. This out-of-bag (OOB) error was used as the performance measure. It is significantly more conservative than cross validation, but has the advantage of using all available data when training the decoder. Furthermore, the bootstrapped sampling method has the traditional advantages associated with bootstrapping, such as revealing the true underlying distribution from the available training data, and reducing the impact of outlier trials <sup><xref rid="c53" ref-type="bibr">53</xref></sup>. The decoder then used a boosting method to create decision trees. At each branch point, a random subset of the features (square root of the total number of features) was chosen to calculate potential decision boundaries. Each of the features in the subset was used as a linear threshold for linearly partitioning the population of trials. The Gini impurity (GI) of the original sample, as well as of the two partitions was calculated using the formula:
<disp-formula id="ueqn4">
<alternatives><graphic xlink:href="399626_ueqn4.gif"/></alternatives>
</disp-formula>
Where J is the number of classes, and <italic>p</italic><sub><italic>i</italic></sub> is the probability of choosing stimulus class <italic>i</italic> at random from the sample. The GI of the two partitions was averaged, and subtracted from the GI of the parent sample. The feature with the greatest decrease in GI was used at the decision boundary at that branch point. The use of a random subset of features reduces the influence of outlier features, allowing one to be less careful about the neurons selected for use in decoding. Stopping criteria for the decision trees was when either all the trials at a branch point had the same label (GI = 0), or there were only 5 trials at the branch point. We set the number of trees to 500. The decoder was trained and tested using each of the 100 feature matrices, producing a distribution of decoder performance.</p>
<p>For visualization, we calculated the proximity matrix based on shared decision leaves, and plotted the first two principal components for each trial.</p>
</sec>
<sec id="s4d3">
<title>Neuron-dropping Curves</title>
<p>We used neuron-dropping curves to assess the performance of the decoder. Also known as learning-curves, these are a standard tool in the machine learning to assess whether performance limitations are due to the decoder, or to the quantity of data. When computing these functions, the quantity of data used for decoding is varied and an error rate (or performance level) is plotted as a function of that quantity. The presence of an asymptote indicates that the decoder has reached maximal performance, whereas the absence of an asymptote indicates more data is needed. We then fit a saturating function and compared both the rate of rise, and the asymptotic value between populations.</p>
<p>We created pseudo-populations, starting with 5 units, and then incrementing by 5 until the maximal number of available units was reached. For each population size, we randomly sampled the requisite number from the larger population with replacement, repeating this process 100 times to bootstrap a representative distribution. To this range of performance levels, we fit the saturating function,
<disp-formula id="ueqn5">
<alternatives><graphic xlink:href="399626_ueqn5.gif"/></alternatives>
</disp-formula>
where s is the size of the population, a controls the y intercept, b the slope and c specifies the function asymptote. This was implemented using the Matlab fit function with the method non-linear least squares. A confidence interval of 95&#x0025; was derived from the fitting process.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>Citations</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Felleman</surname>, <given-names>D. J.</given-names></string-name> &#x0026; <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name> <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>. <source>Cereb. Cortex</source> <volume>1</volume>, <fpage>1</fpage>&#x2013;<lpage>47</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Hilgetag</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>O&#x2019;Neill</surname>, <given-names>M. A.</given-names></string-name> &#x0026; <string-name><surname>Young</surname>, <given-names>M. P.</given-names></string-name> <article-title>Indeterminate organization of the visual system</article-title>. <source>Science</source> <volume>271</volume>, <fpage>776</fpage>&#x2013;<lpage>777</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Zeki</surname>, <given-names>S.</given-names></string-name> <article-title>The distribution of wavelength and orientation selective cells in different areas of monkey visual cortex</article-title>. <source>Proc. R. Soc. Lond. B Biol. Sci</source>. <volume>217</volume>, <fpage>449</fpage>&#x2013;<lpage>470</lpage> (<year>1983</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Chang</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Xian</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rubin</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name> <article-title>Latency of chromatic information in area V4</article-title>. <source>J. Physiol. Paris</source> <volume>108</volume>, <fpage>11</fpage>&#x2013;<lpage>17</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Schein</surname>, <given-names>S. J.</given-names></string-name> <article-title>Visual properties of neurons in area V4 of the macaque: sensitivity to stimulus form</article-title>. <source>J. Neurophysiol</source>. <volume>57</volume>, <fpage>835</fpage>&#x2013;<lpage>868</lpage> (<year>1987</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Roe</surname>, <given-names>A. W.</given-names></string-name> <etal>et al.</etal> <article-title>Toward a unified theory of visual area V4</article-title>. <source>Neuron</source> <volume>74</volume>, <fpage>12</fpage>&#x2013;<lpage>29</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Pasupathy</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Connor</surname>, <given-names>C. E.</given-names></string-name> <article-title>Responses to contour features in macaque area V4</article-title>. <source>J. Neurophysiol</source>. <volume>82</volume>, <fpage>2490</fpage>&#x2013;<lpage>2502</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Yau</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Pasupathy</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brincat</surname>, <given-names>S. L.</given-names></string-name> &#x0026; <string-name><surname>Connor</surname>, <given-names>C. E.</given-names></string-name> <article-title>Curvature Processing Dynamics in Macaque Area V4</article-title>. <source>Cereb. Cortex</source> <volume>23</volume>, <fpage>198</fpage>&#x2013;<lpage>209</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Tanigawa</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Lu</surname>, <given-names>H. D.</given-names></string-name> &#x0026; <string-name><surname>Roe</surname>, <given-names>A. W.</given-names></string-name> <article-title>Functional organization for color and orientation in macaque V4</article-title>. <source>Nat. Neurosci</source>. <volume>13</volume>, <fpage>1542</fpage>&#x2013;<lpage>1548</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Motter</surname>, <given-names>B. C.</given-names></string-name> <article-title>Focal attention produces spatially selective processing in visual cortical areas V1, V2, and V4 in the presence of competing stimuli</article-title>. <source>J. Neurophysiol</source>. <volume>70</volume>, <fpage>909</fpage>&#x2013;<lpage>919</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Baruni</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Lau</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Salzman</surname>, <given-names>C. D.</given-names></string-name> <article-title>Reward expectation differentially modulates attentional behavior and activity in visual area V4</article-title>. <source>Nat. Neurosci</source>. <volume>18</volume>, <fpage>1656</fpage>&#x2013;<lpage>1663</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Steinmetz</surname>, <given-names>N. A.</given-names></string-name> &#x0026; <string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name> <article-title>Eye movement preparation modulates neuronal responses in area V4 when dissociated from attentional demands</article-title>. <source>Neuron</source> <volume>83</volume>, <fpage>496</fpage>&#x2013;<lpage>506</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Tolias</surname>, <given-names>A. S.</given-names></string-name> <etal>et al.</etal> <article-title>Eye Movements Modulate Visual Receptive Fields of V4 Neurons</article-title>. <source>Neuron</source> <volume>29</volume>, <fpage>757</fpage>&#x2013;<lpage>767</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Bichot</surname>, <given-names>N. P.</given-names></string-name>, <string-name><surname>Rossi</surname>, <given-names>A. F.</given-names></string-name> &#x0026; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>Parallel and Serial Neural Mechanisms for Visual Search in Macaque Area V4</article-title>. <source>Science</source> <volume>308</volume>, <fpage>529</fpage>&#x2013;<lpage>534</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name>, <string-name><surname>Galkin</surname>, <given-names>T. W.</given-names></string-name>, <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Gattass</surname>, <given-names>R.</given-names></string-name> <article-title>Cortical Connections of Area V4 in the Macaque</article-title>. <source>Cereb. Cortex</source> <volume>18</volume>, <fpage>477</fpage>&#x2013;<lpage>499</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Yukie</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Iwai</surname>, <given-names>E.</given-names></string-name> <article-title>Laminar origin of direct projection from cortex area V1 to V4 in the rhesus monkey</article-title>. <source>Brain Res</source>. <volume>346</volume>, <fpage>383</fpage>&#x2013;<lpage>386</lpage> (<year>1985</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Nakamura</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Gattass</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name> <article-title>The modular organization of projections from areas V1 and V2 to areas V4 and TEO in macaques</article-title>. <source>J. Neurosci</source>. <volume>13</volume>, <fpage>3681</fpage>&#x2013;<lpage>3691</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Markov</surname>, <given-names>N. T.</given-names></string-name> <etal>et al.</etal> <article-title>Anatomy of hierarchy: feedforward and feedback pathways in macaque visual cortex</article-title>. <source>J. Comp. Neurol</source>. <volume>522</volume>, <fpage>225</fpage>&#x2013;<lpage>259</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Leichnetz</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Spencer</surname>, <given-names>R. F.</given-names></string-name>, <string-name><surname>Hardy</surname>, <given-names>S. G. P.</given-names></string-name> &#x0026; <string-name><surname>Astruc</surname>, <given-names>J.</given-names></string-name> <article-title>The prefrontal corticotectal projection in the monkey; An anterograde and retrograde horseradish peroxidase study</article-title>. <source>Neuroscience</source> <volume>6</volume>, <fpage>1023</fpage>&#x2013;<lpage>1041</lpage> (<year>1981</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="book"><string-name><surname>Gilbert</surname>, <given-names>C. D.</given-names></string-name> &#x0026; <string-name><surname>Wiesel</surname>, <given-names>T. N.</given-names></string-name> <chapter-title>Functional Organization of the Visual Cortex. in Progress in Brain Research</chapter-title> (eds. <person-group person-group-type="editor"><string-name><surname>Changeux</surname>, <given-names>J.-P.</given-names></string-name>, <string-name><surname>Glowinski</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Imbert</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Bloom</surname>, <given-names>F. E.</given-names></string-name></person-group>) <volume>58</volume>, <fpage>209</fpage>&#x2013;<lpage>218</lpage> (<publisher-name>Elsevier</publisher-name>, <year>1983</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Buffalo</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Landman</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Buschman</surname>, <given-names>T. J.</given-names></string-name> &#x0026; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>Laminar differences in gamma and alpha coherence in the ventral stream</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A</source>. <volume>108</volume>, <fpage>11262</fpage>&#x2013;<lpage>11267</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Nandy</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Nassi</surname>, <given-names>J. J.</given-names></string-name> &#x0026; <string-name><surname>Reynolds</surname>, <given-names>J. H.</given-names></string-name> <article-title>Laminar organization of attentional modulation in macaque visual area V4</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>235</fpage>&#x2013;<lpage>246</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Simons</surname>, <given-names>D. J.</given-names></string-name> &#x0026; <string-name><surname>Rensink</surname>, <given-names>R. A.</given-names></string-name> <article-title>Change blindness: past, present, and future</article-title>. <source>Trends Cogn. Sci</source>. <volume>9</volume>, <fpage>16</fpage>&#x2013;<lpage>20</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Nandy</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Mitchell</surname>, <given-names>J. F.</given-names></string-name>, <string-name><surname>Jadi</surname>, <given-names>M. P.</given-names></string-name> &#x0026; <string-name><surname>Reynolds</surname>, <given-names>J. H.</given-names></string-name> <article-title>Neurons in Macaque Area V4 Are Tuned for Complex Spatio-Temporal Patterns</article-title>. <source>Neuron</source> <volume>91</volume>, <fpage>920</fpage>&#x2013;<lpage>930</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Lebedev</surname>, <given-names>M. A.</given-names></string-name> <article-title>How to read neuron-dropping curves?</article-title> <source>Front. Syst. Neurosci</source>. <volume>8</volume>, (<year>2014</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Bonhoeffer</surname>, <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Grinvald</surname>, <given-names>A.</given-names></string-name> <article-title>The layout of iso-orientation domains in area 18 of cat visual cortex: optical imaging reveals a pinwheel-like organization</article-title>. <source>J. Neurosci</source>. <volume>13</volume>, <fpage>4157</fpage>&#x2013;<lpage>4180</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Fujita</surname>, <given-names>I.</given-names></string-name> &#x0026; <string-name><surname>Fujita</surname>, <given-names>T.</given-names></string-name> <article-title>Intrinsic connections in the macaque inferior temporal cortex</article-title>. <source>J. Comp. Neurol</source>. <volume>368</volume>, <fpage>467</fpage>&#x2013;<lpage>486</lpage></mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Pasupathy</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Connor</surname>, <given-names>C. E.</given-names></string-name> <article-title>Shape Representation in Area V4: Position-Specific Tuning for Boundary Conformation</article-title>. <source>J. Neurophysiol</source>. <volume>86</volume>, <fpage>2505</fpage>&#x2013;<lpage>2519</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Kosai</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>El-Shamayleh</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Fyall</surname>, <given-names>A. M.</given-names></string-name> &#x0026; <string-name><surname>Pasupathy</surname>, <given-names>A.</given-names></string-name> <article-title>The Role of Visual Area V4 in the Discrimination of Partially Occluded Shapes</article-title>. <source>J. Neurosci</source>. <volume>34</volume>, <fpage>8570</fpage>&#x2013;<lpage>8584</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Tolias</surname>, <given-names>A. S.</given-names></string-name> &#x0026; <string-name><surname>Schiller</surname>, <given-names>P. H.</given-names></string-name> <article-title>Visual representations during saccadic eye movements</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>95</volume>, <fpage>8981</fpage>&#x2013;<lpage>8984</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Sheinberg</surname>, <given-names>D. L.</given-names></string-name> &#x0026; <string-name><surname>Logothetis</surname>, <given-names>N. K.</given-names></string-name> <article-title>Noticing Familiar Objects in Real World Scenes: The Role of Temporal Cortical Neurons in Natural Vision</article-title>. <source>J. Neurosci</source>. <volume>21</volume>, <fpage>1340</fpage>&#x2013;<lpage>1350</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Reppas</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Usrey</surname>, <given-names>W. M.</given-names></string-name> &#x0026; <string-name><surname>Reid</surname>, <given-names>R. C.</given-names></string-name> <article-title>Saccadic Eye Movements Modulate Visual Responses in the Lateral Geniculate Nucleus</article-title>. <source>Neuron</source> <volume>35</volume>, <fpage>961</fpage>&#x2013;<lpage>974</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Bosman</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Womelsdorf</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name> <article-title>A Microsaccadic Rhythm Modulates Gamma-Band Synchronization and Behavior</article-title>. <source>J. Neurosci</source>. <volume>29</volume>, <fpage>9471</fpage>&#x2013;<lpage>9480</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Armstrong</surname>, <given-names>K. M.</given-names></string-name> &#x0026; <string-name><surname>Fallah</surname>, <given-names>M.</given-names></string-name> <article-title>Visuomotor origins of covert spatial attention</article-title>. <source>Neuron</source> <volume>40</volume>, <fpage>671</fpage>&#x2013;<lpage>683</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name> <article-title>Shape Representations and Visual Guidance of Saccadic Eye Movements</article-title>. <source>Science</source> <volume>285</volume>, <fpage>1914</fpage>&#x2013;<lpage>1917</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Schafer</surname>, <given-names>R. J.</given-names></string-name> &#x0026; <string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name> <article-title>Attention Governs Action in the Primate Frontal Eye Field</article-title>. <source>Neuron</source> <volume>56</volume>, <fpage>541</fpage>&#x2013;<lpage>551</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Fries</surname>, <given-names>W.</given-names></string-name> <article-title>Cortical projections to the superior colliculus in the macaque monkey: A retrograde study using horseradish peroxidase</article-title>. <source>J. Comp. Neurol</source>. <volume>230</volume>, <fpage>55</fpage>&#x2013;<lpage>76</lpage></mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Gattass</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Sousa</surname>, <given-names>A. P.</given-names></string-name> &#x0026; <string-name><surname>Gross</surname>, <given-names>C. G.</given-names></string-name> <article-title>Visuotopic organization and extent of V3 and V4 of the macaque</article-title>. <source>J. Neurosci</source>. <volume>8</volume>, <fpage>1831</fpage>&#x2013;<lpage>1845</lpage> (<year>1988</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Kalwani</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Bloy</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Elliott</surname>, <given-names>M. A.</given-names></string-name> &#x0026; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> <article-title>A method for localizing microelectrode trajectories in the macaque brain using MRI</article-title>. <source>J. Neurosci. Methods</source> <volume>176</volume>, <fpage>104</fpage>&#x2013;<lpage>111</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Pettersen</surname>, <given-names>K. H.</given-names></string-name>, <string-name><surname>Devor</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ulbert</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Dale</surname>, <given-names>A. M.</given-names></string-name> &#x0026; <string-name><surname>Einevoll</surname>, <given-names>G. T.</given-names></string-name> <article-title>Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities</article-title>. <source>J. Neurosci. Methods</source> <volume>154</volume>, <fpage>116</fpage>&#x2013;<lpage>133</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Hansen</surname>, <given-names>B. J.</given-names></string-name> &#x0026; <string-name><surname>Dragoi</surname>, <given-names>V.</given-names></string-name> <article-title>Adaptation-induced synchronization in laminar cortical circuits</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>108</volume>, <fpage>10720</fpage>&#x2013;<lpage>10725</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Schroeder</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>Mehta</surname>, <given-names>A. D.</given-names></string-name> &#x0026; <string-name><surname>Givre</surname>, <given-names>S. J.</given-names></string-name> <article-title>A spatiotemporal profile of visual system activation revealed by current source density analysis in the awake macaque</article-title>. <source>Cereb. Cortex</source> <volume>8</volume>, <fpage>575</fpage>&#x2013;<lpage>592</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Swadlow</surname>, <given-names>H. A.</given-names></string-name>, <string-name><surname>Gusev</surname>, <given-names>A. G.</given-names></string-name> &#x0026; <string-name><surname>Bezdudnaya</surname>, <given-names>T.</given-names></string-name> <article-title>Activation of a Cortical Column by a Thalamocortical Impulse</article-title>. <source>J. Neurosci</source>. <volume>22</volume>, <fpage>7766</fpage>&#x2013;<lpage>7773</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>C.-M.</given-names></string-name> <etal>et al.</etal> <article-title>Functional Anatomy and Interaction of Fast and Slow Visual Pathways in Macaque Monkeys</article-title>. <source>Cereb. Cortex</source> <volume>17</volume>, <fpage>1561</fpage>&#x2013;<lpage>1569</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Guillery</surname>, <given-names>R. W.</given-names></string-name> &#x0026; <string-name><surname>Sherman</surname>, <given-names>S. M.</given-names></string-name> <article-title>Thalamic Relay Functions and Their Role in Corticocortical Communication: Generalizations from the Visual System</article-title>. <source>Neuron</source> <volume>33</volume>, <fpage>163</fpage>&#x2013;<lpage>175</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Shipp</surname>, <given-names>S.</given-names></string-name> <article-title>The functional logic of cortico&#x2013;pulvinar connections</article-title>. <source>Philos. Trans. R. Soc. Lond. B Biol. Sci</source>. <volume>358</volume>, <fpage>1605</fpage>&#x2013;<lpage>1624</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="book"><string-name><given-names>Edward G.</given-names> <surname>Jones</surname></string-name>. <source>The thalamus</source>. (<publisher-name>Springer Science&#x002B;Business Media, LLC, Plenum Press</publisher-name>, <year>1985</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Bollimunta</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Schroeder</surname>, <given-names>C. E.</given-names></string-name> &#x0026; <string-name><surname>Ding</surname>, <given-names>M.</given-names></string-name> <article-title>Neuronal Mechanisms of Cortical Alpha Oscillations in Awake-Behaving Macaques</article-title>. <source>J. Neurosci</source>. <volume>28</volume>, <fpage>9976</fpage>&#x2013;<lpage>9988</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Givre</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Schroeder</surname>, <given-names>C. E.</given-names></string-name> &#x0026; <string-name><surname>Arezzo</surname>, <given-names>J. C.</given-names></string-name> <article-title>Contribution of extrastriate area V4 to the surface-recorded flash VEP in the awake macaque</article-title>. <source>Vision Res</source>. <volume>34</volume>, <fpage>415</fpage>&#x2013;<lpage>428</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Trongnetrpunya</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>Assessing Granger Causality in Electrophysiological Data: Removing the Adverse Effects of Common Signals via Bipolar Derivations</article-title>. <source>Front. Syst. Neurosci</source>. <volume>9</volume>, (<year>2016</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Pinherio</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bates</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>DebRoy</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Sarkar</surname>, <given-names>D.</given-names></string-name> <source>nlme: Linear and Nonlinear Mixed Effects Models</source>. (<year>2018</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Strobl</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Malley</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Tutz</surname>, <given-names>G.</given-names></string-name> <article-title>An introduction to recursive partitioning: rationale, application, and characteristics of classification and regression trees, bagging, and random forests</article-title>. <source>Psychol. Methods</source> <volume>14</volume>, <fpage>323</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Ho</surname>, <given-names>T. K.</given-names></string-name> <article-title>A Data Complexity Analysis of Comparative Advantages of Decision Forest Constructors</article-title>. <source>Pattern Anal. Appl</source>. <volume>5</volume>, <fpage>102</fpage>&#x2013;<lpage>112</lpage> (<year>2002</year>).</mixed-citation></ref>
</ref-list>
</back>
</article>
