<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/321497</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Animal Behavior and Cognition</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Learning to act by integrating mental simulations and physical experiments</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Dasgupta</surname>
<given-names>Ishita</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Smith</surname>
<given-names>Kevin A.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schulz</surname>
<given-names>Eric</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Tenenbaum</surname>
<given-names>Joshua B.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gershman</surname>
<given-names>Samuel J.</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Physics and Center for Brain Science, Harvard University</institution></aff>
<aff id="a2"><label>2</label><institution>Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology</institution></aff>
<aff id="a3"><label>3</label><institution>Department of Psychology, Harvard University</institution></aff>
<aff id="a4"><label>4</label><institution>Department of Psychology and Center for Brain Science, Harvard University</institution></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>&#x002A;</label><p>These authors contributed equally to the work</p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>321497</elocation-id>
<history>
<date date-type="received">
<day>13</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>13</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="321497.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>People can learn about the effects of their actions either by performing physical experiments or by running mental simulations. Physical experiments are reliable but risky; mental simulations are unreliable but safe. We investigate how people negotiate the balance between these strategies. Participants attempted to shoot a ball at a target, and could pay to take practice shots (physical experiments). They could also simply think (run mental simulations), but were incentivized to act quickly by paying for time. We demonstrate that the amount of thinking time and physical experiments is sensitive to trial characteristics in a way that is consistent with a model that integrates information across simulation and experimentation and decides online when to perform each.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Mental Simulation</kwd>
<kwd>Intuitive Physics</kwd>
<kwd>Sampling</kwd>
<kwd>Metareasoning</kwd>
</kwd-group>
<counts>
<page-count count="6"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p><xref ref-type="bibr" rid="c3">Craik (1943)</xref> famously proposed that an advanced organism might hold &#x201C;a &#x2018;small-scale model&#x2019; of external reality and of its own possible actions in its head&#x2026; to try out various alternatives, conclude which is the best of them&#x2026; [and] to react in a much fuller, safer, and more competent manner.&#x201D; These simulatable models allow us to gain information about the effect of our actions without needing to incur the cost of performing those actions. Simulation using mental models has explained how we perform not just spatial (<xref ref-type="bibr" rid="c14">Kosslyn et al., 1978</xref>; <xref ref-type="bibr" rid="c19">Shepard &#x0026; Metzler, 1971</xref>) and physical (<xref ref-type="bibr" rid="c1">Battaglia et al., 2013</xref>; <xref ref-type="bibr" rid="c12">Hegarty, 2004</xref>) reasoning, but has also been suggested to underlie language understanding (<xref ref-type="bibr" rid="c2">Bergen, 2012</xref>) and theory of mind (<xref ref-type="bibr" rid="c4">Gallese &#x0026; Goldman, 1998</xref>).</p>
<p>While simulations are cheaper, safer, and faster than acting on the world, they are not perfect substitutes. Because any mental model only approximates the world, simulation provides uncertain predictions of the effects of our actions (<xref ref-type="bibr" rid="c20">Smith &#x0026; Vul, 2013</xref>). Furthermore, simulations are less costly than actions but are not costless &#x2013; they require mental effort and time to perform (<xref ref-type="bibr" rid="c22">Vul et al., 2014</xref>). Thus, when we want to learn about the world, we need to decide how to combine relatively cheap and imprecise simulations with more costly and accurate physical experiments. To do this rationally requires integrating information from both simulation and action and assessing their expected benefits and costs (<xref ref-type="bibr" rid="c5">Gershman et al., 2015</xref>; <xref ref-type="bibr" rid="c15">Lieder &#x0026; Griffiths, 2017</xref>).</p>
<p>We study this problem in a physical action planning task, which serves as a suitable test bed because we have models of uncertainty in people&#x2019;s physical predictions (<xref ref-type="bibr" rid="c20">Smith &#x0026; Vul, 2013</xref>), and because there is evidence that people make rational trade-offs about how much simulation to use when physical experiments are not possible (<xref ref-type="bibr" rid="c10">Hamrick et al., 2015</xref>). We use a task in which participants are asked to aim a ball at a goal, but can think about it or take practice shots beforehand (<xref ref-type="fig" rid="fig1">Fig. 1</xref>). We find that people modulate the number of experiments and time spent thinking based on trial characteristics that cannot be explained solely by simple measures of difficulty.</p>
<p>We then propose a model of how people combine simulation and experimentation. This model is based on the theory that just as we can learn mappings between actions and outcomes by real-world observations, we can gain information about this mapping using simulations in place of observations (<xref ref-type="bibr" rid="c6">Gershman et al., 2017</xref>; <xref ref-type="bibr" rid="c21">Sutton, 1991</xref>). This model uses a type of Bayesian optimization &#x2013; Gaussian process entropy optimization (<xref ref-type="bibr" rid="c13">Hern&#x00E1;ndez-Lobato et al., 2014</xref>) &#x2013; that integrates different sources of information and decides between performing noisy but cheap simulations and running more expensive but near-deterministic experiments. It captures aspects of how many experiments people perform, how much time they spend thinking, as well as their ultimate action choices.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Diagram of the experimental trials.</title> <p><bold>A</bold>: Participants observe a table and are asked to shoot the ball into the green goal without hitting the red areas. Participants could aim the ball and take practice shots at a cost to the score. <bold>B</bold>: The trajectory and outcome of shots were shown. Once participants had finished practicing and thinking, they could click the &#x2018;Take a shot&#x2019; button and would have one chance to score. <bold>C</bold>: The 18 trials used in the experiment, ordered from least to most likely to succeed by chance.</p></caption>
<graphic xlink:href="321497_fig1.tif"/>
</fig>
</sec>
<sec id="s2">
<title>Experiment</title>
<p>We developed a physical reasoning task in which participants choose an angle to launch a ball at a target. On each trial (see <xref ref-type="fig" rid="fig1">Fig. 1</xref>), they could choose to perform physical experiments as well as think about how to shoot the ball. Once they decided they were ready, they had to perform an action in the exact same scenario and earned points based on the success of their action as well as on how much time they had spent thinking about the task and how many experiments they had run.</p>
<p><bold>Participants.</bold> We recruited 60 participants from Amazon Mechanical Turk using the psiTurk framework (<xref ref-type="bibr" rid="c8">Gureckis et al., 2016</xref>). Each participant was paid a participation fee of &#x0024;2.50 and randomly assigned to the <italic>cheap experiments</italic> condition or <italic>costly experiments</italic> condition.</p>
<p><bold>Procedure.</bold> On each trial, participants observed a rectangular table of 1000 &#x00D7; 600 pixels on their screen. On this table was a single blue ball, any number of black walls, and on the edge of the table were green and red colored patches (see <xref ref-type="fig" rid="fig1">Fig 1</xref>). Participants were instructed that their task was to determine the angle to launch the ball so that it would touch the green goal before touching the red area or traveling too far a distance.</p>
<p>Each trial was divided into two phases: information gathering and the final action phase. In the first phase, participants started with 100 points. They were instructed that they could think or take practice shots, but both would cost points. The score would decay at a rate of 6 points/second, and each practice shot would incur a cost depending on the experimental condition: 10 points in the cheap condition and 20 points in the costly condition.</p>
<p>Participants could take a practice shot by positioning their mouse within 250px of the center of the ball and clicking. If the mouse was within this range, a straight line would extend from the ball indicating the direction of the shot. Once a practice shot was clicked, the ball would travel in that direction, bouncing off of any walls or table edges until it either reached the green or red areas, or had traveled a distance of 3000px (which would take &#x223C; 1.5s, though could vary based on the participant&#x2019;s computer speed). During a practice shot, the score decay was paused.</p>
<p>When participants believed they knew how to shoot the ball, they could click a button below the table to move to the final phase. As soon as this button was clicked, the score would stop decaying, and a yellow border would appear around the table to indicate the final action phase. Participants would have three seconds to take their final shot, which could be performed in the same way as a practice shot. If this final shot hit the green goal, the participant would earn a score equal to the number of points remaining from the information gathering phase. If the final shot hit the red area or timed out, the participant would lose 10 points from their total score. If the participant did not make a shot within the three second limit, they would also lose 10 points. Afterwards, the participant would be notified of the outcome and move on to the next trial.</p>
<p>If the score decayed to zero during the information gathering phase, the final shot phase would immediately begin (including the yellow border notification). Participants would then earn no points for a successful shot, but could lose points for a miss or failure to act.</p>
<p>The total score was displayed in the lower right of the screen as a motivation for participants, but did not affect compensation.</p>
<p><bold>Materials.</bold> Participants performed a total of 25 trials. The first seven trials were always presented in the same order and were designed as introductory trials to familiarize participants with the interface; these trials were not included in any analyses. The remaining 18 trials (see <xref ref-type="fig" rid="fig1">Fig. 1</xref>, right) were presented in a randomized order for each participant. These trials were designed by hand to provide a range of difficulties for an agent that took shots at random angles: six trials would be solved by fewer than 10&#x0025; of random shots, six trials would be solved by between 10&#x2013;30&#x0025; of random shots, and six trials would be solved by greater than 30&#x0025; of random shots. This probability of succeeding by guessing is used as a rough proxy for difficulty, and to assess whether participants were adapting their practice experiments or actual shots to new information or simply guessing. Trials were labeled by number in increasing probability of guessing.</p>
<p><bold>Data exclusions.</bold> We removed data from three participants for whom we did not record actions for all 18 trials, and from seven additional participants who &#x2018;timed out&#x2019; in either the information seeking or final action phase on more than half of the trials (indicating low attention). This left 27 participants in the cheap condition and 23 participants in the costly condition. We further excluded from analysis any trials in which the participants timed out only for the final shot (5.7&#x0025;) and trials in which the participant minimized or browsed away from the experimental window (0.1&#x0025;).</p>
<sec id="s2a">
<title>Behavioral results</title>
<p>Overall, participants performed well in this task and hit the target on their final shot more frequently than would be expected under chance performance (61&#x0025; accuracy versus 25&#x0025; accuracy at chance; <italic>t</italic>(17) &#x003D; 5.01, <italic>p</italic> &#x003C; .001, <italic>d</italic> &#x003D; 2.43).</p>
<p>There was no good evidence that participants performed fewer practice shots on average between the two experimental conditions (cheap: 0.68, costly: 0.48, <italic>t</italic>(47.3)&#x003D; 1.08, <italic>p</italic> &#x003D; .29, <italic>d</italic> &#x003D; 0.31), nor was there evidence that the average time spent thinking differed by condition (cheap: 2.5<italic>s</italic>, costly: 2.4<italic>s</italic>, <italic>t</italic>(46.2) &#x003D; 0.26, <italic>p</italic> &#x003D; .79, <italic>d</italic> &#x003D; 0.08). Participants were also roughly equally accurate across the two conditions (cheap: 63&#x0025;, costly: 60&#x0025;, <italic>t</italic>(40.0) &#x003D; 0.82, <italic>p</italic> &#x003D; .42, <italic>d</italic> &#x003D; 0.26). Because we found no difference in behavior by cost condition, we ignore this manipulation for all future analyses.</p>
<p>Across individuals, simulation and experimentation were tightly linked: the average time participants spent thinking on a trial (excluding time watching practice shots) was correlated with the number of practice shots they took (<italic>r</italic>(48) &#x003D; 0.76, <italic>p</italic> &#x003C; .001).</p>
<p>At the trial level, participants were sensitive to the gross difficulty: as the probability of shooting the ball in the goal by chance increased they were more accurate (averaged over trials, <italic>r</italic>(16) &#x003D; 0.72, <italic>p</italic> &#x003C; .001), performed fewer experimental shots (<italic>r</italic> (16) &#x003D; &#x2212;0.52, <italic>p</italic> &#x003D; .027, see <xref ref-type="fig" rid="fig2">Fig. 2</xref>, left), and took less time to think (<italic>r</italic>(16) &#x003D; &#x2212;0.65, <italic>p</italic> &#x003D; .004, see <xref ref-type="fig" rid="fig2">Fig. 2</xref>, right).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Plot of trial difficulty (chance of random shot being successful) versus number of practice shots (<italic>left</italic>) and average thinking time (<italic>right</italic>) for each trial. Points are labeled with trial indicators. See <xref ref-type="fig" rid="fig1">Fig. 1</xref> for trials by number, and <xref ref-type="fig" rid="fig3">Fig. 3</xref> for results from colored trials.</p></caption>
<graphic xlink:href="321497_fig2.tif"/>
</fig>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Qualitative behavior of the model.</title> <p><bold>A</bold>: Screen shots of the three different trials (see main text for logic behind selection of trials). <bold>B</bold>: Polar plots showing the results of one run of the model, with probability of success from simulation and experiment. Dots indicate observations with blue dots marking simulations and orange dots marking experiments. The black line indicates the final estimate from the model (from that run) for probability of success. <bold>C</bold>: Density of final shots taken by the model, overlaid with final shots taken by participants. <bold>D</bold>: Number of experiments and simulations as generated by our model and humans (with amount of time spent not doing an experiments before taking the final shot as a proxy for number of simulations, with an assumption of 0.7 s/simulation, for ease of visualization) <bold>E</bold>: Evolution of one run of the model&#x2019;s prediction over simulation/action choices, from top to bottom. The black line is the model&#x2019;s belief (with grey indicating &#x00B1; 1sd), the blue line is simulation probability, and the orange line is experimentation probability; dots indicate observations, with the same corresponding colors, and circles are the most recent observation. <italic>Top:</italic> the model initially simulates which increases probability of success in the region but is still uncertain. <italic>Middle:</italic> an experiment gives much more certainty, but it is still unclear if clockwise (right) or anticlockwise (left) from that point is better. <italic>Bottom:</italic> the final experiment updates belief that shooting clockwise from the first experiment would likely miss.</p></caption>
<graphic xlink:href="321497_fig3.tif"/>
</fig>
<p>Participants were sensitive to trial features beyond this gross difficulty measure. Even for trials with similar probabilities of guessing, there was a wide variation in the average number of practice shots participants took; including trial indicators provided better predictions of the number of practice shots participants used as compared to predictions based only on the chance of a successful guess (<italic>X</italic><sup>2</sup>(16) &#x003D; 115, <italic>p</italic> &#x003C; .001). This can also be observed when comparing specific trials: for example, looking at the difference between Trial 7 (blue in <xref ref-type="fig" rid="fig2">Fig. 2</xref>), and both Trial 6 (red) and Trial 18 (green). While Trial 6 &#x0026; 7 have roughly the same &#x201C;chance&#x201D; difficulty (9&#x0025; vs 12&#x0025;), participants rarely took practice shots in Trial 7 (0.18 / participant) but used a large number of practices for Trial 6 (1.21 / participant). Conversely, while the random chance of success are very different between Trial 7 &#x0026; 18 (12&#x0025; vs 84&#x0025;) participants use a comparable number of practice shots in both (0.18 / participant for Trial 7 and 0.31 / participant for Trial 18).</p>
<p>We next investigated whether executing physical experiments improved participants&#x2019; performance across participants; however, we found no evidence for this. There was no evidence that participants who performed more practice shots were more accurate (<italic>r</italic>(48) &#x003D; &#x2212;0.07, <italic>p</italic> &#x003D; .62), nor did they spend less time thinking (<italic>r</italic>(48) &#x003D; &#x2212;0.16, <italic>p</italic> &#x003D; .26). While we would expect that experimentation would improve performance, it is possible that less skilled participants need this additional information, while more skilled participants can perform just as well without it.</p>
<p>In summary, participants modulated their simulation/experiment policy in response to trial difficulty, but not to relative action cost. Next, we turn to a model that can integrate information from simulation and physical actions to explain this pattern of information seeking across trials.</p>
</sec>
</sec>
<sec id="s3">
<title>Computational model</title>
<p>The integration model was designed to map actions (shot angles) to outcomes (probability of hitting the goal) by combining information from both simulation and experimentation. Let &#x03B8; be the shooting angle and<italic>f</italic>(&#x03B8;) be the log odds that &#x03B8; will lead to a target hit. People learn this function by sampling physical paths, either through simulation or an experiment. Simulations are derived from the probability of hitting the target using the noisy physics model of <xref ref-type="bibr" rid="c20">Smith &#x0026; Vul (2013)</xref>, and experimental outcomes are sampled from a smoothed function mapping the actions to actual outcomes according to the physics engine used in the experiment.</p>
<p>To capture how people generalize from sampled paths to new paths, we assume that people learn a Gaussian process (GP) regression model of <italic>f</italic>(&#x03B8;) (<xref ref-type="bibr" rid="c18">Rasmussen &#x0026; Williams, 2006</xref>), a flexible nonparametric framework for function learning that has previously been successfully applied to model mental simulations (<xref ref-type="bibr" rid="c9">Hamrick &#x0026; Griffiths, 2014</xref>). A GP prior over functions is specified by a mean (typically assumed to be0) and a covariance function, or kernel, <italic>k</italic> (&#x03B8;,&#x03B8;<sup>&#x2032;</sup>) which governs the smoothness of the function. Given this prior, the posterior over functions is Gaussian and can be computed in closed form (<xref ref-type="bibr" rid="c18">Rasmussen &#x0026; Williams, 2006</xref>).</p>
<p>While mental simulations are fast, they are also noisier than physical experiments, and hence not as informative. To integrate information from both of these sources of information, we follow the proposal put forward by <xref ref-type="bibr" rid="c16">Marco et al. (2017)</xref> for a kernel that can integrate simulations and experiments: <disp-formula id="eqn1"><alternatives><graphic xlink:href="321497_eqn1.gif"/></alternatives></disp-formula> where &#x03B4;(&#x03B8;) &#x003D; 1 indicates that &#x03B8; was used to generate an experiment, and &#x03B4;(&#x03B8;) &#x003D; 0 indicates that q was used to generate a simulation. The kernel<italic>k</italic><sub>sim</sub> models the contribution from simulations, and<italic>k</italic><sub>diff</sub> models the difference between simulation and experiment. This is similar to exemplar-based models that generalize based on the distance (similarity) to previous observations (<xref ref-type="bibr" rid="c7">Griffiths et al., 2009</xref>), except observations here can be either simulations or experiments. To account for the differences in uncertainty from these two sources, we weight the distances to previous examples differently for each source, with a weaker generalization for simulations (using kernel <italic>k</italic><sub>sim</sub>) and a stronger one for experiments (using kernel <italic>k</italic><sub>sim</sub> &#x002B; <italic>k</italic><sub>diff</sub>). We use a radial basis function for both kernels.</p>
<p>In order to find the angle &#x03B8;&#x002A; that optimizes <italic>f</italic>(&#x03B8;), our model has to query informative angles. When choosing angles to query, it also has to account for a differences in costs of each information source. This requires us to have a principled way to quantify how valuable an observation from each of these sources of information is, relative to its cost. One such measure is how much an observation from each source reduces the entropy over the maxima of <italic>f</italic>(&#x03B8;).</p>
<p>An acquisition function that utilizes this metric is predictive entropy search (PES, <xref ref-type="bibr" rid="c13">Hern&#x00E1;ndez-Lobato et al., 2014</xref>). We adapt this acquisition function following <xref ref-type="bibr" rid="c16">Marco et al. (2017)</xref> to accommodate the two information sources. The mapping between query angle q and how much it reduces entropy over the maxima of <italic>f</italic>(&#x03B8;) is given by PES<sub>sim</sub>(&#x03B8;) and PES<sub>expt</sub>(&#x03B8;), depending on if the query is a simulation or a physical experiment. The simulations are more noisy so PES<sub>sim</sub>(&#x03B8;) &#x003C; PES<sub>expt</sub>(&#x03B8;). To account for the difference in cost, we associate an effort measure with both kinds of evaluations <italic>t</italic><sub>sim</sub> for the simulation and <italic>t</italic><sub>exp</sub> for the physical experiments. While simulations are less informative, they are normally cheaper than experiments, so <italic>t</italic><sub>sim</sub> &#x003C; <italic>t</italic><sub>exp</sub>. We then select the next angle to evaluate, &#x03B8;<sub><italic>n</italic>&#x002B;1</sub>, and whether it is a simulation or experiment, &#x03B4;(&#x03B8;<sub><italic>n</italic>&#x002B;1</sub>), according to argmax<sub>&#x03B8;,<italic>i</italic>&#x2208;{sim,exp}</sub> PES<sub><italic>i</italic></sub>(&#x03B8;)/<italic>t<sub>i</sub></italic>. The predictive entropy search first tries four randomly selected mental simulations, and afterwards chooses to evaluate new points based on the PES acquisition function.</p>
<p>We discretized the possible shots into 100 different angles spanning the circle, and precomputed for each trial and angle the following variables: (a) whether that shot would hit the green goal according to the game physics, and (b) the probability that a simulation would hit the green goal based on 50 random simulations from the noisy physics model. These variables are then smoothed using a Gaussian window, to account for perceptual error in distinguishing angles. We then take the logit of these functions to transform them onto the real line in order to carry out unconstrained Gaussian process regression.</p>
<p>There are four free parameters in this model: the ratio of the cost of simulations versus experiments (<italic>t</italic><sub>exp</sub>/<italic>t</italic><sub>sim</sub>), the simulation noise variance relative to the experiment noise variance, and two stopping criteria for the optimization: an entropy threshold that stops if a lower bound for the relative change in PES is reached, and a probability threshold if an upper bound for the best-so-far probability of success is reached. We used grid search to select the parameter values that minimized the sum-squared error between the number of experiments predicted by the model and the participants.<xref ref-type="fn" rid="fn1">&#x002A;</xref></p>
</sec>
<sec id="s4">
<title>Model results</title>
<p>Our model closely tracked the frequency of experiments participants chose to perform across trials, <italic>r</italic>(16) &#x003D; 0.68, <italic>p</italic> &#x003D; 0.002 (<xref ref-type="fig" rid="fig4">Fig. 4</xref>, left). We then compared the number of simulations done by the model with the number of simulations done by participants. Since the number of simulations done by a participant is not explicitly available, a rough proxy is the amount of time participants spent thinking. We found a moderate correlation between the predicted number of simulations and participant&#x2019;s thinking time (<italic>r</italic>(16) &#x003D; 0.48, <italic>p</italic> &#x003D; .042; <xref ref-type="fig" rid="fig4">Fig. 4</xref>, right).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Correlations between model predictions and average participant behavior for each trial. <italic>Left</italic>: number of experiments. <italic>Right</italic>: time spent thinking (calculated based on a linear regression from number of model simulations, in seconds).</p></caption>
<graphic xlink:href="321497_fig4.tif"/>
</fig>
<p>While there was a strong correlation in participants&#x2019; data between the number of practice shots and thinking time per trial (<italic>r</italic>(16) &#x003D; 0.93, <italic>p</italic> &#x003C; .001), the model predicts that there should be no appreciable correlation between the number of experiments and simulations (<italic>r</italic>(16) &#x003D; .15, <italic>p</italic> &#x003D; .54). Nonetheless, the number of simulations expected by the model does predict part of the unexplained variance in thinking time above and beyond the number of practice shots (<italic>F</italic>(1,15)&#x003D; 4.55, <italic>p</italic> &#x003D; .05), indicating that the number of simulations predicted by the model is still reflected in the amount of time spent thinking. Further, the correlation between simulations and thinking time (<italic>r</italic> &#x003D; 0.48) is almost unchanged when partialing out the number of observed practice shots per trial (<italic>r<sub>part</sub></italic> &#x003D; 0.48), indicating that the model&#x2019;s predicted simulations are explaining independent information to the number of practice shots.</p>
<p>We also see that our model is able to replicate the qualitative patterns of information seeking behavior in humans across trials, as highlighted by Trials 6, 7 and 18 in <xref ref-type="fig" rid="fig3">Figure 3</xref>: trials that are intuitively obvious and have very few practice shots (Trials 7 &#x0026; 18) are solved by the model using simulation alone, while more difficult trials that spur participants to take practice shots (e.g., Trial 6) also spur the integration model to experiment.</p>
<p>In order to highlight the importance of integrating simulation and experiment for explaining the human data, we also test a model that cannot simulate, and fit it to the number of observed experiments from the data with a grid search through the stopping criteria parameters (the other parameters do not apply to this lesioned model). This model by definition cannot explain thinking time, though it can predict the number of practice shots (<italic>r</italic>(16) &#x003D; 0.42, <italic>p</italic> &#x003D; 0.08) which is not significantly worse than the full model (<italic>z</italic> &#x003D; 0.21, <italic>p</italic> &#x003D; 0.83). However, this is because the lesioned model was fit to the number of practice shots. Next, we investigate how the model uses those experiments to produce a final shot. Assessing the log-likelihood (LLH) of participants&#x2019; final shots under a smoothed distribution of model-predicted shots, we find that the full model (<italic>LLH<sub>full</sub></italic> &#x003D; &#x2212;968, estimated kernel bandwidth &#x003D; 0.295 radians) predicts participants&#x2019; shots better than the lesioned model (<italic>LLH<sub>lesion</sub></italic>&#x003D;&#x2212;1,563, estimated bandwidth = 2.7 radians), making each final shot 2.02 times more likely to have occurred under the full vs. the lesioned model.</p>
<p>In summary, the lesioned, experiment-only model is not an adequate account of the data, and because we did observe practice shots, a simulation-only model could not account for participants&#x2019; behavior either. Our integrated model provides a good qualitative explanation for the information seeking behavior we see across trials and corresponds well to the final shots people take. It also provides reasonably good quantitative correlations with the number of experiments humans do across different trials, as well as the time they spent thinking.</p>
</sec>
<sec id="s5">
<title>Discussion</title>
<p>Using a novel experimental paradigm that requires integrating simulation and experimentation to gather information, we found that people use both strategies, and furthermore that people&#x2019;s use of both of these strategies varies across different scenarios. We can explain much of the variation in experimentation, time spent thinking, and final decisions using a single information gathering model that treats knowledge gained from both simulations and experiments in a common currency and uses an expected cost/benefit analysis to determine which strategy to use next.</p>
<p>This finding provides a starting framework to address the question of how people can flexibly integrate cheap but noisy information gathering in their heads and accurate but potentially expensive information gathering in the world. We find that people&#x2019;s behavior is roughly consistent with a rational process model that chooses actions based on a measure of information gain. While this experiment focused on physical action planning, there are many domains in which people can gather information from both thinking and acting that this framework could be applied to, from problem solving to reinforcement learning (e.g., <xref ref-type="bibr" rid="c6">Gershman et al., 2017</xref>).</p>
<p>This is not the only possible model of people&#x2019;s active information seeking (cf. <xref ref-type="bibr" rid="c17">Nelson, 2005</xref>): there are other ways of integrating information, assessing the expected benefits from each information source, or determining whether to simulate or act based on the current information. In future work we will assess further information seeking models that integrate simulation and experiment.</p>
<sec id="s5a">
<title>Limitations</title>
<p>There are features of this integration problem that we will need to further investigate. For instance, according to our model there should be relatively little correlation between experiments and simulation, yet we find a large correlation between practice shots and thinking time in the empirical data. By assuming that thinking time is linearly related to the number of simulations, we could explain some of the variance in thinking time across trials, but left a large part unexplained. Future work needs to determine whether this is because our model of thinking time is incorrect (e.g., it should include time to set up practice shots), or if this points to an area of the integration process that requires further consideration.</p>
<p>Our participants were extremely consistent in the ultimate angle at which they shot the ball &#x2013; in almost all cases choosing almost identical or one of two directions (<xref ref-type="fig" rid="fig5">Fig. 5, left</xref>). The integration model could explain why there were some accurate shots that people did not consider, but still picked out some angles that people did not (e.g., shooting at the opposite wall from a straight shot in Trials 7 &#x0026; 18, <xref ref-type="fig" rid="fig3">Fig. 3</xref>). This may reflect preferences not built into the model (e.g., for shorter path lengths) or priors on the action-outcome mapping that can be gleaned before any simulations or actions occur.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Density of final shots taken for each trial by participants (<italic>left</italic>), the full model (<italic>middle</italic>), and the experiment-only model (<italic>right</italic>). The green areas below the axes indicate angles that would be successful.</p></caption>
<graphic xlink:href="321497_fig5.tif"/>
</fig>
<p>And finally, if we assume that people are sensitive to the costs of simulation versus action, we would expect to see a difference in behavior when experiments were cheaper or more costly, yet none was found here. Because this manipulation was performed across participants, perhaps people had set different expectations for points in each condition, and so any cost trade-offs would cancel out. This theory would be consistent with findings that between-subject incentive manipulations can be ineffective while the same incentive manipulations are effective within-subject (<xref ref-type="bibr" rid="c11">Harley, 1965</xref>).</p>
</sec>
<sec id="s5b">
<title>Conclusion</title>
<p>Mental simulation is a powerful tool that can help us plan ahead and solve complex problems without having to perform an action. Nonetheless, complex tasks often require both mental simulation and actual experiments. We have developed both a computational framework and reported preliminary behavioral findings that take a step towards understanding how people integrate simulation and experiments.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>ID is supported by Microsoft Research. KAS, SJG and JBT are supported by CBMM funded by NSF STC award CCF-1231216, and ONR grant N00014-13-1-0333. ES is supported by the Harvard Data Science Initiative. Code and data are available at: <monospace>github.com/ishita-dg/SimulationVSAction</monospace></p>
</ack>
<fn-group>
<fn id="fn1">
<label>&#x002A;</label>
<p>Our results are robust to fairly large variations in the parameter settings we searched. The only parameter that explained a large portion (32&#x0025;) of the variance in the sum of squared errors over all parameter settings was the cost factor between experiment and simulation, with other factors explaining less than 1&#x0025; of the variance.</p></fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Battaglia</surname>, <given-names>P. W.</given-names></string-name>, <string-name><surname>Hamrick</surname>, <given-names>J. B.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2013</year>). <article-title>Simulation as an engine of physical scene understanding</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>45</issue>), <fpage>18327</fpage>&#x2013;<lpage>18332</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><string-name><surname>Bergen</surname>, <given-names>B. K.</given-names></string-name> (<year>2012</year>). <source>Louder than words: The new science of how the mind makes meaning</source>. <publisher-name>Basic Books</publisher-name>(<publisher-loc>AZ</publisher-loc>).</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="other"><string-name><surname>Craik</surname>, <given-names>K. J. W.</given-names></string-name> (<year>1943</year>). <source>The nature of explanation</source>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Gallese</surname>, <given-names>V.</given-names></string-name>, &#x0026; <string-name><surname>Goldman</surname>, <given-names>A.</given-names></string-name>(<year>1998</year>). <article-title>Mirror neurons and the simulation theory of mind-reading</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>2</volume>(<issue>12</issue>), <fpage>493</fpage>&#x2013;<lpage>501</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Horvitz</surname>, <given-names>E. J.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2015</year>). <article-title>Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</article-title>. <source>Science</source>, <volume>349</volume>(<issue>6245</issue>), <fpage>273</fpage>&#x2013;<lpage>278</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Kommers</surname>, <given-names>C.</given-names></string-name> (<year>2017</year>). <article-title>Imaginative reinforcement learning: Computational principles and neural mechanisms</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>29</volume>(<issue>12</issue>),<fpage>2103</fpage>&#x2013;<lpage>2113</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="other"><string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Lucas</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Kalish</surname>, <given-names>M. L.</given-names></string-name> (<year>2009</year>). <chapter-title>Modeling human function learning with Gaussian processes</chapter-title>. In <source>Advances in Neural Information Processing Systems</source>, (pp. <fpage>553</fpage>&#x2013;<lpage>560</lpage>).</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Gureckis</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>McDonnell</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rich</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Markant</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Coenen</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Halpern</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hamrick</surname>, <given-names>J. B.</given-names></string-name>, &#x0026; <string-name><surname>Chan</surname>, <given-names>P.</given-names></string-name> (<year>2016</year>). <article-title>psiturk: An open-source framework for conducting replicable behavioral experiments online</article-title>. <source>Behavior Research Methods</source>, <volume>48</volume>(<issue>3</issue>), <fpage>829</fpage>&#x2013;<lpage>842</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Hamrick</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Griffiths</surname>, <given-names>T.</given-names></string-name> (<year>2014</year>). <article-title>What to simulate? Inferring the right direction for mental rotation</article-title>. In <source>Proceedings of the Cognitive Science Society</source>, <volume>vol. 36</volume>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="other"><string-name><surname>Hamrick</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &#x0026; <string-name><surname>Vul</surname>, <given-names>E.</given-names></string-name> (<year>2015</year>). <article-title>Think again? The amount of mental simulation tracks uncertainty in the outcome</article-title>. In <source>Proceedings of the Cognitive Science Society</source>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Harley</surname>, <given-names>W. F.</given-names></string-name> (<year>1965</year>). <article-title>The effect of monetary incentive in paired associate learning using a differential method</article-title>. <source>Psychonomic Science</source>, <volume>2</volume>(<issue>1&#x2013;12</issue>), <fpage>377</fpage>&#x2013;<lpage>378</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Hegarty</surname>, <given-names>M.</given-names></string-name> (<year>2004</year>). <article-title>Mechanical reasoning by mental simulation</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>8</volume>(<issue>6</issue>), <fpage>280</fpage>&#x2013;<lpage>285</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="other"><string-name><surname>Hern&#x00E1;ndez-Lobato</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Hoffman</surname>, <given-names>M. W.</given-names></string-name>, &#x0026; <string-name><surname>Ghahramani</surname>, <given-names>Z.</given-names></string-name> (<year>2014</year>). <chapter-title>Predictive entropy search for efficient global optimization of black-box functions</chapter-title>. In <source>Advances in Neural Information Processing Systems</source>, (pp. <fpage>918</fpage>&#x2013;<lpage>926</lpage>).</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Kosslyn</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Ball</surname>, <given-names>T. M.</given-names></string-name>, &#x0026; <string-name><surname>Reiser</surname>, <given-names>B. J.</given-names></string-name> (<year>1978</year>). <article-title>Visual images preserve metric spatial information: Evidence from studies of image scanning</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>4</volume>(<issue>1</issue>),<fpage>47</fpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Lieder</surname>, <given-names>F.</given-names></string-name>, &#x0026; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name> (<year>2017</year>). <article-title>Strategy selection as rational metareasoning</article-title>. <source>Psychological Review</source>, <volume>124</volume>(<issue>6</issue>), <fpage>762</fpage>&#x2013;<lpage>794</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="other"><string-name><surname>Marco</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Berkenkamp</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Hennig</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Schoellig</surname>, <given-names>A. P.</given-names></string-name>, <string-name><surname>Krause</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schaal</surname>, <given-names>S.</given-names></string-name>, &#x0026; <string-name><surname>Trimpe</surname>, <given-names>S.</given-names></string-name> (<year>2017</year>). <chapter-title>Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization</chapter-title>. In <source>Proc. of the International Conference on Robotics and Automation (ICRA)</source>, (pp. <fpage>1557</fpage>&#x2013;<lpage>1563</lpage>).</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Nelson</surname>, <given-names>J. D.</given-names></string-name> (<year>2005</year>). <article-title>Finding useful questions: On Bayesian diagnosticity, probability, impact, and information gain</article-title>. <source>Psychological Review</source>, <volume>112</volume>(<issue>4</issue>),<fpage>979</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="other"><string-name><surname>Rasmussen</surname>, <given-names>C. E.</given-names></string-name>, &#x0026; <string-name><surname>Williams</surname>, <given-names>C. K.</given-names></string-name> (<year>2006</year>). <source>Gaussian Processes for Machine Learning</source>, <volume>vol. 1</volume>. <publisher-name>MIT press Cambridge</publisher-name>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Shepard</surname>, <given-names>R. N.</given-names></string-name>, &#x0026; <string-name><surname>Metzler</surname>, <given-names>J.</given-names></string-name> (<year>1971</year>). <article-title>Mental rotation of three-dimensional objects</article-title>. <source>Science</source>, <volume>171</volume>(<issue>3972</issue>), <fpage>701</fpage>&#x2013;<lpage>703</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>K. A.</given-names></string-name>, &#x0026; <string-name><surname>Vul</surname>, <given-names>E.</given-names></string-name> (<year>2013</year>). <article-title>Sources of uncertainty in intuitive physics</article-title>. <source>Topics in Cognitive Science</source>, <volume>5</volume>(<issue>1</issue>), <fpage>185</fpage>&#x2013;<lpage>199</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Sutton</surname>, <given-names>R. S.</given-names></string-name> (<year>1991</year>). <article-title>Dyna, an integrated architecture for learning, planning, and reacting</article-title>. <source>ACM SIGART Bulletin</source>, <volume>2</volume>(<issue>4</issue>), <fpage>160</fpage>&#x2013;<lpage>163</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Vul</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &#x0026; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2014</year>). <article-title>One and done? Optimal decisions from very few samples</article-title>. <source>Cognitive Science</source>, <volume>38</volume>(<issue>4</issue>), <fpage>599</fpage>&#x2013;<lpage>637</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>