<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/472076</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Border-ownership-dependent tilt aftereffect for shape defined by binocular disparity and motion parallax</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Rideaux</surname>
<given-names>Reuben</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Harrison</surname>
<given-names>William J</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, University of Cambridge</institution></aff>
<aff id="a2"><label>2</label><institution>Queensland Brain Institute, The University of Queensland</institution></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author (<email>reuben.rideaux@gmail.com</email>)</corresp>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>472076</elocation-id>
<history>
<date date-type="received">
<day>16</day>
<month>11</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>16</day>
<month>11</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>17</day>
<month>11</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="472076.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>Segmenting a visual object from its surrounds is a critical function that may be supported by a class of cells in the macaque visual cortex known as border-ownership cells. These orientation-tuned cells respond conditionally to the borders of objects defined by luminance or binocular disparity. Recent findings suggest that some border-ownership cells also are selective for the depth of an object. To effectively support perceptual figure-ground segmentation, however, border-ownership cells must have access to information from multiple depth cues and strict depth order selectivity. Here we measure border-ownership-dependent tilt aftereffects in humans to figures defined by either motion parallax or binocular disparity. We find strong tilt aftereffects for both depth cues, which are transferable between cues, but selective for figure-ground depth order. These results suggest that the neural systems involved in figure-ground segmentation have strict depth order selectivity and access to multiple depth cues that are jointly encoded.</p>
</abstract>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>INTRODUCTION</title>
<p>Our natural visual environments are complex and often cluttered with objects. In order to interact with our surrounds appropriately, therefore, objects must be segmented from other objects and their backgrounds, and their position in depth must be inferred from often fragmented and ambiguous cues such as binocular disparity, motion parallax, and texture. Achieving such so-called &#x201C;figure-ground segmentation&#x201D; with the speed and automaticity necessary to effectively function within the environment is non-trivial; understanding how the brain accomplishes this remains of fundamental importance in neuroscience.</p>
<p>Recent neurophysiological work has revealed a class of cells in the macaque primary visual cortex that has been implicated in figure-ground segmentation. These cells, known as border-ownership cells (<xref ref-type="bibr" rid="c22">Zhou et al., 2000</xref>), are tuned to oriented edges, like many neurons in the primary visual cortex (<xref ref-type="bibr" rid="c10">Hubel &#x0026; Wiesel, 1959</xref>). However, unlike most orientation-tuned cells, the activity of border-ownership cells is contingent on whether or not the edge belongs to the border of an object (<xref ref-type="bibr" rid="c22">Zhou et al., 2000</xref>). For instance, the same light-dark edge presented within the receptive field of a neuron could produce a significantly larger increase in firing rate if the light region was part of a distinct &#x2018;figure&#x2019; positioned on a dark &#x2018;background&#x2019; than the other way around (<bold><xref rid="fig1" ref-type="fig">Fig. 1a</xref></bold>). Critically, this contingency is active even when the object extends far beyond the classic receptive field of the cell, suggesting that border-ownership cells are connected through a network that can identify borders that are common to an object. This distinctive characteristic is ideally suited for binding the borders of an object in order to segment it from the background.</p>
<p>The contingency that characterizes border-ownership cells can also be demonstrated psychophysically in humans using a modification of the classic tilt-aftereffect paradigm (<xref ref-type="bibr" rid="c18">von der Heydt, Macuda, &#x0026; Qiu, 2005</xref>). The tilt-aftereffect occurs when an observer views an oriented stimulus, an adaptor, for a prolonged period, and subsequently views a different (test) orientation (<xref ref-type="bibr" rid="c8">Gibson &#x0026; Radner, 1935</xref>). The test orientation is perceived as being tilted further away from the adaptor orientation than its veridical angle. This repulsion effect occurs because perceived orientation is represented at the neural level as a population response of orientation-tuned neurons (<xref ref-type="bibr" rid="c9">Graham, 1989</xref>). Prolonged viewing selectively reduces the responsiveness of neurons tuned to the adaptor orientation, a process referred to as adaptation, so that when the test orientation is viewed, the population response is now biased away from the adaptor (<bold><xref rid="fig1" ref-type="fig">Fig. 1b</xref></bold>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Illustrations of border-ownership neurons and tilt-aftereffects.</title>
<p>(a) The same dark-light edge within the (dotted circle) receptive field of certain orientation-tuned neurons will evoke different levels of activity depending on whether (cyan) the light region is part of a &#x201C;figure&#x201D; and the dark region part of the &#x201C;ground&#x201D; or (orange) vice versa. (b) The (magenta line) perceived orientation of a (green) vertical bar is based on (top) the population response of multiple orientation tuned cells. Prolonged exposure to a bar tilted clockwise from vertical reduces (middle) the responsiveness of cells tuned to this orientation (i.e., adaptation). Following adaptation, viewing a vertical bar will now produce (bottom) a population response that is biased away from the adapted orientation, i.e., a tilt-aftereffect, due to (dashed lines) the attenuated response of the cells. (c) By extending the vertical bar such that it becomes the border of a figure, on (dotted orange) the left or on (cyan) the right, (top) the bar will now evoke activity from separate populations of border-ownership cells. Prolonged alternating viewing of borders tilted clockwise and anti-clockwise from vertical that belong to the left and right figures, respectively, will produce (middle) border-ownership-dependent adaptation in separate populations of cells with receptive fields in the same retinotopic location. Now, when a vertical border is viewed it will produce (bottom) a population response that is biased away from the adapted tilt orientation of the figure it belongs.</p></caption>
<graphic xlink:href="472076_fig1.tif"/>
</fig>
<p>By selectively adapting border-ownership cells, a border-ownership-dependent tilt-aftereffect can be observed such that repulsion is only perceived when the test border belongs to the same figure as the adaptor border (<xref ref-type="bibr" rid="c18">von der Heydt et al., 2005</xref>). Thus, multiple distinct populations of border-ownership cells can be adapted in the same retinotopic location, producing separate tilt-aftereffects that are contingent on the figure to which the test border belongs (<bold><xref rid="fig1" ref-type="fig">Fig 1c</xref></bold>). This object-based effect was elegantly demonstrated by <xref ref-type="bibr" rid="c18">von der Heydt et al (2005)</xref>, who presented two adaptor figures alternating in time. One object was presented to the left of centre, while the other object was presented to the right of centre. Importantly, the inner border of these objects intersected in space, but were of opposite tilt. When a solitary test line was subsequently presented at the intersection, no tilt-aftereffect was observed, presumably because the effects of the adapting edges were balanced. In contrast, if the test line was extended to form a figure to the left or the right of fixation, a tilt-aftereffect was observed that was repulsed away from the border of the adaptor on the side to which the test line extended (<xref ref-type="bibr" rid="c18">von der Heydt et al., 2005</xref>).</p>
<p>Further electrophysiological work with macaque revealed that in addition to luminance-defined borders, some border-ownership cells are sensitive to borders defined by binocular disparity (<xref ref-type="bibr" rid="c19">von der Heydt et al., 2000</xref>). A proportion of these cells further showed depth order selectivity, for example by responding selectively to an step-edge with a near-far depth profile (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>). This has been interpreted as further evidence that border-ownership cells support figure-ground segmentation. However, depth cues are noisy and often unreliable; in order to yield accurate inferences, the brain combines information from many different depth cues (<xref ref-type="bibr" rid="c5">Ernst &#x0026; B&#x00FC;lthoff, 2004</xref>). Thus, for a class of cells to effectively support figure-ground segmentation, they must have access to information from multiple depth cues. Further, in order to establish the depth order of borders these cells must have depth order selectivity.</p>
<p>To test whether other depth cues are used by border-ownership cells, and whether they are selectivity tuned to a particular depth order, we measured border-ownership-dependent tilt-aftereffects following adaptation to figures defined by two primary depth cues: 1) motion parallax and 2) binocular disparity. We found that both depth cues produce a tilt-aftereffect which is selective for depth order. Moreover, we found that the effect of adaptation is transferable between cues. These results indicate that border-ownership cells have strict depth order selectivity and access to multiple depth cues that are jointly encoded.</p>
</sec>
<sec id="s2">
<title>METHODS</title>
<sec id="s2a">
<title>Participants</title>
<p>Observers were recruited from the University of Cambridge and had normal or corrected-to-normal vision and were screened for stereo deficits using a fine discrimination task (just-noticeable difference &#x003C; .5 arcmin). Eight right-handed human adults participated in each of the two experiments (Experiment 1: 4 male, 26.3&#x00B1;5.6 years; Experiment 2: 3 male, 26.7&#x00B1;4.9 years). Five participants participated in both experiments, including one author (RR). With the exception of (RR), all participants were na&#x00EF;ve to the aims of the experiment. Experiments were approved by the University of Cambridge ethics committee; all observers provided written informed consent.</p>
</sec>
<sec id="s2b">
<title>Apparatus and stimuli</title>
<p>Stimuli were generated in MATLAB (The MathWorks, Inc., Matick, MA) using Psychophysics Toolbox and Eyelink Toolbox extensions (<xref ref-type="bibr" rid="c2">Brainard, 1997</xref>; <xref ref-type="bibr" rid="c3">Cornelissen, Peters, &#x0026; Palmer, 2002</xref>; <xref ref-type="bibr" rid="c13">Pelli, 1997</xref>; see <ext-link ext-link-type="uri" xlink:href="http://psychtoolbox.org/">http://psychtoolbox.org/</ext-link>). Binocular presentation was achieved using a pair of Samsung 2233RZ LCD monitors (120Hz, 1680&#x00D7;1050) viewed through front-silvered mirrors in a Wheatstone stereoscope configuration. The viewing distance was 50 cm and the participants&#x2019; head position were stabilized using an eye mask, headrest and chin rest. Eye movement was recorded binocularly at 1 kHz using an EyeLink 1000 (SR Research Ltd., Ontario, Canada).</p>
<p>Stimuli and design were motivated by those used by (<xref ref-type="bibr" rid="c18">von der Heydt et al., 2005</xref>). Unlike this previous study that used solid lines on a blank background, however, our stimuli consisted of pixel noise in which shapes were distinguished by either (i) binocular disparity or (ii) motion parallax, appearing as (near) a &#x201C;figure&#x201D; or (far) a &#x201C;window&#x201D; in front of a background surface (<bold><xref rid="fig2" ref-type="fig">Fig. 2a</xref></bold>). Binocular disparity-defined shapes could be either near or far (&#x00B1;2.5 arcmin) relative to the background, with the closer plane always at zero degrees offset (<bold><xref rid="fig2" ref-type="fig">Fig. 2b</xref></bold>). Pixel (white, 198 cd/m<sup>2</sup>; black, 5 cd/m<sup>2</sup>) luminance was randomly reassigned at 10 Hz. Similarly, motion parallax-defined shapes were made to appear near or far by moving the pixels on either the inside or the outside of the trapezoidal region horizontally according to a sinusoidal function (max speed 40&#x00B0;/s, with an initial phase 0 or pi, counterbalanced across presentations; <bold><xref rid="fig2" ref-type="fig">Fig. 2c</xref></bold>). To reduce non-target cues to orientation that could be used as a reference, the stimulus region was circular (radius 4&#x00B0;) with a Gaussian smoothed edge (sd 8 arcmin). Trapezoidal regions (height 3&#x00B0;, centre width 3&#x00B0;) were positioned on the left or the right side of the centre of the screen with the tilted edge (henceforth referred to as the flank) centred on the midline. A blue dot (radius 6 arcmin) was positioned to the left or right of centre (30 armin) to stabilize fixation. During blank periods the stimulus region was midgrey (99 cd/m<sup>2</sup>); the remainder of the screen was always black (5 cd/m<sup>2</sup>).</p>
</sec>
<sec id="s2c">
<title>Procedure</title>
<p>Runs consisted of an initial adaptation sequence (32 pairs of trapezoids; 76.8 s), followed by test trials that were separated by top-up adaptation sequences (three pairs of trapezoids; 7.2 s; <bold><xref rid="fig2" ref-type="fig">Fig. 2d</xref></bold>). During the adaptation sequences, observers viewed trapezoidal figures (left and right flank tilt either [-15, 15]&#x00B0; or [15, -15]&#x00B0; in separate blocks) alternating between left- and right-side presentation (duration 1 s, ISI .2 s). The depth cue (binocular disparity or motion parallax) that defined the adaptor and test figures was always the same within a run, but the depth order could be either congruent (e.g., figure with figure) or incongruent (e.g., figure with window). A method of constant stimuli was used with trials consisting of a test figure (flank tilt &#x00B1;[8, 4.8, 1.6]&#x00B0;) presented pseudo-randomly, either on the left or the right of the screen centre for a duration of 0.5 s. Following the test stimulus, there was a 0.2 s blank period followed by presentation of a green arrow centred on fixation, pointing left or right (1.5 s). The arrow was drawn behind the fixation dot to avoid disrupting fixation, and its direction was selected at random.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Examples of experimental stimuli and design.</title>
<p>(<bold>a</bold>) Illustration of the two (figure/window) depth structures used in the experiment. (<bold>b</bold>) Stereogram of the (figure) adaptor stimulus in the binocular disparity condition designed for cross-eyed fusion. (<bold>c</bold>) One frame of the adaptor stimulus in the motion parallax condition; the figure region is indicated in magenta. Pixels either (window) inside or (figure) outside the trapezoidal region were moved horizontally according to a sinusoidal function. (<bold>d</bold>) Schematic of the design; alternating presentation of adaptation figures on the left and right (adaptation sequence) followed by a test figure and an arrow pointing either left or right, each separated by blank intervals. The observers&#x2019; task was to indicate whether the orientation of the test figure flank was consistent with the direction of the proceeding arrow.</p></caption>
<graphic xlink:href="472076_fig2.tif"/>
</fig>
<p>Observers&#x2019; task was to press the &#x201C;space&#x201D; key when the test flank&#x2019;s tilt direction (anticlockwise/left or clockwise/right) appeared to be consistent with the direction of the following arrow. This method of response was used instead of separate left/right responses to avoid systematic response bias, such as observers pressing left or right more frequently under high uncertainty. A 1 s blank interval separated adaptation and test periods to avoid a potential bias of the afterimage of the last-presented adaptation figure. For the same reason, the starting trapezoid of the adaptation sequence was alternated so that left-/right-side trapezoids were presented as the last figure on half the trials. During the blank interval preceding each trial, the fixation dot was changed from blue to yellow to prepare observers for the upcoming trial. Prior to adaptation runs, baseline test runs were performed in which subjects were presented with the same test stimuli without adaptation.</p>
<p>In Experiment 1, we used a 2&#x00D7;2&#x00D7;2 factorial design: depth cue (motion parallax/binocular disparity) &#x00D7; depth (figure/window) &#x00D7; depth congruence (congruent/incongruent). Adaptation and baseline runs consisted of 48 and 72 trials, respectively. For each condition, observers underwent two baseline and two adaptation runs; one for each of the left-/right-positioned fixation dot (randomized order). In each session, observers completed two conditions, for a total duration of approximately 60 min. To avoid carry-over effects, sessions were completed on separate days and the adaptation orientation was reversed between conditions. Congruent runs were completed prior to incongruent runs and the depth cue condition was held constant within sessions. The order of depth sign and depth cue conditions was counterbalanced across participants.</p>
<p>In Experiment 2, we tested whether adaptation to one depth cue influenced objects defined by the other depth cue. We therefore ran two conditions where the depth portrayed a (near) figure, but the cue used to define the adaptor and test stimuli were incongruent. For example, an observer would adapt to motion-defined objects, and were then tested with disparity-defined objects, or vice versa.</p>
</sec>
<sec id="s2d">
<title>Task response data analysis</title>
<p>For each condition, we concatenated data from the two runs and fit it with a psychometric function using the MATLAB toolbox Psignifit (<xref ref-type="bibr" rid="c7">Frund, Haenel, &#x0026; Wichmann, 2011</xref>; see <ext-link ext-link-type="uri" xlink:href="http://psignifit.sourceforge.net/">http://psignifit.sourceforge.net/</ext-link>) to establish separate threshold and slope values for responses corresponding to test figures presented on the left and right. To determine the bias on perceived orientation that resulted from adaptation, we calculated the difference between baseline and adaptation threshold values. To match the bias between runs with [-15, 15]&#x00B0; tilt adaptors across observers, we reversed the sign of bias in the [15, - 15]&#x00B0; tilt runs. For the same reason, we reversed the sign of the bias for figures presented on the left prior to averaging the two, yielding a single measure of bias for each condition. Thus, average bias was normalized to the -15&#x00B0; tilt adaptor condition.</p>
</sec>
<sec id="s2e">
<title>Eye tracking data analysis</title>
<p>Prior to analysis, eye movement data were screened to remove blinks and noisy and/or spurious recordings. To test for differences in eye position between experimental conditions, we calculated the mean and standard deviation of observers&#x2019; vertical and horizontal binocular eye position, relative to fixation, for version and vergence eye movements during adaptor and test presentation. To match eye position coordinates between runs with left- and right-side fixation, we reversed the sign of horizontal eye movements in runs where the fixation dot was presented on the left side.</p>
</sec>
</sec>
<sec id="s3">
<title>RESULTS</title>
<sec id="s3a">
<title>Selectivity for multiple depth cues</title>
<p>Neurophysiological work has revealed orientation-tuned cells in the primary visual cortex of macaque that conditionally respond to the borders of figures. These border-ownership cells have been implicated in supporting figure-ground segmentation. For a class of cells to effectively support figure-ground segmentation in a three-dimensional environment, there are two crucial characteristics required: 1) sensitivity to multiple depth cues and 2) depth order preference.</p>
<p>Here we tested whether adaptation to figures defined by one of two primary depth cues (motion parallax or binocular disparity) produce a border-ownership-dependent tilt-aftereffect. We further investigated whether any adaptation effect is transferable between depth order configurations (e.g., adapt to a near object, and test with a far object). We found that perceptual bias following adaptation was significantly larger when the adaptor and test stimulus depth were congruent than incongruent (repeated-measures ANOVA; F<sub>1,49</sub>&#x003D;37.6, P&#x003D;1.5e<sup>-7</sup>; <bold><xref rid="fig3" ref-type="fig">Fig. 3a</xref> &#x0026; <xref rid="fig3" ref-type="fig">b</xref></bold>). Indeed, we found a significant adaptation effect for all congruent conditions, but failed to find an effect for any incongruent condition (<bold><xref rid="fig3" ref-type="fig">Fig. 3b</xref></bold>). We also found no difference in the strength of the effect for different cues (F<sub>1,49</sub>&#x003D;0.4, P&#x003D;.521) or depths (F<sub>1,49</sub>&#x003D;4.0, P&#x003D;.087). No interactions were significant (all ps&#x003E;.05). These results indicate that border-ownership cells are sensitive to both motion parallax and binocular disparity, and that they show depth order preference. A possible concern is that we failed to detect a bias in the incongruent conditions because bias estimates were less precise. Such a problem could arise because of, for example, reduced anticipation of the test stimulus due to the change in depth relative to the cue stimulus. However, we found no evidence for a difference in the precision of observers&#x2019; estimates between congruent and incongruent conditions (F<sub>1,49</sub>&#x003D;0.04, P&#x003D;.849; <bold><xref rid="fig3" ref-type="fig">Fig. 3c</xref></bold>). By contrast, we found that observers&#x2019; judgements were more precise for stimuli defined by motion parallax than binocular disparity (F<sub>1,49</sub>&#x003D;15.6, P&#x003D;.006). No differences in the precision of estimates were observed between depth conditions (F<sub>1,49</sub>&#x003D;4.2, P&#x003D;.079).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Psychophysical measurements of orientation judgements following adaptation.</title>
<p>Following adaptation to oriented stimuli defined by either motion parallax or binocular disparity, observers judged the orientation of the edge of a test stimulus that was either the same (congruent) or different (incongruent) depth order. (<bold>a</bold>) A representative example of the psychometric functions fit to one (na&#x00EF;ve) participants&#x2019; data in the motion-figure congruent and incongruent conditions. Solid lines, and dots without outlines, indicate baseline data, dashed lines and dots with black outlines indicate adaptation data. Orange and cyan dots and lines indicate data from test figures presented on the left and right sides, respectively. (<bold>b</bold>) Relative to a pre-adaptation baseline, observers&#x2019; point of subjective equality (PSE) was biased away from the orientation of the adaptor when the test stimulus was congruent (paired t-test; motion-near, t<sub>7</sub>&#x003D;8.8, P&#x003D;4.9e<sup>-5</sup>; motion-far, t<sub>7</sub>&#x003D;7.9, P&#x003D;9.5e<sup>-5</sup>; disparity-near, t<sub>7</sub>&#x003D;5.3, P&#x003D;.001; disparity-far, t<sub>7</sub>&#x003D;2.8, P&#x003D;.023), but not incongruent (paired t-test; motion-near, t<sub>7</sub>&#x003D;-0.8, P&#x003D;.446; motion-far, t<sub>7</sub>&#x003D;1.3, P&#x003D;.216; disparity-near, t<sub>7</sub>&#x003D;-1.8.3, P&#x003D;.120; disparity-far, t<sub>7</sub>&#x003D;-0.7, P&#x003D;.508), with the adaptor. Further, the PSE in congruent conditions was significantly more biased than in corresponding incongruent conditions (paired t-test; motion-near, t<sub>7</sub>&#x003D;2.7, P&#x003D;.029; motion-far, t<sub>7</sub>&#x003D;6.9, P&#x003D;2.3e<sup>-4</sup>; disparity-near, t<sub>7</sub>&#x003D;4.5, P&#x003D;.003; disparity-far, t<sub>7</sub>&#x003D;2.8, P&#x003D;.028). The difference in bias between congruent and incongruent conditions cannot be explained by differences in the precision of judgements, (c) we found no differences in precision (inverse of sigma) between corresponding in/congruent conditions (paired t-test; motion-near, t<sub>7</sub>&#x003D;0.7, P&#x003D;.513; motion-far, t<sub>7</sub>&#x003D;0.8, P&#x003D;.420; disparity-near, t<sub>7</sub>&#x003D;0.1, P&#x003D;.956; disparity-far, t<sub>7</sub>&#x003D;1.6, P&#x003D;.152). Note that labels along the abscissa refer to the depth of the test stimulus.</p></caption>
<graphic xlink:href="472076_fig3.tif"/>
</fig>
<p>The border-ownership-dependent tilt-aftereffect is retinotopically localized to a relatively small region (&#x007E;2&#x00B0;)(<xref ref-type="bibr" rid="c18">von der Heydt et al., 2005</xref>); thus, another possible concern is that we failed to detect a tilt-aftereffect in the incongruent conditions because observers&#x2019; gaze position moved more between adaptor and test stimulus presentation than in congruent conditions. However, we found no evidence for a larger change in binocular eye position between adaptor and test periods for either horizontal/vertical vergence (RM ANOVA; horizontal, F<sub>1,49</sub>&#x003D;2.8, P&#x003D;.159; vertical, F<sub>1,49</sub>&#x003D;0.7, P&#x003D;.433; <bold><xref rid="fig4" ref-type="fig">Fig. 4a</xref></bold>) or version eye movements (horizontal, F<sub>1,49</sub>&#x003D;0.4, P&#x003D;.541; vertical, F<sub>1,49</sub>&#x003D;0.3, P&#x003D;.593; <bold><xref rid="fig4" ref-type="fig">Fig. 4b</xref></bold>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Change in binocular eye gaze position between adaptor and test stimulus presentation.</title>
<p>To test whether our failure to detect transference of adaptation between (relatively) near and far figure borders was due to larger changes in eye gaze position between test and adaptor stimulus presentation in the incongruent condition, we compared the absolute difference in the average horizontal/vertical (<bold>a</bold>) vergence and (<bold>b</bold>) version eye movements between (cyan) congruent and (orange) incongruent conditions. We found no evidence for a larger change in binocular eye gaze position for either vergence or version eye movements. Note, the caption at the top of each plot indicates the test stimulus condition.</p></caption>
<graphic xlink:href="472076_fig4.tif"/>
</fig>
</sec>
<sec id="s3b">
<title>Joint encoding of depth cues</title>
<p>The results above suggest that there are border-ownership cells tuned to motion parallax and binocular disparity depth cues. There are two ways in which these cues may be encoded by border-ownership cells: 1) depth cues are encoded in separate neural populations, or 2) border-ownership cells jointly encode depth cues. Consistent with the joint encoding hypothesis, previous neurophysiological work indicates that some border-ownership cells combine binocular disparity and Gestalt cues (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>). To determine whether border-ownership cells encode (motion parallax and binocular disparity) depth cues separately or jointly, we tested whether the effect of adaptation to a stimulus defined by one cue was transferred to a stimulus defined by the other. In line with the hypothesis that cues are jointly encoded, we found a significant tilt-aftereffect for stimuli defined by motion parallax, following adaptation to stimuli defined by binocular disparity (paired t-test, t<sub>7</sub>&#x003D;6.3, P&#x003D;3.9e<sup>-4</sup>), and vice versa (t<sub>7</sub>&#x003D;8.0, P&#x003D;8.8e<sup>-5</sup>; <bold><xref rid="fig5" ref-type="fig">Fig. 5a</xref></bold>). Consistent with our previous results, we again found that judgements for stimuli defined by motion parallax were more precise (t<sub>7</sub>&#x003D;4.1, P&#x003D;.004; <bold><xref rid="fig5" ref-type="fig">Fig. 5b</xref></bold>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Transfer of adaptation effects between stimuli defined by motion parallax and binocular disparity.</title>
<p>Following adaptation to oriented figure defined by either motion parallax or binocular disparity, observers judged the orientation of a test figure that was defined by the other cue. (<bold>a</bold>) Relative to a pre-adaptation baseline, observers&#x2019; point of subjective equality (PSE) was biased away from the orientation of the adaptor for both stimuli. Note that the shade of the bars indicates the depth cue used to define the test stimulus, whereas the opposite cue was the adaptor stimulus. (<bold>b</bold>) Consistent with the results from the previous experiment, we also found that judgements made for stimuli defined by motion were more precise than for disparity.</p></caption>
<graphic xlink:href="472076_fig5.tif"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>DISCUSSION</title>
<p>Psychophysical work with human observers has shown that multiple tilt aftereffects can be induced at the same retinotopic location by adapting to the orientation of overlapping borders of different figures (<xref ref-type="bibr" rid="c18">von der Heydt et al., 2005</xref>). This finding supports evidence from neurophysiological work with macaque revealing orientation-tuned border-ownership cells in the primary visual cortex that conditionally respond to the figure borders (<xref ref-type="bibr" rid="c22">Zhou et al., 2000</xref>). Further neurophysiological work with macaque demonstrated that some border-ownership cells show tuning for borders defined by binocular disparity (<xref ref-type="bibr" rid="c19">von der Heydt et al., 2000</xref>), with a proportion of these (60&#x0025;) also selective for depth order (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>). These properties make border-ownership cells ideally suited for supporting figure-ground segmentation. However, there are multiple depth cues that are used to infer depth; thus, to effectively segment the visual environment a class of cells would be expected to have access to other depth cues and to show strong depth order tuning. To test this hypothesis, here we measured border-ownership-dependent tilt-aftereffects for stimuli defined by two primary depth cues, motion parallax and binocular disparity. We found tilt-aftereffects for both cues, which were <italic>not</italic> transferable between depth order configurations (e.g., adapting to a &#x201C;figure&#x201D; edge did not influence perception of a &#x201C;window&#x201D; edge), but were transferable between cues (e.g., adapting to motion parallax influenced perception of a subsequent object defined by binocular disparity).</p>
<p>The finding that a border-ownership-dependent tilt-aftereffect can be induced using stimuli defined by motion parallax or binocular disparity is consistent with previous work showing that binocular disparity and Gestalt cues are both encoded by border-ownership cells (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>) and suggests that border-ownership cells may be sensitive to a range of depth cues including, but not limited to, these two. Neurophysiological work with macaque found that just over half of border-ownership cells tuned to binocular disparity were also depth order selective (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>). This appears (at last partially) inconsistent with the current results. If a significant proportion (40&#x0025;) of border-ownership cells are not selective for depth order, it may have been reasonable to have expected to find transference of adaptation between depth order conditions; however, we found no evidence for this. Our results instead suggest that depth order selectivity is more prevalent in border-ownership cells than previous estimates. This discrepancy could be explained by under sampling. That is, the sample (62 border-ownership cells) from which the previous estimate is based may be uncharacteristic of the population. Additionally, the process by which depth order selectivity was established may have underestimated the prevalence within the sample, for example, by applying a conservative criterion. Note, however, that the proportion of depth order selective border-ownership cells in the macaque primary visual cortex may not be representative of those in the human&#x2019;s, and the relationship between the proportion of these cells and their behavioural consequences may not be linear.</p>
<p>Some border-ownership cells in macaque cortex encode both binocular disparity and Gestalt cues (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>). Here we found that adaptation effects could be transferred between stimuli defined by either motion parallax or binocular disparity, suggesting that some border-ownership cells also jointly encode these depth cues. Functional MRI work with humans indicates that motion parallax and depth cues are combined in area V3B/KO (<xref ref-type="bibr" rid="c1">Ban, Preston, Meeson, &#x0026; Welchman, 2012</xref>). Our results may therefore indicate that border-ownership cells, which combine motion parallax and binocular disparity, are present in this area. However, neurophysiology work with macaque (<xref ref-type="bibr" rid="c22">Zhou et al., 2000</xref>) and fMRI with humans (<xref ref-type="bibr" rid="c6">Fang, Boyaci, &#x0026; Kersten, 2009</xref>) indicate that the border-ownership cells are found as early as V2, including those selective for binocular disparity (<xref ref-type="bibr" rid="c14">Qiu &#x0026; von der Heydt, 2005</xref>; <xref ref-type="bibr" rid="c19">von der Heydt et al., 2000</xref>). Thus, motion parallax and binocular disparity signals may be combined earlier than V3B/KO.</p>
<p>Several models have been proposed to capture the mechanism by which border-ownership cells perform figure-ground segmentation, which can be broadly categorized as either feedforward (<xref ref-type="bibr" rid="c16">Sakai &#x0026; Nishimura, 2006</xref>; <xref ref-type="bibr" rid="c17">Sup&#x00E8;r, Romeo, &#x0026; Keil, 2010</xref>), lateral (<xref ref-type="bibr" rid="c21">Zhaoping, 2005</xref>), or feedback models (<xref ref-type="bibr" rid="c4">Craft, Schutze, Niebur, &#x0026; von der Heydt, 2007</xref>; <xref ref-type="bibr" rid="c11">Jehee, Lamme, &#x0026; Roelfsema, 2007</xref>); see (<xref ref-type="bibr" rid="c20">Williford &#x0026; Heydt, 2013</xref>) for a review. Our data provide new challenges for these models, as they will need to incorporate the capacity of border-ownership cells to jointly encode multiple depth cues with a high prevalence of depth order selectivity. Similarly, multiple models exist for describing the way in which the brain combines cues (<xref ref-type="bibr" rid="c12">Ohshiro, Angelaki, &#x0026; Deangelis, 2011</xref>; <xref ref-type="bibr" rid="c15">Rideaux &#x0026; Welchman, 2018</xref>); given that border-ownership cells appear to combine depth cues, future work may also investigate how border-ownership cells combine cues and whether it can be described by an existing model.</p>
<p>Growing evidence describing the properties of border-ownership cells suggest they are ideally suited for supporting figure-ground segmentation. The current study provides further support for the role of border-ownership cells in this fundamental visual process by showing that the process in humans jointly encodes multiple depth cues with strong depth order selectivity.</p>
</sec>
</body>
<back>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ban</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Preston</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Meeson</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Welchman</surname>, <given-names>A. E.</given-names></string-name> (<year>2012</year>). <article-title>The integration of motion and disparity cues to depth in dorsal visual cortex</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume>(<issue>4</issue>), <fpage>636</fpage>&#x2013;<lpage>643</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1038/nn.3046">http://doi.org/10.1038/nn.3046</ext-link></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Brainard</surname>, <given-names>D. H.</given-names></string-name> (<year>1997</year>). <article-title>The Psychophysics Toolbox</article-title>. <source>Spatial Vision</source>, <volume>10</volume>(<issue>4</issue>), <fpage>433</fpage>&#x2013;<lpage>436</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1163/156856897X00357">http://doi.org/10.1163/156856897X00357</ext-link></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Cornelissen</surname>, <given-names>F. W.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>E. M.</given-names></string-name>, &#x0026; <string-name><surname>Palmer</surname>, <given-names>J.</given-names></string-name> (<year>2002</year>). <article-title>The Eyelink Toolbox: eye tracking with MATLAB and the Psychophysics Toolbox</article-title>. <source>Behavior Research Methods, Instruments &#x0026; Computers</source>, <volume>34</volume>(<issue>4</issue>), <fpage>613</fpage>&#x2013;<lpage>617</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Craft</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Schutze</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Niebur</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>von der Heydt</surname>, <given-names>R.</given-names></string-name> (<year>2007</year>). <article-title>A Neural Model of Figure-Ground Organization</article-title>. <source>Journal of Neurophysiology</source>, <volume>97</volume>(<issue>6</issue>), <fpage>4310</fpage>&#x2013;<lpage>4326</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1152/jn.00203.2007">http://doi.org/10.1152/jn.00203.2007</ext-link></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Ernst</surname>, <given-names>M. O.</given-names></string-name>, &#x0026; <string-name><surname>B&#x00FC;lthoff</surname>, <given-names>H. H.</given-names></string-name> (<year>2004</year>). <article-title>Merging the senses into a robust percept</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>8</volume>(<issue>4</issue>), <fpage>162</fpage>&#x2013;<lpage>169</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1016/j.tics.2004.02.002">http://doi.org/10.1016/j.tics.2004.02.002</ext-link></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Fang</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Boyaci</surname>, <given-names>H.</given-names></string-name>, &#x0026; <string-name><surname>Kersten</surname>, <given-names>D.</given-names></string-name> (<year>2009</year>). <article-title>Border Ownership Selectivity in Human Early Visual Cortex and its Modulation by Attention</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>(<issue>2</issue>), <fpage>460</fpage>&#x2013;<lpage>465</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1523/JNEUROSCI.4628-08.2009">http://doi.org/10.1523/JNEUROSCI.4628-08.2009</ext-link></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Frund</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Haenel</surname>, <given-names>N. V.</given-names></string-name>, &#x0026; <string-name><surname>Wichmann</surname>, <given-names>F. A.</given-names></string-name> (<year>2011</year>). <article-title>Inference for psychometric functions in the presence of nonstationary behavior</article-title>. <source>Journal of Vision</source>, <volume>11</volume>(<issue>6</issue>), <fpage>16</fpage>&#x2013;<lpage>16</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1167/11.6.16">http://doi.org/10.1167/11.6.16</ext-link></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Gibson</surname>, <given-names>B. Y. J. J.</given-names></string-name>, &#x0026; <string-name><surname>Radner</surname>, <given-names>M.</given-names></string-name> (<year>1935</year>). <article-title>ADAPTATION, AFTER-EFFECT AND CONTRAST IN THE PERCEPTION OF TILTED LINES . I . QUANTITATIVE STUDIES An essential element in visual perception is one indicated by the terms edge, boundary, contour or line . Things are seen because they are delimited from</article-title>. <source>Perception</source>, <fpage>186</fpage>&#x2013;<lpage>196</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="book"><string-name><surname>Graham</surname>, <given-names>N. V. S.</given-names></string-name> (<year>1989</year>). <source>Visual pattern analyzers</source>. <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname>, <given-names>D. H.</given-names></string-name>, &#x0026; <string-name><surname>Wiesel</surname>, <given-names>T. N.</given-names></string-name> (<year>1959</year>). <article-title>Receptive fields of single neurones in the cat&#x2019;s striate cortex</article-title>. <source>The Journal of Physiology</source>, <volume>148</volume>(<issue>3</issue>), <fpage>574</fpage>&#x2013;<lpage>591</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1113/jphysiol.1959.sp006308">http://doi.org/10.1113/jphysiol.1959.sp006308</ext-link></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Jehee</surname>, <given-names>J. F. M.</given-names></string-name>, <string-name><surname>Lamme</surname>, <given-names>V. A. F.</given-names></string-name>, &#x0026; <string-name><surname>Roelfsema</surname>, <given-names>P. R.</given-names></string-name> (<year>2007</year>). <article-title>Boundary assignment in a recurrent network architecture</article-title>. <source>Vision Research</source>, <volume>47</volume>(<issue>9</issue>), <fpage>1153</fpage>&#x2013;<lpage>1165</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1016/j.visres.2006.12.018">http://doi.org/10.1016/j.visres.2006.12.018</ext-link></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Ohshiro</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Angelaki</surname>, <given-names>D. E.</given-names></string-name>, &#x0026; <string-name><surname>Deangelis</surname>, <given-names>G. C.</given-names></string-name> (<year>2011</year>). <article-title>A normalization model of multisensory integration</article-title>. <source>Nature Neuroscience</source>, <volume>14</volume>(<issue>6</issue>), <fpage>775</fpage>&#x2013;<lpage>782</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1038/nn.2815">http://doi.org/10.1038/nn.2815</ext-link></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Pelli</surname>, <given-names>D. G.</given-names></string-name> (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title>. <source>Spatial Vision</source>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1163/156856897X00366">http://doi.org/10.1163/156856897X00366</ext-link></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Qiu</surname>, <given-names>F. T.</given-names></string-name>, &#x0026; <string-name><surname>von der Heydt</surname>, <given-names>R.</given-names></string-name> (<year>2005</year>). <article-title>Figure and ground in the visual cortex: V2 combines stereoscopic cues with Gestalt rules</article-title>. <source>Neuron</source>, <volume>47</volume>(<issue>1</issue>), <fpage>155</fpage>&#x2013;<lpage>156</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1016/j.neuron.2005.05.028">http://doi.org/10.1016/j.neuron.2005.05.028</ext-link></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Rideaux</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Welchman</surname>, <given-names>A. E.</given-names></string-name> (<year>2018</year>). <article-title>Proscription supports robust perceptual integration by suppression in human visual cortex</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>), 1502. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1038/s41467-018-03400-y">http://doi.org/10.1038/s41467-018-03400-y</ext-link></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Sakai</surname>, <given-names>K.</given-names></string-name>, &#x0026; <string-name><surname>Nishimura</surname>, <given-names>H.</given-names></string-name> (<year>2006</year>). <article-title>Surrounding Suppression and Facilitation in the Determination of Border Ownership</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>18</volume>(<issue>4</issue>), <fpage>562</fpage>&#x2013;<lpage>579</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1162/jocn.2006.18.4.562">http://doi.org/10.1162/jocn.2006.18.4.562</ext-link></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Sup&#x00E8;r</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Romeo</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Keil</surname>, <given-names>M.</given-names></string-name> (<year>2010</year>). <article-title>Feed-forward segmentation of figure-ground and assignment of border-ownership</article-title>. <source>PLoS ONE</source>, <volume>5</volume>(<issue>5</issue>), <fpage>e10705</fpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1371/journal.pone.0010705">http://doi.org/10.1371/journal.pone.0010705</ext-link></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>von der Heydt</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Macuda</surname>, <given-names>T.</given-names></string-name>, &#x0026; <string-name><surname>Qiu</surname>, <given-names>F. T.</given-names></string-name> (<year>2005</year>). <article-title>Border-ownership-dependent tilt aftereffect</article-title>. <source>Journal of the Optical Society of America A</source>, <volume>22</volume>(<issue>10</issue>), 2222. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1364/JOSAA.22.002222">http://doi.org/10.1364/JOSAA.22.002222</ext-link></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>von der Heydt</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>H.</given-names></string-name>, &#x0026; <string-name><surname>Friedman</surname>, <given-names>H. S.</given-names></string-name> (<year>2000</year>). <article-title>Representation of stereoscopic edges in monkey visual cortex</article-title>. <source>Vision Research</source>, <volume>40</volume>(<issue>15</issue>), <fpage>1955</fpage>&#x2013;<lpage>1967</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1016/S0042-6989(00)00044-4">http://doi.org/10.1016/S0042-6989(00)00044-4</ext-link></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Williford</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Heydt</surname>, <given-names>R.</given-names></string-name> (<year>2013</year>). <article-title>Border-ownership coding</article-title>. <source>Scholarpedia</source>, <volume>8</volume>(<issue>10</issue>), <fpage>30040</fpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.4249/scholarpedia.30040">http://doi.org/10.4249/scholarpedia.30040</ext-link></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Zhaoping</surname>, <given-names>L.</given-names></string-name> (<year>2005</year>). <article-title>Border ownership from intracortical interactions in visual area V2</article-title>. <source>Neuron</source>, <volume>47</volume>(<issue>1</issue>), <fpage>143</fpage>&#x2013;<lpage>153</lpage>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1016/j.neuron.2005.04.005">http://doi.org/10.1016/j.neuron.2005.04.005</ext-link></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Friedman</surname>, <given-names>H. S.</given-names></string-name>, &#x0026; <string-name><surname>von der Heydt</surname>, <given-names>R.</given-names></string-name> (<year>2000</year>). <article-title>Coding of border ownership in monkey visual cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>20</volume>(<issue>17</issue>), 6594. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1523/JNEUROSCI.2797-12.2013">http://doi.org/10.1523/JNEUROSCI.2797-12.2013</ext-link></mixed-citation></ref>
</ref-list>
<sec>
<title>DATA AVAILABILITY</title>
<p>The data that support the findings of this study are available from the corresponding author upon request.</p>
</sec>
<ack>
<title>ACKNOWLEDGEMENTS</title>
<p>This work was supported by the Leverhulme Trust (ECF-2017-573 to RR) and the Wellcome Trust (095183/Z/10/Z to RR as a postdoctoral fellow of Andrew E Welchman), and by a National Health and Medical Research Council of Australia (CJ Martin Fellowship APP1091257 to WJH).</p>
</ack>
<sec>
<title>AUTHOR CONTRIBUTIONS</title>
<p>Both authors designed the experiments. RR programmed/performed/analysed the experiments. RR wrote the manuscript and WJH edited the manuscript.</p>
</sec>
<sec>
<title>COMPETING INTERESTS</title>
<p>The authors declare no competing interests.</p>
</sec>
</back>
</article>