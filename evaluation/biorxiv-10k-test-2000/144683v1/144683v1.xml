<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/144683</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A self-organizing memory network</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Federer</surname>
<given-names>Callie</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zylberberg</surname>
<given-names>Joel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Physiology and Biophysics, University of Colorado Anschutz Medical Campus</institution></aff>
<aff id="a2"><label>2</label><institution>Learning in Machines and Brains Program, Canadian Institute For Advanced Research</institution></aff>
</contrib-group>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>144683</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>5</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>31</day>
<month>5</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>5</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="144683.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Working memory requires information about external stimuli to be represented in the brain even after those stimuli go away. This information is encoded in the activities of neurons, and neural activities change over timescales of tens of milliseconds. Information in working memory, however, is retained for tens of <italic>seconds</italic>, suggesting the question of how time-varying neural activities maintain stable representations. Prior work shows that, if the neural dynamics are in the &#x2018;null space&#x2019; of the representation - so that changes to neural activity do not affect the downstream read-out of stimulus information - then information can be retained for periods much longer than the time-scale of individual-neuronal activities. The prior work, however, requires precisely constructed synaptic connectivity matrices, without explaining how this would arise in a biological neural network. To identify mechanisms through which biological networks can self-organize to support memory function, we derived biologically plausible synaptic plasticity rules that dynamically modify the connectivity matrix to enable information storing. Networks implementing this plasticity rule can successfully learn to store information even if only 10&#x0025; of the synapses are plastic, they are robust to synaptic noise, and they can store information about multiple stimuli.</p>
</abstract>
<counts>
<page-count count="9"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Working memory is a key cognitive function, and it relies on us retaining information about external stimuli even after they go away. Stimulus-specific elevated firing rates have been observed in the prefrontal cortex during the delay period of working memory tasks, and are the main neural correlates of working memory [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>]. Perturbations to the delay period neural activities cause changes in the animal&#x2019;s subsequent report of the remembered stimulus [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c23">23</xref>]. These elevated delay-period firing rates are not static but have time-varying dynamics with activities changing over timescales of tens of <italic>milliseconds</italic> [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c1">1</xref>], yet information can be retained for tens of <italic>seconds</italic> (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>). This suggests the question of how time-varying neural activities keeps representing the same information.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Stimulus retention in working memory. (<bold>A</bold>) When presented with an external stimulus, <italic>s</italic>, neural activity patterns initially encode an internal representation of that stimulus, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline1.gif"/></alternatives></inline-formula>. These neural activity patterns change over time on timescales of tens of milliseconds, and yet somehow the same information is stored for up to tens of seconds. (<bold>B</bold>) While the firing rates, <italic>r<sub>i</sub></italic>(<italic>t</italic>), change over time, information about stimulus, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline2.gif"/></alternatives></inline-formula>, can be remain unchanged as long as the projection of the firing rates onto the &#x201C;read-out&#x201D; vector <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline3.gif"/></alternatives></inline-formula>, remains constant [<xref ref-type="bibr" rid="c9">9</xref>].</p></caption>
<graphic xlink:href="144683_fig1.tif"/>
</fig>
<p>Prior work from Druckmann and Chklovksii shows that, if the neural dynamics are in the &#x201C;null space&#x201D; of the representation &#x2013; so that changes to neural activity do not affect the downstream read-out of stimulus information &#x2013; then information can be retained for periods much longer than the time-scale of individual neuronal activities (called the FEVER model; <xref ref-type="fig" rid="fig1">Fig. 1B</xref>) [<xref ref-type="bibr" rid="c9">9</xref>]. That model has a severe fine-tuning problem, discussed below. We identified a synaptic plasticity mechanism that overcomes this fine-tuning problem, enabling neural networks to learn to form stable representations.</p>
<p>While the dynamics of neurons in the FEVER model closely match that which is observed in the monkey prefrontal cortex during a working memory task [<xref ref-type="bibr" rid="c20">20</xref>], the model itself requires that the network connectivity matrix have one or more eigenvalues very near to unity. According to the Gershgorin Circle Theorem, this will almost surely not happen in randomly-connected networks: finely tuned connectivity is needed. Druckmann and Chklovskii suggest a mechanism of Hebbian learning by which this fine-tuned connectivity can be learned. That mechanism requires the read-out weights to form a &#x2018;tight frame&#x2019; [<xref ref-type="bibr" rid="c9">9</xref>], which will not necessarily be true in biological circuits. Thus, the prior work leaves it unknown how synaptic plasticity can form and/or maintain functional working memory networks.</p>
<p>In this paper, we identify biologically plausible synaptic plasticity rules that can solve this fine-tuning problem without making strong assumptions like &#x2018;tight frame&#x2019; representations. Our plasticity rules dynamically re-tune the connectivity matrix to enable persistent representations of stimulus information. We perform experiments to demonstrate that networks using these plasticity rules are able to store information about multiple stimuli, work even if only a fraction of the synapses are tuned, and are robust to synaptic noise. We also show that these networks improve over time with multiple presented stimuli, and that the learning rules work within densely or sparsely connected networks.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Model</title>
<sec id="s2a">
<label>2.1</label>
<title>The Rate-Based Network Model</title>
<p>We use a rate-based network like that of the FEVER model [<xref ref-type="bibr" rid="c9">9</xref>] but with positive rectifying activation functions (ReLU - rectified linear units) [<xref ref-type="bibr" rid="c5">5</xref>]. We use standard linear dynamics in the network model:
<disp-formula id="eqn1"><alternatives><graphic xlink:href="144683_eqn1.gif"/></alternatives></disp-formula>
where <italic>a</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the internal state (membrane potential) of the <italic>i</italic><sup>th</sup> neuron at time <italic>t, r</italic><sub><italic>j</italic></sub>(<italic>t</italic>) is the output (firing rate) of the j<sup><italic>th</italic></sup> neuron, <italic>&#x03C4;</italic> the time constant, and <italic>L</italic><sub><italic>ij</italic></sub> represents the strength of synaptic connection from neuron <italic>j</italic> to neuron <italic>i</italic>. The firing rates, <italic>r</italic><sub><italic>j</italic></sub>(<italic>t</italic>), are given by a positive rectifying function of the internal states: <italic>r</italic><sub><italic>j</italic></sub>(<italic>t</italic>) &#x003D; [<italic>a</italic><sub><italic>j</italic></sub>(<italic>t</italic>)]<sub>&#x002B;</sub>. After an external stimulus, <italic>s</italic>, is presented to the network, the network&#x2019;s representation of the stimulus, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline4.gif"/></alternatives></inline-formula> is obtained from a weighted combination of firing rates:
<disp-formula id="eqn2"><alternatives><graphic xlink:href="144683_eqn2.gif"/></alternatives></disp-formula>
where <italic>d</italic><sub><italic>i</italic></sub> is the weight of the contribution of neuron <italic>i</italic> to the stimulus (the &#x201C;read-out weight&#x201D;). For now we consider a single scalar stimulus value: we study the encoding of multiple stimuli in <xref ref-type="sec" rid="s3b">section 3.2</xref>.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Plasticity Rules</title>
<p>In order to organize the network to store information, we update the synaptic weights, <italic>L</italic><sub><italic>ij</italic></sub>, so as to minimize changes in the stimulus representation. To do this, we differentiated <xref ref-type="disp-formula" rid="eqn2">Equation 2</xref> with respect to time, to calculate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline5.gif"/></alternatives></inline-formula>. We then used gradient descent with respect to <italic>L</italic><sub><italic>ij</italic></sub> on loss function <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline6.gif"/></alternatives></inline-formula> to calculate the update rule:
<disp-formula id="eqn3"><alternatives><graphic xlink:href="144683_eqn3.gif"/></alternatives></disp-formula>
where <italic>&#x03B7;</italic> is the learning rate of the network and <italic>r</italic>&#x0027; is the slope of the (ReLU) activation function. In <xref ref-type="sec" rid="s3f">section 3.6</xref>, we discuss the biological plausibility of this plasticity rule. We chose the elements of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline7.gif"/></alternatives></inline-formula> to be positive based on candidate sources of the global error signal discussed in <xref ref-type="sec" rid="s3f">section 3.6</xref>. The source code and scripts for reproducing our experiments are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/cfederer/SOMN">https://github.com/cfederer/SOMN</ext-link>.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Results</title>
<sec id="s3a">
<label>3.1</label>
<title>Stimulus retention in the self-organizing memory network</title>
<p>To evaluate the performance of our working memory networks, we determined how well the networks could store information about a scalar stimulus value. We quantified the fraction of stimulus retained, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline8.gif"/></alternatives></inline-formula>, over 3 seconds. This is the duration of heightened activity observed during working memory tasks [<xref ref-type="bibr" rid="c10">10</xref>]. The networks were all-to-all connected (partial connectivity discussed in <xref ref-type="sec" rid="s3e">section 3.5</xref>) and contained 100 neurons. We first determined how well random networks without plastic synapses store information, by initializing each network with random neural activities, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline9.gif"/></alternatives></inline-formula>, random read-out weights, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline10.gif"/></alternatives></inline-formula>, and random connection weight matrices, <italic>L</italic>, and simulating the dynamical evolution of the representation. We then compared these &#x201C;constant random synapse&#x201D; networks to ones with identical random initial conditions, but in which our plasticity rule (<xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>) dynamically updated the synapses (<xref ref-type="fig" rid="fig2">Figs. 2B, C</xref>). Finally, we compared both of these randomly-initialized networks to ones that had the fine-tuned connectivity specified by the FEVER model.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Stimulus retention in self-organizing memory networks. (<bold>A</bold>) Neural dynamics of the first 50 ms of a simulation of two different networks with the same random initial conditions. One network had constant random synapses (bottom panel), while the other one had plastic synapses that were updated via <xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref> (top panel). Red dashed lines show the firing rates of 10 of the neurons. The remembered stimulus values at times 0, 17 ms and 35 ms (indicated by the shaded vertical bars) are shown. In the plastic random network, the remembered stimulus value does not change much even though the neural activities keep evolving. (<bold>B</bold>) The average fraction of stimulus retained over 100 random initializations for the FEVER model (black), the plastic synapse model (blue) and the constant random synapse model (red). (<bold>C</bold>) A zoomed in look at the average fraction of stimulus retained for the FEVER model and the plastic random synapse model from (B). Shaded areas in B and C represent &#x00B1; standard error of the mean.</p></caption>
<graphic xlink:href="144683_fig2.tif"/>
</fig>
<p>The stimulus value in the randomly-initialized plastic network initially decreased slightly, but the plasticity rules quickly reorganized the connectivity, and the representation remained constant after the first &#x007E; 50 ms. In the networks with fixed random synaptic weights, the representation quickly decayed to 0 (<xref ref-type="fig" rid="fig2">Figs. 2A, B</xref>). Thus, our plasticity rule enables initially random networks to quickly become effective working memory systems.</p>
<p>To ensure that the success of our plasticity rule at forming an effective memory network was not limited to a fortuitous random initialization, we quantified the fraction of stimulus retained over 100 different networks, each with a different initial connectivity matrix, read-out vector, and initial activity vector <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline11.gif"/></alternatives></inline-formula>. In the FEVER networks, stimulus retention is perfect across all networks. The models with plastic random synapses perform almost as well as the FEVER models, but require some time to self-organize before the representations remain constant (<xref ref-type="fig" rid="fig2">Figs. 2B, C</xref>). In the random constant synapse networks, information is quickly lost (<xref ref-type="fig" rid="fig2">Fig. 2B</xref>).</p>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Remembering multiple stimuli</title>
<p>The previous section shows how networks can self-organize to store information about one stimulus, but working memory capacity in adult humans is typically 3&#x2013;5 items [<xref ref-type="bibr" rid="c7">7</xref>]. To incorporate this working memory capacity into our models, we adapted the representation such that there were multiple read-out vectors, one for each stimulus value. We then derived plasticity rules via gradient descent on the squared and summed time derivatives of these representations: the loss was <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline12.gif"/></alternatives></inline-formula>. This led to the plasticity rule
<disp-formula id="eqn4"><alternatives><graphic xlink:href="144683_eqn4.gif"/></alternatives></disp-formula>
where <italic>n</italic> is the number of stimuli to be remembered. We chose <italic>n</italic> &#x003D; 4 for our experiments, and we quantified how well the networks remember these stimuli (S1-S4 in <xref ref-type="fig" rid="fig3">Fig. 3</xref>). (The networks can store up to 100 stimuli; data not shown). In our experiments, each neuron in the network contributed to the representation of every stimulus value: <italic>in vivo</italic>, most neurons are sensitive to multiple aspects of stimuli [<xref ref-type="bibr" rid="c19">19</xref>]. This is not a requirement: the models successfully represent multiple stimuli even when subsets of the neurons participate in each representation.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Remembering four things. (<bold>A</bold>) The average fraction of four stimuli retained for 100 randomly initialized networks with constant random synapses (dashed lines) and plastic random synapses (solid lines). Different colors are for different stimulus values. Shaded areas represent &#x00B1; standard error of the mean. (<bold>B</bold>). A zoomed in look at the average fraction of four stimuli retained in the plastic model in panel A. Shading omitted from lines in panel B for clarity.</p></caption>
<graphic xlink:href="144683_fig3.tif"/>
</fig>
</sec>
<sec id="s3c">
<label>3.3</label>
<title>Network Robustness</title>
<sec id="s3c1">
<label>3.3.1</label>
<title>Partial Tuning</title>
<p>While synapses are plastic, it is not known if <italic>all</italic> synapses change. To determine how well the network performs if only some synapses are updated, we simulated networks in which different fractions of the synapses were updated using <xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>: the other synapses were held constant. We quantified the fraction of stimulus retained by these networks (<xref ref-type="fig" rid="fig4">Fig. 4A</xref>). Even with just 10&#x0025; of the synapses being tuned, the networks learn to store information about the stimulus. In hindsight, this makes sense. To store <italic>n</italic> stimulus values, <italic>n</italic> constraints must be satisfied by the connectivity matrix: it must have <italic>n</italic> eigenvalues near 1 (we chose <italic>n</italic> &#x003D;1 for <xref ref-type="fig" rid="fig4">Fig. 4A</xref>). Because the connectivity matrix has many more than <italic>n</italic> elements, many configurations can satisfy the constraint, so it is possible to satisfy the constraint without updating every synapse.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Network robustness to partial plasticity and noise. (<bold>A</bold>) The fraction of stimulus retained for 100 random initializations. Different lines are for different fractions of plastic synapses. (<bold>B</bold>) The fraction of stimulus retained for 100 random initializations of networks with differing levels of synaptic update noise (<italic>&#x03B1;</italic>). Shaded areas in A and B represent &#x00B1; standard error of the mean.</p></caption>
<graphic xlink:href="144683_fig4.tif"/>
</fig>
</sec>
<sec id="s3c2">
<label>3.3.2</label>
<title>Noisy Synapses</title>
<p>Working memory must be robust to noise and imprecise components [<xref ref-type="bibr" rid="c4">4</xref>]. To determine how robust our networks are to synaptic noise, we simulated networks with various levels of random noise added to the synaptic updates. We added Gaussian noise with mean 0 and standard deviation <italic>&#x03B1;</italic> times the update to the synapse, &#x0394;<italic>L</italic><sub><italic>ij</italic></sub>, where <italic>&#x03B1;</italic> was varied from 0 to 1. We quantified the fraction of stimulus retained for networks with various noise levels and found that the noise did not have a noticeable effect on the network performance (<xref ref-type="fig" rid="fig4">Fig. 4B</xref>). The fraction of stimulus retained is almost equivalent for all values of <italic>&#x03B1;</italic>, with minor differences due to random initial conditions. This should not be surprising considering that multiplying error signals by random synaptic weights does not hinder learning, so long as the network is still being pushed down the loss gradient, even if not directly [<xref ref-type="bibr" rid="c17">17</xref>].</p>
</sec>
</sec>
<sec id="s3d">
<label>3.4</label>
<title>Pre-training the Network</title>
<p>In the previous examples, each network is initialized with random connection weights. In reality, the working memory network will be continuously learning and will not start over with random connection weights when each new stimulus is presented. Consequently, we speculated that, once the network had learned to store one stimulus, it should be able to remember subsequently presented stimuli, even with minimal re-training. Relatedly, experimental work shows that performance in working memory tasks in children and young adults can be increased not only for trained tasks but for new tasks not part of the training: this coincides with strengthening of connectivity in the prefrontal cortex [<xref ref-type="bibr" rid="c6">6</xref>].</p>
<p>To determine if our synaptic update rule enables the network to store new stimuli without further training, we first trained the networks (<xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>) to remember 1, 5 or 10 individual stimuli, one at a time: each new stimulus corresponded to another random initialization of the activity patterns <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline13.gif"/></alternatives></inline-formula>. We quantified the networks&#x2019; abilities to represent these training stimuli, and found that the networks performed better on each subsequent stimulus: training improved performance (<xref ref-type="fig" rid="fig5">Fig. 5A</xref>). Next, we asked if after training on 1, 5, or 10 prior stimuli, the network could store information about a new stimulus without any more synaptic updates. We found that a network was able to store information about a new stimulus after being trained on at least 1 previous stimulus (<xref ref-type="fig" rid="fig5">Fig. 5B</xref>). Once the connectivity weight matrix (<italic>L</italic>) has obtained one or more eigenvalues near unity, it is able to stably store novel stimuli without additional training.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Training improves performance. (<bold>A</bold>) The fraction of stimulus retained over 100 random initializations for a plastic random synapse network that has seen 0 previous stimuli (orange), 1 previous stimulus (blue), 5 previous stimuli (green) or 10 previous stimuli (purple). (<bold>B</bold>) The fraction of stimulus retained over 100 random initializations for a constant synapse network that has previously been trained on 0, 1, 5, or 10 previous stimuli, but with no training during the simulation period shown. Color coding as in panel A. Shaded areas in A and B represent &#x00B1; standard error of the mean.</p></caption>
<graphic xlink:href="144683_fig5.tif"/>
</fig>
</sec>
<sec id="s3e">
<label>3.5</label>
<title>Partially Connected Networks</title>
<p>In the previous results, the connectivity was all-to-all (100&#x0025; connectivity). Real neural circuits are not 100&#x0025; connected. In visual cortex, for example, connection probabilities range from 50&#x0025; to 80&#x0025; for adjacent neurons [<xref ref-type="bibr" rid="c14">14</xref>]. To ask if our synaptic update rule could self-organize partially connected networks, we simulated networks with different connection probabilities, and in which the synapses were updated using <xref ref-type="disp-formula" rid="eqn3">Eq. 3</xref>. We quantified the fraction of stimulus retained by these networks. Performance declines somewhat as connectivity decreases, but even networks with 10&#x0025; connection probabilities can learn to store stimulus information (<xref ref-type="fig" rid="fig6">Fig. 6</xref>). Experiments show that working memory performance declines with age, which correlates with a reduction in the number of synapses [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c2">2</xref>].</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><p>Network robustness to partial connectivity. The fraction of stimulus retained over 100 random initializations. Different lines are for different connection probabilities. Shaded areas represent &#x00B1; standard error of the mean.</p></caption>
<graphic xlink:href="144683_fig6.tif"/>
</fig>
</sec>
<sec id="s3f">
<label>3.6</label>
<title>Biological Plausibility</title>
<p>Synaptic updates are thought to rely on synaptically local information, like the activities of the pre- and post-synaptic neurons. Our plasticity rules (<xref ref-type="disp-formula" rid="eqn3">Eqs. 3</xref>,<xref ref-type="disp-formula" rid="eqn4">4</xref>) involve this information, in addition to &#x201C;global&#x201D; error value(s) <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline14.gif"/></alternatives></inline-formula>. Thus, we obtained three-factor rules: synaptic changes depend on the pre- and post-synaptic neurons&#x2019; activities, and a global error signal [<xref ref-type="bibr" rid="c17">17</xref>]. We propose two possible sources of the global error signal, one involving segregated dendrites, and the other using neuromodulators.</p>
<sec id="s3f1">
<label>3.6.1</label>
<title>Calculating the Global Error Signal Locally Using Segregated Dendrites</title>
<p>The global error signal could be calculated locally by each neuron, by exploiting the fact that, in pyramidal cells, feedback arrives at the apical dendrites, and modulates synaptic plasticity at the basal dendrites (where information comes in from other cells in the memory network) [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c12">12</xref>] (<xref ref-type="fig" rid="fig7">Fig. 7A</xref>). Here, a readout layer provides feedback to the apical dendrites that specifies the represented stimulus value <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline15.gif"/></alternatives></inline-formula> the weight of the feedback synapse to neuron <italic>i</italic> from read-out neuron <italic>k</italic> is <italic>d<sub>i<sub>k</sub></sub></italic>, and so the apical dendrite receives a signal <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline16.gif"/></alternatives></inline-formula>. The apical dendrites track the changes in these feedback signals, sending that information <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline17.gif"/></alternatives></inline-formula> to basal dendrites via the soma. Correlating those signals with the pre- and post-synaptic activity at each of the synapses on the basal dendrites, the synaptic updates specified by <xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref> are obtained. Thus, the neurons locally compute the synaptic updates.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption><p>Potential biological implementations. (<bold>A</bold>) Cartoon depicting the error signals being calculated locally by the neurons&#x2019; apical dendrites [<xref ref-type="bibr" rid="c12">12</xref>]. The read-out neuron calculates the remembered stimulus value via Eq. 7, where <italic>q</italic><sub><italic>i</italic></sub> is the weight of the synapses from cell <italic>i</italic> in the memory circuit to the read-out neuron. The apical dendrite calculates the error signal, weighted by <italic>d</italic><sub><italic>i</italic></sub>, by subtracting the feedback values at adjacent time points. The basal dendrite receives inputs from neurons in the working memory circuit. The soma transmits the error signal to the basal dendrites, where the synaptic updates, <italic>L</italic><sub><italic>ij</italic></sub> are calculated by correlating the pre- and post-synaptic activities with the error signal. (<bold>B</bold>) Cartoon depicting the error signals being communicated by neuromodulators. Neurons in the modulatory system calculate the remembered stimulus values via Eq. 7, where <italic>q</italic><sub><italic>i</italic></sub> is the weight of the synapse from cell <italic>i</italic> in the memory circuit to the modulatory read-out neuron. That cell releases an amount of neuromodulator that tracks the changes in the represented stimulus value. The modulatory chemical affects synaptic plasticity by an amount that depends on the receptor density, <italic>d</italic><sub><italic>i</italic></sub>, at the synapses on neuron <italic>i</italic>. Both implementations require asymmetric feedback: the weights to the read-out neuron from cell <italic>i</italic>(<italic>q</italic><sub><italic>i</italic></sub>) will not necessarily match the weights, <italic>d</italic><sub><italic>i</italic></sub>, with which cell <italic>i</italic> receives the feedback signals. (<bold>C</bold>) The fraction of stimulus retained over 100 random initializations of a network with a plastic random synapse model with symmetric feedback (<italic>q</italic> &#x003D; <italic>d</italic>) (blue), plastic random synapses with random feedback and readout weights (<italic>q</italic> &#x2260; <italic>d</italic>) (green), and constant synapses (red). The shaded areas represent &#x00B1; standard error of the mean.</p></caption>
<graphic xlink:href="144683_fig7.tif"/>
</fig>
</sec>
<sec id="s3f2">
<label>3.6.2</label>
<title>Signalling the Global Error Signal with Neuromodulators</title>
<p>Alternatively, the global error signal(s) could be communicated throughout the network by neuromodulators, like dopamine, acetylcholine, serotonin, norepinephrine or nitric oxide. These have all been shown to be important in synaptic plasticity in the prefrontal cortex and in working memory [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c8">8</xref>]. This is reward learning, with the reward values coming from the neuromodulator concentrations. Experimental work shows that synapses have activity-dependent &#x201C;eligibility traces&#x201D; that are converted into changes in synaptic strength by reward-linked neuromodulators [<xref ref-type="bibr" rid="c13">13</xref>]. In this scenario the concentration of different modulators tracks the error signals, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline18.gif"/></alternatives></inline-formula>, and the densities of the receptors to the modulators at each synapse are <italic>d<sub>i<sub>k</sub></sub></italic>. Thus, at each synapse, the modulators bring information <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="144683_inline19.gif"/></alternatives></inline-formula> that, when correlated with the pre- and post-synaptic activities, yields the updates from <xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref> (<xref ref-type="fig" rid="fig7">Fig. 7B</xref>).</p>
</sec>
<sec id="s3f3">
<label>3.6.3</label>
<title>Calculating the stimulus with random feedback weights</title>
<p>In either of the two scenarios discussed above, <italic>d</italic><sub><italic>i</italic></sub> must be accessed in two separate places: at the synapse, <italic>L</italic><sub><italic>ij</italic></sub>, to calculate the update, and at the read-out layer to calculate the remembered stimulus value (<xref ref-type="disp-formula" rid="eqn2">Eq. 2</xref>). Weight transport is not biologically plausible [<xref ref-type="bibr" rid="c17">17</xref>]. To remove this source of implausibility, we let the top-down feedback impinge on the neurons at synapses with weights <italic>d</italic><sub><italic>i</italic></sub>, and the read-out layer calculate the remembered stimulus as:
<disp-formula id="eqn5"><alternatives><graphic xlink:href="144683_eqn5.gif"/></alternatives></disp-formula>
where <italic>d</italic> &#x2260; <italic>q</italic> [<xref ref-type="bibr" rid="c17">17</xref>]. To test whether networks with this asymmetric feedback could learn to store stimulus information, we simulated such asymmetric networks and quantified the fraction of stimulus remaining. The results (<xref ref-type="fig" rid="fig7">Fig. 7C</xref>) show that even with asymmetric feedback, networks can learn to store stimulus information. This can be understood by noting that, so long as both <italic>q</italic> and <italic>d</italic> contain only positive elements, the feedback update signal to each synapse has the same sign as the update calculated from gradient descent. Thus, the synaptic updates with asymmetric feedback are in the same direction as those obtained from gradient descent, which suffices for learning [<xref ref-type="bibr" rid="c17">17</xref>].</p>
</sec>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Discussion</title>
<p>We derived biologically plausible synaptic plasticity rules through which networks self-organize to store information in working memory. Networks implementing these plasticity rules are robust to synaptic noise, to having only some of the synapses updated, and to partial connectivity. These networks can store multiple stimuli and have increased performance after previous training. We suggest two candidate sources for the global error signal necessary for the plasticity rule, and demonstrate that our networks can learn to store stimulus information while satisfying the added requirements imposed by these biological mechanisms. This flexibility suggests that other types of synaptic plasticity updates may also be able to organize working memory circuits.</p>
<p>The results presented here were obtained for networks of 100 neurons &#x2013; as opposed to larger networks &#x2013; to speed up the simulations. Tests on networks with 10,000 neurons show that the update rule works in larger networks. The optimal learning rate, <italic>&#x03B7;</italic>, decreases as the network size increases. Aside from network size, a potential caveat in using a rate-based network model is losing information about spike-timing dependency. A future direction would be to create a spike-based model and determine what, if anything, must be adjusted to account for spike timing, and for the discretization that spiking neurons entail for the information shared between cells.</p>
<p>Along with understanding how information is stored in working memory, this work may have implications in training recurrent neural networks (RNNs). Machine learning algorithms are generally unrealistic from a biological perspective: most algorithms rely on non-local synaptic updates or symmetric synapses. We show that a recurrent network can learn to store information using biologically plausible synaptic plasticity rules which require local information plus a global error signal (or signals), that can be calculated on the apical dendrite or via neuromodulators. This same synaptic update setup could be utilized in RNNs to make them more biologically realistic. This would let us better understand how the brain learns, and could lead to novel biomimetic technologies: prior work on biologically realistic machine learning algorithms has led to hardware devices that use on-chip learning [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c24">24</xref>]. Synaptically local updates do not have to be coordinated over all parts of the chip, enabling simpler and more efficient hardware implementations.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The authors would like to acknowledge Z. Kilpatrick, A. Person, G. Felson, J. Costello and J. Gilmer for their help. This work was supported by a Canadian Institute for Advanced Research (CIFAR), Azrieli Global Scholar Award, and a Google Faculty Research Award.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>E. H.</given-names> <surname>Baeg</surname></string-name>, <string-name><given-names>Y. B.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Huh</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Mook-Jung</surname></string-name>, <string-name><given-names>H. T.</given-names> <surname>Kim</surname></string-name>, and <string-name><given-names>M. W.</given-names> <surname>Jung</surname></string-name>. <article-title>Dynamics of population code for working memory in the prefrontal cortex</article-title>. <source>Neuron</source>, <volume>40</volume>(<issue>1</issue>):<fpage>177</fpage>&#x2013;<lpage>188</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>K.L.</given-names> <surname>Bopp</surname></string-name> and <string-name><given-names>P.</given-names> <surname>Verhaeghen</surname></string-name>. <article-title>Working Memory and Aging: Separating the Effects of Content and Context</article-title>. <source>Psychol Aging</source>, <volume>24</volume>(<issue>4</issue>):<fpage>968</fpage>&#x2013;<lpage>980</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>CD</given-names> <surname>Brody</surname></string-name>, <string-name><given-names>A</given-names> <surname>Hern&#x00E1;ndez</surname></string-name>, <string-name><given-names>A</given-names> <surname>Zainos</surname></string-name>, and <string-name><given-names>R.</given-names> <surname>Romo</surname></string-name>. <article-title>Timing and neural encoding of somatosensory parametric working memory in macaque prefrontal cortex</article-title>. <source>Cereb Cortex</source>, (<issue>11</issue>), <year>2003</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>CD</given-names> <surname>Brody</surname></string-name>, <string-name><given-names>R</given-names> <surname>Romo</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Kepecs</surname></string-name>. <article-title>Basic mechanisms for graded persistent activity: Discrete attractors, continuous attractors, and dynamic representations</article-title>. <source>Curr Opin Neurobiol</source>, <volume>13</volume>(<issue>2</issue>):<fpage>204</fpage>&#x2013;<lpage>211</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Carandini</surname></string-name>. <article-title>Amplification of trial-to-trial response variability by neurons in visual cortex</article-title>. <source>PLoS Biology</source>, <volume>2</volume>(<issue>9</issue>), <year>2004</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>C</given-names> <surname>Constantinidis</surname></string-name> and <string-name><given-names>T</given-names> <surname>Klingberg</surname></string-name>. <article-title>The neuroscience of working memory capacity and training</article-title>. <source>Nat Rev Neurosci.</source>, <volume>17</volume>(<issue>7</issue>):<fpage>438</fpage>&#x2013;<lpage>449</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Cowan</surname></string-name>. <article-title>NIH Public Access</article-title>. <source>Curr Dir Psychol Sci</source>, <volume>19</volume>(<issue>1</issue>):<fpage>51</fpage>&#x2013;<lpage>57</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>M D</given-names> <surname>&#x2018;esposito</surname></string-name> and <string-name><given-names>BR.</given-names> <surname>Postle</surname></string-name>. <article-title>The Cognitive Neuroscience of Working Memory</article-title>. <source>Annu. Rev. Psychol</source>, <volume>66</volume>:<fpage>115</fpage>&#x2013;<lpage>42</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>S</given-names> <surname>Druckmann</surname></string-name> and <string-name><given-names>DB.</given-names> <surname>Chklovskii</surname></string-name>. <article-title>Neuronal circuits underlying persistent representations despite time varying activity</article-title>. <source>Curr Biol</source>, <volume>22</volume>(<issue>22</issue>):<fpage>2095</fpage>&#x2013;<lpage>2103</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="other"><string-name><given-names>S</given-names> <surname>Funahashi</surname></string-name>, <string-name><given-names>M.V.</given-names> <surname>Chafee</surname></string-name>, and <string-name><given-names>P.S.</given-names> <surname>Goldman-Rakic</surname></string-name>. <article-title>Prefrontal neuronal activity in rhesus monkeys performing a delayed anti-saccade task</article-title>. <source>Nature</source>, (<issue>365</issue>):<fpage>753</fpage>&#x2013;<lpage>756</lpage>, <year>1993</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>J. M.</given-names> <surname>Fuster</surname></string-name> and <string-name><given-names>G. E.</given-names> <surname>Alexander</surname></string-name>. <article-title>Neuron Activity Related to Short-Term Memory</article-title>. <source>Science</source>, <volume>173</volume>(<issue>3997</issue>):<fpage>652</fpage>&#x2013;<lpage>654</lpage>, <year>1971</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>J</given-names> <surname>Guergiuev</surname></string-name>, <string-name><given-names>T.P.</given-names> <surname>Lillicrap</surname></string-name>, and <string-name><given-names>B.A.</given-names> <surname>Richards</surname></string-name>. <article-title>Deep learning with segregated dendrites</article-title>. <source>arXiv preprint</source>, <volume>1610</volume>(<issue>00161</issue>):<fpage>1</fpage>&#x2013;<lpage>29</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>K</given-names> <surname>He</surname></string-name>, <string-name><given-names>M</given-names> <surname>Huertas</surname></string-name>, <string-name><given-names>S.Z.</given-names> <surname>Hong</surname></string-name>, <string-name><given-names>X</given-names> <surname>Tie</surname></string-name>, <string-name><given-names>J.W.</given-names> <surname>Hell</surname></string-name>, <string-name><given-names>H</given-names> <surname>Shouval</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Kirkwood</surname></string-name>. <article-title>Distinct Eligibility Traces for LTP and LTD in Cortical Synapses</article-title>. <source>Neuron</source>, <volume>88</volume>(<issue>3</issue>):<fpage>528</fpage>&#x2013;<lpage>538</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>B</given-names> <surname>Hellwig</surname></string-name>. <article-title>A quantative analysis of the local connectivity between pyramidal neuron in layers 2/3 of the visual cortex</article-title>. <source>Biol. Cybern.</source>, <volume>82</volume>:<fpage>111</fpage>&#x2013;<lpage>121</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>P</given-names> <surname>Knag</surname></string-name>, <string-name><given-names>J.K.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>T</given-names> <surname>Chen</surname></string-name>, and <string-name><given-names>Z</given-names> <surname>Zhang</surname></string-name>. <article-title>A Sparse Coding Neural Network ASIC With On-Chip Learning for Feature Extraction and Encoding</article-title>. <source>IEEE J. Solid-State Circuits</source>, <volume>50</volume>(<issue>4</issue>):<fpage>1070</fpage>&#x2013;<lpage>1079</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>N</given-names> <surname>Li</surname></string-name>, <string-name><given-names>K</given-names> <surname>Daie</surname></string-name>, <string-name><given-names>K</given-names> <surname>Svoboda</surname></string-name>, and <string-name><given-names>S</given-names> <surname>Druckmann</surname></string-name>. <article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title>. <source>Nature</source>, <volume>532</volume>(<issue>7600</issue>):<fpage>459</fpage>&#x2013;<lpage>464</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="other"><string-name><given-names>T.P.</given-names> <surname>Lillicrap</surname></string-name>, <string-name><given-names>D</given-names> <surname>Cownden</surname></string-name>, <string-name><given-names>D.B.</given-names> <surname>Tweed</surname></string-name>, and <string-name><given-names>C.J.</given-names> <surname>Akerman</surname></string-name>. <article-title>Random feedback weights support learning in deep neural networks</article-title>. <source>Nat. Commun</source>, pages <fpage>1</fpage>&#x2013;<lpage>27</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>C.N.J.</given-names> <surname>Meunier</surname></string-name>, <string-name><given-names>P</given-names> <surname>Chameau</surname></string-name>, and <string-name><given-names>P. M.</given-names> <surname>Fossier</surname></string-name>. <article-title>Modulation of Synaptic Plasticity in the Cortex Needs to Understand All the Players</article-title>. <source>Front. Synaptic Neurosci.</source>, <volume>9</volume>(<issue>February</issue>):<fpage>2</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>E.K</given-names> <surname>Miller</surname></string-name> and <string-name><surname>Fusi</surname> <given-names>S</given-names></string-name>. <article-title>Limber neurons for a nimble mind</article-title>. <source>Neuron</source>, <volume>78</volume>(<issue>2</issue>):<fpage>211</fpage>&#x2013;<lpage>213</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>J.D.</given-names> <surname>Murray</surname></string-name>, <string-name><given-names>A</given-names> <surname>Bernacchia</surname></string-name>, <string-name><given-names>N.A</given-names> <surname>Roy</surname></string-name>, <string-name><given-names>C</given-names> <surname>Constantinidis</surname></string-name>, <string-name><given-names>R</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>X</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>S</given-names> <surname>Fusi</surname></string-name>, and <string-name><given-names>J.C.</given-names> <surname>Martinez-Trujillo</surname></string-name>. <article-title>Stable population coding for working memory coexists with heterogeneous neural dynamics in prefrontal cortex</article-title>. <source>Proc. Natl. Acad. Sci.</source>, <volume>114</volume>(<issue>2</issue>):<fpage>1</fpage>&#x2013;<lpage>6</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Peters</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Sethares</surname></string-name>, and <string-name><given-names>J. I.</given-names> <surname>Luebke</surname></string-name>. <article-title>Synapses are lost during aging in the primate prefrontal cortex</article-title>. <source>Neuroscience</source>, <volume>152</volume>(<issue>4</issue>):<fpage>970</fpage>&#x2013;<lpage>981</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>R</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>C D</given-names> <surname>Brody</surname></string-name>, <string-name><given-names>a</given-names> <surname>Hern&#x00E1;ndez</surname></string-name>, and <string-name><given-names>L</given-names> <surname>Lemus</surname></string-name>. <article-title>Neuronal correlates of parametric working memory in the prefrontal cortex</article-title>. <source>Nature</source>, <volume>399</volume>(<issue>6735</issue>):<fpage>470</fpage>&#x2013;<lpage>473</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>K</given-names> <surname>Wimmer</surname></string-name>, <string-name><given-names>D</given-names> <surname>Nykamp</surname></string-name>, <string-name><given-names>C</given-names> <surname>Constantinidis</surname></string-name>, and <string-name><given-names>A</given-names> <surname>Compte</surname></string-name>. <article-title>Bump attractor dynamics in prefrontal cortex explains behavioral precision in spatial working memory</article-title>. <source>Nat. Neurosci.</source>, <volume>17</volume>(<issue>3</issue>):<fpage>431</fpage>&#x2013;<lpage>439</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>J</given-names> <surname>Zylberberg</surname></string-name>, <string-name><given-names>J.T.</given-names> <surname>Murphy</surname></string-name>, and <string-name><given-names>M.R.</given-names> <surname>DeWeese</surname></string-name>. <article-title>A sparse coding model with synaptically local plasticity and spiking neurons can account for the diverse shapes of V1 simple cell receptive fields</article-title>. <source>PLoS Comput. Biol.</source>, <volume>7</volume>(<issue>10</issue>), <year>2011</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>