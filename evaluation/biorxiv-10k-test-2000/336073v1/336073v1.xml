<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/336073</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Evolutionary Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Unreasonable Effectiveness of Convolutional Neural Networks in Population Genetic Inference</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2106-4196</contrib-id>
<name>
<surname>Flagel</surname>
<given-names>Lex</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3392-0220</contrib-id>
<name>
<surname>Brandvain</surname>
<given-names>Yaniv</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5249-4151</contrib-id>
<name>
<surname>Schrider</surname>
<given-names>Daniel R.</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Monsanto Company</institution>, Chesterfield, MO.</aff>
<aff id="a2"><label>2</label><institution>Department of Plant and Microbial Biology, University of Minnesota</institution>, St. Paul, MN.</aff>
<aff id="a3"><label>3</label><institution>Department of Genetics, University of North Carolina</institution>, Chapel Hill, NC.</aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author. Email: <email>drs@unc.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>336073</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>31</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="336073.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>Population-scale genomic datasets have given researchers incredible amounts of information from which to infer evolutionary histories. Concomitant with this flood of data, theoretical and methodological advances have sought to extract information from genomic sequences to infer demographic events such as population size changes and gene flow among closely related populations/species, construct recombination maps, and uncover loci underlying recent adaptation. To date most methods make use of only one or a few summaries of the input sequences and therefore ignore potentially useful complementary information encoded in the data. The most sophisticated of these approaches involve likelihood calculations, which require theoretical advances for each new problem addressed, and often must focus on a single aspect of the data (e.g. allele frequency information only) in the interest of mathematical and computational tractability. Directly interrogating the entirety of the input sequence data in a likelihood-free manner would thus offer a fruitful alternative. Here we accomplish this by representing DNA sequence alignments as images and then using a deep learning technique called a convolutional neural network (CNN) to make population genetic inferences from these images. We apply CNNs to a number of evolutionary questions and find that they frequently exceed current state-of-the-art methods. Importantly, we show that CNNs can perform accurate evolutionary model selection and parameter estimation, even on problems that have not received detailed theoretical treatments. Thus, when applied to population genetic alignments, CNN are capable of outperforming expert-derived statistical methods, and offer a new path forward in cases where no theoretical approaches exist.</p>
</abstract>
<counts>
<page-count count="41"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>INTRODUCTION</title>
<p>Using genetic data to make inferences about the natural histories of populations represents a major goal of evolutionary research. As the ever-increasing throughput of DNA sequencing technologies makes the generation of large population genomic data sets more routine, researchers can leverage patterns of genetic variation across the genome to characterize the evolutionary forces at play (<xref ref-type="bibr" rid="c29">Hahn 2008</xref>). For example, advances have been made in identifying historical demographic events such as population size changes (<xref ref-type="bibr" rid="c72">Marth <italic>et al.</italic> 2004</xref>; <xref ref-type="bibr" rid="c108">Tennessen <italic>et al.</italic> 2012</xref>; <xref ref-type="bibr" rid="c26">Gazave <italic>et al.</italic> 2014</xref>) and genetic exchange between populations and species (<xref ref-type="bibr" rid="c73">Martin <italic>et al.</italic> 2013</xref>; <xref ref-type="bibr" rid="c32">Hellenthal <italic>et al.</italic> 2014</xref>; <xref ref-type="bibr" rid="c91">Sankararaman <italic>et al.</italic> 2014</xref>; <xref ref-type="bibr" rid="c16">Corbett-Detig and Nielsen 2017</xref>; <xref ref-type="bibr" rid="c94">Schrider <italic>et al.</italic> 2018</xref>). Population genomic analyses have also revealed the pervasive impact of selection on polymorphism on linked neutral polymorphism (<xref ref-type="bibr" rid="c7">Begun and Aquadro 1992</xref>; <xref ref-type="bibr" rid="c8">Begun <italic>et al.</italic> 2007</xref>; <xref ref-type="bibr" rid="c59">Langley <italic>et al.</italic> 2012</xref>; <xref ref-type="bibr" rid="c17">Elyashiv <italic>et al.</italic> 2016</xref>), both through positive selection (<xref ref-type="bibr" rid="c74">Maynard Smith and Haigh 1974</xref>; <xref ref-type="bibr" rid="c45">Kaplan <italic>et al.</italic> 1989</xref>) and purifying selection (<xref ref-type="bibr" rid="c14">Charlesworth <italic>et al.</italic> 1993</xref>). As the volume of population genomic data sets has increased, so too has the demand for powerful computational methods capable of using these data to learn about the fundamental evolutionary processes shaping genomic variation.</p>
<p>To meet this need, myriad statistical and computational tools have been devised to answer evolutionary questions using population genetic data. One particularly common paradigm, which predates the high-throughput sequencing revolution, is that of the population genetic summary statistic: a single value designed to capture the information present in a sequence alignment of individuals from one or more populations. When a particular evolutionary phenomenon acts on a population, it alters the shapes of genealogies, and this effect is then manifest in the observed sequence alignment. For example, a population expansion will result in genealogies with longer branches near the leaves of the tree, which will manifest as an excess of rare alleles. Many summary statistics seek to uncover the signature of these genealogical skews through their effect on the alignment; e.g. Tajima&#x2019;s <italic>D</italic> will be negative following a recent expansion or recovery from a bottleneck (<xref ref-type="bibr" rid="c107">Tajima 1989</xref>; <xref ref-type="bibr" rid="c100">Simonsen <italic>et al.</italic> 1995</xref>). Ideally a summary statistic will only detect the signal of the evolutionary process it is being used to investigate, but in practice summary statistics are frequently confounded by other forces that may have similar effects on the shapes and/or sizes of genealogies. For example, Tajima&#x2019;s <italic>D</italic> is sensitive to positive selection as well as population size changes (<xref ref-type="bibr" rid="c100">Simonsen <italic>et al.</italic> 1995</xref>).</p>
<p>Rather than detecting a phenomenon of interest, some statistics are designed to estimate theoretical population parameters such as the population-scaled mutation rate <italic>&#x03B8;</italic>=4<italic>&#x1D4A9;u</italic> (<xref ref-type="bibr" rid="c114">Watterson 1975</xref>; <xref ref-type="bibr" rid="c78">Nei and Li 1979</xref>; <xref ref-type="bibr" rid="c107">Tajima 1989</xref>; <xref ref-type="bibr" rid="c19">Fay and Wu 2000</xref>; <xref ref-type="bibr" rid="c1">Achaz 2009</xref>) or recombination rate <italic>&#x03C1;</italic>=4<italic>&#x1D4A9;r</italic> (<xref ref-type="bibr" rid="c41">Hudson and Kaplan 1985</xref>; <xref ref-type="bibr" rid="c38">Hudson 1987</xref>). Unfortunately, these statistics will also be sensitive to confounding forces, and will only estimate the parameter of interest when none of its assumptions are violated. Moreover, neither type of summary statistic will capture all of the information present in the alignment. Thus a major challenge of population genetic inference is to create methods that utilize as much information from the input data as possible in order to maximize our ability to distinguish among the numerous evolutionary processes that can give rise to an observed signal.</p>
<p>One approach researchers have adopted to address this challenge is to incorporate a larger number of observations from the data into likelihood-based inference methods. However, calculating likelihoods of population genomic data sets is often mathematically and computationally intractable, and therefore such approaches often ignore the non-independence of observations (e.g. using composite likelihoods; <xref ref-type="bibr" rid="c39">Hudson 2001</xref>; <xref ref-type="bibr" rid="c80">Nielsen <italic>et al.</italic> 2005</xref>). For example, Nielsen et al.&#x2019;s SweepFinder (2005), which examines allele frequencies at polymorphisms flanking a focal region to determine whether that region has experienced a recent selective sweep (<xref ref-type="bibr" rid="c74">Maynard Smith and Haigh 1974</xref>), treats each allele frequency as an independent observation despite the partially shared evolutionary histories linked alleles experience. Another drawback of most likelihood-based methods is that they generally compute the likelihood of very few features of the data (often only one), and therefore additional information that could improve accuracy is ignored. For example, SweepFinder examines allele frequencies but ignores linkage disequilibrium (LD), which is elevated in areas flanking the selected site (<xref ref-type="bibr" rid="c51">Kim and Nielsen 2004</xref>).</p>
<p>More recently, population geneticists have begun to explore an alternative strategy of using a large set of complementary summary statistics for model selection and parameter estimation, an approach that often results in more powerful and robust inference (e.g. <xref ref-type="bibr" rid="c67">Lin <italic>et al.</italic> 2011</xref>; <xref ref-type="bibr" rid="c84">Pybus <italic>et al.</italic> 2015</xref>; <xref ref-type="bibr" rid="c23">Gao <italic>et al.</italic> 2016</xref>; <xref ref-type="bibr" rid="c95">Schrider and Kern 2016</xref>; <xref ref-type="bibr" rid="c99">Sheehan and Song 2016</xref>). Each summary statistic seeks to measure a particular attribute of the genealogy, and one can thus design a customized set of summary statistics to more fully represent the genealogical information present in the sequence alignment. This view deploys summary statistics less for their individual links to underlying theory, and more for their collective ability to perform pattern recognition. The challenge then becomes extracting information about the underlying evolutionary processes from the set of summary statistics. Two exciting approaches for dealing with this challenge that have garnered increasing attention in recent years are approximate Bayesian computation (ABC; reviewed in <xref ref-type="bibr" rid="c6">Beaumont 2010</xref>) and supervised machine learning (reviewed in <xref ref-type="bibr" rid="c97">Schrider and Kern 2018</xref>). Both of these approaches make use of suites of user-defined summary statistics and training data generated under known parameters to identify reasonable evolutionary models and parameterizations that could have generated the observed data. Here we focus on the supervised machine learning approach, as it sets the scene for the convolutional neural networks described below.</p>
<p>In the terminology of supervised machine learning, each summary statistic is called a feature, and the full set of statistics used is called a feature vector. To use supervised machine learning, a researcher must first obtain training data (often referred to as &#x201C;labeled&#x201D; data)&#x2014;a set of data points for each of which the user has obtained a feature vector (the explanatory variables) accompanied by a known outcome (the response variable). Next, a supervised machine learning algorithm is trained to predict the outcome given the feature vector using the labeled training data. Thus, the supervised machine learning technique automates the process of extracting information and constructing rules from a set of summary statistics. Across many areas of research, supervised machine learning techniques are fast replacing rules developed by human experts because they are often more accurate (<xref ref-type="bibr" rid="c62">LeCun <italic>et al.</italic> 2015</xref>).</p>
<p>Machine learning methods are increasingly applied to numerous problems in population genomics (<xref ref-type="bibr" rid="c97">Schrider and Kern 2018</xref>). This approach requires the generation of labeled training data via population genetic simulation, an endeavor that has grown considerably more feasible given recent improvements in simulation flexibility and efficiency (e.g. <xref ref-type="bibr" rid="c110">Thornton 2014</xref>; <xref ref-type="bibr" rid="c46">Kelleher <italic>et al.</italic> 2016</xref>; <xref ref-type="bibr" rid="c30">Haller and Messer 2017</xref>; <xref ref-type="bibr" rid="c47">Kelleher <italic>et al.</italic> 2018</xref>). To date, population genetic applications of machine learning include demographic inference (<xref ref-type="bibr" rid="c83">Pudlo <italic>et al.</italic> 2016</xref>; <xref ref-type="bibr" rid="c99">Sheehan and Song 2016</xref>), local ancestry inference (<xref ref-type="bibr" rid="c94">Schrider <italic>et al.</italic> 2018</xref>), inferring recombination rates (<xref ref-type="bibr" rid="c66">Lin <italic>et al.</italic> 2013</xref>; <xref ref-type="bibr" rid="c23">Gao <italic>et al.</italic> 2016</xref>), and detecting genomic regions experiencing recent selective sweeps (<xref ref-type="bibr" rid="c81">Pavlidis <italic>et al.</italic> 2010</xref>; <xref ref-type="bibr" rid="c67">Lin <italic>et al.</italic> 2011</xref>; <xref ref-type="bibr" rid="c88">Ronen <italic>et al.</italic> 2013</xref>; <xref ref-type="bibr" rid="c84">Pybus <italic>et al.</italic> 2015</xref>; <xref ref-type="bibr" rid="c95">Schrider and Kern 2016</xref>). While such methods have great promise, they still rely on a user-defined set of summary statistics. Moreover, it is not known whether it is possible to construct a set of statistics that sufficiently captures all relevant information in the input data.</p>
<p>Unlike other machine learning approaches, convolutional neural networks (CNN; <xref ref-type="bibr" rid="c63">LeCun <italic>et al.</italic> 1998</xref>) are pattern recognition algorithms that do not require a predefined feature vector. When fed labeled training data, a CNN discovers meaningful features itself, in essence making a feature vector, and then extracts information from these features in order to make inferences. CNNs have proved effective in a number of fields (reviewed in <xref ref-type="bibr" rid="c62">LeCun <italic>et al.</italic> 2015</xref>), and particularly in the field of image recognition, where they have achieved dramatic improvements over previous efforts (e.g. <xref ref-type="bibr" rid="c60">Lawrence <italic>et al.</italic> 1997</xref>; <xref ref-type="bibr" rid="c57">Krizhevsky <italic>et al.</italic> 2012</xref>; <xref ref-type="bibr" rid="c101">Simonyan and Zisserman 2014</xref>). The application of CNNs to population genomic inference is just beginning, and shows great promise (<xref ref-type="bibr" rid="c13">Chan <italic>et al.</italic> 2018</xref>; <xref ref-type="bibr" rid="c50">Kern and Schrider 2018</xref>). Population genetic questions may be particularly well suited for CNN-based learning because they take matrices as inputs, and alignments of sequenced chromosomes are quite naturally represented in this manner.</p>
<p>The goal of this paper is to assess the effectiveness of CNNs as a general strategy for population genomic inference. We demonstrate that CNNs can be successfully applied to a number of population genomic problems, in some cases achieving surprising accuracy. In particular, we use simulation to show that CNNs can leverage images of aligned sequences to accurately detect selective sweeps, uncover regions experiencing gene flow between related populations/species, make demographic inferences, and estimate recombination rates. Indeed, in most cases we observe performance that matches or exceeds that of current state-of-the-art methods. We also use a CNN to accurately infer recombination rates from read coverage data in a simulated autotetraploid, demonstrating this approach&#x2019;s flexibility in handling noisy data while solving a complex problem for which no theoretical solutions exist. In light of these encouraging findings, we argue that population genetics researchers should consider CNNs as a potential solution to a variety of problems involving evolutionary inferences from sequence data. Because many readers will have little background with this tool, we also provide an overview of the inner workings of CNNs and explore several technical considerations that may impact performance.</p>
</sec>
<sec id="s2">
<title>MATERIALS AND METHODS</title>
<sec id="s2a">
<title>Overview of convolutional neural networks</title>
<p>Internally, a CNN is a type of artificial neural network &#x2013; a collection of connected layers of combinatorially linked logic functions (termed <italic>artificial neurons</italic>) that take an input and transform it into an output value (<xref ref-type="bibr" rid="c76">Mitchell 1997</xref>). In a typical fully connected artificial neural network, the input values are fed through a series of layers of neurons (<xref rid="fig1" ref-type="fig">Figure 1A</xref>), termed hidden layers, before reaching the output layer which transforms its inputs into a final prediction. The output for the <italic>j</italic><sup>th</sup> neuron within one of the hidden layers is given by the following:
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="336073_ueqn1.gif"/></alternatives>
</disp-formula></p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Schematics of a standard feedforward neural network and two convolutional neural network designs used in this study.</title>
<p>A) Diagram of a fully connected feedforward neural network. Gray circles represent input (left side), output (right side), or hidden (center) neurons. Blue circles represent collections of bias terms. With the exception of the input layer, the value of any given neuron is a linear combination of values from the previous layer plus a bias term; this sum is then passed to an activation function (not shown). Each edge represents a distinct weighted input or bias term. Outputs may represent class membership posterior probabilities or estimates of continuous variables. B) A diagram of a 2D CNN similar to that used in this study to infer demographic parameters. The input is an alignment represented as an image which is passed through a first convolutional layer in order to create a set of feature maps which are then downsized via a pooling step. These feature maps are then passed through a second convolutional filter and pooling step, and the resulting output is flattened in order to be passed as input into a fully connected feedfoward layer (bias terms not shown). Also passed into this layer is output from a second branch of this network: the vector of positions of segregating sites in the alignment which have been passed through their own fully connected layer. Finally, the last fully connected ANN layer yields the predicted output values. C) Similar to panel B, but showing a 1D CNN with three convolutional layers (each followed by a pooling step), as used for our recombination rate estimator.</p></caption>
<graphic xlink:href="336073_fig1.tif"/>
</fig>
<p>In the expression above, <italic>x</italic><sub><italic>i</italic></sub> is the neuron&#x2019;s <italic>i</italic><sup>th</sup> input value (either an input value from the data or from a neuron in the previous layer&#x2019;s output), and <italic>w</italic><sub><italic>ij</italic></sub> is the <italic>weight</italic> attached to the connection between that node (<italic>i</italic>) and the current node (<italic>j</italic>) and <italic>b</italic><sub><italic>j</italic></sub> is the current node&#x2019;s <italic>bias</italic> term. That is, to obtain the value of neuron <italic>j</italic>, we compute the linear combination of the vector containing all values from the previous layer and the <italic>j</italic><sup>th</sup> neuron&#x2019;s vector of weights; the results of this summation are in turn added to neuron <italic>j</italic>&#x2019;s bias term and then fed as input to some function <italic>f</italic>, termed the <italic>activation function</italic>. Thus, an artificial neural network is a mathematical function.</p>
<p>Importantly, by changing the values of the weights and biases, an artificial neural network can be tuned to detect informative patterns in the input data in order to produce the desired output. In the case of image recognition, an image is first represented numerically, typically as a matrix of pixel intensities, and then transformed by the artificial neural network to produce an output, for example a prediction of the type of object in the image. CNNs (<xref rid="fig1" ref-type="fig">Figure 1B&#x2013;C</xref>) differ from standard artificial neural networks in that they begin with one or more convolutional layers, in which a series of smaller weight matrices referred to as &#x201C;filters&#x201D; slide across the input image&#x2014; mimicking the manner in which animal cortical neurons each focus on input only from a small receptive field&#x2014;and perform a matrix convolution at each step until a series of filtered image matrices are produced (<xref ref-type="bibr" rid="c63">LeCun <italic>et al.</italic> 1998</xref>). Each convolutional layer is often followed by a pooling layer which reduces the size of these filtered image matrices while maintaining potentially important discriminatory information obtained by the convolutional filters. Finally, these matrices are flattened and fed into a fully connected (or &#x201C;dense&#x201C;) artificial neural network (for an accessible overview see <xref ref-type="bibr" rid="c62">LeCun <italic>et al.</italic> 2015</xref>). Thus, salient features derived from the image matrix by the convolutional and pooling layers are passed into one or more layers of a fully connected neural network whose output layer then yields our predicted response value.</p>
<p>CNNs allow for two types of convolutional layers: 1-dimensional and 2-dimensional layers, which differ only with respect to the possible shapes that the convolutional filter can take (<xref rid="fig1" ref-type="fig">Figure 1B&#x2013;C</xref>). 1-dimensional (1D) convolutions are often used in the application to time-series data, but are also applicable to sequence alignment matrices. Despite its name, a 1D filter is not a vector but rather a rectangular matrix that spans a user-defined number of entries (called the &#x201C;kernel size&#x201C;) in one dimension in the input data (in our case this dimension is that of the polymorphic sites in the alignment), and stretches entirely across the other dimension (in our case across all chromosomes in the sample). A 2-dimensional (2D) convolutional filter, which is more often used with image data, allows the user to specify both dimensions of the filter matrix (often using a square matrix). Whether 1- or 2-dimensional, the benefit of incorporating convolutions is that it allows the CNN to take advantage of structural information in the input data. For example, from an image of a face, a CNN can learn to detect the repeated pattern of the eye shape and the location of both eyes relative to one another and to other features. When there is meaningful structural information such as this, CNNs tend to outperform non-convolutional neural networks.</p>
<p>Here our input data is an alignment of linked segregating sites with partially shared evolutionary histories. Our hope is that a CNN can discover structural information in these data in order to make evolutionary inferences&#x2014;for example, locating the valley in diversity at the center of a sweep (<xref ref-type="bibr" rid="c74">Maynard Smith and Haigh 1974</xref>), the &#x201C;shoulders&#x201D; on the flanks of a sweep where linkage disequilibrium and allele frequencies are both elevated (<xref ref-type="bibr" rid="c98">Schrider <italic>et al.</italic> 2015</xref>), or even the spatial relationship between these different structures. We also note that neural networks such as CNNs can have multiple &#x201C;branches&#x201D; each with separate architectures and input types&#x2014; in some of the cases discussed below we will incorporate an additional network branch whose input is the vector of the positions of the segregating sites (<xref rid="fig1" ref-type="fig">Figure 1B&#x2013;C</xref>).</p>
<p>Like all supervised machine learning methods, a CNN must be trained on labeled training data before it can make predictions on unlabeled data (i.e. data whose response variables are unknown). Training is accomplished by tuning the weights and biases that control the behavior of its artificial neurons so that together they maximize the accuracy of the outputs on the training data. This tuning occurs over a number of iterations using the backpropagation algorithm (<xref ref-type="bibr" rid="c90">Rumelhart <italic>et al.</italic> 1986</xref>), which in modern implementations feeds a small number of training examples (a &#x201C;mini-batch&#x201C;) through the network and then estimates the error gradient on the output vectors produced for these examples. The error gradient is then propagated in reverse through the network&#x2014;a given hidden neuron&#x2019;s contribution to the error is proportional to the linear combination of its weight vector and the errors associated with each neuron in the next layer. The weights are then updated using one of the many flavors of stochastic gradient descent (e.g. <xref ref-type="bibr" rid="c53">Kingma and Ba 2014</xref>). This process repeats until each training example has been fed through the network, marking the completion of a single training iteration. Training continues for a number of these iterations (often called epochs) until a specified stopping criterion is reached (e.g. a predefined number of iterations has been performed, accuracy on the validation set has not improved relative to the previous iteration, etc.).</p>
<p>In the context of population genetics, the CNN&#x2019;s input could be a matrix of allelic states at each polymorphic site (<xref rid="fig2" ref-type="fig">Figure 2</xref>). For example, an alignment of haploid individuals <italic>M</italic>, where <italic>M</italic><sub><italic>ij</italic></sub>=0 if the <italic>i</italic><sup>th</sup> individual has the ancestral allele at the <italic>j</italic><sup>th</sup> segregating site in the alignment, and 1 if this individual has the derived allele (an input format that can easily be altered to allow for multiallelic polymorphisms); we adopt this approach and variants of it below. The output can be a categorical indicator (e.g. whether or not the genomic window experienced a recent selective sweep) in which the problem is referred to as a classification task in machine learning terminology, a quantitative value (e.g. the population recombination rate) in which case the task is referred to as regression, or a vector with numerous categorical and/or quantitative values. Once the CNN has been trained to produce the desired output, it can be applied to unlabeled data (e.g. sequence from natural populations).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Example population genetic alignments visualized as black-and-white images.</title>
<p>An unsorted alignment matrix (left) and this same matrix sorted by genetic similarity among chromosomes (right) are shown. Each row represents one of twenty chromosomes in the sample and each column represents one of forty segregating sites. Derived and ancestral states are encoded as black and white, respectively.</p></caption>
<graphic xlink:href="336073_fig2.tif"/>
</fig>
<p>Because supervised machine learning relies on predictive functions tuned algorithmically from training data rather than theoretical predictions, CNNs can be flexibly applied to any problem for which a training set can be obtained. In a population genetics context, coalescent simulations provide a versatile and computationally efficient (<xref ref-type="bibr" rid="c40">Hudson 2002</xref>; <xref ref-type="bibr" rid="c109">Teshima and Innan 2009</xref>; <xref ref-type="bibr" rid="c18">Ewing and Hermisson 2010</xref>; <xref ref-type="bibr" rid="c46">Kelleher <italic>et al.</italic> 2016</xref>; <xref ref-type="bibr" rid="c49">Kern and Schrider 2016</xref>) means to generating training data. In this paper we relied exclusively on coalescent simulations to produce training data for the CNN. However, compute-intensive forward population simulations may offer greater flexibility than coalescent simulations in some situations, and recent advances are making them more computationally feasible (<xref ref-type="bibr" rid="c47">Kelleher <italic>et al.</italic> 2018</xref>).</p>
</sec>
<sec id="s2b">
<title>Computational environment for training CNNs</title>
<p>All CNNs used in this study were developed using two open source Python packages: Keras (version 2.0.6; <ext-link ext-link-type="uri" xlink:href="https://keras.io/">https://keras.io/</ext-link>) to define neural network architecture and orchestrate training and testing, and TensorFlow (version 1.1.0; <ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/">https://www.tensorflow.org/</ext-link>) as the backend (i.e. TensorFlow performs the computation during training/testing). All code used for training is available online (<ext-link ext-link-type="uri" xlink:href="https://github.com/flag0010/pop_gen_cnn">https://github.com/flag0010/pop_gen_cnn</ext-link>).</p>
</sec>
<sec id="s2c">
<title>CNN validation strategy</title>
<p>For each task, we divided our set of simulated inputs into three sets: a training set, a validation set, and a test set. The training set was used to optimize the weights and biases of the CNN. The validation set was used during training to determine how well the CNN generalizes to unseen data, and adjustments were made to the CNN to improve its performance on the validation data. Finally, the test set was used to obtain a performance assessment of the final trained network. Importantly, this test set was previously unseen by the CNN and therefore yields an unbiased evaluation of its accuracy.</p>
</sec>
<sec id="s2d">
<title>Evaluating techniques for rescaling and reordering inputs to improved CNN accuracy</title>
<p>To evaluate the impact of alternative data preparation techniques (below), we developed a simple CNN that estimates the locus-wide population mutation rate <italic>&#x03B8;</italic>=4<italic>&#x1D4A9;&#x03BC;L</italic> where <italic>&#x03BC;</italic> is the mutation rate per base pair per generation and <italic>L</italic> is the physical length of the locus being examined. (<ext-link ext-link-type="uri" xlink:href="https://github.com/flag0010/pop_gen_cnn/tree/master/data_prep_tricks">https://github.com/flag0010/pop_gen_cnn/tree/master/data_prep_tricks</ext-link>). This CNN is trained using alignment images with forty chromosomes and <italic>&#x03B8;</italic> drawn uniformly between 10 and 50 as simulated for a panmictic, constant sized population by ms (<xref ref-type="bibr" rid="c40">Hudson 2002</xref>). We trained this CNN to minimize the root mean squared error (RMSE) between its prediction and the true value of <italic>&#x03B8;</italic> using 4,000 training matrices. Then its accuracy was scored on 1,000 test matrices that the CNN was never trained on. These values were compared under the different data preparation approaches described below.</p>
<p>First, the matrices output by most coalescent simulation software, including ms, encode ancestral and derived alleles for bialleleic sites as 0 and 1, respectively, and present the matrix with chromosomes as rows and sites as columns. When doing 1D convolutions, we used row-wise convolutional filters (<xref rid="fig1" ref-type="fig">Figure 1C</xref>), i.e. those that examine each chromosome in our sample across a small number of contiguous segregating sites (specified by the &#x201C;kernel_size&#x201D; parameter in Keras) before sliding the filter forward one site (our stride length, &#x201C;strides&#x201D; in Keras, was always set to 1). At present Keras does not allow for row-wise 1D convolutions, so we accomplished this by simply transposing the alignment matrix and performing column-wise convolutions.</p>
<p>We find that sorting the chromosomes in the alignment by genetic similarity accelerates learning. For example, the matrices in <xref rid="fig2" ref-type="fig">Figure 2</xref> contain identical information, but chromosomes in the matrix on the left are randomized, while on the right they are sorted by genetic similarity. We found that the CNN trains faster when given sorted matrices like the one on the right in <xref rid="fig2" ref-type="fig">Figure 2</xref>. We offer a fast algorithm for sorting matrices by genetic similarity (sort_min_diff function: <ext-link ext-link-type="uri" xlink:href="https://github.com/flag0010/pop_gen_cnn/blob/master/data_prep_tricks/genet.data.matrix.prep.tricks.py">https://github.com/flag0010/pop_gen_cnn/blob/master/data_prep_tricks/genet.data.matrix.prep.tricks.py</ext-link>).</p>
</sec>
<sec id="s2e">
<title>Introgression detection</title>
<p>To detect introgression, we simulated training and test examples with msmove (<ext-link ext-link-type="uri" xlink:href="https://github.com/geneva/msmove">https://github.com/geneva/msmove</ext-link>) from the same demographic model that <xref ref-type="bibr" rid="c94">Schrider et al. (2018)</xref> used to train the FILET classifier for detecting introgression between <italic>Drosophila simulans</italic> and <italic>D. sechellia</italic>. In total we produced 237,500 coalescent simulations from 3 classes: 112,500 without no migration between species (No Introgression), 112,500 with gene flow from <italic>D. simulans</italic> into <italic>D. sechellia</italic> (<italic>sim</italic>&#x2192;<italic>sech</italic>), and 12,500 with gene flow from <italic>D. sechellia</italic> into <italic>D. simulans</italic> (<italic>sech</italic>&#x2192;<italic>sim</italic>). We used fewer <italic>sech</italic>&#x2192;<italic>sim</italic> examples because test runs on smaller training sets suggested that the network could detect this class fairly accurately, which allowed us to increase the sampling of the other two more challenging classes. The simulations were randomly assigned to training and validation sets so that the training set included 107,500 examples each from the No Introgression and <italic>sim</italic>&#x2192;<italic>sech</italic> classes, and 7,500 examples from the <italic>sech</italic>&#x2192;<italic>sim</italic> class. Both the validation set and the test set contained 2,500 of each class (i.e. 7,500 total).</p>
<p>As in the <italic>Drosophila</italic> data set to which Schrider et al. applied FILET, each of our coalescent simulations generated 34 chromosomes (14 <italic>D. sechellia</italic> and 20 <italic>D. simulans</italic>). Each column in the alignment corresponded to a biallelic polymorphism, which was encoded as &#x201C;0&#x201D; (ancestral allele) or &#x201C;1&#x201D; (derived allele) for each chromosome. Each matrix was organized so that individual chromosomes were grouped by species. Each coalescent simulation produced a different number of segregating sites (with the largest containing 1201 polymorphisms). Because the CNN&#x2019;s input matrices must all have the same dimensions, we padded the right side of all matrices with fewer than 1201 polymorphisms with columns containing only &#x201C;0&#x201D; until the total number of columns reached 1201. Finally we transposed this matrix resulting in a 1201&#x00D7;34 matrix for each coalescent simulation.</p>
<p>We trained a CNN architecture with three 1D-convolutional layers (kernel size = 2), each followed by average-pooling, and finally two densely connected layers (i.e. the same network architecture as the main network branch illustrated in <xref rid="fig1" ref-type="fig">Figure 1C</xref>, but with one additional dense layer). These layers contained 256, 128, 128, 128, and 128 neurons, respectively. To avoid overfitting during training, each layer used dropout regularization (randomly removing 25&#x0025; of neurons between convolutional layers during each training iteration, and 50&#x0025; between densely connected layers) and rectified linear unit activation functions (i.e. ReLUs; <xref ref-type="bibr" rid="c77">Nair and Hinton 2010</xref>). This &#x201C;dropout regularization&#x201D; encourages the CNN to learn redundant representations of the data, thereby reducing the network&#x2019;s dependence on individual weights (<xref ref-type="bibr" rid="c104">Srivastava <italic>et al.</italic> 2014</xref>). The last layer was a sigmoid output layer with 3 neurons, each corresponding to the 3 classes given above. The CNN was trained using the Adam optimization procedure (<xref ref-type="bibr" rid="c53">Kingma and Ba 2014</xref>), a categorical cross-entropy loss function, and a mini-batch size of 256. The CNN was run for 19 training iterations through the training data.</p>
</sec>
<sec id="s2f">
<title>Recombination rate: phased haplotype version</title>
<p>For the recombination rate estimator we used <monospace>ms</monospace> (<xref ref-type="bibr" rid="c40">Hudson 2002</xref>) to simulate 50 chromosomes, each with a target length of 20kb. To do so, we drew a population size (<italic>&#x1D4A9;</italic>) from the following values: 5,000, 10,000, 15,000, 20,000, and 50,000, and set the mutation rate parameter <italic>&#x03B8;</italic> = 4<italic>&#x1D4A9;&#x03BC;L</italic> (letting <italic>&#x03BC;</italic>=1.5&#x00D7;10<sup>&#x2212;8</sup> and again <italic>L</italic>=20kb). We also set a population-scaled recombination rate, <italic>&#x03C1;</italic> = 4<italic>&#x1D4A9;rL</italic>, where <italic>r</italic> is the per bp crossover rate per meiosis, by drawing <italic>r</italic> from a bounded exponential distribution ranging from10<sup>&#x2212;8</sup> to 10<sup>&#x2212;6</sup>. Following this procedure, we generated 156,275 coalescent simulations. &#x223C;92&#x0025; were used to train the CNN, and &#x223C;4&#x0025; each were set aside for validation and testing. To assess our CNNs ability to interpolate to unseen population sizes, we also created 5,000 additional test matrices using the procedures above, but with <italic>&#x1D4A9;</italic> drawn uniformly from the following: 30,000, 35,000, 40,000, and 45,000.</p>
<p>Each simulation was represented by a matrix of 50 rows, one for each chromosome, and 418 columns (the largest number of segregating sites). As before we encoded the ancestral allele with &#x201C;0&#x201D; and the derived allele with &#x201C;1&#x201C;. Because not all simulations resulted in the same number of polymorphisms, we padded both the genotype matrix and the position vector in the same manner as for the introgression CNN, bringing the total size of each matrix to 50&#x00D7;418. Next, we sorted each matrix by genetic similarity among chromosomes as described above and then transposed the matrix to 418&#x00D7;50. We also extracted the segregating site positions vector from the ms output which represents each position as a real number between zero (the leftmost position on the simulated chromosome) and one (the rightmost position). For simulations with fewer than 418 segregating sites, we padded the positions vector with &#x201C;-1&#x201C;s.</p>
<p>Prior to training, we also transformed the <italic>&#x03C1;</italic> values for the training, validation, and test sets by taking the natural log of each value and centering them on the mean of the training set. By using the mean from the training set for each of these we ensure that there is no leakage of information between training and validation/testing.</p>
<p>We trained a CNN with two input branches. The first branch took the haplotype matrices as input and included three 1D-convolutional layers (kernel size = 2), each followed by average-pooling. These layers contained 1250, 256, and 256 neurons, respectively. Each of these layers uses dropout normalization (25&#x0025;), L2-regularization of the weights (&#x03BB; = 0.0001), and ReLU activation functions. The second branch takes the position vector as input and contains one densely connected layer with 64 neurons, again using dropout normalization (10&#x0025;) and a ReLU activation function. The two branches are then merged into another densely connected layer of 256 neurons with ReLU activation functions. Finally, the output layer is a single neuron with a simple linear activation function that predicts the continuous <italic>&#x03C1;</italic> value. The CNN was trained using the Adam optimization algorithm, using mean-squared error as our loss function, and a mini-batch size of 32. The CNN was trained for 16 iterations.</p>
<p>We compared our CNN&#x2019;s results to those of <monospace>LDhat</monospace> version 2.2a (<ext-link ext-link-type="uri" xlink:href="https://github.com/auton1/LDhat">https://github.com/auton1/LDhat</ext-link>). We chose <monospace>LDhat</monospace> because it is widely used to estimate historical recombination rates, and because it can be efficiently run on large data sets. LDhat will estimate <italic>&#x03C1;</italic> only for a specified population mutation rate (<italic>&#x03B8;</italic> = 4<italic>&#x1D4A9;&#x03BC;</italic>), and we supplied it with the exact <italic>&#x03B8;</italic> value used for each coalescent simulation. This was done by creating five likelihood lookup tables using the <monospace>complete</monospace> program, all set for 50 haploid chromosomes, for the following <italic>&#x03B8;</italic> values: 6, 12, 18, 24, and 60. Respectively, these correspond to <italic>&#x1D4A9;</italic> = 5,000, 10,000, 15,000, 20,000, and 50,000 (the same values we used for training our CNNs). <monospace>LDhat</monospace> only predicts values within the bounds of the lookup table. Therefore, to facilitate a fair comparison to results from our CNN, which is unbounded, we selected the maximum <italic>&#x03C1;</italic> value in the likelihood lookup table to be 133.3&#x0025; of the true maximum for each <italic>&#x03B8;</italic>. We then set the grid size of <italic>&#x03C1;</italic> equal 1, and estimated <italic>&#x03C1;</italic> on the test set using <monospace>LDhat&#x2019;s pairwise</monospace> program.</p>
<p>In contrast, the CNN was not provided information about <italic>&#x03B8;</italic>, and instead had to infer <italic>&#x03C1;</italic> independent of <italic>&#x03B8;</italic>. This ability would be a desirable property for an estimator, as <italic>&#x03B8;</italic> is likely to vary considerably across the genome and outside of simulated data sets one may never know <italic>&#x03B8;</italic> precisely. On the other hand, the CNN was provided with the physical distance between segregating sites, information <monospace>LDhat</monospace> does not utilize but which will generally be available when making inferences on real data. Both of these factors make our direct comparison of the CNN with <monospace>LDhat</monospace> imperfect because each had access to information the other lacked when producing its estimate. Nonetheless we consider this example a useful illustration of the CNN&#x2019;s power.</p>
</sec>
<sec id="s2g">
<title>Recombination rate: autotetraploid version</title>
<p>We sought to train a CNN to estimate a locus-wide recombination rate in autotetraploid genomes. To add a level of methodological realism to this problem, we did so from a matrix storing a simple summary of read pileup information at each site for each individual.</p>
<p>To this end, we generated new coalescent simulations with 48 chromosomes each following the procedure outlined above for the haploid CNN. This approach is reasonable because it has been shown that the standard coalescent approximates the appropriate coalescent for autotetraploids as long as &#x1D4A9; is larger than a few hundred (<xref ref-type="bibr" rid="c2">Arnold <italic>et al.</italic> 2012</xref>). We generated 217,500 coalescent simulations, and randomly assigned 200,000 to the training set, 10,000 to the validation set, and 7,500 to the test set. Next, within each coalescent simulation, we randomly partitioned our 48 chromosomes into twelve sets of four. Each set represents one synthetic autotetraploid genome and every site has five possible genotypes (<italic>AAAA, AAAa, AAaa, Aaaa</italic>, and <italic>aaaa</italic>). For each autotetraploid genome <italic>i</italic> and each site <italic>j</italic> we simulated the number of reads covering the site (<italic>C</italic><sub><italic>ij</italic></sub>) by drawing a random sample from a Poisson distribution with &#x03BB; = 25. Then we selected the number of reads representing the <italic>a</italic> allele <italic>R</italic><sub><italic>ij</italic></sub> <italic>&#x223C; Binom(n=C</italic><sub><italic>ij</italic></sub>, <italic>p=x</italic><sub><italic>ij</italic></sub><italic>)</italic>, where <italic>x</italic><sub><italic>ij</italic></sub> represents the frequency of the <italic>a</italic> allele in the tetraploid genotype (i.e. 0, 0.25, 0.5, 0.75, and 1 for the five genotypes listed above). For each individual <italic>i</italic> at site <italic>j</italic>, the corresponding entry in the input matrix was the fraction <italic>R</italic><sub><italic>ij</italic></sub>/<italic>C</italic><sub><italic>ij</italic></sub>, i.e. the fraction of reads supporting the derived allele. The <italic>AAAA</italic> and <italic>aaaa</italic> genotypes were always 0 and 1, respectively. For the three heterozygous genotypes (<italic>AAAa, AAaa</italic>, and <italic>Aaaa</italic>), <italic>R</italic><sub><italic>ij</italic></sub>/<italic>C</italic><sub><italic>ij</italic></sub> varied based on sampling error but had expected values of 0.25, 0.5, and 0.75, respectively. Thus at each site the original 48 chromosomes were reduced to a set of 12 values corresponding to the fractions of reads supporting the <italic>a</italic> allele in a pool of sequence reads from an autotetraploid sequenced at &#x223C;25X coverage. Note that this scheme does not include sequencing error but is nonetheless adequate for our proof of concept.</p>
<p>As above, we sorted the rows of this matrix by genetic similarity and padded each matrix with zeros to a length of 460 (the most segregating sites of any of the simulated matrices) before transposing, yielding a 460&#x00D7;12 matrix. Again, we recorded the padded vector of positions from the simulation output. Our CNN architecture was identical to the one given above for the phased haplotype version, except for the dimensionality of the input changed to 460&#x00D7;12, and we reduced the first convolutional layer from 1250 to 256 because of the smaller second dimension of the input. The CNN was trained for 9 iterations.</p>
</sec>
<sec id="s2h">
<title>Detecting selective sweeps and discriminating between modes of selection</title>
<p>For detecting selective sweeps, we used the same coalescent simulations that <xref ref-type="bibr" rid="c96">Schrider and Kern (2017)</xref> used to train a classifier to detect sweeps in the JPT population (Japanese individuals from Tokyo) from Phase 3 of the 1000 Genomes dataset (<xref ref-type="bibr" rid="c3">Auton <italic>et al.</italic> 2015</xref>). The JPT demographic scenario is one where detecting selective sweeps is fairly difficult (see Figure S1 from <xref ref-type="bibr" rid="c96">Schrider and Kern 2017</xref>), as expected for bottlenecked populations (<xref ref-type="bibr" rid="c42">Jensen <italic>et al.</italic> 2005</xref>). For this CNN, we began with a set of 269,000 simulated genomic windows with the 5 following classes: a recent hard sweep (i.e. fixation of a <italic>de novo</italic> beneficial mutation), a recent soft sweep (i.e. fixation of a beneficial but previously neutral segregating polymorphism), a region linked to a nearby hard sweep, a region linked to a nearby soft sweep, and a neutrally evolving region. Each simulated alignment contained 208 chromosomes and we kept only coalescent simulations that contained &#x2264; 5,000 segregating sites, and again padded with zeros so that all matrices were 208&#x00D7;5000. This left 238,655 simulations, and from those we constructed a training set of 233,655 simulations. In trial runs, we found that regions flanking hard and soft sweeps were the most difficult classes to predict, so we shifted the balance of our training set so that is was comprised of approximately 13&#x0025; neutral regions, 17&#x0025; each for hard and soft sweeps, and 26.5&#x0025; each for regions linked to nearby hard and soft sweeps windows. We then set aside an evenly balanced set of 2,000 simulations for validation and 3,000 for testing.</p>
<p>As before, we sorted each matrix by genetic similarity among chromosomes and then transposed the matrix to 5000&#x00D7;208. We also extracted the segregating site positions vector from these simulations which were generated by <monospace>discoal</monospace> (<xref ref-type="bibr" rid="c49">Kern and Schrider 2016</xref>), which like <monospace>ms</monospace> represents each position as a real number between zero and one.</p>
<p>As above, we trained a CNN with two input branches. The first branch took the haplotype matrices as input and included five 1D-convolutional layers (kernel size = 2), each followed by average-pooling. These layers each contained 256 neurons and used dropout normalization (20&#x0025;). The second branch takes the position vector as input and contains one densely connected layer with 64 neurons, again using dropout normalization (10&#x0025;). The two branches are then merged into another densely connected layer of 256 neurons with 25&#x0025; dropout. Each hidden layer of the network used L2-regularization of the weights (&#x03BB; = 0.0001) and ReLU as the activation function. Finally, the output of this layer was fed to a five neuron layer with softmax activation functions that predicts the five classes given above. The CNN was trained using the Adam optimization algorithm, the categorical cross-entropy loss function, and a mini-batch size of 32. The CNN was trained for 3 iterations.</p>
</sec>
<sec id="s2i">
<title>Inferring population size histories</title>
<p>To show how CNNs can be used to infer species&#x2019; demographic histories, and how CNN architecture can impact this inference, we experimented with a variety of CNN approaches to infer the 5 parameters of a 3-epoch model of instantaneous population size changes (i.e. 3 population sizes and 2 times of size change). We also use this challenging problem as an opportunity to evaluate how alternative approaches to building a CNN can influence its performance. In effect, we conducted a full grid search of the following attributes of both our CNN architecture and input/output format: the dimensionality of our convolutions (1D or 2D), the kernel size (i.e. the width of our 1D convolutional filters and both the height and width of our square 2D filters; we tried each multiple of 2 raging from 2 to 10), whether to include dropout (yes or no) following max pooling steps or dense layers, whether to sort our rows based on similarity (yes or no), whether to log-scale our response variables (yes or no), and whether to represent ancestral and derived alleles as &#x2212;1/1 or as 0/255. When included, our dropout layers immediately followed both max pooling steps, the dense layer following the distance input layer, and the final dense layer. Each of these dropout steps randomly removed 25&#x0025; of neurons. Each response variable was transformed to a <italic>&#x1D4CF;</italic>-score according to the sample mean and variance for that variable across all simulated examples.</p>
<p>The network we used for this task had two branches: a standard CNN like that depicted in <xref rid="fig1" ref-type="fig">Figure 1B&#x2013;C</xref> but with more convolutional layers (four CNN layers each producing 128 filters and each followed by a max pooling layer with a kernel size of 2), and a dense neural network layer (consisting of 32 nodes) taking positional information as its input, and concatenating its output with that of the final max pooling layer of the CNN prior to being fed into the final dense layer (256 nodes). The positional information was a vector, <bold><italic>d</italic></bold>, whose length was the maximum of the number of segregating sites observed across all simulated examples minus one. Each value in the vector <italic>d</italic><sub><italic>i</italic></sub> was simply the distance (scaled between zero and one where one is the total length of the simulated region) between segregating site <italic>i</italic> and site <italic>i</italic>-1.</p>
<p>In total, we simulated 100,000 examples using <monospace>ms</monospace>. 10,000 each were set aside for testing and validation, while the remaining 80,000 were used for training. The simulated population size histories were generated randomly&#x2014;each demographic model parameter was drawn uniformly from a rage listed in Table S1. Each simulated region was roughly equivalent 1.5 Mbp in the human genome, assuming per base pair mutation and recombination rates of 1.2&#x00D7;10<sup>&#x2212;8</sup> and 1&#x00D7;10<sup>&#x2212;8</sup>, respectively. However, in order to make the size of the simulation output more tractable for processing in a CNN we divided the mutation rate by 10 (equivalent to randomly downsampling the number of polymorphisms included in the input by a factor of 10). During training we used a batch size of 200, trained our networks for up to 10 iterations, and retained the best performing CNN as assessed on the validation set. Often the best CNN was obtained prior to completing all 10 training iterations. We then evaluated the performance of the best CNN for each network architecture and input format on the test set by calculating total RMSE (our loss function for this task); we also calculated Spearman correlation coefficients between the true and predicted values for each of the five demographic model parameters.</p>
</sec>
</sec>
<sec id="s3">
<title>RESULTS</title>
<p>Our goal is to use a CNN to make population genetic inferences from an alignment image, which can be thought of as matrices where each entry represents the allele present in a given chromosome at a given site. In particular, we focus on four distinct problems: identifying local introgression, estimating the recombination rate, detecting selective sweeps, and inferring population size changes. We chose these four tasks because each represents a different challenge in population genetic inference, each with its own attendant branch of theory. To show the ability of CNNs to solve problems that are not already solved, we extended our recombination inference to infer recombination rates in autotetraploids with tetrasomic inheritance. We took slightly different approaches in training the CNN for each task, though we hope any lack of consistency in part demonstrates the different ways in which one can successfully implement and tune CNNs.</p>
<p>Below, we address each of these problems in turn, providing a brief overview of the phenomenon in question and existing methodology before describing our results using CNNs. But prior to tackling these problems, we begin by introducing a few strategies for reorganizing our input data that we found to be helpful in making CNNs work efficiently with population genetic alignments.</p>
<sec id="s3a">
<title>Using a CNN to make inferences from an alignment: a simple test case</title>
<p>We evaluated the performance impact of transposing the alignment matrix and sorting the chromosomes in the alignment matrix by genetic similarity. We did this using a CNN trained to estimate the population-scaled mutation rate, <italic>&#x03B8;</italic>, in an equilibrium population. We found that both of these techniques accelerates the decline in root-mean-square error RMSE (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Transposing the alignment matrix so that chromosomes are represented by rows and polymorphisms by columns has a particularly notable effect (compare blue and black lines in <xref rid="fig3" ref-type="fig">Figure 3</xref>). Additionally, sorting the chromosomes by genetic similarity further increases the accuracy of the CNN when combined with the matrix transposition above (magenta line); alternatively, using a permutation-invariant network architecture would abdicate any need for this step (<xref ref-type="bibr" rid="c13">Chan <italic>et al.</italic> 2018</xref>). The effect of transposition should disappear when using 2D convolutions because in those cases we always used a square convolutional filter matrix (Methods), but we found that 1D CNNs often performed as well as 2D CNNs (data not shown). Thus, unless otherwise specified we use 1D convolutions for the tasks discussed below.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>The impact of input data reorganization on accuracy.</title>
<p>We show the root mean squared error (RMSE) of a 1D CNN&#x2019;s predictions of <italic>&#x03B8;</italic> as assessed on 1,000 test alignments after a given number of training iterations. Each line is the average of 10 runs. The blue line shows accuracy after training using alignment matrices with each row representing one chromosome. The black line shows accuracy after transposing of all matrices so that chromosomes correspond to columns (so that 1D convolutional filters examine each individual at a group of adjacent segregating sites). The magenta line shows the impact of transposing matrices, and sorting the chromosomes in the alignment matrix by genetic similarity.</p></caption>
<graphic xlink:href="336073_fig3.tif"/>
</fig>
</sec>
<sec id="s3b">
<title>CNN&#x2019;s can accurately detect introgressed loci</title>
<p>Recent studies indicate that closely related species often exchange genes (<xref ref-type="bibr" rid="c58">Kulathinal <italic>et al.</italic> 2009</xref>; <xref ref-type="bibr" rid="c73">Martin <italic>et al.</italic> 2013</xref>; <xref ref-type="bibr" rid="c10">Brandvain <italic>et al.</italic> 2014</xref>; <xref ref-type="bibr" rid="c21">Fontaine <italic>et al.</italic> 2015</xref>). There are several motivations for locating genomic segments introgressed from one species into another. For one, the occurrence of cross-species gene flow raises the possibility of adaptive introgression, wherein a beneficial allele enters a population via migration from a related species (reviewed in <xref ref-type="bibr" rid="c31">Hedrick 2013</xref>). Discovering introgressed loci can therefore identify alleles underlying rapid ecological adaptation as well as the source of these alleles. In addition, uncovering genomic regions that are and are not porous to cross species gene flow may help to illuminate the genomic basis of reproductive isolation (<xref ref-type="bibr" rid="c111">Turner <italic>et al.</italic> 2005</xref>).</p>
<p>Researchers have thus sought to devise methods capable of detecting introgressed regions from multispecies population genomic data sets. These include methods that attempt to infer the ancestry for each individual at each site (e.g. <xref ref-type="bibr" rid="c82">Price <italic>et al.</italic> 2009</xref>; <xref ref-type="bibr" rid="c61">Lawson <italic>et al.</italic> 2012</xref>; <xref ref-type="bibr" rid="c103">Sohn <italic>et al.</italic> 2012</xref>) and those that explicitly seek to discriminate between introgressed and non-introgressed loci (<xref ref-type="bibr" rid="c27">Geneva <italic>et al.</italic> 2015</xref>; <xref ref-type="bibr" rid="c89">Rosenzweig <italic>et al.</italic> 2016</xref>; <xref ref-type="bibr" rid="c94">Schrider <italic>et al.</italic> 2018</xref>). We trained a CNN to identify introgression in a scenario modeled after <italic>Drosophila simulans</italic> and <italic>D. sechellia</italic> (Methods), two species where there is evidence for recent gene flow (<xref ref-type="bibr" rid="c24">Garrigan <italic>et al.</italic> 2012</xref>). <xref rid="fig4" ref-type="fig">Figure 4</xref> displays the results of these tests in the form of confusion matrices, which show the fraction of test examples correctly predicted for each class (diagonal values) as well as the fractions incorrectly assigned (off-diagonal values). Overall, this CNN classified 88.5&#x0025; of test simulations correctly. The most difficult scenario for the CNN was introgression from <italic>D. simulans</italic> into <italic>D. sechellia</italic>, which it misclassified as &#x201C;no introgression&#x201D; 23&#x0025; of the time. For the other two classes the CNN accuracy was &#x003E;95&#x0025;. Importantly, in every case this CNN achieved greater accuracy than FILET, a machine learning approach that leverages a vector of 31 summary statistics (<xref ref-type="bibr" rid="c94">Schrider <italic>et al.</italic> 2018</xref>). Importantly, FILET was previously shown to outperform several competing methods, including two statistics for detecting introgression (<xref ref-type="bibr" rid="c43">Joly <italic>et al.</italic> 2009</xref>; <xref ref-type="bibr" rid="c27">Geneva <italic>et al.</italic> 2015</xref>), and a tool that infers local ancestry tracks for each individual (<xref ref-type="bibr" rid="c61">Lawson <italic>et al.</italic> 2012</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Performance of classifiers for detecting introgression.</title>
<p>We use confusion matrices to show the performance of a CNN trained to detect genomic regions of introgression between two closely related species (panel A), and a competing method that uses a vector of summary statistics to the same end (FILET; panel B). These classifiers were tested on data simulated under a joint demographic history inferred from a sample of <italic>Drosophila simulans</italic> and <italic>D. sechellia</italic> individuals (as described in the Methods) with and without introgression. The classifiers seek to discriminate among three classes: no introgression in the genomic window being examined, introgression from <italic>D. sechellia</italic> to <italic>D. simulans</italic>, and introgression from <italic>D. simulans</italic> into <italic>D. sechellia</italic>. Each entry in the matrix shows the fraction of test examples belonging to the class specified on the <italic>y</italic>-axis that were inferred by the method to belong to the class specified on the <italic>x</italic>-axis. Correct classifications are those found along the diagonals, while all off-diagonal entries represent incorrect classifications.</p></caption>
<graphic xlink:href="336073_fig4.tif"/>
</fig>
</sec>
<sec id="s3c">
<title>Estimating historical recombination rate</title>
<p>Recombination creates new combinations of alleles, and the degree of linkage between selected sites affects the efficiency with which natural selection can act on each individual site (<xref ref-type="bibr" rid="c36">Hill and Robertson 1966</xref>). The interplay of selection and recombination also influences the landscape of diversity across the genome (<xref ref-type="bibr" rid="c7">Begun and Aquadro 1992</xref>). Knowledge of recombination rates is thus key to population genetics research. As a more practical alternative to estimating rates directly (e.g. from pedigrees; <xref ref-type="bibr" rid="c54">Kong <italic>et al.</italic> 2010</xref>), one can infer recombination rates from population genetic data by examining associations among alleles at different sites. A number of methods have been proposed to solve this problem, including summary statistic estimation approaches (e.g. <xref ref-type="bibr" rid="c41">Hudson and Kaplan 1985</xref>; <xref ref-type="bibr" rid="c38">Hudson 1987</xref>; <xref ref-type="bibr" rid="c35">Hey and Wakeley 1997</xref>), composite likelihood-based methods (e.g. <xref ref-type="bibr" rid="c39">Hudson 2001</xref>; <xref ref-type="bibr" rid="c75">McVean <italic>et al.</italic> 2004</xref>; <xref ref-type="bibr" rid="c12">Chan <italic>et al.</italic> 2012</xref>), and machine learning tools using a vector of statistics (<xref ref-type="bibr" rid="c66">Lin <italic>et al.</italic> 2013</xref>; <xref ref-type="bibr" rid="c23">Gao <italic>et al.</italic> 2016</xref>). We sought to determine if a CNN taking an alignment image as input could be trained to tackle this task.</p>
<p>To address this problem, we first trained a CNN to estimate the historical population recombination rate <italic>&#x03C1;</italic>=4<italic>&#x1D4A9;r</italic> (where <italic>r</italic> is the crossover rate per base pair per meiosis) from phased chromosomes. This is the simplest scenario, as the arrangement of alleles on chromosomes is completely resolved. Following training, we compared the CNN&#x2019;s performance to that of <monospace>LDhat</monospace> (<xref ref-type="bibr" rid="c75">McVean <italic>et al.</italic> 2004</xref>), a widely used composite likelihood method, on the same testing data (<xref rid="fig5" ref-type="fig">Figure 5</xref>). We generated a test set of alignments whose values of <italic>&#x03C1;</italic> spanned three orders of magnitude, from 0.0002 to 0.2 (expressed per bp). Overall, both approaches performed well at predicting the true value of <italic>&#x03C1;</italic>. <monospace>LDhat</monospace> had an <italic>R</italic><sup>2</sup> = 0.77 and an RMSE = 0.016, whereas the CNN had a <italic>R</italic><sup>2</sup> = 0.86 and an RMSE = 0.011 (<xref rid="fig5" ref-type="fig">Figure 5A,B</xref>). <monospace>LDhat</monospace> appears to estimate <italic>&#x03C1;</italic> slightly better than the CNN for lower recombination rates, whereas the CNN performs better at the higher values of <italic>&#x03C1;</italic> (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). Additionally, the CNN appears to provide a roughly unbiased estimator of <italic>&#x03C1;</italic>, while <monospace>LDhat</monospace>&#x2019;s estimates appear downwardly biased.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Accuracy of recombination rate estimates from <monospace>LDhat</monospace> and our CNN.</title>
<p>Panels A and B show the real <italic>&#x03C1;</italic> values on the <italic>x</italic>-axes and LDhat&#x2019;s (A) and the CNN&#x2019;s (B) predictions on the <italic>y</italic>-axes. Panel C again shows the real <italic>&#x03C1;</italic> values on the <italic>x</italic>-axis, and the probability that the CNN was more accurate than <monospace>LDhat</monospace> (black line) on the <italic>y</italic>-axis. This probability was calculated by scoring estimates where the CNN outperformed <monospace>LDhat</monospace> as one and the reciprocal as zero, and then smoothing these values with a lowess curve with a span of 15&#x0025;. The red line represents the expectation if both methods had identical accuracy. Panel D shows the results from the simulated autotraploid model, with the real <italic>&#x03C1;</italic> values on the <italic>x</italic>-axes and the CNN prediction on the <italic>y</italic>-axes.</p></caption>
<graphic xlink:href="336073_fig5.tif"/>
</fig>
<p>Because the CNN was capable of estimating <italic>&#x03C1;</italic> independent of <italic>&#x03B8;</italic>, we were interested to see how well it could interpolate between the <italic>&#x03B8;</italic> values it was trained with. The CNN was trained with a large gap between <italic>&#x1D4A9;</italic>= 20,000 and <italic>&#x1D4A9;</italic>= 50,000 (and thus a large gap in <italic>&#x03B8;</italic>; see Methods), so we used coalescent simulations to generate an additional test set with <italic>&#x1D4A9;</italic> values drawn uniformly among 30,000, 35,000, 40,000, and 45,000. When tested on these data the CNN&#x2019;s predictions had an <italic>R</italic><sup>2</sup> = 0.82 and an RMSE = 0.017. This represents a slight decrease in accuracy from the values obtained when tested on the same <italic>&#x1D4A9;</italic> values used in training, but nonetheless shows that the CNN can interpolate between training parameters without a dramatic loss in accuracy. This could be a useful property, for example in cases where <italic>&#x1D4A9;</italic> (or <italic>&#x03B8;</italic>) is unknown, but where one can generate coalescent simulations across a range of plausible values.</p>
<p>Further complications arise when estimating <italic>&#x03C1;</italic> from unphased data. Under this scenario the arrangement of alleles on chromosomes is not known. One work-around is to first phase the alleles and then infer <italic>&#x03C1;</italic> as above, but not all data sources are easily phased, and phasing errors will, of course, reduce accuracy. Another approach is to analyze the unphased data directly. The relevant theory required to tackle this problem in a probabilistic manner has been worked out for unphased diploids (<xref ref-type="bibr" rid="c4">Auton and McVean 2007</xref>), but expanding this theory to higher ploidies would require a substantial effort. Take for example an autotetraploid with tetrasomic inheritance, where there are five possible genotypes (<italic>AAAA, AAAa, AAaa, Aaaa</italic>, and <italic>aaaa</italic>). To further complicate things, after sequencing an autotetraploid genome to a moderate depth of coverage and identifying polymorphisms, the true underlying genotype may be uncertain. For example, given a site with 10 reads supporting <italic>A</italic> and 10 supporting <italic>a</italic>, the true genotype could be <italic>AAAa, AAaa</italic>, or <italic>Aaaa</italic>. Perhaps the greatest strength of likelihood-free approaches like CNNs is that they can be used to solve problems for which no appropriate tool exists, and can be easily customized to accommodate methodological and biological realities by constructing appropriate training sets. To show the utility of CNNs in addressing novel population genomic inference problems, we designed a CNN capable of inferring <italic>&#x03C1;</italic> from a simulated set of sequence reads from an unphased autotetraploid population sample.</p>
<p>We used a simple simulation scheme to produce read counts for each allele at each site for each individual in a sample of 12 autotetraploids, each with approximately 25X expected genome-wide coverage (see Methods). Rather than allelic assignments, the input matrix for this CNN contains for every site in each individual the fraction of reads bearing the <italic>a</italic> allele. Deriving a likelihood function for <italic>&#x03C1;</italic> under this formulation may be possible, but such a solution has not yet been attempted. However, appropriately designed artificial neural networks are universal approximators, meaning that they have the potential to approximate any continuous function over a compact input space (<xref ref-type="bibr" rid="c37">Hornik 1991</xref>). Thus it is possible for a CNN to approximate the desired likelihood function, even in its absence. To this end we trained a CNN with a similar architecture to the one used above on phased haploid chromosomes (see Methods). We evaluated the performance of this CNN a set of simulations where <italic>&#x03C1;</italic> again ranged from 0.0002 to 0.2 (still scaling by 4<italic>&#x1D4A9;</italic>, rather than 8<italic>&#x1D4A9;</italic> which would be appropriate for tetraploids, so the result can be compared to those above). The CNN&#x2019;s predictions had an <italic>R</italic><sup>2</sup> = 0.83 and an RMSE = 0.012 (<xref rid="fig5" ref-type="fig">Figure 5D</xref>). As before, the estimate of <italic>&#x03C1;</italic> was made independent of <italic>&#x03B8;</italic>, which varied over an order of magnitude. The fact that this autotetraploid network performed only slightly worse than the haploid version demonstrates that in addition to outperforming current methods, CNN&#x2019;s can also solve a problem for which no model-based likelihood (or even composite likelihood) approach has been obtained.</p>
</sec>
<sec id="s3d">
<title>CNNs can accurately detect and categorize signatures of recent positive selection</title>
<p>When a new mutation is immediately favored by positive selection, it rapidly increases in frequency until it fixes (i.e. completely replaces all other alleles at that site). This phenomenon, referred to as a hard selective sweep, drastically reduces the amount of linked neutral variation (<xref ref-type="bibr" rid="c74">Maynard Smith and Haigh 1974</xref>), and produces characteristic skews in the allele frequency spectrum (<xref ref-type="bibr" rid="c19">Fay and Wu 2000</xref>) and linkage disequilibrium at linked sites (<xref ref-type="bibr" rid="c51">Kim and Nielsen 2004</xref>). Alternatively, in a process known as a &#x201C;soft sweep&#x201D; populations may adapt via selection on a polymorphism that has been segregating for some time, such that the adaptive allele exists on numerous haplotypes (<xref ref-type="bibr" rid="c33">Hermisson and Pennings 2005</xref>). In order to uncover the genomic regions underlying recent adaptation, a large number of methods have been devised to detect and characterize selective sweeps. These include summary statistics (<xref ref-type="bibr" rid="c48">Kelly 1997</xref>; <xref ref-type="bibr" rid="c19">Fay and Wu 2000</xref>; <xref ref-type="bibr" rid="c51">Kim and Nielsen 2004</xref>; <xref ref-type="bibr" rid="c112">Voight <italic>et al.</italic> 2006</xref>; <xref ref-type="bibr" rid="c25">Garud <italic>et al.</italic> 2015</xref>), composite likelihood-based approaches (<xref ref-type="bibr" rid="c52">Kim and Stephan 2002</xref>; <xref ref-type="bibr" rid="c51">Kim and Nielsen 2004</xref>; <xref ref-type="bibr" rid="c80">Nielsen <italic>et al.</italic> 2005</xref>; <xref ref-type="bibr" rid="c113">Vy and Kim 2015</xref>), and supervised machine learning approaches using a vector of statistics to obtain greater power than individual tests/statistics (<xref ref-type="bibr" rid="c67">Lin <italic>et al.</italic> 2011</xref>; <xref ref-type="bibr" rid="c84">Pybus <italic>et al.</italic> 2015</xref>; <xref ref-type="bibr" rid="c95">Schrider and Kern 2016</xref>; <xref ref-type="bibr" rid="c99">Sheehan and Song 2016</xref>; <xref ref-type="bibr" rid="c105">Sugden <italic>et al.</italic> 2018</xref>). Although these efforts have led to considerable progress, detecting and distinguishing between hard and soft sweeps remains a major challenge.</p>
<p>We built a CNN to detect selective sweeps and to discriminate between hard sweeps and soft sweeps. This CNN follows the S/HIC method of <xref ref-type="bibr" rid="c95">Schrider and Kern (2016)</xref> by casting the problem as a classification task where the genomic region being examined is assigned to one of five disjoint classes: a recent classic &#x201C;hard&#x201D; sweep, a recent &#x201C;soft&#x201D; sweep, a region linked to a nearby hard sweep, a region linked to a nearby soft sweep, or a neutrally evolving region. However, rather than adopting S/HIC&#x2019;s approach of using a large vector of statistics, the CNN takes an alignment image as input. We tested both methods against data simulated under a challenging demographic history estimated from human population data (Methods). As evidenced by the confusion matrices in <xref rid="fig6" ref-type="fig">Figure 6</xref>, the CNN has higher overall accuracy than S/HIC (60.5&#x0025; versus 55.9&#x0025;), a remarkable feat given that S/HIC was shown to have greater power than a number of competing methods (<xref ref-type="bibr" rid="c95">Schrider and Kern 2016</xref>). While S/HIC appears to be somewhat more sensitive to sweeps, the CNN is achieves a nearly 4-fold reduction in false positive rate: 2&#x0025; of neutral simulations are classified as sweeps by the CNN, versus 7.61&#x0025; for S/HIC. This quality may be particularly desirable when scanning genomes where sweeps are relatively rare and thus a high degree of specificity is required to maintain a low false discovery rate. Note that these classifiers were both trained under the same demographic history from which the test data were generated. We would not expect this CNN to match S/HIC&#x2019;s robustness to demographic misspecification given that S/HIC&#x2019;s feature vector was designed with this in mind, though we did not test this. Nonetheless, the fact that the CNN has greater accuracy than S/HIC under this difficult test scenario is highly encouraging.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Confusion matrices showing accuracies of two methods that seek to detect recent positive selection by discriminating among hard sweeps, soft sweeps, unselected regions closely linked to hard and soft sweeps, and neutrally evolving regions.</title>
<p>(A) Confusion matrix summarizing the performance of our CNN, which uses an alignment image as input. (B) Performance of S/HIC, which uses a vector of summary statistics each measured in windows surrounding the region to be classified.</p></caption>
<graphic xlink:href="336073_fig6.tif"/>
</fig>
</sec>
<sec id="s3e">
<title>CNNs can extract demographic information from alignments</title>
<p>A major focus of population genetics research is to use genomic data to elucidate species&#x2019; demographic histories&#x2014;the extent and timing of population size changes, and the history of population splits and migration events. For example, a host of population genetic approaches have been devised to infer the times and intensities of population contractions and expansions over the course of a species&#x2019; recent history (e.g. <xref ref-type="bibr" rid="c72">Marth <italic>et al.</italic> 2004</xref>; <xref ref-type="bibr" rid="c92">Schiffels and Durbin 2014</xref>; <xref ref-type="bibr" rid="c69">Liu and Fu 2015</xref>), and to elucidate the history of population splits and subsequent gene flow (<xref ref-type="bibr" rid="c79">Nielsen and Wakeley 2001</xref>; <xref ref-type="bibr" rid="c34">Hey 2009</xref>), and population merging events (e.g. <xref ref-type="bibr" rid="c68">Lipson <italic>et al.</italic> 2013</xref>; <xref ref-type="bibr" rid="c70">Loh <italic>et al.</italic> 2013</xref>). We sought to ask whether CNNs can effectively extract demographic information from alignment images, focusing on the task of inferring population size histories. In particular, we attempted to train a CNN to estimate the parameters of a three-epoch model of instantaneous population size changes. There are five such parameters: the ancestral population size (<italic>&#x1D4A9;</italic><sub><italic>2</italic></sub>), the time of the more ancient population size change (<italic>&#x1D4AF;</italic><sub><italic>1</italic></sub>), the population size after this change (<italic>&#x1D4A9;</italic><sub><italic>1</italic></sub>), the time of the more recent change (<italic>&#x1D4AF;</italic><sub><italic>0</italic></sub>), and the present-day population size (<italic>&#x1D4A9;</italic><sub><italic>0</italic></sub>); our response variable is the vector of these 5 real-valued parameters. Thus this analysis also allows us to assess the ability of CNNs to predict multiple population parameters simultaneously.</p>
<p>We simulated 50 haploid chromosomes under a variety of randomly selected population size histories, and trained a CNN to estimate the demographic model parameters. The simulated region was roughly equivalent in length to 1.5 Mbp of the human genome (Methods). Because we found this problem to be comparatively difficult, we experimented with a variety of hyperparameters governing the neural network structure and input/output format. In Table S2 we show the optimal RMSE (i.e. the minimum RMSE across training iterations) for each hyperparameter combination examined. This experiment revealed several general trends. First, 1D convolutional networks tended to fare slightly better than their 2D counterparts (median RMSE of 0.52 across all hyperparameter combinations with 1D convolutional filters, and median RMSE 0.54 for 2D convolutions; <italic>&#x03C1;</italic>=1.1&#x00D7;10<sup>&#x2212;4</sup>; Mann-Whitney <italic>U</italic> test); however several 2D networks performed nearly as well as the best 1D network, achieving an RMSE of &#x003C;0.5 while the best score obtained overall was 0.43. Second, smaller convolutional filters tended to perform slightly better than larger ones&#x2014;we observed a positive correlation of kernel size with RMSE across hyperparameter combinations (<italic>&#x03C1;</italic>=0.26; <italic>&#x03C1;</italic>=6.9&#x00D7;10<sup>&#x2212;4</sup>; Mann-Whitney <italic>U</italic> test). For example, the median validation RMSE was 0.51 for a kernel size of 2 versus 0.56 for a kernel size of 10. Third, log-scaling the demographic parameters to be estimated increased accuracy (RMSE decreased from 0.55 to 0.52; <italic>p</italic>=0.020; Mann-Whitney <italic>U</italic> test). For this problem sorting chromosomes by relatedness resulted in a small improvement (RMSE decreased from 0.54 to 0.53; <italic>p</italic>=0.034). Encoding ancestral and derived alleles as &#x2018;0&#x2019; and &#x2018;255&#x2019; (i.e. black and white in a grayscale image), respectively, versus &#x2018;-1&#x2019; and &#x2018;1&#x2019; had a significant influence on accuracy, with the former yielding better performance than the latter (RMSE of 0.51 vs. 0.60; <italic>p</italic>=1.5&#x00D7;10<sup>&#x2212;15</sup>). Finally, using dropout resulted in a slight decrease in accuracy (median RMSE increased from 0.52 to 0.55) though this was not statistically significant (<italic>p</italic>=0.092). We note that these trends may change if the amount of training data is increased or decreased, and may not necessarily hold for other tasks.</p>
<p>In <xref rid="fig7" ref-type="fig">Figure 7</xref>, we show the correlation between the true and inferred values for each of these 5 parameters for the best performing network. For <italic>&#x1D4A9;</italic><sub><italic>0</italic></sub> and <italic>&#x1D4AF;</italic><sub><italic>0</italic></sub>, these correlations are quite high, implying that our CNN can recover the true values reasonably well. However, for the remaining parameters, the correlation is lower (though still highly significant), and our CNN produces downwardly biased estimates when the values of these parameters are larger. Although our accuracy is far from perfect, we consider these results fairly encouraging because we are only examining a single moderately sized genomic region, while other modern demographic inference methods use data from across the genome. For example, &#x2202;a&#x2202;i (<xref ref-type="bibr" rid="c28">Gutenkunst <italic>et al.</italic> 2009</xref>) uses allele frequencies measured at a large number of polymorphisms (e.g. those found in all distal intergenic regions across the genome; <xref ref-type="bibr" rid="c26">Gazave <italic>et al.</italic> 2014</xref>). PSMC andMSMC (<xref ref-type="bibr" rid="c64">Li and Durbin 2011</xref>; <xref ref-type="bibr" rid="c92">Schiffels and Durbin 2014</xref>) take data from a single very large recombining region such as an entire chromosome. In essence, we are currently only able to utilize information about the coalescent histories of the region in question&#x2014;and this collection of histories may not match that of the entire population, which would be more accurately reflected in genome-wide data. In the Discussion, we address prospects for incorporating genome-scale data in demographic inference.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Accuracy of demographic inference CNN.</title>
<p>The scatterplots show the correlation between true and predicted demographic parameter values using our best-performing CNN for this task when applied to an independent test set.</p></caption>
<graphic xlink:href="336073_fig7.tif"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>DISCUSSION</title>
<sec id="s4a">
<title>Convolutional neural networks are well suited for population genetic problems</title>
<p>Population geneticists have devised a wide array of computational methods to make evolutionary inferences from genomic data. Typically the goal of these efforts is to aggregate information across genomic sites in order to make an accurate inference. These methods include maximum likelihood approaches (e.g. <xref ref-type="bibr" rid="c52">Kim and Stephan 2002</xref>; <xref ref-type="bibr" rid="c80">Nielsen <italic>et al.</italic> 2005</xref>; <xref ref-type="bibr" rid="c28">Gutenkunst <italic>et al.</italic> 2009</xref>; <xref ref-type="bibr" rid="c69">Liu and Fu 2015</xref>), probabilistic graphical models such as hidden Markov models (e.g. <xref ref-type="bibr" rid="c111">Turner <italic>et al.</italic> 2005</xref>; <xref ref-type="bibr" rid="c9">Boitard <italic>et al.</italic> 2009</xref>; <xref ref-type="bibr" rid="c61">Lawson <italic>et al.</italic> 2012</xref>), and those rely on the use one or more summary statistics designed to characterize patterns of variation within a genomic region (e.g. <xref ref-type="bibr" rid="c107">Tajima 1989</xref>; <xref ref-type="bibr" rid="c22">Fu and Li 1993</xref>; <xref ref-type="bibr" rid="c48">Kelly 1997</xref>; <xref ref-type="bibr" rid="c19">Fay and Wu 2000</xref>; <xref ref-type="bibr" rid="c51">Kim and Nielsen 2004</xref>; <xref ref-type="bibr" rid="c112">Voight <italic>et al.</italic> 2006</xref>; <xref ref-type="bibr" rid="c20">Ferrer-Admetlla <italic>et al.</italic> 2014</xref>). While these approaches differ substantially from one another, they all have one thing in common: they make use of population genomic theory to connect the features of a data set to the underlying evolutionary process. Here we have demonstrated the potential of an alternative approach: treating population genetic inference as an image recognition problem where the &#x201C;image&#x201D; is the population genetic alignment, which is directly fed as input to a convolutional neutral network. In contrast to mainstream approaches, this CNN approach makes use of the entirety of the data and does not rely on results from population genetic theory.</p>
<p>Here we have shown that CNNs perform remarkably well on a number of problems in population genetics. We developed CNNs with greater power to detect selective sweeps, identify introgressed loci, and infer local recombination rates when compared to current methods on simulated data sets. The CNNs for detecting sweeps and introgression demonstrate the ability to use an alignment image to distinguish among multiple evolutionary models, while the recombination rate estimator demonstrates that continuous parameters can also be inferred. Finally, although our demographic parameter estimates were fairly imprecise, they were only based on a short stretch of the genome, and nonetheless demonstrate that CNNs have the potential to infer multiple parameters from a sequence alignment. While we were in the process of preparing this manuscript, Chan et al. completed an important study demonstrating that a CNN can accurately detect recombination hotspots (<xref ref-type="bibr" rid="c13">Chan <italic>et al.</italic> 2018</xref>). Taken together these results suggest that CNNs have enormous potential as a general paradigm for population genetic inference.</p>
<p>The effectiveness and generality of CNNs in population genetic inference should not be surprising. CNNs offer a number of intrinsic advantages that make them particularly amenable to population genetic data. First, there have been a number of efforts to move in the direction of making inferences on the basis of the full complement of data present in an alignment rather than one or more summary statistics (<xref ref-type="bibr" rid="c65">Li and Stephens 2003</xref>; <xref ref-type="bibr" rid="c61">Lawson <italic>et al.</italic> 2012</xref>; <xref ref-type="bibr" rid="c102">Smith <italic>et al.</italic> 2018</xref>). CNNs represent a natural way of examining the entirety of an alignment in order to increase inferential power. The development of novel CNN architectures to better handle spatial associations in the data across multiple scales (<xref ref-type="bibr" rid="c115">Yu and Koltun 2015</xref>) has the potential to improve CNN-driven population genetic inference even further; for example, improved ability to detect both the localized reduction in diversity at a sweep (<xref ref-type="bibr" rid="c74">Maynard Smith and Haigh 1974</xref>) as well as the potentially confounding skews in patterns of diversity produced in its flanking regions (<xref ref-type="bibr" rid="c98">Schrider <italic>et al.</italic> 2015</xref>) would be beneficial in sweep detection.</p>
<p>Another desirable property of CNNs is that they effectively perform automated feature detection (<xref ref-type="bibr" rid="c62">LeCun <italic>et al.</italic> 2015</xref>). Because they discover discriminatory information directly from the image, there is no need to manually construct an optimal set of features. This brings up perhaps the strongest quality of CNNs in the context of evolutionary inference: because CNNs are not rooted in population genetic theory, they can make predictions for phenomena for which there exists no analytical expectation.</p>
<p>Indeed, CNNs can tackle problems for which no relevant summary statistics have been devised&#x2014;vectors of such statistics are required for other likelihood-free methods such as ABC (<xref ref-type="bibr" rid="c6">Beaumont 2010</xref>) or more traditional supervised machine learning techniques (<xref ref-type="bibr" rid="c97">Schrider and Kern 2018</xref>). On a related note, neural networks are particularly amenable to the incorporation of disparate data types with no prior knowledge of their relationships. For example, here we have included both genotype information and positional information for segregating sites as branches to our networks, allowing for both to be used together in prediction despite the fact that our network does not &#x201C;know&#x201D; how these two pieces of information relate to one another. All that is required is appropriate training data. Thus, we may not have to wait for theoretical advances in order to draw inferences from data, provided we are concerned with evolutionary models for which training data can be obtained from simulation&#x2014;including the wide range of scenarios that could potentially be investigated via increasingly flexible and efficient forward simulators (<xref ref-type="bibr" rid="c110">Thornton 2014</xref>; <xref ref-type="bibr" rid="c30">Haller and Messer 2017</xref>; <xref ref-type="bibr" rid="c47">Kelleher <italic>et al.</italic> 2018</xref>) &#x2014;or otherwise.</p>
<p>This point is driven home by the remarkable success of our CNN that estimating recombination rates in autotetraploids from read pileup information alone&#x2014;despite the input&#x2019;s lack of genotype calls, let alone phased haplotypes, these inferences are nearly as accurate as those that we obtained from haplotype alignments. This result also suggests that CNNs may be well suited for other inferences where genotype calls are unreliable (e.g. low coverage sequencing data; <xref ref-type="bibr" rid="c55">Korneliussen <italic>et al.</italic> 2014</xref>) or unobtainable (e.g. pooled population sequencing; <xref rid="c93" ref-type="bibr">Schl&#x00F6;tterer <italic>et al.</italic> 2014</xref>). Given CNNs&#x2019; remarkable flexibility, future studies should evaluate their potential to tackle not only those problems examined in this paper, but the myriad additional important challenges in evolutionary genetics to which they could be readily applied, including but not limited to uncovering adaptive introgression (<xref ref-type="bibr" rid="c85">Racimo <italic>et al.</italic> 2016</xref>), joint inference of selective and demographic histories (<xref ref-type="bibr" rid="c99">Sheehan and Song 2016</xref>), and even inferring structured outputs such as ancestral recombination graphs (<xref ref-type="bibr" rid="c86">Rasmussen <italic>et al.</italic> 2014</xref>).</p>
</sec>
<sec id="s4b">
<title>To what extent are CNNs robust to model misspecification?</title>
<p>Another particularly encouraging result of our recombination rate estimation analysis is that we were able to infer rates for data generated from a range of parameter values to which the CNN had not been exposed during training with very little decrease in accuracy. This ability to interpolate between training values is a particularly desirable property. First, it implies that CNNs can be used to create flexible inference tools using a modest training data set, and second that researchers can focus training between reasonable parameter bounds, without knowing the true (and often unknowable) underlying parameters; future efforts must explore the possibility of training networks to be robust to more extreme cases of model misspecification.</p>
<p>One illustrative example of the potential pitfalls of model misspecification is the problem of detecting selective sweeps without accounting for confounding demographic events. For example, population bottlenecks will skew genealogies in a manner similar to sweeps (<xref ref-type="bibr" rid="c100">Simonsen <italic>et al.</italic> 1995</xref>), and thus may result in a large fraction of false positives (<xref ref-type="bibr" rid="c42">Jensen <italic>et al.</italic> 2005</xref>; <xref ref-type="bibr" rid="c80">Nielsen <italic>et al.</italic> 2005</xref>). <xref ref-type="bibr" rid="c95">Schrider and Kern (2016)</xref> were able to mitigate this problem by designing a feature vector that is sensitive to the spatial skews in patterns of variation created by a sweep but insensitive to genome-wide skews produced by demographic events. Although this strategy is not possible with CNNs because they perform automated feature extraction, it may be that incorporating training examples generated under potentially confounding scenarios could alleviate this issue.</p>
<p>Therefore, future work must thoroughly 1) assess how CNNs trained under one range of evolutionary parameters fare when applied to different parameterizations, and 2) determine whether robustness to such misspecification might be achieved by training a CNN under a wide range of parameter values that are likely to encapsulate the correct values&#x2014;the recombination rate estimator&#x2019;s successful interpolation suggests that this may be a possibility.</p>
</sec>
<sec id="s4c">
<title>Outstanding practical challenges associated with the application of CNNs to sequence data</title>
<p>Although the CNN approach outlined above has great potential, there are several outstanding challenges with applying CNNs to a wider spectrum of problems. One important obstacle is the large amount of training data required by CNNs, which makes applications requiring alignments of large regions (e.g. entire chromosomes) more difficult. This challenge includes both the generation of large labeled training examples, and time-and memory-efficient training with these large examples given limited computational resources. Fortunately, continued improvements in simulation speed (<xref ref-type="bibr" rid="c46">Kelleher <italic>et al.</italic> 2016</xref>; <xref ref-type="bibr" rid="c47">Kelleher <italic>et al.</italic> 2018</xref>) and the efficiency of CNN training (<xref ref-type="bibr" rid="c15">Chilimbi <italic>et al.</italic> 2014</xref>; <xref ref-type="bibr" rid="c115">Yu and Koltun 2015</xref>; <xref ref-type="bibr" rid="c44">Jouppi <italic>et al.</italic> 2017</xref>; <xref ref-type="bibr" rid="c56">K&#x00F6;ster <italic>et al.</italic> 2017</xref>) is mitigating this problem. Such advances would be a boon for efforts to infer demographic parameters, which require simultaneously examining data sampled from across the genome or along an entire chromosome, unlike scans to infer locus-by-locus histories of selection/recombination/introgression. Advances in handling large or high-resolution images may also prove fruitful. For example, CNN-based strategies that simultaneously examine a number of smaller &#x201C;patches&#x201C;, each covering a portion of the image rather than the entirety of the image (e.g. <xref ref-type="bibr" rid="c71">Lu <italic>et al.</italic> 2015</xref>), may aid efforts to extract demographic information from genome-scale data.</p>
<p>Another challenge with the application of CNNs is that their performance can be sensitive to network architecture (<xref ref-type="bibr" rid="c106">Szegedy <italic>et al.</italic> 2015</xref>). There is no underlying theory for selecting optimal network architecture, though improved architectures are sure to continue to arise. Though we uncover some promising CNN architectures for population genetic inference, we suspect that substantial improvements can still be made.</p>
<p>We have also demonstrated that CNNs are sensitive to the input format of the population genetic alignment, and our work has yielded several insights along this front. First, we found that the ordering of haplotypes within the alignment can impact accuracy, and our results suggest that it is often beneficial to reorder haplotypes so that more similar chromosomes appear next to one another. This may be a suboptimal solution, and more creative approaches may be required to provide a more general strategy. To this end, research into permutation-invariant neural networks (<xref ref-type="bibr" rid="c116">Zaheer <italic>et al.</italic> 2017</xref>) may prove promising when dealing with sequence alignments. This is evidenced by Chan et al.&#x2019;s recent findings that a permutation-invariant architecture improves both training speed and final accuracy of their CNN for detecting recombination rate hotspots (<xref ref-type="bibr" rid="c13">Chan <italic>et al.</italic> 2018</xref>). We also observed that, somewhat surprisingly, 1D convolutions in the proper orientation perform as well as the more widely used 2D convolutions in many cases. Scaling of response variables for regression problems (both log-scaling and standardization) may also affect accuracy. We therefore recommend that users experiment with these different ways of representing their data, as well as different CNN architectures, in order to find the design that works best for the task at hand.</p>
<p>Another important consideration of CNNs is that once trained, they are specialized to a particular problem as defined by the training set. That is, a CNN trained to infer recombination rates under a European demographic history may have reduced accuracy when applied to an African sample. Training under a variety of demographic scenarios may make a CNN more robust to this problem, but a question for further study is whether this can be accomplished without a loss in power relative to a more specialized CNN. Even a change as subtle as adding another chromosome to a dataset will make one of our previously trained CNNs inapplicable, as the input matrix would no longer be the proper size and either a new CNN must be trained or the data subsampled. Importantly, <xref ref-type="bibr" rid="c13">Chan et al. (2018)</xref> describe an architecture that can allow for variation in the number individuals in the input matrix. In spite of these limitations, recent advances have greatly simplified training CNNs, and it will often be practical&#x2014;or even preferable&#x2014;for a researcher to create a CNN tailored to their specific data set.</p>
</sec>
<sec id="s4d">
<title>Are CNNs a black box?</title>
<p>Unlike most existing population genetic inference methods, a CNN is not rooted in evolutionary models or summary statistics. Instead a CNN is an algorithm that tries to maximize its predictive accuracy by optimizing its internal logic operations on training data. Its lack of reliance on theory gives CNNs enormous flexibility; however, one consequence of this is that CNNs are in some ways a &#x201C;black box&#x201C;. For example, a CNN cannot &#x201C;explain&#x201D; why it made a particular prediction given its input. Supervised machine learning algorithms in general have perhaps been unfairly maligned with this &#x201C;black box&#x201D; label. These methods can in principle reveal much about underlying processes by revealing which features are most informative under certain scenarios (i.e. feature ranking; see <xref ref-type="bibr" rid="c11">Breiman 2001</xref>). For example, the observation that certain features are highly informative for recent but not ancient introgression (<xref ref-type="bibr" rid="c94">Schrider <italic>et al.</italic> 2018</xref>) suggests some key differences between the genealogies produced under these two scenarios. It is even possible for supervised machine learning methods relying on feature vectors to reveal which features had the greatest influence on a particular prediction (e.g. <xref ref-type="bibr" rid="c5">Baehrens <italic>et al.</italic> 2010</xref>). A population geneticist could thus use supervised machine learning not only to find a soft selective sweep, but also to quickly reveal which summary statistics (and therefore genealogical properties) were most consistent with a soft sweep. Due to their complex inner workings, less progress has been made in breaking through the CNN &#x201C;black box&#x201D; as compared to more traditional supervised machine learning techniques. However, some successful explanatory tools are available for CNNs (<xref ref-type="bibr" rid="c87">Ribeiro <italic>et al.</italic> 2016</xref>), and there is ongoing research in this area. Moreover, because the CNN framework we adopt here works on images, it may be possible to translate future breakthroughs in CNN interpretation from other fields (e.g. image recognition) into population genetic inference. Thus a more optimistic view is that as CNNs and related methods become more interpretable, these theory-free image recognition approaches may help to reveal theoretical insights into evolutionary processes.</p>
<p>In the near-term, CNNs may remain useful only as a predictive tool, and we will continue to rely on theoretical advances to improve our understanding of population genetic processes. In spite of the shortcomings noted above, the highly encouraging results that we have laid out here suggest that CNNs are able to discover information about the underlying genealogies from alignment images and to use this information to more accurately elucidate the evolutionary phenomena that have shaped these genealogies. CNNs thus have enormous potential for population genomic inference. We believe that progress on a host of problems could accelerate appreciably were this technology to be embraced by the field. Indeed, when it comes to the business-end of population genetics&#x2014;drawing accurate evolutionary inferences from data&#x2014;we predict that increasingly, theory-free approaches such as the ones we have describe here will prove most effective at solving existing problems, and expand the universe of problems that researchers can investigate.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Achaz</surname>, <given-names>G.</given-names></string-name>, <year>2009</year> <article-title>Frequency spectrum neutrality tests: one for all and all for one</article-title>. <source>Genetics</source> <volume>183</volume>: <fpage>249</fpage>&#x2013;<lpage>258</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Arnold</surname>, <given-names>B.</given-names></string-name>, <string-name><given-names>K.</given-names> <surname>Bomblies</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Wakeley</surname></string-name>, <year>2012</year> <article-title>Extending coalescent theory to autotetraploids</article-title>. <source>Genetics</source> <volume>192</volume>: <fpage>195</fpage>&#x2013;<lpage>204</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Auton</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>L. D.</given-names> <surname>Brooks</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Durbin</surname></string-name>, <string-name><given-names>E. P.</given-names> <surname>Garrison</surname></string-name>, <string-name><given-names>H. M.</given-names> <surname>Kang</surname></string-name> <etal>et al.</etal>, <year>2015</year> <article-title>A global reference for human genetic variation</article-title>. <source>Nature</source> <volume>526</volume>: <fpage>68</fpage>&#x2013;<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Auton</surname>, <given-names>A.</given-names></string-name>, and <string-name><given-names>G.</given-names> <surname>McVean</surname></string-name>, <year>2007</year> <article-title>Recombination rate estimation in the presence of hotspots</article-title>. <source>Genome Res</source>. <volume>17</volume>: <fpage>1219</fpage>&#x2013;<lpage>1227</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Baehrens</surname>, <given-names>D.</given-names></string-name>, <string-name><given-names>T.</given-names> <surname>Schroeter</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Harmeling</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Kawanabe</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Hansen</surname></string-name> <etal>et al.</etal>, <year>2010</year> <article-title>How to explain individual classification decisions</article-title>. <source>Journal of Machine Learning Research</source> <volume>11</volume>: <fpage>1803</fpage>&#x2013;<lpage>1831</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Beaumont</surname>, <given-names>M. A.</given-names></string-name>, <year>2010</year> <article-title>Approximate Bayesian computation in evolution and ecology</article-title>. <source>Annual review of ecology, evolution, and systematics</source> <volume>41</volume>: <fpage>379</fpage>&#x2013;<lpage>406</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Begun</surname>, <given-names>D. J.</given-names></string-name>, and <string-name><given-names>C. F.</given-names> <surname>Aquadro</surname></string-name>, <year>1992</year> <article-title>Levels of naturally occurring DNA polymorphism correlate with recombination rates in <italic>D. melanogaster</italic></article-title>. <source>Nature</source> <volume>356</volume>: <fpage>519</fpage>&#x2013;<lpage>520</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Begun</surname>, <given-names>D. J.</given-names></string-name>, <string-name><given-names>A. K.</given-names> <surname>Holloway</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Stevens</surname></string-name>, <string-name><given-names>L. W.</given-names> <surname>Hillier</surname></string-name>, <string-name><given-names>Y.-P.</given-names> <surname>Poh</surname></string-name> <etal>et al.</etal>, <year>2007</year> <article-title>Population genomics: whole-genome analysis of polymorphism and divergence in Drosophila simulans</article-title>. <source>PLoS Biol</source>. <volume>5</volume>: <fpage>e310</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Boitard</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Schl&#x00F6;tterer</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Futschik</surname></string-name>, <year>2009</year> <article-title>Detecting selective sweeps: a new approach based on hidden Markov models</article-title>. <source>Genetics</source> <volume>181</volume>: <fpage>1567</fpage>&#x2013;<lpage>1578</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Brandvain</surname>, <given-names>Y.</given-names></string-name>, <string-name><given-names>A. M.</given-names> <surname>Kenney</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Flagel</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Coop</surname></string-name> and <string-name><given-names>A. L.</given-names> <surname>Sweigart</surname></string-name>, <year>2014</year> <article-title>Speciation and introgression between Mimulus nasutus and Mimulus guttatus</article-title>. <source>PLoS Genet</source>. <volume>10</volume>: <fpage>e1004410</fpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Breiman</surname>, <given-names>L.</given-names></string-name>, <year>2001</year> <article-title>Statistical modeling: The two cultures (with comments and a rejoinder by the author</article-title>). <source>Statistical science</source> <volume>16</volume>: <fpage>199</fpage>&#x2013;<lpage>231</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Chan</surname>, <given-names>A. H.</given-names></string-name>, <string-name><given-names>P. A.</given-names> <surname>Jenkins</surname></string-name> and <string-name><given-names>Y. S.</given-names> <surname>Song</surname></string-name>, <year>2012</year> <article-title>Genome-wide fine-scale recombination rate variation in Drosophila melanogaster</article-title>. <source>PLoS Genet</source>. <volume>8</volume>: <fpage>e1003090</fpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="other"><string-name><surname>Chan</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>V.</given-names> <surname>Perrone</surname></string-name>, <string-name><given-names>J. P.</given-names> <surname>Spence</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Jenkins</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Mathieson</surname></string-name> <etal>et al.</etal>, <year>2018</year> <article-title>A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Charlesworth</surname>, <given-names>B.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Morgan</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Charlesworth</surname></string-name>, <year>1993</year> <article-title>The effect of deleterious mutations on neutral molecular variation</article-title>. <source>Genetics</source> <volume>134</volume>: <fpage>1289</fpage>&#x2013;<lpage>1303</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="other"><string-name><surname>Chilimbi</surname>, <given-names>T. M.</given-names></string-name>, <string-name><given-names>Y.</given-names> <surname>Suzue</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Apacible</surname></string-name> and <string-name><given-names>K.</given-names> <surname>Kalyanaraman</surname></string-name>, <year>2014</year> <article-title>Project Adam: Building an Efficient and Scalable Deep Learning Training System</article-title>, pp. <fpage>571</fpage>&#x2013;<lpage>582</lpage> in <source>OSDI</source>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Corbett-Detig</surname>, <given-names>R.</given-names></string-name>, and <string-name><given-names>R.</given-names> <surname>Nielsen</surname></string-name>, <year>2017</year> <article-title>A hidden Markov model approach for simultaneously estimating local ancestry and admixture time using next generation sequence data in samples of arbitrary ploidy</article-title>. <source>PLoS Genet</source>. <volume>13</volume>: <fpage>e1006529</fpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Elyashiv</surname>, <given-names>E.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Sattath</surname></string-name>, <string-name><given-names>T. T.</given-names> <surname>Hu</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Strutsovsky</surname></string-name>, <string-name><given-names>G.</given-names> <surname>McVicker</surname></string-name> <etal>et al.</etal>, <year>2016</year> <article-title>A genomic map of the effects of linked selection in Drosophila</article-title>. <source>PLoS Genet</source>. <volume>12</volume>: <fpage>e1006130</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Ewing</surname>, <given-names>G.</given-names></string-name>, and <string-name><given-names>J.</given-names> <surname>Hermisson</surname></string-name>, <year>2010</year> <article-title>MSMS: a coalescent simulation program including recombination, demographic structure and selection at a single locus</article-title>. <source>Bioinformatics</source> <volume>26</volume>: <fpage>2064</fpage>&#x2013;<lpage>2065</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Fay</surname>, <given-names>J. C.</given-names></string-name>, and <string-name><given-names>C.-I.</given-names> <surname>Wu</surname></string-name>, <year>2000</year> <article-title>Hitchhiking under positive Darwinian selection</article-title>. <source>Genetics</source> <volume>155</volume>: <fpage>1405</fpage>&#x2013;<lpage>1413</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Ferrer-Admetlla</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Liang</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Korneliussen</surname></string-name> and <string-name><given-names>R.</given-names> <surname>Nielsen</surname></string-name>, <year>2014</year> <article-title>On detecting incomplete soft or hard selective sweeps using haplotype structure</article-title>. <source>Mol. Biol. Evol</source>. <volume>31</volume>: <fpage>1275</fpage>&#x2013;<lpage>1291</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Fontaine</surname>, <given-names>M. C.</given-names></string-name>, <string-name><given-names>J. B.</given-names> <surname>Pease</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Steele</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Waterhouse</surname></string-name>, <string-name><given-names>D. E.</given-names> <surname>Neafsey</surname></string-name> <etal>et al.</etal>, <year>2015</year> <article-title>Extensive introgression in a malaria vector species complex revealed by phylogenomics</article-title>. <source>Science</source> <volume>347</volume>: <fpage>1258524</fpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Fu</surname>, <given-names>Y.-X.</given-names></string-name>, and <string-name><given-names>W.-H.</given-names> <surname>Li</surname></string-name>, <year>1993</year> <article-title>Statistical tests of neutrality of mutations</article-title>. <source>Genetics</source> <volume>133</volume>: <fpage>693</fpage>&#x2013;<lpage>709</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Gao</surname>, <given-names>F.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Ming</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Hu</surname></string-name> and <string-name><given-names>H.</given-names> <surname>Li</surname></string-name>, <year>2016</year> <article-title>New software for the fast estimation of population recombination rates (FastEPRR) in the genomic era</article-title>. <source>G3: Genes, Genomes, Genetics</source> <volume>6</volume>: <fpage>1563</fpage>&#x2013;<lpage>1571</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Garrigan</surname>, <given-names>D.</given-names></string-name>, <string-name><given-names>S. B.</given-names> <surname>Kingan</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Geneva</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Andolfatto</surname></string-name>, <string-name><given-names>A. G.</given-names> <surname>Clark</surname></string-name> <etal>et al.</etal>, <year>2012</year> <article-title>Genome sequencing reveals complex speciation in the Drosophila simulans clade</article-title>. <source>Genome Res</source>. <volume>22</volume>: <fpage>1499</fpage>&#x2013;<lpage>1511</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Garud</surname>, <given-names>N. R.</given-names></string-name>, <string-name><given-names>P. W.</given-names> <surname>Messer</surname></string-name>, <string-name><given-names>E. O.</given-names> <surname>Buzbas</surname></string-name> and <string-name><given-names>D. A.</given-names> <surname>Petrov</surname></string-name>, <year>2015</year> <article-title>Recent selective sweeps in North American Drosophila melanogaster show signatures of soft sweeps</article-title>. <source>PLoS Genet</source>. <volume>11</volume>: <fpage>e1005004</fpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Gazave</surname>, <given-names>E.</given-names></string-name>, <string-name><given-names>L.</given-names> <surname>Ma</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Chang</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Coventry</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Gao</surname></string-name> <etal>et al.</etal>, <year>2014</year> <article-title>Neutral genomic regions refine models of recent rapid human population growth</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>111</volume>: <fpage>757</fpage>&#x2013;<lpage>762</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Geneva</surname>, <given-names>A. J.</given-names></string-name>, <string-name><given-names>C. A.</given-names> <surname>Muirhead</surname></string-name>, <string-name><given-names>S. B.</given-names> <surname>Kingan</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Garrigan</surname></string-name>, <year>2015</year> <article-title>A new method to scan genomes for introgression in a secondary contact model</article-title>. <source>PLoS ONE</source> <volume>10</volume>: <fpage>e0118621</fpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Gutenkunst</surname>, <given-names>R. N.</given-names></string-name>, <string-name><given-names>R. D.</given-names> <surname>Hernandez</surname></string-name>, <string-name><given-names>S. H.</given-names> <surname>Williamson</surname></string-name> and <string-name><given-names>C. D.</given-names> <surname>Bustamante</surname></string-name>, <year>2009</year> <article-title>Inferring the joint demographic history of multiple populations from multidimensional SNP frequency data</article-title>. <source>PLoS Genet</source>. <volume>5</volume>: <fpage>e1000695</fpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Hahn</surname>, <given-names>M. W.</given-names></string-name>, <year>2008</year> <article-title>Toward a selection theory of molecular evolution</article-title>. <source>Evolution</source> <volume>62</volume>: <fpage>255</fpage>&#x2013;<lpage>265</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Haller</surname>, <given-names>B.</given-names></string-name>, and <string-name><given-names>P.</given-names> <surname>Messer</surname></string-name>, <year>2017</year> <article-title>SLiM 2: Flexible, Interactive Forward Genetic Simulations</article-title>. <source>Mol. Biol. Evol</source>. <volume>34</volume>: <fpage>230</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Hedrick</surname>, <given-names>P. W.</given-names></string-name>, <year>2013</year> <article-title>Adaptive introgression in animals: examples and comparison to new mutation and standing variation as sources of adaptive variation</article-title>. <source>Mol. Ecol</source>. <volume>22</volume>: <fpage>4606</fpage>&#x2013;<lpage>4618</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Hellenthal</surname>, <given-names>G.</given-names></string-name>, <string-name><given-names>G. B.</given-names> <surname>Busby</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Band</surname></string-name>, <string-name><given-names>J. F.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Capelli</surname></string-name> <etal>et al.</etal>, <year>2014</year> <article-title>A genetic atlas of human admixture history</article-title>. <source>Science</source> <volume>343</volume>: <fpage>747</fpage>&#x2013;<lpage>751</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Hermisson</surname>, <given-names>J.</given-names></string-name>, and <string-name><given-names>P. S.</given-names> <surname>Pennings</surname></string-name>, <year>2005</year> <article-title>Soft sweeps molecular population genetics of adaptation from standing genetic variation</article-title>. <source>Genetics</source> <volume>169</volume>: <fpage>2335</fpage>&#x2013;<lpage>2352</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Hey</surname>, <given-names>J.</given-names></string-name>, <year>2009</year> <article-title>Isolation with migration models for more than two populations</article-title>. <source>Mol. Biol. Evol</source>. <volume>27</volume>: <fpage>905</fpage>&#x2013;<lpage>920</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Hey</surname>, <given-names>J.</given-names></string-name>, and <string-name><given-names>J.</given-names> <surname>Wakeley</surname></string-name>, <year>1997</year> <article-title>A coalescent estimator of the population recombination rate</article-title>. <source>Genetics</source> <volume>145</volume>: <fpage>833</fpage>&#x2013;<lpage>846</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Hill</surname>, <given-names>W. G.</given-names></string-name>, and <string-name><given-names>A.</given-names> <surname>Robertson</surname></string-name>, <year>1966</year> <article-title>The effect of linkage on limits to artificial selection</article-title>. <source>Genetics Research</source> <volume>8</volume>: <fpage>269</fpage>&#x2013;<lpage>294</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Hornik</surname>, <given-names>K.</given-names></string-name>, <year>1991</year> <article-title>Approximation capabilities of multilayer feedforward networks</article-title>. <source>Neural networks</source> <volume>4</volume>: <fpage>251</fpage>&#x2013;<lpage>257</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Hudson</surname>, <given-names>R. R.</given-names></string-name>, <year>1987</year> <article-title>Estimating the recombination parameter of a finite population model without selection</article-title>. <source>Genetics Research</source> <volume>50</volume>: <fpage>245</fpage>&#x2013;<lpage>250</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Hudson</surname>, <given-names>R. R.</given-names></string-name>, <year>2001</year> <article-title>Two-locus sampling distributions and their application</article-title>. <source>Genetics</source> <volume>159</volume>: <fpage>1805</fpage>&#x2013;<lpage>1817</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Hudson</surname>, <given-names>R. R.</given-names></string-name>, <year>2002</year> <article-title>Generating samples under a Wright&#x2013;Fisher neutral model of genetic variation</article-title>. <source>Bioinformatics</source> <volume>18</volume>: <fpage>337</fpage>&#x2013;<lpage>338</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Hudson</surname>, <given-names>R. R.</given-names></string-name>, and <string-name><given-names>N. L.</given-names> <surname>Kaplan</surname></string-name>, <year>1985</year> <article-title>Statistical properties of the number of recombination events in the history of a sample of DNA sequences</article-title>. <source>Genetics</source> <volume>111</volume>: <fpage>147</fpage>&#x2013;<lpage>164</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Jensen</surname>, <given-names>J. D.</given-names></string-name>, <string-name><given-names>Y.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>V. B.</given-names> <surname>DuMont</surname></string-name>, <string-name><given-names>C. F.</given-names> <surname>Aquadro</surname></string-name> and <string-name><given-names>C. D.</given-names> <surname>Bustamante</surname></string-name>, <year>2005</year> <article-title>Distinguishing between selective sweeps and demography using DNA polymorphism data</article-title>. <source>Genetics</source> <volume>170</volume>: <fpage>1401</fpage>&#x2013;<lpage>1410</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Joly</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>P. A.</given-names> <surname>McLenachan</surname></string-name> and <string-name><given-names>P. J.</given-names> <surname>Lockhart</surname></string-name>, <year>2009</year> <article-title>A statistical approach for distinguishing hybridization and incomplete lineage sorting</article-title>. <source>The American Naturalist</source> <volume>174</volume>: <fpage>E54</fpage>&#x2013;<lpage>E70</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="book"><string-name><surname>Jouppi</surname>, <given-names>N. P.</given-names></string-name>, <string-name><given-names>C.</given-names> <surname>Young</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Patil</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Patterson</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Agrawal</surname></string-name> <etal>et al.</etal>, <year>2017</year> <chapter-title>In-datacenter performance analysis of a tensor processing unit</chapter-title>, pp. <fpage>1</fpage>&#x2013;<lpage>12</lpage> in <source>Proceedings of the 44th Annual International Symposium on Computer Architecture</source>. <publisher-name>ACM</publisher-name>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Kaplan</surname>, <given-names>N. L.</given-names></string-name>, <string-name><given-names>R.</given-names> <surname>Hudson</surname></string-name> and <string-name><given-names>C.</given-names> <surname>Langley</surname></string-name>, <year>1989</year> <article-title>The &#x201C;hitchhiking effect&#x201D; revisited</article-title>. <source>Genetics</source> <volume>123</volume>: <fpage>887</fpage>&#x2013;<lpage>899</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Kelleher</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>A. M.</given-names> <surname>Etheridge</surname></string-name> and <string-name><given-names>G.</given-names> <surname>McVean</surname></string-name>, <year>2016</year> <article-title>Efficient coalescent simulation and genealogical analysis for large sample sizes</article-title>. <source>PLoS Comput. Biol</source>. <volume>12</volume>: <fpage>e1004842</fpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Kelleher</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>K.</given-names> <surname>Thornton</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Ashander</surname></string-name> and <string-name><given-names>P.</given-names> <surname>Ralph</surname></string-name>, <year>2018</year> <article-title>Efficient pedigree recording for fast population genetics simulation</article-title>. <source>bioRxiv</source>: <volume>248500</volume>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Kelly</surname>, <given-names>J. K.</given-names></string-name>, <year>1997</year> <article-title>A test of neutrality based on interlocus associations</article-title>. <source>Genetics</source> <volume>146</volume>: <fpage>1197</fpage>&#x2013;<lpage>1206</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Kern</surname>, <given-names>A. D.</given-names></string-name>, and <string-name><given-names>D. R.</given-names> <surname>Schrider</surname></string-name>, <year>2016</year> <article-title>discoal: flexible coalescent simulations with selection</article-title>. <source>Bioinformatics</source> <volume>32</volume>: <fpage>btw556</fpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Kern</surname>, <given-names>A. D.</given-names></string-name>, and <string-name><given-names>D. R.</given-names> <surname>Schrider</surname></string-name>, <year>2018</year> <article-title>diploS/HIC: an updated approach to classifying selective sweeps</article-title>. <source>bioRxiv</source>: <volume>267229</volume>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>Y.</given-names></string-name>, and <string-name><given-names>R.</given-names> <surname>Nielsen</surname></string-name>, <year>2004</year> <article-title>Linkage disequilibrium as a signature of selective sweeps</article-title>. <source>Genetics</source> <volume>167</volume>: <fpage>1513</fpage>&#x2013;<lpage>1524</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>Y.</given-names></string-name>, and <string-name><given-names>W.</given-names> <surname>Stephan</surname></string-name>, <year>2002</year> <article-title>Detecting a local signature of genetic hitchhiking along a recombining chromosome</article-title>. <source>Genetics</source> <volume>160</volume>: <fpage>765</fpage>&#x2013;<lpage>777</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="other"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name>, and <string-name><given-names>J.</given-names> <surname>Ba</surname></string-name>, <year>2014</year> <article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv preprint arXiv:1412.6980</source>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Kong</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>G.</given-names> <surname>Thorleifsson</surname></string-name>, <string-name><given-names>D. F.</given-names> <surname>Gudbjartsson</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Masson</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Sigurdsson</surname></string-name> <etal>et al.</etal>, <year>2010</year> <article-title>Fine-scale recombination rate differences between sexes, populations and individuals</article-title>. <source>Nature</source> <volume>467</volume>: <fpage>1099</fpage>&#x2013;<lpage>1103</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Korneliussen</surname>, <given-names>T. S.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Albrechtsen</surname></string-name> and <string-name><given-names>R.</given-names> <surname>Nielsen</surname></string-name>, <year>2014</year> <article-title>ANGSD: analysis of next generation sequencing data</article-title>. <source>BMC Bioinformatics</source> <volume>15</volume>: <fpage>356</fpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="other"><string-name><surname>K&#x00F6;ster</surname>, <given-names>U.</given-names></string-name>, <string-name><given-names>T.</given-names> <surname>Webb</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Nassar</surname></string-name>, <string-name><given-names>A. K.</given-names> <surname>Bansal</surname></string-name> <etal>et al.</etal>, <year>2017</year> <article-title>Flexpoint: An adaptive numerical format for efficient training of deep neural networks</article-title>, pp. <fpage>1742</fpage>&#x2013;<lpage>1752</lpage> in <source>Advances in Neural Information Processing Systems</source>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="other"><string-name><surname>Krizhevsky</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>I.</given-names> <surname>Sutskever</surname></string-name> and <string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name>, <year>2012</year> <article-title>Imagenet classification with deep convolutional neural networks</article-title>, pp. <fpage>1097</fpage>&#x2013;<lpage>1105</lpage> in <source>Advances in neural information processing systems</source>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Kulathinal</surname>, <given-names>R. J.</given-names></string-name>, <string-name><given-names>L. S.</given-names> <surname>Stevison</surname></string-name> and <string-name><given-names>M. A.</given-names> <surname>Noor</surname></string-name>, <year>2009</year> <article-title>The genomics of speciation in Drosophila: diversity, divergence, and introgression estimated using low-coverage genome sequencing</article-title>. <source>PLoS Genet</source>. <volume>5</volume>: <fpage>e1000550</fpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Langley</surname>, <given-names>C. H.</given-names></string-name>, <string-name><given-names>K.</given-names> <surname>Stevens</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Cardeno</surname></string-name>, <string-name><given-names>Y. C. G.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>D. R.</given-names> <surname>Schrider</surname></string-name> <etal>et al.</etal>, <year>2012</year> <article-title>Genomic variation in natural populations of <italic>Drosophila melanogaster</italic></article-title>. <source>Genetics</source> <volume>192</volume>: <fpage>533</fpage>&#x2013;<lpage>598</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Lawrence</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>C. L.</given-names> <surname>Giles</surname></string-name>, <string-name><given-names>A. C.</given-names> <surname>Tsoi</surname></string-name> and <string-name><given-names>A. D.</given-names> <surname>Back</surname></string-name>, <year>1997</year> <article-title>Face recognition: A convolutional neural-network approach</article-title>. <source>IEEE transactions on neural networks</source> <volume>8</volume>: <fpage>98</fpage>&#x2013;<lpage>113</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Lawson</surname>, <given-names>D. J.</given-names></string-name>, <string-name><given-names>G.</given-names> <surname>Hellenthal</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Myers</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Falush</surname></string-name>, <year>2012</year> <article-title>Inference of population structure using dense haplotype data</article-title>. <source>PLoS Genet</source>. <volume>8</volume>: <fpage>e1002453</fpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name>, <string-name><given-names>Y.</given-names> <surname>Bengio</surname></string-name> and <string-name><given-names>G.</given-names> <surname>Hinton</surname></string-name>, <year>2015</year> <article-title>Deep learning</article-title>. <source>Nature</source> <volume>521</volume>: <fpage>436</fpage>&#x2013;<lpage>444</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name>, <string-name><given-names>L.</given-names> <surname>Bottou</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Bengio</surname></string-name> and <string-name><given-names>P.</given-names> <surname>Haffner</surname></string-name>, <year>1998</year> <article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proceedings of the IEEE</source> <volume>86</volume>: <fpage>2278</fpage>&#x2013;<lpage>2324</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>H.</given-names></string-name>, and <string-name><given-names>R.</given-names> <surname>Durbin</surname></string-name>, <year>2011</year> <article-title>Inference of human population history from individual whole-genome sequences</article-title>. <source>Nature</source> <volume>475</volume>: <fpage>493</fpage>&#x2013;<lpage>496</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>N.</given-names></string-name>, and <string-name><given-names>M.</given-names> <surname>Stephens</surname></string-name>, <year>2003</year> <article-title>Modeling linkage disequilibrium and identifying recombination hotspots using single-nucleotide polymorphism data</article-title>. <source>Genetics</source> <volume>165</volume>: <fpage>2213</fpage>&#x2013;<lpage>2233</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Lin</surname>, <given-names>K.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Futschik</surname></string-name> and <string-name><given-names>H.</given-names> <surname>Li</surname></string-name>, <year>2013</year> <article-title>A fast estimate for the population recombination rate based on regression</article-title>. <source>Genetics</source> <volume>194</volume>: <fpage>473</fpage>&#x2013;<lpage>484</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Lin</surname>, <given-names>K.</given-names></string-name>, <string-name><given-names>H.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Schl&#x00F6;tterer</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Futschik</surname></string-name>, <year>2011</year> <article-title>Distinguishing positive selection from neutral evolution: boosting the performance of summary statistics</article-title>. <source>Genetics</source> <volume>187</volume>: <fpage>229</fpage>&#x2013;<lpage>244</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Lipson</surname>, <given-names>M.</given-names></string-name>, <string-name><given-names>P.-R.</given-names> <surname>Loh</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Levin</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Reich</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Patterson</surname></string-name> <etal>et al.</etal>, <year>2013</year> <article-title>Efficient moment-based inference of admixture parameters and sources of gene flow</article-title>. <source>Mol. Biol. Evol</source>. <volume>30</volume>: <fpage>1788</fpage>&#x2013; <lpage>1802</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name>, and <string-name><given-names>Y.-X.</given-names> <surname>Fu</surname></string-name>, <year>2015</year> <article-title>Exploring population size changes using SNP frequency spectra</article-title>. <source>Nat. Genet</source>. <volume>47</volume>: <fpage>555</fpage>&#x2013;<lpage>559</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Loh</surname>, <given-names>P.-R.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Lipson</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Patterson</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Moorjani</surname></string-name>, <string-name><given-names>J. K.</given-names> <surname>Pickrell</surname></string-name> <etal>et al.</etal>, <year>2013</year> <article-title>Inferring admixture histories of human populations using linkage disequilibrium</article-title>. <source>Genetics</source> <volume>193</volume>: <fpage>1233</fpage>&#x2013;<lpage>1254</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="other"><string-name><surname>Lu</surname>, <given-names>X.</given-names></string-name>, <string-name><given-names>Z.</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Shen</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Mech</surname></string-name> and <string-name><given-names>J. Z.</given-names> <surname>Wang</surname></string-name>, <year>2015</year> <article-title>Deep multi-patch aggregation network for image style, aesthetics, and quality estimation, pp. 990-998</article-title> in <source>Proceedings of the IEEE International Conference on Computer Vision</source>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Marth</surname>, <given-names>G. T.</given-names></string-name>, <string-name><given-names>E.</given-names> <surname>Czabarka</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Murvai</surname></string-name> and <string-name><given-names>S. T.</given-names> <surname>Sherry</surname></string-name>, <year>2004</year> <article-title>The allele frequency spectrum in genome-wide human variation data reveals signals of differential demographic history in three large world populations</article-title>. <source>Genetics</source> <volume>166</volume>: <fpage>351</fpage>&#x2013;<lpage>372</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Martin</surname>, <given-names>S. H.</given-names></string-name>, <string-name><given-names>K. K.</given-names> <surname>Dasmahapatra</surname></string-name>, <string-name><given-names>N. J.</given-names> <surname>Nadeau</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Salazar</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Walters</surname></string-name> <etal>et al.</etal>, <year>2013</year> <article-title>Genome-wide evidence for speciation with gene flow in Heliconius butterflies</article-title>. <source>Genome Res</source>. <volume>23</volume>: <fpage>1817</fpage>&#x2013;<lpage>1828</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Maynard Smith</surname>, <given-names>J.</given-names></string-name>, and <string-name><given-names>J.</given-names> <surname>Haigh</surname></string-name>, <year>1974</year> <article-title>The hitch-hiking effect of a favourable gene</article-title>. <source>Genet. Res</source>. <volume>23</volume>: <fpage>23</fpage>&#x2013;<lpage>35</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>McVean</surname>, <given-names>G. A.</given-names></string-name>, <string-name><given-names>S. R.</given-names> <surname>Myers</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Hunt</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Deloukas</surname></string-name>, <string-name><given-names>D. R.</given-names> <surname>Bentley</surname></string-name> <etal>et al.</etal>, <year>2004</year> <article-title>The fine-scale structure of recombination rate variation in the human genome</article-title>. <source>Science</source> <volume>304</volume>: <fpage>581</fpage>&#x2013;<lpage>584</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Mitchell</surname>, <given-names>T. M.</given-names></string-name>, <year>1997</year> <article-title>Artificial neural networks</article-title>. <source>Machine Learning</source> <volume>45</volume>: <fpage>81</fpage>&#x2013;<lpage>127</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="other"><string-name><surname>Nair</surname>, <given-names>V.</given-names></string-name>, and <string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name>, <year>2010</year> <article-title>Rectified linear units improve restricted boltzmann machines</article-title>, pp. <fpage>807</fpage>&#x2013;<lpage>814</lpage> in <source>Proceedings of the 27th international conference on machine learning (ICML-10)</source>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Nei</surname>, <given-names>M.</given-names></string-name>, and <string-name><given-names>W.-H.</given-names> <surname>Li</surname></string-name>, <year>1979</year> <article-title>Mathematical model for studying genetic variation in terms of restriction endonucleases</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>76</volume>: <fpage>5269</fpage>&#x2013;<lpage>5273</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><string-name><surname>Nielsen</surname>, <given-names>R.</given-names></string-name>, and <string-name><given-names>J.</given-names> <surname>Wakeley</surname></string-name>, <year>2001</year> <article-title>Distinguishing migration from isolation: a Markov chain Monte Carlo approach</article-title>. <source>Genetics</source> <volume>158</volume>: <fpage>885</fpage>&#x2013;<lpage>896</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><string-name><surname>Nielsen</surname>, <given-names>R.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Williamson</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Hubisz</surname></string-name>, <string-name><given-names>A. G.</given-names> <surname>Clark</surname></string-name> <etal>et al.</etal>, <year>2005</year> <article-title>Genomic scans for selective sweeps using SNP data</article-title>. <source>Genome Res</source>. <volume>15</volume>: <fpage>1566</fpage>&#x2013;<lpage>1575</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><string-name><surname>Pavlidis</surname>, <given-names>P.</given-names></string-name>, <string-name><given-names>J. D.</given-names> <surname>Jensen</surname></string-name> and <string-name><given-names>W.</given-names> <surname>Stephan</surname></string-name>, <year>2010</year> <article-title>Searching for footprints of positive selection in whole-genome SNP data from nonequilibrium populations</article-title>. <source>Genetics</source> <volume>185</volume>: <fpage>907</fpage>&#x2013;<lpage>922</lpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><string-name><surname>Price</surname>, <given-names>A. L.</given-names></string-name>, <string-name><given-names>A.</given-names> <surname>Tandon</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Patterson</surname></string-name>, <string-name><given-names>K. C.</given-names> <surname>Barnes</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Rafaels</surname></string-name> <etal>et al.</etal>, <year>2009</year> <article-title>Sensitive detection of chromosomal segments of distinct ancestry in admixed populations</article-title>. <source>PLoS Genet</source>. <volume>5</volume>: <fpage>e1000519</fpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><string-name><surname>Pudlo</surname>, <given-names>P.</given-names></string-name>, <string-name><given-names>J.-M.</given-names> <surname>Marin</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Estoup</surname></string-name>, <string-name><given-names>J.-M.</given-names> <surname>Cornuet</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Gautier</surname></string-name> <etal>et al.</etal>, <year>2016</year> <article-title>Reliable ABC model choice via random forests</article-title>. <source>Bioinformatics</source> <volume>32</volume>: <fpage>859</fpage>&#x2013;<lpage>866</lpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><string-name><surname>Pybus</surname>, <given-names>M.</given-names></string-name>, <string-name><given-names>P.</given-names> <surname>Luisi</surname></string-name>, <string-name><given-names>G. M.</given-names> <surname>Dall&#x2019;Olio</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Uzkudun</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Laayouni</surname></string-name> <etal>et al.</etal>, <year>2015</year> <article-title>Hierarchical boosting: a machine-learning framework to detect and classify hard selective sweeps in human populations</article-title>. <source>Bioinformatics</source> <volume>31</volume>: <fpage>3946</fpage>&#x2013;<lpage>3952</lpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><string-name><surname>Racimo</surname>, <given-names>F.</given-names></string-name>, <string-name><given-names>D.</given-names> <surname>Marnetto</surname></string-name> and <string-name><given-names>E.</given-names> <surname>Huerta-Sanchez</surname></string-name>, <year>2016</year> <article-title>Signatures of archaic adaptive introgression in present-day human populations</article-title>. <source>Mol. Biol. Evol</source>. <volume>34</volume>: <fpage>296</fpage>&#x2013;<lpage>317</lpage>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="other"><string-name><surname>Rasmussen</surname>, <given-names>M. D.</given-names></string-name>, <string-name><given-names>M. J.</given-names> <surname>Hubisz</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Gronau</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Siepel</surname></string-name>, <year>2014</year> <source>Genome-wide inference of ancestral recombination graphs</source>.</mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="book"><string-name><surname>Ribeiro</surname>, <given-names>M. T.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Singh</surname></string-name> and <string-name><given-names>C.</given-names> <surname>Guestrin</surname></string-name>, <year>2016</year> <chapter-title>Why should i trust you?: Explaining the predictions of any classifier</chapter-title>, pp. <fpage>1135</fpage>&#x2013;<lpage>1144</lpage> in <source>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>. <publisher-name>ACM</publisher-name>.</mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><string-name><surname>Ronen</surname>, <given-names>R.</given-names></string-name>, <string-name><given-names>N.</given-names> <surname>Udpa</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Halperin</surname></string-name> and <string-name><given-names>V.</given-names> <surname>Bafna</surname></string-name>, <year>2013</year> <article-title>Learning natural selection from the site frequency spectrum</article-title>. <source>Genetics</source> <volume>195</volume>: <fpage>181</fpage>&#x2013;<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><string-name><surname>Rosenzweig</surname>, <given-names>B. K.</given-names></string-name>, <string-name><given-names>J. B.</given-names> <surname>Pease</surname></string-name>, <string-name><given-names>N. J.</given-names> <surname>Besansky</surname></string-name> and <string-name><given-names>M. W.</given-names> <surname>Hahn</surname></string-name>, <year>2016</year> <article-title>Powerful methods for detecting introgressed regions from population genomic data</article-title>. <source>Mol. Ecol</source>. <volume>25</volume>: <fpage>2387</fpage>&#x2013;<lpage>2397</lpage>.</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><string-name><surname>Rumelhart</surname>, <given-names>D. E.</given-names></string-name>, <string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name> and <string-name><given-names>R. J.</given-names> <surname>Williams</surname></string-name>, <year>1986</year> <article-title>Learning representations by back-propagating errors</article-title>. <source>Nature</source> <volume>323</volume>: <fpage>533</fpage>.</mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><string-name><surname>Sankararaman</surname>, <given-names>S.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Mallick</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Dannemann</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Pr&#x00FC;fer</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Kelso</surname></string-name> <etal>et al.</etal>, <year>2014</year> <article-title>The genomic landscape of Neanderthal ancestry in present-day humans</article-title>. <source>Nature</source> <volume>507</volume>: <fpage>354</fpage>&#x2013;<lpage>357</lpage>.</mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><string-name><surname>Schiffels</surname>, <given-names>S.</given-names></string-name>, and <string-name><given-names>R.</given-names> <surname>Durbin</surname></string-name>, <year>2014</year> <article-title>Inferring human population size and separation history from multiple genome sequences</article-title>. <source>Nat. Genet</source>. <volume>46</volume>: <fpage>919</fpage>&#x2013;<lpage>925</lpage>.</mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="journal"><string-name><surname>Schl&#x00F6;tterer</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>R.</given-names> <surname>Tobler</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Kofler</surname></string-name> and <string-name><given-names>V.</given-names> <surname>Nolte</surname></string-name>, <year>2014</year> <article-title>Sequencing pools of individuals&#x2014; mining genome-wide polymorphism data without big funding</article-title>. <source>Nature Reviews Genetics</source> <volume>15</volume>: <fpage>749</fpage>.</mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><string-name><surname>Schrider</surname>, <given-names>D.</given-names></string-name>, <string-name><given-names>J.</given-names> <surname>Ayroles</surname></string-name>, <string-name><given-names>D. R.</given-names> <surname>Matute</surname></string-name> and <string-name><given-names>A. D.</given-names> <surname>Kern</surname></string-name>, <year>2018</year> <article-title>Supervised machine learning reveals introgressed loci in the genomes of <italic>Drosophila simulans</italic> and <italic>D. sechellia</italic></article-title>. <source>PLoS Genet</source>. <volume>14</volume>: <fpage>e1007341</fpage>.</mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="journal"><string-name><surname>Schrider</surname>, <given-names>D. R.</given-names></string-name>, and <string-name><given-names>A. D.</given-names> <surname>Kern</surname></string-name>, <year>2016</year> <article-title>S/HIC: Robust Identification of Soft and Hard Sweeps Using Machine Learning</article-title>. <source>PLoS Genet</source>. <volume>12</volume>: <fpage>e1005928</fpage>.</mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><string-name><surname>Schrider</surname>, <given-names>D. R.</given-names></string-name>, and <string-name><given-names>A. D.</given-names> <surname>Kern</surname></string-name>, <year>2017</year> <article-title>Soft sweeps are the dominant mode of adaptation in the human genome</article-title>. <source>Mol. Biol. Evol</source>. <volume>34</volume>: <fpage>1863</fpage>&#x2013;<lpage>1877</lpage>.</mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><string-name><surname>Schrider</surname>, <given-names>D. R.</given-names></string-name>, and <string-name><given-names>A. D.</given-names> <surname>Kern</surname></string-name>, <year>2018</year> <article-title>Supervised Machine Learning for Population Genetics: A New Paradigm</article-title>. <source>Trends Genet</source>. <volume>34</volume>: <fpage>301</fpage>&#x2013;<lpage>312</lpage>.</mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="journal"><string-name><surname>Schrider</surname>, <given-names>D. R.</given-names></string-name>, <string-name><given-names>F. K.</given-names> <surname>Mendes</surname></string-name>, <string-name><given-names>M. W.</given-names> <surname>Hahn</surname></string-name> and <string-name><given-names>A. D.</given-names> <surname>Kern</surname></string-name>, <year>2015</year> <article-title>Soft shoulders ahead: spurious signatures of soft and partial selective sweeps result from linked hard sweeps</article-title>. <source>Genetics</source> <volume>200</volume>: <fpage>267</fpage>&#x2013;<lpage>284</lpage>.</mixed-citation></ref>
<ref id="c99"><mixed-citation publication-type="journal"><string-name><surname>Sheehan</surname>, <given-names>S.</given-names></string-name>, and <string-name><given-names>Y. S.</given-names> <surname>Song</surname></string-name>, <year>2016</year> <article-title>Deep learning for population genetic inference</article-title>. <source>PLoS Comput. Biol</source>. <volume>12</volume>: <fpage>e1004845</fpage>.</mixed-citation></ref>
<ref id="c100"><mixed-citation publication-type="journal"><string-name><surname>Simonsen</surname>, <given-names>K. L.</given-names></string-name>, <string-name><given-names>G. A.</given-names> <surname>Churchill</surname></string-name> and <string-name><given-names>C. F.</given-names> <surname>Aquadro</surname></string-name>, <year>1995</year> <article-title>Properties of statistical tests of neutrality for DNA polymorphism data</article-title>. <source>Genetics</source> <volume>141</volume>: <fpage>413</fpage>&#x2013;<lpage>429</lpage>.</mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="other"><string-name><surname>Simonyan</surname>, <given-names>K.</given-names></string-name>, and <string-name><given-names>A.</given-names> <surname>Zisserman</surname></string-name>, <year>2014</year> <article-title>Very deep convolutional networks for large-scale image recognition</article-title>. <source>arXiv preprint arXiv:1409.1556</source>.</mixed-citation></ref>
<ref id="c102"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>G.</given-names> <surname>Coop</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Stephens</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Novembre</surname></string-name>, <year>2018</year> <article-title>Estimating time to the common ancestor for a beneficial allele</article-title>. <source>Mol. Biol. Evol</source>.</mixed-citation></ref>
<ref id="c103"><mixed-citation publication-type="journal"><string-name><surname>Sohn</surname>, <given-names>K.-A.</given-names></string-name>, <string-name><given-names>Z.</given-names> <surname>Ghahramani</surname></string-name> and <string-name><given-names>E. P.</given-names> <surname>Xing</surname></string-name>, <year>2012</year> <article-title>Robust estimation of local genetic ancestry in admixed populations using a nonparametric Bayesian approach</article-title>. <source>Genetics</source> <volume>191</volume>: <fpage>1295</fpage>&#x2013;<lpage>1308</lpage>.</mixed-citation></ref>
<ref id="c104"><mixed-citation publication-type="journal"><string-name><surname>Srivastava</surname>, <given-names>N.</given-names></string-name>, <string-name><given-names>G.</given-names> <surname>Hinton</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Krizhevsky</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Sutskever</surname></string-name> and <string-name><given-names>R.</given-names> <surname>Salakhutdinov</surname></string-name>, <year>2014</year> <article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title>. <source>The Journal of Machine Learning Research</source> <volume>15</volume>: <fpage>1929</fpage>&#x2013;<lpage>1958</lpage>.</mixed-citation></ref>
<ref id="c105"><mixed-citation publication-type="journal"><string-name><surname>Sugden</surname>, <given-names>L. A.</given-names></string-name>, <string-name><given-names>E. G.</given-names> <surname>Atkinson</surname></string-name>, <string-name><given-names>A. P.</given-names> <surname>Fischer</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Rong</surname></string-name>, <string-name><given-names>B. M.</given-names> <surname>Henn</surname></string-name> <etal>et al.</etal>, <year>2018</year> <article-title>Localization of adaptive variants in human genomes using averaged one-dependence estimation</article-title>. <source>Nature Communications</source> <volume>9</volume>: <fpage>703</fpage>.</mixed-citation></ref>
<ref id="c106"><mixed-citation publication-type="other"><string-name><surname>Szegedy</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>W.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Jia</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Sermanet</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Reed</surname></string-name> <etal>et al.</etal>, <year>2015</year> <article-title>Going deeper with convolutions, pp</article-title>. in <source>CVPR</source>.</mixed-citation></ref>
<ref id="c107"><mixed-citation publication-type="journal"><string-name><surname>Tajima</surname>, <given-names>F.</given-names></string-name>, <year>1989</year> <article-title>Statistical method for testing the neutral mutation hypothesis by DNA polymorphism</article-title>. <source>Genetics</source> <volume>123</volume>: <fpage>585</fpage>&#x2013;<lpage>595</lpage>.</mixed-citation></ref>
<ref id="c108"><mixed-citation publication-type="journal"><string-name><surname>Tennessen</surname>, <given-names>J. A.</given-names></string-name>, <string-name><given-names>A. W.</given-names> <surname>Bigham</surname></string-name>, <string-name><given-names>T. D.</given-names> <surname>O&#x2019;Connor</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Fu</surname></string-name>, <string-name><given-names>E. E.</given-names> <surname>Kenny</surname></string-name> <etal>et al.</etal>, <year>2012</year> <article-title>Evolution and functional impact of rare coding variation from deep sequencing of human exomes</article-title>. <source>Science</source> <volume>337</volume>: <fpage>64</fpage>&#x2013;<lpage>69</lpage>.</mixed-citation></ref>
<ref id="c109"><mixed-citation publication-type="journal"><string-name><surname>Teshima</surname>, <given-names>K. M.</given-names></string-name>, and <string-name><given-names>H.</given-names> <surname>Innan</surname></string-name>, <year>2009</year> <article-title>mbs: modifying Hudson&#x2019;s ms software to generate samples of DNA sequences with a biallelic site under selection</article-title>. <source>BMC Bioinformatics</source> <volume>10</volume>: <fpage>166</fpage>.</mixed-citation></ref>
<ref id="c110"><mixed-citation publication-type="journal"><string-name><surname>Thornton</surname>, <given-names>K. R.</given-names></string-name>, <year>2014</year> <article-title>A C&#x002B;&#x002B; template library for efficient forward-time population genetic simulation of large populations</article-title>. <source>Genetics</source> <volume>198</volume>: <fpage>157</fpage>&#x2013;<lpage>166</lpage>.</mixed-citation></ref>
<ref id="c111"><mixed-citation publication-type="journal"><string-name><surname>Turner</surname>, <given-names>T. L.</given-names></string-name>, <string-name><given-names>M. W.</given-names> <surname>Hahn</surname></string-name> and <string-name><given-names>S. V.</given-names> <surname>Nuzhdin</surname></string-name>, <year>2005</year> <article-title>Genomic islands of speciation in Anopheles gambiae</article-title>. <source>PLoS Biol</source>. <volume>3</volume>: <fpage>e285</fpage>.</mixed-citation></ref>
<ref id="c112"><mixed-citation publication-type="journal"><string-name><surname>Voight</surname>, <given-names>B. F.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Kudaravalli</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Wen</surname></string-name> and <string-name><given-names>J. K.</given-names> <surname>Pritchard</surname></string-name>, <year>2006</year> <article-title>A map of recent positive selection in the human genome</article-title>. <source>PLoS Biol</source>. <volume>4</volume>: <fpage>e72</fpage>.</mixed-citation></ref>
<ref id="c113"><mixed-citation publication-type="journal"><string-name><surname>Vy</surname>, <given-names>H. M. T.</given-names></string-name>, and <string-name><given-names>Y.</given-names> <surname>Kim</surname></string-name>, <year>2015</year> <article-title>A Composite-Likelihood Method for Detecting Incomplete Selective Sweep from Population Genomic Data</article-title>. <source>Genetics</source> <volume>200</volume>: <fpage>633</fpage>&#x2013;<lpage>649</lpage>.</mixed-citation></ref>
<ref id="c114"><mixed-citation publication-type="journal"><string-name><surname>Watterson</surname>, <given-names>G.</given-names></string-name>, <year>1975</year> <article-title>On the number of segregating sites in genetical models without recombination</article-title>. <source>Theor. Popul. Biol</source>. <volume>7</volume>: <fpage>256</fpage>&#x2013;<lpage>276</lpage>.</mixed-citation></ref>
<ref id="c115"><mixed-citation publication-type="other"><string-name><surname>Yu</surname>, <given-names>F.</given-names></string-name>, and <string-name><given-names>V.</given-names> <surname>Koltun</surname></string-name>, <year>2015</year> <article-title>Multi-scale context aggregation by dilated convolutions</article-title>. <source>arXiv preprint arXiv:1511.07122</source>.</mixed-citation></ref>
<ref id="c116"><mixed-citation publication-type="other"><string-name><surname>Zaheer</surname>, <given-names>M.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Kottur</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Ravanbakhsh</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Poczos</surname></string-name>, <string-name><given-names>R. R.</given-names> <surname>Salakhutdinov</surname></string-name> <etal>et al.</etal>, <year>2017</year> <article-title>Deep sets</article-title>, pp. <fpage>3394</fpage>&#x2013;<lpage>3404</lpage> in <source>Advances in Neural Information Processing Systems</source>.</mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>SUPPLEMENTARY TABLE LEGENDS</title>
<p>Table S1: Demographic parameter ranges used to simulate 3-epoch population size histories.</p>
<p>Table S2: The effect of different neural network input/output/architecture hyperparameters on demographic inference error.</p>
</sec>
</back>
</article>
