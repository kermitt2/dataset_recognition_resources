<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/430173</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Epidemiology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A theoretical foundation of state-transition cohort models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8680-4824</contrib-id>
<name>
<surname>Iskandar</surname>
<given-names>Rowan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Health Services, Policy, and Practice, Brown University</institution>, Providence, Rhode Island, <country>USA</country></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="other"><label>&#x002A;</label><p><email>rowan_iskandar@brown.edu</email></p></fn>
<fn fn-type="present-address"><label>&#x00A4;</label><p>Current Address: Department of Health Services, Policy, and Practice, Brown University, Providence, Rhode Island, USA</p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2018</year></pub-date>
<elocation-id>430173</elocation-id>
<history>
<date date-type="received">
<day>28</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>28</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>9</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="430173.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Following its introduction over three decades ago, the cohort model has been used extensively to model population trajectories over time in decision-analytic modeling studies. However, the stochastic process underlying cohort models has not been properly described. In this study, we explicate the stochastic process underlying a cohort model, by carefully formulating the dynamics of populations across health states and assigning probability rules on these dynamics. From this formulation, we explicate a mathematical representation of the system, which is given by the master equation. We solve the master equation by using the probability generation function method to obtain the explicit form of the probability of observing a particular realization of the system at an arbitrary time. The resulting generating function is used to derive the analytical expressions for calculating the mean and the variance of the process. Secondly, we represent the cohort model by a difference equation for the number of individuals across all states. From the difference equation, a continuous-time cohort model is recovered and takes the form of an ordinary differential equation. To show the equivalence between the derived stochastic process and the cohort model, we conduct a numerical exercise. We demonstrate that the population trajectories generated from the formulas match those from the cohort model simulation. In summary, the commonly-used cohort model represent the average of a continuous-time stochastic process on a multidimensional integer lattice governed by a master equation. Knowledge of the stochastic process underlying a cohort model provides a theoretical foundation for the modeling method.</p>
</abstract>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Decision models have been used in various applications from clinical decision making to screening guideline development. The objective of decision modeling is to integrate and present evidence within a coherent and explicit mathematical structure that can be used to link evidence to decision-relevant outcomes. In decision modeling, a state-transition Markov model is often used to simulate the prognosis of a patient or a group of patients following an intervention. Beck and Pauker [<xref ref-type="bibr" rid="c1">1</xref>] introduced the modeling method over 30 years ago with the aim to provide a simple tool for prognostic modeling and for practical use in medical decision making. They applied standard methods from the Markov chain theory [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>] to simulate a life history of <italic>an individual</italic> which is structured as transitions across various heath states over time, i.e. a stochastic process on a finite state space (<inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1a.gif"/></alternatives></inline-formula>). However, the current literature in decision modeling lacks clarity in the following two concepts. First, a <italic>cohort model</italic>, an extension of the state-transition model from one individual to a group of individuals, is often used to introduce and describe a stochastic process on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1b.gif"/></alternatives></inline-formula>. According to [<xref ref-type="bibr" rid="c1">1</xref>] and the subsequent published tutorials and textbook [<xref ref-type="bibr" rid="c4">4</xref>&#x2013;<xref ref-type="bibr" rid="c7">7</xref>], given a matrix of transition probabilities and an initial distribution of <italic>counts</italic> of individuals across health states, a cohort model generates the life trajectory of a cohort of <italic>identical</italic> individuals by repeated multiplications of the vector of population counts by the transition probability matrix. This matrix operation alludes to a stochastic process on a much larger state space, i.e. <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_2a.gif"/></alternatives></inline-formula> (compared to <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1c.gif"/></alternatives></inline-formula>),where &#x2115; and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline1k.gif"/></alternatives></inline-formula> denote the set of natural numbers and the number of states, respectively. For example, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1d.gif"/></alternatives></inline-formula> may be a partitioning on an individual&#x2019;s health state into healthy, sick, or dead. In contrast, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_2b.gif"/></alternatives></inline-formula> may refer to a partitioning of a cohort of individuals into the numbers of healthy, sick and, dead individuals. The convolution of these two different processes in decision modeling literature lead to the second issue: practitioners are taught that cohort models capture the <italic>average behavior</italic> of the individuals. [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>] However, this claim is often stated without any clear reference to which stochastic process. Frederix et. al. [<xref ref-type="bibr" rid="c9">9</xref>] proposes an ordinary differential equation (ODE)-based method to approximate Markov models whilst acknowledging that the ODEs can describe only &#x201C;the typical (mean) change,&#x201D; albeit, without providing any rational or reference. One of the standard textbooks [<xref ref-type="bibr" rid="c7">7</xref>] describes cohort model as a representation of the average experience of patients in the cohort without providing any rationales to support this description. Furthermore, wide acceptance of methodologies does not automatically imply veracity. [<xref ref-type="bibr" rid="c10">10</xref>] In the context of cohort models, the wide acceptance is ingrained by the ISPOR-SMDM Modeling Good Research Practices Task Force-3. [<xref ref-type="bibr" rid="c11">11</xref>] The published best practices cites the work of Beck et al. [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c4">4</xref>] as the main and <italic>only</italic> references for cohort models, thereby standardizing cohort models as the recommended method for simulating population trajectories despite of the lack of a proper description of the theoretical support in the decision modeling area.</p>
<p>This paper aims to address the aforementioned problems by placing cohort models in a larger framework based on existing literature on stochastic process. Therefore, in this paper, we explicate the stochastic process underlying a cohort model and derive its corresponding probability function from which the prevailing notion of an <italic>average</italic> is based on. For this paper, we adopt a continuous-time perspective, i.e. for a discrete-time process, a corresponding continuous-time process exists (<italic>embeddability assumption</italic>). In addition, we assume that transition rates are time-invariant and the process of interest is Markovian, i.e. knowledge of the current state conveys all information that is relevant to forecasting future states. This paper is organized into four main parts. Firstly, we review the prevailing descriptions of cohort model in decision modeling literature and formulate their mathematical representations to substantiate our claim of lack of clarity in the current description of a cohort model. Secondly, we postulate a precise description of the cohort dynamics and the probability rules on these dynamics to derive the underlying stochastic process. Thirdly, we solve for the probability function associated with the stochastic process by method of evolution equation. To show that the derived stochastic process corresponds to cohort model, we also derive the mathematical formulas for the average and the variance of the process. Fourthly, the correspondence is then demonstrated by showing the equivalence between the first two moments of the process and the cohort model via a numerical example. Throughout this exposition, we try to strike a balance between mathematical rigor and accessibility to practitioners.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Prevailing views of cohort model</title>
<p>Beck and Pauker [<xref ref-type="bibr" rid="c1">1</xref>] introduced a discrete-time Markov model as a method for representing a patient&#x2019;s prognosis which can be viewed as a sequence of states of health in discrete time steps. We distinguish between three prevalent descriptions of a Markov model [<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>]: (1) a model for an individual or a Markov chain on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1e.gif"/></alternatives></inline-formula>, (2) a cohort model or a process on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_2c.gif"/></alternatives></inline-formula>, and (3) the continuous-time analogue of a cohort model from which the ODE-based method [<xref ref-type="bibr" rid="c9">9</xref>] arises.</p>
</sec>
<sec id="s2b">
<title>Markov chain on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1f.gif"/></alternatives></inline-formula></title>
<p>A discrete-time Markov chain on a finite set of mutually exclusive and completely exhaustive states: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_3.gif"/></alternatives></inline-formula>, is a stochastic process, {<italic>S</italic>(<italic>n</italic>)} &#x003D; {<italic>S</italic>(<italic>t<sub>n</sub></italic>)} where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_4.gif"/></alternatives></inline-formula> is the initial time, <italic>&#x03C4;</italic> is the Markov cycle and <italic>n</italic> &#x2208; {0, 1, &#x2026;, <italic>N</italic>}, given an <italic>s</italic> &#x00D7; <italic>s</italic> stochastic matrix of transition probabilities governing the transitions among states, <bold>P</bold><sub><italic>&#x03C4;</italic></sub>(<italic>t</italic>) &#x003D; (<italic>p<sub>ij</sub></italic>(<italic>t</italic>))<sub>1&#x2264;<italic>i,j</italic>&#x2264;<italic>s</italic></sub>, and a 1 &#x00D7; <italic>s</italic> vector of initial probability distribution <bold>p</bold>(<italic>t</italic><sub>0</sub>) &#x003D; [1 0 &#x2026; 0 0] if, without loss of generality, we assume an individual start in <italic>S</italic><sub>1</sub>. Each <italic>p<sub>ij</sub></italic>(<italic>t, &#x03C4;</italic>) has the usual interpretation of the probability of an individual transitioning from <italic>S<sub>i</sub></italic> to <italic>S<sub>j</sub></italic> in <italic>&#x03C4;</italic> at time <italic>t</italic>. In principle, to calculate the distribution of states in the next cycle, <bold>p</bold>(<italic>t</italic>&#x002B;<italic>&#x03C4;</italic>), we post-multiply the distribution in the current cycle, <bold>p</bold>(<italic>t</italic>), with <bold>P</bold><sub><italic>&#x03C4;</italic></sub>(<italic>t</italic>):</p>
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="430173_eqn1.gif"/></alternatives>
</disp-formula>
</sec>
<sec id="s2c">
<title>Cohort simulation</title>
<p>An <italic>s</italic>-state cohort simulation [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c7">7</xref>] is a recursive algebraic calculations that generates a trajectory of population counts (<italic>state-configuration</italic>): <disp-formula id="eqn2"><alternatives><graphic xlink:href="430173_eqn2.gif"/></alternatives>
</disp-formula> where <bold>N</bold>(<italic>t</italic>) &#x2208; &#x211D;<sup><italic>s</italic></sup> denotes the number of individuals in state <italic>S<sub>i</sub></italic> at time <italic>t</italic> &#x2265; <italic>t</italic><sub>0</sub>, given <bold>P</bold><sub><italic>&#x03C4;</italic></sub>(<italic>t</italic>) as defined above, and an initial distribution <bold>N</bold>(<italic>t</italic><sub>0</sub>) &#x003D; [<italic>n</italic><sub>0</sub> 0 &#x2026; 0 0]. In principle, to calculate the distribution of individuals across all states at time <italic>t</italic> &#x002B; <italic>&#x03C4;, N</italic>(<italic>t</italic> &#x002B; <italic>&#x03C4;</italic>), the state-configuration at time <italic>t, N</italic>(<italic>t</italic>), is projected forward in time using the linear operator <bold>P</bold><sub><italic>&#x03C4;</italic></sub>(<italic>t</italic>): <disp-formula id="eqn3"><alternatives><graphic xlink:href="430173_eqn3.gif"/></alternatives></disp-formula></p>
</sec>
<sec id="s2d">
<title>Continuous-time ODE-equivalence</title>
<p>The recursive formula (<xref ref-type="disp-formula" rid="eqn3">Eq 3</xref>) can be written as a difference equation and if we take the limit of this difference equation with respect to the Markov cycle, we obtain the differential form of a cohort model: <disp-formula id="eqn4"><alternatives><graphic xlink:href="430173_eqn4.gif"/></alternatives>
</disp-formula> where <bold>Q</bold> is the <italic>infinitesimal generator</italic> matrix of size <italic>s</italic> &#x00D7; <italic>s</italic>, <bold>Q</bold> &#x003D; (<italic>&#x0109;<sub>kl</sub></italic>)<sub>1&#x2264;<italic>i,j</italic>&#x2264;<italic>s</italic></sub>, for the continuous-time stochastic process underlying a cohort model. The off-diagonal elements of <bold>Q</bold> are non-negative while the diagonal elements are non-positive, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_5.gif"/></alternatives></inline-formula>. If <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_6.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>], then the continuous-time version of a cohort model is a <italic>deterministic</italic> process governed by an ordinary differential equation (ODE) or, alternatively, a rate equation for the state-configuration.</p>
</sec>
</sec>
<sec id="s3">
<title>Reformulation of cohort model</title>
<sec id="s3a">
<title>Formulation strategy</title>
<p>In the context of decision modeling, the typical system of interest is exemplified by the health state of an individual following the implementation of an intervention and the changes in the health state during a time period, often a lifetime. The representation is dynamic in the sense that the states and parameters of the system are functions of time. The formulation of a <italic>dynamic</italic> process underlying the changes in an individual&#x2019;s health state starts by observing the state of the world at, at least two different time points, e.g., at <italic>t</italic> and <italic>t</italic> &#x002B; <italic>&#x03C4;</italic>. The difference between the two observations are then identified and the events, that contributed to these differences in health state and are most consistent with the prevailing evidence and theories, are postulated. After identifying all possible events, an individual&#x2019;s health state is then represented by enumerating the possible health states, i.e. a partitioning on the world via S. The dynamics of the system is consequently determined by the identified events and operationalized by assigning the allowable transitions to all pairs of states in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1g.gif"/></alternatives></inline-formula> that are consistent with theories and data. The aforementioned formulation of a process for an individual, which follows Beck and Pauker [<xref ref-type="bibr" rid="c1">1</xref>], is then extended to a cohort of individuals, i.e. a process on &#x2115;<sup><italic>s</italic></sup>. In this expanded state space, the dynamic system of interest is the changes in state-configuration, which is represented by <xref ref-type="disp-formula" rid="eqn2">Eq 2</xref>. The transition from one state-configuration to another represents not only a change in health state of one individual, which follows the rules on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1h.gif"/></alternatives></inline-formula> but also a change in the number of individuals of the two corresponding states.</p>
<p>Given the state space and the transition rules, we then specify the nature of the transitions, i.e. stochastic or deterministic changes. The choice of a stochastic (vs. deterministic) representation of the transition is natural because the applications of decision modeling often involves a disease progression component which is an inherently random system, i.e. can be described up to a certain degree of confidence. In contrast to a deterministic model, in which given an initial condition, the sequence of the states of the world can be determined with a probability of one, the solution to a stochastic model can be represented by a multidimensional probability function at any <italic>t</italic> following the initial time <italic>t</italic><sub>0</sub>. Therefore, the state of the system at any given time can only be described with a probabilistic statement, i.e., the probability of observing a particular state-configuration, <bold>N</bold>(<italic>t</italic>) &#x003D; <bold>n</bold> &#x2208; &#x2124;<sup><italic>s</italic></sup> at time <italic>t</italic> or <italic>P</italic>(<bold>N</bold>(<italic>t</italic>) &#x003D; <bold>n</bold>) &#x003D; <italic>P</italic> (<bold>n</bold>, <italic>t</italic>).</p>
</sec>
<sec id="s3b">
<title>Master equation</title>
<p>Given the formulation strategy, we formalize the description of the process in this section. An event of transitioning from <italic>S<sub>k</sub></italic> to <italic>S<sub>l</sub></italic> is denoted by the <italic>transition R<sub>kl</sub></italic> where <italic>k, l</italic> &#x2208; {1 &#x2026;, <italic>s</italic>}. Since the occurrence of each transition alters the state-configuration, each <italic>R<sub>kl</sub></italic> is associated with a vector representing this change, <italic>s<sub>kl</sub></italic>, and is defined as <italic>s<sub>kl</sub></italic> &#x003D; <italic>e<sub>l</sub> &#x2212; e<sub>k</sub></italic> where <italic>e<sub>i</sub></italic> is the <italic>i</italic>-th column of an identity matrix of size <italic>s</italic>. We associate each transition with a <italic>propensity function</italic>: <italic>v<sub>kl</sub></italic>(<bold>n</bold>, <italic>t</italic>) &#x003D; <italic>c<sub>kl</sub></italic>(<italic>t</italic>)<italic>h</italic>(<italic>n<sub>k</sub>, n<sub>l</sub></italic>), where <italic>c<sub>kl</sub></italic>(<italic>t</italic>) is the transition rate for transition <italic>R<sub>kl</sub></italic>, and <italic>N<sub>k</sub></italic>(<italic>t</italic>) &#x003D; <italic>n<sub>k</sub></italic> and <italic>N<sub>l</sub></italic>(<italic>t</italic>) &#x003D; <italic>n<sub>l</sub></italic>. The function <italic>h</italic>(<italic>n<sub>k</sub>, n<sub>l</sub></italic>) determines the number of ways <italic>R<sub>kl</sub></italic> can occur which is equal to the number of individuals in <italic>S<sub>k</sub>, h<sub>kl</sub></italic>(<italic>n<sub>k</sub>, n<sub>l</sub></italic>) &#x003D; <italic>n<sub>k</sub></italic>. The propensity function denotes the probability of a (any) transition occurring in continuous time as a function of the state-configuration and rate constant. The probability of observing <italic>one particular</italic> transition <italic>R<sub>kl</sub></italic> in a small time interval <italic>&#x03C4;</italic> is assumed to be linear in time: <italic>c<sub>kl</sub></italic>(<italic>t</italic>)<italic>&#x03C4;</italic> &#x002B; <italic>o</italic>(<italic>&#x03C4;</italic>), where <italic>o</italic>(<italic>&#x03C4;</italic>) represents other terms that decay to zero faster than <italic>&#x03C4;</italic>. Therefore, the probability of a transition from <italic>S<sub>k</sub></italic> to <italic>S<sub>l</sub></italic> in time step <italic>&#x03C4;</italic> is given by <italic>n<sub>k</sub>c<sub>kl</sub></italic>(<italic>t</italic>)<italic>&#x03C4;</italic> &#x002B; <italic>o</italic>(<italic>&#x03C4;</italic>) (see S1 Transition probability). A transition <italic>R<sub>k,l</sub></italic> occurring with a probability <italic>v<sub>kl</sub></italic>(<bold>n</bold>, <italic>t</italic>)<italic>&#x03C4;</italic> in a time step <italic>&#x03C4;</italic> alters the current state <bold>N</bold>(<italic>t</italic>) &#x003D; <bold>n</bold> to:</p>
<disp-formula>
<alternatives><graphic xlink:href="430173_ueqn1.gif"/></alternatives>
</disp-formula>
<p>Following the mathematical descriptions of the possible changes in the state-configuration and the probabilities of these changes, we derive the evolution equation for <italic>P</italic> (<bold>n</bold>, <italic>t</italic>), i.e., master equation (also known as the <italic>forward Kolmogorov</italic> equation), which describes how <italic>P</italic> (<bold>n</bold>, <italic>t</italic>) changes in continuous time. The master equation is obtained by enumerating all possible events contributing to a change in the probability of observing a particular state-configuration in an infinitesimal time step and is given by (see S2 Master equation:</p>
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="430173_eqn5.gif"/></alternatives>
</disp-formula>
<p>The terms, <italic>v<sub>kl</sub></italic>(<bold>n</bold>, <italic>t</italic>)<italic>P</italic> (<bold>n</bold>, <italic>t</italic>), represent the probability transferred from one to another state-configuration resulting from the transition <italic>R<sub>kl</sub></italic>. (<italic>probability flux</italic>). In principle, a master equation expresses the change per unit of time of the probability of observing a state-configuration <bold>n</bold> as the sum of two opposite effects: the probability flux into and out of <bold>n</bold>. Therefore, a master equation is essentially a rate equation for the probability of observing a state-configuration (c.f. <xref ref-type="disp-formula" rid="eqn4">Eq 4</xref>). The solution to the master equation, <italic>P</italic> (<bold>n</bold>, <italic>t</italic>), contains all information about the modeled system and can be, under some conditions on <italic>c<sub>kl</sub></italic>(<italic>t</italic>) obtained by applying the generating function technique (see S3 Generating function method). A probability generating function (PGF) of <italic>P</italic> (<bold>n</bold>, <italic>t</italic>) is defined by:</p>
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="430173_eqn6.gif"/></alternatives>
</disp-formula>
<p>The explicit solution to the <xref ref-type="disp-formula" rid="eqn6">Eq 6</xref> is obtained by solving a first-order linear partial differential equation (PDE) for <italic>G</italic>(x, <italic>t</italic>). [<xref ref-type="bibr" rid="c14">14</xref>] We solve for the PGF under two initial conditions: (1) an arbitrary initial distribution and (2) all individuals start in <italic>S</italic><sub>1</sub>. From the solution to the PDE, we recover <italic>P</italic> (n, <italic>t</italic>) by using the definition of PGF and obtain the first two moments of the process, i.e., the mean and the variance from the first derivative of <italic>G</italic>(x, <italic>t</italic>) (see S4 Mean and variance of the master equation).</p>
</sec>
</sec>
<sec id="s4">
<title>Results</title>
<sec id="s4a">
<title>Solution to master equation</title>
<p>The solution to the master equation, the probability function of a state-configuration <bold>n</bold> at time <italic>t</italic>, for an arbitrary initial state-configuration <italic>P</italic> (<bold>n</bold>, 0) is given by: where <bold>z</bold><sub><italic>i</italic></sub> &#x003D; [<italic>z</italic><sub><italic>i</italic>1</sub> <italic>z</italic><sub><italic>i</italic>2</sub> &#x2026; <italic>z<sub>is</sub></italic>] where <italic>i</italic> &#x2208; {1, 2, &#x2026;, <italic>s</italic>}, <italic>B</italic>(<italic>t</italic>) &#x003D; exp <italic>At</italic>, i.e. the matrix exponential and <italic>A</italic> is an <italic>s</italic> &#x00D7; <italic>s</italic> matrix, (<italic>c<sub>kl</sub></italic>)<sub><italic>k,l</italic>&#x2208;{1,2,&#x2026;,<italic>s</italic>}</sub>, with elements of the form: <italic>a<sub>kl</sub></italic> &#x003D; <italic>c<sub>kl</sub></italic> &#x2212; <italic>&#x03B3;<sub>k</sub>&#x03B4;<sub>kl</sub></italic> with <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_7.gif"/></alternatives></inline-formula> and <italic>&#x03B4;<sub>kl</sub></italic> is the Kronecker delta (<italic>&#x03B4;<sub>kl</sub></italic> &#x003D; 1 if <italic>k</italic> &#x003D; <italic>l</italic> and is 0 otherwise). Matrix <italic>A</italic> is identical to matrix <italic>Q</italic> in <xref ref-type="disp-formula" rid="eqn4">Eq 4</xref>, the generator matrix for the continuous-time ODE-equivalence of a cohort model. For the case where all <italic>n</italic><sub>0</sub> individuals start in <italic>S</italic><sub>1</sub> (<italic>N</italic><sub>1</sub>(0) &#x003D; <italic>n</italic><sub>0</sub>), the probability function of a state-configuration <bold>n</bold> at time <italic>t</italic> is represented by: <disp-formula id="eqn7"><alternatives><graphic xlink:href="430173_eqn7.gif"/></alternatives></disp-formula></p>
<p>The mean of the number of individuals in the <italic>i</italic>-th state at time <italic>t</italic> is given by: <disp-formula id="eqn8"><alternatives><graphic xlink:href="430173_eqn8.gif"/></alternatives></disp-formula></p>
<p>The variance of the number of individuals is the <italic>i</italic>-th state at time <italic>t</italic> is given by: <disp-formula id="eqn9"><alternatives><graphic xlink:href="430173_eqn9.gif"/></alternatives></disp-formula></p>
<p>For an arbitrary initial distribution, the mean of the number of individuals in state <italic>S<sub>i</sub></italic> is given by: <disp-formula id="eqn10">
<alternatives><graphic xlink:href="430173_eqn10.gif"/></alternatives></disp-formula> and the variance is given by: <disp-formula id="eqn11"><alternatives><graphic xlink:href="430173_eqn11.gif"/></alternatives></disp-formula></p>
</sec>
<sec id="s4b">
<title>Numerical verification</title>
<p>We conduct a numerical exercise to verify the validity of the derived stochastic process. In particular, we aim to verify the formulas for the mean (<xref ref-type="disp-formula" rid="eqn8">Eq 8</xref>) and the variance (<xref ref-type="disp-formula" rid="eqn9">Eq 9</xref>). For this verification exercise, we consider a stochastic process with <italic>s</italic> &#x003D; 4, i.e.</p>
<p><inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_8.gif"/></alternatives></inline-formula> (<xref ref-type="fig" rid="fig1">Fig 1</xref>), rate constants (elements of <italic>Q</italic>): <italic>c</italic><sub>12</sub> &#x003D; 0.05, <italic>c</italic><sub>13</sub> &#x003D; 0.01, <italic>c</italic><sub>14</sub> &#x003D; 0.001, <italic>c</italic><sub>23</sub> &#x003D; 0.1, <italic>c</italic><sub>24</sub> &#x003D; 0.05, and <italic>c</italic><sub>34</sub> &#x003D; 2, and an initial condition in which all individuals start in <italic>S</italic><sub>1</sub>, i.e. <italic>N</italic><sub>1</sub>(0) &#x003D; 10000. As a set of benchmarks for the mean, we simulate the population trajectories, i.e. the counts of individuals in all states, (1) using a cohort model with <italic>&#x03C4;</italic> &#x003D; 1-year (<xref ref-type="disp-formula" rid="eqn3">Eq 3</xref>) and (2) a continuous-time cohort model (<xref ref-type="disp-formula" rid="eqn4">Eq 4</xref>). The benchmark for variance is based on 1000 Monte Carlo samples of <italic>microsimulation</italic> population with <italic>&#x03C4;</italic> &#x003D; 1-year. Each microsimulation population is conceived as a realization of 10000 Markov chains with the generator matrix <italic>Q</italic> (as in <xref ref-type="disp-formula" rid="eqn4">Eq 4</xref>). The calculation of the 1-year transition probability matrix from the <italic>Q</italic> matrix is based on the formulas from Welton and Ades. [<xref ref-type="bibr" rid="c15">15</xref>] The results of the population trajectories are given in Figure (<xref ref-type="fig" rid="fig2">Fig 2</xref>). We observe no difference between the empirical estimates from the microsimulation and the analytic formulas for both the mean and the variance of the process associated with the cohort model.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1.</label><caption><p>A 4-states continuous-time stochastic process used in numerical verification exercise</p></caption>
<graphic xlink:href="430173_fig1.tif"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2.</label><caption><p>Population trajectories across 4 states [CM: cohort model, MSM: microsimulation, ODE: continuous-time cohort model, PGF: master equation, sd: standard deviation.</p></caption>
<graphic xlink:href="430173_fig2.tif"/>
</fig>
</sec>
</sec>
<sec id="s5">
<title>Discussion</title>
<p>In this study, we explicate the stochastic process underlying the commonly used cohort model, defined as a continuous-time discrete-state stochastic process, in the context where population counts are of interest. First, We start the derivation by specifying a stochastic state-transition model for an individual following Beck and Pauker: a stochastic process on state space <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1i.gif"/></alternatives></inline-formula>. [<xref ref-type="bibr" rid="c1">1</xref>] We then extend the model to a cohort of individuals by formulating a set of postulates for the cohort dynamics: a stochastic process on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_2d.gif"/></alternatives></inline-formula>. The evolution equation representing the stochastic process for the cohort dynamics in the form of master equation is then obtained. We then solve the master equation to get the probability function of individuals across all states, which completely characterizes stochastic nature of the dynamics, by using the generating function method. Based on the explicit form of the generating function, the analytical formulas for the average and variance are obtained. This measure of variance quantifies the inherent variability of the population trajectories (<italic>aleatory uncertainty</italic> [<xref ref-type="bibr" rid="c16">16</xref>] or first-order uncertainty [<xref ref-type="bibr" rid="c17">17</xref>]) and may be useful for quantifying the extent of variability in the mean prediction. In our simulation example, we show that to estimate the variance of the population counts across states, we need to replicate the microsimulation population a sufficiently large number of times, which is a computationally intensive task and is similar to applying uncertainty analysis to a microsimulation model. [<xref ref-type="bibr" rid="c18">18</xref>] Our theoretical result provides a more direct and non-computationally demanding approach through the explicit formula for the variance. The derived probability function, when all individuals start in one state (a typical scenario in most applications) takes the form of a multinomial distribution and is a known result from the stochastic compartmental model literature [<xref ref-type="bibr" rid="c19">19</xref>]. In applications where the relevant population comprises of an actual cohort (e.g. birth cohorts), the individuals are often, prior to an implementation of an intervention, distributed across health states. For this purpose, we also derive the probability function and formulas for the moments, for an arbitrary initial condition. Lastly, we show the equivalence between the average of the derived stochastic process and the cohort model; thereby substantiating the prevailing notion of cohorts models as average process.</p>
<p>In the introduction to cohort models [<xref ref-type="bibr" rid="c1">1</xref>] for use in decision modeling, the authors emphasized the clinical utility of a <italic>Markov</italic> process (as opposed to a decision tree model) for modeling patient&#x2019;s prognosis with ongoing risks: a model for an inherently stochastic system. A stochastic representation of a system amounts to making probabilistic statements about its state given a set of probabilistic rules for the system dynamics. Therefore, the solution to any stochastic processes or models takes the form of a probability function on a set of random variables [<xref ref-type="bibr" rid="c2">2</xref>], i.e., in our context, <italic>P</italic> (<bold>n</bold>, <italic>t</italic>), which is the solution to the master equation. However, in their expositions, population counts were used as a representation of the stochastic system via a <italic>cohort simulation</italic>. The multiplication of the transition probabilities (used in individual process) with the cohort size (3) produces a deterministic quantity, i.e. the average of the process, not a probabilistic statement about the process. The commonly used representation of a cohort model via cohort simulation in decision modeling literature convolutes two distinct processes: a process on <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_1j.gif"/></alternatives></inline-formula> and a Markov chain on &#x2115;<sup><italic>s</italic></sup>. The notion of the average as represented by cohort simulation is based on the latter. To date, our work is the only study that delineates the convolution of these two different processes which has been perpetuated by tutorials and textbooks in decision modeling [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c20">20</xref>].</p>
<p>Having an explicit form of the evolution equation for <italic>P</italic> (n, <italic>t</italic>) is advantageous for, in some cases (e.g. time-invariant rates), finding the analytical form of <italic>P</italic> (<bold>n</bold>, <italic>t</italic>) and, in most cases (e.g. time-varying rates), deriving the mean and the variance of the process by using their evolution equations and without knowing the explicit form of <italic>P</italic> (<bold>n</bold>, <italic>t</italic>). In addition, given this knowledge of evolution equation associated with a cohort model, we can identify the relationship between cohort models and other known methodologies in stochastic process. In the classification tree of Markov processes [<xref ref-type="bibr" rid="c21">21</xref>], a cohort model as represented by the master equation is derived from the differential Chapman-Kolmogorov equation without the drift and diffusion coefficients. If the cohort size is sufficiently large, a cohort model can be approximated by the van Kampen&#x2019;s expansion method [<xref ref-type="bibr" rid="c22">22</xref>], which is analytically more tractable compared to master equation. In addition, if we relaxed the integrality constraint on the state space to allow for nonnegative real numbers, a cohort model may be represented by a Fokker-Planck or a stochastic differential equation (SDE). [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c23">23</xref>] Therefore, our study results provide practitioners and researchers the proper platform for the porting of methods from stochastic process literature for applications in decision modeling.</p>
<p>Knowledge of the underlying process will provide a proper context for efforts to resolve or clarify methodological challenges or issues, for example, in estimating the appropriate time step for cohort models. [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>] Practitioners of cohort models are taught to add an additional half-year of lives at the end of the cohort simulation to account for the fact that individuals transition at the end of each time step. This half-cycle correction is a consequence of discretizing a continuous-time scale. However, the refinement of half-cycle correction method was based on the average process [<xref ref-type="bibr" rid="c26">26</xref>], i.e. not taking into account the variance of the process or other higher-order moments. Naimark et al. [<xref ref-type="bibr" rid="c26">26</xref>] proposed several methods, including numerical integration techniques to determine the appropriate time step to bypass the need of half-cycle correction. Elbasha and Chhatwal [<xref ref-type="bibr" rid="c27">27</xref>] quantified the approximation errors from using these numerical integration methods in the context of a 3-states cohort model. However, these numerical approximation methods were applied to the &#x201C;state membership function,&#x201D; which is essentially the average number of individuals: an approximation of an approximation. This study result can facilitate a more accurate approximation, which would be based on directly using the master equation, i.e. based on how a change in the time step affects the probability function.</p>
<p>One limitation of the study concerns with the focus on cohort models with time-invariant rates. In most applications, the transition probabilities are often time-dependent (e.g. age-specific probability of death due to other causes). A direct consequence of assuming non-constant rates is that the solution to a master equation becomes mathematically intractable and henceforth inaccessible to most practitioners. However, various numerical and approximation methods for solving master equations are available as a corollary of knowing the proper placement of cohort models in the classification tree of stochastic processes, as described above. For example, Gillespie&#x2019;s stochastic simulation [<xref ref-type="bibr" rid="c28">28</xref>] and tau-leap methods [<xref ref-type="bibr" rid="c29">29</xref>] numerically solves a master equation by simulating all possible events one-at-a-time or in batches, respectively. Despite of this limitation, our analytical results remain applicable in many situations since no restriction is placed on the number of states and the allowable transition patters on the set of states. In addition, the analytical results for an arbitrary initial condition can be utilized to approximate a process with time-varying rates by using a piecewise process. Each piece or time interval corresponds to a time-invariant process. The initial condition of the next time interval would be the distribution of individuals at the end of the previous interval. We plan to introduce this piecewise method in a future study.</p>
<p>This paper also assumes that the discrete-time transition probability matrix is embeddable to a continuous-time model, i.e. the limit of <italic>P</italic> exists and its equal to the generator matrix of the process (<xref ref-type="disp-formula" rid="eqn4">Eq 4</xref>). Although discrete-time Markov models has been the method of choice in many applications in decision modeling, the processes under consideration, e.g. biological process or disease progression, evolve continuously; henceforth the appropriate modeling framework would be a continuous-time model [<xref ref-type="bibr" rid="c30">30</xref>]. In addition, the reason for the greater popularity of the discrete-time structure stems from its simpler mathematical nature, not from considerations of veracity. [<xref ref-type="bibr" rid="c31">31</xref>] However, in some instances, one can argue that an individual-level model tend to follow a discrete-time process, e.g. the transitions among living arrangements for an elderly patient occur in discrete time steps. However, if we consider a cohort of individuals, the probability of a patient transitioning in a small time interval would very likely to be nonzero. Nevertheless, we believe that future studies investigating whether the typical Markov models in decision modeling are embeddable are warranted.</p>
</sec>
<sec id="s6">
<title>Conclusion</title>
<p>The cohort model provides an easy-to-implement method for modeling recurrent events over time and has been used extensively in many applications ranging from clinical decision making to policy evaluations. Knowledge of the underlying theoretical framework would reaffirm the prevailing beliefs in the veracity and validity of the method and thereby increase confidence in conclusions derived from studies using cohort models.</p>
</sec>
</body>
<back>
<sec id="s7">
<title>Supporting information</title>
<p><bold>S1 Transition probability</bold> In this section, we show the derivation for the probability of transitioning from <italic>S<sub>k</sub></italic> to state <italic>S<sub>l</sub></italic> in time step <italic>&#x03C4;</italic>, which is given by:</p>
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="430173_eqn12.gif"/></alternatives>
</disp-formula>
<p>The probability of a <italic>particular</italic> transition <italic>k &#x2192; l</italic> (<italic>R<sub>kl</sub></italic>) in a small time step <italic>&#x03C4;</italic> is postulated to be linear in time: <italic>c<sub>kl</sub>&#x03C4;</italic> &#x002B; <italic>o</italic>(<italic>&#x03C4;</italic>). This postulate is conceptually a first-order Taylor approximation to an instantaneous transition probability. The transition rate constant, <italic>c<sub>kl</sub></italic>, is interpreted as the derivative of the transition probability at time <italic>&#x03C4;</italic> &#x003D; 0. We also restrict the number of allowable transitions in <italic>&#x03C4;</italic> to one transition. If the number of individuals in <italic>S<sub>k</sub></italic> at time <italic>t</italic> is equal to <italic>n<sub>k</sub></italic>, then any of these <italic>n<sub>k</sub></italic>, assumed to be <italic>indistinguishable</italic>, individuals is at risk of transitioning. Since individuals are indistinguishable, each individual transition can be considered as a Bernoulli trial with a probability of success of <italic>c<sub>kl</sub>&#x03C4;</italic> &#x002B; <italic>o</italic>(<italic>&#x03C4;</italic>). The probability of only one individual transitioning is equal to: (<italic>c<sub>kl</sub>&#x03C4;</italic> &#x002B; <italic>o</italic>(<italic>&#x03C4;</italic>))(1 &#x2212; <italic>c<sub>kl</sub>&#x03C4;</italic> &#x002B; <italic>o</italic>(<italic>&#x03C4;</italic>))<sup><italic>n<sub>k</sub></italic> &#x2212;1</sup>. Since there are <italic>n<sub>k</sub></italic> ways of this transition to occur, we have:</p>
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="430173_eqn13.gif"/></alternatives>
</disp-formula>
<p><xref ref-type="disp-formula" rid="eqn12">Eq 12</xref> is then recovered as the <italic>&#x03C4;</italic> terms of higher order are collected as <italic>o</italic>(<italic>&#x03C4;</italic>) after expanding the binomial term in <xref ref-type="disp-formula" rid="eqn13">Eq 13</xref>.</p>
<p><bold>S2 Master equation</bold> In this section, the steps for deriving <xref ref-type="disp-formula" rid="eqn5">Eq 5</xref> are outlined. In principle, the master equation is based on the idea of mass conservation. First, the probability of observing a particular state-configuration at time <italic>t</italic> &#x002B; <italic>&#x03C4;</italic> is a function of the probabilities of the adjacent state-configurations at time <italic>t</italic> and the transitions between the corresponding probabilities of the state-configurations occurring in time step <italic>&#x03C4;</italic>. The adjacent state configurations are defined as state-configurations with differences of &#x002B;1 and <italic>&#x2212;</italic>1 in two of the state counts, compared to the state-configuration of interest. The transitions between these corresponding probabilities are governed by the propensity function (<italic>v</italic>). Mathematically, the first step translates to:</p>
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="430173_eqn14.gif"/></alternatives>
</disp-formula>
<p>Rearranging <xref ref-type="disp-formula" rid="eqn14">Eq 14</xref> and dividing it by <italic>&#x03C4;</italic> yields:</p>
<disp-formula id="eqn15">
<alternatives><graphic xlink:href="430173_eqn15.gif"/></alternatives>
</disp-formula>
<p>The master equation is then established after taking the limit <italic>&#x03C4;</italic> &#x2192; 0.</p>
<p><bold>S3 Generating function method</bold> A probability generating function (PGF) for a vector <bold>x</bold> &#x003D; (<italic>x</italic><sub>1</sub> <italic>x</italic><sub>2</sub> &#x2026; <italic>x<sub>s</sub></italic>) is defined by: <disp-formula id="eqn16"><alternatives><graphic xlink:href="430173_eqn16.gif"/></alternatives>
</disp-formula> where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_9.gif"/></alternatives></inline-formula>. Differentiating <italic>G</italic>(<bold>x</bold>, <italic>t</italic>) with respect to <italic>t</italic> and assuming that the series is uniformly convergent, we obtain: <disp-formula><alternatives><graphic xlink:href="430173_ueqn2.gif"/></alternatives></disp-formula> or <disp-formula id="eqn17"><alternatives><graphic xlink:href="430173_eqn17.gif"/></alternatives></disp-formula> <xref ref-type="disp-formula" rid="eqn17">Eq 17</xref> can be simplified by (1) recognizing the following identity (e.g., for <italic>x</italic><sub>1</sub>): <disp-formula><alternatives><graphic xlink:href="430173_ueqn3.gif"/></alternatives></disp-formula> (2) using the definition of PGF (<xref ref-type="disp-formula" rid="eqn16">Eq 16</xref>), and (3) rearranging the summation index to obtain the following first-order linear partial differential equation (PDE): <disp-formula id="eqn18"><alternatives><graphic xlink:href="430173_eqn18.gif"/></alternatives></disp-formula> with an initial condition: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_10.gif"/></alternatives></inline-formula> The PDE by solved by using the method of characteristics [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. The characteristics equations are: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_11.gif"/></alternatives></inline-formula> where <bold>v</bold> &#x003D; (<italic>v</italic><sub>1</sub><italic>v</italic><sub>2</sub> &#x2026; <italic>v<sub>s</sub></italic>) and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_12.gif"/></alternatives></inline-formula>. Putting <italic>&#x03B2;</italic>(<italic>s</italic>) &#x003D; <italic>G</italic>(<italic>x</italic>(<italic>&#x03BE;</italic>), <italic>t</italic> &#x2212; <italic>&#x03BE;</italic>), we have: <disp-formula id="eqn19"><alternatives><graphic xlink:href="430173_eqn19.gif"/></alternatives></disp-formula> from which a general solution can be deduced: <italic>G</italic>(<bold>x</bold>(0), <italic>t</italic>) &#x003D; <italic>G</italic>(<bold>x</bold>(<italic>t</italic>), 0) &#x003D; <italic>g</italic>(<bold>x</bold>(<italic>t</italic>)). The system of the characteristics equations can be written as: <disp-formula id="eqn20"><alternatives><graphic xlink:href="430173_eqn20.gif"/></alternatives>
</disp-formula> where <italic>A</italic> is an <italic>s</italic> &#x00D7; <italic>s</italic>, (<italic>c<sub>kl</sub></italic>)<sub><italic>k,l</italic>&#x2208;{1,2,&#x2026;,<italic>s</italic>}</sub>, matrix with elements of the form: <italic>A<sub>kl</sub></italic> &#x003D; <italic>c<sub>kl</sub></italic> &#x2212; <italic>&#x03B3;<sub>k</sub>&#x03B4;<sub>kl</sub></italic> with <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_13.gif"/></alternatives></inline-formula> and <italic>&#x03B4;<sub>kl</sub></italic> is the usual Kronecker delta. Therefore, the solution of 20 takes the form: <disp-formula id="eqn21"><alternatives><graphic xlink:href="430173_eqn21.gif"/></alternatives></disp-formula> where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_14.gif"/></alternatives></inline-formula>, i.e. the matrix exponential. Given, <italic>G</italic>(<bold>x</bold>, 0), <italic>G</italic>(<bold>x</bold>(0), <italic>t</italic>) &#x003D; <italic>g</italic>(<italic>B</italic><bold>x</bold>(0)). The solution of the PGF is then: <disp-formula id="eqn22"><alternatives><graphic xlink:href="430173_eqn22.gif"/></alternatives></disp-formula></p>
<p>If we assumed all <italic>n</italic><sub>0</sub> individuals start in state <italic>S</italic><sub>1</sub>, i.e. <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_15a.gif"/></alternatives></inline-formula>, the solution of the PGF is then: <disp-formula id="eqn23"><alternatives><graphic xlink:href="430173_eqn23.gif"/></alternatives></disp-formula></p>
<p>The probability density function of the state-configuration can be recovered from <xref ref-type="disp-formula" rid="eqn23">Eq 23</xref> by using the definition of the PGF. We introduce a vector: <bold>z</bold><sub><italic>i</italic></sub> &#x003D; [<italic>z<sub>i</sub></italic><sub>1</sub> <italic>z<sub>i</sub></italic><sub>2</sub> &#x2026; <italic>z<sub>is</sub></italic>] where <italic>i</italic> &#x2208; {1, 2, &#x2026;, <italic>s</italic>} and the norm &#x2225;<bold>z</bold><sub><italic>i</italic></sub>&#x2225; &#x003D; <italic>z<sub>i</sub></italic><sub>1</sub> &#x002B; <italic>z<sub>i</sub></italic><sub>2</sub> &#x002B; &#x2026; &#x002B; <italic>z<sub>is</sub></italic>. Using the multinomial theorem: <disp-formula><alternatives><graphic xlink:href="430173_ueqn4.gif"/></alternatives></disp-formula> we write <disp-formula id="eqn24"><alternatives><graphic xlink:href="430173_eqn24.gif"/></alternatives></disp-formula></p>
<p>Therefore, we have: <disp-formula><alternatives><graphic xlink:href="430173_ueqn5.gif"/></alternatives></disp-formula></p>
<p>If we rearrange the last line, we have: <disp-formula id="eqn25"><alternatives><graphic xlink:href="430173_eqn25.gif"/></alternatives></disp-formula></p>
<p>Therefore the solution to the master equation is obtained after equating the coefficients in <xref ref-type="disp-formula" rid="eqn16">Eq 16</xref> with <xref ref-type="disp-formula" rid="eqn22">Eq 22</xref>: <disp-formula id="eqn26"><alternatives><graphic xlink:href="430173_eqn26.gif"/></alternatives></disp-formula></p>
<p>If we assumed all <italic>n</italic><sub>0</sub> individuals start in state <italic>S</italic><sub>1</sub>, i.e. <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="430173_inline_15b.gif"/></alternatives></inline-formula>, the solution takes the form of a multinomial distribution: <disp-formula id="eqn27"><alternatives><graphic xlink:href="430173_eqn27.gif"/></alternatives></disp-formula></p>
<p><bold>S4 Mean and variance of the master equation</bold> The first moment of the master equation can be computed by differentiating <xref ref-type="disp-formula" rid="eqn23">Eq 23</xref> and set all <italic>x</italic> equal to 1, e.g. the mean of the number of individuals in state <italic>S<sub>i</sub></italic>, given all <italic>n</italic><sub>0</sub> individuals start in state <italic>S</italic><sub>1</sub>, is equal to: <disp-formula id="eqn28"><alternatives><graphic xlink:href="430173_eqn28.gif"/></alternatives></disp-formula></p>
<p>For an arbitrary initial distribution, the mean of the number of individuals in state <italic>S<sub>i</sub></italic> is given by: <disp-formula id="eqn29"><alternatives><graphic xlink:href="430173_eqn29.gif"/></alternatives></disp-formula></p>
<p>The variance of the master equation can be derived by using the following relationship: <disp-formula id="eqn30"><alternatives><graphic xlink:href="430173_eqn30.gif"/></alternatives></disp-formula></p>
<p>The variance of the number of individuals in state <italic>S<sub>i</sub></italic>, given all <italic>n</italic><sub>0</sub> individuals start in state <italic>S</italic><sub>1</sub>, is equal to: <disp-formula id="eqn31"><alternatives><graphic xlink:href="430173_eqn31.gif"/></alternatives></disp-formula></p>
<p>The variance of the number of individuals in state <italic>S<sub>i</sub></italic> for an arbitrary initial distribution is given by: <disp-formula id="eqn32"><alternatives><graphic xlink:href="430173_eqn32.gif"/></alternatives></disp-formula></p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>I would like to thank Fernando Alarid-Escudero, Thomas A. Trikalinos, and Shaun P. Forbes for their insightful comments on the final draft.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Beck</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Pauker</surname> <given-names>SG</given-names></string-name>. <article-title>The Markov process in medical prognosis</article-title>. <source>Med Decis Making.</source> <year>1983</year>;<volume>3</volume>(<issue>4</issue>):<fpage>419</fpage>&#x2013;<lpage>458</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="book"><string-name><surname>Stroock</surname> <given-names>DW</given-names></string-name>. <chapter-title>An introduction to Markov processes</chapter-title>. <volume>vol. 230</volume>. <publisher-name>Springer Science &#x0026; Business Media</publisher-name>; <year>2013</year>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="book"><string-name><surname>Cox</surname> <given-names>D</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>H</given-names></string-name>. <chapter-title>The theory of stochastic processes</chapter-title>. <year>1965</year>. <publisher-name>Methuen</publisher-name>, <publisher-loc>London</publisher-loc>;.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Sonnenberg</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Beck</surname> <given-names>JR</given-names></string-name>. <article-title>Markov models in medical decision making: a practical guide</article-title>. <source>Medical decision making.</source> <year>1993</year>;<volume>13</volume>(<issue>4</issue>):<fpage>322</fpage>&#x2013;<lpage>338</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Naimark</surname> <given-names>D</given-names></string-name>, <string-name><surname>Krahn</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Naglie</surname> <given-names>G</given-names></string-name>, <string-name><surname>Redelmeier</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Detsky</surname> <given-names>AS</given-names></string-name>. <article-title>Primer on medical decision analysis: part 5&#x2014;working with Markov processes</article-title>. <source>Medical Decision Making.</source> <year>1997</year>;<volume>17</volume>(<issue>2</issue>):<fpage>152</fpage>&#x2013;<lpage>159</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Briggs</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sculpher</surname> <given-names>M</given-names></string-name>. <article-title>An introduction to Markov modelling for economic evaluation</article-title>. <source>Pharmacoeconomics.</source> <year>1998</year>;<volume>13</volume>(<issue>4</issue>):<fpage>397</fpage>&#x2013;<lpage>409</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="book"><string-name><surname>Hunink</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Weinstein</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Wittenberg</surname> <given-names>E</given-names></string-name>, <string-name><surname>Drummond</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Pliskin</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Wong</surname> <given-names>JB</given-names></string-name>, <etal>et al.</etal> <chapter-title>Decision making in health and medicine: integrating evidence and values</chapter-title>. <publisher-name>Cambridge University Press</publisher-name>; <year>2014</year>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="book"><string-name><surname>Kuntz</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Weinstein</surname> <given-names>MC</given-names></string-name>. 7. In: <string-name><surname>Drummond</surname> <given-names>MF</given-names></string-name>, <string-name><surname>A</surname> <given-names>M</given-names></string-name>, <role>editors</role>. <chapter-title>Modelling in economic evaluation</chapter-title>. <publisher-name>Oxford University Press</publisher-name>; <year>2001</year>. p. <fpage>141</fpage>&#x2013;<lpage>71</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Frederix</surname> <given-names>GW</given-names></string-name>, <string-name><surname>van Hasselt</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Severens</surname> <given-names>JL</given-names></string-name>, <string-name><surname>H&#x00F6;vels</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Huitema</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Raaijmakers</surname> <given-names>JA</given-names></string-name>, <etal>et al.</etal> <article-title>Development of a framework for cohort simulation in cost-effectiveness analyses using a multistep ordinary differential equation solver algorithm in R</article-title>. <source>Medical Decision Making</source>. <year>2013</year>;<volume>33</volume>(<issue>6</issue>):<fpage>780</fpage>&#x2013;<lpage>792</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="other"><string-name><surname>Trikalinos</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Dahabreh</surname> <given-names>IJ</given-names></string-name>, <string-name><surname>Wallace</surname> <given-names>BC</given-names></string-name>, <string-name><surname>Schmid</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Lau</surname> <given-names>J</given-names></string-name>. <article-title>Towards a framework for communicating confidence in methodological recommendations for systematic reviews and meta-analyses</article-title>. <year>2013</year>;.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Siebert</surname> <given-names>U</given-names></string-name>, <string-name><surname>Alagoz</surname> <given-names>O</given-names></string-name>, <string-name><surname>Bayoumi</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Jahn</surname> <given-names>B</given-names></string-name>, <string-name><surname>Owens</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>DJ</given-names></string-name>, <etal>et al.</etal> <article-title>State-transition modeling: a report of the ISPOR-SMDM modeling good research practices task force-3</article-title>. <source>Value in Health</source>. <year>2012</year>;<volume>15</volume>(<issue>6</issue>):<fpage>812</fpage>&#x2013;<lpage>820</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Kurtz</surname> <given-names>TG</given-names></string-name>. <article-title>Limit theorems for sequences of jump Markov processes approximating ordinary differential processes</article-title>. <source>Journal of Applied Probability.</source> <year>1971</year>;<volume>8</volume>(<issue>2</issue>):<fpage>344</fpage>&#x2013;<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="book"><string-name><surname>Karlin</surname> <given-names>S</given-names></string-name>, <string-name><surname>Taylor</surname> <given-names>HE</given-names></string-name>. <chapter-title>A second course in stochastic processes</chapter-title>. <publisher-name>Elsevier</publisher-name>; <year>1981</year>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="book"><string-name><surname>Bailey</surname> <given-names>NT</given-names></string-name>. <chapter-title>The elements of stochastic processes with applications to the natural sciences</chapter-title>. <volume>vol. 25</volume>. <publisher-name>John Wiley &#x0026; Sons</publisher-name>; <year>1990</year>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Welton</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Ades</surname> <given-names>A</given-names></string-name>. <article-title>Estimation of Markov chain transition probabilities and rates from fully and partially observed data: uncertainty propagation, evidence synthesis, and model calibration</article-title>. <source>Medical Decision Making.</source> <year>2005</year>;<volume>25</volume>(<issue>6</issue>):<fpage>633</fpage>&#x2013;<lpage>645</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Hagan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Oakley</surname> <given-names>JE</given-names></string-name>. <article-title>Probability is perfect, but we can&#x2019;t elicit it perfectly</article-title>. <source>Reliability Engineering &#x0026; System Safety.</source> <year>2004</year>;<volume>85</volume>(<issue>1&#x2013;3</issue>):<fpage>239</fpage>&#x2013;<lpage>248</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Stinnett</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Mullahy</surname> <given-names>J</given-names></string-name>. <article-title>Net health benefits: a new framework for the analysis of uncertainty in cost-effectiveness analysis</article-title>. <source>Medical decision making.</source> <year>1998</year>;<volume>18</volume>(<issue>2 suppl</issue>):<fpage>S68</fpage>&#x2013;<lpage>S80</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;hagan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Stevenson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Madan</surname> <given-names>J</given-names></string-name>. <article-title>Monte Carlo probabilistic sensitivity analysis for patient level simulation models: efficient estimation of mean and variance using ANOVA</article-title>. <source>Health economics.</source> <year>2007</year>;<volume>16</volume>(<issue>10</issue>):<fpage>1009</fpage>&#x2013;<lpage>1023</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Matis</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Hartley</surname> <given-names>H</given-names></string-name>. <article-title>Stochastic compartmental analysis: model and least squares estimation from time series data</article-title>. <source>Biometrics.</source> <year>1971</year>; p. <fpage>77</fpage>&#x2013;<lpage>102</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="book"><string-name><surname>Briggs</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sculpher</surname> <given-names>M</given-names></string-name>, <string-name><surname>Claxton</surname> <given-names>K</given-names></string-name>. <chapter-title>Decision modelling for health economic evaluation</chapter-title>. <publisher-name>OUP Oxford</publisher-name>; <year>2006</year>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Ullah</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wolkenhauer</surname> <given-names>O</given-names></string-name>. <article-title>Family tree of Markov models in systems biology</article-title>. <source>IET systems biology.</source> <year>2007</year>;<volume>1</volume>(<issue>4</issue>):<fpage>247</fpage>&#x2013;<lpage>254</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="book"><string-name><surname>Kampen</surname> <given-names>NV</given-names></string-name>. <chapter-title>Stochastic processes in physics and chemistry</chapter-title>. <publisher-name>North Holland</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="book"><string-name><surname>Gardiner</surname> <given-names>C</given-names></string-name>. <chapter-title>Stochastic methods</chapter-title>. <source>A Handbook for the Natural and Social Sciences</source>. <volume>vol. 4</volume>. <publisher-name>Springer-Verlag Berlin Heidelberg Berlin</publisher-name>; <year>2009</year>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Gillespie</surname> <given-names>DT</given-names></string-name>, <string-name><surname>Petzold</surname> <given-names>L</given-names></string-name>. <article-title>Numerical simulation for biochemical kinetics</article-title>. <source>Systems Modelling in Cellular Biology.</source> <year>2006</year>; p. <fpage>331</fpage>&#x2013;<lpage>354</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Naimark</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Bott</surname> <given-names>M</given-names></string-name>, <string-name><surname>Krahn</surname> <given-names>M</given-names></string-name>. <article-title>The half-cycle correction explained: two alternative pedagogical approaches</article-title>. <source>Medical Decision Making.</source> <year>2008</year>;<volume>28</volume>(<issue>5</issue>):<fpage>706</fpage>&#x2013;<lpage>712</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Naimark</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Kabboul</surname> <given-names>NN</given-names></string-name>, <string-name><surname>Krahn</surname> <given-names>MD</given-names></string-name>. <article-title>The half-cycle correction revisited: redemption of a kludge</article-title>. <source>Medical Decision Making.</source> <year>2013</year>;<volume>33</volume>(<issue>7</issue>):<fpage>961</fpage>&#x2013;<lpage>970</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Elbasha</surname> <given-names>EH</given-names></string-name>, <string-name><surname>Chhatwal</surname> <given-names>J</given-names></string-name>. <article-title>Theoretical foundations and practical applications of within-cycle correction methods</article-title>. <source>Medical Decision Making.</source> <year>2016</year>;<volume>36</volume>(<issue>1</issue>):<fpage>115</fpage>&#x2013;<lpage>131</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Gillespie</surname> <given-names>DT</given-names></string-name>. <article-title>Exact stochastic simulation of coupled chemical reactions</article-title>. <source>The journal of physical chemistry.</source> <year>1977</year>;<volume>81</volume>(<issue>25</issue>):<fpage>2340</fpage>&#x2013;<lpage>2361</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Gillespie</surname> <given-names>DT</given-names></string-name>. <article-title>Approximate accelerated stochastic simulation of chemically reacting systems</article-title>. <source>The Journal of Chemical Physics.</source> <year>2001</year>;<volume>115</volume>(<issue>4</issue>):<fpage>1716</fpage>&#x2013;<lpage>1733</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Soares</surname> <given-names>MO</given-names></string-name>, <string-name><surname>e Castro</surname> <given-names>LC</given-names></string-name>. <article-title>Continuous time simulation and discretized models for cost-effectiveness analysis</article-title>. <source>Pharmacoeconomics.</source> <year>2012</year>;<volume>30</volume>(<issue>12</issue>):<fpage>1101</fpage>&#x2013;<lpage>1117</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Singer</surname> <given-names>B</given-names></string-name>, <string-name><surname>Spilerman</surname> <given-names>S</given-names></string-name>. <article-title>The representation of social processes by Markov models</article-title>. <source>American Journal of Sociology.</source> <year>1976</year>;<volume>82</volume>(<issue>1</issue>):<fpage>1</fpage>&#x2013;<lpage>54</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="book"><string-name><surname>Strauss</surname> <given-names>WA</given-names></string-name>. <chapter-title>Partial differential equations</chapter-title>. <publisher-name>John Wiley &#x0026; Sons</publisher-name> <publisher-loc>New York, NY, USA</publisher-loc>; <year>1992</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>