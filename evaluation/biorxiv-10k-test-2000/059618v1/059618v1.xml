<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/059618</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Decoding brain activity using a large-scale probabilistic functional-anatomical atlas of human cognition</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Rubin</surname><given-names>Timothy N.</given-names></name>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Koyejo</surname><given-names>Oluwasanmi</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Gorgolewski</surname><given-names>Krzysztof J.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Jones</surname><given-names>Michael N.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Poldrack</surname><given-names>Russell A.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Yarkoni</surname><given-names>Tal</given-names></name>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
<xref ref-type="corresp" rid="cor1">&#x2020;</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychological and Brain Sciences, Indiana University Bloomington</institution></aff>
<aff id="a2"><label>2</label><institution>Department of Psychology, Stanford University</institution></aff>
<aff id="a3"><label>3</label><institution>Department of Computer Science, University of Illinois at UrbanaChampaign</institution></aff>
<aff id="a4"><label>4</label><institution>Department of Psychology, University of Texas at Austin</institution></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>&#x002A;</label><p>Contributed equally to this work</p></fn>
<corresp id="cor1"><label>&#x2020;</label>Corresponding author: <email>tyarkoni@utexas.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub"><year>2016</year></pub-date>
<elocation-id>059618</elocation-id>
<history>
<date date-type="received">
<day>17</day>
<month>6</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>6</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2016</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="059618.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>A central goal of cognitive neuroscience is to decode human brain activity&#x002D;&#x002D;i.e., to infer mental processes from observed patterns of whole-brain activation. Previous decoding efforts have focused on classifying brain activity into a small set of discrete cognitive states. To attain maximal utility, a decoding framework must be open-ended, systematic, and context-sensitive&#x002D;&#x002D;i.e., capable of interpreting numerous brain states, presented in arbitrary combinations, in light of prior information. Here we take steps towards this objective by introducing a Bayesian decoding framework based on a novel topic model&#x002D;&#x002D;&#x002D;Generalized Correspondence Latent Dirichlet Allocation&#x002D;&#x002D;&#x002D;that learns latent topics from a database of over 11,000 published fMRI studies. The model produces highly interpretable, spatially-circumscribed topics that enable flexible decoding of whole-brain images. Importantly, the Bayesian nature of the model allows one to &#x201C;seed&#x201D; decoder priors with arbitrary images and text&#x002D;&#x002D;enabling researchers, for the first time, to generative quantitative, context-sensitive interpretations of whole-brain patterns of brain activity.</p>
</abstract>
<counts>
<page-count count="50"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A central goal of cognitive neuroscience is to understand how neural and cognitive function interrelate. An important component of this effort is to be able to <italic>decode</italic> cognitive processes from brain activity, or vice versa. Although researchers have dedicated increasing effort to the challenges of brain decoding (<xref rid="c24" ref-type="bibr">Haxby, Connolly, &#x0026; Guntupalli, 2014</xref>; <xref rid="c25" ref-type="bibr">Haynes &#x0026; Rees, 2006</xref>; <xref rid="c28" ref-type="bibr">Kriegeskorte &#x0026; Kievit, 2013</xref>; <xref rid="c34" ref-type="bibr">Mitchell et al., 2004</xref>), the vast majority of brain decoding studies to date have focused on fine-grained analysis of a restricted set of cognitive states or experimental tasks&#x002D;&#x002D;for example, classifying which word or picture a subject is currently perceiving (<xref rid="c15" ref-type="bibr">Cox &#x0026; Savoy, 2003</xref>; <xref rid="c35" ref-type="bibr">Mitchell et al., 2008</xref>), or which of several predefined tasks they are engaged in (<xref rid="c43" ref-type="bibr">R. A. Poldrack, Halchenko, &#x0026; Hanson, 2009</xref>; <xref rid="c51" ref-type="bibr">Shirer, Ryali, Rykhlevskaia, Menon, &#x0026; Greicius, 2012</xref>). Such work is notable for its ability to achieve high classification rates of very specific stimuli. However, this accuracy is typically purchased at the cost of high context-specificity: thus far, there is little evidence that the patterns learned by classifiers in such studies can capably generalize to new research sites, experimental designs, and subject populations.</p>
<p>By contrast, much less work has focused on the development of open-ended decoding approaches that are broadly applicable across a variety of contexts. One approach to this type of generalizable decoding is to use large-scale meta-analytic databases such as Neurosynth (<xref rid="c58" ref-type="bibr">Yarkoni et al., 2011</xref>) and BrainMap (<xref rid="c29" ref-type="bibr">Laird et al., 2011</xref>; <xref rid="c30" ref-type="bibr">Laird, Lancaster, &#x0026; Fox, 2005</xref>) to derive estimates of what a broad variety of brain activations imply about cognitive processing-a form of analysis widely known as <italic>reverse inference</italic> (<xref rid="c40" ref-type="bibr">R. A. Poldrack, 2006</xref>; <xref rid="c42" ref-type="bibr">Russell A. Poldrack, 2011</xref>). Such efforts necessarily trade fidelity for breadth; that is, they allow researchers to draw inferences about almost any cognitive process that has been frequently studied with fMRI, but these inference are coarse, and come with a high degree of uncertainty. An illustrative study was conducted by <xref rid="c14" ref-type="bibr">Chang et al. (2012)</xref>, who used the Neurosynth database to &#x0022;decode&#x0022; the functional correlates of three distinct right insula clusters. The analytical strategy involved correlating each insula map with dozens of Neurosynth meta-analysis maps and drawing conclusions about function based on differences in relative similarity (e.g., an anterior insula region showed greatest similarity to executive control-related meta-analysis maps; a ventral insula region showed greatest similarity to affect-related maps; etc.). Other studies have used a similar approach to infer the putative functional correlates of whole-brain maps in a variety of other settings (e.g., <xref rid="c2" ref-type="bibr">Andrews-Hanna, Saxe, &#x0026; Yarkoni, 2014</xref>; <xref rid="c12" ref-type="bibr">Bzdok et al., 2013</xref>; <xref rid="c52" ref-type="bibr">Smith et al., 2009</xref>).</p>
<p>More recently, we have generalized this approach and implemented it in the online Neurosynth and NeuroVault platforms (<ext-link ext-link-type="uri" xlink:href="http://neurosynth.org/decode">http://neurosynth.org/decode</ext-link>). At present, researchers can upload arbitrary whole-brain maps to the NeuroVault repository and instantly decode them against the entire Neurosynth database. This decoding functionality provides researchers with a quantitative means of interpreting whole-brain activity patterns&#x002D;&#x002D;potentially replacing the qualitative conclusions more commonly drawn in the literature. However, the present approach&#x002D;&#x002D;which is based entirely on computation of spatial similarity coefficients between the input map and comparison meta-analysis maps&#x002D;&#x002D;has several weaknesses that limit its utility as a general-purpose decoding framework. Chief among these is that the approach is not grounded in a formal model: it allows one to estimate the similarity of any given brain activity map to other canonical maps, but does not provide a principled way to interpret these mappings.</p>
<p>Furthermore, the approach does not attempt to identify any latent structure that presumably makes such mappings useful&#x002D;&#x002D;for example, individual brain regions or functional brain networks that correspond to specific cognitive processes. A generative framework for decoding brain activity would offer researchers a number of important benefits: it would facilitate the learning of interpretable latent structures from a mass of superficial brain-cognition mappings; provide the ability to decode bidirectionally&#x002D;&#x002D;i.e., to not only identify functional correlates of arbitrary whole-brain images, but to also project descriptions of experimental tasks or psychological concepts into image space; and allow principled generation of novel exemplars or combinations of events that have never been seen before (e.g., what pattern of brain activity would a task combining painful stimulation and phonological awareness produce?).</p>
<p>Perhaps most importantly, by virtue of explicitly modeling both the joint and marginal probabilities of all events, a generative framework would provide the ability to contextualize predictions through the explicit use of Bayesian priors. At present, all brain decoding approaches we are aware of are acontextual: they provide researchers with no way to integrate contextual information or prior belief into the decoding process. Since many if not most brain regions are generally understood to contain multiple circuits with potentially distinguishable functions, knowledge of the experimental context within which a pattern of brain activity unfolds should, in principle, constrain interpretation of observed brain activity. Left inferior frontal gyrus activation may mean different things in the context of language comprehension (<xref rid="c57" ref-type="bibr">Vigneau et al., 2006</xref>), emotion regulation (<xref rid="c10" ref-type="bibr">Buhle et al., 2014</xref>), or response inhibition (<xref rid="c55" ref-type="bibr">Swick, Ashley, &#x0026; Turken, 2011</xref>). More generally, true reverse inference&#x002D;&#x002D;i.e., the move to draw conclusions about the likelihood of different mental states conditional on observed brain activity&#x002D;&#x002D;is an inherently Bayesian notion that requires one to formally model (and specify) the prior probability of each term or concept&#x2019;s occurrence. Whereas a similarity-based decoding approach cannot easily support such specification, it is intrinsic to a generative model.</p>
<p>Here we take the first steps towards these goals by introducing a generative Bayesian decoding framework based on a novel topic model&#x002D;&#x002D;&#x002D;Generalized Correspondence Latent Dirichlet Allocation (GC-LDA)&#x002D;&#x002D;&#x002D;that learns latent topics from the meta-analytic Neurosynth database of over 11,000 published fMRI studies (<xref rid="c58" ref-type="bibr">Yarkoni et al., 2011</xref>). GC-LDA generates topics that are simultaneously constrained by both anatomical and functional considerations: each topic defines a spatial region in the brain that is associated with a highly interpretable, coherent set of cognitive terms. We demonstrate that the dictionary of topics produced by the GC-LDA model successfully captures known anatomical and functional distinctions and provides a novel data-driven metric of hemispheric specialization. We then take advantage of the topic model&#x2019;s joint spatial and semantic constraints to develop a bidirectional, open-ended decoding framework. That is, we demonstrate the ability to extract both a text-based representation of any whole-brain image, and a whole-brain activity pattern corresponding to arbitrary text. Importantly, the Bayesian nature of the model allows us to formally specify a decoder&#x2019;s priors by &#x0022;seeding&#x0022; it with any arbitrary combination of images and text. The direct consequence is that, for the first time, researchers are able to generative quantitative, context-sensitive interpretations of whole-brain patterns of brain activity.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title><italic>Mapping the functional neuroanatomy of the brain with topic models</italic></title>
<p>Our decoding framework is built on a widely-used Bayesian modeling approach known as <italic>topic modeling</italic> (<xref rid="c6" ref-type="bibr">Blei, 2012</xref>; <xref rid="c8" ref-type="bibr">Blei, Ng, &#x0026; Jordan, 2003</xref>). Topic modeling is a dimensionality-reduction technique, which decomposes a corpus of documents into a set of semantically coherent probability distributions over words, known as <italic>topics</italic>. Given this set of topics, each document can be represented as a probabilistic mixture of topics. Topic models have been successfully applied to a wide range of problems, including text classification <underline>(<xref rid="c33" ref-type="bibr">Mcauliffe and Blei 2008</xref>: <xref rid="c48" ref-type="bibr">Rubin et al. 2011</xref>)</underline> information retrieval (<xref rid="c62" ref-type="bibr">Zhai, Chengxiang, &#x0026; John, 2001</xref>), image classification (<xref rid="c13" ref-type="bibr">Cao, Liangliang, &#x0026; Li, 2007</xref>), and theme discovery (<xref rid="c23" ref-type="bibr">Griffiths &#x0026; Steyvers, 2004</xref>; <xref rid="c54" ref-type="bibr">Steyvers, Smyth, Rosen-Zvi, &#x0026; Griffiths, 2004</xref>), and are now regarded as a standard technique for text and image analysis. An important feature from a decoding standpoint is that topic models are generative in nature: they allow a principled approach for bidirectional mapping from documents to latent components and vice versa; probabilistic generation of entirely new (i.e., previously unseen) documents; and formal Bayesian updating that can allow for explicit specification of the prior topic probabilities. We return to these features later.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Replication of topics from <xref rid="c45" ref-type="bibr">Poldrack et al. (2012)</xref>. Figure shows the results of applying the generic LDA model (<xref rid="c7" ref-type="bibr">Blei et al., 2003</xref>) to the Neurosynth database, as described in <xref rid="c45" ref-type="bibr">Poldrack et al. (2012)</xref>. (A) Selected topics reported in <xref rid="c45" ref-type="bibr">Poldrack et al. (2012)</xref> using an older Neurosynth database of 5,809 studies. (B) Closest matching topics when applying the same approach to the current, expanded, Neurosynth database (11,406 studies).</p></caption>
<graphic xlink:href="059618_fig1.tif"/>
</fig>
<p>In previous work, we used a standard topic model to extract 200 semantically coherent topics from the abstracts of all published fMRI articles contained in an older and smaller version of the Neurosynth database (5,809 studies; <xref rid="c45" ref-type="bibr">Russell A. Poldrack et al., 2012</xref>). We then projected each topic onto the space of brain activity to identify brain regions associated with distinct cognitive profiles. A direct replication of this earlier approach using the current, and much larger, Neurosynth database (11,406 studies) produces very similar results (e.g., <xref ref-type="fig" rid="fig1">Figure 1</xref>). As <xref ref-type="fig" rid="fig1">Figure 1</xref> illustrates, the structure-function mappings produced by this approach converge closely with numerous other findings in the literature&#x002D;&#x002D;&#x002D;e.g., the presence of a strongly left-lateralized language network (<xref rid="c57" ref-type="bibr">Vigneau et al., 2006</xref>) and the involvement of dorsal frontoparietal regions in working memory and executive control (<xref rid="c20" ref-type="bibr">Duncan, 2010</xref>). However, because the standard topic model operates only on the text of publications, the topics it produces are not constrained in any way by neural data. Furthermore, the spatial mappings for each topic are indirectly computed via the documents&#x2019; topic loadings&#x002D;&#x002D;the spatial data is not built into the model. The result is a set of widely distributed, network-like activation maps that closely resemble the whole-brain maps produced by individual fMRI experiments. While such an approach is informative if one&#x2019;s goal is to identify the distributed neural correlates of coherent psychological topics, it is of little help in the search for relatively simple, well-defined functional-anatomical atoms. A similar limitation applies to more recent work by Yeo et al, who used a more sophisticated topic model to derive a set of <italic>cognitive components</italic> that map in a many-to-many fashion onto both behavioral tasks and patterns of brain activity (<xref rid="c60" ref-type="bibr">Yeo et al., 2014</xref>). While the latter approach represents an important advance in its simultaneous use of both behavioral and brain activity data, the resulting spatial components remain relatively widely distributed, and do not provide insight into the likely cognitive roles of well-localized brain regions.</p>
</sec>
<sec id="s2b">
<title><italic>The GC-LDA model</italic></title>
<p>To extract structure-to-function mappings focused on a more granular, region-like level of analysis, we developed a novel topic model based on the Correspondence-LDA model (<xref rid="c7" ref-type="bibr">Blei &#x0026; Jordan, 2003</xref>) that generates topics simultaneously constrained by both semantic and spatial information. We term this the Generalized Correspondence LDA (GC-LDA) model <underline>(<xref ref-type="fig" rid="fig2">Fig. 2</xref>: for details, see <xref rid="c49" ref-type="bibr">Rubin. T. N., Koveio. O., Jones. M. N&#x2026;</xref>)</underline>. The GC-LDA model learns a set of latent topics, each associated with (i) a spatial probability distribution over brain activations and (ii) a set of words that co-occur in article abstracts. This extension of the Correspondence-LDA model incorporates a flexible spatial distribution that can be adjusted according to the goals of the experimenter. Here we focus on a version of the model in which each topic is associated with a mixture of two Gaussian clusters constrained to show symmetry around the x-axis, enabling us to directly quantify the degree of hemispheric symmetry (or lack thereof) displayed by each topic.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Schematic overview of the GC-LDA model. Each document (an article in the Neurosynth corpus) is represented as a mixture of learned latent topics, where each topic is associated with both a 3-dimensional Gaussian spatial distribution, and a set of linguistic terms extracted from the abstract text.</p></caption>
<graphic xlink:href="059618_fig2.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig3">Figure 3</xref> displays selected topics extracted using the GC-LDA model (for comprehensive results, see Supplementary Figure 1 and neurovault.org/collections/EBAYVDBZ/). As illustrated, the model produced numerous topics that had well-defined joint spatial and semantic representations (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>)&#x002D;&#x002D;approximately half of the 200 extracted topics were clearly interpretable (see Supp. Fig. 1 for full details). Many of these topics successfully captured relatively basic associations between specific structures and their putative functions; for example, we identified topics associated with amygdala activation and emotion; reward and the ventral striatum; hippocampus and memory; fusiform face area and face perception; and motion perception and the V5/MT complex, among others (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). In other cases, the model successfully captured and localized higher-level cognitive processes&#x002D;&#x002D;e.g., topics associated with the temporoparietal junction and mentalizing, temporal pole and person perception, or ventromedial PFC and valuation, among others (<xref ref-type="fig" rid="fig3">Fig. 3b</xref>). In supplementary analyses, we further demonstrate that the full set of 200 topics can be used to accurately &#x201C;reconstruct&#x201D; arbitrary patterns of whole-brain activity, providing an interpretable, low-dimensional way to summarize virtually any whole-brain image (Supplementary Results).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Selected topics learned by the GC-LDA model (for full results, see Supplementary Figure 1). (a) Spatial distributions for 90 of the 200 topics. Each color represents a different topic. Top row: hard assignments of activations to topics; each point represents a single activation from a single study in the Neurosynth database. Bottom row: estimated multivariate Gaussian mixture distribution of each topic, (b) Top semantic associates (word clouds) and activation distributions (brain orthviews) for selected topics. The size of a term in each word cloud is proportional to the strength of loading on the corresponding topic.</p></caption>
<graphic xlink:href="059618_fig3.tif"/>
</fig>
</sec>
<sec id="s2c">
<title><italic>Probabilistic structure-to-function mapping</italic></title>
<p>An important feature of the GC-LDA model is that it is probabilistic, and avoids the common, but restrictive, clustering assumption that each voxel should only be assigned to a single group (<xref rid="c5" ref-type="bibr">Bellec, Rosa-Neto, Lyttelton, Benali, &#x0026; Evans, 2010</xref>; <xref rid="c9" ref-type="bibr">Blumensath et al., 2013</xref>; <xref rid="c16" ref-type="bibr">Craddock, James, Holtzheimer, Hu, &#x0026; Mayberg, 2012</xref>; <xref rid="c47" ref-type="bibr">Power et al., 2011</xref>; <xref rid="c59" ref-type="bibr">Yeo et al., 2011</xref>). By allowing extracted topics to overlap with one another in space, the model explicitly acknowledges that the brain contains spatially overlapping circuits with thematically related functions. <xref ref-type="fig" rid="fig4">Figure 4</xref> illustrates the close spatial and semantic relationships between 10 different topics localized to overlapping parts of the parietal cortex along the banks of the intraparietal sulcus (IPS). Note the particularly similar posterior parietal cortex (PPC) distributions of topics associated with visuospatial processing, working memory, and general task engagement. These results are consistent with electrophysiological findings of highly heterogeneous, and typically complex, response profiles in PPC neurons (including coding of visual object location, direction of attention, motor plans, etc.; <xref rid="c1" ref-type="bibr">Andersen, Essick, &#x0026; Siegel, 1985</xref>; <xref rid="c11" ref-type="bibr">Bushnell, Goldberg, &#x0026; Robinson, 1981</xref>; <xref rid="c36" ref-type="bibr">Mountcastle, Lynch, Georgopoulos, Sakata, &#x0026; Acuna, 1975</xref>; <xref rid="c53" ref-type="bibr">Snyder, Batista, &#x0026; Andersen, 1997</xref>), and underscore the difficulty individual fMRI studies may face in trying to isolate brain-cognition mappings via a hemodynamic signal that sums over millions of neurons at each voxel.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Activation profiles and top-loading words for spatially overlapping topics in parietal cortex. Top row: hard assignments of activations to topics; each point represents a single activation from a single study in the Neurosynth database. Bottom row: estimated multivariate Gaussian mixture distribution of each topic.</p></caption>
<graphic xlink:href="059618_fig4.tif"/>
</fig>
<p>Analogously, the probabilistic nature of the GC-LDA mappings can also provide insights into the compositional character of most cognitive states&#x002D;&#x002D;&#x002D;i.e., the fact that most states are likely to recruit activation of a number of spatially distinct brain regions. <xref ref-type="fig" rid="fig5">Figure 5</xref> displays activation and word distributions for a number of emotion-related topics. Different topics captured different aspects of emotional processing: consistent with extensive previous work, extrastriate visual cortex and amygdala were associated with perceptual processing of emotion (<xref rid="c31" ref-type="bibr">LeDoux, 2003</xref>; <xref rid="c39" ref-type="bibr">Phelps, 2006</xref>; <xref rid="c61" ref-type="bibr">Zald, 2003</xref>); rostral anterior cingulate cortex and anterior insula were associated with experiential aspects of emotion (<xref rid="c32" ref-type="bibr">Lindquist, Wager, Kober, Bliss-Moreau, &#x0026; Barrett, 2012</xref>); and lateral frontal cortex was associated with emotion regulation (<xref rid="c10" ref-type="bibr">Buhle et al., 2014</xref>; <xref rid="c27" ref-type="bibr">Kohn et al., 2014</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Activation profiles and toploading words for emotionrelated topics. Top row: hard assignments of activations to topics; each point represents a single activation from a single study in the Neurosynth database. Bottom row: estimated multivariate Gaussian mixture distribution of each topic.</p></caption>
<graphic xlink:href="059618_fig5.tif"/>
</fig>
</sec>
<sec id="s2d">
<title><italic>A data-driven window into lateralization of function</italic></title>
<p>As noted above, each topic in the GC-LDA model was deliberately constrained to reflect two sub-regions reflected around the brain&#x2019;s x-axis. This constraint allowed us to estimate the relative weight of activations for each topic in the left vs. right hemisphere&#x002D;&#x002D;in effect providing a novel, data-driven index of hemispheric specialization. As one might expect given the marked degree of activation symmetry observed in most fMRI studies, most topics showed little or no hemispheric bias (<xref ref-type="fig" rid="fig6">Figure 6</xref>, top). However, there were a number of notable exceptions (e.g., <xref ref-type="fig" rid="fig6">Fig. 6</xref>, bottom). Several language-related topics localized strongly to left-hemisphere language regions&#x2014;including inferior and middle frontal gyrus, posterior superior temporal sulcus, and inferotemporal cortex (encompassing the putative visual word form area; <xref rid="c17" ref-type="bibr">Dehaene, Stanislas, &#x0026; Laurent, 2011</xref>). Right-lateralized topics were fewer in number and generally showed a weaker hemispheric asymmetry, but notably included a face processing topic localized to the putative fusiform face area (<xref rid="c26" ref-type="bibr">Kanwisher, McDermott, &#x0026; Chun, 1997</xref>), and an inhibitory control-related topic localized to the right ventral anterior insula (<xref rid="c3" ref-type="bibr">Aron, Robbins, &#x0026; Poldrack, 2004</xref>). To our knowledge, these findings constitute the first data-driven estimation of region-level functional hemispheric asymmetry across the whole brain.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Data-driven estimation of hemispheric lateralization of cognitive function. Top: histogram and kernel density estimation plot of the lateralization coefficient for all topics. Values below 0.5 represent left-lateralization; values above 0.5 represent right-lateralization. Bottom: selected topics that displayed notable hemispheric lateralization.</p></caption>
<graphic xlink:href="059618_fig6.tif"/>
</fig>
</sec>
<sec id="s2e">
<title><italic>Automatic text-to-image and image-to-text decoding</italic></title>
<p>Importantly the GC-LDA model is able to produce probabilistic estimates of word and activation distributions for entirely new data points. Moreover, because each topic is associated with both a word distribution and a spatial distribution, we can proceed bidirectionally&#x002D;&#x002D;&#x002D;either translating arbitrary text into image space, or decoding activations or images for their associated semantic content. <xref ref-type="fig" rid="fig7">Figure 7</xref> illustrates three different applications of this approach. First, we can generate estimated activation probabilities for any word or set of words. <xref ref-type="fig" rid="fig7">Figure 7A</xref> illustrates three concrete examples. In (1), we observe a complex, distributed pattern of activity for the term &#x2019;motor&#x2019;, including activations in primary and supplementary motor cortices, cerebellum, and the basal ganglia. This result demonstrates that even though each topic in our dictionary is spatially constrained, individual words will often still have widely distributed neural correlates by virtue of loading on multiple topics.</p>
<p>In (2) we pass in a list of generic cognitive effort-related terms (&#x2019;effort&#x2019;, &#x2019;difficult&#x2019;, and &#x2019;demands&#x2019;), and observe highly circumscribed activations in frontoparietal regions frequently implicated in general goal-directed processing (<xref rid="c19" ref-type="bibr">Dosenbach et al., 2006</xref>; <xref rid="c20" ref-type="bibr">Duncan, 2010</xref>). This result demonstrates the GC-LDA model&#x2019;s ability to produce topics with relatively abstract semantics: while few studies explicitly set out to study the neural correlates of task difficulty or cognitive effort, our model successfully learns that regions like anterior insula and preSMA&#x002D;&#x002D;which tend to activate in a very wide range of studies&#x002D;&#x002D;likely support fairly general cognitive operations non-selectively invoked by many different tasks (cf. <xref rid="c14" ref-type="bibr">Chang et al., 2012</xref>; <xref rid="c37" ref-type="bibr">Nelson et al., 2010</xref>; Neurosynth; <xref rid="c58" ref-type="bibr">Yarkoni et al., 2011</xref>).</p>
<p>Lastly, in (3), we provide a full sentence as input (&#x0022;painful stimulation during a language task&#x0022;), producing a map with peaks in both pain-related (e.g., posterior insula) and language-related left perisylvian regions. While the model follows the bag-of-words assumption (i.e., the order of words has no effect on the generated image), its compositional character is evident, in that it is possible to generate a predicted image for virtually any cognitive state or states that can be described in text.</p>
<p>Second, we can generate a list of plausible semantic associates for any set of discrete brain coordinates. <xref ref-type="fig" rid="fig7">Figure 7B</xref> illustrates how this approach can be used to probe the function of a particular region both in isolation and in context. The top row lists the top probabilistic word associates for a temporoparietal region centered on MNI x-y-z coordinates (&#x2212;56, &#x2212;52, 18). The function of this region appears ambiguous&#x002D;&#x002D;&#x002D;likely reflecting the presence of multiple overlapping neural circuits&#x002D;&#x002D;&#x002D;with the top associates including &#x2019;reading&#x2019;, &#x2019;mentalizing&#x2019;, and &#x2019;pictures&#x2019;. However, adding other coordinates strongly constrains functional interpretation. The addition of medial parietal (0, &#x2212;58, 38) and dorsomedial prefrontal (4, 54, 26) activations (middle row) produces strong overall loadings on default network-related terms such as &#x2019;self&#x2019;, &#x2019;social&#x2019;, and &#x2019;moral&#x2019;. By contrast, adding left superior temporal sulcus (&#x2212;54, &#x2212;40, 0) and left inferior frontal gyrus (&#x2212;50, 26, 6) activations (bottom row) instead produces strong loadings on language and reading-related terms (<xref ref-type="fig" rid="fig7">Fig. 7B</xref>). Thus, the GC-LDA model allows researchers to freely explore structure-function mappings in the brain in a context-specific way that recognizes that the cognitive operations supported by individual regions can contribute to multiple distinct cognitive functions.</p>
<p>Lastly, and perhaps most powerfully, the activation-to-word mapping approach can be generalized to entire whole-brain images. Given any real-valued input image, we can use the GC-LDA topics to generate a rank-ordered list of associated terms. While the output values cannot be interpreted as actual probabilities (due to the arbitrary scale of the inputs), the results are highly informative, providing a quantitative, literature-based decoding of virtually any pattern of whole-brain activity. <xref ref-type="fig" rid="fig7">Figure 7C</xref> illustrates the results for selected images, including two of the cognitive components from <xref rid="c60" ref-type="bibr">Yeo et al. (2014)</xref>, two of the BrainMap ICA components from <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref>, and two group-level HCP task contrasts (for additional results, see <xref ref-type="fig" rid="figS1">Supplementary Figures 2</xref> and 3). The decoded term list converges closely with extensive prior work; for example, a BrainMap ICA component focused largely on extrastriate visual cortex and adjacent inferotemporal areas is associated with motion, face perception, and other vision-related terms; a cognitive component from <xref rid="c60" ref-type="bibr">Yeo et al. (2014)</xref> largely co-extensive with the frontoparietal control network loads most strongly on terms like &#x201C;working memory&#x201D;, &#x201C;demands&#x201D;, and &#x201C;numerical&#x201D;, and so on.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Examples of generative text-to-image and image-to-text mapping using the trained GC-LDA model. (A) Generation of predicted whole-brain images from arbitrary text. (B) Topic-based decoding of discrete activation coordinates. (C) Topic-based decoding of continuous whole-brain images; examples selected from the cognitive components reported in <xref rid="c60" ref-type="bibr">Yeo et al. (2014)</xref>, the BrainMap ICA components reported in <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref>, and the language and emotion contrasts from the n &#x003D; 500 release of the HCP dataset. Note that the scale of the values in (B) and (C) is dependent on the input image, and should not be assigned an absolute interpretation.</p></caption>
<graphic xlink:href="059618_fig7.tif"/>
</fig>
<p>To more formally assess the performance of the decoder in an unbiased way, we used a set of NeuroVault images that were previously manually annotated using labels derived from the Cognitive Atlas ontology (<xref rid="c42" ref-type="bibr">Russell A. Poldrack et al., 2011</xref>). For each image, we used the image-to-text decoder to generate an image-specific rank-ordering of the 1,000 most common terms in the entire Neurosynth corpus. We then identified the rank, within that list, of each human-annotated Cognitive Atlas label. The median rank across all 300 images was 220&#x002D;&#x002D;an impressive value considering the open-ended nature of the task and the unfiltered nature of the NeuroVault database (i.e., there is no guarantee that the images uploaded to Neurovault actually reflect the processes they are intended to reflect&#x002D;&#x002D;a point we discuss further in the next section). By comparison, when we generated a null distribution of 1,000 permutations and computed the same median statistic, the mean and minimum values across all permutations were 442 and 384, respectively. In other words, the decoder produced rankings that were vastly more similar to expert human judgments than one would expect by chance.</p>
</sec>
<sec id="s2f">
<title><italic>Brain decoding in context</italic></title>
<p>Importantly, the above analysis provides a necessarily conservative estimate of the performance of our decoder, because in many cases, the discrepancy between human-annotated and automatically-decoded labels is bound to reflect error in the former rather than the latter. We note that human-generated annotations typically reflect researchers&#x2019; beliefs about which cognitive processes a particular experimental manipulation is <italic>supposed</italic> to influence, and do not represent ground truth. For example, the HCP Gambling Task (adapted from <xref rid="c18" ref-type="bibr">Delgado, Nystrom, Fissell, Noll, &#x0026; Fiez, 2000</xref>) was putatively designed &#x0022;to assess reward processing and decision making&#x0022; (<xref rid="c4" ref-type="bibr">Barch et al., 2013</xref>). Yet the contrast between the reward and loss conditions (depicted in <xref ref-type="fig" rid="fig8">Fig. 8</xref>) reveals robust reward-related increases in visual and frontoparietal cortices (<xref ref-type="fig" rid="fig8">Fig. 8</xref>, top). Not surprisingly, terms like &#x2019;visual&#x2019;, and &#x2019;working memory&#x2019; are at the top of the list returned by our decoder (see &#x201C;uniform prior&#x201D; results in <xref ref-type="fig" rid="fig8">Fig. 8</xref>). Does this mean that the decoder is performing poorly, and failing to recover a known ground truth? No. Given the non-canonical pattern of observed brain activity, we believe a more plausible alternative is that the manipulation in question simply had a more complex effect on cognition than the &#x0022;Reward vs. Loss&#x0022; label might lead one to expect. In other words, the &#x0022;assumption of pure insertion&#x0022;&#x002D;&#x002D;i.e., that the gain vs. loss contrast measures only cognitive processes related to reward or loss processing&#x002D;&#x002D;is probably unwarranted in this case, as in many others (<xref rid="c21" ref-type="bibr">Friston et al., 1996</xref>; <xref rid="c41" ref-type="bibr">Russell A. Poldrack, 2010</xref>).</p>
<p>The potential for discrepancy between expert human judgment and automated decoding creates an interesting conundrum: which answer should a neuroimaging researcher trust? Our view is that there is no blanket answer to this question; much depends on the particular context. Importantly, our decoding framework provides a way to quantitatively synthesize researchers&#x2019; prior beliefs with the associations learned by the GC-LDA topic model by explicitly manipulating the prior probabilities of the 200 topics. Because our model allows for bi-directional decoding (text-to-image or image-to-text), topic priors can be set by &#x201C;seeding&#x201D; the model with either a whole-brain image (or images), or a set of terms. The seeds are decoded in the normal way to update the initial uniform prior, and subsequent decoding is then based on the updated (non-uniform) priors. The approach is illustrated in <xref ref-type="fig" rid="fig8">Figure 8</xref>, which displays the results of a topic decoding analysis for two HCP task contrasts when the decoder is seeded (i) with uniform priors, (ii) with a set of reward-related terms, or (iii) with the whole-brain Neurosynth meta-analysis map for the term &#x201C;reward&#x201D; (<ext-link ext-link-type="uri" xlink:href="http://neurosynth.org/analyses/terms/reward">http://neurosynth.org/analyses/terms/reward</ext-link>). The strength of the prior is also explicitly varied.</p>
<p>The major result illustrated in <xref ref-type="fig" rid="fig8">Fig. 8</xref> is that if one is able to specify a prior belief about the experimental context, the decoder respects this prior and produces results that are, to varying degrees, biased in the direction of the prior. The decoder results are implicitly smoothed by the underlying latent topics; for instance, in the top row of <xref ref-type="fig" rid="fig8">Fig. 8</xref>, the terms &#x201C;monetary&#x201D; and &#x201C;anticipation&#x201D; appear near the top of the text-seeded results, even though they were not included in the list of seed terms. Moreover, the priors do not overwhelm the data (unless the strength parameter is set very high, as in the columns with weight &#x003D; 0.25). When the reward-related priors are applied to a map that is highly inconsistent with the prior&#x002D;&#x002D;as in the Language &#x003E; Math contrast in the bottom row of <xref ref-type="fig" rid="fig8">Fig. 8</xref>&#x002D;&#x002D;the change in decoder results is much more subtle. Thus, our decoding framework provides a quantitative way of contextualizing interpretations of fMRI data in a principled way&#x002D;&#x002D;or, alternatively, assessing the degree to which a particular interpretation is dependent on typically unstated prior beliefs.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Effects of different topic priors on decoding results. The top 10 terms produced by the decoder are displayed for two different HCP contrasts (Gain &#x003E; Loss from the Gambling task and Language &#x003E; Math from the Language task) and three different sets of topic priors (left: uniform prior; middle: priors seeded with a list of reward-related terms; right: priors seeded with the Neurosynth &#x201C;reward&#x201D; meta-analysis map). For the non-uniform priors, results are displayed for priors of differing strengths (weak &#x003D; 0.1, strong &#x003D; 0.25). Line plots above the decoder outputs illustrate the prior distribution of topics used in each analysis (for the sake of visual clarity, topics are ordered by increasing weight separately in each case).</p></caption>
<graphic xlink:href="059618_fig8.tif"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The present work significantly advances beyond previous efforts with respect to both (a) the modeling of the latent structure of neurocognition and (b) the open-ended decoding of human brain activity. With respect to the former, the GC-LDA topic model we developed introduces several innovative features to the literature. First, the simultaneous use of spatial and semantic information allows the model to learn topics that have both well-localized spatial representations, and clear semantic correlates. Approximately half of the 200 topics we extracted in a completely data-driven way closely tracked previous functional and anatomical distinctions reported in previous fMRI studies. Second, the probabilistic nature of the resulting topics stands in contrast to many previous clustering and parcellation approaches, and more accurately reflects the many-to-many nature of the relationship between cognitive constructs and neurobiological structures. Third, the GC-LDA model&#x2019;s spatial symmetry constraint enabled us to generate brain-wide, data-driven estimates of the relative hemispheric lateralization of distinct cognitive topics. Consistent with the broader literature, most topics displayed a high degree of symmetry, with notable exceptions including the strong left-lateralization of language&#x002D; and memory-related topics, and the more modest right-lateralization of response inhibition and face-related topics. Finally, the spatially compact, semantically well-defined nature of the 200 extracted topics makes the full topic set an ideal basis set for use in dimensionality reduction and image interpretation applications (as exemplified by the &#x201C;topic reconstruction&#x201D; analyses reported in the Supplementary Results and illustrated in <xref ref-type="fig" rid="figS3">Supplementary Figures 4-7</xref>).</p>
<p>From the standpoint of efforts to decode whole-brain activation patterns, our results also advances beyond previous work. First, by simultaneously constraining topics both spatially and semantically, the GC-LDA model generates topics designed to maximize the correspondence between cognition and brain activity. By contrast, previous open-ended decoding approaches have typically relied on predefined cognitive ontologies (<xref rid="c12" ref-type="bibr">Bzdok et al., 2013</xref>; <xref rid="c52" ref-type="bibr">Smith et al., 2009</xref>) or terms (<xref rid="c2" ref-type="bibr">Andrews-Hanna et al., 2014</xref>; <xref rid="c14" ref-type="bibr">Chang et al., 2012</xref>), which are unlikely to collectively maximize the parsimony of derived brain-cognition mappings. Second, the generative nature of our decoding framework facilitates bidirectional decoding, enabling researchers not only to identify likely functional correlates of whole-brain activity patterns or sets of discrete activations, but also to project flexible text descriptions of tasks or processes into image space.</p>
<p>Third, our Bayesian approach allows researchers to formally specify priors on the GC-LDA topics, providing a powerful means of contextualizing interpretations and accounting for prior expectations and beliefs. We illustrate how a researcher can flexibly &#x0022;seed&#x0022; a decoding analysis using cognitive terms and/or whole-brain maps, thus ensuring that the decoder respects prior information about the experimental context. Current decoding approaches are forced to rely on unstated and inflexible assumptions about the base rates associated with different cognitive processes or tasks&#x002D;&#x002D;a limitation that makes it difficult to know how much trust to place in a particular interpretation of one&#x2019;s results. While our Bayesian updating approach currently has important limitations (see below), it represents an important step towards the goal of being able to decode arbitrary patterns of whole-brain activity in a way that formally synthesizes prior knowledge with observed results.</p>
<p>Naturally, the present work remains constrained by a number of important limitations. First, the specificity of the extracted topics is limited (both spatially and semantically) by the quality of the meta-analytic data in the automatically-extracted Neurosynth database (for discussion, see <xref rid="c58" ref-type="bibr">Yarkoni et al., 2011</xref>). In theory, greater specificity might be achievable using human-curated meta-analytic databases (e.g., BrainMap; <xref rid="c30" ref-type="bibr">Laird et al., 2005</xref>) or publicly deposited whole-brain images (<xref rid="c22" ref-type="bibr">Gorgolewski et al., 2015</xref>; <xref rid="c50" ref-type="bibr">Salimi-Khorshidi, Smith, Keltner, Wager, &#x0026; Nichols, 2009</xref>). However, such resources are currently much smaller than Neurosynth&#x002D;&#x002D;implying a significant decrement to the sensitivity of our data-intensive modeling approach&#x002D;&#x002D;and, in the case of BrainMap, have usage restrictions that limit reproducibility and transparency. Nevertheless, it is clear that the present topics already converge closely with prior literature. Moreover, the integration of our topics with the public NeuroVault repository ensures that researchers will always be able to apply the most current topic sets to their data at the push of a button.</p>
<p>Second, the output of the GC-LDA model is necessarily data&#x002D; and context-dependent. While the topics produced by the model generally have parsimonious interpretations that accord well with previous findings, they should be treated as a useful, human-comprehensible approximation of the true nomological network of neurocognition, and not as a direct window into reality. For the sake of analytical tractability, our model assumes a one-to-one mapping between semantic representations and brain regions, whereas the underlying reality almost certainly involves enormously complex many-to-many mappings. Similarly, re-running the GC-LDA model on different input data, with a different number of topics, or with different analysis parameters would necessarily produce somewhat different results. Of course, this concern applies equally to other large-scale data-driven approaches. We highlight it here simply because we would not want researchers to reify the topics we introduce here as if they are uniquely &#x201C;real&#x201D;. In our view, the overriding evaluation metric for any novel parcellation or clustering technique is whether it is scientifically productive over the long term (cf. Russell A. <xref rid="c46" ref-type="bibr">Poldrack &#x0026; Yarkoni, 2015</xref>). Wth that caveat in mind, we believe that the framework introduced here strikes an excellent balance between interpretability, flexibility, and ease of use, and provides an important complement to previous data-driven approaches.</p>
<p>Lastly, while our decoding framework is formally Bayesian, the outputs it generates cannot typically be interpreted as probabilities, because the input images researchers conventionally seek to decode are mostly real-valued t or z maps whose meaning can vary dramatically. While this restriction limits the utility of our framework, it is, at present, unavoidable. Providing meaningful absolute estimates of the likelihood of different cognitive processes given observed brain activity would require either (a) that researchers converge on a common standard for representing observed results within a probabilistic framework (e.g., reporting the probability of subjects displaying supra-threshold activation in every voxel), or (b) re-training the GC-LDA model and associated decoding framework on a very large corpus of whole-brain images comparable to those that researchers seek to decode, rather than on a coordinate-based meta-analytic database. Of these two alternatives, we view the latter as the more feasible and productive strategy. We thus believe that the best hope for truly open-ended, fully probabilistic brain decoding lies in the widespread communal adoption of whole-brain images repositories like NeuroVault.org. We are optimistic that in the relatively near future, we will be able to use the topic modeling and decoding methods introduced here to produce highly informative, context-sensitive predictions about the mental processes implied by arbitrary patterns of whole-brain activity.</p>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title><italic>Datasets</italic></title>
<p>All data used to train the GC-LDA topic model came from the Neurosynth database (<xref rid="c58" ref-type="bibr">Yarkoni et al., 2011</xref>; neurosynth.org). The database contains activation coordinates that were automatically extracted from 11,409 published fMRI studies, as well as associated semantic terms extracted from the corresponding article abstracts. Further details have been reported in previous studies (<xref rid="c14" ref-type="bibr">Chang et al., 2012</xref>; <xref rid="c38" ref-type="bibr">Pauli, O&#x2019;Reilly, Yarkoni, &#x0026; Wager, 2016</xref>; <xref rid="c45" ref-type="bibr">Russell A. Poldrack et al., 2012</xref>; <xref rid="c58" ref-type="bibr">Yarkoni et al., 2011</xref>).</p>
<p>For decoding analyses, we used whole-brain maps obtained from several sources, including: (1) <italic>The 500-subject release of the Human Connectome Project (<xref rid="c56" ref-type="bibr">Van Essen et al., 2013</xref>)</italic>. We focused on single-subject whole-brain beta maps from several functional tasks. In all cases, we used experimental contrasts predefined by the HCP research team and included in the &#x201C;preprocessed&#x201D; data release (i.e., we did not preprocess or alter the provided contrast images in any way). Studied contrasts included the comparison between faces and shapes in the Emotion task; between language and math conditions in the Language-Math condition; between social and non-social motion in the Social Cognition task. (2) <italic>NeuroVault.org maps</italic>. We downloaded two sets of maps from the NeuroVault whole-brain image repository: (i) a completely random set of 100 images (subject to the constraint that each image had to come from a different image collection, to maximize independence of images), and (ii) a random set of 300 NeuroVault images that had been previously manually annotated using the Cognitive Atlas ontology for a completely different purpose (Sochat et al., in preparation). (3) <italic>BrainMap ICA and Yeo etal. author-topic &#x201C;cognitive component&#x201D; maps</italic>. We obtained these two sets of maps&#x002D;&#x002D;reported in <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref> and <xref rid="c60" ref-type="bibr">Yeo et al. (2014)</xref>, respectively&#x002D;&#x002D;via the web.</p>
</sec>
<sec id="s4b">
<title><italic>Topic modeling</italic></title>
<p>A high-level schematic of the model we employ is presented in <xref ref-type="fig" rid="fig2">Figure 2</xref>; the model is presented using graphical model plate notation representation in <xref ref-type="fig" rid="fig8">Figure 8</xref>. We begin with the Neurosynth dataset, which contains data extracted from 11,406 published fMRI articles. Each of the 11,406 document consists of (1) a set of unigrams and bigrams of words extracted from the publication&#x2019;s abstract, describing what each experiment was about, and (2) the set of peak-activation coordinates that were reported in HTML tables within the paper (for data extraction details, see <xref rid="c58" ref-type="bibr">Yarkoni et al, 2011</xref>). The model learns a set of <italic>T topics</italic>, where each topic is associated with some spatial distribution (e.g., a 3-dimensional Gaussian distribution with parameters <italic>&#x03BC;<sub>t</sub></italic> and <italic>&#x03C3;<sub>t</sub></italic>), and a multinomial distribution <italic>&#x03D5;<sub>t</sub></italic> over all of the unique types of linguistic features (consisting of unigrams and bigrams) in the corpus. This model is a generative model, meaning that it describes a process that can generate approximations of the observed data (the linguistic features and activation coordinates) via a set of latent (unobserved) topics.</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Graphical model of the full GC-LDA model.</p></caption>
<graphic xlink:href="059618_fig9.tif"/>
</fig>
<p>The model assumes that each document <italic>d</italic> is generated by first sampling a multinomial probability distribution <italic>&#x03B8;<sub>d</sub></italic> over topics from a Dirichlet prior distribution. Then, to generate each activation peak <italic>x</italic> in the document, the document first samples a topic <italic>y</italic> from its distribution over topics <italic>&#x03B8;<sub>d</sub></italic> and then samples a peak activation at location <italic>x</italic> from the spatial distribution associated with topic <italic>y</italic>. To generate each word in the document, a topic <italic>z</italic> is sampled proportional to the number of times that the document sampled activations from each topic, and then a word token is then sampled from topic <italic>z</italic>&#x2019;s probability distribution over word types <italic>&#x03D5;<sub>z</sub></italic>. To illustrate this process, consider the example Document 1 shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, which we can imagine describes an experiment measuring reaction times on a word-identification task. The model assumes that neural activation peaks reported in this experiment will be sequentially sampled from the spatial distributions associated with topics 1 and 2 (which relate to language processes and motor processes, respectively). The model then assumes that the words in the document&#x002D;&#x002D;used to describe the experiment and its results&#x002D;&#x002D;will be sampled from the linguistic distributions associated with topics 1 and 2, proportional to the number of times activation peaks were sampled from each of these topics.</p>
<p>Because the model enforces a correspondence between the frequency with which documents sample their words and activations from each topic, the model ensures that over the document corpus, the linguistic features associated with each topic will be closely related to the topic&#x2019;s spatial distribution over activations. More specifically, the model will identify a topic-specific distribution over neural activations that tends to co-occur with the topic&#x2019;s linguistic features across the corpus.</p>
<p>The general framework of the GC-LDA model allows the experimenter to choose any valid probability distribution for the spatial component of each topic. The results displayed in <xref ref-type="fig" rid="fig3">Figures 3 - 8</xref> correspond to a GC-LDA model in which each topic&#x2019;s spatial distribution is captured by a mixture of two Gaussian distributions that have been constrained to be symmetric about the x-axis. In our experiments, we evaluated several variations of the GC-LDA model using different probability distributions. We started with each topic having a single multidimensional Gaussian spatial distribution. We then replaced the single Gaussian distribution with a Gaussian Mixture distribution containing two components (i.e. subregions). In a further variant of this model (pictured in <xref ref-type="fig" rid="fig1">Figure 1</xref>), we constrained the spatial arrangement of the two component distributions of the Gaussian mixture distribution, such that their means were symmetrical with respect to the x-axis of the brain (i.e., so that for each topic, the spatial distribution would consist of one component region in the left hemisphere and a second component region in the right hemisphere). This allowed us to include an anatomical constraint based on known features of functional neuroanatomy&#x2014;specifically the fact that there is generally a bilateral symmetry with respect to neural functionality. It further provided us with an automated way of measuring the lateral asymmetry of different cognitive functions (given by each topic&#x2019;s probability of drawing an activation from its different components).</p>
<p>Given a formalized generative process for any of these models, we can use Bayesian inference methods to learn all of the latent (unobserved) parameters of this model from the observed data (see (<xref rid="c49" ref-type="bibr">Rubin, T. N., Koyejo, O., Jones, M. N., &#x0026; Yarkoni, T., Submitted</xref>), for details). Specifically, the model learns a set of <italic>T</italic> topics, where each topic has an associated spatial probability distribution over the coordinates in the brain, as well as a multinomial distribution over linguistic features. The model additionally learns the topic mixture weights for each document.</p>
</sec>
<sec id="s4c">
<title><italic>Text-to-image and image-to-text decoding</italic></title>
<p>For text-to-image decoding (<xref ref-type="fig" rid="fig7">Fig. 7 A</xref>), we first compute a Topic (<italic>T</italic>) by word-type (<italic>W</italic>) matrix <italic>P<sub>W&#x00D7;T</sub></italic> matrix of conditional probabilities, where cell <italic>P<sub>ij</sub></italic> is the probability <italic>P(t &#x003D; i&#x007C;w &#x003D; j)</italic> that the model assigns word type <italic>w</italic> from the text input to the <italic>i<sup>th</sup></italic> topic. This matrix is computed, using Bayes&#x2019; rule, from the topic&#x2019;s probability distributions over word types <italic>&#x03A6;<sub>W&#x00D7;T</sub></italic> in the trained GC-LDA model, as follows:
<disp-formula id="ueqn1"><alternatives><graphic xlink:href="059618_ueqn1.gif"/></alternatives></disp-formula>
assuming a uniform prior probability of each topic, <italic>p(t)</italic>. We then obtain a vector of topic weights <italic>&#x03C4;</italic> for the entire input by summing over the all word tokens <italic>w</italic> in the input; i.e.,
<disp-formula id="ueqn2"><alternatives><graphic xlink:href="059618_ueqn2.gif"/></alternatives></disp-formula>
</p>
<p>Lastly, we multiply this vector of topic weights by the topic x voxel matrix <italic>A<sub>T&#x00D7;V</sub></italic> where cell <italic>A<sub>ij</sub></italic> reflects the smoothed conditional probability <italic>p(v &#x003D; j&#x007C;t &#x003D; i)</italic> that the model samples an activation at brain voxel <italic>j</italic> (of <italic>V</italic> total voxels) from topic <italic>i</italic>. The rows of this matrix are (smoothed versions of) the images displayed in <xref ref-type="fig" rid="fig3">Figure 3</xref>. The resulting (vectorized) whole-brain image is thus given by the product <italic>&#x03C4;A</italic>.</p>
<p>Note that the resulting values cannot be interpreted as probabilities, because we deliberately sum over words in the input rather than computing the joint probability. The reason for this is that, while the latter approach is technically feasible, and typically produces very similar results for short inputs, it produces unstable results when the input sentence exceeds a few words in length (because the sparse nature of the word-to-topic mapping results in the compounding of many very small probabilities).</p>
<p>For discrete coordinate-to-text decoding (<xref ref-type="fig" rid="fig7">Fig. 7B</xref>), we repeat the above process, but proceed in the opposite direction. That is, we first compute a Topic &#x00D7; Voxel matrix <italic>P<sub>T&#x00D7;V</sub></italic>, where cell <italic>A<sub>ij</sub></italic> reflects the conditional probability <italic>p(t &#x003D; i&#x007C;v &#x003D; j)</italic> that the model assigns the the activation at voxel <italic>j</italic> in the input to the <italic>i<sup>th</sup></italic> topic. This matrix is computed from the trained GC-LDA model by first computing the probability of sampling of each voxel from each topic (given each topic&#x2019;s spatial distribution), and then renormalizing these probabilities using Bayes&#x2019; rule, under the same assumption used for text-to-image decoding of a uniform prior probability of each topic <italic>p(t)</italic>. We then sum over all of the input activations to obtain a vector of topic weights <italic>&#x03C4;<sub>t</sub></italic> for the given input. Lastly, we project the topic weights into the word space by multiplying the vector of topic weights <italic>&#x03C4;<sub>t</sub></italic> by the topic x word matrix <italic>&#x03A6;<sub>W&#x00D7;T</sub></italic>, where cell <italic>&#x03A6;<sub>ij</sub></italic>reflects the conditional probability <italic>p(w &#x003D; i&#x007C;t &#x003D; j)</italic> that the model samples the <italic>i<sup>th</sup></italic> word type from topic <italic>j</italic>.</p>
<p>To decode text from continuous whole-brain images (<xref ref-type="fig" rid="fig7">Fig. 7C</xref>), a slightly different approach is required. Although whole-brain decoding superficially resembles the decoding of discrete coordinates, the fact that the input images are real-valued and have arbitrary scaling precludes a true probabilistic treatment. Instead, we adopt a modified approach that weights the conditional probability matrix <italic>P</italic> by the similarity of the input image to each of the GC-LDA topic maps. We compute a vector of topic weights <italic>&#x03C4;</italic> as:
<disp-formula id="ueqn3"><alternatives><graphic xlink:href="059618_ueqn3.gif"/></alternatives></disp-formula>
where <italic>P<sub>T&#x00D7;V</sub></italic> is the topic &#x00D7; voxel matrix of conditional probabilities of assigning an activation at voxel <italic>v</italic> to topic <italic>t</italic>, and <italic>I<sub>v</sub></italic> is the vectorized whole-brain input image. We then project the topic weights into word space in the same way as for the discrete coordinates (i.e., by computing <italic>&#x03C4;</italic> &#x00B7; <italic>&#x03A6;</italic>). The scale of the resulting values is arbitrary, and depends on the input image, but the rank-ordering of terms is instructive and typically converges closely with human-annotated labels.</p>
</sec>
<sec id="s4d">
<title><italic>Contextual decoding via topic &#x201C;seeding&#x201D;</italic></title>
<p>Specifying priors on the GC-LDA topics can in principle be accomplished directly, by simply setting the desired prior probabilities on topics <italic>P(t)</italic> when computing the matrices <italic>P<sub>T&#x00D7;V</sub></italic> and <italic>P<sub>W&#x00D7;T</sub></italic>. The decoder results will then directly reflect the adjustment in both the text-to-image and image-to-text directions. However, researchers are unlikely to have strong intuitions about the relative base rates of the latent topics themselves. More commonly, they will instead wish to update the priors indirectly, based on a more intuitive expression of the experimental context or prior belief. This can be accomplished by &#x201C;seeding&#x201D; the priors with image and/or text inputs. In this case, the procedure can be thought of as a two-step application of the decoding methods described above. On the first pass, the input image or text is used to estimate values of <italic>&#x03C4;</italic> (no further output is generated). On the second pass, the <italic>&#x03C4;</italic> computed during the first pass is used as an informative prior <italic>p(t)</italic> in computing matrix <italic>P<sub>T&#x00D7;V</sub></italic> or <italic>P<sub>W&#x00D7;T</sub></italic> as described previously, and this updated matrix is applied to the actual image or text to be decoded. This procedure can repeat an indefinite number of times, as in a typical Bayesian context (i.e., the posterior <italic>&#x03C4;</italic> probabilities become the priors for the next decoding application).</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The authors wish to thank Vanessa Sochat for contributing the manual NeuroVault annotations. This work was supported by National Institute Institute of Mental Health (NIMH) award R01MH096906 to TY, RAP, and MNJ.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Essick</surname>, <given-names>G. K.</given-names></string-name>, &#x0026; <string-name><surname>Siegel</surname>, <given-names>R. M.</given-names></string-name> (<year>1985</year>). <article-title>Encoding of spatial location by posterior parietal neurons</article-title>. <source>Science</source>, <volume>230</volume>(<issue>4724</issue>), <fpage>456</fpage>&#x2013;<lpage>458</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Andrews-Hanna</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name> (<year>2014</year>). <article-title>Contributions of episodic retrieval and mentalizing to autobiographical thought: evidence from functional neuroimaging, resting-state connectivity, and fMRI meta-analyses</article-title>. <source>Neuroimage</source>, <volume>91</volume>, <fpage>324</fpage>&#x2013;<lpage>335</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Aron</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Robbins</surname>, <given-names>T. W.</given-names></string-name>, &#x0026; <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2004</year>). <article-title>Inhibition and the right inferior frontal cortex</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>8</volume>(<issue>4</issue>), <fpage>170</fpage>&#x2013;<lpage>177</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Harms</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Corbetta</surname>, <given-names>M.</given-names></string-name>, &#x2026; <collab>WU-Minn HCP Consortium</collab>. (<year>2013</year>). <article-title>Function in the human connectome: task-fMRI and individual differences in behavior</article-title>. <source>Neuroimage</source>, <volume>80</volume>, <fpage>169</fpage>&#x2013;<lpage>189</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bellec</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Rosa-Neto</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Lyttelton</surname>, <given-names>O. C.</given-names></string-name>, <string-name><surname>Benali</surname>, <given-names>H.</given-names></string-name>, &#x0026; <string-name><surname>Evans</surname>, <given-names>A. C.</given-names></string-name> (<year>2010</year>). <article-title>Multi-level bootstrap analysis of stable clusters in resting-state fMRI</article-title>. <source>Neuroimage</source>, <volume>51</volume>(<issue>3</issue>), <fpage>1126</fpage>&#x2013;<lpage>1139</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Blei</surname>, <given-names>D. M.</given-names></string-name> (<year>2012</year>). <article-title>Probabilistic topic models</article-title>. <source>Communications of the ACM</source>, <volume>55</volume>(<issue>4</issue>), <fpage>77</fpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="confproc"><string-name><surname>Blei</surname>, <given-names>D. M.</given-names></string-name>, &#x0026; <string-name><surname>Jordan</surname>, <given-names>M. I.</given-names></string-name> (<conf-date>2003</conf-date>). <article-title>Modeling annotated data</article-title>. In <conf-name>Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval - SIGIR &#x2019;03</conf-name>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1145/860435.860460">http://doi.org/10.1145/860435.860460</ext-link></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Blei</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Ng</surname>, <given-names>A. Y.</given-names></string-name>, &#x0026; <string-name><surname>Jordan</surname>, <given-names>M. I.</given-names></string-name> (<year>2003</year>). <article-title>Latent Dirichlet Allocation</article-title>. <source>Journal of Machine Learning Research: JMLR</source>, <volume>3</volume>(<issue>4-5</issue>), <fpage>993</fpage>&#x2013;<lpage>1022</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Blumensath</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Jbabdi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, &#x0026; <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name> (<year>2013</year>). <article-title>Spatially constrained hierarchical parcellation of the brain with resting-state fMRI</article-title>. <source>Neuroimage</source>, <volume>76</volume>, <fpage>313</fpage>&#x2013;<lpage>324</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Buhle</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Silvers</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Lopez</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Onyemekwu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Kober</surname>, <given-names>H.</given-names></string-name>, &#x2026; <string-name><surname>Ochsner</surname>, <given-names>K. N.</given-names></string-name> (<year>2014</year>). <article-title>Cognitive reappraisal of emotion: a meta-analysis of human neuroimaging studies</article-title>. <source>Cerebral Cortex</source>, <volume>24</volume>(<issue>11</issue>), <fpage>2981</fpage>&#x2013;<lpage>2990</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Bushnell</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Goldberg</surname>, <given-names>M. E.</given-names></string-name>, &#x0026; <string-name><surname>Robinson</surname>, <given-names>D. L.</given-names></string-name> (<year>1981</year>). <article-title>Behavioral enhancement of visual responses in monkey cerebral cortex. I. Modulation in posterior parietal cortex related to selective visual attention</article-title>. <source>Journal of Neurophysiology</source>, <volume>46</volume>(<issue>4</issue>), <fpage>755</fpage>&#x2013;<lpage>772</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Bzdok</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Langner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Schilbach</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Jakobs</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Roski</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Caspers</surname>, <given-names>S.</given-names></string-name>, &#x2026; <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name> (<year>2013</year>). <article-title>Characterization of the temporo-parietal junction by combining data-driven parcellation, complementary connectivity analyses, and functional decoding</article-title>. <source>Neuroimage</source>, <volume>81</volume>, <fpage>381</fpage>&#x2013;<lpage>392</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="confproc"><string-name><surname>Cao</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Liangliang</surname>, <given-names>C.</given-names></string-name>, &#x0026; <string-name><surname>Li</surname>, <given-names>F.-F.</given-names></string-name> (<conf-date>2007</conf-date>). <article-title>Spatially Coherent Latent Topic Model for Concurrent Segmentation and Classification of Objects and Scenes</article-title>. In <conf-name>2007 IEEE 11th International Conference on Computer Vision</conf-name>, <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1109/iccv.2007.4408965">http://doi.org/10.1109/iccv.2007.4408965</ext-link></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Chang</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Khaw</surname>, <given-names>M. W.</given-names></string-name>, &#x0026; <string-name><surname>Sanfey</surname>, <given-names>A. G.</given-names></string-name> (<year>2012</year>). <article-title>Decoding the Role of the Insula in Human Cognition: Functional Parcellation and Large-Scale Reverse Inference</article-title>. <source>Cerebral Cortex</source>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1093/cercor/bhs065">http://doi.org/10.1093/cercor/bhs065</ext-link></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>D. D.</given-names></string-name>, &#x0026; <string-name><surname>Savoy</surname>, <given-names>R. L.</given-names></string-name> (<year>2003</year>). <article-title>Functional magnetic resonance imaging (fMRI)&#x0022;brain reading&#x0022;: detecting and classifying distributed patterns of fMRI activity in human visual cortex</article-title>. <source>Neuroimage</source>, <volume>19</volume>(<issue>2</issue>), <fpage>261</fpage>&#x2013;<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Craddock</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>James</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Holtzheimer</surname>, <given-names>P. E.</given-names></string-name>, 3rd, <string-name><surname>Hu</surname>, <given-names>X. P.</given-names></string-name>, &#x0026; <string-name><surname>Mayberg</surname>, <given-names>H. S.</given-names></string-name> (<year>2012</year>). <article-title>A whole brain fMRI atlas generated via spatially constrained spectral clustering</article-title>. <source>Human Brain Mapping</source>, <volume>33</volume>(<issue>8</issue>), <fpage>1914</fpage>&#x2013;<lpage>1928</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Stanislas</surname>, <given-names>D.</given-names></string-name>, &#x0026; <string-name><surname>Laurent</surname>, <given-names>C.</given-names></string-name> (<year>2011</year>). <article-title>The unique role of the visual word form area in reading</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>15</volume>(<issue>6</issue>), <fpage>254</fpage>&#x2013;<lpage>262</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Delgado</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Nystrom</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Fissell</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Noll</surname>, <given-names>D. C.</given-names></string-name>, &#x0026; <string-name><surname>Fiez</surname>, <given-names>J. A.</given-names></string-name> (<year>2000</year>). <article-title>Tracking the hemodynamic responses to reward and punishment in the striatum</article-title>. <source>Journal of Neurophysiology</source>, <volume>84</volume>(<issue>6</issue>), <fpage>3072</fpage>&#x2013;<lpage>3077</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Dosenbach</surname>, <given-names>N. U.</given-names></string-name>, <string-name><surname>Visscher</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Palmer</surname>, <given-names>E. D.</given-names></string-name>, <string-name><surname>Miezin</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Wenger</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Kang</surname>, <given-names>H. C.</given-names></string-name>, &#x2026; <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name> (<year>2006</year>). <article-title>A core system for the implementation of task sets</article-title>. <source>Neuron</source>, <volume>50</volume>(<issue>5</issue>), <fpage>799</fpage>&#x2013;<lpage>812</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> (<year>2010</year>). <article-title>The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>(<issue>4</issue>), <fpage>172</fpage>&#x2013;<lpage>179</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Price</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Fletcher</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Frackowiak</surname>, <given-names>R. S.</given-names></string-name>, &#x0026; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>1996</year>). <article-title>The trouble with cognitive subtraction</article-title>. <source>Neuroimage</source>, <volume>4</volume>(<issue>2</issue>), <fpage>97</fpage>&#x2013;<lpage>104</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rivera</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Schwarz</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Maumet</surname>, <given-names>C.</given-names></string-name>, &#x2026; <string-name><surname>Margulies</surname>, <given-names>D. S.</given-names></string-name> (<year>2015</year>). <article-title>NeuroVault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>9</volume>, <fpage>8</fpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="confproc"><string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &#x0026; <string-name><surname>Steyvers</surname>, <given-names>M.</given-names></string-name> (<conf-date>2004</conf-date>). <article-title>Finding scientific topics</article-title>. <conf-name>Proceedings of the National Academy of Sciences</conf-name>, <volume>707</volume>(Supplement <issue>1</issue>), <fpage>5228</fpage>&#x2013;<lpage>5235</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name>, <string-name><surname>Connolly</surname>, <given-names>A. C.</given-names></string-name>, &#x0026; <string-name><surname>Guntupalli</surname>, <given-names>J. S.</given-names></string-name> (<year>2014</year>). <article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title>. <source>Annual Review of Neuroscience</source>, <volume>37</volume>, <fpage>435</fpage>&#x2013;<lpage>456</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Haynes</surname>, <given-names>J.-D.</given-names></string-name>, &#x0026; <string-name><surname>Rees</surname>, <given-names>G.</given-names></string-name> (<year>2006</year>). <article-title>Decoding mental states from brain activity in humans. Nature Reviews</article-title>. <source>Neuroscience</source>, <volume>7</volume>(<issue>7</issue>), <fpage>523</fpage>&#x2013;<lpage>534</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>McDermott</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Chun</surname>, <given-names>M. M.</given-names></string-name> (<year>1997</year>). <article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title>. <source>Journal of Neuroscience</source>, <volume>17</volume>(<issue>11</issue>), <fpage>4302</fpage>&#x2013;<lpage>4311</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Kohn</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Scheller</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Laird</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>P. T.</given-names></string-name>, &#x0026; <string-name><surname>Habel</surname>, <given-names>U.</given-names></string-name> (<year>2014</year>). <article-title>Neural network of cognitive emotion regulation-an ALE meta-analysis and MACM analysis</article-title>. <source>Neuroimage</source>, <volume>87</volume>, <fpage>345</fpage>&#x2013;<lpage>355</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &#x0026; <string-name><surname>Kievit</surname>, <given-names>R. A.</given-names></string-name> (<year>2013</year>). <article-title>Representational geometry: integrating cognition, computation, and the brain</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>17</volume>(<issue>8</issue>), <fpage>401</fpage>&#x2013;<lpage>412</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Laird</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Uecker</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Ray</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Saenz</surname>, <given-names>J. J.</given-names></string-name>, &#x2026; <string-name><surname>Fox</surname>, <given-names>P. T.</given-names></string-name> (<year>2011</year>). <article-title>The BrainMap strategy for standardization, sharing, and meta-analysis of neuroimaging data</article-title>. <source>BMC Research Notes</source>, <volume>4</volume>(<issue>1</issue>), <fpage>349</fpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Laird</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Lancaster</surname>, <given-names>J. L.</given-names></string-name>, &#x0026; <string-name><surname>Fox</surname>, <given-names>P. T.</given-names></string-name> (<year>2005</year>). <article-title>BrainMap: the social evolution of a human brain mapping database</article-title>. <source>Neuroinformatics</source>, <volume>3</volume>(<issue>1</issue>), <fpage>65</fpage>&#x2013;<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>LeDoux</surname>, <given-names>J.</given-names></string-name> (<year>2003</year>). <article-title>The emotional brain, fear, and the amygdala</article-title>. <source>Cellular and Molecular Neurobiology</source>, <volume>23</volume>(<issue>4-5</issue>), <fpage>727</fpage>&#x2013;<lpage>738</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Lindquist</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Kober</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Bliss-Moreau</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Barrett</surname>, <given-names>L. F.</given-names></string-name> (<year>2012</year>). <article-title>The brain basis of emotion: a meta-analytic review</article-title>. <source>The Behavioral and Brain Sciences</source>, <volume>35</volume>(<issue>3</issue>), <fpage>121</fpage>&#x2013;<lpage>143</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="book"><string-name><surname>Mcauliffe</surname>, <given-names>J. D.</given-names></string-name>, &#x0026; <string-name><surname>Blei</surname>, <given-names>D. M.</given-names></string-name> (<year>2008</year>). <chapter-title>Supervised Topic Models</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>J. C.</given-names> <surname>Platt</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Koller</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Singer</surname></string-name>, &#x0026; <string-name><given-names>S. T.</given-names> <surname>Roweis</surname></string-name> (Eds.)</person-group>, <source>Advances in Neural Information Processing Systems</source> <volume>20</volume> (pp. <fpage>121</fpage>&#x2013;<lpage>128</lpage>). <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Mitchell</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Hutchinson</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Niculescu</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Just</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Newman</surname>, <given-names>S.</given-names></string-name> (<year>2004</year>). <article-title>Learning to decode cognitive states from brain images</article-title>. <source>Machine Learning</source>, <volume>57</volume>(<issue>1</issue>), <fpage>145</fpage>&#x2013;<lpage>175</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Mitchell</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Shinkareva</surname>, <given-names>S. V.</given-names></string-name>, <string-name><surname>Carlson</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Malave</surname>, <given-names>V. L.</given-names></string-name>, <string-name><surname>Mason</surname>, <given-names>R. A.</given-names></string-name>, &#x0026; <string-name><surname>Just</surname>, <given-names>M. A.</given-names></string-name> (<year>2008</year>). <article-title>Predicting human brain activity associated with the meanings of nouns</article-title>. <source>Science</source>, <volume>320</volume>(<issue>5880</issue>), <fpage>1191</fpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Mountcastle</surname>, <given-names>V. B.</given-names></string-name>, <string-name><surname>Lynch</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Georgopoulos</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sakata</surname>, <given-names>H.</given-names></string-name>, &#x0026; <string-name><surname>Acuna</surname>, <given-names>C.</given-names></string-name> (<year>1975</year>). <article-title>Posterior parietal association cortex of the monkey: command functions for operations within extrapersonal space</article-title>. <source>Journal of Neurophysiology</source>, <volume>38</volume>(<issue>4</issue>), <fpage>871</fpage>&#x2013;<lpage>908</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Nelson</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Dosenbach</surname>, <given-names>N. U. F.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Wheeler</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, &#x0026; <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name> (<year>2010</year>). <article-title>Role of the anterior insula in task-level control and focal attention</article-title>. <source>Brain Structure &#x0026; Function</source>, <fpage>1</fpage>&#x2013;<lpage>12</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="confproc"><string-name><surname>Pauli</surname>, <given-names>W. M.</given-names></string-name>, <string-name><surname>O&#x2019;Reilly</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name>, &#x0026; <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name> (<conf-date>2016</conf-date>). <article-title>Regional specialization within the human striatum for diverse psychological functions</article-title>. <conf-name>Proceedings of the National Academy of Sciences of the United States of America</conf-name>, <volume>113</volume>(<issue>7</issue>), <fpage>1907</fpage>&#x2013;<lpage>1912</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Phelps</surname>, <given-names>E. A.</given-names></string-name> (<year>2006</year>). <article-title>Emotion and cognition: insights from studies of the human amygdala</article-title>. <source>Annual Review of Psychology</source>, <volume>57</volume>, <fpage>27</fpage>&#x2013;<lpage>53</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2006</year>). <article-title>Can cognitive processes be inferred from neuroimaging data</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>10</volume>(<issue>2</issue>), <fpage>59</fpage>&#x2013;<lpage>63</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="book"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2010</year>). <chapter-title>Subtraction and Beyond: The Logic of Experimental Designs for Neuroimaging</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>S. J.</given-names> <surname>Hanson</surname></string-name> &#x0026; <string-name><given-names>M.</given-names> <surname>Bunzl</surname></string-name> (Eds.)</person-group>, <source>Foundational Issues in Human Brain Mapping</source> (pp. <fpage>147</fpage>&#x2013;<lpage>160</lpage>). <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> (<year>2011</year>). <article-title>Inferring Mental States from Neuroimaging Data: From Reverse Inference to Large-Scale Decoding</article-title>. <source>Neuron</source>, <volume>72</volume>(<issue>5</issue>), <fpage>692</fpage>&#x2013;<lpage>697</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Halchenko</surname>, <given-names>Y. O.</given-names></string-name>, &#x0026; <string-name><surname>Hanson</surname>, <given-names>S. J.</given-names></string-name> (<year>2009</year>). <article-title>Decoding the large-scale structure of brain function by classifying mental states across individuals</article-title>. <source>Psychological Science</source>, <volume>20</volume>(<issue>11</issue>), <fpage>1364</fpage>&#x2013;<lpage>1372</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Kittur</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kalar</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Seppa</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gil</surname>, <given-names>Y.</given-names></string-name>, &#x2026; <string-name><surname>Bilder</surname>, <given-names>R. M.</given-names></string-name> (<year>2011</year>). <article-title>The Cognitive Atlas: Toward a Knowledge Foundation for Cognitive Neuroscience</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>5</volume>(<issue>September</issue>), <fpage>11</fpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Schonberg</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kalar</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Barman</surname>, <given-names>B.</given-names></string-name>, &#x0026; <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name> (<year>2012</year>). <article-title>Discovering relations between mind, brain, and mental disorders using topic mapping</article-title>. <source>PLoS Computational Biology</source>, <volume>8</volume>(<issue>10</issue>), <fpage>e1002707</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, &#x0026; <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name> (<year>2015</year>). <article-title>From Brain Maps to Cognitive Ontologies: Informatics and the Search for Mental Structure</article-title>. <source>Annual Review of Psychology</source>. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1146/annurev-psych-122414-033729">http://doi.org/10.1146/annurev-psych-122414-033729</ext-link></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Wig</surname>, <given-names>G. S.</given-names></string-name>, <string-name><surname>Barnes</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Church</surname>, <given-names>J. A.</given-names></string-name>, &#x2026; <string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name> (<year>2011</year>). <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source>, <volume>72</volume>(<issue>4</issue>), <fpage>665</fpage>&#x2013;<lpage>678</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Rubin</surname>, <given-names>T. N.</given-names></string-name>, <string-name><surname>America</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Padhraic</surname>, <given-names>S.</given-names></string-name>, &#x0026; <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name> (<year>2011</year>). <article-title>Statistical topic models for multi-label document classification</article-title>. <source>Machine Learning</source>, <volume>88</volume>(<issue>1-2</issue>), <fpage>157</fpage>&#x2013;<lpage>208</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Rubin</surname>, <given-names>T. N.</given-names></string-name>, <string-name><surname>Koyejo</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>M. N.</given-names></string-name>, &#x0026; <string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name> <article-title>(Submitted)</article-title>. <source>Generalized Correspondence-LDA Models (GC-LDA) for Identifying Functional Regions in the Brain</source>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Salimi-Khorshidi</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Keltner</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, &#x0026; <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name> (<year>2009</year>). <article-title>Meta-analysis of neuroimaging data: A comparison of image-based and coordinate-based pooling of studies</article-title>. <source>Neuroimage</source>, <volume>45</volume>(<issue>3</issue>), <fpage>810</fpage>&#x2013;<lpage>823</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Shirer</surname>, <given-names>W. R.</given-names></string-name>, <string-name><surname>Ryali</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rykhlevskaia</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Menon</surname>, <given-names>V.</given-names></string-name>, &#x0026;<string-name><surname>Greicius</surname>, <given-names>M. D.</given-names></string-name> (<year>2012</year>). <article-title>Decoding subject-driven cognitive states with whole-brain connectivity patterns</article-title>. <source>Cerebral Cortex</source>, <volume>22</volume>(<issue>1</issue>), <fpage>158</fpage>&#x2013;<lpage>165</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="confproc"><string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Glahn</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Mackay</surname>, <given-names>C. E.</given-names></string-name>, &#x2026; <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name> (<conf-date>2009</conf-date>). <article-title>Correspondence of the brain&#x2019;s functional architecture during activation and rest</article-title>. <conf-name>Proceedings of the National Academy of Sciences of the United States of America</conf-name>, <volume>706</volume>(<issue>31</issue>), <fpage>13040</fpage>&#x2013;<lpage>13045</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Snyder</surname>, <given-names>L. H.</given-names></string-name>, <string-name><surname>Batista</surname>, <given-names>A. P.</given-names></string-name>, &#x0026; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name> (<year>1997</year>). <article-title>Coding of intention in the posterior parietal cortex</article-title>. <source>Nature</source>, <volume>386</volume>(<issue>6621</issue>), <fpage>167</fpage>&#x2013;<lpage>170</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="confproc"><string-name><surname>Steyvers</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Smyth</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Rosen-Zvi</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Griffiths</surname>, <given-names>T.</given-names></string-name> (<conf-date>2004</conf-date>). <article-title>Probabilistic Author-topic Models for Information Discovery</article-title>. In <conf-name>Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name> (pp. <fpage>306</fpage>&#x2013;<lpage>315</lpage>). <conf-loc>New York, NY, USA: ACM</conf-loc>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Swick</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ashley</surname>, <given-names>V.</given-names></string-name>, &#x0026; <string-name><surname>Turken</surname>, <given-names>U.</given-names></string-name> (<year>2011</year>). <article-title>Are the neural correlates of stopping and not going identical? Quantitative meta-analysis of two response inhibition tasks</article-title>. <source>Neuroimage</source>, <volume>56</volume>(<issue>3</issue>), <fpage>1655</fpage>&#x2013;<lpage>1665</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, &#x0026; <collab>WU-Minn HCP Consortium</collab>. (<year>2013</year>). <article-title>The WU-Minn Human Connectome Project: an overview</article-title>. <source>Neuroimage</source>, <volume>80</volume>, <fpage>62</fpage>&#x2013;<lpage>79</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Vigneau</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beaucousin</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Herve</surname>, <given-names>P. Y.</given-names></string-name>, <string-name><surname>Duffau</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Crivello</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Houde</surname>, <given-names>O.</given-names></string-name>, &#x2026; <string-name><surname>Tzourio-Mazoyer</surname>, <given-names>N.</given-names></string-name> (<year>2006</year>). <article-title>Meta-analyzing left hemisphere language areas: Phonology, semantics, and sentence processing</article-title>. <source>Neuroimage</source>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Essen</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>David</surname>, <given-names>C.</given-names></string-name>, &#x0026; <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name> (<year>2011</year>). <article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title>. <source>Nature Methods</source>, <volume>8</volume>(<issue>8</issue>), <fpage>665</fpage>&#x2013;<lpage>670</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Yeo</surname>, <given-names>B. T. T.</given-names></string-name>, <string-name><surname>Krienen</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Sepulcre</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sabuncu</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Lashkari</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hollinshead</surname>, <given-names>M.</given-names></string-name>, &#x2026; <string-name><surname>Buckner</surname>, <given-names>R. L.</given-names></string-name> (<year>2011</year>). <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>Journal of Neurophysiology</source>, <volume>106</volume>(<issue>3</issue>), <fpage>1125</fpage>&#x2013;<lpage>1165</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Yeo</surname>, <given-names>B. T. T.</given-names></string-name>, <string-name><surname>Thomas Yeo</surname>, <given-names>B. T.</given-names></string-name>, <string-name><surname>Krienen</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Yaakub</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Fox</surname>, <given-names>P. T.</given-names></string-name>, &#x2026; <string-name><surname>Chee</surname>, <given-names>M. W. L.</given-names></string-name> (<year>2014</year>). <article-title>Functional Specialization and Flexibility in Human Association Cortex</article-title>. <source>Cerebral Cortex</source>, <volume>25</volume>(<issue>10</issue>), <fpage>3654</fpage>&#x2013;<lpage>3672</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Zald</surname>, <given-names>D. H.</given-names></string-name> (<year>2003</year>). <article-title>The human amygdala and the emotional evaluation of sensory stimuli. Brain Research</article-title>. <source>Brain Research Reviews</source>, <volume>41</volume>(<issue>1</issue>), <fpage>88</fpage>&#x2013;<lpage>123</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="confproc"><string-name><surname>Zhai</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chengxiang</surname>, <given-names>Z.</given-names></string-name>, &#x0026; <string-name><surname>John</surname>, <given-names>L.</given-names></string-name> (<conf-date>2001</conf-date>). <article-title>Model-based feedback in the language modeling approach to information retrieval</article-title>. In <conf-name>Proceedings of the tenth international conference on Information and knowledge management - CIKM&#x2019;01</conf-name>. <ext-link ext-link-type="uri" xlink:href="http://doi.Org/10.1145/502585.502654">http://doi.Org/10.1145/502585.502654</ext-link></mixed-citation></ref>
</ref-list>
<sec id="s5" sec-type="supplementary-material">
<title>Supplementary Results</title>
<sec id="s5a">
<title><italic>Topic-based reconstruction of whole-brain maps</italic></title>
<p>The probabilistic functional-anatomical atlas we introduce in the main text is useful not only for advancing theoretical understanding of the functional properties of different brain regions, but also for facilitating description and interpretation of novel whole-brain maps. One can conceptualize the topics produced by the GC-LDA model as a basis set that can be combined in various ways to produce much more complex patterns of whole-brain activity. In principle, a diverse array of whole-brain activation maps might be recaptured or reconstructed using a weighted combination of our regionally-circumscribed topics. This capability would provide a powerful means of reducing brain maps that nominally contain hundreds of thousands of distinct voxels to a much smaller number of meaningful, functionally distinctive units.</p>
<p>To test this idea empirically, we attempted to &#x201C;reconstruct&#x201D; a series of whole-brain activation maps by fitting a regression model that predicted activation at each voxel in each target image from activation levels in the 200 region-specific topic maps. We used a regression approach to reconstruct whole-brain activation maps using the topics generated by our GC-LDA model. First, we smoothed each of the 200 topic maps containing activation assignments (e.g., <xref ref-type="fig" rid="fig3">Figure 3b-c</xref>) with a 6 mm FWHM kernel. Next, we vectorized both the target whole-brain map and the 200 smoothed topic maps. We then fit an ordinary least squares regression model predicting the target whole-brain activation map from the 200 topic maps, i.e.,
<disp-formula id="ueqn4"><alternatives><graphic xlink:href="059618_ueqn4.gif"/></alternatives></disp-formula>
where <italic>y</italic> is the vectorized input image to decode, <italic>&#x03B1;</italic> is the intercept, <italic>T</italic> is the number of topics, <italic>&#x03B2;<sub>i</sub></italic> is the estimated coefficient for the <italic>i<sup>th</sup></italic> topic, and <italic>X<sub>i</sub></italic> is the <italic>i<sup>th</sup></italic> smoothed whole-brain topic map (cf. <xref ref-type="fig" rid="fig3">Figure 3</xref>). This analysis produces a set of 200 <italic>&#x03B2;</italic> coefficients that reflect the relative weight of each topic in the reconstructed/predicted map. We report the full model&#x2019;s coefficient of determination (<italic>R</italic><sup>2</sup>) as a metric of the model&#x2019;s relative ability to describe the original map.</p>
<p>We applied this reconstruction approach to three very different sets of whole-brain images, including (1) the 20 BrainMap ICA maps reported by <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref>; (2) a randomly-selected set of 100 maps drawn from the NeuroVault whole-brain image repository (<xref rid="c22" ref-type="bibr">Gorgolewski et al., 2015</xref>); and (3) single-subject activation maps from the the Human Connectome Project (HCP; <xref rid="c56" ref-type="bibr">Van Essen et al., 2013</xref>)&#x002D;&#x002D;&#x002D;a landmark study that to date has released fMRI data from over 900 subjects performing a variety of experimental tasks (<xref rid="c4" ref-type="bibr">Barch et al., 2013</xref>). <xref ref-type="fig" rid="figS3">Supplementary Figure 4</xref> illustrates reconstruction results for sample images of each type (for additional examples, see <xref ref-type="fig" rid="figS4">Supplementary Figures 5 - 7</xref>). For the BrainMap ICA images, reconstruction fidelity was almost universally high (mean R<sup>2</sup> &#x003D; 0.74), and visual inspection revealed striking similarity in the vast majority of cases (<xref ref-type="fig" rid="figS3">Supp. Fig. 4A</xref>, <xref ref-type="fig" rid="figS4">Supp. Fig. 5</xref>; the sole exception was component 19 [R<sup>2</sup> &#x003D; .23], which clearly consisted of artifactual activation on the fringe of the brain). For the NeuroVault maps&#x002D;&#x002D;&#x002D;which varied widely in terms of task, analysis type, and sample size&#x002D;&#x002D;&#x002D;reconstruction fidelity was somewhat lower (mean R<sup>2</sup> &#x003D; 0.46; <xref ref-type="fig" rid="figS3">Supp. Figure 4B</xref>), but the reconstructed maps preserved most of the spatial detail in the original maps (Supp. Fig. 7). As a general rule, maps sourced from clearly-defined group-level contrasts were easier to reconstruct than maps with ambiguous provenance.</p>
<p>In contrast, reconstruction accuracy was relatively poor for the single-subject HCP images, with mean R<sup>2</sup> values ranging from 0.18 (social cognition task) to R<sup>2</sup> &#x003D; 0.3 (gambling task) across 4 different HCP tasks. This decrease was expected, however, as single-subject maps are necessarily noisier than group-averaged estimates, and also reflect considerable idiosyncracies in individual anatomy. Standard mass univariate group-level analyses are typically blind to such fine-grained differences, and can retain only the coarse patterns observed across the sample. The topic reconstruction approach can be viewed as an analogous means of regularizing low-level anatomical idiosyncracies and abstracting away high-level commonalities. That is, subjects whose neural responses to the same stimulus look very different in the original voxel space will typically have considerably more similar representations when reconstructed using our topics. For example, it is not at all apparent that the two single-subject images presented in <xref ref-type="fig" rid="figS3">Supp. Fig. 4C</xref> reflect the same functional task (i.e., the HCP Emotion task). By contrast, the topic-reconstructed images look much more similar, while still correlating strongly with each of the original two images.</p>
</sec>
<sec id="s5b">
<title>Supplementary Figures</title>
<p>[Note: Figures S1 and S7 are too large to include in this document, and are uploaded separately.]</p>
<p><bold>Figure S1</bold> [uploaded separately]. Full results for all topics learned by the GC-LDA model. Each row represents a single topic. For each topic, the word cloud displays the top semantic associates (the size of each term is roughly proportional to the strength of its loading, and the orthviews display all hard assignments of activations to that topic (each point represents a single activation from a single study in Neurosynth).</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S2</label>
<caption><p>Topic-based decoding of 20 BrainMap-derived ICA components reported in <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref>.</p></caption>
<graphic xlink:href="059618_figS1.tif"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S3</label>
<caption><p>Topic-based decoding of 12 &#x201C;cognitive components&#x201D; reported in <xref rid="c60" ref-type="bibr">Yeo et al. (2014)</xref>.</p></caption>
<graphic xlink:href="059618_figS2.tif"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S4</label>
<caption><p>Topic-based reconstruction of whole-brain activity maps. Representative examples from (A) the set of 20 BrainMap ICA components reported in <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref>, (B) the NeuroVault whole-brain image repository (<xref rid="c22" ref-type="bibr">Gorgolewski et al., 2015</xref>), and (C) single-subject contrast maps from the emotion processing task in the Human Connectome Project dataset (face vs. shape contrast). Each row displays the original (left) and reconstructed (center) image, along with the coefficient of determination (R<sup>2</sup>) for the fitted reconstruction model, and a scatter plot of all voxels (right).</p></caption>
<graphic xlink:href="059618_figS3.tif"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S5</label>
<caption><p>Reconstruction of 20 BrainMap ICA components reported in <xref rid="c52" ref-type="bibr">Smith et al. (2009)</xref>.</p></caption>
<graphic xlink:href="059618_figS4.tif"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S6</label>
<caption><p>Topic reconstruction of 12 &#x201C;cognitive components&#x201D; reported in <xref rid="c60" ref-type="bibr">Yeo et al. (2014)</xref>.</p></caption>
<graphic xlink:href="059618_figS5.tif"/>
</fig>
<p><bold>Figure S7</bold> [uploaded separately]. Topic reconstruction of 100 random maps extracted from the NeuroVault whole-brain image repository. Labels in white indicate human-annotated cognitive atlas paradigm, when available.</p>
</sec>
</sec>
</back>
</article>