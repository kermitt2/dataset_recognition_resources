<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/069641</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Memory Replay in Balanced Recurrent Networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Chenkov</surname><given-names>Nikolay</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Sprekeler</surname><given-names>Henning</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kempter</surname><given-names>Richard</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Institute for Theoretical Biology, Humboldt-Universit&#x00E4;t zu Berlin</institution>, Berlin, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Department of Software Engineering and Theoretical Computer Science, Technische Universit&#x00E4;t Berlin</institution>, Berlin, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Bernstein Center for Computational Neuroscience Berlin</institution>, Berlin, <country>Germany</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>&#x002A;</label><p><email>r.kempter@biologie.hu-berlin.de</email></p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2016</year></pub-date>
<elocation-id>069641</elocation-id>
<history>
<date date-type="received">
<day>15</day>
<month>8</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>8</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2016</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="069641.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title><p>Complex patterns of neural activity appear during up-states in the neocortex and sharp waves in the hippocampus, including sequences that resemble those during prior behavioral experience. The mechanisms underlying this replay are not well understood. How can small synaptic footprints engraved by experience control large-scale network activity during memory retrieval and consolidation? We hypothesize that sparse and weak synaptic connectivity between Hebbian assemblies are boosted by pre-existing recurrent connectivity within them. To investigate this idea, we connect sequences of assemblies in randomly connected spiking neuronal networks with a balance of excitation and inhibition. Simulations and analytical calculations show that recurrent connections within assemblies allow for a fast amplification of signals that indeed reduces the required number of inter-assembly connections. Replay can be evoked by small sensory-like cues or emerge spontaneously by activity fluctuations. Global&#x2014;potentially neuromodulatory&#x2014;alterations of neuronal excitability can switch between network states that favor retrieval and consolidation.</p>
<sec>
<title>Author Summary</title>
<p>Synaptic plasticity is the basis for learning and memory, and many experiments indicate that memories are imprinted in synaptic connections. However, basic mechanisms of how such memories are retrieved and consolidated remain unclear. In particular, how can one-shot learning of a sequence of events achieve a sufficiently strong synaptic footprint to retrieve or replay this sequence? Using both numerical simulations of spiking neural networks and an analytic approach, we provide a biologically plausible model for understanding how minute synaptic changes in a recurrent network can nevertheless be retrieved by small cues or even manifest themselves as activity patterns that emerge spontaneously. We show how the retrieval of exceedingly small changes in the connections across assemblies is robustly facilitated by recurrent connectivity within assemblies. This interaction between recurrent amplification within an assembly and the feed-forward propagation of activity across the network establishes a basis for the retrieval of memories.</p>
</sec>
</abstract>
<counts>
<page-count count="32"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><title>Introduction</title>
<p>The idea of sequential activation of mental concepts and neural populations has deep roots in the history of the cognitive sciences [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c88">88</xref>, <xref ref-type="bibr" rid="c97">97</xref>] as well as its share of criticism [<xref ref-type="bibr" rid="c56">56</xref>]. In one of the most influential works in neuroscience, Donald Hebb extended this concept by suggesting that neurons that fire simultaneously should be connected to each other, thus forming a cell assembly that represents an abstract mental concept [<xref ref-type="bibr" rid="c41">41</xref>]. He also suggested that such assemblies could be connected amongst each other, forming a network of associations in which one mental concept can ignite associated concepts by activating the corresponding assemblies. Hebb referred to the resulting sequential activation as well as the underlying circuitry as &#x201C;phase sequence&#x201D;. We will refer to such connectivity patterns as &#x201C;assembly sequences&#x201D;.</p>
<p>The notion of Hebbian assemblies has triggered a huge number of experimental studies (reviewed in [<xref ref-type="bibr" rid="c96">96</xref>]), but relatively few experiments have been dedicated to the idea of assembly sequences [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c53">53</xref>]. Many theoretical studies focused on feedforward networks, also known as synfire chains [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c44">44</xref>]. Synfire chains are characterized by a convergent-divergent feedforward connectivity between groups of neurons, where pulse packets of synchronous firing can propagate through the network. Few works were also dedicated on synfire chains embedded in recurrent networks [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c89">89</xref>], however, without explicitly considering recurrent connectivity within groups.</p>
<p>In this study, we combine the concept of feedforward synfire chains with the notion of recurrently connected Hebbian assemblies to form an assembly sequence. Using numerical simulations of spiking neural networks, we form assemblies consisting of recurrently connected excitatory and inhibitory neurons. The networks are tuned to operate in a balanced regime where large fluctuations of the mean excitatory and inhibitory input currents cancel each other. In this case, distinct assemblies that are sparsely connected in a feedforward fashion can reliably propagate transient activity. This replay can be triggered by external cues for sparse connectivities, but also can be evoked by background activity fluctuations for larger connectivities. Modulating the population excitability can shift the network state between cued-replay and spontaneous-replay regimes. Such spontaneous events may be the basis of the reverberating activity observed in the neocortex [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c63">63</xref>] or in the hippocampus [<xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c58">58</xref>, <xref ref-type="bibr" rid="c86">86</xref>]. Finally, we show that assembly sequences can also be replayed in a reversed direction (i.e., reverse replay) as observed during replay of behavior sequences [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>].</p>
</sec>
<sec id="s2"><title>Results</title>
<p>To test Hebb&#x2019;s hypothesis on activity propagation within a recurrent network, we use a network model of excitatory and inhibitory conductance-based integrate-and-fire neurons. The network has a sparse random background connectivity <italic>p</italic><sub>rand</sub> &#x003D; 0.01. We form a neural assembly (<xref rid="fig1" ref-type="fig">Fig 1A</xref>) by picking <italic>M</italic> excitatory ( <italic>M</italic> &#x003D; 500 if not stated otherwise) and <italic>M</italic>/4 inhibitory neurons and connecting them randomly with probability <italic>p</italic><sub>rc</sub>, resulting in a mutually coupled excitatory and inhibitory population. The new connections are created independently and in addition to the background connections. To embed an assembly sequence in the network, we first form 10 non-overlapping assemblies. The assemblies are then connected in a feedforward manner where an excitatory neuron from one group projects to an excitatory neuron in the subsequent group with probability <italic>p</italic><sub>ff</sub> (<xref rid="fig1" ref-type="fig">Fig 1B</xref>). Thus, by varying the feedforward and the recurrent connectivities, we can set the network structure anywhere in the spectrum between the limiting cases of synfire chains (<italic>p</italic><sub>ff</sub> > 0, <italic>p</italic><sub>rc</sub> &#x003D; 0) and uncoupled Hebbian assemblies (<italic>p</italic><sub>ff</sub> &#x003D; 0, <italic>p</italic><sub>rc</sub> &#x003E; 0), as depicted in <xref rid="fig1" ref-type="fig">Fig 1C</xref>.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1.</label>
<caption><title>Network connectivity.</title><p><bold>A:</bold>Schematic of an assembly <italic>i</italic> consisting of an excitatory (<italic>E<sub>i</sub></italic>) and an inhibitory (<italic>I<sub>i</sub></italic>) population. Red and blue lines indicate excitatory and inhibitory connections, respectively. The symbols w and &#x2212;kw denote total synaptic couplings between populations. <bold>B:</bold> Sketch of network connectivity. The inhomogeneous network is randomly connected with connection probability <italic>p<sub>rand</sub></italic>. A feedforward structure consisting of 10 assemblies (only <italic>i</italic> &#x2212; 1 and <italic>i</italic> shown) is embedded into the network. Each assembly is formed by recurrently connecting its neurons with probability <italic>p</italic><sub>rc</sub>. Subsequent assemblies are connected with feedforward probability <italic>p</italic><sub>ff</sub> between their excitatory neurons. <bold>C:</bold> Embedded structure as a function of connectivities.</p></caption>
<graphic xlink:href="069641_fig1.tif"/>
</fig>
<p>To ensure that the spontaneous activity of the network is close to an <italic>in-vivo</italic> condition, we use Hebbian plasticity of inhibitory connections [<xref ref-type="bibr" rid="c94">94</xref>], which has been shown to generate a balance of excitatory and inhibitory currents in individual neurons (<xref rid="fig2" ref-type="fig">Fig 2A</xref>). As a consequence, spikes are caused by current fluctuations (<xref rid="fig2" ref-type="fig">Fig 2B</xref>), and the network settles into a state of asynchronous irregular (AI) firing (<xref rid="fig2" ref-type="fig">Fig 2C</xref>, 0-500 ms). If we then stimulate the first group in the embedded assembly sequence (<xref rid="fig2" ref-type="fig">Fig 2C</xref>, 500 ms), the network responds with a wave of activity that traverses the whole assembly sequence, as hypothesised by Hebb [<xref ref-type="bibr" rid="c41">41</xref>]. We refer to such a propagation of activity wave as replay. As excitatory and inhibitory neurons are part of the assemblies, they both have elevated firing rates during group activation ( &#x223C; 100 spikes/sec for excitatory, and &#x223C; 60 spikes/sec for inhibitory neurons). Because excitatory neurons in the assembly sequence transiently increase their firing rates from 5 to 100 spikes/sec, a replay can be inferred from their large change in activity, which resembles replay in hippocampal CA networks [<xref ref-type="bibr" rid="c58">58</xref>]. On the other hand, interneurons have higher background firing rates of &#x223C; 20 spikes/sec and smaller maximum firing rates of &#x223C; 60 spikes/ sec during replay. As a result, interneurons have a much lower ratio of peak to background activity than excitatory neurons in our model, in line with lower selectivity of interneurons (e.g., [<xref ref-type="bibr" rid="c100">100</xref>]).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2.</label>
<caption><title>Example of activity in a balanced network.</title><p><bold>A:</bold> Input currents experienced by an example neuron. The excitatory input is denoted by the red trace while the inhibitory one is in blue. The black curve shows the sum of all currents: synaptic, injected, and leak currents. <bold>B:</bold> Membrane potential of the same neuron. Red dots denote the times of firing. <bold>C:</bold> Raster plot of spikes times of 500 neurons for 1 second. For better readability, only 50 neurons (out of 500) per group are shown. At time 500 ms, the first group is stimulated (arrow) and the activity propagates through the assembly sequence, resulting in a replay. The red dots correspond to the firing of the example neuron in A and B.</p></caption>
<graphic xlink:href="069641_fig2.tif"/>
</fig>
<sec id="s2a"><title>Sparse feedforward connectivity is sufficient for replay</title>
<p>Whether an assembly sequence is replayed is largely determined by the connectivities within and between assemblies. Therefore, we first study how the quality of replay depends on the recurrent (<italic>p</italic><sub>rc</sub>) and the feedforward (<italic>p</italic><sub>ff</sub>) connectivities. The network dynamics can be roughly assigned to regimes where the connectivity is too weak, strong enough, or too strong for a successful replay. We use a quality measure of replay (for details see Materials and Methods), which determines whether activations of the first group propagate to the end of the sequence without evoking a &#x201C;pathological&#x201D; burst of activity (<xref rid="fig3" ref-type="fig">Fig 3</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig 3.</label>
<caption><title>Evoked replay.</title><p>Assembly-sequence activation as a function of the feedforward <italic>p</italic> ff and the recurrent <italic>p</italic><sub>rc</sub> connectivities. The color code denotes the quality of replay, that is, the number of subsequent groups firing without bursting (see Materials and Methods). The black curve corresponds to the critical connectivity required for a replay where the slope <italic>c</italic> of the transfer function (See Materials and Methods and Eq 1) is matched manually to fit the simulation results for connectivities <italic>p</italic><sub>rc</sub> &#x003D; 0.08 and <italic>p</italic><sub>ff</sub> &#x003D; 0.04. The slope <italic>c</italic> is also estimated analytically (dashed white line). The raster plots (<bold>a-f</bold>) illustrate the dynamic regimes observed for different connectivity values;neurons above the gray line belong to the background neurons.</p></caption>
<graphic xlink:href="069641_fig3.tif"/>
</fig>
<p>Naturally, for a random network (<italic>p</italic><sub>ff</sub> &#x003D; 0, <italic>p</italic><sub>rc</sub> &#x003D; 0, <xref rid="fig3" ref-type="fig">Fig 3a</xref>) the replay fails because the random connections are not sufficient to drive the succeeding groups. In the case of uncoupled Hebbian assemblies (e.g., <italic>p</italic><sub>ff</sub> &#x003D; 0, <italic>p</italic><sub>rc</sub> &#x003D; 0.30), groups of neurons get activated spontaneously (<xref rid="fig3" ref-type="fig">Fig 3c</xref>), which is reminiscent to the previously reported cluster activation [<xref ref-type="bibr" rid="c61">61</xref>] but on a faster time scale. Already for sparse connectivity (e.g., <italic>p</italic><sub>ff</sub> &#x003D; <italic>p</italic><sub>rc</sub> &#x003D; 0.06) the assembly-sequence replay is successful (<xref rid="fig3" ref-type="fig">Fig 3b</xref>). In the case of denser recurrence (<italic>p</italic><sub>rc</sub> &#x2248; 0.10), a pulse packet propagates for even lower feedforward connectivity (<italic>p</italic><sub>ff</sub> &#x2248; 0.03). The feedforward connectivity that is required for a successful propagation decreases with increasing recurrent connectivity because assemblies of excitatory and inhibitory neurons can increase small fluctuations of the input through &#x201C;balanced amplification&#x201D; [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c72">72</xref>].</p>
<p>For high feedforward <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline1.gif"/></alternatives></inline-formula> but low recurrent <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline2.gif"/></alternatives></inline-formula> connectivity, the replay has low quality. In this case, excitatory neurons receive small recurrent inhibitory input compared to the large feedforward excitation, because the recurrent connection probability is lower than the feedforward one. Due to this lack of sufficient inhibitory input, the propagating activity either leads to run-away excitation (<xref rid="fig3" ref-type="fig">Fig 3e</xref>), also called synfire explosion [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c66">66</xref>], or to epileptiform bursting (<xref rid="fig3" ref-type="fig">Fig 3d</xref>). When both recurrent and feedforward connectivities are high, the inhibition is able to keep the propagating activity transient (<xref rid="fig3" ref-type="fig">Fig 3f</xref>). However, due to the strong input each neuron is firing multiple times within a small time window. Due to this bursting, the replay has a low quality.</p>
<p>To get an analytical understanding of the network, we use a linear approximation of the network dynamics to derive conditions under which replay is successful. The key determinant for replay is an amplification factor <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline3.gif"/></alternatives></inline-formula>, which measures how large is the rate <italic>r<sub>i&#x002B;1</sub></italic> in group <italic>i</italic>&#x002B; 1 in relation to the rate in the previous group <italic>i</italic>.</p>
<p>In the case where the amplification factor is smaller than one (<italic>r<sub>i&#x002B;1</sub></italic> &#x003C; <italic>r<sub>i</sub></italic>), the activity propagating through the assembly sequence will decrease at each step and eventually vanish, while for amplification larger than one (<italic>r<sub>i&#x002B;1</sub></italic> &#x003E; <italic>r<sub>i</sub></italic>) one would expect propagating activity that increases at each step in the sequence. An amplification factor <italic>&#x03BA;</italic>(<italic>p</italic><sub>ff</sub>, <italic>p</italic><sub>rc</sub>) &#x003D; 1 represents the critical value of connectivity for which the replay is stable, and the magnitude of activations is similar across groups. In the Materials and Methods we show that a linear model can approximate the amplification factor by
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="069641_eqn1.gif"/></alternatives>
</disp-formula>
where <italic>c</italic> &#x003D; 0.25 nS<sup>&#x2212;1</sup> is a constant that fits the model to the data (see Materials and Methods). We can interpret <italic>&#x043A;</italic> as an &#x201C;effective feedforward connectivity&#x201D; because the recurrent connectivity (<italic>p</italic><sub>rc</sub>) effectively scales up the feedforward connectivity <italic>p</italic><sub>ff</sub>. We can match the analytical results for critical connectivities to the numerical simulation, and show a qualitative fit between the approaches (black line in <xref rid="fig3" ref-type="fig">Fig 3</xref>).</p>
<p>We note that the number of excitatory synapses that is needed for an association, <italic>M</italic><sup>2</sup>(<italic>p</italic><sub>rc</sub> &#x002B; <italic>p</italic><sub>ff</sub>), weakly depends on the position on the line <italic>&#x043A;</italic> &#x003D; 1. By solving argmin <italic>p</italic><sub>rc</sub>, <italic>p</italic><sub>ff</sub> &#x2208;&#x043A; &#x003D; 1 <italic>M</italic><sup>2</sup>(<italic>p</italic><sub>rc</sub> &#x002B; <italic>p</italic><sub>ff</sub>) we find that the minimum number of new connections required for a replay is obtained for <italic>p</italic><sub>rc</sub> &#x003D; 0 because lines for which <italic>p</italic><sub>rc</sub> &#x002B; <italic>p</italic><sub>ff</sub> &#x003D; const have slope of &#x2212;1 in <xref rid="fig3" ref-type="fig">Fig 3</xref>, and the slope of the line defined by <italic>&#x043A;</italic> &#x003D; 1 has a more negative slope. For example, when <italic>p</italic><sub>rc</sub> &#x003D; 0.0, we need 40 new synapses; for <italic>p</italic><sub>rc</sub> &#x003D; 0.05, we need 50 new synapses; and for <italic>p</italic><sub>rc</sub> &#x003D; 0.2, 111 synapses are required for a new association. However, as feedforward connections might be created/facilitated on demand in one-shot learning, it is advantageous to keep their number low at the cost of higher recurrent connectivity, which has more time to develop <italic>prior</italic> to the learning. We extend this arguments further in the Discussion.</p>
<p>In summary, the recurrent connections within an assembly play a crucial role in integrating and amplifying the input to the assembly. This facilitation of replay is predominantly due to the excitatory-to-excitatory (E-E) recurrent connections, and not due to the excitatory-to-inhibitory (E-I) connections, a connectivity also known as &#x201C;shadow pools&#x201D; [<xref ref-type="bibr" rid="c5">5</xref>]. Embedding shadow pools and omitting the E-E connectivity within assemblies has no beneficial effect on the quality of replay (results not shown).</p>
</sec>
<sec id="s2b"><title>Recurrent connections are important for pattern completion</title>
<p>Neural systems have to deal with obscure or incomplete sensory cues. A widely adopted solution is pattern completion, that is, reconstruction of patterns from partial input. We examine how the network activity evolves in time for a partial or asynchronous activation of the first assembly.</p>
<p>To determine the capability of our network to complete patterns, we quantify the replay when only a fraction of the neurons in the first group is stimulated by external input. If 60 &#x0025; of the neurons in the first group (strong cue) are synchronously activated (<xref ref-type="fig" rid="fig4">Fig 4A</xref>, left panel), the quality of replay is virtually the same as in the case of full stimulation (100&#x0025; activated) in <xref rid="fig3" ref-type="fig">Fig 3</xref>. However, when only 20 &#x0025; of the neurons (weak cue) are simultaneously activated (<xref ref-type="fig" rid="fig4">Fig 4A</xref>, middle panel), we see a deterioration of replay mostly for low recurrent connectivities. The effect of the recurrent connections is illustrated in the right-most panel in <xref ref-type="fig" rid="fig4">Fig 4A</xref> where quality of replay is shown as a function of <italic>p</italic><sub>rc</sub> while the feedforward connectivity was kept constant (<italic>p</italic><sub>ff</sub> &#x003D; 0.05).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig 4.</label>
<caption><title>Pattern completion.</title><p><bold>A:</bold> Quality of replay after partial activation of the first group for cue size 60&#x0025; (left panel) and 20&#x0025; (middle) as a function of feedforward and recurrent connectivity. The right-most panel shows the quality replay after a cue activation (20&#x0025; and 60&#x0025;) as a function of the recurrent connectivity (<italic>p</italic><sub>rc</sub>) while the feedforward connectivity is constant (<italic>p</italic><sub>ff</sub> &#x003D; 0.05). <bold>B:</bold> Examples of network activity during 60&#x0025; (left) and 20&#x0025; (right) cue activation. The top and bottom raster plots correspond to assembly sequences with higher (<italic>p</italic><sub>rc</sub> &#x003D; 0.10, top) and lower (<italic>p</italic><sub>rc</sub> &#x003D; 0.06, bottom) recurrent connectivity, highlighted in A with white and black rectangles, respectively. <bold>C:</bold> State-space portraits representing the pulse-packet propagation. The activity in each group is quantified by the fraction of firing excitatory neurons (<italic>&#x03B1;</italic>) and the standard deviation of their spike times (<italic>&#x03C3;</italic>). The initial stimulations are denoted with small black dots while the colored dots denote the response of the first group to the stimulations; red dot if the whole sequence is activated, and blue otherwise. Stimulations in the region with white background result in replays, while stimulating in the gray region results in no replay. The black arrows illustrate the evolution of pulse packets during the replays in B. Top: <italic>p</italic><sub>rc</sub> &#x003D; 0.10; bottom: <italic>p</italic><sub>rc</sub> &#x003D; 0.06.</p></caption>
<graphic xlink:href="069641_fig4.tif"/>
</fig>
<p>Small input cues lead to a weak activation of the corresponding assembly. In the case of stronger connectivity (e.g., <italic>p</italic><sub>rc</sub>) this weak activity can build up and result in a replay as shown in the example from <xref ref-type="fig" rid="fig4">Fig 4B</xref>. The top and bottom rows of raster plots correspond to two assembly sequences with different recurrent connectivities, as highlighted by the rectangles in <xref ref-type="fig" rid="fig4">Fig 4A</xref>, while left and right columns show the activity during strong and weak cues, respectively. In the case of <italic>p</italic><sub>ff</sub> &#x003D; 0.05 and <italic>p</italic><sub>rc</sub> &#x003D; 0.10 (<xref ref-type="fig" rid="fig4">Fig 4B</xref>, top-right), the weak cue triggers a wide pulse packet with large temporal jitter in the first groups, which gradually shapes into a synchronous pulse packet as it propagates through the network. On the other hand, for a smaller recurrent connectivity (<italic>p</italic><sub>rc</sub> &#x003D; 0.06), the 20&#x0025; partial activation triggers a rather weak response that does not result in replay (<xref ref-type="fig" rid="fig4">Fig 4B</xref>, bottom-right).</p>
<p>The quality of replay depends not only on the number of neurons that are activated but also on the temporal dispersion of the pulse packet. Here, we adopt a quantification method that represents the activity evolution in a state-space portrait [<xref ref-type="bibr" rid="c25">25</xref>]. <xref ref-type="fig" rid="fig4">Fig 4C</xref> shows the time course of the fraction <italic>&#x03B1;</italic> of cells that participate in the pulse packet and the temporal dispersion <italic>&#x03C3;</italic> of the packet as the pulse propagates through the network. The state-space representation of two assembly sequences with equal feedforward (<italic>p</italic><sub>ff</sub> &#x003D; 0.05) but different recurrent connectivity are shown in <xref ref-type="fig" rid="fig4">Fig 4C</xref> (top: <italic>p</italic><sub>rc</sub> &#x003D; 0.10, bottom: <italic>p</italic><sub>rc</sub> &#x003D; 0.06). For each assembly sequence we repeatedly stimulated the first group with varying cue size <italic>&#x03B1;</italic> and time dispersion <italic>&#x03C3;</italic>, depicted by the black dots. Depending on the strength and dispersion of the initial stimulation, the dynamics of a network can enter one of two attractor points. For high <italic>&#x03B1;</italic> and low <italic>&#x03C3;</italic> the pulse packet propagates, entering the so-called synfire attractor (white background). On the other hand, for low <italic>&#x03B1;</italic> and high <italic>&#x03C3;</italic> the pulse packet dies out resulting in low asynchronous firing (gray background). The black-arrow traces in <xref ref-type="fig" rid="fig4">Fig 4C</xref> are example trajectories that describe the propagating pulse packets from <xref ref-type="fig" rid="fig4">Fig 4B</xref> in the (<italic>&#x03B1; &#x2212; &#x03C3;</italic>) space.</p>
<p>To summarize, increasing both the recurrent and feedforward connectivity facilitates the replay triggered by weak and dispersed inputs. Recurrent connectivity is particularly important for pattern completion.</p>
</sec>
<sec id="s2c"><title>Spontaneous replay</title>
<p>An interesting feature of assembly sequences is the potential emergence of spontaneous activations, that is, a replay when no specific input is given to the network. Random fluctuations in the network can be amplified by the feedforward structure and give rise to a spontaneous wave of propagation.</p>
<p>We find that spontaneous and evoked replay share various features such as sequential group activation on the background of AI network activity (<xref rid="fig4" ref-type="fig">Fig 5A</xref>, rasters a and b). As in the case of evoked replay, for exceedingly large connectivities the network dynamics can be dominated by epileptiform bursting activity (<xref rid="fig4" ref-type="fig">Fig 5A</xref>, rasters c and d).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig 5.</label>
<caption><title>Spontaneous network activity.</title><p><bold>A:</bold> The rate of spontaneous sequence activation is measured in the unperturbed network. The black curve is the analytical result for the lower bound of successful propagation from Fig 3. Examples of spontaneous replays for different connectivities are shown in the raster plots <bold>a-d</bold>. Synchrony (<bold>B</bold>), coefficient of variation (<bold>C</bold>), and firing rate (<bold>D</bold>) are averaged over the neurons in the last group of the sequence. <bold>E:</bold> Spontaneous events modulated by an external input. For low enough connectivities no spontaneous events occur (left). A small additional constant current input to the whole excitatory population ( <italic>I<sup>e</sup></italic> &#x003D; 1 pA) generates spontaneous replays (right). <bold>F:</bold> A densely connected network shows replays (left). Once the inhibitory population receives an additional constant current input ( <italic>I<sup>i</sup></italic> &#x003D; 3 pA), the firing rate decreases and no spontaneous events occur (right).</p></caption>
<graphic xlink:href="069641_fig5.tif"/>
</fig>
<p>To assess spontaneous replay, we quantify the number of replay events per time taking into account their quality, i.e., huge bursts of propagating activity are disregarded as replay. The rate of spontaneous activation increases as a function of both the feedforward (<italic>p</italic><sub>ff</sub>) and the recurrent (<italic>p</italic><sub>rc</sub>) connectivity (<xref rid="fig4" ref-type="fig">Fig 5A</xref>). For large connectivities (<italic>p</italic><sub>ff</sub>, <italic>p</italic><sub>rc</sub> &#x003E; 0.20) the quality of the spontaneous events is again poor and mostly dominated by strong bursts (<xref rid="fig4" ref-type="fig">Fig 5A</xref>, raster c). The dynamics of networks with large feedforward and low recurrent connections is dominated by long-lasting bursts of activity consisting of multiple sequence replays within each burst (<xref rid="fig4" ref-type="fig">Fig 5A</xref>, raster d). The maximum rate of activations does not exceed 4 events per second because the inhibitory synaptic plasticity adjusts the inhibition such that the excitatory firing rate is close to 5 spikes/sec.</p>
<p>To better characterize spontaneous dynamics, we refer to more extensive measures of the network dynamics. First, to account for deviations from the AI network state, we measure the synchrony of firing among neurons within the assemblies. To this end, we calculate the average pairwise correlation coefficient of spike trains of neurons within the same group. A low synchrony (value &#x223C; 0) means that neurons are uncorrelated, while a high synchrony (value &#x223C; 1) reveals that neurons fire preferentially together and seldom (or not at all) outside of an assembly activation. Because the synchrony builds up while activity propagates from one group to the next, a synchronization is most pronounced in the latter groups of the sequence. Therefore, we use correlations within the last group of the sequence as a measure of network synchrony (<xref rid="fig4" ref-type="fig">Fig 5B</xref>). The average synchrony is low ( &#x223C; 0) for low connectivities (<italic>p</italic><sub>ff</sub>, <italic>p</italic><sub>rc</sub> &#x003C; 0.10) and increases as a function of both p<sub>ff</sub> and <italic>p</italic><sub>rc</sub>. In the case of high <italic>p</italic><sub>rc</sub>, neurons participating in one assembly excite each other, and hence tend to fire together. On the other hand, for high <italic>p</italic><sub>ff</sub>, neurons within an assembly receive very similar input from the preceding group, so they fire together. This attachment of single neurons to group activity has two major consequences: first, it alters the AI state of the network, and second, it alters the stochastic behavior of the neurons, leading to more deterministic firing and bursting.</p>
<p>The network exhibits frequent epileptiform bursting in the case of high feedforward and low recurrent connectivities (raster plot examples in <xref rid="fig3" ref-type="fig">Fig 3</xref>, panel d, and <xref rid="fig4" ref-type="fig">Fig 5A</xref>, panel d). To assess this tendency of neurons to fire in bursts, we calculate the coefficient of variation (CV) for individual neurons&#x2019; spike trains. The average CV of neurons in the last group of the sequence exhibits Poisson-like irregular firing (CV value &#x223C; 1) for a large range of parameters (<xref rid="fig4" ref-type="fig">Fig 5C</xref>). However, for high <italic>p</italic><sub>ff</sub> ( &#x2265;0.10) and low <italic>p</italic><sub>rc</sub> ( &#x2264;0.10), the CV value exceeds 1, in line with irregular and bursting firing. In this parameter region, small fluctuations of activity in the first groups of the sequence are strongly amplified by the underlying feedforward connectivity, leading to ever increasing activity in the following groups (<xref rid="fig4" ref-type="fig">Fig 5A</xref>, panel d). Because of the variable shapes and sizes of these bursts, they are not always classified as spontaneous activations in <xref rid="fig4" ref-type="fig">Fig 5A</xref>. Highly bursty firing (CV &#x003E; 3) and high synchrony ( &#x223C; 1) suggest that the network cannot be properly balanced.</p>
<p>To test whether the inhibitory plasticity can balance the network activity when assembly sequences are embedded, we measure the average firing rate in the last group of the sequence (<xref rid="fig4" ref-type="fig">Fig 5D</xref>). The firing rate deviates from the target rate of 5 spikes/sec mostly for high feedforward connectivity <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline4.gif"/></alternatives></inline-formula>. This inability of inhibition to keep the firing rate at the target value can be explained by the frequent replays that shape a stronger inhibitory input during the balancing of the network. Once the inhibition gets too strong, neurons can fire only when they receive excessive amount of excitation. Thus, in the case of high clustering, e.g., strong assembly connectivity, the inhibitory plasticity prevents the neurons from reaching high firing rates, but is unable to sustain an AI state of the network.</p>
</sec>
<sec id="s2d"><title>Control of spontaneous and cued replay by external input</title>
<p>Further, we investigate how spontaneous and cued replay are related. The black line in <xref rid="fig4" ref-type="fig">Fig 5A</xref> refers to the analytical approximation for connectivities that enable evoked replay. Compared to the connectivity region of successfully evoked replays in <xref rid="fig3" ref-type="fig">Fig 3</xref>, the region for spontaneous replays in <xref rid="fig4" ref-type="fig">Fig 5</xref> is slightly shifted to the top and to the right. Therefore, in only a narrow area of the parameter space, sequences can be replayed by external input but do not get spontaneously activated. This finding suggests that to embed a sequence with high signal-to-noise ratio of propagation, the connectivities should be chosen appropriately, in line with previous reports [<xref ref-type="bibr" rid="c55">55</xref>]. In what follows we show that the size of this region can be controlled by external input to the network.</p>
<p><xref rid="fig4" ref-type="fig">Fig 5E</xref> and <xref ref-type="fig" rid="fig5">F</xref> illustrate how a small amount of global input current to all excitatory or all inhibitory neurons can modulate the network and shift it between AI and spontaneous-replay regimes. In the first example, the connectivities are relatively low (<italic>p</italic><sub>ff</sub> &#x003D; <italic>p</italic><sub>rc</sub> &#x003D; 0.06) such that replay can be evoked (<xref rid="fig3" ref-type="fig">Fig 3</xref>) but no spontaneous activations are present (<xref rid="fig4" ref-type="fig">Fig 5A</xref> and <xref rid="fig4" ref-type="fig">Fig 5E</xref>, left). After injecting a small additional current of only 1 pA into the whole excitatory population, the network becomes more excitable, i.e., the firing rate rises from 5 to 12 spikes/ sec and spontaneous replays do arise (<xref rid="fig4" ref-type="fig">Fig 5E</xref>, right).</p>
<p>On the other hand, in a network with high connectivities (<italic>p</italic><sub>ff</sub> &#x003D; <italic>p</italic><sub>rc</sub> &#x003D; 0.12), replay can be reliably evoked (<xref rid="fig3" ref-type="fig">Figs 3</xref> and <xref ref-type="fig" rid="fig4">4A</xref>) and also occurs spontaneously (<xref rid="fig4" ref-type="fig">Fig 5A</xref>). An additional input current of 3 pA to the inhibitory population decreases the firing rate of the excitatory population from 5 to 0.33 spikes/sec and shifts the network from a regime showing frequent spontaneous replays to a no-replay, AI regime (<xref rid="fig4" ref-type="fig">Fig 5F</xref>, left and right, respectively). Nevertheless, replays can still be evoked as in <xref rid="fig3" ref-type="fig">Fig 3</xref> (result not shown). Hence, the spontaneous-replay regime and the average firing rate in the AI state can be controlled by global or unspecific external current.</p>
<p>In summary, the balanced AI network state and successfully evoked replay of assembly sequences can coexist for a range of connectivities. For higher connectivities, the underlying network structure amplifies random fluctuations, leading to spontaneous propagations of activity between assemblies. A dynamical control of the rate of spontaneous events is possible through external input, which modulates the network activity and excitability. In the brain, such a switching between regimes could be achieved via neuromodulators, in particular via the cholinergic or adrenergic systems [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c87">87</xref>].</p>
</sec>
<sec id="s2e"><title>Smaller assemblies require higher connectivity</title>
<p>So far, we have shown basic properties of sequences at fixed assembly size <italic>M</italic> &#x003D; 500. To determine the role of this group size in replay, we vary <italic>M</italic> and the connectivity while keeping the size of the network fixed. As we have already explored how recurrent and feedforward connections determine replay individually, we now consider the case where they are equal, i.e., <italic>p</italic>ff &#x003D; <italic>p</italic><sub>rc</sub> &#x003D; <italic>p</italic>.</p>
<p>Assembly sequences can be successfully replayed after stimulation for various assembly sizes (<xref rid="fig5" ref-type="fig">Fig 6A</xref>). Smaller assemblies require denser connectivity (e.g., <italic>p</italic> &#x003D; 0.25 for <italic>M</italic> &#x003D; 100), while larger assemblies allow sparser connectivity (e.g., <italic>p</italic> &#x003D; 0.05 for <italic>M</italic> &#x003D; 500). Moreover, assemblies as small as 20 neurons are sufficient to organize a sequence given the condition of all-to-all connectivity within and between assemblies (result not shown). The analytically derived critical value of effective connectivity <italic>&#x043A;</italic> &#x003D; 1 is in agreement with the numerical simulations (black line in <xref rid="fig5" ref-type="fig">Fig 6A</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig 6.</label>
<caption><title>Assembly-sequence activation for various group sizes and connectivities.</title><p><bold>A:</bold>Simulation results for the quality of replay. <bold>B:</bold> Rate of spontaneous replay. <bold>C:</bold> Synchrony. <bold>D:</bold> Coefficient of variation <bold>E:</bold> Firing rate. <italic>&#x03C1;</italic><sub>0</sub> &#x003D; 5 spikes/sec is the target firing rate. In C, D, and E quantities are averaged over the neurons in the last group of the sequence. The black line is an analytical estimate for the evoked replay as in Figs 3 and 5.</p></caption>
<graphic xlink:href="069641_fig6.tif"/>
</fig>
<p>To further characterize the network dynamics for varying group size, we measure the rate of spontaneous activations of assembly sequences in undisturbed networks driven solely by constant input. <xref rid="fig5" ref-type="fig">Fig 6B</xref> indicates that spontaneous replays occur for a limited set of parameters resembling a banana-shaped region in the (<italic>M</italic>, <italic>p</italic>) plane. The parameter region for spontaneous replays partly overlaps with that of evoked replay. Again, there is a narrow range of parameters to the right of the black line in <xref rid="fig5" ref-type="fig">Fig 6B</xref> for which sequences can be evoked by external input while not being replayed spontaneously. As shown above, the size of this region can be controlled by external input to the whole network (<xref rid="fig4" ref-type="fig">Fig 5E,F</xref>).</p>
<p>To further assess the spontaneous dynamics, we measure the firing synchrony of neurons within the last group. The synchrony grows as function of both connectivity and group size (<xref rid="fig5" ref-type="fig">Fig 6C</xref>). The fact that the synchrony approaches the value one for higher connectivity and group size indicates that the network dynamics gets dominated by spontaneous reactivations. The simulation results reveal that neurons always fire rather irregular with CVs between 0.7 and 1.4 (<xref rid="fig5" ref-type="fig">Fig 6D</xref>). Because the recurrent and the feedforward connectivities are equal (<italic>p</italic><sub>ff</sub> &#x003D; <italic>p</italic><sub>rc</sub> &#x003D; <italic>p</italic>), the inhibition is always strong enough and does not allow epileptiform bursting activity. This behavior is reflected in a rather low maximal value of the coefficient of variation (CV&#x003C;1.4) compared to the results from <xref rid="fig4" ref-type="fig">Fig 5</xref>, where the CV could exceed values of 4 for low <italic>p</italic><sub>rc</sub>. The measured firing rates in the last assembly are at the target firing rate of <italic>&#x03C1;</italic><sub>0</sub> &#x003D; 5 spikes/sec for parameter values around and below the critical value <italic>&#x043A;</italic> &#x003D; 1 (<xref rid="fig5" ref-type="fig">Fig 6E</xref>). However, for increasing connectivity <italic>p</italic> and increasing group size <italic>M</italic>, the firing rate deviates from the target, indicating that the inhibitory plasticity cannot keep the network fully balanced.</p>
<p>To conclude, the assembly size <italic>M</italic> plays an important role in the network activity. The critical values of connectivity and group size for successful propagation are inversely proportional. Thus, the analytics predicts that larger assemblies of several thousands neurons require only a fraction of a percent connectivity in order to propagate synchronous activity. However, for this to happen, the group size <italic>M</italic> must be much smaller than the network size <italic>N<sup>E</sup></italic>. Here <italic>N<sup>E</sup></italic> was fixed to 20,000 neurons for easier comparison of scenarios, but results are also valid for larger networks (see Materials and Methods). The good agreement between the mean-field theory and the numerical results suggests that the crucial parameter for assembly-sequence replay is the total input one neuron is receiving, e.g., the number of input synapses.</p>
</sec>
<sec id="s2f"><title>Stronger synapses are equivalent to more connections</title>
<p>Up to this point, all excitatory synaptic connections in our model had constant and equal strengths. By encoding an assembly sequence we implicitly altered the structural connectivity by creating new synaptic connections. This case of structural plasticity can also occur when silent synapses are turned into functionally active connections upon learning [<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c38">38</xref>]. However, learning new associations might also be possible through a change of synaptic strength of individual connections [<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c64">64</xref>]. If a sequence is to be learned through synaptic plasticity, then instead of increasing the connectivity between groups of neurons, the synaptic conductances could be increased as well. To test whether these two types of plasticity are equivalent in our approach, we embed assembly sequences with various feedforward connectivities <italic>p</italic><sub>ff</sub> and various feedforward conductances <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline5.gif"/></alternatives></inline-formula>, while keeping the recurrent connectivity (<italic>p</italic><sub>rc</sub> &#x003D; 0.06) and recurrent conductances ( <italic>g<sup>E</sup></italic> &#x003D; 0.1 nS) constant.</p>
<p>Numerical results show that feedforward connectivity and feedforward conductance have identical roles in the replay of a sequence. That is, the sparser the connections, the stronger synapses are required for the propagation of activity. The analytical estimate (<xref rid="fig6" ref-type="fig">Fig 7A</xref>, black line corresponds to <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline6.gif"/></alternatives></inline-formula>.) predicts that the product of p <sub>ff</sub>and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline7.gif"/></alternatives></inline-formula> is the essential parameter for replay.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Fig 7.</label>
<caption><title>Feedforward conductance versus feedforward connectivity.</title><p><bold>A:</bold>Quality of replay as a function of connectivity and synaptic strength. <bold>B:</bold> The replay as a function of connectivity and total feedforward conductance input shows that the propagation is independent of connectivity as long as the total feed-forward input is kept constant. <bold>C:</bold> Spontaneous network dynamics described by the rate of spontaneous replay, synchrony, CV, and firing rate.</p></caption>
<graphic xlink:href="069641_fig7.tif"/>
</fig>
<p>That this analytical prediction is fulfilled in the numerical simulations becomes clearer when we show the replay quality as a function of the feedforward connectivity and the total feedforward input <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline8.gif"/></alternatives></inline-formula> a neuron is receiving (<xref rid="fig6" ref-type="fig">Fig 7B</xref>). It is irrelevant whether the number of connections are changed or their strength, what matters is their product. This rule breaks only for sparse connectivities (<italic>p</italic><sub>ff</sub> &#x003C; 0.01), i.e. when the mean number of feedforward connections between two groups is low ( &#x003C;5). Therefore, the number of relevant connections cannot be reduced to very low numbers.</p>
<p>Consistent with earlier findings, the quality of replay is high above a certain strength of the total feedforward conductance (<inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline9.gif"/></alternatives></inline-formula> in <xref rid="fig4" ref-type="fig">Fig 5B</xref>) and for <italic>p</italic><sub>ff</sub> &#x003E; 0.01. However, for sufficiently large feedforward input <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline10.gif"/></alternatives></inline-formula>, the replay of sequences is severely impaired as the network is in a state of highly synchronous bursting activity (<xref rid="fig6" ref-type="fig">Fig 7B</xref>), which is similar to the results shown in <xref rid="fig4" ref-type="fig">Figs 5</xref> and <xref rid="fig5" ref-type="fig">6</xref>.</p>
<p>The rule that the total input <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline11.gif"/></alternatives></inline-formula> determines the network behavior also holds for spontaneous activity. Spontaneous replay rate, CV, synchrony, and firing rate all vary as a function of the total input (<xref rid="fig6" ref-type="fig">Fig 7C</xref>), and only weakly as a function of the connectivity or the conductance alone. Similar to the previous results in <xref rid="fig4" ref-type="fig">Figs 5</xref> and <xref rid="fig5" ref-type="fig">6</xref>, for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline12.gif"/></alternatives></inline-formula> it is possible to evoke a replay while preserving the AI state of the network. Increasing the total input beyond this value drives the network into a state of spontaneous replay with increased synchrony.</p>
</sec>
<sec id="s2g"><title>Forward and reverse replay in assembly sequences with symmetric connections</title>
<p>The assembly-sequence model discussed until now contains asymmetric connections, i.e., neurons from one group project extensively within the same and the subsequent group but not to the previous group. We showed that such feedforward assembly sequences are capable of propagating activity, which we call replay. Thus, the proposed model may give an insight on the replay of behavioral sequences that have been observed in the hippocampus [<xref ref-type="bibr" rid="c58">58</xref>]. However, further experiments revealed that sequences are also replayed in the inverse temporal order than during behavior, so-called reverse replay [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>]. The direction of this replay also depended on the context, i.e., when the animal was at the beginning of the path, forward replays prevailed; while after traversing the path, more reverse replays were detected (but see [<xref ref-type="bibr" rid="c47">47</xref>]). This suggests that the replay activity might be cued by the sensory input experienced at the current location of the animal.</p>
<p>As the feedforward structure adopted in the network model is largely asymmetric, the assembly sequence is incapable of reverse replay in its current form. To be able to activate a sequence in both directions, we modify the network and add symmetric connectivity between assemblies [<xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c82">82</xref>]. Then, an assembly of neurons does not project only to the subsequent assembly but also to the preceding, and both projections are random with probability <italic>p</italic><sub>ff</sub> (<xref rid="fig7" ref-type="fig">Fig 8A</xref>). While this connectivity pattern decreases the group clustering, it does not lead to full merge of the assemblies because the inhibition remains local for each group.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Fig 8.</label>
<caption><title>Symmetric assembly sequence.</title><p><bold>A:</bold>Schematic of an assembly sequence with symmetric connections between groups. <bold>B:</bold> Virtual rat position on a linear track (top) and the corresponding neuronal activity (bottom) as a function of time for 2 seconds. The rat rests at position &#x201C;b&#x201D; for half a second, then moves from &#x201C;b&#x201D; to &#x201C;e&#x201D; with constant speed for one second, where it rests for another 500 ms. While the rat is immobile at both ends of the track, a positive current input <italic>I <sup>e</sup></italic> &#x003D; 2 pA is applied to the excitatory population of the first and last assembly as shown by the red background in the raster plot. Spontaneous replays start from the cued assemblies. During exploration, however, the network activity is decreased by a current <italic>I<sup>e</sup></italic> &#x003D; &#x2212; 10 pA injected to the whole excitatory population, denoted with a blue horizontal bar. Strong sensory input during traversal activates the location-specific assemblies but does not result in any replay. The timing and location of the stimulations is denoted with red vertical bars in the raster plot. Recurrent and feedforward connectivities are <italic>p</italic><sub>rc</sub> &#x003D; 0.15 and <italic>p</italic><sub>ff</sub> &#x003D; 0.03, respectively.</p></caption>
<graphic xlink:href="069641_fig8.tif"/>
</fig>
<p>Interpreting this network as a model for hippocampal activity during spatial navigation of a virtual rat on a linear track (<xref rid="fig7" ref-type="fig">Fig 8B</xref>, top), we test the idea that external input can switch the network between a spontaneous-replay state during rest and a non-replay, spatial-representation state during locomotion. During immobility at the beginning of the track, a context-dependent input cue is mimicked by a constant current <italic>I <sup>e</sup></italic> &#x003D; 2 pA injected into the excitatory neurons of the first assembly (<xref rid="fig7" ref-type="fig">Fig 8B</xref>, red bar from 0 to 500 ms). The elevated firing rate of the first assembly results in a spontaneous forward replay, similar to the experimental findings during resting states at the beginning of a linear track [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>]. In contrast, in the absence of the context-dependent current, spontaneous replay can start at any assembly in the sequence (as in <xref rid="fig4" ref-type="fig">Fig 5</xref>) and propagate in forward or reverse direction.</p>
<p>After the initial 500 ms resting period, an external global current of &#x2212; 10 pA is injected into the whole excitatory population to decrease network excitability and to mimic a state in which the rat explores the environment. In addition, to model place-specific sensory input that is locked to theta oscillations, we apply a strong and brief conductance input (as in <xref rid="fig2" ref-type="fig">Fig 2</xref>) every 100 ms to the assembly that represents the current location. In this situation, the assemblies fire at their corresponding locations only. There is, however, a weak activation of the neighboring assemblies that does not result in a replay. An extension of the model including lateral inhibition and STP would possibly enable theta sequences that span in one direction only [<xref ref-type="bibr" rid="c80">80</xref>]. Such an extension is, however, beyond the scope of the current manuscript.</p>
<p>At the end of the track, we retract the global external current to return to the virtual resting state for the last 500 ms of the simulation, and the network switches back to higher mean firing rates. A context-dependent sensory cue to the last group ( <italic>I <sup>e</sup></italic> &#x003D; 2 pA current injected continuously) then leads to a spontaneous reverse replay, similar to experimental findings at the end of a linear track [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>].</p>
<p>In summary, we show that given symmetric connectivity between assemblies, transient activity can propagate in both directions. Large negative external currents injected into all excitatory neurons can decrease network excitability and thus block the replay of sequences. On the other hand, spontaneous replay can be cued by a small increase in the firing rate of a particular assembly. Interestingly, once a replay is initiated, it does not change direction, in spite of the symmetric connectivity. An active assembly receives feedback inhibition from its inhibitory subpopulation, which prevents immediate further activations and hence a reversal of the direction of propagation.</p>
</sec>
</sec>
<sec id="s3"><title>Discussio</title>
<p>We revived Hebb&#x2019;s idea on assembly sequences (or &#x201C;phase sequences&#x201D;) where activity in a recurrent neural network propagates through assemblies [<xref ref-type="bibr" rid="c41">41</xref>], a dynamics that could underlie the recall and consolidation of memories. An important question in this context is how learning of a series of events can achieve a strong enough synaptic footprint to replay this sequence later. Using both numerical simulations of recurrent spiking neural networks and an analytical approach, we provided a biologically plausible model for understanding how minute synaptic changes can nevertheless be uncovered by small cues or even manifest themselves as activity patterns that emerge spontaneously. We showed how the impact of small changes in the connections between assemblies is boosted by recurrent connectivity within assemblies. This interaction between recurrent amplification within an assembly and the feedforward propagation of activity establishes a possible basis for the retrieval of memories. Our theory thus provides an unifying framework that combines the fields of Hebbian assemblies and assembly sequences [<xref ref-type="bibr" rid="c41">41</xref>], synfire chains [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c25">25</xref>], and fast amplification in balanced recurrent networks that are in an asynchronous-irregular state [<xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c94">94</xref>].</p>
<p>Main conclusions from our work are that the effective coupling between assemblies is a function of both feedforward and recurrent connectivities, and that the network can express three main types of behavior: 1. When the coupling is weak enough, assembly sequences are virtually indistinguishable from the background random connections, and no replays take place. 2. For sufficiently strong coupling, a transient input to some assembly propagates through the sequence, resulting in a replay. 3. For even stronger coupling, noise fluctuations get amplified by the underlying structure, resulting in spontaneous replays. Each of these three regimes has a certain advantage in performing a particular task. Weak coupling is appropriate for imprinting new sequences if the network dynamics is driven by external inputs rather than controlled by the intrinsically generated activity. Intermediate coupling is suitable for recollection of saved memories; sequences remain concealed and are replayed only by specific input cues; otherwise, the network is in the asynchronous-irregular, spontaneous state. For strong coupling, spontaneous replays might be useful for offline recollection of stored sequences when there are no external input cues. Importantly, the network behaviour and the rate of spontaneous events depends not only on the coupling but can be controlled by modulating the network excitability through external input. Neuromodulator systems, for example the cholinergic and the adrenergic systems [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c87">87</xref>] might therefore mediate the retrieval process.</p>
<p>In our simulations, we examined relatively short and non-overlapping assemblies. A natural question is whether the network can sustain longer chains and tolerate overlapping patterns. In additional simulations (results not shown), we found that both is possible. However, because previous work has dealt in great detail with the calculation of capacity of neural networks both analytically [<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c60">60</xref>] and computationally [<xref ref-type="bibr" rid="c89">89</xref>], we did not explore this issue.</p>
<sec id="s3a"><title>Related models</title>
<p>Assembly sequences are tightly related to synfire chains, which were proposed [<xref ref-type="bibr" rid="c1">1</xref>] as a model for the propagation of synchronous activity between groups of neurons. Diesmann et al. [<xref ref-type="bibr" rid="c25">25</xref>] showed for the first time that synfire chains in a noisy network of spiking neurons can indeed support a temporal code. It has been shown, however, that the embedding of synfire chains in recurrent networks is fragile [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c66">66</xref>], because on the one hand, synfire chains require a minimal connectivity to allow propagation, while on the other hand, a dense connectivity between groups of neurons can generate unstable network dynamics. Therefore, Aviel et al. [<xref ref-type="bibr" rid="c5">5</xref>] introduced &#x201C;shadow pools&#x201D;of inhibitory neurons that stabilize the network dynamics for high connectivity. The network fragility can also be mitigated by reducing the required feedforward connectivity: inputs from the previous assembly are boosted by recurrent connections within the assembly. This approach was followed Kumar et al. [<xref ref-type="bibr" rid="c54">54</xref>], which examined synfire chains embedded in random networks with local connectivity, thus, implicitly adopting some recurrent connectivity within assemblies as proposed by the assembly-sequence hypothesis; nevertheless, their assemblies were fully connected in a feedforward manner. Recently, it was shown that replay of synfire chains can be facilitated by adding feedback connections to preceding groups [<xref ref-type="bibr" rid="c69">69</xref>]. However, this Hebbian amplification significantly increased the duration of the spike volleys and thus decreased the speed of replay. Our model circumvents this slowing effect by combining the recurrent excitation with local feedback inhibition, effectively replacing Hebbian amplification by a transient &#x201C;balanced amplification&#x201D; [<xref ref-type="bibr" rid="c72">72</xref>].</p>
<p>To store sequences, further classes of models were proposed, e.g., &#x201C;winner-takes-all&#x201D; [<xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c71">71</xref>] and &#x201C;communication through resonance&#x201D; [<xref ref-type="bibr" rid="c37">37</xref>]. However, the activity propagation in these models has an order of magnitude slower time scales than the synfire chain or the assembly sequence, and thus, are not suitable for rapid transient replays.</p>
<p>The spontaneous replay in our network bears some resemblance with the population bursts that occur in a model with supralinear amplification of precisely synchronised inputs [<xref ref-type="bibr" rid="c67">67</xref>]. Adding such nonlinearities to the conductances in our model might decrease even further the connectivity required for the assembly-sequence replay. Another model class, which relies on lognormal conductance distributions, has been proposed as a burst generator for SWRs [<xref ref-type="bibr" rid="c74">74</xref>]. The model accounts for spontaneously generated stereotypical activity that propagates through neurons that are connected with strong synapses.</p>
<p>To summarize, for the propagation of activity, functionally connecting assemblies of excitatory and inhibitory neurons requires lower number of additional feedforward synapses than connecting random groups of neurons. This lower number of synapses may facilitate rapid, single-shot learning of associations and enhance the memory capacity of the network [<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c90">90</xref>].</p>
</sec>
<sec id="s3b"><title>Relation between recurrent and feedforward connectivity</title>
<p>What is the most efficient set of connectivities in terms of numbers of synapses used? To create an assembly of <italic>M</italic> neurons and to connect it to another assembly of the same size, we need <italic>M</italic><sup>2</sup>(<italic>p</italic><sub>rc</sub> &#x002B; <italic>p</italic><sub>ff</sub>) excitatory-to-excitatory synapses. The constraint <italic>&#x043A;</italic> &#x003D; 1 then leads to a minimum total number of synapses at <italic>p</italic><sub>rc</sub> &#x003D; 0. This result is somewhat surprising because it suggests that our proposed recurrent amplification provides a disadvantage.</p>
<p>However, another constraint might be even more important: to imprint an association in one-shot learning, as for example required for episodic memories, it might be an advantage to change as few synapses as possible so that one can retrieve the memory later via a replay. Therefore, <italic>p</italic><sub>ff</sub> should be low, in particular lower than the recurrent connectivity that is bound by the morphological connectivity that includes also weak or silent synapses. Minimizing <italic>p</italic><sub>ff</sub> under the constraint <italic>&#x043A;</italic> &#x003D; 1 implies, however, maximizing <italic>p</italic><sub>rc</sub>. Such large connectivities might require longer time to develop. A large <italic>p</italic><sub>rc</sub> is compatible with one-shot learning only if assemblies (that are defined by increased <italic>p</italic><sub>rc</sub> among a group of neurons) can be set up <italic>prior</italic> to the (feedforward) association of assemblies. Thus, episodic memories could benefit from strong preexisting assemblies. For setting up such assemblies, long time periods might be available to create new synapses and to morphologically grow synapses. Thus, we predict that for any episodic memory to be stored in one shot learning in hippocampal networks such as CA3, a sufficiently strong representation of the events to be associated does exist <italic>prior</italic> to successful one-shot learning. In this case, <italic>p</italic><sub>ff</sub> (i.e., connectivity in addition to <italic>p</italic><sub>rand</sub>) can be almost arbitrarily low. A natural lower limit is that the number of synapses per neuron <italic>M <sub>pff</sub></italic> is much larger than 1, say 10 as a rough estimate (in <xref rid="fig3" ref-type="fig">Fig 3</xref> we have <italic>M</italic><sub>pff</sub> &#x223C; 30 for a rather low value of <italic>p</italic><sub>rc</sub> &#x003D; <italic>p</italic><sub>ff</sub>, and 10 for <italic>p</italic><sub>rc</sub> &#x003D; 0.30; even 5 or more very strong synapses are sufficient in <xref rid="fig6" ref-type="fig">Fig 7</xref>), which can be interpreted in two ways: (1) Every neuron in an assembly should activate several neurons in the subsequent assembly, and (2) every neuron in an assembly to be activated should receive several synapses from from neurons in the previous assembly.</p>
<p>For example in the modeled network, for <italic>p</italic><sub>ff</sub> &#x003D; 0.02 and <italic>M <sub>pff</sub></italic> &#x003E; 10 we obtain <italic>M &#x003E;</italic> 500, which is in agreement with an estimated optimal size of assemblies in the hippocampus [<xref ref-type="bibr" rid="c59">59</xref>]. The total number of feedforward synapses required for imprinting an association is then <italic>M</italic><sup>2</sup> <italic>p</italic><sub>ff</sub> &#x003E; 5,000, which is a relatively small number compared to the total number of background synapses <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline13.gif"/></alternatives></inline-formula> for <italic>N<sup>E</sup></italic> &#x003D; 20,000 and <italic>p</italic><sub>rand</sub> &#x003D; 0.01. Scaling up the network accordingly (see Materials and Methods) to the size of a mouse CA3 network, i.e., <italic>N <sup>E</sup></italic> &#x003D; 240,000 (a typical number for the rat hippocampus, e.g., [<xref ref-type="bibr" rid="c76">76</xref>, <xref ref-type="bibr" rid="c98">98</xref>]), the number of new associative synapses is <italic>M</italic><sup>2</sup><italic>p</italic><sub>ff</sub> &#x003E; 17,000, while the total connections are more than 0.5.10<sup>9</sup>.</p>
<p>To conclude, abundant recurrent connections within assemblies can decrease the feedforward connectivity required for a replay to almost arbitrary low values. Moreover, the ratio of memory synapses to background synapses decreases as the network is scaled to bigger size.</p>
</sec>
<sec id="s3c"><title>Mechanisms for assembly-sequence formation</title>
<p>For sequence replay, increasing the number of connections between groups has the same effect as scaling up the individual connection strengths. We conclude that structural and synaptic plasticity could play an equivalent role in the formation of assembly sequences. However, in the current study we have not considered plasticity mechanisms that could be mediating the formation of assembly sequences. Previous attempts of implementing a spike-timing-dependent plasticity (STDP) rule with an asymmetric temporal window [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c48">48</xref>] in recurrent networks led to structural instabilities [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c70">70</xref>]. More sophisticated learning rules better matched the experimentally observed plasticity protocols [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c75">75</xref>], and these rules combined with various homeostatic mechanisms could form Hebbian assemblies that remained stable over long time periods [<xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c82">82</xref>, <xref ref-type="bibr" rid="c102">102</xref>]. Moreover, [<xref ref-type="bibr" rid="c62">62</xref>] and [<xref ref-type="bibr" rid="c82">82</xref>] have shown that the voltage-based STDP rule [<xref ref-type="bibr" rid="c17">17</xref>] leads to strong bidirectional connections, a network motif that has been reported in multiple brain regions [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c85">85</xref>]. A recent experimental work on the plasticity of the CA3-to-CA3 pyramidal cell synapses has revealed a symmetric STDP temporal curve [<xref ref-type="bibr" rid="c68">68</xref>]. Such a plasticity rule can be responsible for the encoding of stable assembly representations in the hippocampus.</p>
<p>Several plasticity rules have been successfully applied in learning sequences [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c84">84</xref>, <xref ref-type="bibr" rid="c95">95</xref>]. However, these studies focused purely on sequence replay and did not take into account its interaction with a balanced, asynchronous irregular background state.</p>
</sec>
<sec id="s3d"><title>Relations to hippocampal replay of behavioral sequences</title>
<p>The present model may explain the replay of sequences associated with the sharp-wave ripple (SWR) events, which originate in the CA3 region of the hippocampus predominantly during rest and sleep [<xref ref-type="bibr" rid="c14">14</xref>]. SWRs are characterized by a massive neuronal depolarization reflected in the local field potential [<xref ref-type="bibr" rid="c21">21</xref>]. Moreover, during SWRs, pyramidal cells in the CA areas fire in sequences that reflect their firing during prior awake experience [<xref ref-type="bibr" rid="c58">58</xref>]. Cells can fire in the same or in the reverse sequential order, which we refer to as forward and reverse replay, respectively [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>].</p>
<p>According to the two-stage model of memory trace formation [<xref ref-type="bibr" rid="c14">14</xref>], the hippocampus is encoding new episodic memories during active wakefulness (stage one). Later, these memories are gradually consolidated into neocortex through SWR-associated replays (stage two). It has been proposed that acetylcholine (ACh) modulates the flow of information between the hippocampus and the neocortex and thereby mediates switches between these memory-formation stages [<xref ref-type="bibr" rid="c39">39</xref>]. During active wakefulness, the concentration of ACh in hippocampus is high, leading to partial suppression of excitatory glutamatergic transmission [<xref ref-type="bibr" rid="c40">40</xref>] and promoting synaptic plasticity [<xref ref-type="bibr" rid="c36">36</xref>]. In this state, a single experience seems to be sufficient to encode representations of the immediate future in an environment [<xref ref-type="bibr" rid="c29">29</xref>]. On the other hand, the level of ACh decreases significantly during slow-wave sleep [<xref ref-type="bibr" rid="c65">65</xref>], releasing the synaptic suppression and resulting in strong excitatory feedback synapses, which suggests that this boost of recurrent and feedback connections leads to the occurrence of SWRs. In line with this hypothesis, the present model shows that increasing the synaptic strengths shifts the assembly-sequence dynamics from a no-replay regime to a spontaneous-replay regime. Also, we demonstrated that this regime supports both forward and reverse replay if assemblies are projecting symmetrically to each other and if recurrent connectivity exceeds severalfold the feedforward coupling.</p>
<p>In summary, a prediction of our assembly-sequence model is that prior to being able to store and recall a memory trace that connects events, strong enough representations of events in recurrently connected assemblies are necessary because recalling a minute memory trace requires amplification within assemblies. Another prediction of this model is based on the fact that the network is in an asynchronous-irregular state during the time intervals between replays. Hence, by increasing the activity of the excitatory neurons or by disinhibiting the network, e.g., by decreasing the activity of the interneuron population specialized in keeping the balance, one could increase the rate of spontaneous replays. Our model thus links a diverse set of experimental results on the cellular, behavioral, and systems level of neuroscience on memory retrieval and consolidation [<xref ref-type="bibr" rid="c24">24</xref>].</p>
</sec>
</sec>
<sec id="s4"><title>Materials and Methods</title>
<p>The network simulations as well as the data analyses were performed in Python (<ext-link ext-link-type="uri" xlink:href="http://www.python.org">www.python.org</ext-link>). The neural network was implemented in Brian [<xref ref-type="bibr" rid="c34">34</xref>]. For managing the simulation environment and data processing, we used standard Python libraries such as NumPy, SciPy, Matplotlib, and SymPy.</p>
<sec id="s4a"><title>Neuron model</title>
<p>Neurons are described by a conductance-based leaky integrate-and-fire model, where the subthreshold membrane potential <italic>Vi</italic>(<italic>t</italic>) of cell <italic>i</italic> obeys
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="069641_eqn2.gif"/></alternatives>
</disp-formula></p>
<p>The cells&#x2019; resting potential is <italic>V</italic><sup>rest</sup> &#x003D; &#x2212;60 mV, its capacitance is <italic>C</italic> &#x003D; 200 pF, and the leak conductance is <italic>G</italic><sup>leak</sup> &#x003D; 10 nS, resulting in a membrane time constant of 20 ms in the absence of synaptic stimulation. The variable <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline14.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline15.gif"/></alternatives></inline-formula> are the total synaptic conductances describing the time-dependent synaptic inputs to neuron <italic>i</italic>. The excitatory and inhibitory reversal potentials are <italic>V <sup>E</sup></italic> &#x003D; 0 mV and <italic>V <sup>I</sup></italic> &#x003D; &#x2212; 80 mV, respectively. <italic>I</italic><sup>ext</sup> &#x003D; <italic>I</italic><sup>const</sup> &#x002B; <italic>I<sup>x</sup></italic> is an externally applied current. To evoke activity in the network, a constant external current <italic>I</italic><sup>const</sup> &#x003D; 200 pA is injected into each neuron. Only if explicitly stated (e.g., <xref rid="fig4" ref-type="fig">Figs 5</xref> and <xref rid="fig7" ref-type="fig">8</xref>), small additional current inputs <italic>I <sup>x</sup></italic> are applied to excitatory or inhibitory neurons, which we denote as <italic>I<sup>e</sup></italic> and <italic>I<sup>i</sup></italic>, respectively. As the membrane potential <italic>V<sub>i</sub></italic> reaches the threshold <italic>V</italic><sup>th</sup> &#x003D; &#x2212;50 mV, neuron <italic>i</italic> emits an action potential, and the membrane potential <italic>Vi</italic> is reset to the resting potential <italic>V</italic><sup>rest</sup> for a refractory period <italic>&#x03C4;</italic><sub>rp</sub> &#x003D; 2 ms.</p>
<p>The dynamics of the conductances <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline16.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline17.gif"/></alternatives></inline-formula> of a postsynaptic cell <italic>i</italic> are determined by the spiking of the excitatory and inhibitory presynaptic neurons. Each time a presynaptic cell <italic>j</italic> fires, the synaptic input conductance of the postsynaptic cell <italic>I</italic> is increased by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline18.gif"/></alternatives></inline-formula> for excitatory synapses and by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline19.gif"/></alternatives></inline-formula> for inhibitory synapses. The input conductances decay exponentially with time constants <italic>&#x03C4;<sup>E</sup></italic> &#x003D; 5 ms and <italic>&#x03C4;<sup>I</sup></italic> &#x003D; 10 ms. The dynamics of the total excitatory conductance is described by
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="069641_eqn3.gif"/></alternatives>
</disp-formula></p>
<p>Here the sum runs over the presynaptic projections <italic>j</italic> and over the sequence of spikes <italic>f</italic> from each projection. The time of the <italic>f</italic><sup>th</sup> spike from neuron <italic>j</italic> is denoted by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline20.gif"/></alternatives></inline-formula>, and <italic>&#x03B4;</italic> is the Dirac delta function. The inhibitory conductance <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline21.gif"/></alternatives></inline-formula> is described analogously.</p>
<p>Amplitudes of recurrent excitatory conductances and excitatory conductances on inhibitory neurons are denoted with <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline22.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline23.gif"/></alternatives></inline-formula>, respectively. If not stated otherwise, all excitatory conductance amplitudes are fixed and equal <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline24.gif"/></alternatives></inline-formula>, which results in EPSPs with an amplitude of &#x2248; 0.1 mV at resting potential. The recurrent inhibitory synapses are also constant <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline25.gif"/></alternatives></inline-formula> while the inhibitory-to-excitatory conductances <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline26.gif"/></alternatives></inline-formula> are variable (see below). Irrespectively of the synaptic type, the delay between a presynaptic spike and a postsynaptic response onset is always 2 ms.</p>
</sec>
<sec id="s4b"><title>Network model</title>
<p>The modelled network consists of <italic>N <sup>E</sup></italic> &#x003D; 20,000 excitatory and <italic>N <sup>I</sup></italic> &#x003D; 5,000 inhibitory neurons. Our results do not critically depend on the network size (see Section &#x2018;Scaling the network size&#x2019; below). Initially, all neurons are randomly connected with a sparse probability <italic>p</italic><sub>rand</sub> &#x003D; 0.01.</p>
<p>A cell assembly is defined as a group of recurrently connected excitatory and inhibitory neurons (<xref rid="fig1" ref-type="fig">Fig 1A</xref>). The assembly is formed by picking <italic>M</italic> excitatory and <italic>M/</italic>4 inhibitory neurons from the network; every pair of pre- and post-synaptic neurons within the assembly is randomly connected with probability <italic>p</italic><sub>rc</sub>. The new connections are created independently and in addition to the already existing ones. Thus, if by chance two neurons have a connection due to the background connectivity and are connected due to the participation in an assembly, then the synaptic weight between them is simply doubled. Unless stated otherwise, assemblies are hence formed by additional connections rather than stronger synapses.</p>
<p>In the random network, we embed 10 non-overlapping assemblies with size <italic>M</italic> &#x003D; 500 if not stated otherwise. The groups of excitatory neurons are connected in a feedforward fashion, and a neuron from one group projects to a neuron of the subsequent group with probability <italic>p</italic><sub>ff</sub> (<xref rid="fig1" ref-type="fig">Fig 1B</xref>). Such a feedforward connectivity is reminiscent of a synfire chain. However, classical synfire chains do not have recurrent connections (<italic>p</italic><sub>rc</sub> &#x003D; 0, <italic>p</italic><sub>ff</sub> &#x003E; 0), while here, neurons within a group are recurrently connected even beyond the random background connectivity (<italic>p</italic><sub>rc</sub> &#x003E; 0, <italic>p</italic><sub>ff</sub> &#x003E; 0). We will refer to such a sequence as an &#x201C;assembly sequence&#x201D;. By varying the connectivity parameters <italic>p</italic> <sub>rc</sub>and <italic>p</italic><sub>ff</sub>, the network structure can be manipulated to obtain different network types (<xref rid="fig1" ref-type="fig">Fig 1C</xref>). In the limiting case where feedforward connections are absent (<italic>p</italic><sub>rc</sub> &#x003E; 0, <italic>p</italic><sub>ff</sub> &#x003D; 0) the network contains only largely disconnected Hebbian assemblies. In contrast, in the absence of recurrent connections (<italic>p</italic><sub>rc</sub> &#x003D; 0, <italic>p</italic><sub>ff</sub> &#x003E; 0), the model is reduced to a synfire chain embedded in a recurrent network. Structures with both recurrent and feedforward connections correspond to Hebbian assembly sequences.</p>
<p>To keep the network structure as simple as possible and to be able to focus on mechanisms underlying replay, we use non-overlapping assemblies and we do not embed more than 10 groups. Nevertheless, additional simulations with overlapping assemblies and longer sequences (results not shown) indicate that our approach is in line with previous results on memory capacity [<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c60">60</xref>, <xref ref-type="bibr" rid="c89">89</xref>]. Advancing the theory of memory capacity is, however, beyond the scope of this manuscript.</p>
</sec>
</sec>
<sec id="s5"><title>Balancing the network</title>
<p>A naive implementation of the heterogeneous network as described above leads, in general, to dynamics characterized by large population bursts of activity. To overcome this epileptiform activity and ensure that neurons fire asynchronously and irregularly (AI network state), the network should operate in a balanced regime. In the balanced state, large excitatory currents are compensated by large inhibitory currents, as shown <italic>in vivo</italic> [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c73">73</xref>] and <italic>in vitro</italic>[<xref ref-type="bibr" rid="c101">101</xref>]. In this regime, fluctuations of the input lead to highly irregular firing [<xref ref-type="bibr" rid="c92">92</xref>, <xref ref-type="bibr" rid="c93">93</xref>].</p>
<p>Several mechanisms were proposed to balance numerically simulated neural networks. One method involves structurally modifying the network connectivity to ensure that neurons receive balanced excitatory and inhibitory inputs [<xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c81">81</xref>]. It was shown that a short-term plasticity rule [<xref ref-type="bibr" rid="c91">91</xref>] in a fully connected network can also adjust the irregularity of neuronal firing [<xref ref-type="bibr" rid="c8">8</xref>].</p>
<p>Here, we balance the network using the inhibitory-plasticity rule [<xref ref-type="bibr" rid="c94">94</xref>]. All inhibitory-to-excitatory synapses are subject to a spike-timing-dependent plasticity (STDP) rule where near-coincident pre- and postsynaptic firing potentates the inhibitory synapse while presynaptic spikes alone cause depression. A similar STDP rule with a symmetric temporal window was recently reported in the layer 5 of the auditory cortex [<xref ref-type="bibr" rid="c22">22</xref>].</p>
<p>To implement the plasticity rule in a synapse, we first assign a synaptic trace variable <italic>x<sub>i</sub></italic> to every neuron <italic>i</italic> such that <italic>x<sub>i</sub></italic> is incremented with each spike of the neuron and decays with a time constant <italic>&#x03C4;</italic><sub>STDP</sub> &#x003D; 20 ms:</p>
<disp-formula id="ueqn8">
<alternatives><graphic xlink:href="069641_ueqn8.gif"/></alternatives>
</disp-formula>
<p>The synaptic conductance <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline28.gif"/></alternatives></inline-formula> from inhibitory neuron <italic>j</italic> to excitatory neuron <italic>i</italic> is initialized with value <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline29.gif"/></alternatives></inline-formula> and is updated at the times of pre/post-synaptic events:</p>
<disp-formula id="ueqn9">
<alternatives><graphic xlink:href="069641_ueqn9.gif"/></alternatives>
</disp-formula>
<p>where 0 &#x003C; <italic>&#x03B7;</italic> &#x226A; 1 is the learning-rate parameter, and the bias <italic>&#x03B1;</italic> &#x003D; 2<italic>&#x03C1;</italic><sub>0</sub> <italic>&#x03C4;</italic><sub>STDP</sub> is determined by the desired firing rate <italic>&#x03C1;</italic><sub>0</sub> of the excitatory postsynaptic neurons. In all simulations, <italic>&#x03C1;</italic><sub>0</sub> has been set to 5 spikes/sec, which is at the upper bound of the wide range of rates that were reported in the literature: e.g., 1 &#x2212;3 spikes/sec in [<xref ref-type="bibr" rid="c21">21</xref>]; 3 &#x2212;6 spikes/sec in [<xref ref-type="bibr" rid="c52">52</xref>]; 1 &#x2212; 76 spikes/sec in [<xref ref-type="bibr" rid="c28">28</xref>]; 0.43 &#x2212;3.60 spikes/sec in [<xref ref-type="bibr" rid="c16">16</xref>]; 1 &#x2212; 11 spikes/sec in [<xref ref-type="bibr" rid="c27">27</xref>].</p>
<p>An implementation of the described STDP rule drives typically the network into a balanced state. The excitatory and the inhibitory input currents balance each other and keep the membrane potential just below threshold while random fluctuations drive the firing (<xref rid="fig2" ref-type="fig">Fig 2A,B</xref>). The specific conditions to be met for a successful balance are discussed in the Results section.</p>
<p>In the AI network regime, any perturbation to the input of an assembly will lead to a transient perturbation in the firing rate of the neurons within it. Moreover, because of the recurrent connections, even small perturbations can lead to large responses. This phenomenon of transient pattern completion is known as balanced amplification [<xref ref-type="bibr" rid="c72">72</xref>], where it is essential that each assembly has excitatory and inhibitory neurons. Another advantage of the inhibitory subpopulations is the rapid negative feedback that can lead to enhanced memory capacity of the network [<xref ref-type="bibr" rid="c45">45</xref>].</p>
<sec id="s5a"><title>Simulations and data analysis</title>
<p>Each network simulation consists of 3 main phases:</p>
<sec id="s5a1">
<label>1.</label><title>Balancing the network</title>
<p>Initially, the population activity is characterized by massive population bursts with varying sizes (avalanches). During a first phase, the network (random network with embedded phase sequence) is balanced for 50 seconds with decreasing learning rate (0.005 &#x2265; &#x03B7; &#x2265; 0.00001) for the plasticity on the inhibitory-to-excitatory synapses. During this learning, the inhibitory plasticity shapes the activity, finally leading to AI firing of the excitatory population. Individual excitatory neurons then fire roughly with the target firing rate of 5 spikes/sec, while inhibitory neurons have higher firing rates of around 20 spikes/sec, which is close to rates reported in the hippocampus [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. After 50 seconds simulation time, the network is typically balanced.</p>
</sec>
<sec id="s5a2">
<label>2.</label><title>Reliability and quality of replay</title>
<p>In a second phase, the plasticity is switched off to be able to probe an unchanging network with external cue stimulations. All neurons from the first group/assembly are simultaneously stimulated by an external input so that all neurons fire once. The stimulation is mimicked by adding an excitatory conductance in Eq 3 (<sup>g<sub>max</sub></sup> &#x003D; 3 nS) that is sufficient to evoke a spike in each neuron. For large enough connectivities (<italic>p</italic><sub>rc</sub> and <italic>p</italic><sub>ff</sub>), the generated pulse packet of activity propagates through the sequence of assemblies, resulting in a replay. For too small connectivities, the activity does not propagate. For excessively high connectivities, the transient response of one group results in a burst in the next group and even larger responses in the subsequent groups, finally leading to epileptiform population bursts of activity (<xref rid="fig3" ref-type="fig">Fig 3</xref>).</p>
<p>To quantify the propagation from group to group and to account for abnormal activity, we introduce a quality measure of replay. The activity of a group is measured by calculating the population firing rate of the underlying neurons smoothed with a Gaussian window of 2 ms width. We extract peaks of the smoothed firing rate that exceed a threshold of 30 spikes/sec. A group is considered to be activated at the time at which its population firing rate hits its maximum and is above the threshold rate. Activity propagation from one group to the next is considered to be successful if one group activates the next one within a delay between 2 and 20 ms. A typical delay is about 5 ms, but in the case of extremely small <italic>p</italic><sub>ff</sub> and large <italic>p</italic><sub>rc</sub> the time of propagation can take &#x223C; 15 ms. Additional rules are imposed to account for exceeding activity and punish replays that lead to run-away firing. First, if the activity of an assembly exceeds a threshold of 180 spikes/sec (value is chosen manually for best discrimination), the group is considered as bursting, and thus, the replay is considered as failed. Second, if the assembly activity displays 2 super-threshold peaks that succeed each other within 30 ms, the replay is unsuccessful. Third, a &#x201C;dummy group&#x201D; (of size <italic>M</italic>) from the background neurons is used as a proxy for detecting activations of the whole network. In case that the dummy group is activated during an otherwise successful replay, the replay is failed. Thus, for each stimulation the &#x201C;quality of replay&#x201D; has a value of 1 for successful and a value of 0 for unsuccessful replays. The quality of replay for each set of parameters (<xref rid="fig3" ref-type="fig">Fig 3</xref>) is an average from multiple <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline31.gif"/></alternatives></inline-formula> stimulations of 5 different realizations of each network.</p>
<p>Additionally, we test the ability of the assembly sequence to complete a pattern by stimulating only a fraction of the neurons in the first group (<xref ref-type="fig" rid="fig4">Fig 4</xref>). Analogously to the full stimulation, the quality of replay is measured.</p>
</sec>
<sec id="s5a3">
<label>3.</label><title>Spontaneous activity</title>
<p>In the last phase of the simulations, no specific input is applied to the assemblies. As during the first phase of the simulation, the network is driven solely by the constant-current input <italic>I</italic><sup>const</sup> &#x003D; 200 pA applied to each neuron, and plasticity is switched off.</p>
<p>During this state, we quantify spontaneous replay (<xref rid="fig4" ref-type="fig">Fig 5</xref>). Whenever the last assembly is activated and if this activation has propagated through at least three previous assemblies, we consider this event as a spontaneous replay. Here, we apply the quality measure of replay, where bursty replays are disregarded. Additionally, we quantify the dynamic state of the network by the firing rate, the irregularity of firing, and the synchrony of a few selected groups from the sequence. The irregularity is measured as the average coefficient of variation of inter-spike intervals of the neurons within a group. As a measure of synchrony between 2 neurons, we use the cross-correlation coefficient of their spike trains binned in 5-ms windows. The group synchrony is the average synchrony between all pairs of neurons in a group.</p>
</sec>
</sec>
<sec id="s5b"><title>Mean-field analysis</title>
<p>To analytically describe the conditions for a successful sequence replay, we portray the network activity during replay using a linear model. Approximating the network dynamics with a system of linear differential equations, we estimate a lower bound for the connectivities required for a successful replay.</p>
<p>The dynamics of an assembly <italic>i</italic> (<xref rid="fig1" ref-type="fig">Fig 1A, B</xref>) in the AI state is approximated by two differential equations:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="069641_eqn4.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline32.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline33.gif"/></alternatives></inline-formula>are the deviations of the population firing rates of the excitatory (E) and inhibitory (I) populations from the spontaneous firing rates <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline34.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline35.gif"/></alternatives></inline-formula>, respectively.</p>
<p>The parameter <italic>w</italic><sub>rc</sub> and the term <italic>&#x2212;kw</italic><sub>rc</sub> are the respective strengths of the excitatory and the inhibitory recurrent projections. The constant <italic>k</italic> describes the relative strength of the recurrent inhibition vs. excitation; for a balanced network, we assume that inhibition balances or dominates excitation, e.g., <italic>k</italic> &#x2265; 1. The weight <italic>w</italic><sub>rc</sub> is proportional to the average number <italic>M p</italic><sub>rc</sub> of recurrent synapses a neuron receives, and proportional to the synaptic strength <italic>g<sup>E</sup></italic>. The function <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline36.gif"/></alternatives></inline-formula> describes the external input to the assembly from the rest of the network. In this mean-field analysis, we neglect the influence of the noise on the network dynamics. Activities <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline37.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline38.gif"/></alternatives></inline-formula> are assumed to approach the steady state 0 with a time constant <italic>&#x03C4;</italic>.</p>
<p>The excitatory assemblies are sequentially connected, and we denote the strength of the feedforward projections as <italic>w</italic><sub>ff</sub>. The feedforward drive can be represented as an external input to an assembly:
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn1.gif"/></alternatives>
</disp-formula></p>
<p>Taking into account the feedforward input to population <italic>i</italic> from the preceding excitatory population <italic>i &#x2212;</italic>1, Eq 4 can be rewritten as
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="069641_eqn5.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline39.gif"/></alternatives></inline-formula> the 2-dimensional vector of firing rates in group <italic>i</italic>.</p>
<p>From previous theoretical studies [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c92">92</xref>, <xref ref-type="bibr" rid="c93">93</xref>] we know that in the AI state the population time constant <italic>&#x03C4;</italic> can be much smaller than the membrane time constant of individual neurons. This means that a population of neurons can react faster to external input than individual neurons. Assuming that the time duration of a pulse packet in group <italic>i &#x2212;</italic>1 is much longer than the population time constant <italic>&#x03C4;</italic>in group <italic>i</italic>, wecan consider the solution of the stationary state <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline40.gif"/></alternatives></inline-formula> as an adequate approximation. Thus, by setting the left-hand side of Eq 5 to zero, we can express the firing rate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline41.gif"/></alternatives></inline-formula> as a function of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline42.gif"/></alternatives></inline-formula>
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn2.gif"/></alternatives>
</disp-formula></p>
<p>In the special case of a balanced network where <italic>k</italic> &#x003D; 1, the relation can be simplified further:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="069641_eqn6.gif"/></alternatives>
</disp-formula>
where
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="069641_eqn7.gif"/></alternatives>
</disp-formula>
is the &#x201C;effective feedforward connectivity&#x201D;. Interestingly, the recurrent connections effectively scale up the efficiency of the feedforward connections and facilitate the propagation of activity. For small <italic>&#x043A;</italic>, i.e. <italic>&#x043A;</italic> &#x226A; 1, even large changes of the firing rate in group <italic>i &#x2013;</italic>1 do not alter the rate in group <italic>i</italic>. For <italic>&#x043A;</italic> &#x003C; 1, the pulse packet will steadily decrease while propagating from one group to another as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline43.gif"/></alternatives></inline-formula> On the other hand, if &#x043A; &#x003D; 1, the propagation of a pulse packet is expected to be stable. In the case of <italic>&#x043A;</italic> &#x003E;1, any fluctuation of firing rate in one assembly will lead to a larger fluctuation in the following assembly.</p>
<p>To connect the analytical calculations to the numerical simulations, we again note that a total connection strength is proportional to the number of inputs a neuron is receiving (e.g., the product of group size <italic>M</italic> and connection probability) and proportional to the synaptic strength:
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="069641_eqn8.gif"/></alternatives>
</disp-formula>
where <italic>M</italic> is the group size, and <italic>p</italic><sub>rc</sub> and <italic>p</italic><sub>ff</sub> are the recurrent and feedforward connectivities, respectively. <italic>g<sup>E</sup></italic>is the conductance of an excitatory recurrent synapse within a group, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline44.gif"/></alternatives></inline-formula> is the conductance of feedforward synapses between groups. Unless stated otherwise, we assume <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline45.gif"/></alternatives></inline-formula> The parameter <italic>c</italic> is related to the slope of the neurons&#x2019; input-output transfer function.</p>
<p>Before representing <italic>&#x043A;</italic> as function of the connectivities <italic>p</italic><sub>ff</sub> and <italic>p</italic><sub>rc</sub>, we estimate the parameter <italic>c</italic>. By fitting the critical value <italic>&#x043A;</italic>(<italic>p</italic><sub>rc</sub> &#x003D; 0.08, <italic>p</italic><sub>ff</sub> &#x003D; 0.04) &#x003D; 1 from the simulation results (<xref rid="fig3" ref-type="fig">Fig 3</xref>), we find <italic>c</italic> &#x003D; 0.25 nS<sup>&#x2212;1</sup>. This value of <italic>c</italic> is used in all further analytical estimations for the effective connectivity <italic>&#x043A;</italic>. However, this procedure does not show us how <italic>c</italic> depends on various parameters, e.g., conductances, time constants, network size, etc. Therefore, the next subsection deals with deriving an explicit expression for the transfer function slope <italic>c</italic>.</p>
<p>In summary, the lower bound for the connectivities for a successful replay can be described as
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn3.gif"/></alternatives>
</disp-formula>
which is represented as a black line in <xref rid="fig3" ref-type="fig">Figs 3</xref> and <xref rid="fig4" ref-type="fig">5</xref>. For <xref rid="fig5" ref-type="fig">Figs 6</xref> and <xref rid="fig6" ref-type="fig">7</xref>, the black line is calculated analogously using the same constant <italic>c</italic> &#x003D; 0.25 nS<sup>&#x2212;1</sup>.</p>
</sec>
<sec id="s5c"><title>Calculating the slope <italic>c</italic></title>
<p>In the previous section, the constant <italic>c</italic> was manually fitted to a value of 0.25 nS<sup>&#x2212;1</sup> to match analytical and numerical results. Here we express <italic>c</italic> analytically by utilizing a non-linear neuronal model and by using the parameter values from the simulations.</p>
<p>The resting firing rate <italic>&#x03C1;</italic> of a neuronal population that is in an asynchronous irregular (AI) regime can be expressed as a function of the mean <italic>&#x00B5;</italic> and the standard deviation <italic>&#x03C3;</italic> of the membrane potential distribution [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c79">79</xref>]:
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="069641_eqn9.gif"/></alternatives>
</disp-formula>
where the sums over <italic>k</italic> run over the different synaptic contributions, <italic>&#x03C1;<sub>k</sub></italic> is the corresponding presynaptic firing rate, and <italic>J<sub>k</sub></italic> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline46.gif"/></alternatives></inline-formula> are the integrals over time of the PSP and the square of the PSP from input <italic>k</italic>, respectively. Here PSPs are estimated for the conductance-based integrate-and-fire neuron from Eq 2 for voltage values near the firing threshold <italic>V</italic><sup>th</sup>,
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn4.gif"/></alternatives>
</disp-formula>
where <italic>&#x03C4;</italic> is the membrane time constant, <italic>&#x03C4;<sup>syn</sup></italic> is the synaptic time constant, <italic>V<sup>syn</sup></italic> is the synaptic reversal potential, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline47.gif"/></alternatives></inline-formula> is the synaptic conductance of connection <italic>k</italic>. Connections can be either excitatory or inhibitory.</p>
<p>Here we consider a network with random connections only, and look at a subpopulation of size <italic>M</italic>, where <italic>M &#x226A; N<sup>E</sup></italic>. For a more convenient analytical treatment, the recurrent connections within the group are neglected. This assumption does not affect the estimation of the transfer function slope, as <italic>c</italic> is independent on the type of inputs. The firing rate-fluctuations of the neuronal group are calculated as in Eq 6:
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="069641_eqn10.gif"/></alternatives>
</disp-formula></p>
<p>The membrane potential of an excitatory neuron from this subpopulation has several contributions: <italic>N <sup>E</sup>p<sub>rand</sub></italic> excitatory inputs with firing rate <italic>&#x03C1;<sub>0</sub></italic> and efficacy <italic>J<sup>E</sup></italic>; inhibitory inputs due to the background connectivity: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline48.gif"/></alternatives></inline-formula> injected constant current: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline49.gif"/></alternatives></inline-formula>; and input from an external group: <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline50.gif"/></alternatives></inline-formula>. In summary, we find:
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn5.gif"/></alternatives>
</disp-formula></p>
<p>The standard deviation of the membrane potential is then, accordingly:
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn6.gif"/></alternatives>
</disp-formula></p>
<p>In the case of uncorrelated inputs, the following approximation can be used for the firing rate estimation [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c79">79</xref>]:
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="069641_eqn11.gif"/></alternatives>
</disp-formula>
where <italic>&#x03C4;<sub>rp</sub></italic> is the refractory period, and <italic>V</italic><sup>th</sup>and <italic>V</italic><sup>rest</sup> are membrane threshold and reset potential, respectively (see also section &#x201C;Neural Model&#x201D;).</p>
<p>To find the constant <italic>c</italic> used in the linear model, we estimate the firing rate <italic>&#x03C1;</italic> from Eq 11 and substitute in Eq 10, assuming a linear relation between firing-rate fluctuations:
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="069641_eqn12.gif"/></alternatives>
</disp-formula>
and find:
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="069641_eqn13.gif"/></alternatives>
</disp-formula></p>
<p>Before calculating the constant <italic>c</italic> according to the method presented above, a preliminary step needs to be taken. As we set the firing rate of the excitatory population in the network to a fixed value <italic>&#x03C1;</italic><sub>0</sub> &#x003D; 5 spikes/sec, there are two variables remaining unknown: the firing rate of the inhibitory population <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline51.gif"/></alternatives></inline-formula> and the inhibitory-to-excitatory synaptic conductance <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline52.gif"/></alternatives></inline-formula> that changes due to synaptic plasticity. Therefore, we first solve a system of 2 equations for the firing rates of the excitatory and the inhibitory populations expressed as in Eq 11. Once the unknowns <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline53.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline54.gif"/></alternatives></inline-formula> are calculated, we can estimate <italic>&#x03C1;</italic>(<italic>&#x03C1;<sub>ext</sub></italic>) and <italic>c</italic> according to the method presented above. We note that the analytically calculated values of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline55.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline56.gif"/></alternatives></inline-formula> match the measured values in the simulations.</p>
<p>The value we get after applying the above mentioned method for estimation of <italic>c</italic> is 0.13 nS<sup>&#x2212;1</sup>. The fit corresponding to the estimate of <italic>c</italic> is shown in <xref rid="fig3" ref-type="fig">Fig 3</xref> with a white dashed line. It is worth noting that a slightly more involved calculation relying on the estimate <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline57.gif"/></alternatives></inline-formula> gives a similar result, concretely <italic>c</italic> &#x003D; 0.11 nS<sup>&#x2212;1</sup>.</p>
<p>Although the analytically calculated value <italic>c</italic> is a factor of 2 smaller than the manual fit <italic>c</italic> &#x003D; 0.25 nS<sup>&#x2212;1</sup>, it is qualitatively similar and not too far from describing the results for critical connectivity from the simulations.</p>
<p>The method applied above finds the slope of the transfer function for stationary firing rates. However, the spiking network replay is a fast and brief event, where a transient input in one assembly evokes a transient change in the output firing rate. The value discrepancy suggests that the transfer function of transients is even steeper than at the resting AI state.</p>
</sec>
<sec id="s5d"><title>Scaling the network size</title>
<p>So far we have been dealing with networks of fixed size <italic>N<sup>E</sup></italic> &#x003D; 20,000 neurons. How does the network size affect the embedding of assembly sequences? Is it possible to change the network size but keep the assembly size fixed?</p>
<p>Scaling the network size while keeping the connectivity <italic>p<sub>rand</sub></italic> constant leads to a change in the number of inputs that a neuron receives, and therefore, affects the membrane potential distributions. To compare replays in networks with different sizes <italic>N <sup>E</sup></italic> but identical <italic>M</italic>, we need to assure that the signal-to-noise ratio is kept constant, and the easiest way is to keep both the signal and the noise constant, which requires to change connectivities <italic>p</italic><sub>rc</sub> and <italic>p</italic><sub>ff</sub> and conductances.</p>
<p>While scaling the network from the default network size <italic>N<sup>E</sup></italic> &#x003D; 20,000 to a size <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline58.gif"/></alternatives></inline-formula>, we see that the noise <italic>&#x03C3;</italic> scales as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline59.gif"/></alternatives></inline-formula> (Eq 9). To keep the input current fluctuations constant as we change <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline60.gif"/></alternatives></inline-formula>, all synaptic conductances are rescaled with a factor of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline61.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c92">92</xref>]. However, such a synaptic scaling leads to a change in the coupling between assemblies of fixed size <italic>M</italic>, which is proportional to the conductance. Therefore, the connectivities <italic>p</italic><sub>rc</sub> and <italic>p</italic><sub>ff</sub> are scaled with <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline62.gif"/></alternatives></inline-formula> to compensate the conductance decrease, leading to a constant coupling <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline63.gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline64.gif"/></alternatives></inline-formula> hence, a constant signal-to-noise ratio.</p>
<p>What is the impact of such a scaling on the network capacity to store sequences? The number of connections needed to store a sequence is changed by a factor <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline65.gif"/></alternatives></inline-formula> as we change <italic>p</italic><sub>rc</sub> and <italic>p</italic> <sub>ff</sub>. However, the number of background connections to each neuron is scaled with <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline66.gif"/></alternatives></inline-formula>, resulting in sparser memory representations in larger networks. More precisely, for a neuron participating in the sequence, the ratio of excitatory memory connections to the total number of excitatory connections is
<disp-formula>
<alternatives><graphic xlink:href="069641_ueqn7.gif"/></alternatives>
</disp-formula></p>
<p>Therefore, the proportion of connections needed for an association is scaled as <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline67.gif"/></alternatives></inline-formula> for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline68.gif"/></alternatives></inline-formula> To give a few numbers, <italic>u</italic> is equal to 0.23 for <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline69.gif"/></alternatives></inline-formula>, and <italic>u</italic> &#x003D; 0.09 for.<inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline70.gif"/></alternatives></inline-formula> Other parameter values are: <italic>M</italic> &#x003D; 500, <italic>p</italic><sub>rc</sub> &#x003D; <italic>p</italic><sub>ff</sub> &#x003D; 0.06, <italic>p<sub>rand</sub></italic> &#x003D; 0.01.</p>
<p>The chosen scaling rule is applicable for networks of simpler units such as binary neurons or current-based integrate-and-fire neurons [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c93">93</xref>]. This scaling is not valid in a strict mathematical framework for very large networks <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="069641_inline71.gif"/></alternatives></inline-formula> consisting of conductance-based integrate-and-fire neurons (see [<xref ref-type="bibr" rid="c77">77</xref>] for a detailed discussion).Simulations results, however, reveal that replays are possible in network sizes up to 2 &#x00B7; 10<sup>5</sup>neurons (results not shown).</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The authors thank Jos&#x00E9; Donoso, Andr&#x00E9; Holzbecher, and Jorge Jaramillo for insightful discussions and comments on the manuscript.</p>
</ack>
<ref-list><title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="other"><string-name><surname>Abeles</surname> <given-names>M.</given-names></string-name> <article-title>Corticonics: neural circuits of the cerebral cortex</article-title>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge UP</publisher-name>.; <year>1991</year>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Almeida-Filho</surname> <given-names>DG</given-names></string-name>, <string-name><surname>Lopes-dos-Santos</surname> <given-names>V</given-names></string-name>, <string-name><surname>Vasconcelos</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Miranda</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Tort</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Ribeiro</surname> <given-names>S.</given-names></string-name> <article-title>An investigation of Hebbian phase sequences as assembly graphs</article-title>. <source>Front Neural Circuits</source>. <year>2014</year>;<volume>8</volume>:<fpage>34</fpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Amit</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N.</given-names></string-name> <article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title>. <source>Cereb Cortex</source>.<year>1997</year>;<volume>7</volume>:,<fpage>237</fpage>&#x2013;<lpage>252</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Atwood</surname> <given-names>HL</given-names></string-name>, <string-name><surname>Wojtowicz</surname> <given-names>JM.</given-names></string-name> <article-title>Silent synapses in neural plasticity: current evidence</article-title>. <source>Learn Mem</source>. <year>1999</year>;<volume>6</volume>:<fpage>542</fpage>&#x2013;<lpage>571</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Aviel</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Horn</surname> <given-names>D</given-names></string-name>, <string-name><surname>Abeles</surname> <given-names>M.</given-names></string-name> <article-title>Synfire waves in small balanced networks</article-title>. <source>Neurocomput</source>. <year>2004</year>;<volume>58</volume>:<fpage>123</fpage>&#x2013;<lpage>127</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Aviel</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Mehring</surname> <given-names>C</given-names></string-name>, <string-name><surname>Abeles</surname> <given-names>M</given-names></string-name>, <string-name><surname>Horn</surname> <given-names>D.</given-names></string-name> <article-title>On embedding synfire chains in a balanced network</article-title>. <source>Neural Comput</source>. <year>2003</year>;<volume>15</volume>:<fpage>1321</fpage>&#x2013;<lpage>1340</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Aviel</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Pavlov</surname> <given-names>E</given-names></string-name>, <string-name><surname>Abeles</surname> <given-names>M</given-names></string-name>, <string-name><surname>Horn</surname> <given-names>D.</given-names></string-name> <article-title>Synfire chain in a balanced network</article-title>. <source>Neurocomput</source>. <year>2002</year>;<volume>44</volume>:<fpage>285</fpage>&#x2013;<lpage>292</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Barbieri</surname> <given-names>F</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N.</given-names></string-name> <article-title>Can attractor network models account for the statistics of firing during persistent activity in prefrontal cortex?</article-title> <source>Front Neurosci</source>. <year>2008</year>;<volume>2</volume>:<fpage>114</fpage>&#x2013;<lpage>122</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Bi</surname> <given-names>GQ</given-names></string-name>, <string-name><surname>Poo</surname> <given-names>MM.</given-names></string-name> <article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title>. <source>J Neurosci.</source> <year>1998</year>;<volume>18</volume>:<fpage>10464</fpage>&#x2013;<lpage>10472</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Bliss</surname> <given-names>TV</given-names></string-name>, <string-name><surname>L&#x00F8;mo</surname> <given-names>T.</given-names></string-name> <article-title>Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path</article-title>. <source>J Physiol</source>. <year>1973</year>;<volume>232</volume>:<fpage>331</fpage>&#x2013;<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Brea</surname> <given-names>J</given-names></string-name>, <string-name><surname>Senn</surname> <given-names>W</given-names></string-name>, <string-name><surname>Pfister</surname> <given-names>JP.</given-names></string-name> <article-title>Matching recall and storage in sequence learning with spiking neural networks</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>:<fpage>9565</fpage>&#x2013;<lpage>9575</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Brown</surname> <given-names>GT.</given-names></string-name> <article-title>On the nature of the fundamental activity of the nervous centre: together with an analysis of the conditioning of rhythmic activity in progression, and a theory of the evolution of function in the nervous systems</article-title>. <source>J Physiol</source>. <year>1914</year>;<volume>48</volume>:<fpage>18</fpage>&#x2013;<lpage>46</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Brunel</surname> <given-names>N.</given-names></string-name> <article-title>Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons</article-title>. <source>J Comput Neurosci</source>. <year>2000</year>;<volume>8</volume>:<fpage>183</fpage>&#x2013;<lpage>208</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Buzsa&#x00E9;ki</surname> <given-names>G.</given-names></string-name> <article-title>Two-stage model of memory trace formation: a role for &#x201C;noisy&#x201D; brain states</article-title>. <source>Neurosci</source>. <year>1989</year>;<volume>31</volume>:<fpage>551</fpage>&#x2013;<lpage>570</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Cafaro</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rieke</surname> <given-names>F.</given-names></string-name> <article-title>Noise correlations improve response fidelity and stimulus encoding</article-title>. <source>Nature</source>. <year>2010</year>;<volume>468</volume>:<fpage>964</fpage>&#x2013;<lpage>967</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Cheng</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ji</surname> <given-names>D.</given-names></string-name> <article-title>Rigid firing sequences undermine spatial memory codes in a neurodegenerative mouse model</article-title>. <source>eLife</source>. <year>2013</year>;<volume>2:e00647</volume>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bu&#x00E4;sing</surname> <given-names>L</given-names></string-name>, <string-name><surname>Vasilaki</surname> <given-names>E</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Connectivity reflects coding: a model of voltage-based STDP with homeostasis</article-title>. <source>Nat Neurosci</source>. <year>2010</year>;<volume>13</volume>:<fpage>344</fpage>&#x2013;<lpage>352</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Contreras</surname> <given-names>EJB</given-names></string-name>, <string-name><surname>Schjetnan</surname> <given-names>AGP</given-names></string-name>, <string-name><surname>Muhammad</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bartho</surname> <given-names>P</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Kolb</surname> <given-names>B</given-names></string-name>, <string-name><surname>Gruber</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Luczak</surname> <given-names>A.</given-names></string-name> <article-title>Formation and reverberation of sequential neural activity patterns evoked by sensory stimulation are enhanced during cortical desynchronization</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>79</volume>:<fpage>555</fpage>&#x2013;<lpage>566</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Cossart</surname> <given-names>R</given-names></string-name>, <string-name><surname>Aronov</surname> <given-names>D</given-names></string-name>, <string-name><surname>Yuste</surname> <given-names>R.</given-names></string-name> <article-title>Attractor dynamics of network UP states in the neocortex</article-title>. <source>Nature</source>. <year>2003</year>;<volume>423</volume>:<fpage>283</fpage>&#x2013;<lpage>288</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Cossell</surname> <given-names>L</given-names></string-name>, <string-name><surname>Iacaruso</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Muir</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Houlton</surname> <given-names>R</given-names></string-name>, <string-name><surname>Sader</surname> <given-names>EN</given-names></string-name>, <string-name><surname>Ko</surname> <given-names>H</given-names></string-name>, <string-name><surname>Hofer</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Mrsic-Flogel</surname> <given-names>TD.</given-names></string-name> <article-title>Functional organization of excitatory synaptic strength in primary visual cortex</article-title>. <source>Nature</source>. <year>2015</year>;<volume>518</volume>:<fpage>399</fpage>&#x2013;<lpage>403</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Csicsvari</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hirase</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mamiya</surname> <given-names>A</given-names></string-name>, <string-name><surname>Buzsa&#x00E9;ki</surname> <given-names>G.</given-names></string-name> <article-title>Ensemble patterns of hippocampal CA3-CA1 neurons during sharp wave-associated population events</article-title>. <source>Neuron</source>. <year>2000</year>;<volume>28</volume>:<fpage>585</fpage>&#x2013;<lpage>594</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>D&#x2019;amour</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC.</given-names></string-name> <article-title>Inhibitory and excitatory spike-timing-dependent plasticity in the auditory cortex</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>86</volume>:<fpage>514</fpage>&#x2013;<lpage>528</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Diba</surname> <given-names>K</given-names></string-name>, <string-name><surname>Buzsa&#x00E9;ki</surname> <given-names>G.</given-names></string-name> <article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title>. <source>Nat Neurosci</source>. <year>2007</year>;<volume>10</volume>:<fpage>1241</fpage>&#x2013;<lpage>1242</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Diekelmann</surname> <given-names>S</given-names></string-name>, <string-name><surname>Born</surname> <given-names>J.</given-names></string-name> <article-title>The memory function of sleep</article-title>. <source>Nat Rev Neurosci</source>. <year>2010</year>;<volume>11</volume>:<fpage>114</fpage>&#x2013;<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gewaltig</surname> <given-names>MO</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A.</given-names></string-name> <article-title>Stable propagation of synchronous spiking in cortical neural networks</article-title>. <source>Nature</source>. <year>1999</year>;<volume>402</volume>:<fpage>529</fpage>&#x2013;<lpage>533</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Dragoi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S.</given-names></string-name> <article-title>Distinct preplay of multiple novel spatial experiences in the rat</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2013</year>;<volume>110</volume>:<fpage>9100</fpage>&#x2013;<lpage>9105</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>English</surname> <given-names>DF</given-names></string-name>, <string-name><surname>Peyrache</surname> <given-names>A</given-names></string-name>, <string-name><surname>Stark</surname> <given-names>E</given-names></string-name>, <string-name><surname>Roux</surname> <given-names>L</given-names></string-name>, <string-name><surname>Vallentin</surname> <given-names>D</given-names></string-name>, <string-name><surname>Long</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Buzs&#x00E0;ki</surname> <given-names>G.</given-names></string-name> <article-title>Excitation and inhibition compete to control spiking during hippocampal ripples: intracellular study in behaving mice</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>:<fpage>16509</fpage>&#x2013;<lpage>16517</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Felsen</surname> <given-names>G</given-names></string-name>, <string-name><surname>Touryan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Han</surname> <given-names>F</given-names></string-name>, <string-name><surname>Dan</surname> <given-names>Y.</given-names></string-name> <article-title>Cortical sensitivity to visual features in natural scenes</article-title>. <source>PLoS Biol</source>. <year>2005</year>;<volume>3:e342</volume>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Feng</surname> <given-names>T</given-names></string-name>, <string-name><surname>Silva</surname> <given-names>D</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>DJ.</given-names></string-name> <article-title>Dissociation between the experience-dependent development of hippocampal theta sequences and single-trial phase precession</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>:<fpage>4980</fpage>&#x2013;<lpage>4902</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA.</given-names></string-name> <article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title>. <source>Nature</source>. <year>2006</year>;<volume>440</volume>:<fpage>680</fpage>&#x2013;<lpage>683</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Time structure of the activity in neural network models</article-title>. <source>Phys Rev E</source>. <year>1995</year>;<volume>51</volume>:<fpage>738</fpage>&#x2013;<lpage>758</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>, <string-name><surname>Kempter</surname> <given-names>R</given-names></string-name>, <string-name><surname>van Hemmen</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Wagner</surname> <given-names>H.</given-names></string-name> <article-title>A neuronal learning rule for sub-millisecond temporal coding</article-title>. <source>Nature</source>. <year>1996</year>;<volume>386</volume>:<fpage>76</fpage>&#x2013;<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="book"><string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>, <string-name><surname>Kistler</surname> <given-names>WM.</given-names></string-name> <source>Spiking neuron models: Single neurons, population, plasticity</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge UP</publisher-name>.;<year>2002</year>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Goodman</surname> <given-names>DFM</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R.</given-names></string-name> <article-title>The brian simulator</article-title>. <source>Front Neurosci</source>. <year>2009</year>;<volume>3</volume>:<fpage>192</fpage>&#x2013;<lpage>197</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Graupner</surname> <given-names>M</given-names></string-name>, <string-name><surname>Brunel</surname> <given-names>N.</given-names></string-name> <article-title>Calcium-based plasticity model explains sensitivity of synaptic changes to spike pattern, rate, and dendritic location</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2012</year>;<volume>109</volume>:<fpage>3991</fpage>&#x2013;<lpage>3996</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Halff</surname> <given-names>AW</given-names></string-name>, <string-name><surname>G&#x00E9;omez-Varela</surname> <given-names>D</given-names></string-name>, <string-name><surname>John</surname> <given-names>D</given-names></string-name>, <string-name><surname>Berg</surname> <given-names>DK.</given-names></string-name> <article-title>A novel mechanism for nicotinic potentiation of glutamatergic synapses</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>:<fpage>2051</fpage>&#x2013;<lpage>2064</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Hahn</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bujan</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Fr&#x00E9;egnac</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kumar</surname> <given-names>A.</given-names></string-name> <article-title>Communication through resonance in spiking neuronal networks</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10:e1003811</volume>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Hanse</surname> <given-names>E</given-names></string-name>, <string-name><surname>Seth</surname> <given-names>H</given-names></string-name>, <string-name><surname>Riebe</surname> <given-names>I.</given-names></string-name> <article-title>AMPA-silent synapses in brain development and pathology</article-title>. <source>Nat Rev Neurosci</source>. <year>2013</year>;<volume>14</volume>:<fpage>839</fpage>&#x2013;<lpage>850</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Hasselmo</surname> <given-names>ME.</given-names></string-name> <article-title>Neuromodulation: acetylcholine and memory consolidation</article-title>. <source>Trends Cogn Sci</source>. <year>1999</year>;<volume>3</volume>:<fpage>351</fpage>&#x2013;<lpage>359</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Hasselmo</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Schnell</surname> <given-names>E</given-names></string-name>, <string-name><surname>Barkai</surname> <given-names>E.</given-names></string-name> <article-title>Dynamics of learning and recall at excitatory recurrent synapses and cholinergic modulation in rat hippocampal region CA3</article-title>. <source>J Neurosci</source>. <year>1995</year>;<volume>15</volume>:<fpage>5249</fpage>&#x2013;<lpage>5262</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="book"><string-name><surname>Hebb</surname> <given-names>DO.</given-names></string-name> <chapter-title>The organization of behavior: A neuropsychological theory</chapter-title>. <publisher-loc>New York</publisher-loc>.;<year>1949</year>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Hennequin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Non-normal amplification in random balanced neuronal networks</article-title>. <source>Phys Rev E</source>. <year>2012</year>;<volume>86:011909</volume>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Horn</surname> <given-names>D</given-names></string-name>, <string-name><surname>Levy</surname> <given-names>N</given-names></string-name>, <string-name><surname>Meilijson</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ruppin</surname> <given-names>E.</given-names></string-name> <article-title>Distributed synchrony of spiking neurons in a Hebbian cell assembly</article-title>. <source>Adv Neural Inf Process Syst</source>. <year>2000</year>;<volume>12</volume>:<fpage>129</fpage>&#x2013;<lpage>135</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Jahnke</surname> <given-names>S</given-names></string-name>, <string-name><surname>Memmesheimer</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Timme</surname> <given-names>M.</given-names></string-name> <article-title>Propagating synchrony in feed-forward networks</article-title>. <source>Front Comput Neurosci</source>. <year>2013</year>;<volume>7:153</volume>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Kammerer</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tejero-Cantero</surname> <given-names>A&#x00B4;</given-names></string-name>, <string-name><surname>Leibold</surname> <given-names>C.</given-names></string-name> <article-title>Inhibition enhances memory capacity: optimal feedback, transient replay and oscillations</article-title>. <source>J Comput Neurosci</source>. <year>2013</year>;<volume>34</volume>:<fpage>125</fpage>&#x2013;<lpage>136</lpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Kappel</surname> <given-names>D</given-names></string-name>, <string-name><surname>Nessler</surname> <given-names>B</given-names></string-name>, <string-name><surname>Maass</surname> <given-names>W.</given-names></string-name> <article-title>STDP installs in winner-take-all circuits an online approximation to hidden Markov model learning</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10:e1003511</volume>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Karlsson</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>LM.</given-names></string-name> <article-title>Awake replay of remote experiences in the hippocampus</article-title>. <source>Nature Neurosci</source>. <year>2009</year>;<volume>12</volume>:<fpage>913</fpage>&#x2013;<lpage>918</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Kempter</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>, <string-name><surname>van Hemmen</surname> <given-names>JL.</given-names></string-name> <article-title>Hebbian learning and spiking neurons</article-title>. <source>Phys Rev E</source>. <year>1999</year>;<volume>59</volume>:<fpage>4498</fpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Kenet</surname> <given-names>T</given-names></string-name>, <string-name><surname>Bibitchkov</surname> <given-names>D</given-names></string-name>, <string-name><surname>Tsodyks</surname> <given-names>M</given-names></string-name>, <string-name><surname>Grinvald</surname> <given-names>A</given-names></string-name>, <string-name><surname>Arieli</surname> <given-names>A.</given-names></string-name> <article-title>Spontaneously emerging cortical representations of visual attributes</article-title>. <source>Nature</source>. <year>2003</year>;<volume>425</volume>:<fpage>954</fpage>&#x2013;<lpage>956</lpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Klampfl</surname> <given-names>S</given-names></string-name>, <string-name><surname>Maass</surname> <given-names>W.</given-names></string-name> <article-title>Emergence of dynamic memory traces in cortical microcircuit models through STDP</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>:<fpage>11515</fpage>&#x2013;<lpage>11529</lpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Ko</surname> <given-names>H</given-names></string-name>, <string-name><surname>Hofer</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Pichler</surname> <given-names>B</given-names></string-name>, <string-name><surname>Buchanan</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Sj&#x00E4;ostr&#x00E4;om</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Mrsic-Flogel</surname> <given-names>TD.</given-names></string-name> <article-title>Functional specificity of local synaptic connections in neocortical networks</article-title>. <source>Nature</source>. <year>2011</year>;<volume>473</volume>:<fpage>87</fpage>&#x2013;<lpage>91</lpage>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Kowalski</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jonas</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pern&#x00E9;&#x0131;a-Andrade</surname> <given-names>AJ.</given-names></string-name> <article-title>Intrinsic membrane properties determine hippocampal differential firing pattern in vivo in anesthetized rats</article-title>. <source>Hippocampus</source>. <year>2015</year>;<volume>26</volume>:<fpage>668</fpage>&#x2013;<lpage>682</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Kruskal</surname> <given-names>PB</given-names></string-name>, <string-name><surname>Li</surname> <given-names>L</given-names></string-name>, <string-name><surname>MacLean</surname> <given-names>JN.</given-names></string-name> <article-title>Circuit reactivation dynamically regulates synaptic plasticity in neocortex</article-title>. <source>Nat Commun</source>. <year>2013</year>;<volume>4</volume>:<fpage>2574</fpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A.</given-names></string-name> <article-title>Conditions for propagating synchronous spiking and asynchronous firing rates in a cortical network model</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>:<fpage>5268</fpage>&#x2013;<lpage>5280</lpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A.</given-names></string-name> <article-title>Spiking activity propagation in neuronal networks: reconciling different perspectives on neural coding</article-title>. <source>Nature Rev Neurosci</source>. <year>2010</year>;<volume>11</volume>:<fpage>615</fpage>&#x2013;<lpage>627</lpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="book"><string-name><surname>Lashley</surname> <given-names>KS.</given-names></string-name> <chapter-title>The problem of serial order in behavior</chapter-title>. <source>In: Cerebral mechanisms in behavior</source> (Jeffress LA, ed), pp <fpage>112</fpage>&#x2013;<lpage>131</lpage>. <publisher-loc>New York: Wiley</publisher-loc>.;<year>1951</year>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>Lazar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Pipa</surname> <given-names>G</given-names></string-name>, <string-name><surname>Triesch</surname> <given-names>J.</given-names></string-name> <article-title>SORN: a self-organizing recurrent neural network</article-title>. <source>Front Comput Neurosci</source>. <year>2009</year>;<volume>3:23</volume>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>MA.</given-names></string-name> <article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>36</volume>:<fpage>1183</fpage>&#x2013;<lpage>1194</lpage>.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>Leibold</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kempter</surname> <given-names>R.</given-names></string-name> <article-title>Memory capacity for sequences in a recurrent network with biological constraints</article-title>. <source>Neural Comput</source>. <year>2006</year>;<volume>18</volume>:<fpage>904</fpage>&#x2013;<lpage>941</lpage>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Leibold</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kempter</surname> <given-names>R.</given-names></string-name> <article-title>Sparseness constrains the prolongation of memory lifetime via synaptic metaplasticity</article-title>. <source>Cereb Cortex</source>. <year>2008</year>;<volume>18</volume>:<fpage>67</fpage>&#x2013;<lpage>77</lpage>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Litwin-Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B.</given-names></string-name> <article-title>Slow dynamics and high variability in balanced cortical networks with clustered connections</article-title>. <source>Nat Neurosci</source>. <year>2012</year>;<volume>15</volume>:<fpage>1498</fpage>&#x2013;<lpage>1505</lpage>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Litwin-Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B.</given-names></string-name> <article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title>. <source>Nat Commun</source>. <year>2014</year>;<volume>5</volume>:<fpage>5319</fpage>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><surname>Luczak</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bartho&#x0060;</surname> <given-names>P</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD.</given-names></string-name> <article-title>Spontaneous events outline the realm of possible sensory responses in neocortical populations</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>62</volume>:<fpage>413</fpage>&#x2013;<lpage>425</lpage>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><surname>Malenka</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Bear</surname> <given-names>MF.</given-names></string-name> <article-title>LTP and LTD: an embarrassment of riches</article-title>. <source>Neuron</source>. <year>2004</year>;<volume>44</volume>:<fpage>5</fpage>&#x2013;<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>Marrosu</surname> <given-names>F</given-names></string-name>, <string-name><surname>Portas</surname> <given-names>C</given-names></string-name>, <string-name><surname>Mascia</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Casu</surname> <given-names>MA</given-names></string-name>, <string-name><surname>F&#x0060;a</surname> <given-names>M</given-names></string-name>, <string-name><surname>Giagheddu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Imperato</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gessa</surname> <given-names>GL.</given-names></string-name> <article-title>Microdialysis measurement of cortical and hippocampal acetylcholine release during sleep-wake cycle in freely moving cats</article-title>. <source>Brain Res</source>. <year>1995</year>;<volume>671</volume>:<fpage>329</fpage>&#x2013;<lpage>332</lpage>.</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><string-name><surname>Mehring</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hehl</surname> <given-names>U</given-names></string-name>, <string-name><surname>Kubo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A.</given-names></string-name> <article-title>Activity dynamics and propagation of synchronous spiking in locally connected random networks</article-title>. <source>Biol Cybern</source>. <year>2003</year>;<volume>88</volume>:<fpage>395</fpage>&#x2013;<lpage>408</lpage>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><string-name><surname>Memmesheimer</surname> <given-names>RM.</given-names></string-name> <article-title>Quantitative prediction of intermittent high-frequency oscillations in neural networks with supralinear dendritic interactions</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2010</year>;<volume>107</volume>:<fpage>11092</fpage>&#x2013;<lpage>11097</lpage>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><string-name><surname>Mishra</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>S</given-names></string-name>, <string-name><surname>Guzman</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Jonas</surname> <given-names>P.</given-names></string-name> <article-title>Symmetric spike timing-dependent plasticity at CA3-CA3 synapses optimizes storage and recall in autoassociative networks</article-title>. <source>Nat Commun</source>. <year>2016</year>;<volume>7:11552</volume>.</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><string-name><surname>Moldakarimov</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bazhenov</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sejnowski</surname> <given-names>TJ.</given-names></string-name> <article-title>Feedback stabilizes propagation of synchronous spiking in cortical neural networks</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2015</year>;<volume>112</volume>:<fpage>2545</fpage>&#x2013;<lpage>2550</lpage>.</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><string-name><surname>Morrison</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aertsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M.</given-names></string-name> <article-title>Spike-timing-dependent plasticity in balanced random networks</article-title>. <source>Neural Comput</source>. <year>2007</year>;<volume>19</volume>:<fpage>1437</fpage>&#x2013;<lpage>1467</lpage>.</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><string-name><surname>Mostafa</surname> <given-names>H</given-names></string-name>, <string-name><surname>Indiveri</surname> <given-names>G.</given-names></string-name> <article-title>Sequential activity in asymmetrically coupled winner-take-all circuits</article-title>. <source>Neural Comput</source>. <year>2014</year>;<volume>26</volume>:<fpage>1973</fpage>&#x2013;<lpage>2004</lpage>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><string-name><surname>Murphy</surname> <given-names>BK</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>KD.</given-names></string-name> <article-title>Balanced amplification: a new mechanism of selective amplification of neural activity patterns</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>61</volume>:<fpage>635</fpage>&#x2013;<lpage>648</lpage>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><string-name><surname>Okun</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lampl</surname> <given-names>I.</given-names></string-name> <article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title>. <source>Nat Neurosci</source>. <year>2008</year>;<volume>11</volume>:<fpage>535</fpage>&#x2013;<lpage>537</lpage>.</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><string-name><surname>Omura</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Carvalho</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Inokuchi</surname> <given-names>K</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T.</given-names></string-name> <article-title>A lognormal recurrent network model for burst generation during hippocampal sharp waves</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>:<fpage>14585</fpage>&#x2013;<lpage>145601</lpage>.</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><string-name><surname>Pfister</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Triplets of spikes in a model of spike timing-dependent plasticity</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>:<fpage>9673</fpage>&#x2013;<lpage>9682</lpage>.</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><string-name><surname>Rapp</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Gallagher</surname> <given-names>M.</given-names></string-name> <article-title>Preserved neuron number in the hippocampus of aged rats with spatial learning deficits</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>1996</year>;<volume>93</volume>:<fpage>9926</fpage>&#x2013;<lpage>9930</lpage>.</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><string-name><surname>Renart</surname> <given-names>A</given-names></string-name>, <string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>XJ</given-names></string-name>, <string-name><surname>Parga</surname> <given-names>N.</given-names></string-name> <article-title>Mean-driven and fluctuation-driven persistent activity in recurrent networks</article-title>. <source>Neural Comput</source>. <year>2007</year>;<volume>19</volume>:<fpage>1</fpage>&#x2013;<lpage>46</lpage>.</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><string-name><surname>Rezende</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Stochastic variational learning in recurrent spiking networks</article-title>. <source>Front Comput Neurosci</source>. <year>2014</year>;<volume>8:38</volume>.</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><string-name><surname>Ricciardi</surname> <given-names>LM.</given-names></string-name> <article-title>Diffusion processes and related topics on biology</article-title>. <source>Berlin: Springer</source>.;<year>1977</year>.</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><string-name><surname>Romani</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tsodyks</surname> <given-names>M.</given-names></string-name> <article-title>Short-term plasticity based network model of place cells dynamics</article-title>. <source>Hippocampus</source>. <year>2015</year>;<volume>25</volume>:<fpage>94</fpage>&#x2013;<lpage>105</lpage>.</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><string-name><surname>Roudi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE.</given-names></string-name> <article-title>A balanced memory network</article-title>. <source>PLoS Comput Biol</source>. <year>2007</year>;<volume>3</volume>:<fpage>1679</fpage>&#x2013;<lpage>1700</lpage>.</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><string-name><surname>Sadeh</surname> <given-names>S</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Rotter</surname> <given-names>S.</given-names></string-name> <article-title>Emergence of functional specificity in balanced networks with synaptic plasticity</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11:e1004307</volume>.</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><string-name><surname>Sadovsky</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>MacLean</surname> <given-names>JN.</given-names></string-name> <article-title>Scaling of topologically similar functional modules defines mouse primary auditory and somatosensory microcircuitry</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>:<fpage>14048</fpage>&#x2013;<lpage>14060</lpage>.</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><string-name><surname>Scarpetta</surname> <given-names>S</given-names></string-name>, <string-name><surname>de Candia</surname> <given-names>A</given-names></string-name>. <article-title>Alternation of up and down states at a dynamical phase-transition of a neural network with spatiotemporal attractors</article-title>. <source>Front Syst Neurosci</source>. <year>2014</year>;<volume>8:88</volume>.</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><string-name><surname>Song</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sj&#x00E4;ostr&#x00E4;om</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Reigl</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chklovskii</surname> <given-names>DB.</given-names></string-name> <article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title>. <source>PLoS Biol</source>. <year>2005</year>;<volume>3</volume>:<fpage>e68</fpage>.</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><string-name><surname>Stark</surname> <given-names>E</given-names></string-name>, <string-name><surname>Roux</surname> <given-names>L</given-names></string-name>, <string-name><surname>Eichler</surname> <given-names>R</given-names></string-name>, <string-name><surname>Buzs&#x00E9;aki</surname> <given-names>G.</given-names></string-name> <article-title>Local generation of multineuronal spike sequences in the hippocampal CA1 region</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2005</year>;<volume>112</volume>:<fpage>10521</fpage>&#x2013;<lpage>10526</lpage>.</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><string-name><surname>Thomas</surname> <given-names>SA.</given-names></string-name> <article-title>Neuromodulatory signaling in hippocampus-dependent memory retrieval</article-title>. <source>Hippocampus</source>. <year>2015</year>;<volume>25</volume>:<fpage>415</fpage>&#x2013;<lpage>431</lpage>.</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="other"><string-name><surname>Titchener</surname> <given-names>EB.</given-names></string-name> <article-title>Lectures on the experimental psychology of the thought-processes</article-title>. <publisher-loc>New York: Macmillan</publisher-loc>.;<year>1909</year>.</mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="journal"><string-name><surname>Trengove</surname> <given-names>C</given-names></string-name>, <string-name><surname>vanLeeuwen</surname> <given-names>C</given-names></string-name>, <string-name><surname>Diesmann</surname> <given-names>M.</given-names></string-name> <article-title>High-capacity embedding of synfire chains in a cortical network model</article-title>. <source>J Comput Neurosci</source>. <year>2013</year>;<volume>34</volume>:<fpage>185</fpage>&#x2013;<lpage>209</lpage>.</mixed-citation></ref>
<ref id="c90"><label>90.</label><mixed-citation publication-type="journal"><string-name><surname>Treves</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rolls</surname> <given-names>ET.</given-names></string-name> <article-title>What determines the capacity of autoassociative memories in the brain?</article-title> <source>Network: Comput Neural Syst</source>. <year>1991</year>;<volume>2</volume>:<fpage>371</fpage>&#x2013;<lpage>397</lpage>.</mixed-citation></ref>
<ref id="c91"><label>91.</label><mixed-citation publication-type="journal"><string-name><surname>Tsodyks</surname> <given-names>MV</given-names></string-name>, <string-name><surname>Markram</surname> <given-names>H.</given-names></string-name> <article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>1997</year>;<volume>94</volume>:<fpage>719</fpage>&#x2013;<lpage>723</lpage>.</mixed-citation></ref>
<ref id="c92"><label>92.</label><mixed-citation publication-type="journal"><string-name><surname>van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H.</given-names></string-name> <article-title>Chaos in neuronal networks with balanced excitatory and inhibitory activity</article-title>. <source>Science</source>. <year>1996</year>;<volume>274</volume>:<fpage>1724</fpage>&#x2013;<lpage>1726</lpage>.</mixed-citation></ref>
<ref id="c93"><label>93.</label><mixed-citation publication-type="journal"><string-name><surname>van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H.</given-names></string-name> <article-title>Chaotic balanced state in a model of cortical circuits</article-title>. <source>Neural Comput</source>. <year>1998</year>;<volume>10</volume>:<fpage>1321</fpage>&#x2013;<lpage>1371</lpage>.</mixed-citation></ref>
<ref id="c94"><label>94.</label><mixed-citation publication-type="journal"><string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Sprekeler</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title>. <source>Science</source>. <year>2011</year>;<volume>334</volume>:<fpage>1569</fpage>&#x2013;<lpage>1573</lpage>.</mixed-citation></ref>
<ref id="c95"><label>95.</label><mixed-citation publication-type="journal"><string-name><surname>Waddington</surname> <given-names>A</given-names></string-name>, <string-name><surname>Appleby</surname> <given-names>PA</given-names></string-name>, <string-name><surname>De Kamps</surname> <given-names>M</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>N.</given-names></string-name> <article-title>Triphasic spike-timing-dependent plasticity organizes networks to produce robust sequences of neural activity</article-title>. <source>Front Comput Neurosci</source>. <year>2012</year>;<volume>6:88</volume>.</mixed-citation></ref>
<ref id="c96"><label>96.</label><mixed-citation publication-type="journal"><string-name><surname>Wallace</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Kerr</surname> <given-names>JND.</given-names></string-name> <article-title>Chasing the cell assembly</article-title>. <source>Curr Opin Neurobiol</source>. <year>2010</year>;<volume>20</volume>:<fpage>296</fpage>&#x2013;<lpage>305</lpage>.</mixed-citation></ref>
<ref id="c97"><label>97.</label><mixed-citation publication-type="book"><string-name><surname>Washburn</surname> <given-names>MF.</given-names></string-name> <source>Movement and mental imagery: outlines of a motor theory of the complexer mental processes</source>. <publisher-loc>Boston: Houghton Mifflin</publisher-loc>.;<year>1916</year>.</mixed-citation></ref>
<ref id="c98"><label>98.</label><mixed-citation publication-type="journal"><string-name><surname>West</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Slomianka</surname> <given-names>LHJG</given-names></string-name>, <string-name><surname>Gundersen</surname> <given-names>HJG.</given-names></string-name> <article-title>Unbiased stereological estimation of the total number of neurons in the subdivisions of the rat hippocampus using the optical fractionator</article-title>. <source>Anat Record</source>. <year>1991</year>; <volume>231</volume>:<fpage>482</fpage>&#x2013;<lpage>497</lpage>.</mixed-citation></ref>
<ref id="c99"><label>99.</label><mixed-citation publication-type="journal"><string-name><surname>Willshaw</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Buneman</surname> <given-names>OP</given-names></string-name>,<article-title>Longuet-Higgins HC. Non-holographic associative memory</article-title>. <source>Nature</source>. <year>1969</year>;<volume>222</volume>:<fpage>960</fpage>&#x2013;<lpage>962</lpage>.</mixed-citation></ref>
<ref id="c100"><label>100.</label><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>MA</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL.</given-names></string-name> <article-title>Dynamics of the hippocampal ensemble code for space</article-title>. <source>Science</source>. <year>1993</year>;<volume>261</volume>:<fpage>1055</fpage>&#x2013;<lpage>1058</lpage>.</mixed-citation></ref>
<ref id="c101"><label>101.</label><mixed-citation publication-type="journal"><string-name><surname>Xue</surname> <given-names>M</given-names></string-name>, <string-name><surname>Atallah</surname> <given-names>BV</given-names></string-name>, <string-name><surname>Scanziani</surname> <given-names>M.</given-names></string-name> <article-title>Equalizing excitation-inhibition ratios across visual cortical neurons</article-title>. <source>Nature</source>. <year>2014</year>;<volume>511</volume>:<fpage>596</fpage>&#x2013;<lpage>600</lpage>.</mixed-citation></ref>
<ref id="c102"><label>102.</label><mixed-citation publication-type="journal"><string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Agnes</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks</article-title>. <source>Nature Commun</source>. <year>2015</year>;<volume>6</volume>:<fpage>6922</fpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>