<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/181784</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Covert Shift of Attention Modulates the Value Encoding in the Orbitofrontal Cortex</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Xie</surname>
<given-names>Yang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nie</surname>
<given-names>Chechang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6976-9246</contrib-id>
<name>
<surname>Yang</surname>
<given-names>Tianming</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Institute of Neuroscience, Key Laboratory of Primate Neurobiology, CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences</institution></aff>
<aff id="a2"><label>2</label><institution>University of Chinese Academy of Sciences</institution>, Beijing 100049, <country>China</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1">Correspondence to: Tianming Yang, Ph.D., Institute of Neuroscience, System Neuroscience Building, Rm 302, 320 Yueyang Rd, Shanghai, China</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>181784</elocation-id>
<history>
<date date-type="received">
<day>28</day>
<month>8</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>28</day>
<month>8</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>29</day>
<month>8</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="181784.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>During value-based decision making, we often evaluate the value of each option sequentially by shifting our attention, even when the options are presented simultaneously. The orbitofrontal cortex (OFC) has been suggested to encode value during value-based decision making. Yet it is not known how its activity is modulated by attention shifts. We investigated this question by employing a passive viewing task that allowed us to disentangle effects of attention, value, choice and eye movement. We found that the attention modulated OFC activity through a winner-take-all mechanism. When we attracted the monkeys&#x2019; attention covertly, the OFC neuronal activity reflected the reward value of the newly attended cue. The shift of attention could be explained by a normalization model. Our results strongly argue for the hypothesis that the OFC neuronal activity represents the value of covertly attended item. They provide important insights toward the neural mechanism of value-based decision making.</p>
</abstract>
<counts>
<page-count count="34"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Imagine you are standing before a fruit stand and trying to buy some apples. Facing a box of apples, you usually would pick up one apple at a time, evaluate it, decide whether you will have it or leave it, and then move on to the next apple until you have chosen enough. The apples are evaluated and selected sequentially, and the decision to pick up a particular apple for scrutiny is often based on its simple visual features, such as color, size, or texture. Apples with desired salient features are more likely to capture your attention in a bottom-up manner and thus guide the decision-making process. Although the attentional modulation of neural activity in the visual cortices has been extensively studied, it is often in a setting where visual information is processed in parallel and attention is distributed across the visual space<sup><xref rid="c1" ref-type="bibr">1</xref>-<xref rid="c4" ref-type="bibr">4</xref></sup>. It is not well understood how serial decision making as in the example above is achieved in the brain and what role attention plays during this process.</p>
<p>We focus our study on the orbitofrontal cortex (OFC), which has been shown to play an important role in representing the association between sensory stimuli and reward during value based decision-making<sup><xref rid="c5" ref-type="bibr">5</xref>-<xref rid="c8" ref-type="bibr">8</xref></sup>. The OFC receives visual sensory inputs from inferior temporal and perirhinal cortex, as well as from limbic structures including the amygdala and the cingulate cortex, allowing it to have the information for establishing the association between visual information and reward<sup><xref rid="c9" ref-type="bibr">9</xref>,<xref rid="c10" ref-type="bibr">10</xref></sup>. Studies have shown that a significant number of OFC neurons encode the reward value associated with sensory stimuli<sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c8" ref-type="bibr">8</xref></sup>.</p>
<p>OFC neurons are typically reported to be insensitive to stimulus locations <sup><xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c11" ref-type="bibr">11</xref>,<xref rid="c12" ref-type="bibr">12</xref></sup>. When options are presented simultaneously and the eye movements are controlled as in many studies <sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c8" ref-type="bibr">8</xref>,<xref rid="c13" ref-type="bibr">13</xref>-<xref rid="c15" ref-type="bibr">15</xref></sup>, it is not immediately obvious how OFC neurons encode the value of each option and contribute to decision making. It has been reported that the value encoding in the OFC is affected by gaze location <sup><xref rid="c16" ref-type="bibr">16</xref></sup> and OFC activities alternated between states during decision making <sup><xref rid="c17" ref-type="bibr">17</xref></sup>, which led to the suggestion that the value information may be processed sequentially, possibly guided with eye movements or overt attention. Yet it is not known how covert attention may affect the neuronal activity in the OFC.</p>
<p>In the current study, we aim to test the hypothesis that the activity of OFC neurons represents the value of covertly attended stimulus when multiple options are presented simultaneously. Signals for attention, eye movement, reward, and decisions in the brain are often tangled together, which has prevented the field to understand how value representation in the brain may be modulated by attention <sup><xref rid="c18" ref-type="bibr">18</xref></sup>. We addressed the issue with a passive-viewing task, which allowed us to tease apart the possible interference of eye movement, reward, and decision when studying attentional modulation of OFC neural responses. In this task, a pair of visual cues were presented while monkeys were fixating. The monkeys did not have to make any choices. They received the reward associated with one of the two cues, randomly selected, at the end of the fixation period. In some trials, we applied a transient visual perturbation to one of the cues to induce a transient shift of attention when monkeys continued to fixate. The perturbation is irrelevant to the reward outcome. Similar manipulations were shown to affect both monkeys&#x2019; behavior and neural responses in the lateral intraparietal area that could be attributed to a bottom-up attention mechanism<sup><xref rid="c19" ref-type="bibr">19</xref></sup>. Thus, we expected the manipulation produced similar shifts of attention in our experiments. We recorded single unit activities in the OFC and observed that the OFC neurons encoded only the larger value when two stimuli were presented without visual perturbations. When a visual perturbation was applied, their activity switched to reflect the value of the perturbed stimulus. The attention modulation of OFC neurons can be described with a normalization model of attention shifts.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Subjects and Materials</title>
<p>We trained two na&#x00EF;ve male rhesus monkeys (<italic>Macaca mulatta</italic>) in the study. They weighed 6.4 and 7.4 kg at the beginning of the experiment. All experimental procedures were approved by the Animal Care Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences (Shanghai, China).</p>
<p>During experiments, the monkeys were seated in a primate chair facing a 23.6-inch video monitor. Rewards consisted of 1 to 8 drops of juice per trial (0.08&#x223C;0.5ml), with drop size controlled by a computer-controlled solenoid. Eye positions and pupil size measurements were monitored with an infrared oculometer system at a sampling rate of 500Hz (EyeLink 1000).</p>
</sec>
<sec id="s2b">
<title>Behavioral Task</title>
<p>Two monkeys G and D were trained to perform a passive viewing task (<xref ref-type="fig" rid="fig1">Fig. 1a</xref>). Each trial began with the appearance of a fixation point in the center of the screen. After the monkey gazed at the fixation point 2000 ms, one or two simple geometric shapes of 2.5&#x00B0; in size were presented 7&#x00B0; away from the fixation point for monkey G and 10&#x00B0; away for monkey D at horizontal positions on a computer screen for 1000 ms. When the cues were extinguished, there was a delay period of 1500 ms, at the end of which a reward was delivered if the monkey held its fixation successfully. The fixation window was 2&#x00B0; in size for monkey G and 3&#x00B0; for monkey D. If the monkey broke its fixation, a penalty timeout of 4000 ms was added.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p><bold>a</bold>. Behavior paradigm. The monkey had to maintain its fixation while passively viewing one or two visual cues presented on the screen. Each cue was associated with a reward. In some trials, one of the cues was quickly rotated back and forth for 100 ms. At the end of the trial, the monkey received reward associated with one randomly selected cue from the pair. <bold>b</bold>. Cue-reward associations used in two monkeys. <bold>c</bold>. Estimated recording locations. The structural MRI images shown were from monkey G.</p></caption>
<graphic xlink:href="181784_fig1.tif"/>
</fig>
<p>The visual cues informed the monkeys of the number of drops of juice that would be delivered. The cue set contained five cues, each associated with 0, 1, 2, 4, and 8 drops of juice, respectively. When there was only one cue presented on the screen, its associated reward would be delivered. When two cues were simultaneously presented, one of the cues was randomly selected and its associated reward delivered. Two different cue sets were used for the two monkeys, respectively (<xref ref-type="fig" rid="fig1">Fig. 1b</xref>).</p>
<p>In some trials with two cues, a visual perturbation was added to one of the cues. The perturbation was a quick back-and-forth rotation of 90&#x00B0; for most of the cues and 45&#x00B0; for the square and the star to make rotations easier to see. Its onset was 200 ms after the cue onset and lasted for 100 ms. The perturbation was independent of the assignment of reward and thus did not provide the monkeys any information on the upcoming reward.</p>
<p>All cue conditions were interleaved in blocks. There were 85 conditions in each block: 10 single-cue conditions with each of the 5 cues appearing either on the left or right, 25 double-cue conditions (each of the 5 cues could appear on the left or the right side), and 50 double-cue conditions with visual perturbations applied to either the left or the right cue. Each block contained one trial from each condition. The conditions were randomly interleaved, and the monkeys had to complete all conditions in a block before they started a new one. During recording experiments, the monkeys on average completed 9.4 blocks daily.</p>
</sec>
<sec id="s2c">
<title>Surgery</title>
<p>At the beginning of the training, both monkeys received a chronic implant of a titanium headpost with standard procedures. After recovery, the monkeys received training for the main task until their performance was satisfactory. Then we performed a second surgery to implant an acrylic recording chamber over the prefrontal region. A craniotomy was made inside the chamber. All surgeries were performed under aseptic conditions. Monkeys were sedated with ketamine hydrochloride (5-15 mg/kg, i.m.), and anesthesia was then induced and maintained with isoflurane gas (1.5-2&#x0025;, to effect). Body temperature, heart rate, blood pressure, and expired CO<sub>2</sub> were monitored throughout all surgical procedures.</p>
</sec>
<sec id="s2d">
<title>MRI</title>
<p>Before and after the recording chamber was implanted, we acquired structural Magnetic Resonance Imaging (MRI) scans to identify and then verify implant locations. Scans were carried out on a Siemens 3T scanner. Monkeys were sedated with ketamine hydrochloride (5-15 mg/kg, i.m.), and anesthesia was then induced and maintained with isoflurane gas (1.5-2&#x0025;, to effect).</p>
</sec>
<sec id="s2e">
<title>Electrophysiology</title>
<p>We recorded single unit activity with vertically movable electrodes (Alpha Omega and FHC, 0.5&#x2013;1.5 MU at 1 KHz) using conventional techniques. Briefly, microelectrodes were driven by a four-channel micromanipulator (Alpha Omega EPS) attached to the recording chamber. At most four electrodes were used at the same time. Recordings locations were on the ventral surface of the frontal lobe between the lateral and medial orbital sulci, roughly corresponding to Walker&#x2019;s areas 11 and 13<sup><xref rid="c20" ref-type="bibr">20</xref></sup>. Spike waveforms from putative single neurons were isolated online and recorded with an Alpha Omega SnR system. Offline sorting was done with NeuroExplorer. Other than the quality of isolation, there were no selection criteria for neurons.</p>
</sec>
<sec id="s2f">
<title>Pupil Dilation Analysis</title>
<p>The pupil responses were recorded during all recording sessions. For consistency, the analyses were based on the sessions in which value-encoding neurons were identified and analyzed (33 and 38 sessions from monkey D and G, respectively). We calculated the average pupil size from 400 to 900ms after monkeys acquiring fixation as the baseline. The baseline was then subtracted from the pupil responses in the rest of the analyses. To quantify how reward expectation affects pupil dilation, we calculated the average pupil size in the 1 second period after the offset of the cue. During this period, the pupil dilation showed a consistent pattern between two monkeys.</p>
<p>We quantified how reward value affected pupil dilation in the single-cue conditions with the following linear regression:
<disp-formula id="eqn1">
<alternatives>
<graphic xlink:href="181784_eqn1.gif"/>
</alternatives>
</disp-formula></p>
<p>Where PS is the pupil size measured in the aforementioned window, V is the value (number of drops of juice) associated with the reward cue.</p>
<p>A two-way ANOVA was used to test the pupil dilation difference between the single-cue conditions and the double-cue conditions grouped by the higher value, with one factor being the reward size and the other the number of cues. Posthoc analyses were done with Tukey tests.</p>
</sec>
<sec id="s2g">
<title>Electrophysiology Analysis</title>
<p>The electrophysiology data were based on 84 and 67 recording sessions from monkeys G and D, respectively. On average, 5.6 neurons were recorded from each session, and 297 trials were recorded from each neuron.</p>
<sec id="s2g1">
<title>Value Selectivity</title>
<p>We first categorized a neuron as visual-responsive if its mean firing rate between the fixation onset to the cue onset was significantly different from that between the cue onset to the cue offset based on a t-test. To determine whether a neuron is selective to value, we calculated its average responses between 150 and 550 ms after the cue onset in the single-cue conditions, as most of the neurons have a visual latency larger than 150ms and their responses were transient. We then used a one-way ANOVA to determine the significance at p&#x003C;0.05. Further analyses were only performed on the value-selective neurons.</p>
<p>We further divided the value-selective neurons into the positively- and the negatively-tuned groups with a linear regression:
<disp-formula id="eqn2">
<alternatives>
<graphic xlink:href="181784_eqn2.gif"/>
</alternatives>
</disp-formula>
where FR is the neuron&#x2019;s cue responses during the single-cue conditions and V indicates the cue&#x2019;s associated value (V=0, 1, 2, 4, or 8). The significance was determined at p&#x003C;0.05. We assigned the neurons to the positively- and negatively-tuned groups according to the sign of <italic>b</italic><sub>1</sub>.</p>
</sec>
<sec id="s2g2">
<title>Population Responses</title>
<p>In <xref ref-type="fig" rid="fig3">Figure 3c-e</xref>, each neuron&#x2019;s responses were normalized to its response to the preferred condition (8-drops-of-juice for the positively-tuned group and 0-drops-of-juice for the negatively-tuned group) after the baseline was subtracted. The mean response in the 200ms time window before the cue onset was used as the baseline. The population responses were calculated as the average of the normalized responses of each neuron. The particular choice of normalization method did not change the conclusions.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Pupil dilation responses reflected cue-reward association. <bold>a</bold>. Pupil dilation responses of trials in the single-cue conditions for monkey G. Time 0 indicates the cue onset. The dark gray box indicates the cue presentation period. The light gray box indicates the period in which the mean pupil responses were plotted in panel <bold>c</bold>. Different shades of red indicate cues with different rewards. The shading around each curve represents s.e.m. between sessions. <bold>c</bold>. Pupil dilation responses of both the single- and double-cue condition trials for monkey G. The responses are calculated as the average pupil size within 1 second after the cue offset, indicated by the light gray box in panel <bold>a</bold>. Trials in the double-cue conditions (black curve) are grouped by the higher value between the two cues. The numbers near each data point indicate the cue combinations that go into each group. The error bars represent s.e.m. between sessions. <bold>b and d</bold>. Plots for monkey D.</p></caption>
<graphic xlink:href="181784_fig2.tif"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>OFC responses to cue conditions without perturbations. <bold>a</bold>. The PSTH in the single-cue condition of an example OFC neuron. The trials are grouped by the cue&#x2019;s associated reward value indicated by different shades of red. The shading around each curve represents s.e.m. between trials. <bold>b</bold>. The cue responses to both the single- and double-cue conditions of the example neuron. Trials in the double-cue conditions (black curve) are grouped by the higher value between the two cues. The numbers near each data point indicate the cue combinations that go into each group. The error bars represent s.e.m. between trials. <bold>c and d</bold>. The population cue responses to both the single- and double-cue conditions of positively-(<bold>c</bold>) and negatively-tuned (<bold>d</bold>) OFC neurons, plotted in a similar format as in panel <bold>b</bold>. The error bars represent s.e.m. between neurons. <bold>e</bold>. The responses of each OFC neuron to both the single- and double-cue conditions. Red and blue data points are positively- and negatively-tuned neurons. The red and blue histogram insets are distributions of response difference between two cue conditions for the positively- and the negatively-tuned neurons, respectively.</p></caption>
<graphic xlink:href="181784_fig3.tif"/>
</fig>
</sec>
<sec id="s2g3">
<title>Visual Perturbation Analyses</title>
<p>In the PSTHs in <xref ref-type="fig" rid="fig4">Figure 4a,b</xref>, each neuron&#x2019;s PSTH was calculated with a sliding window of 50 ms and averaged across all completed trials. We used a 200ms window before the cue onset to calculate the baseline and subtracted the neuron&#x2019;s response baseline before normalizing the responses to each neuron&#x2019;s peak response to the preferred condition. The population responses were the average of the normalized responses of each neuron. The significance of the difference between the two rotation conditions in <xref ref-type="fig" rid="fig4">Figure 4a,b</xref> was determined by a one-tail t-test performed at each time point. To account for multiple comparison, we used the Benjamini-Hochberg procedure to control the false discovery rate to be under 0.05 <sup><xref rid="c21" ref-type="bibr">21</xref></sup>. The latency of rotation effects was defined as the first time window after the rotation onset that showed a significant response difference and lasted for more than 50 ms.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>OFC responses to cue conditions with perturbations. <bold>a</bold>. Population responses to the double-cue conditions with visual perturbations of the positively-tuned OFC neurons. The blue curve includes the trials with the lower-value cue rotated. The red curve includes the trials with the higher-value cue rotated. The shading around each curve represents s.e.m. between trials. The grey box indicates the rotation period. The black dots on the top indicates the time points where the difference between two curves is significant (p&#x003C;0.05). <bold>b</bold>. Population responses to the double-cue conditions with visual perturbations of negatively-tuned OFC neurons plotted in the same way as in panel <bold>a</bold>. <bold>c.</bold> The comparison between each positively-tuned neuron&#x2019;s responses when the higher- and the lower-value cues were rotated. Each data point represents a neuron. Red dots indicate neurons that showed significant rotation effects. Pink dots are neurons that were not significantly affected by rotations. Circles are neurons from monkey D, and diamonds monkey G. A histogram of the response difference between two conditions is shown on the top right corner, in which filled squares indicate neurons with significant rotation effects. <bold>d</bold>. Similar to <bold>c</bold>, but for the negatively-tuned neurons. <bold>e.</bold> The comparison between each positively-tuned neuron&#x2019;s responses when the higher-value cue was rotated and when there was no perturbation. Red and pink dots are neurons with significant rotation effects as shown in panel <bold>c</bold>. The color in the histogram indicates the same significance as shown in panel <bold>c</bold>. <bold>f</bold>. Similar to <bold>e</bold>, but for the negatively-tuned neurons.</p></caption>
<graphic xlink:href="181784_fig4.tif"/>
</fig>
<p>We determined whether the visual perturbation affected a neuron&#x2019;s responses in <xref ref-type="fig" rid="fig4">Figure 4c,d</xref> as follows. For each unit, all completed trials with visual perturbations were divided into two groups. One included the conditions when the cue with the higher value was rotated, and the other included the conditions when the lower-value cue was rotated. We defined a neuron&#x2019;s responses as significantly modulated by rotation if there was a time window no less than 200ms during the period between the onset of the rotation and the offset of the cue (200 &#x2013; 1000ms after the cue onset) in which the mean firing rates between the two groups were significantly different when tested with a one-tailed t-test. And this time window was defined as its modulation window (<bold>Supplementary Fig. 4</bold>). For the units that were significantly modulated by rotation, the Z scores of their firing rates during the modulation window were calculated and plotted in <xref ref-type="fig" rid="fig4">Figure 4c-f</xref>. For the units without significant rotation effects, we plotted the Z scores of their firing rates between the onset of the rotation to the offset of the cue. For <xref ref-type="fig" rid="fig4">Figure 4e,f</xref>, the responses under conditions without rotations were calculated using the same time window as the corresponding rotation conditions.</p>
<p>We defined each neuron&#x2019;s attentional modulation index as:
<disp-formula id="eqn3">
<alternatives>
<graphic xlink:href="181784_eqn3.gif"/>
</alternatives>
</disp-formula>
where MI is the modulation index, <italic>FR</italic><sub><italic>h</italic></sub> and <italic>FR</italic><sub><italic>l</italic></sub> are the neuron&#x2019;s responses when the higher- and lower-value cues were rotated, respectively.</p>
</sec>
<sec id="s2g4">
<title>Shift of attention analyses</title>
<p>The population responses of positively-tuned neurons in <xref ref-type="fig" rid="fig5">Figure 5a,b</xref> were calculated as the mean firing rate between the onset of the perturbation and the offset of the cue (200 &#x2013; 1000ms after the cue onset) normalized to each neuron&#x2019;s responses to its preferred cue (8 drops-of-juice). Similarly, the population responses of negatively-tuned neurons in <xref ref-type="fig" rid="fig5">Figure 5c,d</xref> were mean firing rates between the onset of the perturbation and the offset of the cue normalized to each neuron&#x2019;s responses to its preferred cue (0 drops-of-juice).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>The attentional shift between two cues depended on the difference between their associated value. <bold>a</bold>. The solid red curve is the positively-tuned OFC neurons&#x2019; responses to an 8-drops-of-juice cue paired with another cue associated with 0, 1, 2, 4, or 8 drops of juice. The solid black curve indicates the response to the lower-value cue presented alone. The red dashed curve is the responses to the cue pairs with the visual perturbation applied to the lower-value cue. The green dashed curve is the responses predicted by the normalization model. The numbers near each data point indicate the cue combinations that go into each data point, with the little arc indicating the perturbed cue. <bold>b</bold>. The solid blue curve is the positively-tuned OFC neurons&#x2019; responses to a 0-drops-of-juice cue paired with another cue associated with 0, 1, 2, 4, or 8 drops of juice. The dotted black line indicates the responses to the single 0-drops-of-juice cue. The blue dashed line is the responses to the same cue pairs with the visual perturbation applied to the 0-drops-of-juice cue. The green dashed curve is the responses predicted by the normalization model. The numbers near each data point indicate the cue combinations that go into each data point, with the little arc indicating the perturbed cue. <bold>c</bold> and <bold>d</bold>. The same plots as panels <bold>a</bold> and <bold>b</bold>, but for the negatively-tuned OFC neurons. All the error bars indicate s.e.m. between neurons.</p></caption>
<graphic xlink:href="181784_fig5.tif"/>
</fig>
</sec>
<sec id="s2g5">
<title>Normalization model</title>
<p>For each neuron, we modeled their responses under double-cue conditions with their responses under single-cue conditions. We calculated each neuron&#x2019;s mean firing rates under these conditions in a time window between 200 and 1000ms after cue onset, which were then normalized to the neuron&#x2019;s response to its preferred condition (single 8-drops-of-juice cue for positively-tuned neurons, and single 0-drops-of-juice cue for negatively-tuned neurons).</p>
<p>We modeled each neuron&#x2019;s firing rate <italic>R</italic> under double-cue conditions as follows:
<disp-formula id="eqn4">
<alternatives>
<graphic xlink:href="181784_eqn4.gif"/>
</alternatives>
</disp-formula>
where <italic>R</italic><sub><italic>h</italic></sub> and <italic>R</italic><sub><italic>l</italic></sub> are the neuron&#x2019;s responses (as plotted in <xref ref-type="fig" rid="fig5">Fig. 5</xref>) under single-cue conditions when the higher-value cue and the lower-value cues is presented alone, respectively; 0&#x2264;<italic>a</italic>&#x2264;1 is a parameter that indicates how attention is distributed, and <italic>b</italic>&#x2265;1 is a parameter that controls the normalization behavior.</p>
<p>For conditions without visual perturbations, we modeled the distribution of attention between the two cues with a softmax function of the neuron&#x2019;s responses <italic>R</italic><sub><italic>h</italic></sub> and <italic>R</italic><sub><italic>l</italic></sub>:
<disp-formula id="eqn5">
<alternatives>
<graphic xlink:href="181784_eqn5.gif"/>
</alternatives>
</disp-formula></p>
<p>Here, <italic>d</italic> should be positive for positively-tuned neurons and negative for negatively-tuned neurons. When there was a visual perturbation to the lower-value cue, we modeled the shift of attention toward the lower-value cue as an additive term &#x0394;<italic>d</italic>:
<disp-formula id="eqn6">
<alternatives>
<graphic xlink:href="181784_eqn6.gif"/>
</alternatives>
</disp-formula></p>
<p>In total, there are 4 free parameters in our model: <italic>b</italic>, <italic>c</italic>, <italic>d</italic> and &#x0394;<italic>d</italic>. We fit the model to the neurons that were found to be significantly modulated by visual perturbations (n=33 for the positively-tuned neurons, n=15 for the negatively-tuned neurons). For each neuron, we randomly divided the trials into two halves. The fitting was based on one half of the data, and the obtained four parameters were used to generate predictions for the other half of the data (green dashed curves in <xref ref-type="fig" rid="fig5">Fig. 5</xref>). We calculated the R<sup><xref rid="c2" ref-type="bibr">2</xref></sup> for the test dataset and the predictions for each neuron. The reported explained variance reflected the average R<sup><xref rid="c2" ref-type="bibr">2</xref></sup> across all neurons.</p>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Behavior</title>
<p>Two monkeys were trained to perform a cue-reward association task (<xref ref-type="fig" rid="fig1">Fig. 1a,b</xref>). To find out if the monkeys learned the cue-reward associations, we measured the pupil dilation when the monkeys were performing the task. When only one cue was presented, there was no uncertainty in the amount of reward that the monkeys would get. Although the dynamics of pupil responses during the cue presentation period were different between the two monkeys, it is evident that both monkeys showed pupil dilation patterns clearly indicating they understood the reward association (<xref ref-type="fig" rid="fig2">Fig. 2a,b</xref>). For the purpose of this study, we focused our analysis of pupil dilation on the period immediately after the cue presentation. During this period, there was no visual stimuli other than the fixation point on the screen, the pupil responses showed largest separation between different reward conditions, and similar patterns were seen in both monkeys. A linear regression showed that the pupil size increased for both monkeys during the analysis time window when the reward associated with the cue was larger (p&#x003C;&#x003C;0.001 for both monkeys).</p>
<p>Next, we looked at the pupil dilation pattern in the double-cue conditions. The pupil responses were dominated by the cue that predicted a larger reward. When we pooled the cue combinations in which the cue with the larger reward was the same, the pupil dilation was similar to the condition when the larger-reward cue was presented alone (<xref ref-type="fig" rid="fig2">Fig. 2c,d</xref>). Although a two-way ANOVA analysis showed a significant difference between the single- and double-cue conditions (p=0.0027 for monkey D and 0.0239 for monkey G), the posthoc Tukey test showed no individual pairs of reward value conditions were significantly different (0.9996, 1, 0.7448, 0.9397, and 0.9932 for monkey G and 0.9999, 0.9836, 0.9100, 0.0750, and 0.4317 for monkey G). The results suggested the high-value cue dominated the pupil responses. In these conditions, the computer randomly selected one of the cues at the end of a trial and delivered its associated reward to the monkey. Nevertheless, the pupil dilation did not reflect either the sum of the values or the expected value, which was the mean of two cues&#x2019; associated value. This was consistent with the idea that the monkeys were primarily paying attention to the cue associated with a larger reward, and the pupil dilation reflected its value.</p>
<p>Over all, the pupil dilation responses suggested that the monkeys understood the cue-reward associations even under the passive viewing condition. We next explored how the associations were represented in the OFC.</p>
</sec>
<sec id="s3b">
<title>OFC neural responses without visual perturbation</title>
<p>After verifying that the monkeys understood cue-reward associations used in the task, we went on recording neural activity from the OFC. We recorded from a total of 846 neurons in Walker&#x2019;s areas 11 and 13<sup><xref rid="c20" ref-type="bibr">20</xref></sup>, between the lateral and medial orbital sulci (<xref ref-type="fig" rid="fig1">Fig. 1c</xref>). Among the 846 neurons, we identified 232 neurons that exhibited significant responses during the cue period. Among them, we identified 110 neurons whose responses were selective for reward value (<xref ref-type="table" rid="tbl1">Table 1</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Numbers of OFC neurons recorded and classified in this study. For neurons with significant attentional modulation, we defined the consistency of the modulation as whether their responses to the double-cue conditions with visual perturbation became more or less similar to their responses to the single-cue condition when the perturbed cue was presented alone.</p></caption>
<graphic xlink:href="181784_tbl1.tif"/>
</table-wrap>
<p>An example value-selective OFC neuron is shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. In the single-cue conditions, its responses were modulated by the value associated with the cue (<xref ref-type="fig" rid="fig3">Fig. 3a,b</xref>). Moreover, when we presented two cues together, the neuron&#x2019;s response pattern mimicked the pattern of pupil responses (<xref ref-type="fig" rid="fig3">Fig. 3b</xref>). The responses to the single- and double-cue conditions were similar (two-way ANOVA, p&#x003C;1e-7 for reward value, 0.16 for number of cues). A linear regression further revealed that only the higher-value cue affected the neuron&#x2019;s responses (p=3.06e-7 for higher value and 0.51 for lower value). The neuron&#x2019;s responses only reflected the value of the larger reward cue, which presumably captured the monkeys&#x2019; attention.</p>
<p>This pattern was true in general for the population of neurons that encoded value in the OFC. We divided these neurons into two groups. The 73 positively-tuned neurons showed greater responses when cues with larger rewards were presented, and the 37 negatively-tuned neurons showed greater responses when cues with smaller rewards were presented (<xref ref-type="table" rid="tbl1">Table 1</xref>).</p>
<p>The population average responses of both groups of neurons showed similar patterns as the example neuron (<xref ref-type="fig" rid="fig3">Fig. 3c,d</xref>). The two-way ANOVA showed the number of cues did not affect the population responses for each group (p=0.50 for the positively-tuned neurons, 0.29 for the negatively-tuned neurons). The linear regression of the population response on both values showed only the higher value affected the responses significantly (higher-value: p&#x003C;1e-7 for both groups; lower-value: p=0.70 for the positively-tuned group and 0.14 for the negatively-tuned group).</p>
<p>Not surprisingly, each individual neuron, regardless whether categorized as positively-tuned or negatively-tuned, showed similar responses in single- and double-cue conditions, when the double-cue condition trials were grouped by the larger-value (<xref ref-type="fig" rid="fig3">Fig. 3e</xref>). The mean responses between the two conditions were not significantly different (two-tailed t-test, p=0.12 and 0.27 for the positively- and the negatively-tuned neurons).</p>
<p>These results suggested that the value-encoding OFC neurons&#x2019; responses were highly homogenous and dominated by the higher-value cue when multiple cues were presented simultaneously. Note that, for the negatively-tuned neurons, the dominating cue was the non-preferred cue. Therefore, their responses were suppressed by the presence of a larger-value cue. The results were consistent with the idea that the monkeys were mostly paying attention to the cue associated with the larger reward, and that the activity of OFC neurons reflected the value of the attended cue.</p>
</sec>
<sec id="s3c">
<title>OFC neural responses with visual perturbation</title>
<p>Next, we introduced visual perturbations that would attract monkeys&#x2019; attention toward one of the cues in the double-cue conditions. The perturbation was a transient rotation of the cue that lasted only 100ms. The perturbation could be applied to either the higher-value or the lower-value cue. It was independent of the assignment of the rewarded cue, and the monkey would not gain any behavioral advantage or additional reward by paying attention to it. Indeed, we observed no behavior indications that the monkeys were responding to the perturbations. They induced no changes in pupil size, and the monkeys&#x2019; eyes were not attracted toward the perturbed location (<bold>Supplementary Fig. 1 and 2</bold>).</p>
<p>However, these subtle visual perturbations affected OFC neurons&#x2019; responses. Again, we looked at the positively-tuned and the negatively-tuned neuron populations separately. For the positively-tuned neurons, their responses were significantly larger when the cue with higher value was rotated than when the cue with lower value was rotated (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>). The difference became significant from 30 ms after the rotation onset. Such a short latency suggests that a bottom-up process was in play. The rotation effects were highly consistent at the level of individual neurons. Among 73 positively-tuned neurons, 33 of them (45.2&#x0025;) showed a significant increase of responses when the higher-value cue was rotated. The mean responses to the higher- and lower-value cue conditions were significantly different (mean difference= 0.28, p=1.31e-4, two-tailed t-test) (<xref ref-type="fig" rid="fig4">Fig. 4c</xref>). Only 4 (5.5&#x0025;) showed a significant decrease of responses.</p>
<p>A similar but opposite pattern was observed in the negatively tuned neurons. Consistent with their tuning, their responses were significantly lower when the cue with higher value was rotated than when the cue with lower value was rotated (<xref ref-type="fig" rid="fig4">Fig. 4b</xref>). 15 of 37 (40.5&#x0025;) showed a significant response suppression when the higher-value cue was rotated (<xref ref-type="fig" rid="fig4">Fig. 4d</xref>). Only 2 (5.4&#x0025;) showed a response enhancement. The mean responses to the double- and single-cue conditions were significantly different (mean difference = &#x2212;0.39, p=8.05e-6, two-tailed t-test) (<xref ref-type="fig" rid="fig4">Fig. 4d</xref>).</p>
<p>The results from each individual monkey were consistent. The difference between the responses to the higher- and the lower-value cue rotation conditions was similar in two monkeys (two-tailed t-test, p=0.133 for positively-tuned neurons and 0.17 for negatively-tuned neurons).</p>
<p>Although the attentional modulation of each neuron&#x2019;s activity was highly consistent, the magnitude of attentional modulation was modest. We calculated the modulation indices for each neuron. The mean modulation index for the positively- and negatively-tuned neurons were 0.06 and &#x2212;0.09, respectively. They were 0.12 and &#x2212;0.16 for the neurons that showed significant attentional modulation (<bold>Supplementary Fig. 5</bold>).</p>
<p>These results are consistent with the idea that the visual perturbation attracts monkeys&#x2019; attention toward the perturbed cue and the OFC neurons encoded its value. However, when there were no perturbations, we have suggested that the monkeys would attend to the higher-value cue. If so, applying perturbations to the higher-value cue should have minimal effects on the existing attention and the neurons&#x2019; responses. Indeed, when we compared the neurons&#x2019; responses when there were no perturbations and when the perturbations were applied to the higher-value cue, we observed no significant change in the neurons&#x2019; responses (<xref ref-type="fig" rid="fig4">Fig. 4e,f</xref>. p=0.52 and 0.14 for the positively- and the negatively-tuned neurons). Therefore, visual perturbations by themselves did not affect OFC neurons&#x2019; responses. The attentional modulation that we observed when the perturbations were applied to the lower-value cue was due to the attention shift toward the lower-value cue.</p>
</sec>
<sec id="s3d">
<title>Attention Shift and Normalization Model</title>
<p>To further demonstrate how attention shifts affected OFC neurons&#x2019; responses when the perturbations were applied to the lower-value cues, we looked at two specific cases of cue combinations. The first case included conditions when the cue with the maximum reward, 8 drops of juice, was paired with another cue with rewards of 0 to 8 drops of juice. When there were no visual perturbations, presumably the monkeys&#x2019; attention was always on the cue with 8 drops of juice, and the OFC neurons&#x2019; responses reflected that fact (red solid lines in <xref ref-type="fig" rid="fig5">Fig. 5a,c</xref>). When the visual perturbation was applied to the cue with less reward (red dashed lines in <xref ref-type="fig" rid="fig5">Fig. 5a,c</xref>), we saw a decrease of responses among the positively-tuned neurons (one-way ANOVA, p=0.0015), and an increase of responses among the negatively-tuned neurons (one-way ANOVA, p=0.0023), so that the population responses were driven toward the single cue conditions when only the lower-value cue was presented (black solid lines in <xref ref-type="fig" rid="fig5">Fig. 5a,c</xref>). When the value difference between the two cues was large, such as in the 8 vs. 0 and 8 vs. 1 conditions, the shift was moderate. When the value difference between the two cues was small, as in the 8 vs. 4 condition, the shift was closer to complete.</p>
<p>We can see a similar pattern in the second cue combination case. Here we studied all conditions when the cue with the minimum reward, 0 drops of juice, was paired with another cue with reward of 0 to 8 drops of juice. By default, the monkeys&#x2019; attention was away from the cue with 0 drops of juice, and the OFC neurons&#x2019; responses reflected the value of the other cue (one-way ANOVA, p=0.0015 and &#x003C;1e-7 for the positively- and the negatively-tuned neurons, respectively; blue solid lines in <xref ref-type="fig" rid="fig5">Fig. 5b,d</xref>). When the visual perturbation was applied to the 0-drops-of-juice cue, we saw a decrease of responses among the positively-tuned neurons, and an increase of responses among the negatively-tuned neurons (one-way ANOVA, p=0.0023 and 0.0084 for the positively- and the negatively-tuned neurons, respectively; blue dashed lines in <xref ref-type="fig" rid="fig5">Fig. 5b,d</xref>), so that the population responses were driven toward the condition when only 0-drops-of-juice cue was presented alone (black dashed lines in <xref ref-type="fig" rid="fig5">Fig. 5b,d</xref>). Again, the degree of attention shifts depends on the value difference between the two cues.</p>
<p>We modelled the attention shift based on the neurons&#x2019; responses to single cues. We created a normalization model similar to those previously proposed to describe how neurons in the visual cortices respond to competing stimuli<sup><xref rid="c22" ref-type="bibr">22</xref>-<xref rid="c25" ref-type="bibr">25</xref></sup>. In our model, the attention distribution between two cues was a function of both the value difference between the two cues and the location of the visual perturbation. The visual perturbation shifts the attention toward the perturbed cue. The model was based on the idea that the attention should be distributed less evenly when the value difference between the two options is large, and it is harder to drive the attention toward the lower-value cue in this situation. We split the data of the neuronal responses in the double-cue conditions with visual perturbations into 2 halves and compared the model predictions based on parameters obtained from fitting half of the data (<xref ref-type="fig" rid="fig5">Fig. 5a-d</xref>, green dashed lines) with the data from the other half (<xref ref-type="fig" rid="fig5">Fig. 5a-d</xref>, red and blue dashed lines, see Methods). The model prediction matched the real data well. It explained 86.61&#x0025; (s.e.m=0.27&#x0025;) of the variance of the neuronal responses under the double-cue conditions with attention shifts caused by visual perturbations for the positively-tuned neurons and 89.67&#x0025; (s.e.m=0.38&#x0025;) of the variance for the negatively-tuned neurons.</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<sec id="s4a">
<title>The passive-viewing task disentangles attention, value, and choice</title>
<p>Although the observed attentional modulation of the neural responses in the OFC in this study was relatively modest, it represented a worst-case scenario. The monkeys were passively viewing the stimuli without having to make any behavioral responses. They could have just ignored the stimuli. The visual perturbation provided no information on the reward contingency. It did not produce measurable behavior effects. Also, the onset of the attentional modulation was after the peak visual responses of these neurons. Despite all these factors, we still observed a robust and consistent attentional modulation on a substantial proportion of value-sensitive OFC neurons (48 out of 110, or 43.6&#x0025;). We speculate that the attentional modulation would be larger had the monkeys been engaged in a choice task.</p>
<p>Using a passive viewing paradigm may appear not ideal for the investigation of attentional modulation. Paradoxically, however, it was the key to our experimental design that allowed us to tease apart reward, choice, eye movement and attention. First of all, in the double-cue condition, the reward was chosen randomly. It is clear that the OFC neurons did not encode reward expectation. Their responses to a pair of 8-drops-of-juice cues were statistically the same as to the pair of an 8-drops-of-juice cue and a cue associated with no reward. The prospect of getting 8 drops of juice was very different under these two conditions (<xref ref-type="fig" rid="fig5">Fig. 5a</xref>). When a visual perturbation was applied to the lower-value cue, the expected reward remained the same. Thus, the only reasonable explanation for the observed change of OFC neural responses is the shift of attention toward the lower-value cue. Second, because there was no active choice, we avoided the inevitable shift of attention that accompanies a choice. The reward delivered to the monkeys was not contingent on the visual perturbation, and the monkeys never needed to make a choice. It is possible that monkeys were still covertly making choices and planning eye movements toward the perturbed cue, but additional analyses of eye positions do not support this scenario (<bold>Supplementary Fig. 2</bold>).</p>
<p>On the other hand, choice related signals in the OFC that were found in several previous studies may be explained by attention <sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c14" ref-type="bibr">14</xref>,<xref rid="c26" ref-type="bibr">26</xref>,<xref rid="c27" ref-type="bibr">27</xref></sup>. When choices are made, attention is most likely shifted toward the chosen option. Thus, the findings of the overwhelming preponderance of OFC neurons encoding the value of chosen item over neurons encoding unchosen values during decision making <sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c26" ref-type="bibr">26</xref></sup> can be because the activity of these neurons reflected the attention shift toward the chosen item.</p>
</sec>
<sec id="s4b">
<title>A bottom-up attention mechanism</title>
<p>The attentional modulation we observed in the OFC was most likely due to a bottom-up instead of top-down attention mechanism. The monkeys did not have to actively direct its attention toward the visual perturbation. It is possible that the monkeys were doing that nevertheless. However, we found the strength of attentional modulation to be fairly consistent throughout the whole recording part of the experiment, which lasted 3 and 5 months for monkeys G and D, respectively (<bold>Supplementary Fig. 3</bold>). We would expect the modulation to have become smaller if it was due to a top-down control, because the monkeys would have been better at ignoring the perturbation toward the end of the experiments. In addition, the latency of the modulation of the OFC population response was rather small (<xref ref-type="fig" rid="fig4">Fig. 4a,b</xref>).</p>
<p>In the double-cue condition without visual perturbations, the OFC neurons seem to encode the higher-value cue from the very beginning. It is not known how and where in the brain it is determined which cue is associated with higher value. We did not find evidence for an evolving decision in the OFC, calling into question whether the value information encoded in the OFC is actually used in decision making. However, the decision of where to pay attention in this experiment is simple, and it may be solved at a lower level of sensory or value information processing areas, such as the amygdala and the visual cortex<sup><xref rid="c28" ref-type="bibr">28</xref>,<xref rid="c29" ref-type="bibr">29</xref></sup>. After many months of training, the cues with high values probably gained greater salience than the cues with low values. Thereby, a bottom-up attention mechanism may have picked out the cue with the higher value and guided the OFC responses. The OFC may still play an important role when a value-based decision requires more deliberation and the top-down control<sup><xref rid="c30" ref-type="bibr">30</xref></sup>, as well as when values change and need to be retrieved at the time of choice<sup><xref rid="c31" ref-type="bibr">31</xref></sup>.</p>
</sec>
<sec id="s4c">
<title>OFC and the visual system</title>
<p>Our findings are not unlike the findings in visual areas such as V4, MT and IT. When competing stimuli were presented inside the same receptive field of a neuron in the visual cortex, the neuron&#x2019;s response to the attended stimulus was enhanced <sub><xref rid="c22" ref-type="bibr">22</xref>,<xref rid="c25" ref-type="bibr">25</xref>,<xref rid="c28" ref-type="bibr">28</xref>,<xref rid="c32" ref-type="bibr">32</xref>-<xref rid="c34" ref-type="bibr">34</xref></sub>.</p>
<p>Similar to previously described normalization models for modelling attention in the visual system <sup><xref rid="c22" ref-type="bibr">22</xref>,<xref rid="c24" ref-type="bibr">24</xref>,<xref rid="c25" ref-type="bibr">25</xref>,<xref rid="c33" ref-type="bibr">33</xref>-<xref rid="c35" ref-type="bibr">35</xref></sup>, we modelled the OFC neural responses to multiple items as a weighted average of its responses to each individual item. However, we interpret the normalization differently. We believe the weighted average is done across the time rather than across the space. That is to say, the weights reflect how often attention is directed to an item. At any given time, the attention works in a winner-take-all fashion. Admittedly, we only observed such winner-take-all attention effects in the cue condition where the attention was on the high-value stimulus. However, the fact that most OFC neurons, regardless of its value preference, showed such consistent winner-take-all modulation effects strongly suggests that the winner-take-all mechanism works under other stimulus conditions as well. The homogenous attention modulation within the OFC population also leads us to believe that the attention modulation that we observed in the OFC is inherited from the earlier visual processing.</p>
</sec>
<sec id="s4d">
<title>Serial Processing</title>
<p>Our results suggest that the OFC encodes the value information one item at a time even when multiple items are presented. Several previous studies provided evidence in favor of the hypothesis. McGinty et al <sup><xref rid="c16" ref-type="bibr">16</xref></sup> found that the value coding in the OFC was highest when the animals were fixating at locations near the cue. Although there was only one cue presented to the animal in the study, their results indicated that eye fixation and overt attention could modulate the value coding in a similar manner as in the case of covert attention. Rich and Wallis <sup><xref rid="c17" ref-type="bibr">17</xref></sup> showed that the OFC population activity alternated between states associated with the value of available options. Although it was not known if the alternation was due to attention shifts or if individual OFC neurons also exhibited such dynamics, the study provided important evidence that OFC evaluated the value of each option sequentially. Finally, it is reported that human subjects solved a multi-cue probabilistic classification task by integrating different numbers of simultaneously presented cues under varying time pressure, suggesting a sequential processing was in play <sup><xref rid="c36" ref-type="bibr">36</xref></sup>. Taken together, the current evidence supports the hypothesis that the value information is processed in the brain in a sequential manner that is guided by attention and reflected by the OFC activity.</p>
</sec>
<sec id="s4e">
<title>Attention and value-based decision making</title>
<p>If the OFC underlies value-based decision making as previously suggested <sup><xref rid="c37" ref-type="bibr">37</xref></sup>, our results suggest that value-based decision making is a sequential process in which the value of each option is evaluated one at a time, guided by attention. It was shown that value-based decision making may be driven by the value difference between attended and unattended stimuli, which was found to be represented by the neural activity in vmPFC and ventral striatum <sup><xref rid="c38" ref-type="bibr">38</xref>,<xref rid="c39" ref-type="bibr">39</xref></sup>. However, we demonstrated that the OFC activity in monkeys represented only the higher value between the alternatives instead of the value difference between attended and unattended stimuli. It remains a question whether the discrepancy between our study and the previous human fMRI studies is due to specie difference or the difference between neural signals recorded with fMRI and with electrophysiology.</p>
<p>Rangel and his colleagues <sup><xref rid="c39" ref-type="bibr">39</xref>,40</sup> also proposed that fixation or attention may bias value-based decision making by assigning a larger weight to the attended option&#x2019;s value during decision making. Were OFC neurons underlying this attention bias, we should observe that the positively-tuned neurons to have higher responses toward the attended item and the negatively-tuned neurons to have lower responses. Our results did not support this scenario. It is possible that downstream structures in the brain that integrate value signals from the OFC may reflect this attention bias.</p>
</sec>
</sec>
<sec id="s5">
<title>Summary</title>
<p>Based on these results, we may speculate how the OFC supports value-based decision making when multiple items are presented simultaneously. During decision making, the brain evaluates the value of each item sequentially, and the visual features of each item play an important role in guiding the attention to and away from each item. The OFC activity encodes the value of the attended item during this process. Another downstream brain area may extract the information encoded in the OFC and carry out the decision making. Many interesting details in this speculation are still missing but can be addressed with following-up studies.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by the CAS Hundreds of Talents Program, and by Science and Technology Commission of Shanghai Municipality (15JC1400104). We thank Elisabeth Murray and Peter Rudebeck for comments on the manuscript, and Cheng Chen, Yang Chen, Yuanfeng Zhang, Zhongqiao Lin, Zhewei Zhang, and Wei Kong for their help in all phases of the study.</p>
</ack>
<sec id="s6">
<title>Author Contributions</title>
<p>T.Y. designed the experiment. Y.X. and T.Y. wrote the manuscript. Y.X. and C.N. collected data. Y.X. analyzed the data.</p>
</sec>
<sec id="s7" sec-type="COI-statement">
<title>Competing Financial Interests</title>
<p><named-content content-type="COI-statement">The authors declare no competing financial interests.</named-content></p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><string-name><surname>McAdams</surname>, <given-names>C. J.</given-names></string-name> &#x0026; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Effects of attention on orientation-tuning functions of single neurons in macaque cortical area V4</article-title>. <source>J Neurosci</source> <volume>19</volume>, <fpage>431</fpage>&#x2013;<lpage>441</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="other"><string-name><surname>Motter</surname>, <given-names>B. C.</given-names></string-name> <article-title>Focal attention produces spatially selective processing in visual cortical areas V1, V2, and V4 in the presence of competing stimuli</article-title>. <source>J Neurophy iol</source></mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Attentional modulation of visual motion processing in cortical areas MT and MST</article-title>. <source>Nature</source> <volume>382</volume>, <fpage>539</fpage>&#x2013;<lpage>541</lpage>, doi:<pub-id pub-id-type="doi">10.1038/382539a0</pub-id> (<year>1996</year>).</mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><string-name><surname>Moran</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>Selective attention gates visual processing in the extrastriate cortex</article-title>. <source>Science</source> <volume>229</volume>, <fpage>782</fpage>&#x2013;<lpage>784</lpage> (<year>1985</year>).</mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><string-name><surname>O&#x0027;Neill</surname>, <given-names>M.</given-names></string-name> &#x0026; <string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name> <article-title>Economic risk coding by single neurons in the orbitofrontal cortex</article-title>. <source>Journal of physiology, Paris</source> <volume>109</volume>, <fpage>70</fpage>&#x2013;<lpage>77</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.jphysparis.2014.06.002</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="journal"><string-name><surname>Padoa-Schioppa</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name> <article-title>Neurons in the orbitofrontal cortex encode economic value</article-title>. <source>Nature</source> <volume>441</volume>, <fpage>223</fpage>&#x2013;<lpage>226</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature04676</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><string-name><surname>Rudebeck</surname>, <given-names>P. H.</given-names></string-name>, <string-name><surname>Saunders</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Prescott</surname>, <given-names>A. T.</given-names></string-name>, <string-name><surname>Chau</surname>, <given-names>L. S.</given-names></string-name> &#x0026; <string-name><surname>Murray</surname>, <given-names>E. A.</given-names></string-name> <article-title>Prefrontal mechanisms of behavioral flexibility, emotion regulation and value updating</article-title>. <source>Nat Neurosci</source> <volume>16</volume>, <fpage>1140</fpage>&#x2013;<lpage>1145</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.3440</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><string-name><surname>Wallis</surname>, <given-names>J. D.</given-names></string-name> &#x0026; <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name> <article-title>Neuronal activity in primate dorsolateral and orbital prefrontal cortex during performance of a reward preference task</article-title>. <source>The European journal of neuroscience</source> <volume>70</volume>, <fpage>909</fpage>&#x2013;<lpage>919</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><string-name><surname>Carmichael</surname>, <given-names>S. T.</given-names></string-name> &#x0026; <string-name><surname>Price</surname>, <given-names>J. L.</given-names></string-name> <article-title>Sensory and premotor connections of the orbital and medial prefrontal cortex of macaque monkeys</article-title>. <source>The Journal of comparative neurology</source> <volume>18</volume>, <fpage>2069</fpage>&#x2013;<lpage>2081</lpage> (<year>2003</year>). (1995).</mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><string-name><surname>Carmichael</surname>, <given-names>S. T.</given-names></string-name> &#x0026; <string-name><surname>Price</surname>, <given-names>J. L.</given-names></string-name> <article-title>Limbic connections of the orbital and medial prefrontal cortex in macaque monkeys</article-title>. <source>The Journal of comparative neurology</source> <volume>363</volume>, <fpage>642</fpage>&#x2013;<lpage>664</lpage>, doi:<pub-id pub-id-type="doi">10.1002/cne.903630409</pub-id></mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><string-name><surname>Grattan</surname>, <given-names>L. E.</given-names></string-name> &#x0026; <string-name><surname>Glimcher</surname>, <given-names>P. W.</given-names></string-name> <article-title>Absence of spatial tuning in the orbitofrontal cortex</article-title>. <source>PLoS One</source> <volume>9</volume>, <fpage>e112750</fpage>, doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0112750</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><string-name><surname>Kennerley</surname>, <given-names>S. W.</given-names></string-name> &#x0026; <string-name><surname>Wallis</surname>, <given-names>J. D.</given-names></string-name> <article-title>Encoding of reward and space during a working memory task in the orbitofrontal cortex and anterior cingulate sulcus</article-title>. <source>J Neurophysiol</source> <volume>102</volume>, <fpage>3352</fpage>&#x2013;<lpage>3364</lpage>, doi:<pub-id pub-id-type="doi">10.1152/jn.00273.2009</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><string-name><surname>Cai</surname>, <given-names>X.</given-names></string-name> &#x0026; <string-name><surname>Padoa-Schioppa</surname>, <given-names>C.</given-names></string-name> <article-title>Contributions of orbitofrontal and lateral prefrontal cortices to economic choice and the good-to-action transformation</article-title>. <source>Neuron</source> <volume>81</volume>, <fpage>1140</fpage>&#x2013;<lpage>1151</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.008</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><string-name><surname>Rudebeck</surname>, <given-names>P. H.</given-names></string-name>, <string-name><surname>Mitz</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Chacko</surname>, <given-names>R. V.</given-names></string-name> &#x0026; <string-name><surname>Murray</surname>, <given-names>E. A.</given-names></string-name> <article-title>Effects of amygdala lesions on reward-value coding in orbital and medial prefrontal cortex</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>1519</fpage>&#x2013;<lpage>1531</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.036</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><string-name><surname>Blanchard</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Hayden</surname>, <given-names>B. Y.</given-names></string-name> &#x0026; <string-name><surname>Bromberg-Martin</surname>, <given-names>E. S.</given-names></string-name> <article-title>Orbitofrontal cortex uses distinct codes for different choice attributes in decisions motivated by curiosity</article-title>. <source>Neuron</source> <volume>85</volume>, <fpage>602</fpage>&#x2013;<lpage>614</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.050</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><string-name><surname>McGinty</surname>, <given-names>V. B.</given-names></string-name>, <string-name><surname>Rangel</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> <article-title>Orbitofrontal Cortex Value Signals Depend on Fixation Location during Free Viewing</article-title>. <source>Neuron</source> <volume>90</volume>, <fpage>1299</fpage>&#x2013;<lpage>1311</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.045</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><string-name><surname>Rich</surname>, <given-names>E. L.</given-names></string-name> &#x0026; <string-name><surname>Wallis</surname>, <given-names>J. D.</given-names></string-name> <article-title>Decoding subjective decisions from orbitofrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>19</volume>, <fpage>973</fpage>&#x2013;<lpage>980</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.4320</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Neuronal representations of cognitive state: reward or attention?</article-title> <source>Trends Cogn Sci</source> <volume>8</volume>, <fpage>261</fpage>&#x2013;<lpage>265</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tics.2004.04.003</pub-id> (<year>2004</year>).</mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><string-name><surname>Balan</surname>, <given-names>P. F.</given-names></string-name> &#x0026; <string-name><surname>Gottlieb</surname>, <given-names>J.</given-names></string-name> <article-title>Integration of exogenous input into a dynamic salience map revealed by perturbing attention</article-title>. <source>J Neurosci</source> <volume>26</volume>, <fpage>9239</fpage>&#x2013;<lpage>9249</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1898-06.2006</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><string-name><surname>Walker</surname>, <given-names>A. E.</given-names></string-name> <article-title>A cytoarchitectural study of the prefrontal area of the macaque monkey</article-title>. <source>Journal of Comparative Neurology</source> <volume>73</volume>, <fpage>59</fpage>&#x2013;<lpage>86</lpage>, doi:<pub-id pub-id-type="doi">DOI 10.1002/cne.900730106</pub-id> (<year>1940</year>).</mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><string-name><surname>Hochberg</surname>, <given-names>Y.</given-names></string-name> &#x0026; <string-name><surname>Benjamini</surname>, <given-names>Y.</given-names></string-name> <article-title>More powerful procedures for multiple significance testing</article-title>. <source>Stat Med</source> <volume>9</volume>, <fpage>811</fpage>&#x2013;<lpage>818</lpage> (<year>1990</year>).</mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><string-name><surname>Ghose</surname>, <given-names>G. M.</given-names></string-name> &#x0026; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Spatial summation can explain the attentional modulation of neuronal responses to multiple stimuli in area V4</article-title>. <source>J Neurosci</source> <volume>28</volume>, <fpage>5115</fpage>&#x2013;<lpage>5126</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0138-08.2008</pub-id> (<year>2008</year>).</mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Vis Neurosci</source> <volume>9</volume>, <fpage>181</fpage>&#x2013;<lpage>197</lpage> (<year>1992</year>).</mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><string-name><surname>Reynolds</surname>, <given-names>J. H.</given-names></string-name> &#x0026; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> <article-title>The normalization model of attention</article-title>. <source>Neuron</source> <volume>61</volume>, <fpage>168</fpage>&#x2013;<lpage>185</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>A normalization model of attentional modulation of single unit responses</article-title>. <source>PLoS One</source> <volume>4</volume>, <fpage>e4651</fpage>, doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0004651</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><string-name><surname>Padoa-Schioppa</surname>, <given-names>C.</given-names></string-name> <article-title>Neuronal origins of choice variability in economic decisions</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>1322</fpage>&#x2013;<lpage>1336</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.013</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><string-name><surname>Strait</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>Blanchard</surname>, <given-names>T. C.</given-names></string-name> &#x0026; <string-name><surname>Hayden</surname>, <given-names>B. Y.</given-names></string-name> <article-title>Reward value comparison via mutual inhibition in ventromedial prefrontal cortex</article-title>. <source>Neuron</source> <volume>82</volume>, <fpage>1357</fpage>&#x2013;<lpage>1366</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.032</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><string-name><surname>Chelazzi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>A neural basis for visual search in inferior temporal cortex</article-title>. <source>Nature</source> <volume>363</volume>, <fpage>345</fpage>&#x2013;<lpage>347</lpage>, doi:<pub-id pub-id-type="doi">10.1038/363345a0</pub-id> (<year>1993</year>).</mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><string-name><surname>Peck</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Lau</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Salzman</surname>, <given-names>C. D.</given-names></string-name> <article-title>The primate amygdala combines information about space and value</article-title>. <source>Nat Neurosci</source> <volume>16</volume>, <fpage>340</fpage>&#x2013;<lpage>348</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.3328</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c30"><label>30</label><mixed-citation publication-type="journal"><string-name><surname>Beck</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Probabilistic population codes for Bayesian decision making</article-title>. <source>Neuron</source> <volume>60</volume>, <fpage>1142</fpage>&#x2013;<lpage>1152</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.021</pub-id> (<year>2008</year>).</mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="journal"><string-name><surname>Murray</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Moylan</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Saleem</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Basile</surname>, <given-names>B. M.</given-names></string-name> &#x0026; <string-name><surname>Turchi</surname>, <given-names>J.</given-names></string-name> <article-title>Specialized areas for value updating and goal selection in the primate orbitofrontal cortex</article-title>. <source>Elife</source> <volume>4</volume>, doi:<pub-id pub-id-type="doi">10.7554/eLife.11695</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="journal"><string-name><surname>Chelazzi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>Responses of neurons in macaque area V4 during memory-guided visual search</article-title>. <source>Cereb Cortex</source> <volume>11</volume>, <fpage>761</fpage>&#x2013;<lpage>772</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Attentional modulation of MT neurons with single or multiple stimuli in their receptive fields</article-title>. <source>J Neurosci</source> <volume>30</volume>, <fpage>3058</fpage>&#x2013;<lpage>3066</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3766-09.2010</pub-id> (<year>2010</year>).</mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><string-name><surname>Reynolds</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Chelazzi</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>Competitive mechanisms subserve attention in macaque areas V2 and V4</article-title>. <source>J Neurosci</source> <volume>19</volume>, <fpage>1736</fpage>&#x2013;<lpage>1753</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><string-name><surname>Ni</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Ray</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Tuned normalization explains the size of attention modulations</article-title>. <source>Neuron</source> <volume>73</volume>, <fpage>803</fpage>&#x2013;<lpage>813</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.006</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="journal"><string-name><surname>Oh</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal> <article-title>Satisficing in split-second decision making is characterized by strategic cue discounting</article-title>. <source>J Exp Psychol Learn Mem Cogn</source> <volume>42</volume>, <fpage>1937</fpage>&#x2013;<lpage>1956</lpage>, doi:<pub-id pub-id-type="doi">10.1037/xlm0000284</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><string-name><surname>Padoa-Schioppa</surname>, <given-names>C.</given-names></string-name> <article-title>Neurobiology of economic choice: a good-based model</article-title>. <source>Annu Rev Neurosci</source> <volume>34</volume>, <fpage>333</fpage>&#x2013;<lpage>359</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113648</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="journal"><string-name><surname>Lim</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>O&#x0027;Doherty</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Rangel</surname>, <given-names>A.</given-names></string-name> <article-title>The decision value computations in the vmPFC and striatum use a relative value code that is guided by visual attention</article-title>. <source>J Neurosci</source> <volume>31</volume>, <fpage>13214</fpage>&#x2013;<lpage>13223</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1246-11.2011</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><string-name><surname>Krajbich</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Armel</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Rangel</surname>, <given-names>A.</given-names></string-name> <article-title>Visual fixations and the computation and comparison of value in simple choice</article-title>. <source>Nat Neurosci</source> <volume>13</volume>, <fpage>1292</fpage>&#x2013;<lpage>1298</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.2635</pub-id> (<year>2010</year>).</mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="journal"><string-name><surname>Armel</surname>, <given-names>K. C.</given-names></string-name>, <string-name><surname>Beaumel</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Rangel</surname>, <given-names>A.</given-names></string-name> <article-title>Biasing simple choices by manipulating relative visual attention</article-title>. <source>Judgm Decis Mak</source> <volume>3</volume>, <fpage>396</fpage>&#x2013;<lpage>403</lpage> (<year>2008</year>).</mixed-citation></ref>
</ref-list>
</back>
</article>