<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/109108</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Microbiology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Holographic deep learning for rapid optical screening of anthrax spores</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Jo</surname><given-names>YoungJu</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="author-notes" rid="n1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Park</surname><given-names>Sangjin</given-names></name>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="aff" rid="a3">c</xref>
<xref ref-type="author-notes" rid="n1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Jung</surname><given-names>JaeHwang</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Yoon</surname><given-names>Jonghee</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Joo</surname><given-names>Hosung</given-names></name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kim</surname><given-names>Min-hyeok</given-names></name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kang</surname><given-names>Suk-Jo</given-names></name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Choi</surname><given-names>Myung Chul</given-names></name>
<xref ref-type="aff" rid="a6">f</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Lee</surname><given-names>Sang Yup</given-names></name>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="corresp" rid="cor1">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Park</surname><given-names>YongKeun</given-names></name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a7">g</xref>
<xref ref-type="corresp" rid="cor1">2</xref>
</contrib>
<aff id="a1">
<label>a</label>
<institution>Department of Physics, Korea Advanced Institute of Science and Technology (KAIST)</institution>, Daejeon 34141, <country>Republic of Korea</country></aff>
<aff id="a2">
<label>b</label>
<institution>Department of Chemical and Biomolecular Engineering, KAIST</institution>, Daejeon 34141, <country>Republic of Korea</country></aff>
<aff id="a3">
<label>c</label>
<institution>Agency for Defense Development (ADD)</institution>, Daejeon 34186, <country>Republic of Korea</country>.
</aff>
<aff id="a4">
<label>d</label>
<institution>School of Electrical Engineering, KAIST</institution>, Daejeon 34141, <country>Republic of Korea</country></aff>
<aff id="a5">
<label>e</label>
<institution>Department of Biological Sciences, KAIST</institution>, Daejeon 34141, <country>Republic of Korea</country></aff>
<aff id="a6">
<label>f</label>
<institution>Department of Bio and Brain Engineering, KAIST</institution>, Daejeon 34141, <country>Republic of Korea</country></aff>
<aff id="a7">
<label>g</label>
<institution>Tomocube Inc.</institution>, Daejeon 34051, <country>Republic of Korea</country></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>1</label><p>Y.J. and S.P. contributed equally to this work.</p></fn>
<corresp id="cor1">
<label>2</label>To whom correspondence may be addressed. Email: <email>leesy@kaist.ac.kr</email> or <email>yk.park@kaist.ac.kr</email>.</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>109108</elocation-id>
<history>
<date date-type="received">
<day>16</day>
<month>2</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>16</day>
<month>2</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="109108.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Establishing early warning systems for anthrax attacks is crucial in biodefense. Here we present an optical method for rapid screening of <italic>Bacillus anthracis</italic> spores through the synergistic application of holographic microscopy and deep learning. A deep convolutional neural network is designed to classify holographic images of unlabeled living cells. After training, the network outperforms previous techniques in all accuracy measures, achieving single-spore sensitivity and sub-genus specificity. The unique &#x2018;representation learning&#x2019; capability of deep learning enables direct training from <italic>raw images</italic> instead of manually extracted features. The method automatically recognizes key biological traits encoded in the images and exploits them as fingerprints. This remarkable learning ability makes the proposed method readily applicable to classifying various single cells in addition to <italic>B. anthracis</italic>, as demonstrated for the diagnosis of <italic>Listeria monocytogenes</italic>, without any modification. We believe that our strategy will make holographic microscopy more accessible to medical doctors and biomedical scientists for easy, rapid, and accurate diagnosis of pathogens, and facilitate exciting new applications.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>anthrax spores</kwd>
<kwd>deep learning</kwd>
<kwd>holographic microscopy</kwd>
<kwd>quantitative phase imaging</kwd>
<kwd>pathogen diagnosis</kwd>
<kwd>biological warfare</kwd>
</kwd-group>
<counts>
<page-count count="12"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p><italic>Bacillus anthracis</italic>, a gram-positive spore-forming bacterium causing the disease anthrax, is one of the most destructive biological weapons that is prone to be abused for bioterrorism (<xref rid="c1" ref-type="bibr">1</xref>). It is thus crucial to rapidly detect and identify anthrax spores for biodefense (<xref rid="c2" ref-type="bibr">2</xref>). Various biological, chemical, and optical fingerprinting methods have been studied to accelerate diagnosis of <italic>B. anthracis</italic> (<xref rid="c3" ref-type="bibr">3</xref>-<xref rid="c5" ref-type="bibr">5</xref>). Conventional culture-based methods take days and are often inaccurate. PCR-based methods provide species-level specificity but still take hours and require heavy instrumentation with skilled personnel to operate the system (<xref rid="c4" ref-type="bibr">4</xref>). Photoluminescence and surface-enhanced Raman scattering methods take only minutes, but require labeling with exogenous agents and cannot discriminate <italic>B. anthracis</italic> from other <italic>Bacillus</italic> species which are ubiquitous in nature (<xref rid="c5" ref-type="bibr">5</xref>). More importantly, most of these methods are limited by the detection sensitivity of at least thousands of bacterial cells; thus, their applications in practical settings such as aerosolized spores require sample amplification processes that significantly limit the detection speed.</p>
<p>Recent developments of optical methods based on holographic microscopy combined with machine learning, which enables rapid and label-free identification of <italic>single</italic> cells, could be an important step to address the anthrax issue (<xref rid="c6" ref-type="bibr">6</xref>-<xref rid="c11" ref-type="bibr">11</xref>). Holographic microscopy (<xref rid="c12" ref-type="bibr">12</xref>), or quantitative phase imaging (QPI) in a broader sense, measures optical field images (i.e., nanometer-scale distortions of wavefronts passing through a sample) using laser-based interferometry. In addition to the amplitude images available from conventional intensity-based microscopy techniques, holographic microscopy <italic>quantitatively</italic> measures the optical phase delay maps dictated by the refractive index (RI) distribution of a sample (<xref rid="c12" ref-type="bibr">12</xref>). Because the endogenous RI distribution in a cell is strongly related to the structural and biochemical characteristics (<xref rid="c13" ref-type="bibr">13</xref>) of the target classes (e.g., species or cell types), the measured field images of single cells and the corresponding class labels are passed to data-driven machine learning algorithms for systematic discovery of class-specific fingerprints encoded in the images. These approaches can be combined with flow cytometry and/or bioaerosol collection systems to achieve ultrafast identification of unlabeled cells and pathogens (<xref rid="c9" ref-type="bibr">9</xref>, <xref rid="c10" ref-type="bibr">10</xref>). However, none of these methods achieved <italic>sub-genus specificity</italic> required for discriminating <italic>B. anthracis</italic> from other <italic>Bacillus</italic> species ubiquitous in nature.</p>
<p>Here we present a next-generation holographic screening method by adopting &#x2018;deep learning&#x2019;, a state-of-the-art machine learning technique based on deep multi-layered neural networks (<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c15" ref-type="bibr">15</xref>), to holographic microscopy. We designed a deep convolutional neural network (CNN) HoloConvNet specialized in the classification of holographic images of living cells. After training with quantitative phase images of individual <italic>Bacillus</italic> spores, the network identified new anthrax spores with single-spore sensitivity and sub-genus specificity. Its remarkable learning ability enables direct training from <italic>raw images</italic> by automatically recognizing key biological traits encoded in the images, and presents outstanding accuracy that outperforms previous approaches in all accuracy measures. As demonstrated below, this method is readily applicable to classification of various single cells in addition to <italic>B. anthracis</italic> without any modification.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The holographic deep learning framework</title>
<p>The overall framework of our method is shown in <xref rid="fig1" ref-type="fig">Fig. 1</xref>. We used quantitative phase imaging unit (QPIU), a cost-effective palm-sized module that converts a conventional microscope into a holographic microscope (<xref rid="c16" ref-type="bibr">16</xref>), for phase imaging of individual <italic>Bacillus</italic> spores in an isolated biosafety level 3 (BSL-3) laboratory at the Agency for Defense Development, Korea. It is attached to the output port of an existing bright-field microscope to form a common-path interferometry for optical field imaging (<xref rid="fig1" ref-type="fig">Fig. 1 <italic>A-C</italic></xref>; see <italic>Materials and Methods</italic>). After imaging <italic>B. anthracis</italic> and four different <italic>Bacillus</italic> species with various levels of phylogenetic relatedness (see Supplementary Note 1), we trained our deep neural network named HoloConvNet as a species classifier using the phase images of individual spores and the corresponding species labels (training set). The learnable parameters of the deep neural network were iteratively adjusted by the error backpropagation algorithm(<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c15" ref-type="bibr">15</xref>) (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>). The performance of the trained HoloConvNet was tested by taking new images (test set), which were never seen before by the network, as the input to the network (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>). The machine-predicted species labels were compared with the true classes to estimate identification accuracy.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 1.</label>
<caption><p>Holographic deep learning framework for screening of anthrax spores. (<italic>A</italic>) Schematic diagram of QPIUfor holographic imaging of individual <italic>Bacillus</italic> spores. (<italic>B</italic>) An interferogram formed by spatial modulation. It encodes quantitative phase images of individual spores as shown in (<italic>C</italic>). (<italic>D</italic>) The measured phase images from multiple <italic>Bacillus</italic> species are used to train a deep neural network using the error backpropagation algorithm. (<italic>E</italic>) The trained network accurately predicts the corresponding species when independently-measured phase images are shown.</p></caption>
<graphic xlink:href="109108_fig1.tif"/>
</fig>
<p>The <italic>quantitative</italic> nature of holographic microscopy captures subcellular phase delay distribution which could be exploited by machine learning algorithms to extract fingerprint information (<xref rid="c8" ref-type="bibr">8</xref>, <xref rid="c13" ref-type="bibr">13</xref>). On the other hand, conventional techniques (e.g., phase contrast microscopy) provide rough morphological information only (Fig. S1). Simple morphological parameters such as spore size (Fig. S2) are not enough for species discrimination due to high genetic similarities and large cell-to-cell variations (<xref rid="c8" ref-type="bibr">8</xref>, <xref rid="c16" ref-type="bibr">16</xref>).</p>
<p>The endogenous RI distribution of <italic>Bacillus</italic> spores, which dictates the sample-induced phase delay imaged by QPIU, is strongly related to specific characteristics of each species (<xref rid="c8" ref-type="bibr">8</xref>, <xref rid="c13" ref-type="bibr">13</xref>). However, because this relation is often <italic>indirect</italic>, it should be <italic>approximated</italic> using supervised learning. The precision of this function approximation obviously dominates the performance of the trained classifiers. Deep neural networks are <italic>universal approximators</italic> for virtually any arbitrarily nonlinear functions (<xref rid="c15" ref-type="bibr">15</xref>), while conventional machine learning techniques mostly rely on linear or only slightly nonlinear decision boundaries (<xref rid="c8" ref-type="bibr">8</xref>).</p>
<p>The network architecture of HoloConvNet is illustrated in <xref rid="fig2" ref-type="fig">Fig. 2</xref> (and Table S1). A phase image of a single spore is processed by multiple layers of convolution, nonlinearity, and pooling operations, and then finally receives scored class labels through fully-connected layers. The network makes its prediction by selecting the final-layer neuron with the strongest activation. The key functional block of this process is a convolutional layer followed by nonlinearity:
<disp-formula id="eqn1">
<alternatives>
<graphic xlink:href="109108_eqn1.gif"/>
</alternatives>
</disp-formula>
where <italic>x</italic> and <italic>y</italic> are input and output vectors, and <italic>w</italic> and <italic>b</italic> are synaptic weights and biases, respectively. <xref rid="eqn1" ref-type="disp-formula">Equation 1</xref> emulates integration of synaptic inputs by a biological neuron (<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c15" ref-type="bibr">15</xref>) that fires only when the net input exceeds a certain threshold (more precisely, a population of neurons with an output firing rate modeled by a rectified linear unit (ReLU)). Note that the entire processing by the network from images to class labels is a <italic>nonlinear</italic> mapping which corresponds to the approximating function explained above.
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 2.</label>
<caption><p>Architecture of HoloConvNet. When a phase image of an individual spore is taken as the input, thenetwork first processes the images through 3 rounds of convolution, ReLU nonlinearity, and max pooling layers. Then two fully-connected (and ReLU) layers follow; the first is the last hidden layer under dropout regularization, and the second is the output layer with the class scores. These scores are used to calculate the loss function and to make species predictions in the training and test stages, respectively. Only 10 two-dimensional activation maps per layer are presented with layer-wise scaling for visualization (see Table S1 for detailed architecture).</p></caption>
<graphic xlink:href="109108_fig2.tif"/>
</fig></p>
<p>Training a deep neural network is essentially a large-scale nonlinear optimization of the synaptic weights (and biases) which govern the network behaviour. The large number of the learnable parameters makes training process extremely difficult. However, CNNs such as HoloConvNet have dramatically smaller number of parameters (<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c17" ref-type="bibr">17</xref>) by employing localized and shared receptive field structures inspired by physiological visual processing (see Supplementary Note 2). Thus the network can be trained using the error back propagation algorithm that minimizes the mismatch between the machine-predicted and true labels (see <italic>Materials and Methods</italic>). HoloConvNet efficiently converges to a hierarchical <italic>representation</italic> of the images that gradually transforms the data space in which the classes are easily separable. This property is called the &#x2018;representation learning&#x2019; capability of deep learning (<xref rid="c14" ref-type="bibr">14</xref>) and enables direct training from <italic>raw images</italic>.</p>
</sec>
<sec id="s2b">
<title>Performance</title>
<p>The performance of HoloConvNet is shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref>. A well-trained neural network reflects the general relations between the input and output data, so that it accurately predicts the class labels of new images (<italic>generalization</italic> property). The multiclass identification performance of the network for the five <italic>Bacillus</italic> species, trained with 5 class labels representing individual species, is shown in <xref rid="fig3" ref-type="fig">Fig. 3A</xref>. HoloConvNet clearly identifies <italic>B. anthracis</italic> spores from the other four species with high sensitivity and specificity. Since diagnosing anthrax spores from other species is our prime objective, the network was next trained with binary class labels (anthrax versus non-anthrax). Using this method, the performance could be enhanced (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>) by letting the optimization process focus on the characteristics distinguishing <italic>B. anthracis</italic> from others. When the problem was relaxed by excluding the two <italic>Bacillus cereus</italic> group species (note that these species are rare, while <italic>Bacillus subtilis</italic> is ubiquitous in nature; see Supplementary Note 1), HoloConvNet achieved a remarkable accuracy of 95.3&#x0025; (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>).
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 3.</label>
<caption><p>Performance of HoloConvNet. (<italic>A</italic>-<italic>C</italic>) The test images were used to measure the performance of (<italic>A</italic>)multiclass classification of 5 <italic>Bacillus</italic> species; (<italic>B</italic>) binary classification of <italic>B. anthracis</italic> and the other 4 species; (<italic>C</italic>) binary classification of <italic>B. anthracis</italic> and 2 non-member species of the <italic>B. cereus</italic> group. (<italic>D</italic>) The performance of the proposed method is compared to previous techniques (see the main text). Holographic microscopy and deep learning significantly improve the performance in all cases.</p></caption>
<graphic xlink:href="109108_fig3.tif"/>
</fig></p>

<p>The performance of our method was compared with those of several previous techniques (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>): holographic microscopy with conventional machine learning (<xref rid="c8" ref-type="bibr">8</xref>), conventional microscopy with deep learning (training HoloConvNet with binary morphology images; see <italic>Materials and Methods</italic>), and conventional microscopy with conventional machine learning (linear discriminant analysis with the morphological parameters in Fig. S2). HoloConvNet outperformed the previous methods in all accuracy measures, which clearly demonstrates the great potential of deep-learning-based holographic screening of anthrax spores in realistic settings.</p>
</sec>
<sec id="s2c">
<title>Representation learning</title>
<p>Representation learning by HoloConvNet, the fundamental improvement developed in this study, was further examined (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). The network transforms the images into a representation in which the data points are linearly separable because a single layer of neurons is a linear classifier (<xref rid="c15" ref-type="bibr">15</xref>). We applied t-distributed stochastic neighbor embedding (t-SNE), a high-dimensional data visualization technique (<xref rid="c18" ref-type="bibr">18</xref>), to the activation of individual neurons in the last hidden layer (<xref rid="fig4" ref-type="fig">Fig. 4 <italic>A-C</italic></xref>; see <italic>Materials and Methods</italic>). The nice separation observed indicates the great ability of HoloConvNet to learn the optimal representation of phase images without any pre-designed features required by conventional machine learning techniques. The different degrees of separation in the three cases explain the different identification performance. Additionally, the relative distances between the species clusters shown in <xref rid="fig4" ref-type="fig">Fig. 4A</xref> are consistent with the phylogenetic relationship (see Supplementary Note 1); here it should be noted that the relationship was independently discovered by HoloConvNet through training.
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 4.</label>
<caption><p>Representation learning by HoloConvNet. The inter-species difference in cellular dry mass isautomatically recognized and used for screening of anthrax spores. (<italic>A-C</italic>) t-SNE visualization of the CNN codes at the last hidden layer, which shows the representation learning capability of HoloConvNet (see the main text). (<italic>D</italic>-<italic>F</italic>) The activation of the &#x2018;anthrax neuron&#x2019; at the output layer shows a strong correlation with dry mass. (<italic>G</italic>), Dry mass of individual <italic>Bacillus</italic> spores calculated from the quantitative phase images. (<italic>H</italic>) Computationally disabling the dry mass information significantly impairs the performance of HoloConvNet. Dry mass alone is not enough for full performance as well.</p></caption>
<graphic xlink:href="109108_fig4.tif"/>
</fig></p>
<p>The outstanding performance of the proposed method raises a question: what are the <italic>key biological traits</italic> that are measured and exploited for the identification of anthrax spores? We speculated that <italic>cellular dry mass</italic> (<xref rid="c19" ref-type="bibr">19</xref>), the mass of non-aqueous cellular components, is one of the most important traits. This hypothesis is based on the domain knowledge that there exists an additional outermost structure, called the exosporium, in the <italic>B. cereus</italic> group spores but not in the remaining two species (<xref rid="c20" ref-type="bibr">20</xref>). It was reasoned that structural distinction might result in an inter-species difference of dry mass which is inherently measured by holographic imaging with femtogram-level sensitivity (see <italic>Materials and Methods</italic>). Indeed, a strong positive correlation was found between dry mass and activation of the &#x2018;anthrax neuron&#x2019; at the output layer (<xref rid="fig4" ref-type="fig">Fig. 4 <italic>D-F</italic></xref>). This observation makes sense if the mean dry mass of <italic>B. anthracis</italic> is the heaviest among the five species, which turns out to be true (<xref rid="fig4" ref-type="fig">Fig. 4G</xref>). As expected, <italic>B. anthracis</italic> is slightly heavier than the other two <italic>B. cereus</italic> group species, and the remaining two species lacking exosporium have considerably lighter dry mass. The subtle difference within the <italic>B. cereus</italic> group might be due to species-dependent compositions and nanostructures of exosporium (<xref rid="c21" ref-type="bibr">21</xref>), while their contribution to dry mass should be confirmed by additional investigations. It was noted that the same order relation of dry mass was observed in all independent measurements (Fig. S3), and the overall range of measured dry mass is consistent with previous studies (<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c22" ref-type="bibr">22</xref>).</p>
<p>To confirm the causality between dry mass and species prediction by HoloConvNet, a computational disabling strategy was employed. Detrimental effects on the performance were observed by computationally normalizing the phase images to remove the dry mass information. As shown in <xref rid="fig4" ref-type="fig">Fig. 4H</xref>, the network trained and tested with normalized phase images shows a significantly impaired performance, supporting the key role of dry mass. However, it does not mean that it is the sole information extracted by the network; the performance of a single-feature linear discriminant classifier based solely on dry mass was also significantly worse. This suggests that other traits such as spatial distribution of subcellular components in the spores play roles in screening. From these observations, it can be concluded that the inter-species difference of dry mass is recognized and exploited through representation learning by HoloConvNet. Here, it should be emphasized that we never taught the network on how to calculate dry mass from phase images. On the other hand, a conventional machine learning algorithm cannot make use of dry mass unless it is manually selected by a researcher.</p>
<p>Finally, the <italic>generality</italic> of our method expected from the outstanding learning abilities was investigated. As a proof-of-concept example, HoloConvNet was trained for diagnosing the pathogen <italic>L. monocytogenes</italic>, the causative agent of listeriosis which is often fatal to neonates and the elderly (<xref rid="c23" ref-type="bibr">23</xref>), from five different <italic>Listeria</italic> species. The diagnostic accuracy was surprisingly high, showing higher than 85&#x0025;. The architecture and learning rules were identical to those used for the diagnosis of <italic>Bacillus</italic> species. It is also noted that <italic>L. monocytogenes</italic> is not the species with the heaviest dry mass in this case (Fig. S4). These results suggest that the holographic deep learning framework reported here has immediate and wide applicability in contrast to problem-specific conventional machine learning approaches.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We proposed and experimentally demonstrated a novel method for screening of anthrax spores by combining holographic microscopy and deep learning for the first time. The new strategy enables rapid label-free identification of individual anthrax spores with <italic>sub-genus</italic> specificity extending our previous <italic>inter-genus</italic> bacterial fingerprinting method based on conventional machine learning (<xref rid="c8" ref-type="bibr">8</xref>). In addition to the superior performance due to the extreme flexibility of deep neural networks, the transition from classical machine learning to deep learning fundamentally transforms holographic single-cell identification techniques by acquiring the <italic>representation learning</italic> capability. HoloConvNet automatically recognizes and then uses key biological characteristics which are species-dependent (e.g., dry mass in the anthrax problem) simply from <italic>raw</italic> images. Additionally, the present method can be readily extended to other single-cell classification problems, such as the diagnosis of <italic>L. monocytogenes</italic> demonstrated in this study, without any modification. Thus, our method eliminates the need to manually design and optimize features based on trial-and-error for individual problems.</p>
<p>The next steps beyond this proof-of-concept study to achieve practical ultrafast screening of anthrax spores are straightforward. Above all, the proposed method should be combined with flow cytometry (<xref rid="c9" ref-type="bibr">9</xref>, <xref rid="c10" ref-type="bibr">10</xref>) and bioaerosol collection(<xref rid="c24" ref-type="bibr">24</xref>) systems to fully exploit the single-spore and label-free nature of the method. Then, a large amount of holographic imaging data from the resultant high-throughput device would be used to train HoloConvNet for more species and strains under various environmental conditions to assure stable field performance. The performance could be further improved by adopting multimodal QPI (e.g., spectral (<xref rid="c25" ref-type="bibr">25</xref>), polarimetric (<xref rid="c26" ref-type="bibr">26</xref>), or tomographic (<xref rid="c27" ref-type="bibr">27</xref>) images as the stacked input to the network) to increase the amount of raw information investigated by the network.</p>
<p>Despite the fast and label-free nature of holographic microscopy, the limited chemical specificity has left this tool overshadowed by fluorescence microscopy. Specific domain knowledge (e.g., homogeneity of hemoglobin concentration in red blood cells, high RI of lipid droplets in eukaryotic cells, etc.) has been required for effective use of the technique. The method proposed in this paper solves this difficulty by using the powerful learning abilities of deep neural networks. As we demonstrated in this study, now <italic>intelligent</italic> holographic microscopy can actively recognize and exploit the class-specific fingerprints, encoded in the raw images of various biological samples, without any prior knowledge. We believe that our strategy will make holographic microscopy more accessible to medical doctors and biomedical scientists for easy, rapid, and accurate diagnosis of pathogens, and facilitate exciting new applications.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Preparation of Bacillus spores</title>
<p><italic>Bacillus anthracis</italic> Sterne (pXO1&#x002B; and pXO2&#x002D;) was obtained from the Centers for Disease Control and Prevention, Korea (KCDC). <italic>Bacillus thuringiensis</italic> BGSC 4AJ1 was obtained from the Bacillus Genetic Stock Center (BGSC). <italic>Bacillus cereus</italic> ATCC 4342 was obtained from the American Type Culture Collection (ATCC). <italic>Bacillus atrophaeus</italic> KCCM 11314 was obtained from the Korean Culture Center for Microorganisms (KCCM). <italic>Bacillus subtilis</italic> 168 was obtained from the Korean Collection for Type Cultures (KCTC).</p>
<p>All experiments involving <italic>B. anthracis</italic> were conducted in a BSL-3 laboratory following the regulations in the Republic of Korea. Bacterial cells from frozen glycerol stocks were streaked onto Luria-Bertani (LB) agar plates and incubated at 30&#x00B0;C overnight. Next day, a single colony was inoculated into 5 mL of LB broth in a 50 mL CELLSTAR CELLreactor tube (Greiner Bio-One, Austria) and incubated at 30&#x00B0;C with shaking (200 rpm) for 8 hours. Then, 250 &#x03BC;L of the culture broth were transferred to 25 mL of GYS sporulation medium (<xref rid="c28" ref-type="bibr">28</xref>) in a 125 mL polycarbonate Erlenmeyer flask with a vent cap (Corning, NY) and incubated at 30&#x00B0;C with shaking (200 rpm) for 48 hours. After sporulation was completed, spores were harvested by centrifugation (5,420&#x00D7;g, 4&#x00B0;C) and washed four times with phosphate-buffered saline (PBS; Life Technologies, CA). Finally, the spores were suspended in 5 mL of PBS and stored at 4&#x00B0;C until use. Note that we prepared all the species with the same procedure.</p>
<p>A small volume (approximately 10 &#x03BC;L) of the bacterial solution was placed in an imaging chamber comprised of standard cover glasses (C024501, Matsunami Glass, Japan) and (optional) spacers with a thickness of 20-30 &#x03BC;m. Imaging was performed at room temperature after the spores settled down to the bottom and spread into a single layer. All <italic>Bacillus</italic> experiments were independently repeated three times.</p>
</sec>
<sec id="s4b">
<title>Holographic imaging</title>
<p>Because all anthrax experiments had to be conducted in a separate BSL-3 facility at the Agency for Defense Development, we used a compact and portable QPIU recently developed in our group(<xref rid="c16" ref-type="bibr">16</xref>), as the holographic imaging modality. It consists of two polarizers (LPVISE100-A, Thorlabs Inc., NJ) and a Rochon prism (#68-824, Edmund Optics Inc., NJ) inside an aluminum tube mounted in front of a CCD camera (FL3-U3-88S2C-C, PointGrey, Canada). Inserting the unit into the output port of a conventional bright-field microscope (B-382PLi-ALC, Optika, Italy) converts it into a holographic microscope. The light source for illumination was a diode laser (CPS532, &#x03BB; = 532 nm, 4.5 mW, Thorlabs Inc., NJ), and the total magnification was &#x00D7;100 determined by an objective lens (M-148, NA 1.25, oil-immersion, Optika, Italy). Acquisition time per interferogram was less than 20 ms, which could be reduced by many orders with high-intensity light sources and more sensitive cameras.</p>
<p>QPIU, shown in <xref rid="fig1" ref-type="fig">Fig. 1A</xref>, is a spatially-modulated self-reference interferometry. When the light passing through the sample encounters the unit, it becomes linearly polarized by the front polarizer. Then, the following Rochon polarizing prism divides the beam into two duplicated beams with slightly different propagation directions. Finally, the orthogonal polarization states of the divided beams become parallel by the rear polarizer. Thus, the two beams of parallel polarization generate an interference pattern at the overlapped region on the CCD plane. The linear polarizers before and after the prism are adjusted so that the interferogram has a high visibility (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). The quantitative phase information is retrieved (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>) from the measured interferogram using a standard field-retrieval algorithm (<xref rid="c29" ref-type="bibr">29</xref>). The details on the principle of QPIU can be found elsewhere(<xref rid="c16" ref-type="bibr">16</xref>).</p>
</sec>
<sec id="s4c">
<title>Image analysis</title>
<p>All image analysis procedures were done with MATLAB (R2014b; MathWorks Inc., MA). The reconstructed phase images containing multiple spores were segmented by phase thresholding to be separated into images of single spores. The isolated spores were computationally aligned at the centres of square backgrounds for further analysis. The segmented regions were considered as the morphologies of individual spores that could be measured with conventional microscopy techniques such as phase contrast microscopy. The representative morphological parameters plotted in Fig. S2 were quantified with the <italic>regionprops</italic> function of MATLAB.</p>
<p>Calculation of the single-spore dry mass from phase images exploited the well-known proportionality between the optical phase delay and cellular dry mass (<xref rid="c30" ref-type="bibr">30</xref>). The total dry mass (<italic>m</italic>) can be calculated from the phase delay map <inline-formula><alternatives><inline-graphic xlink:href="109108_inline1.gif"/></alternatives></inline-formula> as follows:
<disp-formula id="ueqn1">
<alternatives>
<graphic xlink:href="109108_ueqn1.gif"/>
</alternatives>
</disp-formula>
where <italic>&#x03BB;</italic> is the illumination wavelength, <italic>S</italic> is the projection area of the cell surface, and <italic>&#x03B1;</italic> is the RI increment for non-aqueous molecules. Because the RI increment is known to be 0.18&#x2013;0.21 mL/g for typical biological cells (<xref rid="c30" ref-type="bibr">30</xref>), we used <italic>&#x03B1;</italic> = 0.2 mL/g, and the results were consistent with those measured by other techniques (<xref rid="c16" ref-type="bibr">16</xref>, <xref rid="c22" ref-type="bibr">22</xref>, <xref rid="c31" ref-type="bibr">31</xref>). Note that we never explicitly taught the network about this relation.</p>
</sec>
<sec id="s4d">
<title>Deep learning</title>
<p>HoloConvNet is a CNN designed for the classification of holographic images of single cells. We implemented HoloConvNet using MatConvNet (<xref rid="c32" ref-type="bibr">32</xref>) framework (version 1.0 - beta 20) due to its simplicity and compatibility with our experimental data primarily processed with MATLAB. The final network architecture shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref> and Table S1 was carefully chosen after comparing several variations. Motivated by the recent trend for &#x2018;small receptive fields and deep layers,&#x2019; the sizes of the receptive fields of the convolutional layers were chosen to be small (3-by-3), and thus, the total number of learnable parameters was relatively manageable (approximately 0.1 million). Because the architecture is substantially deep, we used the ReLU nonlinearity as the neuron model to avoid the vanishing gradient problem (<xref rid="c33" ref-type="bibr">33</xref>). Note that we used only phase images and not noisy amplitude images (due to the transparency and small sizes of the single spores) as the inputs to the network.</p>
<p>In addition to the traditional &#x2018;weight decay&#x2019; regularization (<xref rid="c15" ref-type="bibr">15</xref>), several recent techniques were used to reduce overfitting. We used the &#x2018;dropout&#x2019; technique, a regularization method based on efficient ensemble learning (<xref rid="c34" ref-type="bibr">34</xref>), for the last hidden layer with a dropout rate of 0.5. For further regularization and accelerated training speed, &#x2018;batch normalization&#x2019; was done at every interface between a convolutional layer and the following ReLU layer (<xref rid="c35" ref-type="bibr">35</xref>). Due to the large number of learnable parameters, we used &#x2018;data augmentation&#x2019; that enlarged the training dataset (<xref rid="c17" ref-type="bibr">17</xref>) by a factor of 128. This is simply done by generating the new labeled images by rotating the original images by random angles sampled from a zero-mean Gaussian distribution with a standard deviation of 10 degrees and by flipping the images with a probability of 0.5.</p>
<p>During the training stage, the learnable parameters were updated toward the direction minimizing the loss function using the concept of error backpropagation (<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c15" ref-type="bibr">15</xref>). We used cross-entropy loss based on softmax function, which quantifies the mismatch between the machine-predicted and true labels, as the objective function to be minimized. By calculating the partial derivatives of the loss function with respect to the elements of the synaptic weight tensors using the chain rule, we could update the parameters in a stochastic gradient descent (SGD) scheme (<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c15" ref-type="bibr">15</xref>). The learning rule was conventional SGD assisted with a momentum of 0.5 (note that using recent learning rules instead could further improve the performance), and the training batch size was 1024. The weights were initialized from a zero-mean Gaussian distribution with layer-wise scaling based on the input sizes (<xref rid="c36" ref-type="bibr">36</xref>). The biases were initialized with the constant 0. We used an equal learning rate for all layers, which was attenuated by a factor of 5 per five epochs (<xref rid="c15" ref-type="bibr">15</xref>). The hyperparameters were selected by cross-validation; the grid searching process with the initial learning rate and weight decay regularization strength resulted in values of 0.05 and 0.0005, respectively. We used one GPU (GeForce GTX 680, NVIDIA, CA) and CUDA Toolkit 7.5 (NVIDIA, CA), which increased the training speed typically by 5-10 fold. We note that it is possible with more computing resources to train multiple network models with different random initializations to compose a committee machine to further enhance the performance (<xref rid="c17" ref-type="bibr">17</xref>). Finally, the identification performance was estimated using separate test images which were never shown during the training stage. The error bars in <xref rid="fig3" ref-type="fig">Figs. 3</xref> and <xref rid="fig4" ref-type="fig">4</xref> represent standard deviation calculated from 10 classification models with different random initializations.</p>
<p>The visualization of HoloConvNet codes was performed by the unsupervised dimensionality reduction technique t-SNE, which embeds high-dimensional data in a low-dimensional space while preserving the pairwise distances of the data points, implemented in MATLAB (<xref rid="c18" ref-type="bibr">18</xref>). The activation strengths of individual neurons at the last hidden layer by the test images were used as the raw variables. The parameters for the stochastic optimization for t-SNE were as follows: the perplexity was 30, and the dimension for initial principal component analysis was 30.</p>
</sec>
<sec id="s4e">
<title>The <italic>Listeria</italic> experiments</title>
<p>The six major bacterial species of the genus <italic>Listeria</italic>, <italic>Listeria monocytogenes</italic> (10403S), <italic>Listeria grayi</italic> (ATCC 19120), <italic>Listeria innocua</italic> (ATCC 33090), <italic>Listeria ivanovii</italic> (ATCC 19119), <italic>Listeria seeligeri</italic> (ATCC 35967), and <italic>Listeria welshimeri</italic> (ATCC 35897), were cultured in Brain-Heart Infusion media without antibiotics. After culturing overnight in a 37&#x00B0;C shaking incubator, the vegetative bacterial cells were washed and diluted with PBS based on the cultured concentration estimated by optical density measurements at 600 nm. The bacterial solution was placed and imaged in imaging chambers described above for the <italic>Bacillus</italic> experiments.</p>
<p>The holographic imaging of prepared samples was done with a Mach-Zehnder interferometry (<xref rid="c12" ref-type="bibr">12</xref>) with varying illumination angles to exploit the high-resolution synthetic aperture imaging technique (<xref rid="c37" ref-type="bibr">37</xref>). Optical field reconstruction and image processing protocols were identical to those of the <italic>Bacillus</italic> experiments.</p>
<p>The same network architecture and learning rule for training the original HoloConvNet (for <italic>Bacillus</italic> spores) were used to train the network for <italic>Listeria</italic>. The only preprocessing was to adjust the size of the input images to match the input dimension of HoloConvNet.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Minho Choi (KAIST) and SangHyun Kim (Samsung Electronics) for assisting the <italic>Listeria</italic> experiments; Kyeong Rok Choi (KAIST) and Seoyun Yum (UTSW) for biological insights; KyeoReh Lee, Kyoohyun Kim, and SangYun Lee (KAIST) for discussions; and Prof. Soo-Young Lee (KAIST) for inspiring lectures on neural networks. This work was supported by KAIST, ADD (ADD-14-70-06-10), National Research Foundation of Korea (2015R1A3A2066550, 2014K1A3A1A09063027, 2014M3C1A3052567), and Tomocube Inc. Y.-J.J. acknowledges support from KAIST Presidential Fellowship.</p>
</ack>
<sec id="s5">
<title>Author Contributions</title>
<p>Y.-J.J. and Y.-K.P. conceived of the original idea for holographic deep learning. S.Y.L. and Y.-K.P. initiated and coordinated the project. Y.-J.J. and H.J. developed and analyzed HoloConvNet framework. J.-H.J. and J.Y. implemented QPIU and analyzed the holographic data. S.P. under the supervision of M.C.C. and S.Y.L. conducted the <italic>Bacillus</italic> experiments. Y.-J.J. and M.-H.K. under the supervision of S.-J.K. and Y.-K.P. performed the <italic>Listeria</italic> experiments. Y.-J.J., S.P., J.-H.J., J.Y., and Y.-K.P. wrote the initial version of the manuscript. All authors revised the manuscript.</p>
</sec>
<sec id="s6" sec-type="COI-statement">
<title>Competing Financial Interests</title>
<p>Y.-K.P. has financial interests in Tomocube Inc., a company that commercializes optical diffraction tomography and phase imaging instruments, and is one of the sponsors of this work.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Brachman</surname><given-names>PS</given-names></string-name> (<year>2002</year>) <article-title>Bioterrorism: an update with a focus on anthrax</article-title>. <source>American Journal of Epidemiology</source> <volume>155</volume>(<issue>11</issue>):<fpage>981</fpage>&#x2013;<lpage>987</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Walt</surname><given-names>DR</given-names></string-name> &#x0026; <string-name><surname>Franz</surname><given-names>DR</given-names></string-name> (<year>2000</year>) <article-title>Peer Reviewed: Biological Warfare Detection</article-title>. <source>Analytical Chemistry</source> <volume>72</volume>(<issue>23</issue>):<fpage>738A</fpage>&#x2013;<lpage>746A</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>King</surname><given-names>D</given-names></string-name>, <string-name><surname>Luna</surname><given-names>V</given-names></string-name>, <string-name><surname>Cannons</surname><given-names>A</given-names></string-name>, <string-name><surname>Cattani</surname><given-names>J</given-names></string-name>, &#x0026; <string-name><surname>Amuso</surname><given-names>P</given-names></string-name> (<year>2003</year>) <article-title>Performance assessment of three commercial assays for direct detection of Bacillus anthracis spores</article-title>. <source>Journal of Clinical Microbiology</source> <volume>41</volume>(<issue>7</issue>):<fpage>3454</fpage>&#x2013;<lpage>3455</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Hurtle</surname><given-names>W</given-names></string-name>, <etal>et al.</etal> (<year>2004</year>) <article-title>Detection of the Bacillus anthracis gyrA gene by using a minor groove binder probe</article-title>. <source>Journal of Clinical Microbiology</source> <volume>42</volume>(<issue>1</issue>):<fpage>179</fpage>&#x2013;<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Young</surname><given-names>MA</given-names></string-name>, <string-name><surname>Lyandres</surname><given-names>O</given-names></string-name>, &#x0026; <string-name><surname>Van Duyne</surname><given-names>RP</given-names></string-name> (<year>2005</year>) <article-title>Rapid detection of an anthrax biomarker by surface-enhanced Raman spectroscopy</article-title>. <source>Journal of the American Chemical Society</source> <volume>127</volume>(<issue>12</issue>):<fpage>4484</fpage>&#x2013;<lpage>4489</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Javidi</surname><given-names>B</given-names></string-name>, <string-name><surname>Daneshpanah</surname><given-names>M</given-names></string-name>, &#x0026; <string-name><surname>Moon</surname><given-names>I</given-names></string-name> (<year>2010</year>) <article-title>Three-Dimensional Holographic Imaging for Identification of Biological Micro/Nanoorganisms</article-title>. <source>IEEE Photonics Journal</source> <volume>2</volume>(<issue>2</issue>):<fpage>256</fpage>&#x2013;<lpage>259</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Moon</surname><given-names>I</given-names></string-name>, <string-name><surname>Daneshpanah</surname><given-names>M</given-names></string-name>, <string-name><surname>Anand</surname><given-names>A</given-names></string-name>, &#x0026; <string-name><surname>Javidi</surname><given-names>B</given-names></string-name> (<year>2011</year>) <article-title>Cell identification computational 3-D holographic microscopy</article-title>. <source>Optics and Photonics News</source> <volume>22</volume>(<issue>6</issue>):<fpage>18</fpage>&#x2013;<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Jo</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>) <article-title>Label-free identification of individual bacteria using Fourier transform light scattering</article-title>. <source>Optics Express</source> <volume>23</volume>(<issue>12</issue>):<fpage>15792</fpage>&#x2013;<lpage>15805</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Vercruysse</surname><given-names>D</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>) <article-title>Three-part differential of unlabeled leukocytes with a compact lens-free imaging flow cytometer</article-title>. <source>Lab on a Chip</source> <volume>15</volume>(<issue>4</issue>):<fpage>1123</fpage>&#x2013;<lpage>1132</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname><given-names>CL</given-names></string-name>, <etal>et al.</etal> (<year>2016</year>) <article-title>Deep Learning in Label-free Cell Classification</article-title>. <source>Scientific Reports</source> <volume>6</volume>:<fpage>21471</fpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Park</surname><given-names>HS</given-names></string-name>, <string-name><surname>Rinehart</surname><given-names>MT</given-names></string-name>, <string-name><surname>Walzer</surname><given-names>KA</given-names></string-name>, <string-name><surname>Chi</surname><given-names>J-TA</given-names></string-name>, &#x0026; <string-name><surname>Wax</surname><given-names>A</given-names></string-name> (<year>2016</year>) <article-title>Automated Detection of P. falciparum Using Machine Learning Algorithms with Quantitative Phase Images of Unstained Cells</article-title>. <source>PLoS One</source> <volume>11</volume>(<issue>9</issue>):<fpage>e0163045</fpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname><given-names>K</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>) <article-title>Quantitative phase imaging techniques for the study of cell pathophysiology: from principles to applications</article-title>. <source>Sensors</source> <volume>13</volume>(<issue>4</issue>):<fpage>4170</fpage>&#x2013;<lpage>4191</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Liu</surname><given-names>P</given-names></string-name>, <etal>et al.</etal> (<year>2016</year>) <article-title>Cell refractive index for cell biology and disease diagnosis: past, present and future</article-title>. <source>Lab on a Chip</source> <volume>16</volume>(<issue>4</issue>):<fpage>634</fpage>&#x2013;<lpage>644</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>LeCun</surname><given-names>Y</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y</given-names></string-name>, &#x0026; <string-name><surname>Hinton</surname><given-names>G</given-names></string-name> (<year>2015</year>) <article-title>Deep learning</article-title>. <source>Nature</source> <volume>521</volume>(<issue>7553</issue>):<fpage>436</fpage>&#x2013;<lpage>444</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="book"><string-name><surname>Haykin</surname><given-names>SS</given-names></string-name>, <string-name><surname>Haykin</surname><given-names>SS</given-names></string-name>, <string-name><surname>Haykin</surname><given-names>SS</given-names></string-name>, &#x0026; <string-name><surname>Haykin</surname><given-names>SS</given-names></string-name> (<year>2009</year>) <source>Neural networks and learning machines</source> (<publisher-name>Pearson</publisher-name>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Jo</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>) <article-title>Angle-resolved light scattering of individual rod-shaped bacteria based on Fourier transform light scattering</article-title>. <source>Scientific reports</source> <volume>4</volume>:<fpage>5090</fpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Krizhevsky</surname><given-names>A</given-names></string-name>, <string-name><surname>Sutskever</surname><given-names>I</given-names></string-name>, &#x0026; <string-name><surname>Hinton</surname><given-names>GE</given-names></string-name> (<year>2012</year>) <article-title>Imagenet classification with deep convolutional neural networks</article-title>. <source>Advances in Neural Information Processing Systems</source>, pp <fpage>1097</fpage>&#x2013;<lpage>1105</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><given-names>Maaten</given-names> <surname>Lvd</surname></string-name> &#x0026; <string-name><surname>Hinton</surname><given-names>G</given-names></string-name> (<year>2008</year>) <article-title>Visualizing data using t-SNE</article-title>. <source>Journal of Machine Learning Research</source> <volume>9</volume>(<issue>Nov</issue>):<fpage>2579</fpage>&#x2013;<lpage>2605</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Popescu</surname><given-names>G</given-names></string-name>, <etal>et al.</etal> (<year>2008</year>) <article-title>Optical imaging of cell mass and growth dynamics</article-title>. <source>American journal of physiology. Cell physiology</source> <volume>295</volume>(<issue>2</issue>):<fpage>C538</fpage>&#x2013;<lpage>544</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Henriques</surname><given-names>AO</given-names></string-name> &#x0026; <string-name><surname>Moran</surname><given-names>J</given-names></string-name>, <string-name><surname>Charles</surname><given-names>P</given-names></string-name> (<year>2007</year>) <article-title>Structure, assembly, and function of the spore surface layers</article-title>. <source>Annual Review of Microbiology</source> <volume>61</volume>:<fpage>555</fpage>&#x2013;<lpage>588</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Ball</surname><given-names>DA</given-names></string-name>, <etal>et al.</etal> (<year>2008</year>) <article-title>Structure of the exosporium and sublayers of spores of the Bacillus cereus family revealed by electron crystallography</article-title>. <source>Molecular Microbiology</source> <volume>68</volume>(<issue>4</issue>):<fpage>947</fpage>&#x2013;<lpage>958</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Carrera</surname><given-names>M</given-names></string-name>, <string-name><surname>Zandomeni</surname><given-names>RO</given-names></string-name>, &#x0026; <string-name><surname>Sagripanti</surname><given-names>JL</given-names></string-name> (<year>2008</year>) <article-title>Wet and dry density of Bacillus anthracis and other Bacillus species</article-title>. <source>Journal of Applied Microbiology</source> <volume>105</volume>(<issue>1</issue>):<fpage>68</fpage>&#x2013;<lpage>77</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Low</surname><given-names>J</given-names></string-name> &#x0026; <string-name><surname>Donachie</surname><given-names>W</given-names></string-name> (<year>1997</year>) <article-title>A review of Listeria monocytogenes and listeriosis</article-title>. <source>The Veterinary Journal</source> <volume>153</volume>(<issue>1</issue>):<fpage>9</fpage>&#x2013;<lpage>29</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Despr&#x00E9;s</surname><given-names>VR</given-names></string-name>, <etal>et al.</etal> (<year>2012</year>) <article-title>Primary biological aerosol particles in the atmosphere: a review</article-title>. <source>Tellus B</source> <volume>64</volume>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Jung</surname><given-names>J-H</given-names></string-name>, <string-name><surname>Jang</surname><given-names>J</given-names></string-name>, &#x0026; <string-name><surname>Park</surname><given-names>Y</given-names></string-name> (<year>2013</year>) <article-title>Spectro-refractometry of Individual Microscopic Objects Using Swept-Source Quantitative Phase Imaging</article-title>. <source>Analytical Chemistry</source> <volume>85</volume>(<issue>21</issue>):<fpage>10519</fpage>&#x2013;<lpage>10525</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jeong</surname><given-names>J</given-names></string-name>, <string-name><surname>Jang</surname><given-names>J</given-names></string-name>, <string-name><surname>Kim</surname><given-names>MW</given-names></string-name>, &#x0026; <string-name><surname>Park</surname><given-names>Y</given-names></string-name> (<year>2012</year>) <article-title>Polarization holographic microscopy for extracting spatio-temporally resolved Jones matrix</article-title>. <source>Optics Express</source> <volume>20</volume>(<issue>9</issue>):<fpage>9948</fpage>&#x2013;<lpage>9955</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname><given-names>K</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>) <article-title>High-resolution three-dimensional imaging of red blood cells parasitized by Plasmodium falciparum and in situ hemozoin crystals using optical diffraction tomography</article-title>. <source>Journal of Biomedical Optics</source> <volume>19</volume>(<issue>1</issue>):<fpage>011005</fpage>&#x2013;<lpage>011005</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Yousten</surname><given-names>A</given-names></string-name> &#x0026; <string-name><surname>Rogoff</surname><given-names>M</given-names></string-name> (<year>1969</year>) <article-title>Metabolism of Bacillus thuringiensis in relation to spore and crystal formation</article-title>. <source>Journal of Bacteriology</source> <volume>100</volume>(<issue>3</issue>):<fpage>1229</fpage>&#x2013;<lpage>1236</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Debnath</surname><given-names>SK</given-names></string-name> &#x0026; <string-name><surname>Park</surname><given-names>Y</given-names></string-name> (<year>2011</year>) <article-title>Real-time quantitative phase imaging with a spatial phase-shifting algorithm</article-title>. <source>Optics Letters</source> <volume>36</volume>(<issue>23</issue>):<fpage>4677</fpage>&#x2013;<lpage>4679</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Barer</surname><given-names>R</given-names></string-name> (<year>1952</year>) <article-title>Interference microscopy and mass determination</article-title>. <source>Nature</source> <volume>169</volume>(<issue>4296</issue>):<fpage>366</fpage>&#x2013;<lpage>367</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Godin</surname><given-names>M</given-names></string-name>, <etal>et al.</etal> (<year>2010</year>) <article-title>Using buoyant mass to measure the growth of single cells</article-title>. <source>Nature Methods</source> <volume>7</volume>(<issue>5</issue>):<fpage>387</fpage>&#x2013;<lpage>390</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Vedaldi</surname><given-names>A</given-names></string-name> &#x0026; <string-name><surname>Lenc</surname><given-names>K</given-names></string-name> (<conf-date>2015</conf-date>) <article-title>Matconvnet: Convolutional neural networks for matlab</article-title>. <source>Proceedings of the 23rd ACM International Conference on Multimedia, (ACM)</source>, pp <fpage>689</fpage>&#x2013;<lpage>692</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Nair</surname><given-names>V</given-names></string-name> &#x0026; <string-name><surname>Hinton</surname><given-names>GE</given-names></string-name> (<year>2010</year>) <article-title>Rectified linear units improve restricted boltzmann machines</article-title>. <source>Proceedings of the 27th International Conference on Machine Learning</source>, pp <fpage>807</fpage>&#x2013;<lpage>814</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Srivastava</surname><given-names>N</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G</given-names></string-name>, <string-name><surname>Krizhevsky</surname><given-names>A</given-names></string-name>, <string-name><surname>Sutskever</surname><given-names>I</given-names></string-name>, &#x0026; <string-name><surname>Salakhutdinov</surname><given-names>R</given-names></string-name> (<year>2014</year>) <article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title>. <source>Journal of Machine Learning Research</source> <volume>15</volume>(<issue>1</issue>):<fpage>1929</fpage>&#x2013;<lpage>1958</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Ioffe</surname><given-names>S</given-names></string-name> &#x0026; <string-name><surname>Szegedy</surname><given-names>C</given-names></string-name> (<year>2015</year>) <article-title>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</article-title>. <source>Proceedings of The 32nd International Conference on Machine Learning</source>, pp <fpage>448</fpage>&#x2013;<lpage>456</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>He</surname><given-names>K</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Ren</surname><given-names>S</given-names></string-name>, &#x0026; <string-name><surname>Sun</surname><given-names>J</given-names></string-name> (<year>2015</year>) <article-title>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</article-title>. <source>Proceedings of the IEEE International Conference on Computer Vision</source>, pp <fpage>1026</fpage>&#x2013;<lpage>1034</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname><given-names>K</given-names></string-name>, <etal>et al.</etal> (<year>2013</year>) <article-title>Synthetic Fourier transform light scattering</article-title>. <source>Optics Express</source> <volume>21</volume>(<issue>19</issue>):<fpage>22453</fpage>&#x2013;<lpage>22463</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>