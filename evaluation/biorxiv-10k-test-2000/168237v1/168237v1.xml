<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/168237</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Is coding a relevant metaphor for the brain?</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Brette</surname>
<given-names>Romain</given-names>
</name>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="aff1"><institution>UPMC</institution></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author; email: <email>romain.brette@inserm.fr</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>168237</elocation-id>
<history>
<date date-type="received">
<day>25</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="rev-recd">
<day>25</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>7</month>
<year>2017</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="168237.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>&#x201C;Neural coding&#x201D; is a popular metaphor in neuroscience, where objective properties of the world are communicated to the brain in the form of spikes. Here I argue that this metaphor is often inappropriate and misleading. First, when neurons are said to encode experimental parameters, the implied communication channel consists of both the experimental and biological system. Thus, the terms &#x201C;neural code&#x201D; are used inappropriately when &#x201C;neuroexperimental code&#x201D; would be more accurate, although less insightful. Second, the brain cannot be presumed to decode neural messages into objective properties of the world, since it never gets to observe those properties. To avoid dualism, codes must relate not to external properties but to internal sensorimotor models. Because this requires structured representations, neural assemblies cannot be the basis of such codes. Third, a message is informative to the extent that the reader understands its language. But the neural code is private to the encoder since only the message is communicated: each neuron speaks its own language. It follows that in the neural coding metaphor, the brain is a Tower of Babel. Finally, the relation between input signals and actions is circular; that inputs do not preexist to outputs makes the coding paradigm problematic. I conclude that the view that spikes are messages is generally not tenable. An alternative proposition is that action potentials are actions on other neurons and the environment, and neurons interact with each other rather than exchange messages.</p>
</abstract>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<p>A pervasive paradigm in neuroscience is the concept of neural coding (<xref ref-type="bibr" rid="c13">deCharms and Zador, 2000</xref>): the query &#x201C;neural coding&#x201D; on Google Scholar retrieves about 15,000 papers in the last ten years. Neural coding is a communication metaphor. An example is the Morse code (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>), which was used to transmit texts over telegraph lines: each letter is mapped to a binary sequence (dots and dashes). In analogy, visual signals are encoded into the spike trains of retinal ganglion cells (<xref ref-type="fig" rid="fig1">Fig. 1B</xref>). Both the Morse code and the retinal code relate to a communication problem: to communicate text messages over telegraph lines, or to communicate visual signals from the eye to the brain. This problem has been formalized by communication theory (<xref ref-type="bibr" rid="c40">Shannon and Weaver, 1971</xref>), a popular tool in neuroscience (<xref ref-type="bibr" rid="c36">Rieke et al., 1999</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>The coding analogy. A, A communication channel consists of an emitter who wants to transmit some message to a receiver, in an altered form named &#x201C;code&#x201D; (here Morse code). The receiver knows the correspondence and can reconstruct or &#x201C;decode&#x201D; the original message. B, In analogy, sensory signals are encoded in the spike trains of neurons. C. In an experimental context, the emitter is the experimenter, who presents a stimulus (oriented bar) characterized by some parameter (orientation &#x03B8;). The brain receives the message in the form of neural activity, from which it infers information about the stimulus (&#x03B8;).</p></caption>
<graphic xlink:href="168237_fig1.tif"/>
</fig>
<p>However, the neural coding metaphor is used more broadly, in ways that are less obviously related to communication problems. For example, neurons in the primary visual cortex encode the orientation of bars in their firing rate (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>); neurons in the auditory brainstem encode the spatial position of sounds (<xref ref-type="bibr" rid="c2">Ashida and Carr, 2011</xref>), and neurons in the hippocampus encode the animal&#x0027;s location (<xref ref-type="bibr" rid="c31">Moser et al., 2008</xref>). The coding metaphor applies to these situations in the sense that there is a correspondence between neural activity and some measurable property. In this sense, the metaphor applies equally well to any situation where two measurable properties co-vary. But as the linguists <xref ref-type="bibr" rid="c26">Lakoff and Johnson (2008)</xref> have argued, the metaphors that pervade our language are not neutral; on the contrary, they form the architecture of our conceptual system. For example, seeing the heart as a pump is quite different from seeing it as an information processing device encoding walking speed in its beat rate, two equally applicable metaphors. Is perception a communication problem? And if so, with whom?</p>
<p>This critique of the neural coding metaphor is articulated as follows. First, the coding metaphor is often applied in a way that the encoded property is not a sensory signal but an experimental parameter, as when interpreting tuning curves. Casting this situation into a communication problem is problematic because the communication channel is made of both the biological system and the experimental system. One may then speak of a code, but perhaps not of a <italic>neural</italic> code. Second, in the coding metaphor, the encoded message is information in the sense that the receiver can &#x201C;decode&#x201D; it into the original message, but unless we postulate the existence of a homunculus who maps neural activity to an external description of the world, this is not the situation faced by the brain. All that the nervous system ever gets to observe is the Morse code. Thus, coding usually refers to an extrinsic notion of information, while a more biologically relevant notion should be intrinsic. Finally, I will end with a more radical criticism of the neural coding metaphor, based on the circular relation between sensory signals and actions and the fact that no clear separation exists in the brain between representation and computation. This discussion will lead us to the question: are spikes messages or actions?</p>
</sec>
<sec id="s2">
<label>2.</label>
<title>Contextual codes</title>
<sec id="s2a">
<label>2.1.</label>
<title>The fallacy of the overwise neuron</title>
<p>In a reflection on theories of the brain, Francis Crick warned against the &#x201C;fallacy of the overwise neuron&#x201D; (<xref ref-type="bibr" rid="c12">Crick, 1979</xref>) that arises when the neural coding metaphor is combined with methodological reductionism. He took the example of color perception. Cones are tuned to a particular wavelength (<xref ref-type="bibr" rid="c38">Schnapf et al., 1987</xref>): in an experiment where light of different wavelengths is flashed, the amplitude of the transduced current varies systematically with wavelength (<xref ref-type="fig" rid="fig2">Fig. 2A</xref>). Thus, the current encodes wavelength, in the sense that one can recover wavelength from the magnitude of the current. However, the code is contingent on the context of the experiment. In a natural situation, the current may also vary with light intensity and therefore does not provide unambiguous information about wavelength. Indeed, animals or humans with a single functional type of cones are color blind. Thus, from the experimenter&#x0027;s viewpoint, it can be said that photoreceptor current encodes wavelength, yet from the viewpoint of the organism there is no usable information about color in that current. Thus, applied in this way, the coding metaphor is misleading.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Encoding wavelength of light. A, Response of a cone to flashed light as a function of wavelength (cartoon), at different intensities (grey). If intensity is fixed, wavelength can be inferred from transduced current. Otherwise, current is not informative about wavelength. B, The relative response of cones with different tunings may provide intensity-invariant information about wavelength.</p></caption>
<graphic xlink:href="168237_fig2.tif"/>
</fig>
<p>The reason is that, since the encoded property is an experimental parameter, the communication channel implicitly consists of both the biological system and the experimental system (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>). This makes the code contextual, contingent on the specifics of the experiment. If the code is contextual, then the coding metaphor can just as well be applied to an element of context. For example, if intensity rather than wavelength were varied, then the current would encode light intensity. Thus, if it can be said that cones encode wavelength, then it can also be said that cones encode intensity, flickering frequency, and any other stimulus parameter that an experimenter can vary. Used in this sense, coding is a property not of neurons but of a particular experimental situation, which merely refers to neural sensitivity to an experimental parameter. Thus, it is misleading to speak of a neural code when one should speak of neural sensitivity (<xref ref-type="bibr" rid="c7">Brette, 2010</xref>).</p>
<p>When a message is transmitted in Morse code, the encoded message constitutes information for the receiver in the sense that the receiver can reconstruct the original message from the encoded message, a process called &#x201C;decoding&#x201D;. If the decoder depends on the specifics of the experiment, then the message constitutes information for the experimenter, not for the organism. Thus, one can speak of a neural code for some dimension to the extent that the implied decoder is insensitive to other dimensions (but not necessarily the activity of individual neurons). For example, wavelength may be encoded in the relative activity of cones with different tunings, provided that this is invariant to light intensity (<xref ref-type="fig" rid="fig2">Fig. 2B</xref>).</p>
</sec>
<sec id="s2b">
<label>2.2.</label>
<title>Implications for population coding</title>
<p>The reductionist approach to coding is more than an inappropriate use of words. For example, in mammals, the major cue for sound localization in the horizontal plane is the difference in arrival times of the sound wave at the two ears (interaural time difference or ITD) (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>). There are neurons in the auditory brainstem that are very sensitive to that cue (<xref ref-type="bibr" rid="c25">Joris et al., 1998</xref>): when a sound is played through earphones and the ITD is varied, the firing rate of those neurons changes (<xref ref-type="fig" rid="fig3">Fig. 3B</xref>). Thus, these neurons encode ITD in the same way as cones encode wavelength. In this sense, because the relation between ITD and firing rate is steep, a single neuron can in fact encode ITD with the same accuracy as the entire organism, as assessed by behavioral experiments (<xref ref-type="bibr" rid="c42">Skottun, 1998</xref>; <xref ref-type="bibr" rid="c39">Shackleton et al., 2003</xref>). But as we have seen, this comparison is highly misleading, because the code is contextual: playing a different sound (for example a louder or a higher sound) would also change the activity of these neurons, and therefore the firing rate of a single neuron may be informative for the experimenter, but not for the organism.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Encoding sound location. A, A major cue for sound localization is the interaural time difference or ITD, d<sub>R</sub> - d<sub>L</sub>. B, Number of spikes in response to two binaural tones (950 Hz and 800 Hz) as a function of ITD, for the same neuron in the medial superior olive of a cat (digitized from (<xref ref-type="bibr" rid="c44">Yin and Chan, 1990</xref>), Fig. 10). It is possible to infer ITD from spike count if the experimental configuration (presented tone) is known, not if the sound is a priori unknown. C, If the organism lived in a world with a single sound played at different ITDs, then the best way to encode ITD would be with a neuron tuned to an ITD outside the physiological range (shaded), so that the selectivity curve is steep inside that range. However, the response of a single neuron is fundamentally ambiguous when sounds are diverse, irrespective of the steepness of the curve (selectivity curve for another sound shown in grey).</p></caption>
<graphic xlink:href="168237_fig3.tif"/>
</fig>
<p>This misuse of the coding metaphor leads to incorrect conclusions about population coding. If the confounding dimensions (level, etc) are neglected, then the best way to encode ITD is to have a steep monotonous relation between ITD and firing rate, that is, to maximize neural sensitivity to ITD (<xref ref-type="fig" rid="fig3">Fig. 3C</xref>).</p>
<p>Thus, the neuron&#x0027;s preferred ITD should lie outside the range of natural sounds (around &#x00B1;800 &#x03BC;s for humans (<xref ref-type="bibr" rid="c4">Benichoux et al., 2016</xref>)) while the steepest slope of the selectivity curve should be inside, which leads to two symmetrical optimal selectivity curves (<xref ref-type="bibr" rid="c21">Harper and McAlpine, 2004</xref>). This is the concept of &#x201C;slope coding&#x201D;, which motivates an influential model of sound localization (<xref ref-type="bibr" rid="c20">Grothe et al., 2010</xref>), and was meant to explain why many neurons have their preferred ITD outside the natural range (<xref ref-type="bibr" rid="c30">McAlpine et al., 2001</xref>) (even though many are also inside, especially in larger mammals such as cats (<xref ref-type="bibr" rid="c18">Goodman et al., 2013</xref>, <xref ref-type="fig" rid="fig1">Fig. 1a</xref>)).</p>
<p>Unfortunately, this conclusion is incorrect when confounding dimensions are not neglected. To encode wavelength independently of intensity, what is required is not a steep relation between wavelength and current, but cones with diverse tunings. In the same way, modeling work shows that heterogeneity of ITD tunings is crucial to raise the ambiguities due to non-spatial dimensions of sounds, so that the slope coding model cannot account for behavioral accuracy (<xref ref-type="bibr" rid="c7">Brette, 2010</xref>; <xref ref-type="bibr" rid="c18">Goodman et al., 2013</xref>).</p>
<p>Thus, the reductionist approach to coding leads to incorrect conclusions because it focuses exclusively on neural sensitivity. While neural sensitivity is not a sufficient property, it could be argued that it is a necessary one. Unfortunately, this is not true either. For example, no auditory nerve fiber is sensitive to ITD because their responses are exclusively monaural. Yet, the joint response of auditory nerve fibers on opposite sides is informative about ITD, in the relative timing of their spikes. In general, unless confounding dimensions are ignored, there is no direct relation between neural sensitivity and information in the activity of a neural population.</p>
</sec>
<sec id="s2c">
<label>2.3.</label>
<title>Can neurons encode experimental parameters?</title>
<p>For the coding metaphor to be biologically meaningful, the decoder (explicit or implied) must not be experiment-specific. An immediate implication is that the encoded property must be meaningful outside of the experimental context. Such is the case when the coding metaphor is applied to a transduction problem, for example when neural activity encodes visual signals (<xref ref-type="bibr" rid="c28">Laughlin, 1981</xref>). This is less straightforward when the quantity to be decoded is a variable of the experimental protocol rather than the sensory signal, as when tuning curves are measured. Crick noted that the activity of a single cone cannot encode wavelength in any meaningful sense because of confounding factors. But the more profound reason is that natural light is not monochromatic, it has a continuous spectrum. In reality, the transduced current depends on the convolution of the spectrum of incident light with the absorption spectrum of the photoreceptor. Cones do not encode wavelength because there is no such thing as the wavelength of a patch of visual scene.</p>
<p>Do V1 neurons encode the orientation of bars and gratings? The answer completely depends on whether the world is made of bars and gratings. If not, then the proposition must be made more precise, for example: V1 neurons encode the direction of the local gradient of the visual field. But this proposition cannot be established from a simple tuning curve experiment. It turns out that other types of experiments show that it is not true, because the response of those neurons also depends on the surround; typically, responses are suppressed when stimulus properties at the center (e.g. orientation) match those in the surround (<xref ref-type="bibr" rid="c22">Hubel and Wiesel, 1968</xref>; <xref ref-type="bibr" rid="c6">Bolz and Gilbert, 1986</xref>). Thus, it is not so clear what V1 neurons encode; perhaps how surprising a patch of visual scene is given its surround (<xref ref-type="bibr" rid="c35">Rao and Ballard, 1999</xref>).</p>
<p>Thus, the first requirement for the coding metaphor to be meaningful is that the encoded property is meaningful outside of the experimental context, whether it is the physical sensory signal or a more abstract property.</p>
</sec>
<sec id="s2d">
<label>2.4.</label>
<title>Can contextual codes make sense?</title>
<p>Place cells in the hippocampus encode the spatial position of the organism within a given environment (<xref ref-type="bibr" rid="c31">Moser et al., 2008</xref>). The code is contextual, because it is specific of each environment. However, in contrast with the color and sound localization examples, this does not make the coding metaphor irrelevant. Indeed, the issue in those examples is not so much that the code is contextual, but that the context lives outside of the organism, within the design of the experiment. A rat lives in an environment, which has some persistence. The fact that the place code is contextual implies that the activity of place cells does not provide information of the type &#x201C;I am at position (48&#x00B0;, 2&#x00B0;)&#x201D;, but it does provide information of the type &#x201C;I am in the same corner as a few minutes earlier&#x201D;. In addition, a key argument to justify the name of &#x201C;place cell&#x201D; was that the responses of those cells depend on spatial position but not on specific non-spatial features of the environment, for example light intensity - they are not merely sensitive to spatial position (<xref ref-type="bibr" rid="c32">O&#x2019;Keefe, 1976</xref>).</p>
<p>In contrast, cone activity does not provide information about wavelength unless the organism knows that a monochromatic light is being presented and additionally knows how cone activity depends on wavelength. The latter point is crucial: since the organism never gets to observe stimulus wavelength but only the activity of cones, there is no way that it can infer the relation between these two observables.</p>
<p>In the same way, in our sound localization example, the firing rate of a single neuron provides information about the spatial position of a sound, but only if one knows which sound is being played, and what the relation between position and firing rate is for that particular sound. Thus, the code is specific of a particular sound, just as place cell activity is specific of an environment. But while a rat can explore its environment, one does not explore a sound, because a sound is transient. The initial proposition must then be qualified: firing rate encodes sound position within a given world of identical sounds. This makes the coding metaphor much less meaningful than in the case of place cells.</p>
<p>One may raise the following objection. The code for sound position is contextual, but it could be that context is provided by another part of the nervous system: there could be a &#x201C;where&#x201D; pathway and a &#x201C;what&#x201D; pathway, with the former making sense in the context of the latter. This hypothesis implies that there is no information <italic>per se</italic> in the where pathway, but only in the joint activity of the two pathways. It follows that the proposition is logically equivalent to the following: sound position is encoded in the activity of the nervous system. Indeed, consider the following proposition: sound location is encoded in the activity of the left auditory nerve (since firing rate varies with level and thus with sound position), and the context is provided by the right auditory nerve. This is true since sound location is encoded in the joint activity of the two auditory nerves, but separating code and context is arbitrary and misleading.</p>
<p>In summary, when the coding metaphor is applied, the dependence of the code on context must be identified. If the code depends on specifics of the experimental design, then it constitutes information for the experimenter, not for the organism. In this case, it is misleading to speak of a &#x201C;neural&#x201D; code because the communication channel implied by the metaphor is made of both the biological system and the experimental system.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>Extrinsic vs. intrinsic information</title>
<sec id="s3a">
<label>3.1.</label>
<title>The neural coding metaphor is implicitly dualist</title>
<p>In what sense is the neural code &#x201C;information&#x201D; about objective properties of the world? It is information in the sense that these properties can be inferred from neural activity. Methodologically, this inference is done by the experimenter, who confronts these properties with measurements of neural activity. But by using the terms &#x201C;neural code&#x201D;, we imply that the brain must also do this inference. How is it possible for the nervous system to infer external properties from neural activity, if all that it ever gets to observe is that activity? In fact, what does it even mean that a neural network infers external properties (e.g. the direction of a sound source), given that those properties do not belong to the domain of neural activity?</p>
<p>This hints at the homunculus fallacy. In the coding paradigm, meaning is obtained at some final stage where neural activity is mapped to the initial message, where the world is described in external terms. This leads to what philosopher Daniel Dennett called the &#x201C;Cartesian theater&#x201D; (<xref ref-type="bibr" rid="c14">Dennett, 1992</xref>). Descartes suggested that the mind, which he viewed as non-material, interacted with the brain at the pineal gland. At that stage, the mind would read the activity of the nerves and interpret it in terms of the outside physical world. The &#x201C;Cartesian theater&#x201D; is the brain seen as a screen where the world is projected, that a homunculus (the mind) watches. Pushed to its ultimate conclusions, the coding view of perception is logically equivalent to the dualism of Descartes.</p>
<p>I suggest that the appeal of the coding metaphor for the brain stems from the misleading use of the word &#x201C;information&#x201D;. In the coding metaphor, neural activity is information about the world in the sense that it is possible to reconstruct the external world from neural activity, just as it is possible to map a Morse message back to the original message. The problem is, a Morse message translated from German is not informative unless one understands German, and it is even less informative if all that the receiver ever gets to observe is Morse messages. To decipher the Enigma code during World War II, the Allies used the weather of the day as an element that they could look for in the encoded messages. Thus, they used a known element external to the messages (a &#x201C;known-plaintext attack&#x201D;), in addition to their prior knowledge of German.</p>
<p>Thus, the fundamental problem with the coding metaphor, as it applies to the brain, is that it conveys an <italic>extrinsic</italic> notion of information: the meaning conferred to symbols is extrinsic, given by an external observer who has access to both the external world and neural activity. This meaning is not intrinsic to the activity of the nervous system. Thus, it is not immediately obvious that this extrinsic notion of information is the right way to address the informational problems faced by the brain. This problem is known as the <italic>symbol grounding problem</italic>: how do spikes, the symbols of the neural code, make sense for the organism?</p>
</sec>
<sec id="s3b">
<label>3.2.</label>
<title>Information as subjective laws</title>
<p>How can there be any information about the world without direct access to the world? This is the question to be answered if we are to address the implicit dualism of the neural coding metaphor. It has been addressed by philosophers and psychologists. <xref ref-type="bibr" rid="c33">O&#x2019;Regan and No&#x00EB; (2001)</xref> proposed the analogy of the &#x201C;villainous monster&#x201D;. Imagine you are exploring the sea with an underwater vessel. But a villainous monster mixes all the cables and so all the sensors and actuators are now related to the external world in a new way. How can you know anything about the world? The only way is to analyze the structure of sensor data and their relationships with actions that you can perform. If dualism is rejected, then this is the kind of information that is available to the nervous system. A salient feature of this notion of information is that, contrary to Shannon&#x0027;s information, it is defined not as elements of a set but as relations or logical propositions: if I do action A, then sensory property B happens; if sensory property A happens, then another property B will happen next; if I do action A in sensory context B, then C happens.</p>
<p>James Gibson previously developed a related psychological theory (<xref ref-type="bibr" rid="c17">Gibson, 1986</xref>). While criticizing the information-processing view of perception, he argued that there is information about the world present in the <italic>invariant structure</italic> of sensory signals: &#x201C;A great many properties of the [optical] array are lawfully or regularly variant with change of observation point, and this means that in each case a property defined by the law is invariant&#x201D;. Clearly, the word &#x201C;information&#x201D; is not meant in the sense of communication theory, but rather in the sense of scientific knowledge. A set of observations and experiments provides information about the world, in the form of laws that relate observables (sensory signals) between them and with possible actions. This form of information is intrinsic; I proposed to call this set of laws the subjective physics of the world (<xref ref-type="bibr" rid="c9">Brette, 2016</xref>). A related view, formalized by theoretical biologist Robert Rosen (<xref ref-type="bibr" rid="c37">Rosen, 1985</xref>), is that biological organisms build an internal model of the world, in which the variables are sensory signals. This view addresses the symbol grounding problem by mapping sensory signals to elements of an internal model. The signals make sense in reference to that model; they are not mapped to externally defined properties.</p>
<p>To be more concrete, imagine an organism with a linear retina in a world of tiny objects (<xref ref-type="fig" rid="fig4">Fig. 4A</xref>). The presence of an object is signaled by the firing of a retinal neuron, whose identity indicates the object&#x0027;s location through a &#x201C;labelled-line code&#x201D;. However, to infer location from neural activity requires knowing the relation between object position and neuron identity, and this information is not conveyed by the flickering of the cells. Therefore, retinal activity alone does not constitute spatial information for the organism. Now suppose that the organism can move its retina laterally. It can then observe a relation between muscular state (through proprioception or afferent copy) and neural activity (<xref ref-type="fig" rid="fig4">Fig. 4B</xref>). Neural activity is now informative of which neuron would become active if a given action were performed. Thus, neural activity is intrinsic information to the extent that it can be mapped to a rich internal model. We note that this model still entails a very poor notion of space, with no metric structure. A richer notion would require the ability to perform different types of movements, in particular movements which translate the entire organism (see <xref ref-type="bibr" rid="c9">Brette (2016)</xref>). The key point in this example is that neural activity conveys the same extrinsic information about the object&#x0027;s location whether the organism can move or not, yet there is intrinsic information in the latter case but not in the former.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Information in sensorimotor structure. A, Each neuron on a linear retina fires when an object is presented at a specific location. From the brain&#x0027;s viewpoint, these are blinks from different cells with no intrinsic notion of space. B, If the organism can move the retina, then object position is defined as the relation between neural activity and proprioceptive state of the retina. The firing of a cell informs the organism of which cell would fire if the retina were moved in particular directions. C, Piano keys are encoded into the acoustical signals. Beyond Shannon information, there is intrinsic information in the form of sensory laws followed by the signals. For example, the signal produced by a key is periodic, with a specific period, independently of how hard the key is struck. The same sensory law is obeyed by the signal produced by a key an octave higher, providing a natural topology.</p></caption>
<graphic xlink:href="168237_fig4.tif"/>
</fig>
</sec>
<sec id="s3c">
<label>3.3.</label>
<title>Information in a single stimulus</title>
<p>In the coding metaphor, a code constitutes information in the sense of a translation dictionary. But there is more information in the sensory signals than implied by this metaphor. Imagine a world of sounds made by various piano keys (<xref ref-type="fig" rid="fig4">Fig. 4C</xref>). From the coding point of view, there is extrinsic information in the acoustical signals about which piano key is played, in the sense that there is a one-to-one mapping between piano keys and signals. From the organism&#x0027;s viewpoint, this information is poor since the mapping is unknown. However, there is much more information in these sensory signals than what the classical coding paradigm suggests, if we take the viewpoint of information as sensory laws. It can be said for example that the acoustical signals S(t) follow the law S(t&#x002B;T) &#x003D; S(t) for some delay T. The striking difference with the extrinsic notion of information conveyed by the coding metaphor is that something can be said of a <italic>single</italic> stimulus: a (tentative) model of a single stimulus can be built &#x2013; despite the problem of induction, building a model from finite observations is tentative but possible to the extent that science is possible (see (<xref ref-type="bibr" rid="c9">Brette, 2016</xref>) for a discussion). This relates to another theoretical concept of information known as <italic>Kolmogorov complexity</italic>. Kolmogorov complexity is the size of the shortest program that produces the signal. In this case, the program could be to repeat the waveform of one period. This program is a type of information that is absent from the coding metaphor, which considers information in a set-theoretic sense: a stimulus is just one element of a set of possible stimuli.</p>
<p>But a stimulus is not just an element of a set: it can have structure (laws or generative program) and this structure constitutes information. In particular, the structure has predictive value: a law postulated on the basis of the beginning of a signal can be tested on the rest of the signal; or a program can produce the rest of the signal. Structure also defines relations between different stimuli. For example, consider two musical notes that differ by an octave (<xref ref-type="fig" rid="fig4">Fig. 4C</xref>). In the coding view, these are just two distinct labels. However, there is a relation between the two signals stemming from the fact that the period of the lower note is twice the period of the higher note. This implies that the sensory model associated with the lower note (S(t) &#x003D; S(t&#x002B;T)) is also valid for the higher note (but not conversely), which defines a relation of similarity between these two notes. This topology does not exist in the classical coding view, because each signal is seen as an element of an unstructured set. It turns out that these similarities in structure match perceptual similarities, with some qualifications (<xref ref-type="bibr" rid="c45">Zheng and Brette, 2017</xref>): two notes played by different instruments elicit the same pitch if they have the same periodicity but different spectral content.</p>
</sec>
<sec id="s3d">
<label>3.4.</label>
<title>Encoding intrinsic information</title>
<p>In the neural coding literature, variations of the coding paradigm have been proposed to address the question of intrinsic information. An interesting proposition is predictive information, which is the mutual (Shannon) information between the past and future of a signal (<xref ref-type="bibr" rid="c5">Bialek et al., 2001</xref>; <xref ref-type="bibr" rid="c34">Palmer et al., 2015</xref>). This should not to be confused with &#x201C;predictive coding&#x201D; (<xref ref-type="bibr" rid="c35">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="c11">Clark, 2013</xref>), which is a variation of the efficient coding paradigm where neurons encode the difference between the signal and the expectation of the signal based on other observations (either previous observations or the activity of other neurons). Suppose for example that there is some acoustical noise in addition to the musical notes. In the predictive coding paradigm, neurons encode only the difference with expectations, i.e., mostly the noise. It is considered efficient because the code is meant to stand for the original signal, which includes noise. This is paradoxical because noise cannot constitute information for the organism in any meaningful sense. This paradox occurs because the predictive coding paradigm (and more generally the efficient coding paradigm) does not distinguish between what is meaningful and what constitutes noise. Predictive information improves on this by proposing that what should be encoded is only the part of the signal that is informative about the future. In our example, predictive information would only include information about the piano key being played and not acoustical noise.</p>
<p>However, predictive information comes with the same limitation as more classical forms of coding in that what is encoded is not the structure of signals; the encoded messages are note labels. The prediction of the future signal can be made by the encoder, but not by those who read the encoded message. The fact that two notes separated by an octave are structurally similar is not communicated. Thus, the fundamental problem in this and more classical coding paradigms is that all the meaningful structure (the sensory model or the program) is private to the encoding process, while only the encoded message is communicated.</p>
</sec>
<sec id="s3e">
<label>3.5.</label>
<title>Representation of structure and structure of representations</title>
<p>Thus, for the coding metaphor to be biologically meaningful, this intrinsic information, the structure of signals, should be encoded and communicated. There are in fact a few examples in the neuroscience literature, although they are not usually cast in this way. One is the Jeffress model of ITD coding (<xref ref-type="bibr" rid="c23">Jeffress, 1948</xref>) (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). In that model, neurons receive inputs from monaural neurons on the two sides, with different conduction delays. When input spikes arrive simultaneously, the neuron spikes. Thus, the neuron spikes when the two acoustical signals at the two ears are such that S<sub>L</sub>(t) &#x003D; S<sub>R</sub>(t-d), where d is the conduction delay mismatch between the two ears. Physically, this corresponds to a sound source placed at a position such that it produces an ITD equal to d. In this model, the neuron encodes a sensory law; more precisely, it indicates whether signals satisfy a particular sensory law. Its spikes cannot be used to reconstruct the original signals.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Neural representation of structure (adapted from <xref ref-type="bibr" rid="c8">Brette (2012)</xref>). A, The Jeffress model of sound localization. The sound arrives at the two ears with delays d<sub>L</sub> and d<sub>R</sub>. It is then transduced into spike trains that arrive at a binaural neuron with delays &#x03B4;<sub>L</sub> and &#x03B4;<sub>R</sub>. Synchrony occurs when d<sub>R</sub> - d<sub>L</sub> &#x003D; &#x03B4;<sub>L</sub> - &#x03B4;<sub>R</sub>, making the neuron fire. B, The synchrony receptive field. The response of a neuron to a stimulus is described as filtering of the sensory signal S through the receptive field N, followed by spiking. The synchrony receptive field of two neurons A and B with different receptive fields N<sub>A</sub> and N<sub>B</sub> is defined as the set of stimuli that elicit synchronous responses in these neurons.</p></caption>
<graphic xlink:href="168237_fig5.tif"/>
</fig>
<p>This model can be generalized. I recently proposed a computational theory of synchrony in sensory systems (<xref ref-type="bibr" rid="c8">Brette, 2012</xref>), in which synchrony reflects the structure of sensory signals (<xref ref-type="fig" rid="fig5">Fig. 5B</xref>). One considers two neurons A and B which convert their time-varying inputs into precisely timed spike trains, where their inputs are seen as transformed versions N<sub>A</sub>(S) and N<sub>B</sub>(S) of the stimulus S (N<sub>A</sub> and N<sub>B</sub> are fixed and correspond to the receptive fields of the neurons). Synchrony between A and B then reflects the sensory law N<sub>A</sub>(S) &#x003D; N<sub>B</sub>(S). The <italic>synchrony receptive field</italic> of A and B is the set of stimuli that elicit synchronous responses in these two neurons: it is the set of sensory signals that satisfy a particular law. A neuron receiving inputs from A and B would then fire when the stimulus is in the synchrony receptive field of A and B, that is, when it satisfies a particular sensory law. One can then see synchrony patterns or the firing of postsynaptic neurons as a code for sensory laws. This framework has been applied to pitch perception (<xref ref-type="bibr" rid="c27">Laudanski et al., 2014</xref>) and to sound localization in realistic environments where sounds are diffracted by the head (<xref ref-type="bibr" rid="c19">Goodman and Brette, 2010</xref>; <xref ref-type="bibr" rid="c3">Benichoux et al., 2015</xref>).</p>
<p>However, the concept of synchrony receptive fields captures a rather elementary notion of structure. For example, it does not capture predictive sensorimotor propositions such as: &#x201C;if I do action A, then property B should be true&#x201D;. In fact, when perceptual information is understood as propositions about sensorimotor signals, it appears that the information to be represented by the brain is much richer than suggested by coding theory. For example, in a visual scene, there could be Paul, a person I know, wearing a new shirt, driving a car (<xref ref-type="fig" rid="fig6">Fig. 6</xref>). What is important here is that a scene is not just a &#x201C;bag of objects&#x201D;: objects have relationships with each other, and there are many possible different relationships. For example there is a car and there is Paul, and Paul is in a specific relationship with the car, both a physical relationship (a particular posture within the car) and a functional relationship (driving it). Thus, a neural &#x201C;code&#x201D; of a scene should not only represent the individual objects but also specific relationships between these objects, possibly in a recursive way. Since phenomenal experience is at least as complex as what can be consciously described with language, neural representations of perception should be at least as structured as language: it should have syntax, as recently proposed (<xref ref-type="bibr" rid="c10">Buzs&#x00E1;ki, 2010</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Perceptual scenes are highly structured. For example, there is Paul (person I know), driving a car, and wearing a new shirt. Representing this scene by the firing of neural assemblies raises two issues: 1) it may be difficult to split active neurons into the correct assemblies (superposition catastrophe), and more importantly 2) the structure of the scene (relations shown by arrows) cannot be represented in this way.</p></caption>
<graphic xlink:href="168237_fig6.tif"/>
</fig>
<p>Unfortunately, this does not fit well with the concept of &#x201C;neural assemblies&#x201D;, which is the mainstream assumption about how things we perceive are represented in the brain. If it is true that any given object is represented by the firing of a given assembly of neurons, then several objects should be represented by the firing of a bigger assembly of neurons, the union of all assemblies, one for each object. Several authors have noted that this may lead to the &#x201C;superposition catastrophe&#x201D; (<xref ref-type="bibr" rid="c43">von der Malsburg, 1999</xref>), i.e., there may be different sets of objects whose representations are fused into the same big assembly. Even without this segmentation problem, the representation of a scene could still be nothing else than an unstructured &#x201C;bag of objects&#x201D;, for there are no relationships between objects in the assembly representation. Mathematically, the appropriate representation is a graph with labeled edges and vertices, not an unstructured set.</p>
<p>Thus there is a fundamental problem with the concept of neural assembly, which is that there is no representation of relations, only of things to be related. This remark has been made in the past, essentially in the context of the binding problem. It has led several authors to postulate that synchrony is used to bind the features of an object represented by neural firing (<xref ref-type="bibr" rid="c41">Singer, 1999</xref>; <xref ref-type="bibr" rid="c43">von der Malsburg, 1999</xref>). This avoids the superposition catastrophe because at a given time, only one object is represented by neural firing.</p>
<p>However, this is insufficient because only one type of relation can be represented in this way, and a symmetrical one: does Paul drive the car, or does the car run over Paul?</p>
<p>At this point, there is no strong alternative representational theory that would solve all these issues. The analogy of language shows nevertheless that this is possible in principle: it is conceptually possible to represent structures as complex as linguistic structure by using the order of words; in the same way, it is conceptually possible to represent sensory structure by using the order of spikes.</p>
<p>To conclude this part, if the neural code is to be meaningful for the organism, then what is encoded should not be objective properties of the world but internal sensorimotor models. This implies that neural representations themselves must be structured, rather than &#x201C;bags of neurons&#x201D;.</p>
</sec>
</sec>
<sec id="s4">
<label>4.</label>
<title>Spikes: messages or actions?</title>
<sec id="s4a">
<label>4.1.</label>
<title>The brain as a Tower of Babel</title>
<p>In his seminal book on vision, <xref ref-type="bibr" rid="c29">David Marr (1982)</xref> wrote: &#x201C;If we are capable of knowing what is where in the world, our brains must somehow be capable of representing this information.&#x201D;. That is, if we consider that perception emerges from states of matter, then there must be a correspondence between mental representations and neural representations, states of the brain. We have argued that the kind of representations that the brain manipulates must be structured representations of internal sensorimotor models, not objective representations from the perspective of an external observer.</p>
<p>Despite this shift in perspective, seeing neural activity as messages remains problematic. A message is something that a reader makes sense of. But to make sense of a message requires understanding the language of the message. In the coding metaphor, that language is the mapping from original to encoded message, and it is private to the encoder, not communicated. Thus, the receiver of the message cannot be presumed to read it unless it knows that language. Mathematically, original message &#x003D; encoded message &#x002B; code, but only one term of this equation is communicated. If we consider in addition that those messages are coded efficiently, then each neuron uses its own private language on the basis of its personal history of inputs.</p>
<p>Thus, in the neural coding metaphor, the code is private to each neuron. If we follow this metaphor, this means that all neurons speak a different language, a language that might allow expressing concepts very concisely but that no one else can understand. Thus, the neural coding metaphor leads to the conclusion that the brain is a Tower of Babel.</p>
<p>These difficulties arise when neural activity is seen as messages. Another possible view is that neural activity is indeed activity, and action potentials are actions. Each spike has an effect on target neurons; it pushes other neurons in some direction. Does the heart send messages to the blood about how fast the organism runs, or does it move blood in the vascular system? Do neurons read each other&#x0027;s spike trains, or do they interact with each other?</p>
</sec>
<sec id="s4b">
<label>4.2.</label>
<title>Coding vs. acting</title>
<p>I will now discuss a concrete biological example where both the coding and acting metaphors can be applied. Paramecium is a unicellular organism that swims in stagnant fresh water using cilia and feeds on bacteria. It uses different kinds of sensory signals, including mechanical signals to avoid obstacles and chemical signals to localize food (<xref ref-type="bibr" rid="c24">Jennings, 1906</xref>). To a first approximation, it alternates between straight courses and sudden random changes in direction (<xref ref-type="fig" rid="fig7">Fig. 7A</xref>). It turns out that each change in direction is triggered by a spike produced by voltage-gated calcium channels (<xref ref-type="fig" rid="fig7">Fig. 7B</xref>) (<xref ref-type="bibr" rid="c15">Eckert, 1972</xref>). To find a chemical source, Paramecium uses a simple method: when concentration decreases, the membrane is depolarized by chemical receptors and a spike is produced (with some stochasticity), triggering a change of direction (similar to chemotaxis in E. Coli). This is of course a simplified description of Paramecium physiology and behavior, but for the sake of the argument we shall consider an organism that functions in this simple way.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Spatial cognition in Paramecium, a &#x201C;swimming neuron&#x201D;. A, Paramecium finds a chemical source by switching to a new random direction when concentration decreases. B, Each direction change is triggered by an action potential, which transiently inverts cilia beating through a calcium pathway (adapted from (<xref ref-type="bibr" rid="c16">Eckert and Naitoh, 1970</xref>)).</p></caption>
<graphic xlink:href="168237_fig7.tif"/>
</fig>
<p>Thus, Paramecium is a sort of swimming neuron, where spikes can be seen both as encoding sensory signals (concentration) and as producing an action (change of direction). The same could be said of any neuron in a nervous system, except the action of a neuron is generally on other neurons and only indirectly on the environment. We can now expose the difficulties of the coding metaphor in this context.</p>
<p>We may argue that if the organism can navigate efficiently in its environment, then the spikes must contain information about that environment. Therefore, it makes sense to apply the coding metaphor to this situation. How should sensory signals be encoded into spikes? This question raises two issues. First, the primary goal of the organism is not to maximize information but to take appropriate action. But is coding efficiency the same as behavioral performance? In general no, because coding efficiency only depends on the sensory signals while behavioral performance depends on what you want to do: to move towards or away from a source, to look for food or to sleep, or to look for a mate. Therefore, an efficient code (in terms of signal representation) is not in general a good code (in terms of behavior).</p>
<p>There is a second fundamental issue. The input to the organism is not the environment but the signals it captures. It follows that sensory signals are not given <italic>a priori</italic>: they depend on the organism&#x0027;s actions, and therefore on the encoding. Thus, the very notion of coding is ill-defined because the relation between &#x201C;input&#x201D; and &#x201C;output&#x201D; is not a mapping but a circular relation. This affects the coding framework in two ways. First, if we consider organism and environment as two coupled dynamical systems, then what can be said is that the organism&#x0027;s action at a given instant depend on the previous sensory signals, and possibly on internal states. But the input signal is not mapped as a whole to an output signal, because the signal is not given a priori independently of the outputs. Second, one may define an efficient code on the basis of the statistics of the sensory signal, but choosing that code changes the sensory signal. Thus, it is not possible to answer the question: &#x201C;what is the most efficient way to encode the sensory signals?&#x201D;. A possible solution would be to see it as a fixed-point problem, for example by iteratively looking for an efficient code until signal statistics are stable. But this would lead to cells looking for regions of space where sensory signals are easiest to reconstruct, with no guarantee that it matches the organism&#x0027;s goals. Although the circularity is particularly evident in the Paramecium example, it is a general feature of biological organisms (<xref ref-type="bibr" rid="c1">Ahissar and Assa, 2016</xref>); for example, visual signals both trigger and depend on eye movements.</p>
<p>This example illustrates the fact that spikes are not just messages. They are an integral part of the sensorimotor loop, with each spike produced by a neuron triggering changes on the neighboring network, on the environment and ultimately on its input. Thus, failures of efficient coding may occur not because the brain is not efficient, but because the brain does not really code.</p>
</sec>
</sec>
<sec id="s5">
<label>5.</label>
<title>Conclusion</title>
<p>A metaphor is not true or false: it is insightful or misleading (<xref ref-type="bibr" rid="c26">Lakoff and Johnson, 2008</xref>). How insightful is the coding metaphor for the brain?</p>
<p>There are two ways in which the neural coding metaphor is used. One is when we say that neurons encode sensory signals, for example when we say that retinal spike trains encode visual signals. Discussions of efficient coding, predictive coding and predictive information belong to this category. In essence, the proposition means nothing more than there is a mapping from X to neural activity, and we are interested in properties of that mapping. Thus, it implicitly frames the problem of perception as one of representing inputs that are given to the organism. But inputs are not given to the organism. On the contrary, the organism actively captures sensory signals in order to obtain information about the environment. This makes the relation between sensory signals and neural activity circular, for any neuron along the sensorimotor loop. Consequently, normative discussions framed exclusively in terms of coding are problematic (<italic>how should neurons encode sensory signals?</italic>), because inputs are not independent from outputs, and coding efficiency is not <italic>a priori</italic> the same as behavioral performance.</p>
<p>Presumably, an organism is not so much interested in reconstructing the sensory signals as in obtaining information about the environment, and capturing signals is only a means to that end. Thus, a second way to use the neural coding metaphor is when we say that neurons encode some abstract property of the environment. Such propositions are highly misleading when the property is an experimental parameter, because in that case the communication channel is made of both the biological and experimental systems. If the interpretation of the neural code depends on experimental context, then the code is not neural after all, but rather neuro-experimental. This qualification certainly affects the insightfulness of the metaphor for understanding brain function.</p>
<p>Thus, speaking of a neural code for an abstract property is meaningful to the extent that the implied decoder is insensitive to elements of context. But who reads the neural code? If we consider that neurons encode objective properties of the world and the brain reads the code, then the neural coding metaphor is dualist. What does it mean to say that neurons encode the direction of a sound source, does the brain know about radians? To avoid the homunculus fallacy, what is to be encoded and manipulated cannot be objective properties (radians) but internal models that relate sensory signals together and with the organism&#x0027;s actions. It follows that a biologically relevant concept of information cannot be Shannon&#x0027;s unstructured notion of information (an input as an element of an unstructured set). Intrinsic information must take the form of structured models, in which not only elements but also relations between elements are represented. It follows that neural assemblies (&#x201C;bags of neurons&#x201D;) cannot be the basis of mental representations.</p>
<p>Ultimately, the view that spikes are messages leads to a perplexing view of neural activity. A message is only a message for someone who knows its language. But in the neural coding metaphor, each neuron has its own language (the encoding) and only the message is communicated. Thus, the brain is a Tower of Babel. Perhaps more relevant is the view that an action potential is an action on other neurons, that producing a spike is a way of doing rather than of communicating, and that neurons interact with each other and with the environment, rather than speak to each other. After all, we do speak of neural &#x201C;activity&#x201D;.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ahissar</surname> <given-names>E</given-names></string-name>, <string-name><surname>Assa</surname> <given-names>E</given-names></string-name> (<year>2016</year>) <article-title>Perception as a closed-loop convergence process</article-title>. <source>eLife</source> <fpage>5</fpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Ashida</surname> <given-names>G</given-names></string-name>, <string-name><surname>Carr</surname> <given-names>CE</given-names></string-name> (<year>2011</year>) <article-title>Sound localization: Jeffress and beyond</article-title>. <source>Curr Opin Neurobiol</source> <volume>21</volume>:<fpage>745</fpage>&#x2013;<lpage>751</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="other"><string-name><surname>Benichoux</surname> <given-names>V</given-names></string-name>, <string-name><surname>Fontaine</surname> <given-names>B</given-names></string-name>, <string-name><surname>Karino</surname> <given-names>S</given-names></string-name>, <string-name><surname>Joris</surname> <given-names>PX</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2015</year>) <article-title>Frequency-dependent time differences between the ears are matched in neural tuning</article-title>. <source>eLife</source>:10.7554/eLife.06072.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Benichoux</surname> <given-names>V</given-names></string-name>, <string-name><surname>R&#x00E9;billat</surname> <given-names>M</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2016</year>) <article-title>On the variation of interaural time differences with frequency</article-title>. <source>J Acoust Soc Am</source> <volume>139</volume>:<fpage>1810</fpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bialek</surname> <given-names>W</given-names></string-name>, <string-name><surname>Nemenman</surname> <given-names>I</given-names></string-name>, <string-name><surname>Tishby</surname> <given-names>N</given-names></string-name> (<year>2001</year>) <article-title>Predictability, complexity, and learning</article-title>. <source>Neural Comput</source> <volume>13</volume>:<fpage>2409</fpage>&#x2013;<lpage>2463</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bolz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gilbert</surname> <given-names>CD</given-names></string-name> (<year>1986</year>) <article-title>Generation of end-inhibition in the visual cortex via interlaminar connections</article-title>. <source>Nature</source> <volume>320</volume>:<fpage>362</fpage>&#x2013;<lpage>365</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2010</year>) <article-title>On the interpretation of sensitivity analyses of neural responses</article-title>. <source>J Acoust Soc Am</source> <volume>128</volume>:<fpage>2965</fpage>&#x2013;<lpage>2972</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2012</year>) <article-title>Computing with neural synchrony</article-title>. <source>PLoS Comp Biol</source> <volume>8</volume>:<fpage>e1002561</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="book"><string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2016</year>) <chapter-title>Subjective Physics</chapter-title>. In: <source>Closed loop neuroscience</source> (<string-name><surname>El Hady</surname> <given-names>A</given-names></string-name>, ed), pp <fpage>146</fpage>&#x2013;<lpage>170</lpage>. <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Buzs&#x00E1;ki</surname> <given-names>G</given-names></string-name> (<year>2010</year>) <article-title>Neural Syntax: Cell Assemblies, Synapsembles, and Readers</article-title>. <source>Neuron</source> <volume>68</volume>:<fpage>362</fpage>&#x2013;<lpage>385</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Clark</surname> <given-names>A</given-names></string-name> (<year>2013</year>) <article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title>. <source>Behav Brain Sci</source> <volume>36</volume>:<fpage>181</fpage>&#x2013;<lpage>204</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Crick</surname> <given-names>F</given-names></string-name> (<year>1979</year>) <article-title>Thinking about the brain</article-title>. <source>Sci Am</source> <volume>241</volume>:<fpage>219</fpage>&#x2013;<lpage>232</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>deCharms</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Zador</surname> <given-names>A</given-names></string-name> (<year>2000</year>) <article-title>Neural representation and the cortical code</article-title>. <source>Annu Rev Neurosci</source> <volume>23</volume>:<fpage>613</fpage>&#x2013;<lpage>647</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="book"><string-name><surname>Dennett</surname> <given-names>DC</given-names></string-name> (<year>1992</year>) <source>Consciousness Explained</source>, <edition>1st ed.</edition> <publisher-name>Back Bay Books</publisher-name>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Eckert</surname> <given-names>R</given-names></string-name> (<year>1972</year>) <article-title>Bioelectric Control of Ciliary Activity</article-title>. <source>Science</source> <volume>176</volume>:<fpage>473</fpage>&#x2013;<lpage>481</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Eckert</surname> <given-names>R</given-names></string-name>, <string-name><surname>Naitoh</surname> <given-names>Y</given-names></string-name> (<year>1970</year>) <article-title>Passive electrical properties of Paramecium and problems of ciliary coordination</article-title>. <source>J Gen Physiol</source> <volume>55</volume>:<fpage>467</fpage>&#x2013;<lpage>483</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="book"><string-name><surname>Gibson</surname> <given-names>JJ</given-names></string-name> (<year>1986</year>) <source>The Ecological Approach to Visual Perception</source>. <publisher-name>Routledge</publisher-name>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Goodman</surname> <given-names>DF</given-names></string-name>, <string-name><surname>Benichoux</surname> <given-names>V</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2013</year>) <article-title>Decoding neural responses to temporal cues for sound localization</article-title>. <source>eLife</source> <volume>2</volume>:<issue>2</issue>:<fpage>e01312</fpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Goodman</surname> <given-names>DFM</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2010</year>) <article-title>Spike-Timing-Based Computation in Sound Localization</article-title>. <source>PLoS Comput Biol</source> <volume>6</volume>:<fpage>e1000993</fpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Grothe</surname> <given-names>B</given-names></string-name>, <string-name><surname>Pecka</surname> <given-names>M</given-names></string-name>, <string-name><surname>McAlpine</surname> <given-names>D</given-names></string-name> (<year>2010</year>) <article-title>Mechanisms of Sound Localization in Mammals</article-title>. <source>Physiol Rev</source> <volume>90</volume>:<fpage>983</fpage>&#x2013;<lpage>1012</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Harper</surname> <given-names>NS</given-names></string-name>, <string-name><surname>McAlpine</surname> <given-names>D</given-names></string-name> (<year>2004</year>) <article-title>Optimal neural population coding of an auditory spatial cue</article-title>. <source>Nature</source> <volume>430</volume>:<fpage>682</fpage>&#x2013;<lpage>686</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Wiesel</surname> <given-names>TN</given-names></string-name> (<year>1968</year>) <article-title>Receptive fields and functional architecture of monkey striate cortex</article-title>. <source>J Physiol</source> <volume>195</volume>:<fpage>215</fpage>&#x2013;<lpage>243</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Jeffress</surname> <given-names>LA</given-names></string-name> (<year>1948</year>) <article-title>A place theory of sound localisation</article-title>. <source>J Comp Physiol Psychol</source> <volume>41</volume>:<fpage>35</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="book"><string-name><surname>Jennings</surname> <given-names>HS</given-names></string-name> (<string-name><surname>Herbert</surname> <given-names>S</given-names></string-name> (<year>1906</year>) <source>Behavior of the lower organisms</source>. <publisher-loc>New York</publisher-loc>, <publisher-name>The Columbia university press, The Macmillan company, agents</publisher-name>; [etc., etc.]. Available at: <ext-link ext-link-type="uri" xlink:href="http://archive.org/details/behavioroflowero00jenn">http://archive.org/details/behavioroflowero00jenn</ext-link> [Accessed <date-in-citation content-type="accessed-date">December 20, 2015</date-in-citation>].</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Joris</surname> <given-names>PX</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>PH</given-names></string-name>, <string-name><surname>Yin</surname> <given-names>TC</given-names></string-name> (<year>1998</year>) <article-title>Coincidence detection in the auditory system: 50 years after Jeffress</article-title>. <source>Neuron</source> <volume>21</volume>:<fpage>1235</fpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="book"><string-name><surname>Lakoff</surname> <given-names>G</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>M</given-names></string-name> (<year>2008</year>) <source>Metaphors We Live By</source>. <publisher-name>University of Chicago Press</publisher-name>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Laudanski</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zheng</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2014</year>) <article-title>A structural theory of pitch</article-title>. <source>eneuro:ENEURO.0033-14.2014</source>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Laughlin</surname> <given-names>S</given-names></string-name> (<year>1981</year>) <article-title>A simple coding procedure enhances a neuron&#x0027;s information capacity</article-title>. <source>Z Naturforsch [C]</source> <volume>36</volume>:<fpage>910</fpage>&#x2013;<lpage>912</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="book"><string-name><surname>Marr</surname> <given-names>D</given-names></string-name> (<year>1982</year>) <source>Vision</source>, <edition>First Edition</edition>. <publisher-name>W.H.Freeman &#x0026; Co Ltd</publisher-name>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>McAlpine</surname> <given-names>D</given-names></string-name>, <string-name><surname>Jiang</surname> <given-names>D</given-names></string-name>, <string-name><surname>Palmer</surname> <given-names>AR</given-names></string-name> (<year>2001</year>) <article-title>A neural code for low-frequency sound localization in mammals</article-title>. <source>Nat Neurosci</source> <volume>4</volume>:<fpage>396</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Moser</surname> <given-names>EI</given-names></string-name>, <string-name><surname>Kropff</surname> <given-names>E</given-names></string-name>, <string-name><surname>Moser</surname> <given-names>M-B</given-names></string-name> (<year>2008</year>) <article-title>Place Cells, Grid Cells, and the Brain&#x0027;s Spatial Representation System</article-title>. <source>Annu Rev Neurosci</source> <volume>31</volume>:<fpage>69</fpage>&#x2013;<lpage>89</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Keefe</surname> <given-names>J</given-names></string-name> (<year>1976</year>) <article-title>Place units in the hippocampus of the freely moving rat</article-title>. <source>Exp Neurol</source> <volume>51</volume>:<fpage>78</fpage>&#x2013;<lpage>109</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>O&#x2019;Regan</surname> <given-names>JK</given-names></string-name>, <string-name><surname>No&#x00EB;</surname> <given-names>A</given-names></string-name> (<year>2001</year>) <article-title>A Sensorimotor Account of Vision and Visual Consciousness</article-title>. <source>Behav Brain Sci</source> <volume>24</volume>:<fpage>939</fpage>&#x2013;<lpage>973</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Palmer</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Marre</surname> <given-names>O</given-names></string-name>, <string-name><surname>Berry</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Bialek</surname> <given-names>W</given-names></string-name> (<year>2015</year>) <article-title>Predictive information in a sensory population</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>112</volume>:<fpage>6908</fpage>&#x2013;<lpage>6913</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Rao</surname> <given-names>RP</given-names></string-name>, <string-name><surname>Ballard</surname> <given-names>DH</given-names></string-name> (<year>1999</year>) <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nat Neurosci</source> <volume>2</volume>:<fpage>79</fpage>&#x2013;<lpage>87</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="book"><string-name><surname>Rieke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Warland</surname> <given-names>D</given-names></string-name>, <string-name><surname>Steveninck</surname>, <given-names>R de de R van</given-names></string-name>, <string-name><surname>Bialek</surname> <given-names>W</given-names></string-name> (<year>1999</year>) <source>Spikes: Exploring the Neural Code</source>. <publisher-loc>Cambridge, Mass.; London</publisher-loc>: <publisher-name>A Bradford Book</publisher-name>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="book"><string-name><surname>Rosen</surname> <given-names>R</given-names></string-name> (<year>1985</year>) <source>Anticipatory Systems: Philosophical, Mathematical and Methodological Foundations</source>, <edition>1st edition</edition>. <publisher-loc>Oxford u.a</publisher-loc>.: <publisher-name>Pergamon Pr</publisher-name>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Schnapf</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Kraft</surname> <given-names>TW</given-names></string-name>, <string-name><surname>Baylor</surname> <given-names>DA</given-names></string-name> (<year>1987</year>) <article-title>Spectral sensitivity of human cone photoreceptors</article-title>. <source>Nature</source> <volume>325</volume>:<fpage>439</fpage>&#x2013;<lpage>441</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Shackleton</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Skottun</surname> <given-names>BC</given-names></string-name>, <string-name><surname>Arnott</surname> <given-names>RH</given-names></string-name>, <string-name><surname>Palmer</surname> <given-names>AR</given-names></string-name> (<year>2003</year>) <article-title>Interaural Time Difference Discrimination Thresholds for Single Neurons in the Inferior Colliculus of Guinea Pigs</article-title>. <source>J Neurosci</source> <volume>23</volume>:<fpage>716</fpage>&#x2013;<lpage>724</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="book"><string-name><surname>Shannon</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Weaver</surname> <given-names>W</given-names></string-name> (<year>1971</year>) <source>The Mathematical Theory of Communication</source>. <publisher-name>University of Illinois Press</publisher-name>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Singer</surname> <given-names>W</given-names></string-name> (<year>1999</year>) <article-title>Neuronal synchrony: a versatile code for the definition of relations?</article-title> <source>Neuron</source> <volume>24</volume>:<fpage>49</fpage>&#x2013;<lpage>65</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Skottun</surname> <given-names>BC</given-names></string-name> (<year>1998</year>) <article-title>Sound localization and neurons</article-title>. <source>Nature</source> <volume>393</volume>:<fpage>531</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>von der Malsburg</surname> <given-names>C</given-names></string-name> (<year>1999</year>) <article-title>The what and why of binding: the modeler&#x0027;s perspective</article-title>. <source>Neuron</source> <volume>24</volume>:<fpage>95</fpage>&#x2013;<lpage>104</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Yin</surname> <given-names>TC</given-names></string-name>, <string-name><surname>Chan</surname> <given-names>JC</given-names></string-name> (<year>1990</year>) <article-title>Interaural time sensitivity in medial superior olive of cat</article-title>. <source>J Neurophysiol</source> <volume>64</volume>:<fpage>465</fpage>&#x2013;<lpage>488</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Zheng</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Brette</surname> <given-names>R</given-names></string-name> (<year>2017</year>) <article-title>On the relation between pitch and level</article-title>. <source>Hear Res</source> <volume>348</volume>:<fpage>63</fpage>&#x2013;<lpage>69</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>