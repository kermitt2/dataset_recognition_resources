<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/341495</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group><article-title>Kernel machine tests of association between brain networks and phenotypes</article-title></title-group>
<contrib-group>
<contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6337-9079</contrib-id>
<name><surname>Jensen</surname><given-names>Alexandria M</given-names></name><xref ref-type="aff" rid="a1">1</xref></contrib>
<contrib contrib-type="author"><name><surname>Tregellas</surname><given-names>Jason R</given-names></name><xref ref-type="aff" rid="a2">2</xref><xref ref-type="aff" rid="a3">3</xref></contrib>
<contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9134-0884</contrib-id>
<name><surname>Sutton</surname><given-names>Brianne</given-names></name><xref ref-type="aff" rid="a2">2</xref></contrib>
<contrib contrib-type="author"><name><surname>Xing</surname><given-names>Fuyong</given-names></name><xref ref-type="aff" rid="a1">1</xref></contrib>
<contrib contrib-type="author"><name><surname>Ghosh</surname><given-names>Debashis</given-names></name><xref ref-type="aff" rid="a1">1</xref><xref ref-type="author-notes" rid="n1">&#x002A;</xref></contrib>
<aff id="a1"><label>1</label><institution>Department of Biostatistics &#x0026; Informatics, University of Colorado Anschutz Medical Campus</institution>, Aurora, Colorado, <country>United States of America</country></aff>
<aff id="a2"><label>2</label><institution>Department of Psychiatry, University of Colorado Anschutz Medical Campus</institution>, Aurora, Colorado, <country>United States of America</country></aff>
<aff id="a3"><label>3</label><institution>Research Services, Denver VA Medical Center</institution>, Aurora, Colorado, <country>United States of America</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>&#x002A;</label><p><email>debashis.ghosh@ucdenver.edu</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>341495</elocation-id>
<history>
<date date-type="received">
<day>07</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>07</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>07</day>
<month>6</month>
<year>2018</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions>
<self-uri xlink:href="341495.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract><title>Abstract</title>
<p>Applications of quantitative network analysis to functional brain connectivity have become popular in the last decade due to their ability to describe the general topological principles of brain networks. However, many issues arise when standard statistical analysis techniques are applied to functional magnetic resonance imaging (fMRI) connectivity maps. Frequently, summary measures of these maps, such as global efficiency and clustering coefficients, collapse the changing structures of graph topology from many scales to one. This can result in a loss of whole-brain spatio-temporal pattern information that may be significant in association and prediction analyses. Drawing from the electrical engineering field, the resistance perturbation distance is a quantification of similarity between graphs on the same vertex set that has been shown to identify changes in dynamic graphs, such as those from fMRI, while not being computationally expensive or result in a loss of information. This work proposes a novel kernel-based regression scheme that incorporates the resistance perturbation distance to better understand the association with biological phenotypes from fMRI using both simulated and real datasets.</p>
</abstract>
<counts>
<page-count count="29"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><title>Introduction</title>
<p>Since its introduction in the early 1990s [<xref ref-type="bibr" rid="c1">1</xref>] [<xref ref-type="bibr" rid="c2">2</xref>], functional magnetic resonance imaging (fMRI) has rapidly grown to become the most popular technique to observe the living human brain, with nearly 30,000 papers published on the topic in 2015 alone [<xref ref-type="bibr" rid="c3">3</xref>]. First described by Ogawa in 1990, the blood oxygen level dependent (BOLD) signal is the most common method of fMRI [<xref ref-type="bibr" rid="c4">4</xref>]. The BOLD signal employs hemoglobin as an endogenous contrast agent, exploiting the magnetization difference between oxy- and deoxyhemoglobin to create the fMRI signal [<xref ref-type="bibr" rid="c5">5</xref>]. This BOLD signal is theorized to be comprised of three determinants: a neuronal response to either an endogenous or exogenous stimulus, the relationship between the neuronal and hemodynamic responses, and the hemodynamic response itself [<xref ref-type="bibr" rid="c5">5</xref>]. MRI measures this neuronal responses indirectly through its hypothesized hemodynamic correlate, in contrast to EEG and MEG, two popular techniques for analyzing functional connectivity in the brain that rely on quantification of electrical activity. In addition to the differences in focus of these techniques, resolutions differ. While EEG and MEG provide temporal resolution on the scale of milliseconds at the cost of spatial localization ambiguity; fMRI has much higher spatial resolution but is limited in temporal resolution due to the slower rate of brain hemodynamics [<xref ref-type="bibr" rid="c6">6</xref>]. While all of these techniques offer noninvasive ways to study brain activity, fMRI has quickly outpaced EEG and MEG in popularity within the research community.</p>
<p>Techniques like fMRI can be used in biomedical research to examine localization of brain regions engaged by a particular task, determining brain networks, and predicting psychological or disease states [<xref ref-type="bibr" rid="c6">6</xref>]. While most fMRI studies initially focused on the examination of brain regions engaged during a specific task, increased attention has been paid examining the connectivity of the entire brain at rest, commonly referred to as resting state fMRI (rs-fMRI) [<xref ref-type="bibr" rid="c7">7</xref>]. Analysis of rs-fMRI can help yield information about the strength of connections within and among brain regions that may be unique to clinical populations [<xref ref-type="bibr" rid="c7">7</xref>] [<xref ref-type="bibr" rid="c8">8</xref>]. All of these objectives can be achieved through the application of statistical techniques that address the specific complications that arise from analysis of spatially correlated, four-dimensional data.</p>
<p>The most common technique used to analyze fMRI data is a mass univariate analysis (MUA). In MUA, a general linear model is fit at each voxel independently with a combination of experimental conditions and biological confounders as covariates [<xref ref-type="bibr" rid="c9">9</xref>]. This creates a map of parameter estimates and test statistics that is then thresholded to identify significant voxels; the location and clustering of these significant voxels inform the functional relationships within the brain. Time series methods have also been successfully implemented to examine the interregional correlation values over the length of the fMRI scan [<xref ref-type="bibr" rid="c7">7</xref>]. However, these techniques ignore the underlying spatial relationships within the data; even though voxel responses are correlated, mass univariate analysis and its time series extension do not fully account for the underlying spatial correlation [<xref ref-type="bibr" rid="c9">9</xref>]. However, by extending the general linear model framework to allow for the modeling of non-linear relationships, more complex associations can be fit. One such way to accomplish this is through the use of kernels, which are weighting functions used to estimate the conditional expectation of a random variable [<xref ref-type="bibr" rid="c10">10</xref>].</p>
<p>In contrast to the use of general linear models and kernel regression, applications of quantitative network analysis through graph theory have become popular in the last decade due to their utility in describing the general topological principles of brain networks [<xref ref-type="bibr" rid="c11">11</xref>]. First introduced by Leonhard Euler in his 1736 solution to <italic>Seven Bridges of Konigserg,</italic> graph theory can be used to model a range of relations and processes in physical, biological, social, and information systems [?]. The application of graph theory to study the underlying structural and functional connections within the brain was first introduced by Ed Bullmore and Olaf Sporns in their seminal work, published in 2009 [<xref ref-type="bibr" rid="c11">11</xref>]. In their work, Bullmore and Sporns showed how connectivity analyses can be used not only to analyze structural networks that represent the architectural connections within and between regions, but also to analyze the underlying functional networks that can elucidate how this architecture supports various neurophysiological dynamics [<xref ref-type="bibr" rid="c11">11</xref>]. Numerous studies have reported that brain network parameters, derived from fMRI, EEG/MEG, and structural MRI, differ between subjects based on task or underlying biological or physiological condition [<xref ref-type="bibr" rid="c11">11</xref>]. However, many issues arise when applying standard statistical methods to fMRI connectivity maps. Frequently, summary measures of these maps, such as global efficiency and clustering coefficients, collapse the changing structure of graph topology from many scales to one [<xref ref-type="bibr" rid="c12">12</xref>]. This can result in a loss of whole brain spatiotemporal pattern information that may be significant in association and prediction analyses.</p>
<p>This study proposes a kernel regression scheme that incorporates the resistance perturbation distance to better predict biological phenotypes from fMRI using both simulated and real datasets. Drawing from the electrical engineering field, the resistance perturbation distance (RPD) is a quantification of similarity between graphs on the same vertex set that has been shown to identify changes in dynamic graphs, such as those from fMRI, while not being computationally expensive or result in a loss of information [<xref ref-type="bibr" rid="c12">12</xref>]. By incorporating the RPD into a kernel distance function, the high-dimensional feature space of brain networks, defined on input pairs, can be generalized to non-linear spaces; this allows for a wider class of distance-based algorithms, rather than the restrictive squared distance, to be representative of the similarity between two networks. We hypothesize that this algorithm will show significant associations between the metric and phenotype.</p>
<p>The remainder of this paper is organized as follows. The methods section will describe the derivation and properties of the resistance perturbation distance, the general framework for distance-based kernels, and a kernel-based score test. We then apply these methods under a variety of simulation paradigms and to the COBRE-I dataset. Finally, we conclude the paper with a discussion and proposal of future directions. All R code will be made available as supplementary material to this manuscript.</p>
</sec>
<sec id="s2"><title>Materials and methods</title>
<sec id="s2a"><title>The resistance perturbation distance</title>
<p>Like many complex systems, the human brain is highly dynamic, where the relationship between regions changes with respect to time. The brain is a highly plastic organ, able to reorganize itself through modifications of its neuronal connections. This feature is unique to the central nervous system: neuroplasticity occurs at the beginning of life, where the immature brain organizes itself, when it is subjected to trauma or injury, and throughout adulthood whenever something new is learned. Neuroplasticity also relates to the brain&#x2019;s ability to have both specialized and integrated regions, known as neuronal clusters. Depending on the needs of the brain, neuronal clusters, especially those deemed to be highly influential [<xref ref-type="bibr" rid="c13">13</xref>], communicate across many regions of the brain. The most popular graph theory measures collapse this complex system from many scales to one, resulting in a loss of information. In contrast, the resistance perturbation distance is a quantification that is flexible enough to account for configurational changes that can occur on a local scale - through local neighbors on the same node - or on a global scale - through connections between clusters or hubs [<xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>Let <italic>G</italic> = (<italic>V, E, w</italic>), be an undirected, weighted graph that is connected (there is a path between every pair of nodes) and contains no self-loops (edges that connect nodes to themselves), where <italic>V</italic> = {1, 2,&#x2026;, <italic>n</italic>} is the vertex set, <italic>E</italic> is the edge set, and <italic>w</italic> is a symmetric weight function that provides a quantification of the strength of the relationship between two vertices. The higher the value of <italic>w,</italic> the stronger the relationship between two vertices <italic>i</italic> and <italic>j.</italic> If we define the weighted adjacency matrix to be
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn1.gif"/></alternatives></disp-formula>
the degree matrix&#x2019;s definition is simply <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline1.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c12">12</xref>]. Using the adjacency and degree matrices, the Laplacian matrix, <bold>L,</bold> is a symmetric and positive semi-definite matrix, where <bold>L</bold> = <bold>D</bold> &#x2212; <bold>A</bold> [<xref ref-type="bibr" rid="c12">12</xref>]. The Lapacian matrix has many special properties, including that it can be spectrally decomposed into eigenvectors and eigenvalues; as <bold>L</bold> is positive semi-definite, then all eigenvalues <italic>&#x03BB;<sub>j</sub></italic> &#x2265; 0. Further, if we find the Moore-Penrose pseudo-inverse of <bold>L,</bold> denoted <bold>L</bold><sup>&#x2020;</sup>, by definition of <bold>L, L</bold><sup>&#x2020;</sup> is also symmetric.</p>
<p>An important aspect to these adjacency matrices is that a family of distances on <italic>G</italic><sup>(1)</sup> and <italic>G</italic><sup>(2)</sup> can be induced through the application of a matrix-to-matrix function <italic>&#x03D5;</italic> on the corresponding adjacency matrices. Monnig and Meyer define a general graph distance as,</p>
<p>&#x201C;Given a matrix-to-matrix function, <italic>&#x03C6;,</italic> on a square matrix, <italic>M<sub>n&#x00D7;n</sub>,</italic>
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn2.gif"/></alternatives></disp-formula>
and a distance <italic>d</italic> on <italic>M<sub>n&#x00D7;n,</sub></italic> we define the pseudo-distance <italic>d<sub>&#x03C6;</sub></italic> between two graphs <italic>G</italic><sup>(1)</sup> and <italic>G</italic><sup>(2)</sup> as
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn3.gif"/></alternatives></disp-formula>
where <italic>A</italic><sup>(1)</sup> and <italic>A</italic><sup>(2)</sup> are the adjacency matrices of <italic>G</italic><sup>(1)</sup> and <italic>G</italic><sup>(2)</sup>, respectively. If <italic>&#x03C6;</italic> is injective, then <italic>d<sub>&#x03C6;</sub></italic> defines a distance [<xref ref-type="bibr" rid="c12">12</xref>].&#x201D;</p>
<p>This definition is important in that it decouples two important aspects to the distance <italic>d<sub>&#x03D5;</sub>.</italic> The matrix-to-matrix function <italic>&#x03D5;</italic> extracts geometric or configurational properties from each graph while the distance <italic>d</italic> can be used to emphasize the relative size of variations in <italic>&#x03D5;.</italic> Koutra et al. expand on this definition, defining axioms that any distance measure should satisfy:
<list list-type="order">
<list-item><p><italic>d<sub>&#x03C6;</sub></italic> (<italic>G</italic><sup>(1)</sup>, <italic>G</italic><sup>(1)</sup>) = 0</p></list-item>
<list-item><p><italic>d<sub>&#x03C6;</sub></italic> (<italic>G</italic><sup>(1)</sup>, <italic>G</italic><sup>(2)</sup>) = <italic>d<sub>&#x03C6;</sub></italic> (<italic>G</italic><sup>(2)</sup>, <italic>G</italic><sup>(1)</sup>)</p></list-item>
<list-item><p><italic>d<sub>&#x03C6;</sub></italic> (<italic>G</italic><sup>(1)</sup>, <italic>G</italic><sup>(2)</sup>) &#x2192; 0 as the number of nodes <italic>v</italic> &#x2192; &#x221E;, where the edge sets between <italic>G</italic><sup>(1)</sup> and <italic>G</italic><sup>(2)</sup> are complementary [<xref ref-type="bibr" rid="c14">14</xref>].</p></list-item></list></p>
<p>As well, a distance measure should satisfy the following properties:
<list list-type="order">
<list-item><p>Edge Importance: a change in an edge that creates disconnected components within the graph should be penalized more than changes that maintain its connectivity properties.</p></list-item>
<list-item><p>Weight Awareness: the larger the weight of a removed edge, the greater its impact on the distance.</p></list-item>
<list-item><p>Edge- &#x201C;Submodularity&#x201D;: a change is more meaningful in a sparse graph than in a denser graph that are both defined on the same vertex set.</p></list-item>
<list-item><p>Focus Awareness: random changes in a graph result in a smaller impact than targeted changes [<xref ref-type="bibr" rid="c12">12</xref>] [<xref ref-type="bibr" rid="c14">14</xref>].</p></list-item>
</list></p>
<p>The concept of effective resistance, commonly seen in the electrical engineering field, can be understood in terms of a commute time, which can be analogously extended to the graph theoretic measure of path length but with a richer choice of distance <italic>d.</italic> Monnig and Meyer showed that the effective resistance between two vertices falls under the definition of a general graph distance, but also preserves the three axioms and four properties detailed above. Because the BOLD signal measures the indirect correlate of neuronal responses in the brain, which are the transfer of action potential between neurons, seeing the brain as a circuit board is not an uncommon analogy. Therefore, the use of effective resistance can be easily extended to the summarization of fMRI data. Effective resistance can be defined as
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn4.gif"/></alternatives></disp-formula></p>
<p>[<xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>Using this, then define the resistance perturbation distance as the element-wise p-norm of the difference between effective resistances such that
<disp-formula id="eqn1"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn1.gif"/></alternatives></disp-formula>
for 1 &#x2264; <italic>p &#x003C;</italic> &#x221E; and
<disp-formula id="eqn2"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn2.gif"/></alternatives></disp-formula>
for <italic>p</italic> = &#x221E; [<xref ref-type="bibr" rid="c12">12</xref>].&#x201D;</p>
<p>This distance metric defines a distance on the space of connected, undirected, weighted graphs on the same vertex set, where the effective resistance <bold>R</bold> is fully and uniquely defined by a graph&#x2019;s Laplacian matrix <bold>L</bold> and, for 1 &#x2264; <italic>p &#x003C;</italic> &#x221E;, the element-wise p-norm, &#x007C;&#x007C;&#x00B7;&#x007C;&#x007C;<italic><sub>p</sub></italic>, is a norm for a matrix <italic>M<sub>n&#x00D7;n.</sub></italic> Thus, the distance can easily be shown to be non-negative, symmetric by application of the definition of an element-wise p-norm and satisfies the triangle inequality,
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn6.gif"/></alternatives></disp-formula></p>
<p>Additionally, if we observe <italic>G</italic><sup>(1)</sup> = <italic>G</italic><sup>(2)</sup>, then <italic>d<sub>rp</sub></italic><sub>(<italic>p</italic>)</sub> (<italic>G</italic><sup>(1)</sup>, <italic>G</italic><sup>(2)</sup>) = 0 because <bold>R</bold><sup>(1)</sup> = <bold>R</bold><sup>(2)</sup> by definition. Conversely, if <italic>G</italic><sup>(1)</sup> and <italic>G</italic><sup>(2)</sup> are two graphs with the same effective resistance matrix, <bold>R</bold><sup>(1)</sup> = <bold>R</bold><sup>(2)</sup>, this implies the equality of the Laplacian matrices, <bold>L</bold><sup>(1)</sup> = <bold>L</bold><sup>(2)</sup> and, continuing on this train of thought, equality of their weighted adjacency matrices, <bold>A<sup>(</sup></bold><sup>1)</sup> = <bold>A</bold><sup>(2)</sup> [<xref ref-type="bibr" rid="c12">12</xref>].</p>
<sec id="s2b"><title>Distance-Based Kernels and a Kernel-Based Score Test</title>
<p>Rather than assume a parametric form in the relationship between functional connectivity matrices and phenotypic classification, kernel distance estimation was implemented as a non-parametric way to quantify the similarity between data instances. A range of kernel functions are used in statistics, where the choice of kernel determines the function space used to approximate the relationship between two variables [<xref ref-type="bibr" rid="c15">15</xref>]. The most popular is the Gaussian kernel, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline2.gif"/></alternatives></inline-formula>, where &#x007C;&#x007C;<italic>x</italic><sub>1</sub> &#x2212; <italic>x</italic><sub>2</sub>&#x007C;&#x007C;<sup>2</sup> is defined as the squared Euclidean distances and <italic>&#x03C1;</italic> is an unknown bandwidth or scaling parameter. More generally, a distance-based kernel, of which the Gaussian kernel is a member, is denoted as
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn7.gif"/></alternatives></disp-formula>
where <italic>d</italic><sup>2</sup> (<italic>x</italic><sub>1</sub><italic>, x</italic><sub>2</sub>) is a distance function [<xref ref-type="bibr" rid="c10">10</xref>]. <italic>K<sub>d</sub></italic> (<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>) can be thought of as a measure of similarity between two subjects <italic>x</italic><sub>1</sub><italic>, x</italic><sub>2</sub> in terms of some multidimensional variable set <italic>Z.</italic> This similarity measure can then be incorporated into a regression framework to test to what extent variation in <italic>Z</italic> can explain variation in the phenotypic outcome, <italic>Y.</italic></p>
<p>In the case of a dichotomous outcome, assume a logistic regression framework of the semiparametric form
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn8.gif"/></alternatives></disp-formula>
where <italic>X<sub>i</sub></italic> is a matrix of covariates whose association to the dichotomous phenotypic outcome, <italic>Y<sub>i</sub>,</italic> is to be parametrically estimated, <italic>k</italic> (&#x00B7;) is a centered, smooth kernel function, and <italic>Z<sub>i</sub></italic> is a vectorized form of the RPD matrix from the previous section [<xref ref-type="bibr" rid="c15">15</xref>] [<xref ref-type="bibr" rid="c10">10</xref>]. An important feature of <italic>k</italic> (<italic>Z<sub>i</sub></italic>) is that it lies within a Reproducing Hilbert Kernel Space (RHKS). A RHKS is a function space if <italic>f</italic> and <italic>g</italic> are close in norm, &#x007C;&#x007C;<italic>f</italic> &#x2212; <italic>g</italic>&#x007C;&#x007C; <italic>&#x003C; &#x03F5;,</italic> then <italic>f</italic> and <italic>g</italic> are also pointwise close, &#x007C;&#x007C;<italic>f</italic>(<italic>x</italic>) &#x2212; <italic>g</italic>(<italic>x</italic>)&#x007C;&#x007C; <italic>&#x003C; &#x03F5;<sub>x</sub></italic> for all <italic>x.</italic> A hypothesis test can be conducted to determine whether the multidimensional variable set <italic>Z<sub>i</sub></italic> is associated with <italic>Y,</italic> controlling for <italic>X,</italic> of the form
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn9.gif"/></alternatives></disp-formula></p>
<p>[<xref ref-type="bibr" rid="c15">15</xref>] [<xref ref-type="bibr" rid="c10">10</xref>].</p>
<p>Assuming that <italic>k</italic> (&#x00B7;) lies within a RHKS, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline2a.gif"/></alternatives></inline-formula>, <italic>&#x03B2;</italic> and <italic>k</italic> (&#x00B7;) can be simultaneously estimated by maximizing the penalized log likelihood function
<disp-formula id="eqn3"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn3.gif"/></alternatives></disp-formula>
<disp-formula id="eqn5"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn5.gif"/></alternatives></disp-formula>
where <italic>&#x03BB;</italic> is a regularization parameter that reflects the trade off between model complexity and goodness of fit [<xref ref-type="bibr" rid="c16">16</xref>]. At its boundaries, <italic>&#x03BB;</italic> = 0 reflects a saturated model, while <italic>&#x03BB;</italic> = &#x221E; reduces the model to a fully parametric logistic regression model. However, it should be noted that there are two unknown parameters within <italic>&#x2113;</italic>[<italic>&#x03B2;, k</italic> (&#x00B7;)]: the regularization parameter <italic>&#x03BB;</italic> and bandwidth parameter <italic>&#x03C1;.</italic> Intuitively, <italic>&#x03BB;</italic> controls the magnitude of the unknown function <italic>k</italic> (&#x00B7;) while <italic>&#x03C1;</italic> controls the smoothness of <italic>k</italic> (&#x00B7;) [<xref ref-type="bibr" rid="c15">15</xref>]. The choice of <italic>&#x03C1;</italic> has a strong influence on the resulting estimate and we want to choose as small of a value of <italic>&#x03C1;</italic> as the data will allow. Using the representer theorem, which states that a solution to the penalized log likelihood function
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn11.gif"/></alternatives></disp-formula>
takes the form
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn12.gif"/></alternatives></disp-formula></p>
<p>[<xref ref-type="bibr" rid="c17">17</xref>]</p>
<p>then the penalized log likelihood function can be rewritten as
<disp-formula id="eqn7"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn7.gif"/></alternatives></disp-formula></p>
<p>Solving for <italic>&#x03B1;</italic> and <italic>&#x03B2;</italic> gives the closed form equations
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn13.gif"/></alternatives></disp-formula>
and then, plugging in <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline3.gif"/></alternatives></inline-formula> into <italic>k&#x002A;</italic> (<italic>Z<sub>i</sub></italic>),
<disp-formula id="eqn8"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn8.gif"/></alternatives></disp-formula></p>
<p>[<xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>However, it is possible to approach the penalized likelihood function, <italic>&#x2113;</italic>[<italic>&#x03B2;, k</italic> (&#x00B7;)], from a generalized linear mixed models (GzLMM) perspective. As logistic regression is a special case of GzLMM, the kernel estimator within the semiparametric logistic regression model parallels the penalized quasi-likelihood function from a logistic mixed model, letting <italic>&#x03C4;</italic> = 1/<italic>&#x03BB;</italic> denote the regularization parameter and <italic>&#x03C1;</italic> remaining the bandwidth parameter [<xref ref-type="bibr" rid="c15">15</xref>]. These parameters can be treated as variance components, where <italic>k</italic> (&#x00B7;) &#x007E; <italic>N</italic> (0, <italic>&#x03C4;K</italic>(<italic>&#x03C1;</italic>)) can be treated as a subject-specific random effect and the covariance matrix <italic>K</italic> (<italic>&#x03C1;</italic>) is an <italic>n</italic> &#x00D7; <italic>n</italic> kernel matrix as previously defined [<xref ref-type="bibr" rid="c16">16</xref>]. This then means that estimating <italic>&#x03B2;</italic> and <italic>k</italic> (&#x00B7;) can be done by maximizing the penalized log likelihood
<disp-formula id="eqn10"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn10.gif"/></alternatives></disp-formula>
where <italic>h</italic> = <italic>K&#x03B1;</italic> and <italic>&#x03C4;</italic> = 1/<italic>&#x03BB;</italic> [<xref ref-type="bibr" rid="c16">16</xref>]. This provides an advantage as it allows for testing of the null hypothesis <italic>H<sub>0</sub></italic>: <italic>&#x03C4;</italic> = 1/<italic>&#x03BB;</italic> = 0 without explicit specification of the basis functions of <italic>f</italic> (&#x00B7;).</p>
<p>However, under the null hypothesis, the kernel matrix <italic>K</italic> disappears, which makes <italic>&#x03C1;</italic> a nuisance parameters that is inestimable under the null hypothesis. Davies studied the issue of a nuisance parameter disappearing under the null hypothesis [<xref ref-type="bibr" rid="c18">18</xref>], and proposed a score test be used. The score statistic is treated like a nuisance parameter-indexed Gaussian process. To implement this, we must reexamine the likelihoods in <xref ref-type="disp-formula" rid="eqn7">Eq 7</xref> and <xref ref-type="disp-formula" rid="eqn10">Eq 10</xref>. As <xref ref-type="disp-formula" rid="eqn7">Eq 7</xref> is a nonlinear function of (<italic>&#x03B1;, &#x03B2;</italic>), Newton-Raphson needs to be implemented to maximize <xref ref-type="disp-formula" rid="eqn7">Eq 7</xref> in terms of (<italic>&#x03B1;, &#x03B2;</italic>). If (j) is the <italic>j<sup>th</sup></italic> iteration of the algorithm, then the (<italic>j</italic> &#x002B; 1) step solves
<disp-formula id="eqn11"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn11.gif"/></alternatives></disp-formula>
where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline4.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline5.gif"/></alternatives></inline-formula>, and <italic>h</italic><sup>(<italic>j</italic>)</sup> = <italic>K&#x03B1;</italic><sup>(<italic>j</italic>)</sup>. Also noting the <italic>&#x03B2;</italic> and <italic>k</italic> (&#x00B7;) depend on <italic>&#x03C4;</italic> and <italic>&#x03C1;,</italic> can be estimated using penalized quasi-likelihood under a logistic mixed model paradigm, then we can rewrite <xref ref-type="disp-formula" rid="eqn10">Eq 10</xref> as
<disp-formula id="eqn12"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn12.gif"/></alternatives></disp-formula>
where <italic>v =</italic> (<italic>&#x03C4;, &#x03C1;</italic>) and <italic>V</italic> = <italic>D</italic><sup>&#x2212;1</sup> &#x002B; <italic>&#x03C4;K.</italic> Then <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline6.gif"/></alternatives></inline-formula> can be solved for in the usual way [<xref ref-type="bibr" rid="c16">16</xref>]. However, if the derivative of (9) is taken with respect to <italic>&#x03C4;</italic>, then the score test for <italic>H</italic><sub>0</sub>: <italic>&#x03C4;</italic> = 1/<italic>&#x03BB;</italic> = 0 can be written as
<disp-formula id="eqn13"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn13.gif"/></alternatives></disp-formula>
where <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline7.gif"/></alternatives></inline-formula>, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline8.gif"/></alternatives></inline-formula> is the maximum likelihood estimate of <italic>&#x03B2;</italic> under the null hypothesis, <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline9.gif"/></alternatives></inline-formula>, <italic>&#x03BC;<sub>Q</sub></italic> = <italic>trace</italic>[<italic>P</italic><sub>0</sub><italic>K</italic>(<italic>&#x03C1;</italic>)], <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline10.gif"/></alternatives></inline-formula>, <italic>P</italic><sub>0</sub> = <italic>D</italic><sub>0</sub> &#x2212; <italic>D</italic><sub>0</sub><italic>X</italic> (<italic>X<sup>T</sup> D</italic><sub>0</sub><italic>X</italic>)<sup>&#x2212;1</sup> <italic>X<sup>T</sup> D</italic><sub>0</sub>, and <italic>D</italic><sub>0</sub> = <italic>diag</italic> [<italic>&#x00B5;</italic><sub>0</sub> &#x2212; (1 &#x2212; <italic>&#x00B5;</italic><sub>0</sub>)] [<xref ref-type="bibr" rid="c16">16</xref>].</p>
<p><italic>S</italic> (<italic>&#x03C1;</italic>) under the null hypothesis is an approximate, <italic>&#x03C1;</italic>-indexed Gaussian process, which allows us to apply Davies&#x2019; results [<xref ref-type="bibr" rid="c18">18</xref>] to get the upper bound for the score test&#x2019;s p-value. It can be seen that large values of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline11.gif"/></alternatives></inline-formula> would result in a rejection of <italic>H</italic><sub>0</sub>, then the upper bound of the p-value is
<disp-formula id="eqn14"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn14.gif"/></alternatives></disp-formula>
where &#x03A6;(&#x00B7;) is the normal cumulative distribution function, <italic>M</italic> is the maximum of <italic>S</italic> (<italic>&#x03C1;</italic>) over all of the searched range of <italic>p,</italic> <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline12.gif"/></alternatives></inline-formula>, <italic>L</italic> and <italic>U</italic> are the lower and upper bounds, respectively, of the search area for <italic>&#x03C1;,</italic> and <italic>&#x03C1;<sub>m</sub></italic> are the search points between <italic>L</italic> and <italic>U</italic> [<xref ref-type="bibr" rid="c18">18</xref>] [<xref ref-type="bibr" rid="c16">16</xref>]. Liu et al. suggest setting the lower and upper bounds of the <italic>&#x03C1;</italic> search to be <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline13.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline14.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c16">16</xref>].</p>
</sec>
</sec>
</sec>
<sec id="s3"><title>Results and Discussion</title>
<sec id="s3a"><title>Simulations</title>
<p>Functional connectivity matrices were simulated using the <monospace>MNS</monospace> package in <monospace>R</monospace>. This package uses the mixed neighborhood selection (MNS) algorithm, which separates a network into two components: edges that are present in the majority of the sample and those that are subject-specific [<xref ref-type="bibr" rid="c19">19</xref>]. Using the preferential attachment model proposed by Barab&#x00E1;si and Albert in 1999, a set of edges, denoted <italic>E<sup>POP</sup>,</italic> is shared across all subjects in the sample, where edge strengths are uniformly sampled [<xref ref-type="bibr" rid="c19">19</xref>]. Inter-subject variability among the edges, denoted <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline15.gif"/></alternatives></inline-formula>, are chosen according to the Erd&#x00F6;s and R&#x00E9;nyi model, where a choice of the number of elements of <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline16.gif"/></alternatives></inline-formula> determines the number of random edges and, thus, the level of inter-subject variability [<xref ref-type="bibr" rid="c19">19</xref>].</p>
<p>To simulate the data that corresponds to the functional connectivity networks, a multivariate normal distribution is utilized,
<disp-formula><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_ueqn14.gif"/></alternatives></disp-formula>
where <italic>PD</italic> (&#x00B7;) is a function that ensures a positive definite standard deviation matrix, &#x0398;<sup><italic>pop</italic></sup> denotes the population networks, and &#x0398;<sup>(<italic>i</italic>)</sup> denotes the subject-specific networks.</p>
<p>To simulate the functional connectivity data using the <monospace>MNS</monospace> package, the <monospace>gen.Network()</monospace> function was called; the parameters associated with the <monospace>gen.Network()</monospace> are detailed in the <monospace>MNS</monospace> package documentation [<xref ref-type="bibr" rid="c19">19</xref>]. The result is an <monospace>S3</monospace> object of class <monospace>MNS</monospace>. <xref ref-type="fig" rid="fig1">Fig 1</xref> below shows an example of simulated functional connectivity networks for three subjects.
<fig id="fig1" position="float" orientation="portrait" fig-type="figure"><label>Fig 1.</label><caption><title>Simulated networks for N=3 subjects under the &#x201C;cohort&#x201D; method.</title> <p>Solid lines between nodes represent population edges and dashed lines represent subject-specific edges. Red edges represent a positive association between edges while blue edges represent negative associations.</p></caption><graphic xlink:href="341495_fig1.tif"/></fig></p>
<preformat>
&#x003E; library (MNS)
&#x003E; set.seed(80045)
&#x003E; N&#x003C;-3
&#x003E; Nets&#x003C;&#x2013;gen. Network (method=&#x201D; cohort&#x201D; ,p=15,Nsub=N, sparsity=0.2,
REsize=10,REprob=0.5, REnoise=1)
&#x003E; plot (Nets, view=&#x201D; sub&#x201D;)
</preformat>
<p>For all simulations, the following settings were utilized in the <monospace>gen. Network ()</monospace> function, which seem to best represent the variability in functional connectivity networks from resting state MRI datasets: <monospace>p=90, sparsity=0.75, REsize=10, REprob=0.65, REnoise=3</monospace>.</p>
<p>However, the data simulated in the <monospace>MNS</monospace> package does not exactly match data from a resting state fMRI scan. The existence of negative correlations between brain networks has been a hotly contested debate within the neuroimaging community; the origin, interpretation, and link to the underlying structural connectivity are still unresolved issues. Because of this, the norm within the field is to zero out any negative correlations within the connectivity matrices before further analysis is performed. Other options include taking the absolute value or to normalize the correlations to be between 0 and 1, although these are far less popular. For the purposes of this manuscript, simulated datasets from the MNS package had all negative correlations either zeroed out or normalized between 0 and 1.</p>
<p>The four properties of a distance - edge importance, weight awareness, edge-&#x201C;submodularity,&#x201D; and focus awareness - were tested for the resistance perturbation distance under varying simulation models. Under the edge importance property, in weighted graphs, changes that created disconnected components should be penalized more than changes that maintain the connectivity properties of the graph. We simulated this property by breaking up the simulated connectivity matrix into four, equally-sized quadrants and then zeroing out all non-zero cells within the off-diagonal (quadrants I and III) to create two disconnected components. Then, the same number of components were randomly zeroed out to create a comparable &#x201C;random&#x201D; graph. Pairwise RPDs were plotted for 1000 iterations in <xref ref-type="fig" rid="fig2">Fig 2</xref> and summary statistics of the RPDs in <xref ref-type="table" rid="tbl1">Table 1</xref>, both below.
<table-wrap id="tbl1" position="float" orientation="portrait"><label>Table 1.</label><caption><title>Summary statistics of edge importance property simulations</title></caption><graphic xlink:href="341495_tbl1.tif"/></table-wrap>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure"><label>Fig 2.</label><caption><title>Edge importance property.</title> <p>1000 iterations under targeted deletions resulting in disconnected components (top) and equally-numbered but random deletions (bottom)</p></caption><graphic xlink:href="341495_fig2.tif"/></fig></p>
<p>Under the weight awareness property, in weighted graphs, the larger the weight of the removed edge, the greater the impact on the distance. We considered iteratively zeroing out the minimum or maximum non-zero correlation from a simulated ten node connectivity matrix. Pairwise RPDs were plotted for 1000 iterations in <xref ref-type="fig" rid="fig3">Fig 3</xref> and summary statistics of the RPDs in <xref ref-type="table" rid="tbl2">Table 2</xref>, both below.
<table-wrap id="tbl2" position="float" orientation="portrait"><label>Table 2.</label><caption><title>Summary statistics of weight awareness property simulations</title></caption><graphic xlink:href="341495_tbl2.tif"/></table-wrap>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure"><label>Fig 3.</label><caption><title>Weight awareness property.</title> <p>1000 iterations under minimum (top) and maxiumum (bottom) correlation paradigms</p></caption><graphic xlink:href="341495_fig3.tif"/></fig></p>
<p>Under the edge-&#x201C;submodularity&#x201D; property, in weighted graphs, a specific change is more important in a graph with few edges than in a much denser, but equally sized, graph. For ten node graphs, the maximum non-zero correlation was systematically removed from each iteratively-simulated connectivity matrix. Within the <monospace>gen.Network()</monospace> function, sparsity parameters of 0.45 (for a sparse graph) and 0.95 (for a dense graph). Pairwise RPDs were plotted for 1000 iterations in <xref ref-type="fig" rid="fig4">Fig 4</xref> and summary statistics of the RPDs in <xref ref-type="table" rid="tbl3">Table 3</xref>, both below.
<table-wrap id="tbl3" position="float" orientation="portrait"><label>Table 3.</label><caption><title>Summary statistics of edge-&#x201C;submodularity&#x201D; property simulations</title></caption><graphic xlink:href="341495_tbl3.tif"/></table-wrap>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure"><label>Fig 4.</label><caption><title>Edge-&#x201C;submodularity&#x201D; property.</title> <p>1000 iterations under sparse (top) and dense (bottom) graph paradigms</p></caption><graphic xlink:href="341495_fig4.tif"/></fig></p>
<p>Finally, under the focus awareness property, in weighted graphs, random changes in graphs are less important than targeted changes of the same extent. Similar to Koutra et al. [<xref ref-type="bibr" rid="c14">14</xref>], for ten node graphs, targeted changes were made by deleting all edges from a randomly chosen node while random changes were made by randomly removing the same number of edges from the whole graph. Pairwise RPDs were plotted for 1000 iterations in <xref ref-type="fig" rid="fig5">Fig 5</xref> and summary statistics of the RPDs in <xref ref-type="table" rid="tbl4">Table 4</xref>, both below. As these figures and tables show, the Koutra et al. properties are all satisfied under the simulated constraints of fMRI data.
<table-wrap id="tbl4" position="float" orientation="portrait"><label>Table 4.</label><caption><title>Summary statistics of focus awareness property simulations</title></caption><graphic xlink:href="341495_tbl4.tif"/></table-wrap>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure"><label>Fig 5.</label><caption><title>Focus awareness property.</title> <p>1000 iterations under targeted (top) and random (bottom) change paradigms</p></caption><graphic xlink:href="341495_fig5.tif"/></fig></p>
<p>Next, to analyze the robustness of the kernel-based score test described, several simulations were conducted. These simulations were split between whether two or one groups of functional connectivity matrices were generated; a simulation under a one generation process presumes that the null hypothesis of all subjects come from the same population is true while a two generation process presumes that the null hypothesis is false and subjects come from two distinct populations. To simplify the analyses for these simulations, no covariates were generated.</p>
<p>We next conducted a series of simulation studies to evaluate the performance of the kernel-based score test under the hypothesis test of <italic>H</italic><sub>0</sub>: <italic>k</italic> (&#x00B7;) = 0 versus <italic>H<sub>A</sub></italic>: <italic>k</italic> (&#x00B7;) &#x2260; 0. As there is no closed-form solution for the test statistic&#x2019;s accompanying p-value, power and Type I error were calculated using simulated datasets. For the power simulation, 100 different datasets were produced, ten from the &#x201C;control&#x201D; population, ten from the &#x201C;patient&#x201D; population, and the remaining 80 from a third &#x201C;noise&#x201D; population. Each of these populations were simulated under different <monospace>gen.Network()</monospace> function calls in order to prevent common preferential attachment model parameters. This third population was included to mimic the noisy nature of fMRI data; even among two groups that have been shown to have significant differences in their fMRI data, the vast majority of the graphs are indistinguishable because of the universal way the human brain communicates with itself. The noise population was distributed between the &#x201C;control&#x201D; and &#x201C;patient&#x201D; populations such that the final sample sizes were 55 in the &#x201C;control&#x201D; population and 45 in the &#x201C;patient&#x201D; population. Each simulated connectivity matrix was generated with the following parameters: <monospace>p=90, sparsity=0.75, REsize=10, REprob=0.65, and REnoise=3</monospace>. Bounds of the <italic>&#x03C1;</italic> search were set based on the suggestion from Liu et al. [<xref ref-type="bibr" rid="c16">16</xref>]. An indicator function was used to determine whether each simulation&#x2019;s resulting p-value was greater than <italic>&#x03B1;</italic> = 0.05, then the ultimate power of the kernel score test was calculated using <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline17.gif"/></alternatives></inline-formula>, where <italic>n</italic> is the number of repetitions. After 1000 iterations, the empirical power of the kernel-based score test was 0.945. Similarly, for the test statistic&#x2019;s Type I error rate, all 100 simulated samples came from a single generation process with the same parameters as the power simulation and bounds of the <italic>&#x03C1;</italic> search and the final Type I error was calculated using <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline18.gif"/></alternatives></inline-formula>, where <italic>n</italic> is the number of repetitions. After 1000 iterations, the empirical Type I error rate of the kernel-based score test was 0.0496. Our simulations show that the empirically-calculated Type I error is very close to the nominal value of 0.05 while the power of our score test has high power to detect true differences in a dataset.</p>
<p>We also conducted a simulation under a two generation process to understand the impact of how the allocation of the &#x201C;noise&#x2019;&#x201D; population to the &#x201C;control&#x201D; and &#x201C;patient&#x201D; populations affected the kernel-based score test&#x2019;s p-values. In a very similar manner to the power simulation, three datasets were produced. However, the allocation of the simulated noise population to the control and patient populations was varied; the percentage of the noise population allocated to the control population varied along (5&#x0025;,95&#x0025;) by increments of 5&#x0025;. One hundred iterations occurred at each noise allocation. Any iteration that resulted in a p-value greater than 0.05 was considered a false negative as the simulation was set up in such a way that the underlying truth was that the &#x201C;control&#x201D; and &#x201C;patient&#x201D; populations were different from one another. The results of the simulation are plotted in <xref ref-type="fig" rid="fig6">Fig 6</xref>, below. The highest Type II errors occurred between noise splits where 40&#x0025; and 55&#x0025; of the noise was allocated to the control population; this is not surprising as a noise allocation that was nearly evenly split between the two groups would make their average graph look exceedingly similar.
<fig id="fig6" position="float" orientation="portrait" fig-type="figure"><label>Fig 6.</label><caption><title>P-values under varying noise population allocations under a two generation simulation process.</title> <p>At each noise allocation, 100 iterations were conducted. The red dashed line is at the nominal p-value of 0.05. Any point above this red line is a false negative.</p></caption><graphic xlink:href="341495_fig6.tif"/></fig></p>
<p>Similarly, we conducted a simulation under a one generation process to understand how splitting the 100 connectivity matrices between &#x201C;control&#x201D; and &#x201C;patient&#x201D; populations affected the p-values of the kernel-based score test. Like the Type I error simulation, only one dataset was produced. However, how this dataset was split between the two populations was varied; the number of connectivity matrices allocated to the &#x201C;control&#x201D; population varied from five to 95, increasing in increments of one at each iteration. Any iteration that resulted in a p-value less than 0.05 was considered a false positive as the simulation was set up in a way that the underlying truth was that there was no significant difference between &#x201C;controls&#x201D; and &#x201C;patients.&#x201D; The results of the simulation are plotted in <xref ref-type="fig" rid="fig7">Fig 7</xref>, below. The total Type I error across all allocations was 0.05, on par with the empirical Type I error calculated.
<fig id="fig7" position="float" orientation="portrait" fig-type="figure"><label>Fig 7.</label><caption><title>P-values under varying noise population allocations under a one generation simulation process.</title> <p>Allocation of the 100 generated connectivity matrices varied from 5:95 to 95:5, increasing in increments of one. The red dashed line is at the nominal p-value of 0.05. Any point below this red line is a false positive.</p></caption><graphic xlink:href="341495_fig7.tif"/></fig></p>
<p>Finally, the lower and upper bounds of the grid search for the <italic>p</italic> parameter of the kernel were varied under both one- and two-generation processes. While Liu et al. [<xref ref-type="bibr" rid="c16">16</xref>] provides a justification for these bounds, because our kernel-based score test is more complex (i.e., it involves semi-parametric estimation of phenotypic parameters and utilizes a different kernel), we wanted to test the robustness of the test under differing <italic>p</italic> grid searches. A lower value of 0.00001 and upper value of 0.01, each iterative multiplied by 10<italic><sup>i</sup></italic> for <italic>i</italic> = 0, <italic>&#x2026;</italic>, 10 were multiplied by <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline19.gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_inline20.gif"/></alternatives></inline-formula>, respectively. A total of 100 simulations were conducted under each of the one- and two-generation processes and p-values were plotted. Any p-value that was less than 0.05 under the one-generation process was considered a Type I error while any p-value over 0.05 in the two-generation process was considered a Type II error. <xref ref-type="fig" rid="fig8">Fig 8</xref>, below, shows a scatterplot of these simulations. These simulations show that, under a one-generation process, the false positive rate varies according to the boundaries chosen but, overall, is slightly above the empirical Type I error rate at 0.06. Interestingly, for a two-generation process, the boundaries of the <italic>&#x03C1;</italic> grid search are highly robust, with the Type II error at 0.00.
<fig id="fig8" position="float" orientation="portrait" fig-type="figure"><label>Fig 8.</label><caption><title>P-values under varying boundaries of the <italic>&#x03C1;</italic> parameter.</title> <p>For each of the one generation (top) and two generation (bottom) processes, the minimum and maximum sums of squares from the RPD matrix were multiplied by 0.00001 &#x00D7; 10<italic><sup>i</sup></italic> and 0.01 &#x00D7; 10<italic><sup>i</sup></italic> for <italic>i</italic> = 0,1, <italic>&#x2026;</italic>, 10, respectively. Ten iterations at each value of <italic>i</italic> were calculated. Under the one-generation process, any p-value less than the red dashed line - the nominal p-value of 0.05 - is a false positive. Under the two generation process, any p-value greater than the red dashed line is a false negative.</p></caption><graphic xlink:href="341495_fig8.tif"/></fig></p>
</sec>
</sec>
<sec id="s3b"><title>COBRE Dataset</title>
<p>The Center for Biomedical Research Excellence through the Mind Research Network for Neurodiagnostic Discovery (MRN) is one of many National Institute of Health (NIH)-funded institutions that focus on the development of &#x201C;new, disease-specific research centers or augment[ing] the capability of existing centers [<xref ref-type="bibr" rid="c20">20</xref>].&#x201D; The MRN&#x2019;s focus is on the neural mechanisms of schizophrenia, with the unifying theme being that the condition is characterized by &#x201C;structural, functional, and effective connectivity between cortical and subcortical brain regions, producing abnormalities in the integration of information across distributed brain circuits [<xref ref-type="bibr" rid="c21">21</xref>].&#x201D; Previous studies [<xref ref-type="bibr" rid="c22">22</xref>] [<xref ref-type="bibr" rid="c23">23</xref>] of this dataset have shown significant differences between schizophrenia and control patients in the hippocampus and default mode network (a large scale brain network comprised of medial prefrontal cortex, posterior cingulate cortex, and inferior parietal lobule) with more subtle differences in the temporal and frontal networks. However, neither of these studies approached their analysis from a graph theoretic perspective, choosing instead to perform versions of a mass univariate analysis.</p>
<p>As its contribution to the 1000 Functional Connectomes Project, the MRN contributed raw anatomical and functional MR data from 72 patients with diagnosed schizophrenia and 75 healthy controls, although two control patients had to be excluded due to disenrollment [<xref ref-type="bibr" rid="c24">24</xref>]. A multi-echo, magnetization prepared rapid gradient echo (MPRAGE) sequence was used to acquire the anatomical information on each subject, with the following parameters: TR/TE/TI=2530/[1.64, 3.5, 5.36, 7.22, 9.08]/900ms; flip angle=7&#x00B0;; FOV=256&#x00D7;256mm; slab thickness=176mm; matrix=256&#x00D7;256&#x00D7;176; voxel size=1&#x00D7;1&#x00D7;1mm; number of echoes=5; pixel bandwidth=650Hz, total scan time=6 minutes [<xref ref-type="bibr" rid="c24">24</xref>]. Resting state functional MR data was acquired using a single-shot, full k-space, echo planar imaging (EPI) with ramp sampling correction using the intercommissural line as the reference and the following parameters: TR=2 seconds; TE=29ms; matrix size=64&#x00D7;64; 32 slices; voxel size=3&#x00D7;3&#x00D7;4mm [<xref ref-type="bibr" rid="c24">24</xref>]. In addition to this imaging data, the MRN also provided phenotypic information on each subject, including age, gender, handedness, and diagnostic information, when applicable. <xref ref-type="table" rid="tbl5">Table 5</xref> provides a summary of the phenotypic information on controls and patients.
<table-wrap id="tbl5" position="float" orientation="portrait"><label>Table 5.</label><caption><title>COBRE Dataset Subject Demographics</title></caption><graphic xlink:href="341495_tbl5.tif"/></table-wrap></p>
<p>An automated pre-processing and denoising pipeline was implemented with the CONN software package within MatLab [<xref ref-type="bibr" rid="c25">25</xref>]. Within this pipeline, the first four volumes were discarded to ensure T1 equilibrium effects, each subject&#x2019;s images were realigned to the first volume, but no slice-timing correction was applied as images were acquired in a descending manner. Data were spatially normalized to the Montreal Neurological Institute (MNI) space and smoothed using a Gaussian kernel with a full-width at half-maximum of 8mm. During the denoising process, two different sources of possible confounds were regressed out: (1) BOLD signal from white matter and cerebrospinal fluid (CSF); and (2) realignment parameters (6 parameters). Correlation matrices were then extracted from CONN following a first-level ROI-to-ROI analysis. A hybrid physical atlas was used, where the FSL Harvard-Oxford atlas was used to parcellate the cortical and subcortical areas and the Automated Anatomical Labeling (AAL) atlas [<xref ref-type="bibr" rid="c26">26</xref>] was used to to parcellate the cerebellar areas; this resulted in a physical atlas of 132 regions. Weighted networks were extracted from the <monospace>&#x002A;.mat</monospace> files using the <monospace>R.matlab</monospace> package. As the matrices contained Fisher&#x2019;s transformed correlation coefficients, the hyperbolic tangent function was applied to all correlations then negative correlations were set to zero.</p>
<p>Using the entire dataset, which included 72 schizophrenia and and 73 control patients following the pre-processing and denoising procedures, the outcome was a binary classification variable of schizophrenia diagnosis. The regression parameters for the phenotypic covariates of age, sex, and handedness were parametrically estimated while the RPD matrix was non-parametrically estimated. Specifically, we considered the following semiparametric logistic model:
<disp-formula id="eqn15"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn15.gif"/></alternatives></disp-formula>
where <italic>k</italic> (&#x00B7;) is a nonparametric kernel distance function of the 132 &#x00D7; 132 RPD matrix. Details of the estimation procedure can be found in the Methods section. Additionally, we also considered a simpler, fully non-parametric logistic model, which does not include any of the phenotypic covariates:
<disp-formula id="eqn16"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="341495_eqn16.gif"/></alternatives></disp-formula></p>
<p>This was done to test whether the phenotypic covariates were confounders in the association between the RPD matrix and binary schizophrenia classification.</p>
<p>The same two models (semiparametric and fully non-parametric) were fit to the full dataset, but for which all negative correlations within the subject-level fMRI connectivity matrices left as is. This was done to determine whether there was a significant loss of information by following the neuroimaging standard of zeroing out any negative correlation between regions of interest. Recent articles [<xref ref-type="bibr" rid="c27">27</xref>] [<xref ref-type="bibr" rid="c28">28</xref>] have pointed to a potentially significant physiological role of negative correlations within fMRI. Specifically, Parente et al. notes that, while these negatively correlated brain networks still lack a well-defined biological explanation, they appear to be have an association with the alterations in brain function in people diagnosed with schizophrenia [<xref ref-type="bibr" rid="c27">27</xref>].</p>
<p>The results of these analyses are present in <xref ref-type="table" rid="tbl6">Table 6</xref>, below.
<table-wrap id="tbl6" position="float" orientation="portrait"><label>Table 6.</label><caption><title>Analysis of full COBRE dataset</title></caption><graphic xlink:href="341495_tbl6.tif"/></table-wrap></p>
<p><xref ref-type="table" rid="tbl6">Table 6</xref> shows that only under the fully non-parametric paradigm when the negative correlations were zeroed out did we reject the null hypothesis of <italic>H</italic><sub>0</sub>: <italic>k</italic> (<italic>&#x00B7;</italic>) = 0. Our hypothesis that keeping all negative correlations within the dataset would preserve more information was not confirmed as both the semiparametric and fully non-parametric models were not significant at the <italic>&#x03B1;</italic> = 0.05 level. Heat maps of the average connectivity matrix for control versus schizophrenia patients under both paradigms can be seen in <xref ref-type="fig" rid="fig9">Fig 9</xref>, below. These heat maps show exceedingly similar patterns of average connectivity between the two groups, which may be the reason why the RPD-based score test was unable to find a significant difference in most of the scenarios we considered.
<fig id="fig9" position="float" orientation="portrait" fig-type="figure"><label>Fig 9.</label><caption><title>Correlation heat maps full COBRE-I dataset.</title> <p>Correlation heat maps of control and schizophrenia subjects under zeroing out negative correlations (top row) and normalizing all correlations (bottom row).</p></caption><graphic xlink:href="341495_fig9.tif"/></fig></p>
<p>A subset of the entire COBRE dataset, which included all schizophrenia subjects who had an diagnosis of paranoid schizophrenia (ICD-9 code of 295.3) and an equal number of randomly selected control subjects, was analyzed. To ensure comparable groups, frequency matching for handedness, sex, and age category (18 &#x2013; 25, 26 &#x2013; 35, 36 &#x2013; 45, 46&#x002B;) was conducted. Because schizophrenia is such a heterogeneous condition, we believed that by restricting our sample of cases to only those with the same sub-diagnosis, we would be removing some of the noise present within the dataset exogenous to the normal variation in fMRI connectivity. As with the full dataset, four different regression models were fit to the data, the results of which are summarized in <xref ref-type="table" rid="tbl7">Table 7</xref>, below.
<table-wrap id="tbl7" position="float" orientation="portrait"><label>Table 7.</label><caption><title>Analysis of COBRE dataset - Paranoid Schizophrenia Cases Only</title></caption><graphic xlink:href="341495_tbl7.tif"/></table-wrap></p>
<p><xref ref-type="table" rid="tbl7">Table 7</xref> shows that for all four conditions, we fail to reject the null hypothesis of <italic>H</italic><sub>0</sub>: <italic>k</italic> (<italic>&#x00B7;</italic>) = 0. Heat maps of the average connectivity matrix for the randomly-selected control versus paranoid schizophrenia patients under both paradigms can be seen in <xref ref-type="fig" rid="fig10">Fig 10</xref>, below. As with the full COBRE dataset, the heat maps do not show differences in the totality of functional connectivity. However, in both cases, the schizophrenia patients appear to have lower correlations between regions of interest than the control patients.
<fig id="fig10" position="float" orientation="portrait" fig-type="figure"><label>Fig 10.</label><caption><title>Correlation heat maps paranoid schizophrenia COBRE-I dataset.</title> <p>Correlation heat maps of control and schizophrenia subjects for only the paranoid schizophrenia subset under zeroing out negative correlations (top row) and normalizing all correlations (bottom row).</p></caption><graphic xlink:href="341495_fig10.tif"/></fig></p>
</sec>
<sec id="s4"><title>Conclusion</title>
<p>In this paper, we applied a concept from the electrical engineering field, the resistance perturbation distance, to a kernel logistic regression framework, where the outcome of interest is a binary classifier, phenotypic covariates are modeled parametrically, and the distance metric is modeled nonparametrically using a kernel machine method. The RPD is computationally efficient and does not result in a loss of information on either a local or global scale, unlike many other graph theoretic measures. The application of a kernel logistic regression allows for the RPD to be modeled without making any assumption as to the parametric form of its association with the binary classifier. Because our model is semi-parametric, we are able to control for potential phenotypic confounders within a parametric framework, allowing for ease of parameter estimate interpretation, should they be desired. Further, the kernel regression framework could be extended to account for repeated measures, allowing for RPD metrics to be calculated at multiple points during each subject&#x2019;s fMRI scan time.</p>
<p>There are several limitations that affect our approach. First, while our model proved to have high power, a low Type I error rate, and is robust to varying study design and searchable spaces of the score test statistics, only one significant association was found between the RPD matrix and the binary classifier in the full COBRE-I dataset under the fully non-parametric score test with negative correlations zeroed out. However, when accounting for multiple comparisons, this association is no longer significant. The difference between simulation and real datasets could be due to a variety of factors, either working in isolation or compounded on one another. Several recently-published studies [<xref ref-type="bibr" rid="c8">8</xref>] [<xref ref-type="bibr" rid="c29">29</xref>] [<xref ref-type="bibr" rid="c30">30</xref>] have noted that choice of pre-processing pipeline can impact the results of an inferential analysis involving graph theoretic measures, especially in resting state fMRI. We have not studied the impact of different parameters within the same pre-processing pipeline nor the impact of an entirely different manner of pre-processing on the RPD. As well, it was noted earlier that, while the overall patterns of connectivity within the heat maps appear to be similar between cases and controls, the overall magnitude of the correlations may differ; the RPD is not sensitive to a global difference in the magnitude of edge weights as it is scale invariant. Finally, while no self loops allows for desirable mathematical properties of simple graphs, its absence is significant biologically. Network function is maintained by biologic feedback loops, which cannot be modeled with the current graph theory framework. These feedback loops could have particular importance in the distinction of fMRI connectivity patterns between controls and those with schizophrenia.</p>
<p>A future direction within this modeling approach could be to use the RPD and kernel logistic regression within a more confined brain atlas. The hybrid atlas contains 132 parcellated regions covering the entirely of the brain. However, it may be that restricting this methodology to pre-specified regions of interest may bear results more comparable to that seen in simulation. Additionally, as the RPD is scale invariant, relative, rather than absolute, differences in connectivity may be more informative for this algorithm. Specifically, if the total sample average connectivity between two nodes is some value <italic>p</italic> satisfying &#x2212;1 <italic>&#x003C; p &#x003C;</italic> 1 then looking at differences in individual deviation values from this average, rather than the absolute differences, may help circumvent the scale invariance of the distance metric. Finally, an extension to take into account repeated measures could help provide an analytical framework for analyzing resting state fMRI as rs-fMRI connectivity is known to not be consistent across the entirely of the scan time.</p>
</sec>
</body>
<back>
<ack><title>Acknowledgments</title>
<p>We thank Michael Regner, M.D. for his insight into the use and troubleshooting of the CONN toolbox within MatLab as well as providing comments that greatly improved the manuscript.</p></ack>
<ref-list><title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Kwong</surname> <given-names>KK</given-names></string-name>, <string-name><surname>Belliveau</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Chesler</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>IE</given-names></string-name>, <string-name><surname>Weisskoff</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Poncelet</surname> <given-names>BP</given-names></string-name>, <etal>et al.</etal> <article-title>Dynamic magnetic resonance imaging of human brain activity during primary sensory stimulation</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>1992</year> <month>Jun</month>;<volume>89</volume>(<issue>12</issue>):<fpage>5675</fpage>&#x2013;<lpage>5679</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Belliveau</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Kennedy</surname> <given-names>DN</given-names></string-name>, <string-name><surname>McKinstry</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Buchbinder</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Weisskoff</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>MS</given-names></string-name>, <etal>et al.</etal> <article-title>Functional mapping of the human visual cortex by magnetic resonance imaging</article-title>. <source>Science</source>. <year>1991</year> <month>Nov</month>; <volume>254</volume>(<issue>5032</issue>):<fpage>716</fpage>&#x2013;<lpage>719</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1948051</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="website"><source>EEG and FMRI Papers by the Numbers&#x007C; Neuroscience I Human Brain Diversity Project</source>;. Available from: <ext-link ext-link-type="uri" xlink:href="http://sapienlabs.co/500000-human-neuroscience-papers/">http://sapienlabs.co/500000-human-neuroscience-papers/</ext-link>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Ogawa</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Kay</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Tank</surname> <given-names>DW.</given-names></string-name> <article-title>Brain magnetic resonance imaging with contrast dependent on blood oxygenation</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>1990</year> <month>Dec</month>;<volume>87</volume>(<issue>24</issue>):<fpage>9868</fpage>&#x2013;<lpage>9872</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Arthurs</surname> <given-names>OJ</given-names></string-name>, <string-name><surname>Boniface</surname> <given-names>S</given-names></string-name>. <article-title>How well do we understand the neural origins of the fMRI BOLD signal?</article-title> <source>Trends in Neurosciences</source>. <year>2002</year> <month>Jan</month>;<volume>25</volume>(<issue>1</issue>):<fpage>27</fpage>&#x2013;<lpage>31</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0166-2236 (00) 01995-0</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Lindquist</surname> <given-names>MA</given-names></string-name>. <article-title>The Statistical Analysis of fMRI Data. Statistical Science</article-title>. <year>2008</year> <source>Nov</source>;<volume>23</volume>(<issue>4</issue>):<fpage>439</fpage>&#x2013;<lpage>464</lpage>. doi:<pub-id pub-id-type="doi">10.1214/09-STS282</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Gur</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Gur</surname> <given-names>RC.</given-names></string-name> <article-title>Functional magnetic resonance imaging in schizophrenia</article-title>. <source>Dialogues in Clinical Neuroscience</source>. <year>2010</year> <month>Sep</month>;<volume>12</volume>(<issue>3</issue>):<fpage>333</fpage>&#x2013;<lpage>343</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Argyelan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ikuta</surname> <given-names>T</given-names></string-name>, <string-name><surname>DeRosse</surname> <given-names>P</given-names></string-name>, <string-name><surname>Braga</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Burdick</surname> <given-names>KE</given-names></string-name>, <string-name><surname>John</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>Resting-State fMRI Connectivity Impairment in Schizophrenia and Bipolar Disorder</article-title>. <source>Shizophrenia Bulletin.</source> <year>2014</year> <month>Jan</month>;<volume>40</volume>(<issue>1</issue>):<fpage>100</fpage>&#x2013;<lpage>110</lpage>. doi:<pub-id pub-id-type="doi">10.1093/schbul/sbt092</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Brown</surname> <given-names>GG</given-names></string-name>, <string-name><surname>Perthen</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>TT</given-names></string-name>, <string-name><surname>Buxton</surname> <given-names>RB.</given-names></string-name> <article-title>A Primer on Functional Magnetic Resonance Imaging</article-title>. <source>Neuropsychology Review</source>. <year>2007</year> <month>Jun</month>;<volume>17</volume>(<issue>2</issue>):<fpage>107</fpage>&#x2013;<lpage>125</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s11065-007-9028-8</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Zhan</surname> <given-names>X</given-names></string-name>, <string-name><surname>Patterson</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Ghosh</surname> <given-names>D.</given-names></string-name> <article-title>Kernel approaches for differential expression analysis of mass spectrometry-based metabolomics data</article-title>. <source>BMC bioinformatics</source>. <year>2015</year> <month>Mar</month>;<volume>16</volume>:<fpage>77</fpage>. doi:<pub-id pub-id-type="doi">10.1186/s12859-015-0506-3</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Bullmore</surname> <given-names>E</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name> <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2009</year> <month>Mar</month>;<volume>10</volume>(<issue>3</issue>):<fpage>186</fpage>&#x2013;<lpage>198</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn2575</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Monnig</surname> <given-names>ND</given-names></string-name>, <string-name><surname>Meyer</surname> <given-names>FG</given-names></string-name>. <article-title>The Resistance Perturbation Distance: A Metric for the Analysis of Dynamic Networks</article-title>. <source>arXiv:160501091 [physics]</source>. <year>2016</year> <month>May</month>;ArXiv: 1605.01091. Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1605.01091">http://arxiv.org/abs/1605.01091</ext-link>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name> <article-title>Structure and function of complex brain networks</article-title>. <source>Dialogues in Clinical Neuroscience</source>. <year>2013</year> <month>Sep</month>;<volume>15</volume>(<issue>3</issue>):<fpage>247</fpage>&#x2013;<lpage>262</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Koutra</surname> <given-names>D</given-names></string-name>, <string-name><surname>Vogelstein</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Faloutsos</surname> <given-names>C</given-names></string-name>. <article-title>DELTACON: A Principled Massive-Graph Similarity Function</article-title>. <source>arXiv:13044657 [physics]</source>. <year>2013</year> <month>Apr</month>;ArXiv: 1304.4657. Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1304.4657">http://arxiv.org/abs/1304.4657</ext-link>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Liu</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>X</given-names></string-name>, <string-name><surname>Ghosh</surname> <given-names>D</given-names></string-name>. <source>Semiparametric Regression of Multidimensional Genetic Pathway Data: Least-Squares Kernel Machines and Linear Mixed Models</source>;<volume>63</volume>(<issue>4</issue>):<fpage>1079</fpage>&#x2013;<lpage>1088</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1541-0420.2007.00799.x</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Liu</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ghosh</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>X.</given-names></string-name> <article-title>Estimation and testing for the effect of a genetic pathway on a disease outcome using logistic kernel machine regression via logistic mixed models</article-title>. <source>Biometrics</source>. <year>2007</year> <month>Dec</month>;<volume>9</volume>:<fpage>292</fpage>. doi:<pub-id pub-id-type="doi">10.1186/1471-2105-9-292</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Kimeldorf</surname>, <given-names>George</given-names></string-name>, <string-name><surname>Wahba</surname>, <given-names>Grace</given-names></string-name>. <article-title>Some Results on Tchebycheffian Spline Functions</article-title>. <source>Journal of Mathematical Analysis and Applications</source>. <year>1971</year> <month>Jan</month>;<volume>33</volume>(<issue>1</issue>):<fpage>82</fpage>&#x2013;<lpage>95</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Davies</surname> <given-names>RB.</given-names></string-name> <article-title>Hypothesis Testing when a Nuisance Parameter is Present Only Under the Alternatives</article-title>. <source>Biometrika</source>. <year>1987</year>;<volume>74</volume>(<issue>1</issue>):<fpage>33</fpage>&#x2013;<lpage>43</lpage>. doi:<pub-id pub-id-type="doi">10.2307/2336019</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Monti</surname>, <given-names>Ricardo Pio</given-names></string-name>, <string-name><surname>Anagnostopoulos</surname>, <given-names>Christoforos</given-names></string-name>, <string-name><surname>Montana</surname>, <given-names>Giovanni</given-names></string-name>. <article-title>Estimating and simulating multiple related functional connectivity networks via the MNS Package</article-title>. <source>CRAN</source>. <year>2015</year> <month>Dec</month>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="website"><source>Centers of Biomedical Research Excellence - National Institute of General Medical Sciences</source>;. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nigms.nih.gov/Research/CRCB/IDeA/Pages/COBRE.aspx">https://www.nigms.nih.gov/Research/CRCB/IDeA/Pages/COBRE.aspx</ext-link>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="website"><source>Center for Biomedical Research Excellence</source>;. Available from: <ext-link ext-link-type="uri" xlink:href="http://cobre.mrn.org/phase1/index.html">http://cobre.mrn.org/phase1/index.html</ext-link>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Calhoun</surname> <given-names>VD</given-names></string-name>, <string-name><surname>Sui</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kiehl</surname> <given-names>K</given-names></string-name>, <string-name><surname>Turner</surname> <given-names>J</given-names></string-name>, <string-name><surname>Allen</surname> <given-names>E</given-names></string-name>, <string-name><surname>Pearlson</surname> <given-names>G.</given-names></string-name> <article-title>Exploring the Psychosis Functional Connectome: Aberrant Intrinsic Networks in Schizophrenia and Bipolar Disorder</article-title>. <source>Frontiers in Psychiatry</source>. <year>2012</year> <month>Jan</month>;<volume>2</volume>. doi:<pub-id pub-id-type="doi">10.3389 /fpsyt. 2011.00075</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Hanlon</surname> <given-names>FM</given-names></string-name>, <string-name><surname>Houck</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Pyeatt</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Lundy</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Euler</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Weisend</surname> <given-names>MP</given-names></string-name>, <etal>et al.</etal> <article-title>Bilateral Hippocampal Dysfunction in Schizophrenia</article-title>. <source>NeuroImage</source>. <year>2011</year> <month>Oct</month>;<volume>58</volume>(<issue>4</issue>):<fpage>1158</fpage>&#x2013;<lpage>1168</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.06.091</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="website"><source>COBRE</source>;. Available from: <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html">http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html</ext-link>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Whitfield-Gabrieli</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nieto-Castanon</surname> <given-names>A.</given-names></string-name> <article-title>Conn: a functional connectivity toolbox for correlated and anticorrelated brain networks</article-title>. <source>Brain Connectivity</source>. <year>2012</year>;<volume>2</volume>(<issue>3</issue>):<fpage>125</fpage>&#x2013;<lpage>141</lpage>. doi:<pub-id pub-id-type="doi">10.1089/brain.2012.0073</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Tzourio-Mazoyer</surname> <given-names>N</given-names></string-name>, <string-name><surname>Landeau</surname> <given-names>B</given-names></string-name>, <string-name><surname>Papathanassiou</surname> <given-names>D</given-names></string-name>, <string-name><surname>Crivello</surname> <given-names>F</given-names></string-name>, <string-name><surname>Etard</surname> <given-names>O</given-names></string-name>, <string-name><surname>Delcroix</surname> <given-names>N</given-names></string-name>, <etal>et al.</etal> <article-title>Automated Anatomical Labeling of Activations in SPM Using a Macroscopic Anatomical Parcellation of the MNI MRI Single-Subject Brain</article-title>. <source>NeuroImage</source>. <year>2002</year> <month>Jan</month>;<volume>15</volume>(<issue>1</issue>):<fpage>273</fpage>&#x2013;<lpage>289</lpage>. doi:<pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Parente</surname> <given-names>F</given-names></string-name>, <string-name><surname>Frascarelli</surname> <given-names>M</given-names></string-name>, <string-name><surname>Mirigliani</surname> <given-names>A</given-names></string-name>, <string-name><surname>Di Fabio</surname> <given-names>F</given-names></string-name>, <string-name><surname>Biondi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Colosimo</surname> <given-names>A.</given-names></string-name> <article-title>Negative functional brain networks</article-title>. <source>Brain Imaging and Behavior</source>. <year>2017</year> <month>Mar</month>. doi:<pub-id pub-id-type="doi">10.1007/s11682-017-9715-x</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Zhan</surname> <given-names>Liang</given-names></string-name>, <string-name><surname>Jenkins</surname> <given-names>Lisanne M</given-names></string-name>, <string-name><surname>Wolfson</surname> <given-names>Ouri E</given-names></string-name>, <string-name><surname>Gad</surname> <given-names>Elkarim Johnson Jonaris</given-names></string-name>, <string-name><surname>Nocito</surname> <given-names>Kevin</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>Paul M</given-names></string-name>, <etal>et al.</etal> <article-title>The significance of negative correlations in brain connectivity</article-title>. <source>Neurology</source>. <year>2017</year> <month>Jul</month>;<volume>525</volume>(<issue>15</issue>):<fpage>3251</fpage>&#x2013;<lpage>3265</lpage>. doi:<pub-id pub-id-type="doi">10.1002/cne.24274</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Gargouri</surname> <given-names>F</given-names></string-name>, <string-name><surname>Kallel</surname> <given-names>F</given-names></string-name>, <string-name><surname>Delphine</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ben Hamida</surname> <given-names>A</given-names></string-name>, <string-name><surname>Leh&#x00E9;ricy</surname> <given-names>S</given-names></string-name>, <string-name><surname>Valabregue</surname> <given-names>R.</given-names></string-name> <article-title>The Influence of Preprocessing Steps on Graph Theory Measures Derived from Resting State fMRI</article-title>. <source>Frontiers in Computational Neuroscience.</source> <year>2018</year> <month>Feb</month>;<volume>12</volume>. doi:<pub-id pub-id-type="doi">10.3389/fncom.2018.00008</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Vergara</surname> <given-names>VM</given-names></string-name>, <string-name><surname>Mayer</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Damaraju</surname> <given-names>E</given-names></string-name>, <string-name><surname>Calhoun</surname> <given-names>VD</given-names></string-name>. <article-title>The effect of preprocessing in dynamic functional network connectivity used to classify mild traumatic brain injury</article-title> <source>Brain and Behavior</source>. <year>2017</year> <month>Sep</month>;<volume>7</volume>(<issue>10</issue>). doi:<pub-id pub-id-type="doi">10.1002/brb3.809</pub-id>.</mixed-citation></ref>
</ref-list></back>
</article>
