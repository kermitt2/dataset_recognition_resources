<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/104737</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Confirmatory Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Using computational theory to constrain statistical models of neural data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3878-9073</contrib-id>
<name><surname>Linderman</surname> <given-names>Scott W.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6546-3298</contrib-id>
<name><surname>Gershman</surname> <given-names>Samuel J.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1">
<label>1</label>
<institution>Department of Statistics, Columbia University</institution>
</aff>
<aff id="a2">
<label>2</label>
<institution>Department of Psychology and Center for Brain Science, Harvard University</institution>
</aff>
</contrib-group>
<pub-date pub-type="epub">
<year>2017</year>
</pub-date>
<elocation-id>104737</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>1</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>1</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2017</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions>
<self-uri xlink:href="104737.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Computational neuroscience is, to first order, dominated by two approaches: the &#x201C;bottom-up&#x201D; approach, which searches for statistical patterns in large-scale neural recordings, and the &#x201C;top-down&#x201D; approach, which begins with a theory of computation and considers plausible neural implementations. While this division is not clear-cut, we argue that these approaches should be much more intimately linked. From a Bayesian perspective, computational theories provide constrained prior distributions on neural data&#x2014;albeit highly sophisticated ones. By connecting theory to observation via a probabilistic model, we provide the link necessary to test, evaluate, and revise our theories in a data-driven and statistically rigorous fashion. This review highlights examples of this theory-driven pipeline for neural data analysis in recent literature and illustrates it with a worked example based on the temporal difference learning model of dopamine.</p>
</abstract>
<counts>
<page-count count="14"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The statistical toolbox for neuroscience has been steadily growing in sophistication&#x2014;relaxing restrictive assumptions, increasing expressiveness, and enhancing computational efficiency. These advances have enabled a recent blossoming of &#x201C;data-driven&#x201D; approaches to neuroscience, which aim to provide insight into neural mechanisms without testing specific computational theories. Data-driven approaches are appealing, at least in principle, for several reasons: they do not require the scientist to explicitly specify a set of hypotheses, they are unprejudiced by the scientist&#x2019;s theoretical dispositions, and they avoid the problem that many computational theories are too abstract to make direct contact with neural data.</p>
<p>In this paper, we argue that such faith in data-driven approaches is misplaced. Far from escaping the explicit specification of hypotheses, any statistical model of neural data inevitably makes assumptions about the structure of the data, and there is no principled distinction between statistical assumptions and scientific hypotheses. (Admittedly, a purely data-driven approach is something of a straw-man, but we pursue this line of argument for pedagogical purposes). A corollary of this point is that theoretical dispositions are inescapable: it is impossible to specify a statistical model without making assumptions. The question then becomes what assumptions to make. We argue that these assumptions should be derived from computational theories, coupled with flexible statistical parametrizations that compensate for inaccuracy and under-specification of the theories.</p>
<p>We illustrate this argument with a worked example, using a paradigmatic neurocomputational theory: the temporal difference learning model of dopamine. We show how the computational theory can be augmented with modern statistical tools to produce a powerful data analysis methodology. This approach generates a more complete and flexible specification of the theory. Moreover, we show that this approach offers insights into the mechanisms underlying neural data that are inaccessible to purely data-driven approaches.
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>A theory-driven pipeline for neural data analysis based on &#x201C;Box&#x2019;s Loop&#x201D;[<xref rid="c1" ref-type="bibr">1</xref>, <xref rid="c2" ref-type="bibr">2</xref>]. This reviewillustrates many examples of translating theory into statistical model (red box). The benefits are many. Given a model, we may leverage a powerful toolbox of statistical techniques for inference, model criticism, and experimental design. Equally important, theory constrains the space of models and provides a critical lens through which to interpret the posterior. We will discuss advances in each stage of this pipeline.</p></caption>
<graphic xlink:href="104737_fig1.tif"/>
</fig>
</p>
</sec>
<sec id="s2">
<title>A Theory-driven Pipeline for Neural Data Analysis</title>
<p>Neural data analysis is an iterative process that begins with a data set and an idea of the underlying processes that shaped it. The first step, and arguably the most important one, is to turn that idea into a model. With a model in hand, we fit it to the data and investigate the learned parameters, searching for patterns that shed new light on the system under study. But the process does not end here; we then interrogate our model, see where it captures the data well and where it fails, and use these criticisms to suggest model enhancements or subsequent experiments. Thus, model criticism leads to a new model and another iteration of the process.</p>
<p>Statisticians have formalized and automated many pieces of this pipeline: models are joint distributions over data, latent variables and parameters; &#x201C;fitting&#x201D; is performed by posterior inference; criticism is carried out with statistical tests; and optimal experimental design suggests what experiment to run next. This cyclic process of probabilistic modeling, inference, and statistical criticism is known as &#x201C;Box&#x2019;s loop&#x201D; [<xref rid="c1" ref-type="bibr">1</xref>, <xref rid="c2" ref-type="bibr">2</xref>], and later sections of this review will discuss many recent advances in each stage of the pipeline.</p>
<p>Still, the art of carving a manageable class of models from the infinite space of possibilities remains the province of the practitioner. It is here that computational theory can play a vital role, since theories suggest what structure and patterns may exist in the data. In doing so, theories constrain the class of models and make it easier to search, and provide a lens through which to interpret model parameters. These benefits are reciprocated: once a theory has been translated into a probabilistic model, a vast statistical toolbox can be harnessed to test and refine it in light of data.</p>
<p>Theory-driven statistical models are the norm in many fields, most notably in physics, where strong quantitative predictions can be derived from first principles. For example, the discovery of the Higgs boson relied on statistical tests based on predictions of the standard model [<xref rid="c3" ref-type="bibr">3</xref>]. Perhaps it is unsurprising, then, that some of the best examples of theory-driven statistical analyses in neuroscience arise from detailed, biophysical models of single cells. For example, Huys and Paninski [<xref rid="c4" ref-type="bibr">4</xref>] use the Hodgkin-Huxley model to derive a probabilistic model for noisy membrane potential recordings. The conductances of various ion channels are free parameters of their model, and the time-varying channel activations are their latent states. Given the membrane potential, their goal is to infer the conductances, integrating over possible activation states. The highly nonlinear nature of the Hodgkin-Huxley dynamics and the potentially large number of different channel types present a formidable challenge, but biophysical constraints limit the space of feasible parameters. In recent work, these methods have been extended to data in which only spike trains are observed [<xref rid="c5" ref-type="bibr">5</xref>], which present an even greater challenge.</p>
<p>Many models in neuroscience are phenomenological rather than mechanistic in nature. One step up from biophysical models are firing rate models like the generalized linear model (GLM) [<xref rid="c6" ref-type="bibr">6</xref>, <xref rid="c7" ref-type="bibr">7</xref>, <xref rid="c8" ref-type="bibr">8</xref>]. Recent work has extended these classical models to make them more flexible [<xref rid="c9" ref-type="bibr">9</xref>], more biophysically inspired [<xref rid="c10" ref-type="bibr">10</xref>], and more interpretable [<xref rid="c11" ref-type="bibr">11</xref>]. While the GLM omits many mechanistic details, in fully-observed networks its weights can be roughly interpreted as synaptic strengths [<xref rid="c12" ref-type="bibr">12</xref>, <xref rid="c13" ref-type="bibr">13</xref>]. However, the weights of the standard GLM are static, even though synaptic plasticity may be at work in many neural recordings. While the space of all possible dynamic GLM&#x2019;s is intractably large, theories of synaptic plasticity place strong constraints on how synaptic weights evolve over time in response to preceding activity. A number of authors have leveraged these constraints to develop theory-driven GLM&#x2019;s with time-varying weights and have shown how alternative models of synaptic plasticity can be compared on the basis of their fit to spike train data [<xref rid="c14" ref-type="bibr">14</xref>, <xref rid="c15" ref-type="bibr">15</xref>, <xref rid="c16" ref-type="bibr">16</xref>].</p>
<p>This approach extends to computational theories as well, and is exemplified in the work of <xref rid="c17" ref-type="bibr">Latimer et al</xref>. [<xref rid="c17" ref-type="bibr">17</xref>]. The authors reconsider the long-standing theory of evidence accumulation in lateral intraparietal (LIP) cortex [<xref rid="c18" ref-type="bibr">18</xref>], and ask whether patterns that emerge in trial-averaged data are borne out in individual trials. Specifically, do the firing rates of neurons in LIP slowly ramp as evidence is accumulated, or do they exhibit a discrete jump in firing rate? Theory suggests the former, whereas the latter would indicate that LIP may not be the site of integration. Critically, both theories would yield the appearance of a ramp in trial-averaged firing rate. <xref rid="c17" ref-type="bibr">Latimer et al</xref>. [<xref rid="c17" ref-type="bibr">17</xref>] formulate both theories as probabilistic models for single trial data, fit these models with Bayesian inference, compare them on the basis of the marginal likelihood of the data, and find that a large fraction of neurons are better explained by the discrete jump model. This provides statistical evidence with which to assess and reevaluate canonical theory. Indeed, this work has prompted further assessments of their modeling assumptions and the validity of their conclusions [<xref rid="c19" ref-type="bibr">19</xref>]&#x2014;a prime example of Box&#x2019;s loop in action post-publication.</p>
<p>Integrative approaches to computational theory and statistical analysis have also been pursued in higher-level cognition. Detre and colleagues [<xref rid="c20" ref-type="bibr">20</xref>] used Bayesian inference to identify a nonmonotonic relationship between memory activation (as measured by functional MRI) and subsequent memory, as predicted by a competition-dependent theory of episodic memory [<xref rid="c21" ref-type="bibr">21</xref>]. The same analytical approach was used to identify other nonmonotonic effects of retrieval strength on memory [<xref rid="c22" ref-type="bibr">22</xref>, <xref rid="c23" ref-type="bibr">23</xref>].</p>
<p>The aforementioned examples stand in contrast to many dimensionality reduction methods like PCA, tSNE [<xref rid="c24" ref-type="bibr">24</xref>], and others [<xref rid="c25" ref-type="bibr">25</xref>], and differ as well from general-purpose state space models [<xref rid="c26" ref-type="bibr">26</xref>, <xref rid="c27" ref-type="bibr">27</xref>, <xref rid="c28" ref-type="bibr">28</xref>] and recurrent neural network models [e.g. <xref rid="c29" ref-type="bibr">29</xref>] for neural data. Such methods start with very weak assumptions&#x2014;linear embeddings or low-dimensional dynamics&#x2014;and, in this sense, allow the data to speak freely. Thus, they are invaluable exploratory tools. However, in the absence of a theory, the inferred low-dimensional states and projections require careful interpretation. In many cases, theories correspond to special cases of these general-purpose models, and thus help address issues of interpretability.</p>
<p>The landscape of neural data-analysis is not as strictly divided into top-down and bottom-up approaches as the preceding discussion may suggest. Indeed, many models fall somewhere in the middle, incorporating aspects of theory while allowing flexibility in aspects that are less certain. Wiltschko et al. [<xref rid="c30" ref-type="bibr">30</xref>] strike such a balance in their model for depth videos of freely behaving mice. Starting with the classic ethological theory that behavior is composed of a sequence of discrete, resuable units, or &#x201C;syllables,&#x201D; the authors propose an autoregressive hidden Markov model to discover these syllables from raw data. However, since the number of syllables is not known <italic>a priori</italic>, the authors use a Bayesian nonparametric prior distribution [<xref rid="c31" ref-type="bibr">31</xref>] to determine the number of states in a data-driven manner.</p>
<p>These works exhibit a diverse array of &#x201C;theory-driven&#x201D; neural data analyses, but the best way to understand this pipeline is through an example.</p>
</sec>
<sec id="s3">
<title>A Worked Example</title>
<p>There is no single recipe for translating computational theories into probabilistic models of data, but the conversion necessarily involves answering a few basic questions. Which theoretical variables and parameters are observed and which are latent? How are they encoded by the neural system under study? How do these variables evolve over time? What are the sources of noise in the system and in the measurements? The answers to these questions inform statistical models of data that in turn define distributions of likely patterns of neural activity. We will illustrate this translation with a simple worked example<xref rid="fn1" ref-type="fn"><sup>1</sup></xref>.</p>
<p>Temporal difference (TD) learning [<xref rid="c33" ref-type="bibr">33</xref>] is a classical algorithm by which agents, over the course of many trials, learn to use sensory cues to predict the discounted sum of future rewards. Assume that there are <italic>L</italic> trials, each lasting <italic>T</italic> time steps. On trial &#x2113; the agent receives a sequence of stimuli, which are stored and encoded as vectors, <italic>u<sub>&#x2113;,t</sub></italic> and a corresponding sequence of rewards, <italic>r<sub>&#x2113;,1</sub></italic>&#x2026;,<italic>r<sub>&#x2113;,T</sub></italic>, most of which may be zero. In a classical conditioning experiment, the stimulus may be a light at time <italic>t</italic> followed by a reward some number of time steps in the future, and <italic>u<sub>&#x2113;,t</sub></italic> may encode, for example, the number of time steps since the bell was heard. The agent then uses this encoding to compute a <italic>value function</italic> for the given trial and time step,
<disp-formula id="eqn1"><alternatives><graphic xlink:href="104737_eqn1.gif"/></alternatives></disp-formula></p>
<p>In reinforcement learning, the value is the total amount of future reward to be expected after receiving input <italic>u<sub>&#x2113;,t</sub></italic> However, according to the theory, the reward is discounted by how long one must wait before receiving it. For example, a reward <italic>k</italic> time steps into the future is down-weighted by a factor of &#x03B3;<sup><italic>k</italic></sup>, where &#x03B3;&#x2208; [0, 1] is the <italic>discount factor</italic>. The agent&#x2019;s goal is to adjust the weights<xref rid="fn2" ref-type="fn"><sup>2</sup></xref> of its value function z<sub>&#x2113;</sub>, such that the value function approximates this discounted sum of expected future rewards,<disp-formula id="eqn2"><alternatives><graphic xlink:href="104737_eqn2.gif"/></alternatives></disp-formula></p>
<p>If the environment is a Markov decision process, the target value function can be written recursively as <inline-formula><alternatives><inline-graphic xlink:href="104737_inline1.gif"/></alternatives></inline-formula> When the value function equals the cumulative discounted reward, the <italic>reward prediction error</italic>,
<disp-formula id="eqn3"><alternatives><graphic xlink:href="104737_eqn3.gif"/></alternatives></disp-formula> will equal zero. Intuitively, the reward prediction error provides an instantaneous estimate of how well the value function predicts the received reward. Thus, to improve its value function, the agent should adjust its weights to reduce this error. Indeed, this is accomplished by the simple learning rule, <disp-formula id="eqn4"><alternatives><graphic xlink:href="104737_eqn4.gif"/></alternatives></disp-formula> which can be seen as a form of stochastic gradient descent on the (squared) reward prediction error with learning rates &#x03B1;<sub>1</sub>,&#x2026;, &#x03B1;<sub><italic>L</italic></sub>. In the following experiments, we will consider two learning schedules: a power-law schedule,<inline-formula><alternatives><inline-graphic xlink:href="104737_inline2.gif"/></alternatives></inline-formula>and a constant schedule, &#x03B1;<sub>&#x2113;</sub>&#x2261;&#x03C4;. In both cases, assume &#x03C4; &#x2208; [0, 1].</p>
<p><xref rid="c34" ref-type="bibr">Schultz et al</xref>. [<xref rid="c34" ref-type="bibr">34</xref>] found that the firing rates of dopaminergic neurons in the ventral tegmental area (VTA) mimic the reward prediction errors essential to the TD-learning algorithm. Moreover, it is hypothesized that cortex represents the stimulus, striatum represents the value function estimate, and VTA activity modulates plasticity of synapses from cortex to striatum [<xref rid="c35" ref-type="bibr">35</xref>]. Still, many important questions remain, like how learning schedules, which affect this plasticity, vary from trial to trial in real neural circuits. As a didactic exercise, we will we use the TD learning theory to construct a probabilistic model for neural data, and use that model to compare between different learning schedules in a statistically rigorous manner.</p>
<p>Suppose that we have access to simultaneous noisy recordings of a VTA neuron and an upstream population of <italic>N</italic> cortical neurons. As has been hypothesized, we will assume the VTA neuron encodes reward prediction error, &#x03C7;<sub>&#x2113;,t</sub> and the cortical neurons carry the stimulus encoding, <italic>u<sub>&#x2113;,t</sub></italic>. Moreover, assume we know the reward signal, <italic>r</italic><sub>&#x2113;,t</sub>.According to the TD learning theory, the cortical and VTA signals are related via a value function, which is determined by an unobserved and dynamic set of weights at each trial. In other words, the theory implies that the reward prediction errors follow a latent state space model whose hidden states are the weights, <italic>z</italic><sub>&#x2113;</sub>, and whose parameters vary from trial to trial according to the cortical inputs, rewards, and prediction errors. If we assume Gaussian noise in the weight updates and observations, the theory implies that the VTA activity follows a Gaussian linear dynamical system (LDS) with non-stationary parameters.</p>
<p>To see this equivalence, we rewrite the TD learning updates in standard state space notation:
<disp-formula id="eqn5"><alternatives><graphic xlink:href="104737_eqn5.gif"/></alternatives></disp-formula>
<disp-formula id="eqn6"><alternatives><graphic xlink:href="104737_eqn6.gif"/></alternatives></disp-formula></p>
<p>Here, the latent states are the weights, <inline-formula><alternatives><inline-graphic xlink:href="104737_inline3.gif"/></alternatives></inline-formula> and their dynamics are determined by, <italic>A<sub>&#x2113;</sub>&#x003D;I</italic> and <inline-formula><alternatives><inline-graphic xlink:href="104737_inline4.gif"/></alternatives></inline-formula> That is, the weights follow a random walk biased by the learning rate, error signal, and inputs. The emissions are vectors of observed VTA activity, <italic>x</italic><sub><italic>&#x2113;</italic></sub> = [<italic>x</italic><sub><italic>&#x2113;</italic></sub>,1; &#x2026;; <italic>x</italic><sub><italic>&#x2113;</italic></sub>,<sub>T&#x2212;1</sub>], and they are determined by the matrix <italic>C</italic><sub><italic>&#x2113;</italic></sub> = [<italic>c</italic><sup>T</sup><sub><italic>&#x2113;</italic>, 1</sub>; &#x2026;; <italic>c</italic><sup>T</sup> <sub><italic>&#x2113;</italic>,<italic>T</italic>&#x2212;1</sub>], where <italic>c</italic><sub><italic>&#x2113;,t</italic></sub> = <italic>&#x03B3;u</italic><sub><italic>&#x2113;</italic></sub>,<sub><italic>t</italic>&#x002B;1 &#x2212;</sub> <italic>u</italic><sub><italic>&#x2113;,t</italic></sub>, and by the bias vector, <italic>d</italic><sub><italic>&#x2113;</italic></sub> = [<italic>d</italic><sub><italic>&#x2113;</italic>,1</sub>, &#x2026;, <italic>d</italic><sub><italic>&#x2113;</italic></sub>,<sub>T&#x2212;1</sub>], where, <italic>d</italic><sub>&#x2113;,<italic>t</italic></sub>&#x003D;<italic>r<sub>&#x2113;,t&#x002B;1</sub></italic> Note that both the dynamics and emission parameters are non-stationary; that is, they vary from trial to trial. The noise in the weight updates is governed by, and the noise in the observations is governed by &#x03C3;. Referring back to equations (1)&#x2013;(4), we see that the exact TD learning model is recovered in the noise-free limit. The free parameters are &#x03B8;=(&#x03C4;, &#x03B3;, &#x2208;,&#x03C3;,)&#x2014;the learning rate parameters, discount factor, and noise variances.</p>
<p>We call this constrained model a temporal difference LDS (TD-LDS). Importantly, by translating the TD learning theory into a constrained Gaussian LDS, we have reduced it to an essentially solved model with very mature estimation and interpretation procedures [<xref rid="c36" ref-type="bibr">36</xref>]. In the next section we will show how to infer the states and parameters of the TD-LDS from data.</p>
<p>What assumptions did we make in deriving the TD-LDS? First, we assumed Gaussian noise in both the observed reward prediction errors and the weight dynamics. If we observed spike counts instead, the resulting model would be more akin to a Poisson linear dynamical system (PLDS) <xref rid="c26" ref-type="bibr">26</xref>, <xref rid="c27" ref-type="bibr">27</xref>]. If we had assumed a nonlinear model for the value function, i.e V<sub><italic>&#x2113;,t</italic></sub> = <italic>f</italic>(<italic>z</italic><sub><italic>&#x2113;</italic></sub> <italic>u</italic><sub><italic>&#x2113;t</italic></sub>), then both the dynamics and observation models would be nonlinear in <italic>z</italic><sub>&#x2113;</sub>, which would necessitate more sophisticated inference procedures. We will only consider the linear Gaussian case in this didactic example.</p>
</sec>
<sec id="s4">
<title>Bayesian Inference</title>
<p>Bayesian inference algorithms take as input the observed data, <italic>x</italic>, and a probabilistic model, <italic>p</italic>(<italic>x</italic>, <italic>z</italic>, &#x03B8;), and output the posterior distribution over the latent variables and param-eters of the model, <italic>p</italic>(<italic>z</italic>,&#x03B8; &#x007C; <italic>x</italic>). By Bayes&#x2019; rule, this posterior distribution is given by,
<disp-formula id="eqn7">
<alternatives>
<graphic xlink:href="104737_eqn7.gif"/>
</alternatives>
</disp-formula>
</p>
<p>With this posterior distribution in hand, we can answer a host of scientific questions. We can estimate the posterior mean and mode (the maximum <italic>a posteriori</italic> estimate), and we can provide Bayesian credible intervals by computing the quantiles of the posterior distribution. Moreover, we can predict what future data would look like with the <italic>posterior predictive</italic> distribution,
<disp-formula id="eqn8">
<alternatives>
<graphic xlink:href="104737_eqn8.gif"/>
</alternatives>
</disp-formula> which integrates over the space of parameters and latent variables, weighting them by their posterior probability given the data seen thus far. As we will show below, these functions of the posterior distribution provide principled means of comparing and checking models.</p>
<p>Unfortunately, the normalizing constant on the right-hand side of Bayes&#x2019; rule, <italic>p</italic>(<italic>x</italic>), also known as the <italic>marginal likelihood</italic>, requires an integral over all possible parameters. This integral is intractable for all but the simplest models, so in practice we must resort to approximate techniques like Markov chain Monte Carlo (MCMC) [<xref rid="c37" ref-type="bibr">37</xref>] or variational inference [<xref rid="c38" ref-type="bibr">38</xref>, <xref rid="c39" ref-type="bibr">39</xref>]. MCMC algorithms approximate the posterior distribution with a collection of samples collected by a Markov chain that randomly walks over the space of parameters. With a carefully tuned random walk, the stationary distribution of the Markov chain is equal to the desired posterior distribution so that, once the chain has converged, parameters are visited according to their posterior probability. In contrast, variational inference algorithms specify a family of &#x201C;simpler&#x201D; distributions and search for the member of this family that best approximates the desired posterior. Thus, they convert an integration problem of computing the denominator of Bayes&#x2019; rule into an optimization problem of searching over the variational family. Of course, both approaches present challenges&#x2014;how to tell if a Markov chain has converged? how to select and search over a variational family and diagnose errors in the obtained approximation?&#x2014;making Bayesian inference both an art and a science.</p>
<p>Fortunately for the practitioner, as probabilistic programming packages grow in sophistication, the nuances of approximate inference play a lesser role. Probabilistic programming languages like Anglican [<xref rid="c40" ref-type="bibr">40</xref>], Stan [<xref rid="c41" ref-type="bibr">41</xref>], Venture [<xref rid="c42" ref-type="bibr">42</xref>], and Edward [<xref rid="c43" ref-type="bibr">43</xref>] remove the burden of deriving and implementing an inference algorithm, and simply require the practitioner to specify their probabilistic model and supply their data. Under the hood, these packages automatically derive suitable MCMC or variational inference algorithms. In practice, some care must be taken to ensure these systems provide accurate inferences, and these tools still cannot compete with well-tuned, model-specific inference algorithms. However, they can dramatically accelerate the scientific process by enabling rapid iteration over models. Once a model has been selected, time may be invested in deriving bespoke inference algorithms for peak performance.</p>
<p>We have taken an intermediate approach to inference in our working example. After reducing TD learning theory to a canonical state space model, we leverage off-the-shelf inference algorithms for the latent states and develop model-specific updates only for the parameters. Specifically, given the discount factor and the learning schedule, the posterior distribution over latent states is found with a standard message passing algorithm [<xref rid="c39" ref-type="bibr">39</xref>]. Given a distribution over latent states, we estimate the most likely learning schedule parameters and discount factor with hand-derived updates. We alternate these two steps&#x2014; updating the latent states and re-estimating the parameters&#x2014;in our variational inference algorithm.</p>
<p><xref rid="fig2" ref-type="fig">Figure 2</xref> illustrates some of the results of our Bayesian inference algorithm. Panel (e) shows the posterior mean of the states, which in this model correspond to the weights of the value function. From the posterior distribution over weights, we derive the distribution over the value function, which is linear in the weights (c.f. (1)). Panel (f) shows the true and inferred value function at early (blue), middle (red), and late (yellow) trials, along with the uncertainty under the posterior. Likewise, panel (g) shows the inferred learning rate under two different models: a model with constant rates and a model with rates that decay according to a power law (the true model in this case). Posterior visualizations like these play a critical role in the scientific process, providing views of the low-dimensional structure of complex data. However, these visualizations are only useful to the extent that the model captures meaningful structure. Panel (h) exemplifies this point: a standard LDS with the same latent dimension as the TD-LDS provides a very good fit to the data, but its latent states look like pure noise. Without a theoretical structure with which to interpret this low-dimensional projection, the latent states are meaningless.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p>An illustrative example of using the theory of TD learning to constrain a probabilistic state space model for neural data. <bold>(a)</bold> Simulated example of a dopamine neuron encoding reward prediction error in VTA. Over many trials, the response shifts from the delivery of reward (at <italic>t</italic> = 60) to the onset of stimulus (at <italic>t</italic> = 10, dashed line). <bold>(b)</bold> Hypothetical cortical neurons encode time since stimulus onset with a set of temporal tuning curves, as has been suggested [<xref rid="c32" ref-type="bibr">32</xref>]. <bold>(c)</bold> Thus, on each trial, the cortical neurons exhibit a cascade of activity. <bold>(d)</bold> We use TD learning theory to constrain a state space model for the activity of cortex and VTA, whose graphical model is shown here (rewards omitted). The latent states are the weights relating cortical activity to an unobserved value function. <bold>(e)</bold> The posterior mean of the latent states of the TD learning state space model. Though not particularly insightful on their own, when combined with cortical activity, the weights determine the posterior distribution of the value function <bold>(f)</bold>. Colors correspond to trials 1, 30, and 150, as in (a). Dotted black line: ground truth. <bold>(g)</bold> We also learn the learning rate, &#x03B1;<sub>l</sub>, under two different models: a constant model and a power-law decay model. <bold>(h)</bold> In contrast to the TD-LDS, fitting a standard LDS to the VTA activity yields accurate predictions, but its latent states are uninformative and do not correspond to weights of a value function.</p></caption>
<graphic xlink:href="104737_fig2.tif"/>
</fig>
</sec>
<sec id="s5">
<title>Model Criticism and Comparison</title>
<p>Bayesian inference is not the end of the scientific process, but rather an intermediate step in the iterative loop of hypothesizing, fitting, criticizing, and revising a model. Still, posterior inference provides a rigorous and quantifiable method of guiding model criticism and revision. Intuitively, if the model is a good match for the data, then samples from the fit model should &#x201C;look like&#x201D; the observed data. <italic>Posterior predictive checks</italic> (PPC&#x2019;s) [<xref rid="c1" ref-type="bibr">1</xref>, <xref rid="c2" ref-type="bibr">2</xref>, <xref rid="c44" ref-type="bibr">44</xref>], which are essentially Bayesian goodness-of-fit tests, formalize this intuition in a statistically rigorous manner. Our presentation here parallels that of Blei [<xref rid="c2" ref-type="bibr">2</xref>].</p>
<p>PPC&#x2019;s compare the observed data to datasets sampled from the posterior predictive distribution (8) of the model. If the sampled data differs from the observed along important dimensions, the model fails the PPC. These &#x201C;important dimensions&#x201D; are determined by the practitioner&#x2019;s choice of a test statistic, <italic>T(x)</italic>: a function that identifies a particular aspect of the data, <italic>x</italic>. For example, in our TD learning simulations, a salient characteristic is the propagation of error signal from the onset of reward to the presentation of the cue. Thus, a simple statistic is amplitude of the error signal in particular trials and time bins. The PPC is defined as the probability that the test statistic of sampled data exceeds that of observed data PPC = Pr(<italic>T</italic>(<italic>x</italic>) &#x003E; <italic>T</italic>(<italic>x</italic>)| <italic>x</italic><sup>&#x002A;</sup>).</p>
<p>The choice of test statistic is left to the practitioner. Clearly, probabilistic modeling under computational constraints necessitates trade-offs and assumptions; no model is perfect. PPC&#x2019;s are a diagnostic tool for assessing whether the model recapitulates salient features of the data, as determined by the practitioner. In this sense, PPC&#x2019;s provide a targeted means of criticizing models, shining spotlights on the most important parts. Moreover, there is no limit to the number of PPC&#x2019;s that may be applied, and the marginal cost of estimating multiple PPC&#x2019;s is negligible since they can all be estimated using the same sampled data.</p>
<p><xref rid="fig3" ref-type="fig">Figure 3</xref> illustrates a very simple posterior predictive check for the TD learning model. Panels (a-c) show the observed data (black) and the quantiles of the posterior predictive distribution for the tenth trial, estimated with 1000 samples from the posterior predictive distributions. In this case, the true model uses a power law learning rate, and indeed this is the only model that consistently captures the data. The constant model overestimates the response to the reward (time 60) and the standard LDS incorrectly predicts a response at cue onset. We quantify this with PPC&#x2019;s for the simplest statistics, <italic>T</italic><sub><italic>l,t</italic></sub>&#x003D; <italic>x</italic><sub><italic>l,t</italic></sub>.Panels (d-f) show the PPC&#x2019;s for each trial and time bin. This reveals the delayed responses of the constant model in early trials, and the tendency of the standard LDS to predict a response at cue onset regardless of trial. Under the true model, these PPC&#x2019;s are uniformly distributed on [0, 1]. Panels (g-f) show that only the power law achieves this.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Model criticism using posterior predictive checks (PPC&#x2019;s). <bold>(a-c)</bold> PPC of the data on trial 10 for three models: the TD-LDS with a power-law learning schedule (i.e. the true model that generated the data); the TD-LDS with a constant learning rate; and a standard LDS. Blue line: posterior predictive median; blue shading: posterior predictive quantiles; black line: observed data. The constant learning rate fails the PPC because it generates a much larger prediction error at time <italic>t</italic> = 59. The standard LDS fails because it always predicts large signals at <italic>t</italic> = 10, regardless of trial. <bold>(d-f)</bold> A summary view of the PPC for all trials and time points. Color denotes the PPC value estimated from 1000 generated trajectories. Blue: model predictions larger than data; red: data larger than model predictions. Values close to zero or one indicate model mismatch. <bold>(g-i)</bold> A histogram of values in (d-f), respectively. The true model should yield uniformly distributed PPC&#x2019;s(dotted line), as indeed the power law does. The other models generated data that systematically differs from the true data.</p></caption>
<graphic xlink:href="104737_fig3.tif"/>
</fig>
<p>While PPC&#x2019;s check, in absolute terms, how well the model fits the data, in some cases we seek a relative comparison of two models instead. For example, we often cascade models of increasing complexity&#x2014;factor analysis is a special case of an LDS, which in turn is a special case of a switching LDS&#x2014;and we need means of justifying this increased capacity. The most straightforward approach is to measure predictive likelihood on held-out data. A better model should assign higher posterior predictive probability, <italic>p</italic>(<italic>x</italic><sup>&#x002A;</sup>&#x007C;<italic>x</italic>), to the held-out data. We see that the predictive probability (8) is an expectation with respect to the posterior. Since this is typically intractable, we estimate the predictive probability with samples from the approximate posterior.</p>
<p>This is by no means the only method of comparing models. In &#x201C;fully Bayesian&#x201D; analyses, it is common to compare models on the basis of their marginal likelihood, <italic>p</italic>(<italic>x</italic>) [<xref rid="c45" ref-type="bibr">45</xref>, <xref rid="c46" ref-type="bibr">46</xref>]. Recall that this is the denominator in Bayes&#x2019; rule (7), and it is generally intractable. Variational methods provide a lower bound on this quantity, and Monte Carlo estimates like annealed importance sampling [<xref rid="c47" ref-type="bibr">47</xref>] can yield unbiased estimates of it. In general, however, marginal likelihood estimation is an active area of research [<xref rid="c48" ref-type="bibr">48</xref>, <xref rid="c49" ref-type="bibr">49</xref>, <xref rid="c50" ref-type="bibr">50</xref>].</p>
<p>Model criticism suggests not only new theories to test, but also new experiments to run. Specifically, we should choose an experiment that is most likely to reduce the uncertainty of the posterior. Equivalently, we should perform the experiment that yields the maximal information gain in expectation. This intuition is the basis of Bayesian optimal experimental design [<xref rid="c45" ref-type="bibr">45</xref>, <xref rid="c51" ref-type="bibr">51</xref>, <xref rid="c52" ref-type="bibr">52</xref>, <xref rid="c53" ref-type="bibr">53</xref>] and is also the guiding principle underlying Bayesian optimization [<xref rid="c54" ref-type="bibr">54</xref>]. In our working example, these methods could suggest the combination of stimulus and reward patterns that would be most informative of the underlying learning rate. These methods have been proposed for sampling the voltage on dendritic trees in high-noise settings [<xref rid="c55" ref-type="bibr">55</xref>], as well as for designing training regimes for animals [<xref rid="c56" ref-type="bibr">56</xref>].</p>
<p>Just as probabilistic programming languages and automated inference algorithms are relieving the burden of Bayesian inference, recent work has attempted to automate model criticism and model comparison. Automatic two-sample tests [<xref rid="c57" ref-type="bibr">57</xref>, <xref rid="c58" ref-type="bibr">58</xref>] search for test statistics that best discriminate between the observed data and a model&#x2019;s samples. In this sense, these approaches are similar to generative adversarial networks [<xref rid="c59" ref-type="bibr">59</xref>], which simultaneously train competing generator and discriminator networks. Likewise, automatic model composition methods [<xref rid="c60" ref-type="bibr">60</xref>, <xref rid="c61" ref-type="bibr">61</xref>] iteratively construct models, adding increasingly sophisticated structure to capture nuances of the data and comparing on the basis of marginal likelihood. While these advances have still not taken the human &#x201C;out of the loop,&#x201D; recent work suggests that these approaches do indeed mimic the process by which humans learn the complex structure of data [<xref rid="c62" ref-type="bibr">62</xref>].</p>
</sec>
<sec id="s6">
<title>Conclusions</title>
<p>The idea of combining statistical models with computational theories is not new (see [<xref rid="c63" ref-type="bibr">63</xref>]), but researchers are only beginning to appreciate the range of possibilities that have opened up with advances in probabilistic modeling. Richly expressive probabilistic programming languages, efficient inference algorithms, and flexible Bayesian nonparametric priors allow complex models to be specified and fit to data much more easily than in the past. Model criticism and comparison techniques can be used to guide the refinement of modeling assumptions, as in Box&#x2019;s loop. We have shown how this statistical toolbox can be seam-lessly integrated with computational theory, using a worked example from reinforcement learning. The key lesson from this modeling exercise is that data-driven and theory-driven approaches to neuroscience need not be mutually exclusive; indeed, the most powerful insights can be gained by using computational theories as constraints on data-driven statistical models.</p>
<p>Conversely, flexible statistical models can enrich computational theories. Historically, computational tractability has biased the kinds of models we fit towards simplicity (conjugacy, convex optimization problems, unimodal posteriors, low-dimensional parametrizations). With faster computers, larger datasets and new algorithms, machine learning has increasingly pushed the envelope towards much more complex models [<xref rid="c64" ref-type="bibr">64</xref>, <xref rid="c29" ref-type="bibr">29</xref>, <xref rid="c65" ref-type="bibr">65</xref>], altering the usual tradeoff between neuroscientific realism and computational tractability. We are now in a position to start experimentally testing a vast range of computational theories.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>SWL is supported by a Simons Collaboration on the Global Brain postdoctoral fellowship (SCGB-418011). SJG is supported by the National Institutes of Health (CRCNS 1207833). We thank Liam Paninski for his helpful feedback on this work.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>George EP</given-names> <surname>Box</surname></string-name>. <article-title>Sampling and Bayes&#x2019; inference in scientific modelling and robustness</article-title>. <source>Journal of the Royal Statistical Society. Series A (General)</source>, pages <fpage>383</fpage>&#x2013;<lpage>430</lpage>, <year>1980</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>David M</given-names> <surname>Blei</surname></string-name>. <article-title>Build, compute, critique, repeat: Data analysis with latent variable models</article-title>. <source>Annual Review of Statistics and Its Application</source>, <volume>1</volume>:<fpage>203</fpage>&#x2013;<lpage>232</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><article-title>The ATLAS Collaboration. A particle consistent with the Higgs boson observed with the ATLAS detector at the Large Hadron Collider</article-title>. <source>Science</source>, <volume>338</volume>(<issue>6114</issue>):<fpage>1576</fpage>&#x2013;<lpage>1582</lpage>, <month>December</month> <year>2012</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Quentin JM</given-names> <surname>Huys</surname></string-name> and <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Smoothing of, and parameter estimation from, noisy biophysical recordings</article-title>. <source>PLoS Comput Biol</source>, <volume>5</volume>(<issue>5</issue>), <fpage>2009</fpage>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>Liang</given-names> <surname>Meng</surname></string-name>, <string-name><given-names>Mark A</given-names> <surname>Kramer</surname></string-name>, <string-name><given-names>Steven J</given-names> <surname>Middleton</surname></string-name>, <string-name><given-names>Miles</given-names> <surname>A Whittington</surname></string-name>, and <string-name><given-names>Uri</given-names> <surname>T Eden</surname></string-name>. <article-title>A unified approach to linking experimental, statistical and computational analysis of spike train data</article-title>. <source>PloS One</source>, <volume>9</volume>(<issue>1</issue>):<fpage>e85269</fpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Maximum likelihood estimation of cascade point-process neural encoding models</article-title>. <source>Network: Computation in Neural Systems</source>, <volume>15</volume>(<issue>4</issue>):<fpage>243</fpage>&#x2013;<lpage>262</lpage>, <month>January</month> <year>2004</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Wilson</given-names> <surname>Truccolo</surname></string-name>, <string-name><given-names>Uri T.</given-names> <surname>Eden</surname></string-name>, <string-name><given-names>Matthew R.</given-names> <surname>Fellows</surname></string-name>, <string-name><given-names>John P.</given-names> <surname>Donoghue</surname></string-name>, and <string-name><given-names>Emery N.</given-names> <surname>Brown</surname></string-name>. <article-title>A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects</article-title>. <source>Journal of Neurophysiology</source>, <volume>93</volume>(<issue>2</issue>):<fpage>1074</fpage>&#x2013;<lpage>1089</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Jonathan W</given-names> <surname>Pillow</surname></string-name>, <string-name><given-names>Jonathon</given-names> <surname>Shlens</surname></string-name>, <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Sher</surname></string-name>, <string-name><given-names>Alan M</given-names> <surname>Litke</surname></string-name>, <string-name><given-names>EJ</given-names> <surname>Chichilnisky</surname></string-name>, and <string-name><given-names>Eero</given-names> <surname>P Simoncelli</surname></string-name>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>, <volume>454</volume>(<issue>7207</issue>):<fpage>995</fpage>&#x2013;<lpage>999</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Il Memming</given-names> <surname>Park</surname></string-name>, <string-name><given-names>Evan W</given-names> <surname>Archer</surname></string-name>, <string-name><given-names>Nicholas</given-names> <surname>Priebe</surname></string-name>, and <string-name><given-names>Jonathan</given-names> <surname>W Pillow</surname></string-name>. <article-title>Spectral methods for neural characterization using generalized quadratic models</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>2454</fpage>&#x2013;<lpage>2462</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>Kenneth W</given-names> <surname>Latimer</surname></string-name>, <string-name><given-names>EJ</given-names> <surname>Chichilnisky</surname></string-name>, <string-name><given-names>Fred</given-names> <surname>Rieke</surname></string-name>, and <string-name><given-names>Jonathan</given-names> <surname>W Pillow</surname></string-name>. <article-title>Inferring synaptic conductances from spike trains with a biophysically inspired point process model</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>954</fpage>&#x2013;<lpage>962</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>Scott</given-names> <surname>W Linderman</surname></string-name>, <string-name><given-names>Ryan</given-names> <surname>P Adams</surname></string-name>, and <string-name><given-names>Jonathan</given-names> <surname>W Pillow</surname></string-name>. <article-title>Bayesian latent structure discovery from multi-neuron recordings</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>2002</fpage>&#x2013;<lpage>2010</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Felipe</given-names> <surname>Gerhard</surname></string-name>, <string-name><given-names>Tilman</given-names> <surname>Kispersky</surname></string-name>, <string-name><given-names>Gabrielle J</given-names> <surname>Gutierrez</surname></string-name>, <string-name><given-names>Eve</given-names> <surname>Marder</surname></string-name>, <string-name><given-names>Mark</given-names> <surname>Kramer</surname></string-name> and <string-name><given-names>Uri</given-names> <surname>Eden</surname></string-name>. <article-title>Successful reconstruction of a physiological circuit with known connectivity from spiking activity alone</article-title>. <source>PLoS Computational Biology</source>, <volume>9</volume>(<issue>7</issue>):<fpage>e1003138</fpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Daniel</given-names> <surname>Soudry</surname></string-name>, <string-name><given-names>Suraj</given-names> <surname>Keshri</surname></string-name>, <string-name><given-names>Patrick</given-names> <surname>Stinson</surname></string-name>, <string-name><surname>Min-hwan</surname> <given-names>Oh</given-names></string-name>, <string-name><given-names>Garud</given-names> <surname>Iyengar</surname></string-name> and <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Efficient &#x201C;shotgun&#x201D; inference of neural connectivity from highly sub-sampled activity data</article-title>. <source>PLoS Computational Biology</source>, <volume>11</volume>(<issue>10</issue>):<fpage>e1004464</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Scott W</given-names> <surname>Linderman</surname></string-name>, <string-name><given-names>Christopher H</given-names> <surname>Stock</surname></string-name>, and <string-name><given-names>Ryan P</given-names> <surname>Adams</surname></string-name>. <article-title>A framework for studying synaptic plasticity with neural spike train data</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>2330</fpage>&#x2013;<lpage>2338</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Ian</given-names> <surname>Stevenson</surname></string-name> and <string-name><given-names>Konrad</given-names> <surname>Koerding</surname></string-name>. <article-title>Inferring spike-timing-dependent plasticity from spike train data</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>2582</fpage>&#x2013;<lpage>2590</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>Brian</given-names> <surname>S Robinson</surname></string-name>, <string-name><given-names>Theodore</given-names> <surname>W Berger</surname></string-name>, and <string-name><given-names>Dong</given-names> <surname>Song</surname></string-name>. <article-title>Identification of stable spike-timing-dependent plasticity from spiking activity with generalized multilinear modeling</article-title>. <source>Neural Computation</source>, <year>2016</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>Kenneth W</given-names> <surname>Latimer</surname></string-name>, <string-name><given-names>Jacob L</given-names> <surname>Yates</surname></string-name>, <string-name><given-names>Miriam LR</given-names> <surname>Meister</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>C Huk</surname></string-name>, and <string-name><given-names>Jonathan</given-names> <surname>W Pillow</surname></string-name>. <article-title>Single-trial spike trains in parietal cortex reveal discrete steps during decision-making</article-title>. <source>Science</source>, <volume>349</volume>(<issue>6244</issue>):<fpage>184</fpage>&#x2013;<lpage>187</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>Joshua I</given-names> <surname>Gold</surname></string-name> and <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>. <article-title>The neural basis of decision making</article-title>. <source>Annual Review of Neuroscience</source>, <volume>30</volume>:<fpage>535</fpage>&#x2013;<lpage>574</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>Ariel</given-names> <surname>Zylberberg</surname></string-name> and <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>. <article-title>Cause for pause before leaping to conclusions about stepping</article-title>. <source>bioRxiv</source>, page <fpage>085886</fpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><surname>Greg</surname> <given-names>J Detre</given-names></string-name>, <string-name><surname>Annamalai</surname> <given-names>Natarajan</given-names></string-name>, <string-name><given-names>Samuel</given-names> <surname>J Gershman</surname></string-name> and <string-name><given-names>Kenneth</given-names> <surname>A Norman</surname></string-name>. <article-title>Moderate levels of activation lead to forgetting in the think/no-think paradigm</article-title>. <source>Neu-ropsychologia</source>, <volume>51</volume>(<issue>12</issue>):<fpage>2371</fpage>&#x2013;<lpage>2388</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><surname>Kenneth</surname> <given-names>A Norman</given-names></string-name>, <string-name><surname>Ehren</surname> <given-names>Newman</given-names></string-name>, <string-name><given-names>Greg</given-names> <surname>Detre</surname></string-name> and <string-name><given-names>Sean</given-names> <surname>Polyn</surname></string-name>. <article-title>How inhibitory oscillations can train neural networks and punish competitors</article-title>. <source>Neural Computation</source>, <volume>18</volume>(<issue>7</issue>):<fpage>1577</fpage>&#x2013;<lpage>1610</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><surname>Ghootae</surname> <given-names>Kim</given-names></string-name>, <string-name><surname>Jarrod A</surname> <given-names>Lewis-Peacock</given-names></string-name>, <string-name><surname>KennethA</surname> <given-names>Norman</given-names></string-name>, and <string-name><surname>NicholasB</surname> <given-names>Turk-Browne</given-names></string-name>. <article-title>Pruning of memories by context-based prediction error</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>111</volume>(<issue>24</issue>):<fpage>8997</fpage>&#x2013;<lpage>9002</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>Jarrod A</given-names> <surname>Lewis-Peacock</surname></string-name> and <string-name><given-names>Kenneth A</given-names> <surname>Norman</surname></string-name>. <article-title>Competition between items in working memory leads to forgetting</article-title>. <source>Nature Communications</source>, <volume>5</volume>, <year>2014</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Laurens van der</given-names> <surname>Maaten</surname></string-name> and <string-name><given-names>Geoffrey</given-names> <surname>Hinton</surname></string-name>. <article-title>Visualizing data using t-SNE</article-title>. <source>Journal of Machine Learning Research</source>, <volume>9</volume>(<month>Nov</month>):<fpage>2579</fpage>&#x2013;<lpage>2605</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>John P</given-names> <surname>Cunningham</surname></string-name> and <string-name><given-names>Byron M</given-names> <surname>Yu</surname></string-name>. <article-title>Dimensionality reduction for large-scale neural recordings</article-title>. <source>Nature Neuroscience</source>, <volume>17</volume>(<issue>11</issue>):<fpage>1500</fpage>&#x2013;<lpage>1509</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>, <string-name><given-names>Yashar</given-names> <surname>Ahmadian</surname></string-name>, <string-name><given-names>Daniel Gil</given-names> <surname>Ferreira</surname></string-name>, <string-name><given-names>Shinsuke</given-names> <surname>Koyama</surname></string-name>, <article-title>Kamiar Rah-nama Rad, Michael Vidne, Joshua Vogelstein, and Wei Wu. A new look at state-space models for neural data</article-title>. <source>Journal of Computational Neuroscience</source>, <volume>29</volume>(<issue>1&#x2013;2</issue>):<fpage>107</fpage>&#x2013;<lpage>126</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>Jakob H</given-names> <surname>Macke</surname></string-name>, <string-name><given-names>Lars</given-names> <surname>Buesing</surname></string-name>, <string-name><given-names>John P</given-names> <surname>Cunningham</surname></string-name>, <string-name><given-names>M Yu</given-names> <surname>Byron</surname></string-name>, <string-name><given-names>Krishna</given-names> <surname>V Shenoy</surname></string-name>, and <string-name><given-names>Maneesh</given-names> <surname>Sahani</surname></string-name>. <article-title>Empirical models of spiking in neural populations</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>1350</fpage>&#x2013;<lpage>1358</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>Scott W</given-names> <surname>Linderman</surname></string-name>, <string-name><given-names>Andrew C</given-names> <surname>Miller</surname></string-name>, <string-name><given-names>Ryan P</given-names> <surname>Adams</surname></string-name>, <string-name><given-names>David M</given-names> <surname>Blei</surname></string-name>, <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>, and <string-name><given-names>Matthew</given-names> <surname>J Johnson</surname></string-name>. <source>Recurrent switching linear dynamical systems</source>. arXiv preprint arXiv:<volume>1610</volume>. <fpage>08466</fpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Sussillo</surname></string-name>, <string-name><given-names>Rafal</given-names> <surname>Jozefowicz</surname></string-name>, <string-name><given-names>LF</given-names> <surname>Abbott</surname></string-name>, and <string-name><given-names>Chethan</given-names> <surname>Pandarinath</surname></string-name>. <article-title>LFADS - latent factor analysis via dynamical systems</article-title>. <source>In Advances in Neural Information Processing Systems</source>, <year>2016</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>Alexander B</given-names> <surname>Wiltschko</surname></string-name>, <string-name><given-names>Matthew J</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>Giuliano</given-names> <surname>Iurilli</surname></string-name>, <string-name><given-names>Ralph E</given-names> <surname>Peterson</surname></string-name>, <string-name><given-names>Jesse M</given-names> <surname>Katon</surname></string-name>, <string-name><given-names>Stan L</given-names> <surname>Pashkovski</surname></string-name>, <string-name><given-names>Victoria E</given-names> <surname>Abraira</surname></string-name>, <string-name><given-names>Ryan</given-names> <surname>P Adams</surname></string-name>, and <string-name><given-names>Sandeep</given-names> <surname>Robert Datta</surname></string-name>. <article-title>Mapping sub-second structure in mouse behavior</article-title>. <source>Neuron</source>, <volume>88</volume>(<issue>6</issue>):<fpage>1121</fpage>&#x2013;<lpage>1135</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><surname>Samuel</surname> <given-names>J Gershman</given-names></string-name> and <string-name><surname>David</surname> <given-names>M Blei</given-names></string-name>. <article-title>A tutorial on Bayesian nonparametric models</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>56</volume>(<issue>1</issue>):<fpage>1</fpage>&#x2013;<lpage>12</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>Samuel</given-names> <surname>Gershman</surname></string-name>, <string-name><given-names>Ahmed</given-names> <surname>Moustafa</surname></string-name>, and <string-name><given-names>Elliot</given-names> <surname>Ludvig</surname></string-name>. <article-title>Time representation in reinforcement learning models of the basal ganglia</article-title>. <source>Frontiers in Computational Neuro-science</source>, <volume>7</volume>:<fpage>194</fpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><given-names>Richard S</given-names> <surname>Sutton</surname></string-name> and <string-name><given-names>Andrew G</given-names> <surname>Barto</surname></string-name>. <article-title>Toward a modern theory of adaptive networks: expectation and prediction</article-title>. <source>Psychological Review</source>, <volume>88</volume>(<issue>2</issue>):<fpage>135</fpage>, <year>1981</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>Wolfram</given-names> <surname>Schultz</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>P</given-names> <surname>Read Montague</surname></string-name>. <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>, <volume>275</volume>(<issue>5306</issue>):<fpage>1593</fpage>&#x2013;<lpage>1599</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>Yael</given-names> <surname>Niv</surname></string-name>. <article-title>Reinforcement learning in the brain</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>53</volume> (<issue>3</issue>):<fpage>139</fpage>&#x2013;<lpage>154</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="book"><string-name><given-names>James</given-names> <surname>Durbin</surname></string-name> and <string-name><given-names>Siem</given-names> <surname>Jan Koopman</surname></string-name>. <source>Time series analysis by state space methods</source>, volume<volume>38</volume>. <publisher-name>Oxford University Press</publisher-name>, <year>2012</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="book"><string-name><given-names>Christian</given-names> <surname>Robert</surname></string-name> and <string-name><given-names>George</given-names> <surname>Casella</surname></string-name>. <source>Monte Carlo statistical methods</source>. <publisher-name>Springer Science &#x0026; Business Media</publisher-name>, <year>2013</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><surname>Michael</surname> <given-names>I Jordan</given-names></string-name>, <string-name><surname>Zoubin</surname> <given-names>Ghahramani</given-names></string-name>, <string-name><given-names>Tommi</given-names> <surname>S Jaakkola</surname></string-name> and <string-name><given-names>Lawrence</given-names> <surname>K Saul</surname></string-name>. <article-title>An introduction to variational methods for graphical models</article-title>. <source>Machine Learning</source>, <volume>37</volume>(<issue>2</issue>): <fpage>183</fpage>&#x2013;<lpage>233</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>Martin J</given-names> <surname>Wainwright</surname></string-name> and <string-name><given-names>Michael I</given-names> <surname>Jordan</surname></string-name>. <article-title>Graphical models, exponential families, and variational inference</article-title>. <source>Foundations and Trends in Machine Learning</source>, <volume>1</volume>(<issue>1&#x2013;2</issue>):<fpage>1</fpage>&#x2013;<lpage>305</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>Frank</given-names> <surname>Wood</surname></string-name>, <string-name><given-names>Jan-Willem</given-names> <surname>van de Meent</surname></string-name>, and <string-name><given-names>Vikash</given-names> <surname>Mansinghka</surname></string-name>. <article-title>A new approach to probabilistic programming inference</article-title>. <source>In AISTATS</source>, pages <fpage>1024</fpage>&#x2013;<lpage>1032</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>Bob</given-names> <surname>Carpenter</surname></string-name>, <string-name><given-names>Andrew</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>Matt</given-names> <surname>Hoffman</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Ben</given-names> <surname>Goodrich</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Betancourt</surname></string-name>, <string-name><given-names>Michael A</given-names> <surname>Brubaker</surname></string-name>, <string-name><given-names>Jiqiang</given-names> <surname>Guo</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Li</surname></string-name> and <string-name><given-names>Allen</given-names> <surname>Riddell</surname></string-name>. <article-title>Stan: A probabilistic programming language</article-title>. <source>Journal of Statistical Software</source>, <volume>20</volume>, <year>2016</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>Vikash</given-names> <surname>Mansinghka</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Selsam</surname></string-name>, and <string-name><given-names>Yura</given-names> <surname>Perov</surname></string-name>. <source>Venture: a higher-order probabilistic programming platform with programmable inference</source>. arXiv preprint arXiv:<volume>1404</volume>. <fpage>0099</fpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>Dustin</given-names> <surname>Tran</surname></string-name>, <string-name><given-names>Alp</given-names> <surname>Kucukelbir</surname></string-name>, <string-name><given-names>Adji B.</given-names> <surname>Dieng</surname></string-name>, <string-name><given-names>Maja</given-names> <surname>Rudolph</surname></string-name>, <string-name><given-names>Dawen</given-names> <surname>Liang</surname></string-name> and <string-name><given-names>David M.</given-names> <surname>Blei</surname></string-name>. <source>Edward: A library for probabilistic modeling, inference, and criticism</source>. arXiv preprint arXiv:<volume>1610</volume>. <fpage>09787</fpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="book"><string-name><given-names>Andrew</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>John B</given-names> <surname>Carlin</surname></string-name>, <string-name><given-names>Hal S</given-names> <surname>Stern</surname></string-name>, <string-name><given-names>David B</given-names> <surname>Dunson</surname></string-name>, <string-name><given-names>Aki</given-names> <surname>Vehtari</surname></string-name>, and <string-name><given-names>Donald B</given-names> <surname>Rubin</surname></string-name>. <source>Bayesian Data Analysis</source>. <publisher-name>CRC press</publisher-name>, 3rdedition, <year>2013</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>David JC</given-names> <surname>MacKay</surname></string-name>. <article-title>Bayesian interpolation</article-title>. <source>Neural Computation</source>, <volume>4</volume>(<issue>3</issue>):<fpage>415</fpage>&#x2013;<lpage>447</lpage>, <year>1992</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>Robert E</given-names> <surname>Kass</surname></string-name> and <string-name><given-names>Adrian E</given-names> <surname>Raftery</surname></string-name>. <article-title>Bayes factors</article-title>. <source>Journal of the American Statistical Association</source>, <volume>90</volume>(<issue>430</issue>):<fpage>773</fpage>&#x2013;<lpage>795</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>Radford M</given-names> <surname>Neal</surname></string-name>. <article-title>Annealed importance sampling</article-title>. <source>Statistics and Computing</source>, <volume>11</volume>(<issue>2</issue>): <fpage>125</fpage>&#x2013;<lpage>139</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><given-names>Roger</given-names> <surname>B Grosse</surname></string-name>, <string-name><given-names>Chris</given-names> <surname>J Maddison</surname></string-name>, and <string-name><given-names>Ruslan</given-names> <surname>R Salakhutdinov</surname></string-name>. <article-title>Annealing between distributions by averaging moments</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>2769</fpage>&#x2013;<lpage>2777</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><given-names>Roger</given-names> <surname>B Grosse</surname></string-name>, <string-name><given-names>Zoubin</given-names> <surname>Ghahramani</surname></string-name>, and <string-name><given-names>Ryan</given-names> <surname>P Adams</surname></string-name>. <source>Sandwiching the marginal likelihood using bidirectional Monte Carlo</source>. arXiv preprint arXiv:<volume>1511</volume>. <fpage>02543</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Carlson</surname></string-name>, <string-name><given-names>Patrick</given-names> <surname>Stinson</surname></string-name>, <string-name><given-names>Ari</given-names> <surname>Pakman</surname></string-name>, and <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Partition functions from Rao-Blackwellized tempered sampling</article-title>. In <source>Proceedings of The 33rd International Conference on Machine Learning</source>, pages <fpage>2896</fpage>&#x2013;<lpage>2905</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><string-name><given-names>Dennis V</given-names> <surname>Lindley</surname></string-name>. <article-title>On a measure of the information provided by an experiment</article-title>. <source>The Annals of Mathematical Statistics</source>, pages <fpage>986</fpage>&#x2013;<lpage>1005</lpage>, <year>1956</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Asymptotic theory of information-theoretic experimental design</article-title>. <source>Neural Computation</source>, <volume>17</volume>(<issue>7</issue>):<fpage>1480</fpage>&#x2013;<lpage>1507</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><given-names>Jeremy</given-names> <surname>Lewi</surname></string-name>, <string-name><given-names>Robert</given-names> <surname>Butera</surname></string-name>, and <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Sequential optimal design of neurophysiology experiments</article-title>. <source>Neural Computation</source>, <volume>21</volume>(<issue>3</issue>):<fpage>619</fpage>&#x2013;<lpage>687</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>Bobak</given-names> <surname>Shahriari</surname></string-name>, <string-name><given-names>Kevin</given-names> <surname>Swersky</surname></string-name>, <string-name><given-names>Ziyu</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Ryan</given-names> <surname>P Adams</surname></string-name> and <string-name><given-names>Nando</given-names> <surname>de Freitas</surname></string-name>. <article-title>Taking the human out of the loop: A review of Bayesian optimization</article-title>. <source>Proceedings of the IEEE</source>, <volume>104</volume>(<issue>1</issue>):<fpage>148</fpage>&#x2013;<lpage>175</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><string-name><given-names>Jonathan H</given-names> <surname>Huggins</surname></string-name> and <string-name><given-names>Liam</given-names> <surname>Paninski</surname></string-name>. <article-title>Optimal experimental design for sampling voltage on dendritic trees in the low-SNR regime</article-title>. <source>Journal of Computational Neuroscience</source>, <volume>32</volume>(<issue>2</issue>):<fpage>347</fpage>&#x2013;<lpage>366</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><string-name><surname>Ji</surname> <given-names>Hyun Bak</given-names></string-name>, <string-name><surname>Jung</surname> <given-names>Choi</given-names></string-name>, <string-name><given-names>Ilana</given-names> <surname>Witten</surname></string-name> and <string-name><given-names>Jonathan</given-names> <surname>W Pillow</surname></string-name>. <article-title>Adaptive optimal training of animal behavior</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>1939</fpage>&#x2013;<lpage>1947</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><string-name><given-names>James R</given-names> <surname>Lloyd</surname></string-name> and <string-name><given-names>Zoubin</given-names> <surname>Ghahramani</surname></string-name>. <article-title>Statistical model criticism using kernel two sample tests</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>829</fpage>&#x2013;<lpage>837</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Lopez-Paz</surname></string-name> and <string-name><given-names>Maxime</given-names> <surname>Oquab</surname></string-name>. <source>Revisiting classifier two-sample tests</source>. arXiv preprint arXiv:<volume>1610</volume>. <fpage>06545</fpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><string-name><given-names>Ian</given-names> <surname>Goodfellow</surname></string-name>, <string-name><given-names>Jean</given-names> <surname>Pouget-Abadie</surname></string-name>, <string-name><given-names>Mehdi</given-names> <surname>Mirza</surname></string-name>, <string-name><given-names>Bing</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>David</given-names> <surname>Warde-Farley</surname></string-name>, <string-name><given-names>Sherjil</given-names> <surname>Ozair</surname></string-name>, <string-name><given-names>Aaron</given-names> <surname>Courville</surname></string-name> and <string-name><given-names>Yoshua</given-names> <surname>Bengio</surname></string-name>. <article-title>Generative adversarial nets</article-title>. <source>In Advances in Neural Information Processing Systems</source>, pages <fpage>2672</fpage>&#x2013;<lpage>2680</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><string-name><surname>Roger</surname> <given-names>Grosse</given-names></string-name>, <string-name><given-names>Ruslan R</given-names> <surname>Salakhutdinov</surname></string-name>, <string-name><given-names>William T</given-names> <surname>Freeman</surname></string-name>, and <string-name><given-names>Joshua</given-names> <surname>B Tenenbaum</surname></string-name>. <article-title>Exploiting compositionality to explore a large space of model structures</article-title>. <source>Uncertainty and Artificial Intelligence (UAI)</source>, <year>2012</year>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><string-name><given-names>David K</given-names> <surname>Duvenaud</surname></string-name>, <string-name><given-names>James Robert</given-names> <surname>Lloyd</surname></string-name>, <string-name><given-names>Roger B</given-names> <surname>Grosse</surname></string-name>, <string-name><given-names>Joshua</given-names> <surname>B Tenenbaum</surname></string-name>, and <string-name><given-names>Zoubin</given-names> <surname>Ghahramani</surname></string-name>. <article-title>Structure discovery in nonparametric regression through compositional kernel search</article-title>. In <source>Proceedings of the International Conference on Machine Learning (ICML)</source>, pages <fpage>1166</fpage>&#x2013;<lpage>1174</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><string-name><given-names>Eric</given-names> <surname>Schulz</surname></string-name>, <string-name><given-names>Josh</given-names> <surname>Tenenbaum</surname></string-name>, <string-name><given-names>David K</given-names> <surname>Duvenaud</surname></string-name>, <string-name><given-names>Maarten</given-names> <surname>Speekenbrink</surname></string-name>, and <string-name><given-names>Samuel</given-names> <surname>J Gershman</surname></string-name>. <article-title>Probing the compositionality of intuitive functions</article-title>. <source>In Advances in Neural Information Processing Systems</source> <volume>29</volume>, pages <fpage>3729</fpage>&#x2013;<lpage>3737</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><string-name><given-names>Daniel</given-names> <surname>Durstewitz</surname></string-name>, <string-name><given-names>Georgia</given-names> <surname>Koppe</surname></string-name>, and <string-name><given-names>Hazem</given-names> <surname>Toutounji</surname></string-name>. <article-title>Computational models as statistical tools</article-title>. <source>Current Opinion in Behavioral Sciences</source>, <volume>11</volume>:<fpage>93</fpage>&#x2013;<lpage>99</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><string-name><given-names>Michael I</given-names> <surname>Jordan</surname></string-name><etal>et al.</etal> <article-title>On statistics, computation and scalability</article-title>. <source>Bernoulli</source>, <volume>19</volume>(<issue>4</issue>): <fpage>1378</fpage>&#x2013;<lpage>1390</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><string-name><given-names>Alex</given-names> <surname>Graves</surname></string-name>, <string-name><given-names>Greg</given-names> <surname>Wayne</surname></string-name>, <string-name><given-names>Malcolm</given-names> <surname>Reynolds</surname></string-name>, <string-name><given-names>Tim</given-names> <surname>Harley</surname></string-name>, <string-name><given-names>Ivo</given-names> <surname>Danihelka</surname></string-name>, <string-name><given-names>Agnieszka</given-names> <surname>Grabska-Barwi&#x0144;ska</surname></string-name>, <string-name><given-names>Sergio G&#x00F3;mez</given-names> <surname>Colmenarejo</surname></string-name>, <string-name><given-names>Edward</given-names> <surname>Grefenstette</surname></string-name>, <string-name><given-names>Tiago</given-names> <surname>Ramalho</surname></string-name>, <string-name><given-names>John</given-names> <surname>Agapiou</surname></string-name>, <etal>et al.</etal> <article-title>Hybrid computing using a neural network with dynamic external memory</article-title>. <source>Nature</source>, <volume>538</volume>(<issue>7626</issue>):<fpage>471</fpage>&#x2013;<lpage>476</lpage>, <year>2016</year>.</mixed-citation></ref></ref-list>
<fn-group>
<fn id="fn1">
<label><sup>1</sup></label>
<p>Code to run this example and reproduce <xref rid="fig2" ref-type="fig">Figures 2</xref> and <xref rid="fig3" ref-type="fig">3</xref> is available at <ext-link ext-link-type="uri" xlink:href="http://https://github.com/slinderman/tdlds">https://github.com/slinderman/tdlds</ext-link></p></fn>
<fn id="fn2">
<label><sup>2</sup></label>
<p>We denote the weights by <italic>z</italic> instead of something more traditional, like <italic>w</italic>, since this will highlight the connection to state space models</p></fn>
</fn-group></back></article>