<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/257741</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Animal Behavior and Cognition</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Liberal Detection Bias in the Unattended Periphery during Simulated Driving</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Li</surname>
<given-names>Musen Kingsley</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lau</surname>
<given-names>Hakwan</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Odegaard</surname>
<given-names>Brian</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Industrial Engineering, Tsinghua University</institution>, Beijing</aff>
<aff id="a2"><label>2</label><institution>Department of Psychology, University of California-Los Angeles</institution></aff>
<aff id="a3"><label>3</label><institution>Brain Research Institute, University of California-Los Angeles</institution></aff>
<aff id="a4"><label>4</label><institution>Department of Psychology, University of Hong Kong</institution></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Correspondence concerning this article should be addressed to Musen Kingsley Li or Brian Odegaard. Musen Kingsley Li, Shunde Building, Tsinghua University, Beijing, China 100084; Telephone: &#x002B;86 158-1078-3696; Email: <email>limusen.cn@gmail.com</email>. Brian Odegaard, Franz Hall, 502 Portola Plaza Los Angeles, CA 90095; Telephone: &#x002B;1 (651)491-5897; Email: <email>odegaard.brian@gmail.com</email>.</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>257741</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>31</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>1</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="257741.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Do we accurately perceive fine details in the visual periphery? While people often think they veridically perceive much of the visual surround, recent findings indicate that when asked to detect targets such as gratings embedded in visual noise, observers make more false alarms in the unattended periphery. Do these results from psychophysics studies generalize to naturalistic settings? We used a modern game engine to create a simulated driving environment where participants (as drivers) had to make judgments about the colors of pedestrians&#x2019; clothing in the periphery. Confirming our hypothesis based on previous psychophysics studies, we found that subjects showed liberal biases for unattended locations when detecting specific colors of pedestrians&#x2019; clothing. A second experiment showed that this finding was not simply due to a confirmation bias in decision-making when subjects were unsure. Together, these results support the idea that in everyday visual experience, there is subjective inflation of experienced detail in the periphery, which may happen at the decisional level.</p>
<p>Liberal Detection Bias in the Unattended Periphery during Simulated Driving</p>
</abstract>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Do we perceive fine details in the periphery of our visual field? Subjectively, it may seem that we perceive the unattended visual periphery in precise detail, and there is some evidence supporting this claim (<xref ref-type="bibr" rid="c1">Block, 2007</xref>, <xref ref-type="bibr" rid="c2">2011</xref>; <xref ref-type="bibr" rid="c10">Lamme, 2004</xref>, <xref ref-type="bibr" rid="c11">2006</xref>; <xref ref-type="bibr" rid="c24">Sperling, 1960</xref>). However, inattentional blindness (<xref ref-type="bibr" rid="c22">Simons &#x0026; Chabris, 1999</xref>) and change blindness (<xref ref-type="bibr" rid="c6">Grimes, 1996</xref>; <xref ref-type="bibr" rid="c17">Rensink, O&#x2019;Regan, &#x0026; Clark, 1997</xref>) experiments show that alterations to unattended elements in natural scenes are often unnoticed. Additionally, recent experiments reveal that coarse summary statistical properties can be perceived and remembered for unattended items, but individual details are lost (Ward, <xref ref-type="bibr" rid="c27">Bear, &#x0026; Scholl, 2016</xref>). Profound deficits are also revealed when subjects are asked simple questions about color perception in the periphery (see Box 2, Cohen, <xref ref-type="bibr" rid="c3">Dennett, &#x0026; Kanwisher, 2016</xref>). Thus, while perceptual deficits in the periphery are evident, a precise characterization of this deficit remains elusive, and overall the idea of impaired peripheral perception seems at odds with the subjective impression that we perceive the visual world in relatively uniform detail.</p>
<p>Previous work has addressed this question within the framework of Signal Detection Theory. Results show that observers tend to use liberal detection biases when evaluating peripheral or unattended stimuli, such as grating patterns embedded in noise (Rahnev, <xref ref-type="bibr" rid="c16">Maniscalco, et al., 2011</xref>; Solovey, <xref ref-type="bibr" rid="c23">Graney, &#x0026; Lau, 2015</xref>); that is, participants were more likely to say that items were presented in peripheral or unattended locations, even when they were not. These results were interpreted to reflect a subjective sense of inflated phenomenology in the unattended periphery, because detection biases could in principle reflect both subjective perception and decisional or response strategies (Witt, Taylor, <xref ref-type="bibr" rid="c28">Sugovic, &#x0026; Wixted, 2015</xref>). It was argued that a decisional or cognitive account of these biases is less likely because results remain consistent even when subjects are given feedback and training (Rahnev, <xref ref-type="bibr" rid="c16">Maniscalco, et al., 2011</xref>; <xref ref-type="bibr" rid="c23">Solovey et al., 2015</xref>).</p>
<p>If liberal biases reflect inflated visual phenomenology, we should expect these results to emerge in naturalistic settings, too. This question is important, because as noted by previous research, findings from artificial tasks may not be representative of the perceptual and decisional strategies used by the brain in more ecologically valid settings (<xref ref-type="bibr" rid="c5">Felsen &#x0026; Dan, 2005</xref>). Additionally, research indicates that while most processing of real-world scene information is intact with diminished attention, the depth of processing of this information does depend on attention (Groen, Ghebreab, <xref ref-type="bibr" rid="c7">Lamme, &#x0026; Scholte, 2016</xref>). Therefore, results from attentional cuing tasks based on a few simple stimuli on a gray background may not generalize well to naturalistic settings where the visual scene is complex. To address the question of whether liberal detection biases are evident when making judgments in the unattended periphery, we conducted a study where subjects engaged in a naturalistic task of simulated driving while they looked for (i.e., detected) specific colors of pedestrians&#x2019; clothing in the visual periphery. Unlike in previous studies (Rahnev, <xref ref-type="bibr" rid="c16">Maniscalco, et al., 2011</xref>; <xref ref-type="bibr" rid="c23">Solovey et al., 2015</xref>), the stimuli were not degraded by noise or reduced contrast; instead, near-threshold task difficulty was created more naturalistically by having the pedestrians move at a fast speed. We reasoned that if the previous results (Rahnev, <xref ref-type="bibr" rid="c16">Maniscalco, et al., 2011</xref>; <xref ref-type="bibr" rid="c23">Solovey et al., 2015</xref>) were not due to idiosyncratic strategies adopted in artificial psychophysics experiments, here, subjects should exhibit similar liberal detection biases in the unattended periphery as well.</p>
</sec>
<sec id="s2">
<title>Methods Participants</title>
<p>Twenty-six individuals (fifteen female, eleven male) participated in Experiment 1; mean age = 20.8, SD = 3.0. Fifteen individuals (twelve female, three male) participated in Experiment 2; mean age = 21.8, SD = 5.5. For both studies we sought to collect data around 20 observers as in previous work from our laboratory (<xref ref-type="bibr" rid="c14">Rahnev, Koizumi, McCurdy, D&#x2019;Esposito, &#x0026; Lau, 2015</xref>; <xref ref-type="bibr" rid="c15">Rahnev, Lau, &#x0026; de Lange, 2011</xref>). No statistical analyses reported in the paper were performed on partial data. All participants were students at the University of California-Los Angeles. All of them had normal or corrected-to-normal vision, were 18 years or older, and did not have a history of seizures, epilepsy, stroke, or head trauma. Each participant gave informed consent and received either credits or monetary compensation of &#x0024;10 per hour. This study was approved by the UCLA Institutional Review Board.</p>
</sec>
<sec id="s3">
<title>Stimuli and Apparatus</title>
<p>Stimuli were generated using Unreal Engine 4 (Epic Games, Cary, NC, USA) to create game-like naturalistic environments and stimuli. Participants were instructed to drive a vehicle along the straight two-lane road in a small town (<xref ref-type="fig" rid="fig1">Fig. 1A</xref>) and stop at the stoplight at the first intersection. The vehicle was parked 82 meters (in virtual distance) away from the stop line at the intersection at the beginning of each trial. When the vehicle was 43 meters away from the stop line, in 80&#x0025; of the trials, a pre-cue textbox was displayed for approximately four seconds in the upper center of the screen, reading either &#x201C;Attention to the LEFT&#x201D; or &#x201C;Attention to the RIGHT&#x201D; (<xref ref-type="fig" rid="fig1"><xref ref-type="fig" rid="fig1">Fig 1B</xref></xref>). Participants were informed that if a pre-cue textbox appeared, there was 75&#x0025; chance that the item they would have to answer a detection question about would be at the same location as indicated by the pre-cue (&#x201C;valid&#x201D; trials), and there was 25&#x0025; chance that the item they would have to answer a detection question about would be at a different location as indicated by the pre-cue (&#x201C;invalid&#x201D; trials). They were instructed to allocate attention equally to both the left and right locations if no pre-cue text was presented (&#x201C;baseline&#x201D; trials), which accounted for 20&#x0025; of the total trials.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>The task design of both experiments. (A) The start of each trial. Vehicles started from a parked position near the end of a straight, two-lane road in a small town, 82 meters away from the stop line of the intersection. (B) The attention cue. When the vehicle was 43 meters away from the intersection, in 80&#x0025; of the trials, a pre-cue textbox was displayed in the upper central portion of the screen, which indicated the direction that subjects were to attend when stopped at the intersection. (C) Fixation validation. Before stimuli were presented, each participant&#x2019;s fixation was continuously monitored to ensure he/she was fixating on the red stoplight for one full second. The white dotted circle indicates the position of the red light. (D) Presentation of stimuli. Two people wearing shirts of different colors ran out from behind two telephone booths positioned on each side of the street, and then turned around before getting halfway across the intersection. The two white, dotted circles indicate the positions of the two people. (E) The yes/no detection question. This question was presented one second after the stimuli disappeared. (F) The confidence question. After answering the yes/no question, participants were also asked to report their confidence level (1-4) regarding their choice. colors for Experiment 2 (red, pink, orange, yellow, green, blue, purple, brown, white, gray, and black) on each trial (<xref ref-type="fig" rid="fig1"><xref ref-type="fig" rid="fig1">Fig. 1D</xref></xref>). These male pedestrians quickly ran out from behind telephone booths simultaneously at the speed of 17.5&#x00B0; / second after the vehicle had stopped for one second, and then quickly ran back behind the telephone booths. They were presented for 300 milliseconds in total. 1000 ms after the stimuli disappeared, a yes-no question (e.g., &#x201C;Was the shirt color of the person on the left yellow?&#x201D; or &#x201C;Was the shirt color of the person on the right yellow?&#x201D;) was presented (<xref ref-type="fig" rid="fig1"><xref ref-type="fig" rid="fig1">Fig. 1E</xref></xref>). The probability that the correct choice was &#x201C;Yes&#x201D; or &#x201C;No&#x201D; were both 50&#x0025;, and participants were told this explicitly in advance. In Experiment 1, the target color was always yellow, while in Experiment 2, the target color was randomly picked from the seven possible colors in each trial. After answering the yes-no question, participants were also asked to report their confidence level regarding their choice from 1 (low confidence) to 4 (high confidence) (<xref ref-type="fig" rid="fig1"><xref ref-type="fig" rid="fig1">Fig. 1F</xref></xref>).</p></caption>
<graphic xlink:href="257741_fig1.tif"/>
</fig>
<p>Upon reaching the intersection, the vehicle was automatically moved to a fixed position to ensure the stimuli were presented in identical fashion on the screen on each trial. After the vehicle was fully stopped, the pre-cue text disappeared. Then, the participant&#x2019;s fixation was continuously monitored to ensure the participant was fixating on the red light for one second (we set the tolerance of distance between fixation and center of the red light as 2.5&#x00B0; in visual angle) (<xref ref-type="fig" rid="fig1">Fig. 1C</xref>). For details of eye tracking, see Supplementary Methods. The stimuli of interest in this task were two running male individuals, with shirt colors randomly drawn from seven potential colors for Experiment 1 (yellow, red, orange, green, blue, purple and gray) or eleven potential</p>
<p>Stimuli were shown on a 24-inch monitor with 60 Hz refresh rate and resolution of 1280 &#x00D7;1024 pixels. Each shirt was approximately 1.1&#x00B0; &#x00D7; 1.0&#x00B0; in visual angles, and was located 15.4&#x00B0; - 17.6&#x00B0; away from fixation while the stimuli were moving. Participants were seated 60 cm from the screen, and viewed the screen freely with their head unrestrained.</p>
</sec>
<sec id="s4">
<title>Procedure</title>
<p>In both experiments, all participants were required to complete two sessions; the two sessions occurred roughly one week apart. The first session included eye tracker calibration, 15 practice trials, and 210 experiment trials. The second session included eye tracker calibration and 270 experiment trials. Participants were instructed to take a break of up to 60 seconds after every 30 trials.</p>
</sec>
<sec id="s5">
<title>Results</title>
<sec id="s5a">
<title>Experiment 1: Evaluating detection biases for one specific color</title>
<p>To ensure participants were fixating as instructed, we analyzed their eye gaze data at 17 ms (i.e., time of one frame) before stimuli were presented. Participants&#x2019; fixations when stimuli were presented from every trial in Experiment 1 are illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>, which shows that subjects were fixating properly, and stimuli were presented in the periphery of our participants&#x2019; visual fields in every trial.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Participants&#x2019; fixations at 17 ms (i.e., time of one frame) before stimuli were presented from every trial in Experiment 1. Each black point represents a fixation from one of the two eyes, and fixation points from both eyes are plotted in the figure. The fixations of almost all subjects are on or near the stoplight in every trial.</p></caption>
<graphic xlink:href="257741_fig2.tif"/>
</fig>
<p>Next, before conducting Signal Detection Theoretical (SDT) analyses, we assessed the equal variance assumption from SDT and found significant deviations in some subjects (Supplementary Methods, Supplementary <xref ref-type="fig" rid="fig1">Fig. 1</xref>). Because of this, in subsequent SDT analyses we used the measures <inline-formula><alternatives><inline-graphic xlink:href="257741_inline1.gif"/></alternatives></inline-formula> (sensitivity) and <italic>c</italic><sub><italic>a</italic></sub> (i.e., the criterion, or response bias) to account for unequal variances; this was possible because in addition to yes/no answers, we also collected confidence ratings and could perform a full ROC analysis with multiple criteria points in ROC space for each subject.</p>
<p>For our primary analyses, we conducted Mauchly&#x2019;s test and repeated measures ANOVAs to analyze the effects of attention on the percentage of correct responses, <inline-formula><alternatives><inline-graphic xlink:href="257741_inline2.gif"/></alternatives></inline-formula> and <italic>c</italic><sub><italic>a</italic></sub>. Overall, performance was similar across attention conditions (<xref ref-type="fig" rid="fig3">Fig. 3A</xref>), and the percentage of correct trials did not significantly differ across attention levels,</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Behavioral results from Experiment 1. (A) The percentage of correct responses across attention conditions. While subjects exhibited the best performance for valid attention trials and the lowest performance for invalid trials, the conditions were not significantly different from one another. Bars represent averages, error bars represent SEM. (B) <inline-formula><alternatives><inline-graphic xlink:href="257741_inline12.gif"/></alternatives></inline-formula> and <italic>c</italic><sub><italic>a</italic></sub> across attention conditions. <inline-formula><alternatives><inline-graphic xlink:href="257741_inline13.gif"/></alternatives></inline-formula> values were quite consistent across attention conditions. <italic>c</italic><sub><italic>a</italic></sub> under inattention (i.e., invalid trials) was significantly lower than <italic>c</italic><sub><italic>a</italic></sub> in the valid or baseline conditions, providing evidence for a liberal detection bias. Bars represent the average values across subjects; error bars represent the standard error of the mean. <italic>&#x002A;&#x002A;p &#x003C;</italic> .01, NS: not significant.</p></caption>
<graphic xlink:href="257741_fig3.tif"/>
</fig>
<p><italic>F</italic>(2, 50) = 0.97, <italic>p</italic> = .387. This indicates the effects of attentional cuing were likely modest. However, performance was still highest in the valid attention trials and lowest in the invalid attention trials.</p>
<p>Similar to the effect of attention on the percentage correct, the average <inline-formula><alternatives><inline-graphic xlink:href="257741_inline3.gif"/></alternatives></inline-formula> was quite consistent across attention conditions (<xref ref-type="fig" rid="fig3">Fig. 3B</xref>) and <inline-formula><alternatives><inline-graphic xlink:href="257741_inline4.gif"/></alternatives></inline-formula> did not significantly differ across attention levels, <italic>F</italic>(2, 50) = 0.38, <italic>p</italic> = .685. However, when we compared <italic>c</italic><sub><italic>a</italic></sub> across attention conditions, <italic>c</italic><sub><italic>a</italic></sub> values were significantly different across attention levels, <italic>F</italic>(1.71, 42.80) = 7.91, <italic>p</italic> = .002 (the degrees of freedom were corrected using Huynh-Feldt estimates of sphericity, &#x03F5; = .86). Post-hoc paired <italic>t</italic>-tests indicated that the difference of <italic>c</italic><sub><italic>a</italic></sub> between the valid condition and invalid condition was significant, <italic>t</italic>(25) = 3.25, <italic>p</italic> = .003; the difference of <italic>c</italic><sub><italic>a</italic></sub> between baseline condition and invalid condition was also significant, <italic>t</italic>(25) = 2.83, <italic>p</italic> = .009. This provided evidence that participants adopted more liberal criteria for making detection judgments when the target was unattended and presented in periphery.</p>
</sec>
<sec id="s5b">
<title>Experiment 2: Evaluating detection biases in the periphery for an array of colors</title>
<p>In Experiment 1, the detection question that was asked on every trial involved a constant target: a person in a yellow shirt. One could argue that a liberal detection bias may be observed due to the sheer fact that subjects may have a tendency to respond &#x201C;Yes&#x201D; whenever they are uncertain. That is, our primary finding of a liberal detection criterion could be driven by a confirmation bias at the decisional level. To test if this is the case, in Experiment 2, we changed the target color on each trial, and participants only knew of the color they were to detect when they were prompted by the detection question. This way, participants could not anticipate what target to detect beforehand. If the liberal detection bias we observed in Experiment 1 were due to a confirmation bias in responding, we should still see the effect here. On the other hand, we would not expect similar results if they were contingent on the fact that in Experiment 1 subjects were able to form a template for the target color before they were prompted.</p>
<p>As in Experiment 1, we evaluated participants&#x2019; fixations at 17 ms before stimuli were presented. The consistent fixation positions indicated that stimuli were indeed presented in the periphery of our participants&#x2019; visual fields in every trial (Supplementary Fig. 3).</p>
<p>We evaluated the percent correct in each of the three attention conditions from Experiment 2, and also calculated <inline-formula><alternatives><inline-graphic xlink:href="257741_inline5.gif"/></alternatives></inline-formula> and <italic>c</italic><sub><italic>a</italic></sub> to measure the sensitivity and response criterion for each subject. Specifically, we conducted Mauchly&#x2019;s test and repeated measures ANOVAs to evaluate the effect of attention on the percent correct, <inline-formula><alternatives><inline-graphic xlink:href="257741_inline6.gif"/></alternatives></inline-formula> and <italic>c</italic><sub><italic>a</italic></sub>. Overall, attention increased the percentage of correct responses, as participants exhibited the highest performance in the valid attention condition and the lowest performance in the invalid condition (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). The percentage of correct trials was significantly different across attention levels, <italic>F</italic>(2, 50) = 5.29, <italic>p</italic> = .011. Post-hoc paired <italic>t</italic>-tests indicated that the difference in the percentage of correct responses between the valid condition and invalid condition was significant, <italic>t</italic>(14) = 2.96, <italic>p</italic> = .010; the difference in the percentage of correct responses between the valid condition and baseline condition was also significant, <italic>t</italic>(14) = 2.40, <italic>p</italic> = .031, which suggested that participants performed better when allocating full attention to stimuli, rather than distributing attention across the two locations.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Behavioral results for Experiment 2. (A) The percentage of correct responses across attention conditions. The percentage of correct responses for valid trials was significantly larger than the percentage correct for baseline and invalid trials. (B) <inline-formula><alternatives><inline-graphic xlink:href="257741_inline14.gif"/></alternatives></inline-formula> and <italic>c</italic><sub><italic>a</italic></sub> across attention conditions. Similar to the effect of attention on percentage of correct responses, <inline-formula><alternatives><inline-graphic xlink:href="257741_inline15.gif"/></alternatives></inline-formula> was significantly greater in the valid attention condition compared to the invalid condition. ca did not significantly differ across attention conditions, which indicated that participants used similar internal criteria to make perceptual judgments in all attention conditions. <italic>&#x002A;p &#x003C;</italic> .05, NS: not significant.</p></caption>
<graphic xlink:href="257741_fig4.tif"/>
</fig>
<p>The average <inline-formula><alternatives><inline-graphic xlink:href="257741_inline7.gif"/></alternatives></inline-formula> showed a similar trend compared to the percentage of correct responses: <inline-formula><alternatives><inline-graphic xlink:href="257741_inline8.gif"/></alternatives></inline-formula> increased with attention significantly (Figure reffig:res2B), <italic>F</italic>(1.44, 20.22) = 4.37, <italic>p</italic> = .037 (the degrees of freedom were corrected using Greenhouse-Geisser estimates of sphericity, &#x03F5;= .72). Post-hoc paired t-tests indicated that the difference of <inline-formula><alternatives><inline-graphic xlink:href="257741_inline9.gif"/></alternatives></inline-formula> between the valid condition and invalid condition was significant, <italic>t</italic>(14) = 2.42, <italic>p</italic> = .029, while the difference of <inline-formula><alternatives><inline-graphic xlink:href="257741_inline10.gif"/></alternatives></inline-formula> between the baseline condition and invalid condition was not significant, <italic>t</italic>(14) = 1.99<italic>,p</italic> = .067; the difference of <inline-formula><alternatives><inline-graphic xlink:href="257741_inline11.gif"/></alternatives></inline-formula> between the valid condition and baseline condition was also not significant, <italic>t</italic>(14) = 0.79, <italic>p</italic> = .441. As for the response criteria <italic>c</italic><sub><italic>a</italic></sub>, the results showed that <italic>c</italic><sub><italic>a</italic></sub> did not significantly differ across attention levels, <italic>F</italic>(2, 28) = 0.50, <italic>p</italic> = .614. Importantly, these response criteria were positive, meaning they were much more conservative than those observed in Experiment 1. This finding indicates that our results in Experiment 1 were not due to a sheer confirmation bias at the decisional level (see Discussion).</p>
</sec>
</sec>
<sec id="s6">
<title>Discussion</title>
<p>In this study, we investigated how subjects detected colorful stimuli in the unattended periphery in a naturalistic environment. In our first experiment, on each trial, we asked observers whether an individual wearing a shirt with a specific color (yellow) had been presented at a specific location. Results showed that observers exhibited higher numbers of false alarms (Supplementary <xref ref-type="fig" rid="fig4">Fig. 4</xref>) (i.e., saying a yellow shirt was present, even when it was not) in unattended locations in the visual periphery, compared to locations that were fully or partially attended. This tendency to use liberal detection criteria in unattended or peripheral locations has been shown previously in artificial settings (<xref ref-type="bibr" rid="c16">Rahnev, Maniscalco, et al., 2011</xref>; <xref ref-type="bibr" rid="c23">Solovey et al., 2015</xref>). Here, we confirmed the hypothesis that this detection bias extends to more naturalistic stimuli and tasks, too. In our second experiment, on each trial, we asked observers whether an individual wearing a shirt with a particular color had been presented at a specific location, but in this experiment, we varied the target color randomly from trial to trial. Results showed that subjects used relatively conservative perceptual criteria (i.e., were relatively reluctant to say a color was present) when making detection-related judgments in this experiment, regardless of the amount of attention that was allocated to a given location.</p>
<p>This ruled out the interpretation that the results in Experiment 1 were only due to confirmation bias at the decisional level.</p>
<p>One important question which remains is what it means when people say they see the target more often. Traditionally, it is thought that much of peripheral vision is &#x2018;filled in&#x2019; via top-down mechanisms (<xref ref-type="bibr" rid="c9">Komatsu, 2006</xref>). However, it has also been reported that people trust unreliable, filled-in percepts more than precepts based on external input (<xref ref-type="bibr" rid="c4">Ehinger, Hausser, Ossandon, &#x0026; Konig, 2017</xref>), suggesting that filling-in may not be the complete mechanism to explain peripheral phenomenology, and that decisional or metacognitive mechanisms are also involved. In our study, perhaps the findings of detection bias in the unattended periphery can also be interpreted as congruent with this account involving mechanisms at the decisional or metacognitive level. Importantly, just because the effect is to be thought of at the &#x2018;decisional&#x2019; level does not mean that this is unrelated to perceptual phenomenology; criterion effects can also reflect subjective percept (<xref ref-type="bibr" rid="c13">Phillips, 2016</xref>; <xref ref-type="bibr" rid="c28">Witt et al., 2015</xref>). This interpretation is in line with previous findings that people tend to overestimate their ability to detect changes in change blindness experiments (Levin, Momen, <xref ref-type="bibr" rid="c12">Drivdahl, &#x0026; Simons, 2000</xref>), and in a sense, people are not subjectively aware of their poor acuity and color perception in the periphery (<xref ref-type="bibr" rid="c3">Cohen et al., 2016</xref>).</p>
<p>In terms of practical implications, if people tend to confirm what they expect whenever they don&#x2019;t attend, this raises an important issue regarding driving safety. Many people are optimistic and tend to expect things to be positive (<xref ref-type="bibr" rid="c19">Sharot, 2011</xref>; Sharot, Guitart-Masip, Korn, <xref ref-type="bibr" rid="c20">Chowdhury, &#x0026; Dolan, 2012</xref>; Sharot, Riccardi, <xref ref-type="bibr" rid="c21">Raio, &#x0026; Phelps, 2007</xref>), so they may tend to mistakenly detect hazards that present in unattended periphery as no danger, while what is actually happening is they just don&#x2019;t see the hazards. Similar results have been found in previous studies where drivers showed conservative criteria in hazard detection regardless of driving experience (<xref ref-type="bibr" rid="c25">Ventsislavova et al., 2016</xref>; <xref ref-type="bibr" rid="c26">Wallis &#x0026; Horswill, 2007</xref>). Hazard detection is a special detection task, because the penalty for a miss and a false alarm is different: a miss may cause a crash, while a false alarm may only lead to unnecessary brakes; thus, the criterion in hazard detection task is closely related with driving safety. In our research, the task is to detect pedestrian when the vehicle has stopped. However, in real driving, most of the hazards are presented while driving, which is quite different from our task. Future research should more systematically address how inattention affects hazard detection judgment while driving. Specifically, while the impact of distractions (e.g., due to phone calls and text messaging) on driving performance is well known (Haigney, <xref ref-type="bibr" rid="c8">Taylor, &#x0026; Westerman, 2000</xref>; <xref ref-type="bibr" rid="c18">Rumschlag et al., 2015</xref>), the impact on specific aspects of the perceptual decision making process remains relatively unexplored.</p>
<p>One limitation of our study is that the attention manipulation wasn&#x2019;t overly strong in Experiment 1. Yet there is still a trend that the performance increased with attention, and we obtained the effect that people showed liberal detection bias in the unattended periphery. Also, in our study we compared the criteria when the naturalistic stimuli were presented in the periphery at equal eccentricity, between validly cued and invalidly cued conditions. It is possible that a stronger difference in criteria can be found when naturalistic stimuli are presented in the center vs. the periphery, as has been done in previous studies using artificial stimuli (<xref ref-type="bibr" rid="c23">Solovey et al., 2015</xref>). We hypothesize that the decisional effects we obtained here may generalize to these other conditions too, using naturalistic stimuli. We hope this can be tested in the future.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by a grant from the Air Force Office of Scientific Research (FA-9550-15-1-0110) to HL.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Block</surname>, <given-names>N.</given-names></string-name> (<year>2007</year>). <article-title>Consciousness, accessibility, and the mesh between psychology and neuroscience</article-title>. <source>The Behavioral and brain sciences</source>, <volume>30</volume>(<issue>5&#x2013;6</issue>), <fpage>481</fpage>&#x2013;<lpage>99</lpage>; discussion 499-548.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Block</surname>, <given-names>N.</given-names></string-name> (<year>2011</year>). <article-title>Perceptual consciousness overflows cognitive access</article-title>. <source>Trends in cognitive sciences</source>, <volume>15</volume>(<issue>12</issue>), <fpage>567</fpage>&#x2013;<lpage>575</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Dennett</surname>, <given-names>D. C.</given-names></string-name>, &#x0026; <string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name> (<year>2016</year>). <article-title>What is the bandwidth of perceptual experience?</article-title> <source>Trends in cognitive sciences</source>, <volume>20</volume>(<issue>5</issue>), <fpage>324</fpage>&#x2013;<lpage>335</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="other"><string-name><surname>Ehinger</surname>, <given-names>B. V.</given-names></string-name>, <string-name><surname>H&#x00E4;usser</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Ossandon</surname>, <given-names>J. P.</given-names></string-name>, &#x0026; <string-name><surname>K&#x00F6;nig</surname>, <given-names>P.</given-names></string-name> (<year>2017</year>). <article-title>Humans treat unreliable filled-in percepts as more real than veridical ones</article-title>. <source>eLife</source>, <fpage>6</fpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Felsen</surname>, <given-names>G.</given-names></string-name>, &#x0026; <string-name><surname>Dan</surname>, <given-names>Y.</given-names></string-name> (<year>2005</year>). <article-title>A natural approach to studying vision</article-title>. <source>Nature neuroscience</source>, <volume>8</volume> (<issue>12</issue>), <fpage>1643</fpage>&#x2013;<lpage>1646</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="book"><string-name><surname>Grimes</surname>, <given-names>J. A.</given-names></string-name> (<year>1996</year>). <chapter-title>On the failure to detect changes in scenes across saccades</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K</given-names>. <surname>Akins</surname></string-name> (Ed.)</person-group>, <source>Perception</source>. <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Groen</surname>, <given-names>I. I. A.</given-names></string-name>, <string-name><surname>Ghebreab</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lamme</surname>, <given-names>V. A. F.</given-names></string-name>, &#x0026; <string-name><surname>Scholte</surname>, <given-names>H. S.</given-names></string-name> (<year>2016</year>). <article-title>The time course of natural scene perception with reduced attention</article-title>. <source>Journal of neurophysiology</source>, <volume>115</volume>(<issue>2</issue>), <fpage>931</fpage>&#x2013;<lpage>946</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Haigney</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Taylor</surname>, <given-names>R. G.</given-names></string-name>, &#x0026; <string-name><surname>Westerman</surname>, <given-names>S. J.</given-names></string-name> (<year>2000</year>). <article-title>Concurrent mobile (cellular) phone use and driving performance: task demand characteristics and compensatory processes</article-title>. <source>Transportation research. Part F, Traffic psychology and behaviour</source>, <volume>3</volume>(<issue>3</issue>), <fpage>113</fpage>&#x2013;<lpage>121</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Komatsu</surname>, <given-names>H.</given-names></string-name> (<year>2006</year>). <article-title>The neural mechanisms of perceptual filling-in</article-title>. <source>Nature reviews Neuroscience</source>, <volume>7</volume>(<issue>3</issue>), <fpage>220</fpage>&#x2013;<lpage>231</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Lamme</surname>, <given-names>V. A. F.</given-names></string-name> (<year>2004</year>). <article-title>Separate neural definitions of visual consciousness and visual attention; a case for phenomenal awareness</article-title>. <source>Neural networks: the official journal of the International Neural Network Society</source>, <volume>17</volume>(<issue>5&#x2013;6</issue>), <fpage>861</fpage>&#x2013;<lpage>872</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Lamme</surname>, <given-names>V. A. F.</given-names></string-name> (<year>2006</year>). <article-title>Towards a true neural stance on consciousness</article-title>. <source>Trends in cognitive sciences</source>, <volume>10</volume>(<issue>11</issue>), <fpage>494</fpage>&#x2013;<lpage>501</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Levin</surname>, <given-names>D. T.</given-names></string-name>, <string-name><surname>Momen</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Drivdahl</surname>, <given-names>S. B.</given-names></string-name>, &#x0026; <string-name><surname>Simons</surname>, <given-names>D. J.</given-names></string-name> (<year>2000</year>). <article-title>Change blindness blindness: The metacognitive error of overestimating change-detection ability</article-title>. <source>Visual cognition</source>, <volume>7</volume>(<issue>1&#x2013;3</issue>), <fpage>397</fpage>&#x2013;<lpage>412</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Phillips</surname>, <given-names>I.</given-names></string-name> (<year>2016</year>). <article-title>Naive realism and the science of (some) illusions</article-title>. <source>Philosophical Topics</source>, <volume>44</volume> (<issue>2</issue>), <fpage>353</fpage>&#x2013;<lpage>380</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Rahnev</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Koizumi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>McCurdy</surname>, <given-names>L. Y.</given-names></string-name>, <string-name><surname>D&#x2019;Esposito</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Lau</surname>, <given-names>H.</given-names></string-name> (<year>2015</year>). <article-title>Confidence leak in perceptual decision making</article-title>. <source>Psychological science</source>, <volume>26</volume>(<issue>11</issue>),<fpage>1664</fpage>&#x2013;<lpage>1680</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Rahnev</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Lau</surname>, <given-names>H.</given-names></string-name>, &#x0026; <string-name><surname>de Lange</surname>, <given-names>F. P.</given-names></string-name> (<year>2011</year>). <article-title>Prior expectation modulates the interaction between sensory and prefrontal regions in the human brain</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>31</volume> (<issue>29</issue>), <fpage>10741</fpage>&#x2013;<lpage>10748</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Rahnev</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Maniscalco</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Graves</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>de Lange</surname>, <given-names>F. P.</given-names></string-name>, &#x0026; <string-name><surname>Lau</surname>, <given-names>H.</given-names></string-name> (<year>2011</year>). <article-title>Attention induces conservative subjective biases in visual perception</article-title>. <source>Nature neuroscience</source>, <volume>14</volume> (<issue>12</issue>), <fpage>1513</fpage>&#x2013;<lpage>1515</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Rensink</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>O&#x2019;Regan</surname>, <given-names>J. K.</given-names></string-name>, &#x0026; <string-name><surname>Clark</surname>, <given-names>J. J.</given-names></string-name> (<year>1997</year>). <article-title>To see or not to see: The need for attention to perceive changes in scenes</article-title>. <source>Psychological science</source>, <volume>8</volume>(<issue>5</issue>), <fpage>368</fpage>&#x2013;<lpage>373</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Rumschlag</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Palumbo</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Head</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>George</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Commissaris</surname>, <given-names>R. L.</given-names></string-name> (<year>2015</year>). <article-title>The effects of texting on driving performance in a driving simulator: the influence of driver age</article-title>. <source>Accident analysis and prevention</source>, <volume>74</volume>, <fpage>145</fpage>&#x2013;<lpage>149</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Sharot</surname>, <given-names>T.</given-names></string-name> (<year>2011</year>). <article-title>The optimism bias</article-title>. <source>Current biology: CB</source>, <volume>21</volume> (<issue>23</issue>), <fpage>R941</fpage>&#x2013;<lpage>5</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Sharot</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Guitart-Masip</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Korn</surname>, <given-names>C. W.</given-names></string-name>, <string-name><surname>Chowdhury</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>2012</year>). <article-title>How dopamine enhances an optimism bias in humans</article-title>. <source>Current biology: CB</source>, <volume>22</volume> (<issue>16</issue>), <fpage>1477</fpage>&#x2013;<lpage>1481</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Sharot</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Riccardi</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Raio</surname>, <given-names>C. M.</given-names></string-name>, &#x0026; <string-name><surname>Phelps</surname>, <given-names>E. A.</given-names></string-name> (<year>2007</year>). <article-title>Neural mechanisms mediating optimism bias</article-title>. <source>Nature</source>, <volume>450</volume>(<issue>7166</issue>), <fpage>102</fpage>&#x2013;<lpage>105</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Simons</surname>, <given-names>D. J.</given-names></string-name>, &#x0026; <string-name><surname>Chabris</surname>, <given-names>C. F.</given-names></string-name> (<year>1999</year>). <article-title>Gorillas in our midst: sustained inattentional blindness for dynamic events</article-title>. <source>Perception</source>, <volume>28</volume>(<issue>9</issue>), <fpage>1059</fpage>&#x2013;<lpage>1074</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Solovey</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Graney</surname>, <given-names>G. G.</given-names></string-name>, &#x0026; <string-name><surname>Lau</surname>, <given-names>H.</given-names></string-name> (<year>2015</year>). <article-title>A decisional account of subjective inflation of visual perception at the periphery</article-title>. <source>Attention, perception &#x0026; psychophysics</source>, <volume>77</volume>(<issue>1</issue>), <fpage>258</fpage>&#x2013;<lpage>271</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Sperling</surname>, <given-names>G.</given-names></string-name> (<year>1960</year>). <article-title>the Information Available in Brief Visual Presentations</article-title>. <source>Psychological Monographs: General and Applied</source>, <volume>74</volume> (<issue>11</issue>), <fpage>1</fpage>&#x2013;<lpage>29</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Ventsislavova</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gugliotta</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pena-Suarez</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Garcia-Fernandez</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Eisman</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Crundall</surname>, <given-names>D.</given-names></string-name>, &#x0026; <string-name><surname>Castro</surname>, <given-names>C.</given-names></string-name> (<year>2016</year>). <article-title>What happens when drivers face hazards on the road?</article-title> <source>Accident analysis and prevention</source>, <volume>91</volume>, <fpage>43</fpage>&#x2013;<lpage>54</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Wallis</surname>, <given-names>T. S. A.</given-names></string-name>, &#x0026; <string-name><surname>Horswill</surname>, <given-names>M. S.</given-names></string-name> (<year>2007</year>). <article-title>Using fuzzy signal detection theory to determine why experienced and trained drivers respond faster than novices in a hazard perception test</article-title>. <source>Accident analysis and prevention</source>, <volume>39</volume>(<issue>6</issue>), <fpage>1177</fpage>&#x2013;<lpage>1185</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Ward</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Bear</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Scholl</surname>, <given-names>B. J.</given-names></string-name> (<year>2016</year>). <article-title>Can you perceive ensembles without perceiving individuals?: The role of statistical perception in determining whether awareness overflows access</article-title>. <source>Cognition</source>, <volume>152</volume>, <fpage>78</fpage>&#x2013;<lpage>86</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Witt</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Taylor</surname>, <given-names>J. E. T.</given-names></string-name>, <string-name><surname>Sugovic</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Wixted</surname>, <given-names>J. T.</given-names></string-name> (<year>2015</year>). <article-title>Signal detection measures cannot distinguish perceptual biases from response biases</article-title>. <source>Perception</source>, <volume>44</volume> (<issue>3</issue>), <fpage>289</fpage>&#x2013;<lpage>300</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
