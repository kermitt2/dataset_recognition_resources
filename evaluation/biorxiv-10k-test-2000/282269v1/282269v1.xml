<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/282269</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Bayesian Mixture Modelling Approach For Spatial Proteomics</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5669-8506</contrib-id>
<name>
<surname>Crook</surname>
<given-names>Oliver M.</given-names>
</name>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2989-2052</contrib-id>
<name>
<surname>Mulvey</surname>
<given-names>Claire M.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5931-7489</contrib-id>
<name>
<surname>Kirk</surname>
<given-names>Paul D. W.</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0594-6543</contrib-id>
<name>
<surname>Lilley</surname>
<given-names>Kathryn S.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1520-2268</contrib-id>
<name>
<surname>Gatto</surname>
<given-names>Laurent</given-names>
</name>
<xref ref-type="author-notes" rid="n2">&#x2020;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Computational Proteomics Unit, Department of Biochemistry, University of Cambridge</institution>, Tennis Court Road, Cambridge, CB2 1QR, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>Cambridge Centre for Proteomics, Department of Biochemistry, University of Cambridge</institution>, Tennis Court Road, Cambridge, CB2 1QR, <country>UK</country></aff>
<aff id="a3"><label>3</label><institution>MRC Biostatistics Unit, Cambridge Institute for Public Health</institution>, Cambridge CB2 0SR, <country>UK</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><label>&#x002A;</label><p><email>omc25@cam.ac.uk</email></p></fn>
<fn id="n2"><label>&#x2020;</label><p><email>lg390@cam.ac.uk</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>282269</elocation-id>
<history>
<date date-type="received">
<day>14</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>14</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>14</day>
<month>3</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="282269.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Analysis of the spatial sub-cellular distribution of proteins is of vital importance to fully understand context specific protein function. Some proteins can be found with a single location within a cell, but up to half of proteins may reside in multiple locations, can dynamically relocalise, or reside within an unknown functional compartment. These considerations lead to uncertainty in associating a protein to a single location. Currently, mass spectrometry (MS) based spatial proteomics relies on supervised machine learning algorithms to assign proteins to sub-cellular locations based on common gradient profiles. However, such methods fail to quantify uncertainty. Here we reformulate the framework on which we perform statistical analysis. We propose a Bayesian generative classifier based on Gaussian mixture models to assign proteins probabilistically to sub-cellular niches, thus proteins have a probability distribution over sub-cellular locations, with posterior Bayesian computation performed using the expectationmaximisation (EM) algorithm, as well as Markov-chain Monte-Carlo(MCMC). Our methodology allows proteome-wide uncertainty quantification, thus adding a further layer to the analysis of spatial proteomics. Our framework is flexible, allowing many different systems to be analysed and reveals new modelling opportunities for spatial proteomics. We find our methods perform competitively with the current state-of-the art machine learning methods, whilst simultaneously providing more information. We highlight several examples where uncertainty quantification provides biologically intriguing results. To our knowledge this is the first Bayesian model of MS based spatial proteomics data.</p>
</abstract>
<counts>
<page-count count="62"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<sec id="s1a">
<label>1.1</label>
<title>Spatial Proteomics</title>
<p>Spatial proteomics is an interdisciplinary field studying the localisation of proteins on a large-scale. Where a protein is localised in a cell is a fundamental question, since a protein must be localised to its required sub-cellular compartment to interact with its binding partners (for example, proteins, nucleic acids, metabolic substrates) (<xref ref-type="bibr" rid="c23">Gibson, 2009</xref>). Furthermore, mis-localisations of proteins is also critical to our understanding of biology, as aberrant protein localisation have been implicated in several diseases (<xref ref-type="bibr" rid="c31">Kau <italic>et al.</italic>, 2004</xref>; <xref ref-type="bibr" rid="c34">Laurila and Vihinen, 2009</xref>; <xref ref-type="bibr" rid="c37">Luheshi <italic>et al.</italic>, 2008</xref>; <xref ref-type="bibr" rid="c47">Siljee <italic>et al.</italic>, 2018</xref>). Sub-cellular localisations of proteins can be studied by high-throughput mass spectrometry (MS) (<xref ref-type="bibr" rid="c18">Gatto <italic>et al.</italic>, 2010</xref>). MS based spatial proteomics experiments enable us to confidently determine the sub-cellular localisation of thousands of proteins within in a cell (<xref ref-type="bibr" rid="c8">Christoforou <italic>et al.</italic>, 2016</xref>), given the availability of rigorous data analysis and interpretation (<xref ref-type="bibr" rid="c18">Gatto <italic>et al.</italic>, 2010</xref>).</p>
<p>In a typical MS-based spatial proteomics experiment, cells first undergo lysis in a fashion which maintains the integrity of their organelles. The cell content is then separated using a variety of methods, such as density separation (<xref ref-type="bibr" rid="c14">Dunkley <italic>et al.</italic>, 2006</xref>; <xref ref-type="bibr" rid="c8">Christoforou <italic>et al.</italic>, 2016</xref>), differential centrifugation (<xref ref-type="bibr" rid="c30">Itzhak <italic>et al.</italic>, 2016</xref>), free-flow electrophersis (<xref ref-type="bibr" rid="c43">Parsons <italic>et al.</italic>, 2014</xref>), or affinity purification (<xref ref-type="bibr" rid="c28">Heard <italic>et al.</italic>, 2015</xref>). In the LOPIT (<xref ref-type="bibr" rid="c13">Dunkley <italic>et al.</italic>, 2004</xref>, <xref ref-type="bibr" rid="c14">2006</xref>; <xref ref-type="bibr" rid="c45">Sadowski <italic>et al.</italic>, 2006</xref>) and <italic>hyper</italic> LOPIT (<xref ref-type="bibr" rid="c40">Mulvey <italic>et al.</italic>, 2017</xref>) techniques cell lysis is proceeded by separation of the content along a density gradient. Organelles and macro-molecular complexes are thus characterised by density-specific profiles along the gradient (<xref ref-type="bibr" rid="c11">De Duve and Beaufay, 1981</xref>). Discrete fractions along the continuous density gradient are then collected and quantitative protein profiles, that match the organelle profiles along the gradient, are measured using high accuracy mass spectrometry (<xref ref-type="bibr" rid="c40">Mulvey <italic>et al.</italic>, 2017</xref>).</p>
</sec>
<sec id="s1b">
<label>1.2</label>
<title>Data Analysis</title>
<p>The data is first visualized using principle component analysis (PCA, for example <xref rid="fig2" ref-type="fig">figure 2</xref>) and known sub-cellular compartments are annotated (<xref ref-type="bibr" rid="c5">Breckels <italic>et al.</italic>, 2016a</xref>). Supervised machine learning algorithms are then typically employed to create classifiers, that associate un-annotated proteins to specific organelles (<xref ref-type="bibr" rid="c19">Gatto <italic>et al.</italic>, 2014a</xref>), as well as semi-supervised methods that detect novel sub-cellular clusters using both labelled and un-labelled features (<xref ref-type="bibr" rid="c4">Breckels <italic>et al.</italic>, 2013</xref>). More recently, a state-of-the-art transfer learning (TL) algorithm has been shown to improved the quantity and reliability of sub-cellular protein assignments (<xref ref-type="bibr" rid="c6">Breckels <italic>et al.</italic>, 2016b</xref>). Applications of such methods have led to organelle-specific localisation information of proteins in plants (<xref ref-type="bibr" rid="c14">Dunkley <italic>et al.</italic>, 2006</xref>), <italic>Drosophila</italic> (<xref ref-type="bibr" rid="c48">Tan <italic>et al.</italic>, 2009</xref>), chicken (<xref ref-type="bibr" rid="c25">Hall <italic>et al.</italic>, 2009</xref>), human cell lines (<xref ref-type="bibr" rid="c4">Breckels <italic>et al.</italic>, 2013</xref>), mouse pluripotent stem cells (<xref ref-type="bibr" rid="c8">Christoforou <italic>et al.</italic>, 2016</xref>) and cancer cell lines (<xref ref-type="bibr" rid="c49">Thul <italic>et al.</italic>, 2017</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>(a) PCA plot of the 1st and 2nd principle components for the curated marker proteina of the mouse stem cell data. The organelles are, in general, well separated. Though some organelles overlap, they are separated along different principle components. The densities used to derive the ellipses are the MAP estimates from the EM method. (b) Marker resolution along the 1st and 4th principle components show that the mitochondrion and peroxisome markers are well resolved, despite overlapping in the 1st and 2nd component. We also see that the ER/Golgi apparatus markers are better separated from the extracellular matrix markers.</title></caption>
<graphic xlink:href="282269_fig2.tif"/>
</fig>
<p>Classification methods which have previously been used include partial least squares discriminate analysis (<xref ref-type="bibr" rid="c14">Dunkley <italic>et al.</italic>, 2006</xref>), K nearest neighbours, random forests and the support vector machine amongst others (see <xref ref-type="bibr" rid="c19">Gatto <italic>et al.</italic> (2014a)</xref> for an overview). Though these methods have proved successful within the field they have limitations. Typically, such classifiers ouput an assignment of proteins to discreet pre-annotated sub-cellular locations. However, it is important to note that half the proteome cannot be robustly assigned to a single sub-cellular location, which may be a manifestation of proteins in so far uncharaterised organelles or proteins that are distributed amongst multiple locations. These factors lead to uncertainty in the assignment of proteins to sub-cellular localisations and thus quantifying this uncertainty is of vital importance (<xref ref-type="bibr" rid="c32">Kirk <italic>et al.</italic>, 2015</xref>).</p>
<p>This article is laid out as follows: <xref ref-type="sec" rid="s2">section 2</xref> describes our probabilistic model and how we perform inference; <xref ref-type="sec" rid="s3">section 3</xref> describes the results of applying our methods to a dataset of interest and compares our method with alternative approaches on 5 spatial proteomics datasets, and in <xref ref-type="sec" rid="s4">section 4</xref> we make some concluding remarks. We make extensive use of the R programming language (<xref ref-type="bibr" rid="c44">R Core Team, 2017</xref>) and existing MS packages (<xref ref-type="bibr" rid="c17">Gatto and Lilley, 2012</xref>; <xref ref-type="bibr" rid="c20">Gatto <italic>et al.</italic>, 2014b</xref>) and our methods will be made available within the R/Bioconductor package pRoloc (<xref ref-type="bibr" rid="c20">Gatto <italic>et al.</italic>, 2014b</xref>).</p>
</sec>
</sec>
<sec id="s2">
<label>2.</label>
<title>Model and Methods</title>
<p>We describe in this section the probabilistic model that uses the labelled data to associate un-annotated proteins to specific organelles or sub-cellular compartments.</p>
<sec id="s2a">
<label>2.1</label>
<title>Mixture models for spatial proteomic data</title>
<p>We observe <italic>N</italic> protein profiles each of length <italic>L</italic>, corresponding to the number of quantified fractions along the gradient density, including combining replicates. For <italic>i</italic> &#x003D; 1,&#x2026;, <italic>N</italic>, we denote the profile of the <italic>i</italic>-th protein by <bold>x</bold><sub><italic>i</italic></sub> &#x003D; [<italic>x</italic><sub>1<italic>i</italic></sub>,&#x2026;,<italic>x<sub>Li</sub></italic>]. We suppose that there are <italic>K</italic> known sub-cellular compartments to which each protein could localise (e.g. cytoplasm, endoplasmic reticulum, mitochondria,&#x2026;). Henceforth, we refer to these <italic>K</italic> sub-cellular compartments as <italic>components</italic>, and introduce component labels <italic>z</italic><sub><italic>i</italic></sub>, so that <italic>z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k</italic> if the <italic>i</italic>-th protein localises to the <italic>k</italic>-th component. We denote by <italic>X</italic><sub><italic>L</italic></sub> the set of proteins whose component labels are known, and by <italic>X</italic><sub><italic>U</italic></sub> the set of unlabelled proteins. If protein <italic>i</italic> is in <italic>X</italic><sub><italic>U</italic></sub>, we desire the probability that <italic>z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k</italic> for each <italic>k</italic> &#x003D; 1,&#x2026;, <italic>K</italic>. That is, for each unlabelled protein, we want the probability of belonging to each component (given a model and the observed data).</p>
<p>We initially model the distribution of profiles associated with proteins that localise to the <italic>k</italic>-th component as multivariate normal with mean vector <bold><italic>&#x00B5;</italic></bold><sub><italic>k</italic></sub> and covariance matrix &#x03A3;<sub><italic>k</italic></sub>, so that:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="282269_eqn1.gif"/></alternatives>
</disp-formula>
For any <italic>i</italic>, we define the prior probability of the <italic>i</italic>-th protein localising to the <italic>k</italic>-th component to be <italic>p</italic>(<italic>z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k</italic>) &#x003D; <italic>&#x03C0;</italic><sub><italic>k</italic></sub>. Letting <inline-formula><alternatives><inline-graphic xlink:href="282269_inline1.gif"/></alternatives></inline-formula> denote the set of all component mean and covariance parameters, and <inline-formula><alternatives><inline-graphic xlink:href="282269_inline2.gif"/></alternatives></inline-formula> <inline-formula><alternatives><inline-graphic xlink:href="282269_inline12.gif"/></alternatives></inline-formula> denote the set of all mixture weights, it follows (from the law of total probability) that:
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="282269_eqn2.gif"/></alternatives>
</disp-formula>
where <italic>f</italic> (<bold>x&#x2223; <italic>&#x00B5;</italic></bold>, &#x03A3;) denotes the density of the multivariate normal with mean vector <bold><italic>&#x00B5;</italic></bold> and covariance matrix &#x03A3; evaluated at <bold>x</bold>.</p>
<p>Equation (<xref ref-type="disp-formula" rid="eqn2">2</xref>) defines a generative probabilistic model known as a <italic>mixture model</italic>. Such models are useful for describing populations that are composed of a number of distinct homogeneous subpopulations. In our case, we model the full complement of measured proteins as being composed of <italic>K</italic> subpopulations, each corresponding to a different organelle or sub-cellular compartment. The literature of mixture model applications to biology is rich and some recent example include applications to retroviral integration sites (<xref ref-type="bibr" rid="c33">Kirk <italic>et al.</italic>, 2016</xref>), genome-wide associations studies (<xref ref-type="bibr" rid="c35">Liley <italic>et al.</italic>, 2017</xref>) and single-cell transcriptomics (<xref ref-type="bibr" rid="c36">Lonnberg <italic>et al.</italic>, 2017</xref>).</p>
<p>Though some proteins are well described as belonging to a single component, many proteins multi-localise or might belong to uncharacterised organelles. In order to allow the model to better account for these &#x201D;outliers&#x201D; that cannot be straightforwardly allocated to any single known component, we extend it by introducing an additional &#x201D;outlier component&#x201D;. To do this, we augment our model by introducing a further indicator latent variable <italic>&#x03C6;</italic>. Each protein <bold>x</bold><sub><italic>i</italic></sub> is now described by an additional variable <italic>&#x03C6;</italic><sub><italic>i</italic></sub>, with <italic>&#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 1 indicating that protein <bold>x</bold><sub><italic>i</italic></sub> belongs to a organelle derived component and <italic>&#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 0 indicating that protein <bold>x</bold><sub><italic>i</italic></sub> is not well described by these known components. This outlier component is modelled as a multivariate T distribution with degrees of freedom <italic>&#x03BA;</italic>, mean vector <bold>M</bold>, and scale matrix <italic>V</italic>. Thus equation (<xref ref-type="disp-formula" rid="eqn1">1</xref>) becomes
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="282269_eqn3.gif"/></alternatives>
</disp-formula>
Further let <italic>g</italic>(<bold>x</bold><italic>&#x007C;&#x03BA;</italic>, <bold>M</bold>, <bold>V</bold>) denote the density of the multivariate T-distribution so that Equation (<xref ref-type="disp-formula" rid="eqn2">2</xref>) becomes:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="282269_eqn4.gif"/></alternatives>
</disp-formula>
For any <italic>i</italic>, we define the prior probability of the <italic>i</italic>-th protein belonging to the outlier component as <italic>p</italic>(<italic>&#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 0) &#x003D; &#x03F5; We can then rewrite equation (<xref ref-type="disp-formula" rid="eqn4">4</xref>) in the following way:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="282269_eqn5.gif"/></alternatives>
</disp-formula>
Throughout we take <italic>&#x03BA;</italic> &#x003D; 4, <bold>M</bold> as the global mean, and <italic>V</italic> as half the global variance of the data. The reason for formulating the model as in equation (<xref ref-type="disp-formula" rid="eqn4">4</xref>) is because it leads to a flexible modelling framework. Furthermore, <italic>&#x03C6;</italic> has an elegant model selection interpretation, since it decides whether <bold>x</bold><sub><italic>i</italic></sub> is better modelled by the known components or the outlier component. It is important to note that <italic>f</italic> and <italic>g</italic> could be replaced by many combinations of distributions and thus could be valuable in modelling other datasets. The choice of parameters for the multivariate T-distribution was decided so that it mimicked a multivariate normal component with the same mean and variance but with heavier tails to better capture dispersed proteins, which we refer to as outlier proteins throughout the text. Similar approaches for modelling outliers have been explored in the literature and often the outlier term is considered constant or as a Poisson process, independent of the observation (<xref ref-type="bibr" rid="c1">Banfield and Raftery, 1993</xref>; <xref ref-type="bibr" rid="c9">Cooke <italic>et al.</italic>, 2011</xref>; <xref ref-type="bibr" rid="c10">Coretto and Hennig, 2016</xref>; <xref ref-type="bibr" rid="c29">Hennig, 2004</xref>).</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Model fitting</title>
<p>We adopt a Bayesian approach toward inferring the unknown parameters, <inline-formula><alternatives><inline-graphic xlink:href="282269_inline3.gif"/></alternatives></inline-formula>, and &#x03F5; of the mixture model presented in Equation (<xref ref-type="disp-formula" rid="eqn4">4</xref>). For <bold><italic>&#x03C0;</italic></bold>, we take a conjugate symmetric Dirichlet prior with parameter <italic>&#x03B2;</italic>, so that <italic>&#x03C0;</italic><sub>1</sub>,&#x2026;, <italic>&#x03C0;<sub>K</sub> &#x223C;</italic> Dirichlet(<italic>&#x03B2;</italic>); and for the componentspecific parameters <bold><italic>&#x00B5;</italic></bold><sub><italic>k</italic></sub> and &#x03A3;<sub><italic>k</italic></sub> we take conjugate normal-inverse-Wishart (NIW) priors with parameters &#x007B;<bold><italic>&#x00B5;</italic></bold><sub>0</sub>, <italic>&#x03BB;</italic><sub>0</sub>, <italic>v</italic><sub>0</sub>, <italic>S</italic><sub>0</sub><italic>&#x007D;</italic>, so that:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="282269_eqn6.gif"/></alternatives>
</disp-formula>
We also place a conjugate Beta prior on <italic>E</italic> with parameters <italic>u</italic> and <italic>v</italic>, so that <italic>&#x03F5; &#x223C; &#x212C;</italic> (<italic>u, v</italic>). Allowing <italic>&#x03F5;</italic> to be random allows us to infer the number of proteins that are better described by an outlier component rather than any known component.</p>
<p>The full model, which we henceforth refer to as a T-augmented Gaussian Mixture model (TAGM), can then be summarised by the plate diagram shown in <xref rid="fig1" ref-type="fig">Figure 1</xref>.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Plate diagram for TAGM model. This diagram specifies the conditional independecies and parameters in our model.</title></caption>
<graphic xlink:href="282269_fig1.tif"/>
</fig>
<p>To perform inference for the parameters, we make use of both the labelled and unlabelled data. For the labelled data <italic>X</italic><sub><italic>L</italic></sub>, since <italic>z</italic><sub><italic>i</italic></sub> and <italic>&#x03C6;</italic><sub><italic>i</italic></sub> are known for these proteins, we can update the parameters with their data analytically by exploiting conjugacy of the priors (see, for example, <xref ref-type="bibr" rid="c22">Gelman <italic>et al.</italic>, 1995</xref>). For the unlabelled data we do not have such information and so in the next sections we explain how to make inferences of the latent variables.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Prediction of localisation of unlabelled proteins</title>
<p>Having obtained the posterior distribution of the model parameters analytically using, at first, the labelled data only, we wish to predict the component to which each of the unlabelled proteins belongs. The probability that a protein belongs to any of the <italic>K</italic> known components, that is <italic>z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k</italic> and <italic>&#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 1, is given by (see <xref ref-type="sec" rid="s5a">appendix 5.1</xref> for derivations):
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="282269_eqn7.gif"/></alternatives>
</disp-formula>
whilst on the other hand,
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="282269_eqn8.gif"/></alternatives>
</disp-formula>
Processing of the unlabelled data can be done by infering <italic>maximum a posteriori</italic> (MAP) estimates for the parameters. However, this approach fails to account for the uncertainty in the parameters, thus we additionally explore inferring the distribution over these parameters.</p>
<sec id="s2c1">
<label>2.3.1</label>
<title>Maximum a posteriori prediction</title>
<p>We use the Expectation-Maximisation (EM) algorithm (<xref ref-type="bibr" rid="c12">Dempster <italic>et al.</italic>, 1977</xref>) to find <italic>maximum a posteriori</italic> (MAP) estimates for the parameters (see, for example, <xref ref-type="bibr" rid="c42">Murphy, 2012</xref>). To specify the parameters of the prior distributions, we use a simple set of heuristics provided by <xref ref-type="bibr" rid="c16">Fraley and Raftery (2007)</xref>. By defining the following quantities
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="282269_eqn9.gif"/></alternatives>
</disp-formula>
we can compute
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="282269_eqn10.gif"/></alternatives>
</disp-formula>
Then the parameters of the posterior mode are:
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="282269_eqn11.gif"/></alternatives>
</disp-formula>
We note if <bold><italic>x</italic></bold><sub><italic>i</italic></sub> is a labelled protein then <italic>a</italic><sub><italic>ik</italic></sub> &#x003D; 1 and these parameters can be updated without difficulty. The above equation consitutes a backbone of the E-step of the EM algorithm, with the entire algorithm specified by the following summary:</p>
<p>E-Step: Given the current parameters compute the values given by equations (<xref ref-type="disp-formula" rid="eqn9">9</xref>), with formulae provided in equations (<xref ref-type="disp-formula" rid="eqn7">7</xref>) and (<xref ref-type="disp-formula" rid="eqn8">8</xref>).</p>
<p>M-Step: Compute
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="282269_ueqn1.gif"/></alternatives>
</disp-formula>
and
<disp-formula id="ueqn2">
<alternatives><graphic xlink:href="282269_ueqn2.gif"/></alternatives>
</disp-formula>
as well as
<disp-formula id="ueqn3">
<alternatives><graphic xlink:href="282269_ueqn3.gif"/></alternatives>
</disp-formula>
Finally, compute the MAP estimates given by equations (<xref ref-type="disp-formula" rid="eqn11">11</xref>). These estimates are then used in the following iteration of the E-step.</p>
<p>Denoting by Q the expected value of the log-posterior and letting <italic>t</italic> denote the current iteration of the EM algorithm, we iterate until <italic>&#x007C;Q</italic>(<bold><italic>&#x03B8;</italic></bold><italic>&#x007C;</italic><bold><italic>&#x03B8;</italic></bold><sub><italic>t</italic></sub>) <italic>-Q</italic>(<bold><italic>&#x03B8;</italic></bold><italic>&#x007C;</italic><bold><italic>&#x03B8;</italic></bold><sub><italic>t-</italic></sub>1)<italic>&#x007C; &#x003C; &#x03B4;</italic> for some pre-specified <italic>&#x03B4; &#x003E;</italic> 0. Once we have found MAP estimates for the parameters <bold><italic>&#x03B8;</italic></bold><sub><italic>MAP</italic></sub>, <bold><italic>&#x03C0;</italic></bold><sub><italic>MAP</italic></sub> and <italic>&#x03F5;</italic><sub><italic>MAP</italic></sub> we proceed to perform prediction. We plug the MAP parameter estimates into Equation (<xref ref-type="disp-formula" rid="eqn7">7</xref>) in order to obtain the posterior probability of protein <italic>i</italic> localising to component <italic>k, p</italic>(<italic>z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k, &#x03C6;</italic> &#x003D; 1 <bold>x</bold><sub><italic>i</italic></sub>, <bold><italic>&#x03B8;</italic></bold><sub><italic>MAP</italic></sub>, <bold><italic>&#x03C0;</italic></bold><sub><italic>MAP</italic></sub>, <italic>E</italic><sub><italic>MAP</italic></sub>, <italic>&#x03BA;</italic>, <bold>M</bold>, <italic>V</italic>). To make a final assignment, we may allocate each protein according to the component that has maximal probability. A full technical derivation of the EM algorithm can be found in the appendix (<xref ref-type="sec" rid="s5a">appendix 5.1</xref>).</p>
</sec>
<sec id="s2c2">
<label>2.3.2</label>
<title>Uncertainty in the posterior localisation probabilities</title>
<p>The MAP approach described above provides us with a probabilistic assignment, <italic>p</italic>(<italic>z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k, &#x03C6;</italic> &#x003D; 1<italic>&#x007C;</italic><bold>x</bold><sub><italic>i</italic></sub>, <bold><italic>&#x03B8;</italic></bold><sub><italic>MAP</italic></sub>, <bold><italic>&#x03C0;</italic></bold><sub><italic>MAP</italic></sub>, <italic>E</italic><sub><italic>MAP</italic></sub>, <italic>&#x03BA;</italic>, <bold>M</bold>, <italic>V</italic>), of each unlabelled protein to each component. However, it fails to account for the uncertainty in the parameters <bold><italic>&#x03B8;</italic></bold>, <bold><italic>&#x03C0;</italic></bold> and &#x03F5;. To address this, we can sample parameters from the posterior distribution.</p>
<p>Let <inline-formula><alternatives><inline-graphic xlink:href="282269_inline4.gif"/></alternatives></inline-formula> be a set of <italic>T</italic> sampled values for the parameters <bold><italic>&#x03B8;</italic></bold>, <bold><italic>&#x03C0;</italic></bold>, <italic>&#x03F5;</italic>, drawn from the posterior.</p>
<p>The assignment probabilities can then be summarised by the Monte-Carlo average:
<disp-formula id="ueqn4">
<alternatives><graphic xlink:href="282269_ueqn4.gif"/></alternatives>
</disp-formula>
Other summaries of the assignment probabilities can be determined in the usual ways to obtain, for example, interval-estimates. We summarise intervalestimates using the 95&#x0025; equi-tailed interval, which is defined by the 0.025 and 0.975 quantiles of the distribution of assignment probabilities, <inline-formula><alternatives><inline-graphic xlink:href="282269_inline5.gif"/></alternatives></inline-formula> <inline-formula><alternatives><inline-graphic xlink:href="282269_inline5a.gif"/></alternatives></inline-formula></p>
<p>Sampling parameter values in our model requires us to compute the required conditional probabilities and then a straightforward Gibbs sampler can be used to sample in turn from these conditionals. In addition, we can bypass sampling the parameters by exploiting the conjugacy of our priors. By marginalising parameters in our model we can obtain an efficient collapsed Gibbs sampler and therefore only sample the component allocation probabilities and the outlier allocation probabilities. The derivations and required conditionals can be found in the appendix (<xref ref-type="sec" rid="s5b">appendix 5.2</xref>).</p>
</sec>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Classifier Assessment</title>
<p>In later sections we compare the classification performance of the two above learning schemes to the K-nearest neighbours (KNN) and the weighted support vector machine (SVM) classifiers.</p>
<p>The following schema was used to assess the classifier performance of all methods. We split the marker sets for each experiment into a class-stratified training (80&#x0025;) and test (20&#x0025;) partitions, with the separation formed at random. The true classes of the test profiles are withheld from the classifier, whilst the algorithm is trained. The algorithm is then assessed on its ability to predict the classes of the proteins in the test partition for generalisation accuracy. How each classifier is trained is specific to that classifier. The KNN and SVM have hyperparameters optimised using 5-fold cross-validation.</p>
<p>This 80<italic>/</italic>20 data stratification is performed 100 times in order to produce 100 sets of macro-F1 (<xref ref-type="bibr" rid="c27">He and Garcia, 2009</xref>) scores and class specific F1 scores (<xref ref-type="bibr" rid="c6">Breckels <italic>et al.</italic>, 2016b</xref>). The F1 score is the harmonic mean of the precision and recall, more precisely:
<disp-formula id="ueqn5">
<alternatives><graphic xlink:href="282269_ueqn5.gif"/></alternatives>
</disp-formula>
tp denotes the number of true positives; fp the number of false positives and fn the number of false negatives. Thus
<disp-formula id="ueqn6">
<alternatives><graphic xlink:href="282269_ueqn6.gif"/></alternatives>
</disp-formula>
High Macro F1 scores indicates that marker proteins in the test dataset are consistently correctly assigned by the classifier. We note that accuracy alone is an inadequate measure of performance, since it fails to quantify false positives.</p>
<p>However, a Bayesian Generative classifier produces probabilistic assignment of observations to classes. Thus while the classifier may make an incorrect assignment it may do so with low probability. The F1 score is unforgiving in this situation and will not use this information. To measure this uncertainty we introduce the quadratic loss which allows us to compare probabilistic assignments (<xref ref-type="bibr" rid="c24">Gneiting and Raftery, 2007</xref>). For the SVM, a logistic distribution is fitted using maximum likelihood estimation to the decision values of all binary classifiers. Then, the membership probabilities for the multi-class classification is calculated using quadratic optimization. The logistic regression model assumes errors which are distributed according to a centred Laplace distribution for the predictions, where maximum likelihood estimation is used to estimate the scale parameter (<xref ref-type="bibr" rid="c39">Meyer <italic>et al.</italic>, 2017</xref>). For the K-NN classifier, we interpret the proportion of neighbours belonging to each class as a non-parametric posterior probability. To avoid non-zero probabilities for classes we perform Laplace smoothing; that is, the posterior allocation probability is given by
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="282269_eqn12.gif"/></alternatives>
</disp-formula>
where <italic>N</italic><sub><italic>ik</italic></sub> is the number of neighbours belonging to class <italic>k</italic> in the neighbourhood of <italic>x</italic><sub><italic>i</italic></sub>, <italic>C</italic> is the number of classes, <italic>K</italic> is the number of nearest neighbours (optimised through 5-fold cross validation) and <italic>d</italic><sub><italic>k</italic></sub> is the incidence rate of each class in the training set. Finally, <italic>&#x03B1; &#x003E;</italic> 0 is the pseudo-count smoothing parameter. Motivated by a Bayesian interpretation of placing a Jeffrey&#x2019;s type Dirichlet prior over multinomial counts, we choose <italic>&#x03B1;</italic> &#x003D; 0.5 (<xref ref-type="bibr" rid="c26">Hazimeh and Zhai, 2015</xref>; <xref ref-type="bibr" rid="c50">Valcarce <italic>et al.</italic>, 2016</xref>; <xref ref-type="bibr" rid="c38">Manning <italic>et al.</italic>, 2008</xref>). The quadratic loss is given by the following formula:
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="282269_eqn13.gif"/></alternatives>
</disp-formula>
where &#x2016;&#x00B7;&#x2016;<sub>2</sub> is the <italic>l</italic><sub>2</sub> norm and <italic>q</italic><sub><italic>i</italic></sub> is the true classification vector and <italic>p</italic><sub><italic>i</italic></sub> is a vector of predicted assignments to each class. It is useful to note that the corresponding risk function is the mean square error (MSE), which is the expected value of the quadratic loss.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>Results</title>
<sec id="s3a">
<label>3.1</label>
<title>Application to Mouse Pluripotent Stem Cell Data</title>
<p>We model the mouse pluripotent E14TG2a stem cell data (<xref ref-type="bibr" rid="c8">Christoforou <italic>et al.</italic>, 2016</xref>), which contains quantitation data for 5032 proteins. The data resolves 14 sub-cellular niches with an additional chromatin preparation resolving the nuclear chromatin and non-chromatin components. Two biological replicates of the data are concatenated each with 10 fractions along the density gradient. The following section applies our statistical methodology to this data and we explore the results.</p>
<sec id="s3a1">
<label>3.1.1</label>
<title>Maximum a posteriori prediction of protein localisation</title>
<p>This section applies the TAGM model to the mouse pluripotent stem cell data, by deriving MAP estimates for the model parameters and using these for prediction. Visualisation is important for data analysis and exploration. A simple way to visualise our model is to project probabilities ellipses onto a PCA plot. Each ellipse contains a proportion of total probability of a particular multiavariate Guassian density. The outer ellipse contains 99&#x0025; of the total probability whilst the middle and inner ellipses contain 95&#x0025; and 90&#x0025; of the probability respectively. Visualising only the first two principle components can be misleading, since protein can be more (or less) seperated in higher principle components. We visualise the first two principle components along with the first and fourth principle component as a representive example. For the TAGM model, we derive probability ellipses from the MAP estimates of the parameters.</p>
<p>We now apply the statistical methodology described in <xref rid="s2" ref-type="sec">section 2</xref> to predicit the localisation of proteins to organelles and subcellular components. We produce MAP estimates of the parameters by using the expectation-maximisation algorithm. We run the algorithm for 200 iterations and inspect a plot of the log-posterior to confirm plateauing of the log-posterior (see <xref ref-type="sec" rid="s5c">appendix 5.3</xref>). We confirm that the difference of the log posterior between the final two iterations is less than 10<sup>&#x2212;6</sup> and we conclude that our algorithm has converged. The results can be seen in <xref rid="fig3" ref-type="fig">figure 3</xref>, where the posterior localisation probability can be visualised by scaling the pointer for each protein.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>PCA plot of the protein quantitation data with colours representing the predicted class (5032 proteins). The pointer size of a protein is scaled to the probability that particular protein was assigned to that organelle. Markers are automatically assigned a probability of 1 and the size of the pointer reflects this.</title></caption>
<graphic xlink:href="282269_fig3.tif"/>
</fig>
<p><xref rid="fig3" ref-type="fig">Figure 3</xref> demonstrates a range of probabilistic assignments of proteins to organelles and subcellular niches. Furthermore, some protein assignments seemingly overlap with several possible organelles. Point estimates are misleading because they do not express uncertainty. We are not satisfied with simply point estimates of the probabilities and desire credible intervals. We envoke the MCMC learning method detailed in next section.</p>
</sec>
<sec id="s3a2">
<label>3.1.2</label>
<title>Uncertainty in the posterior localisation probabilities</title>
<p>This section applies the TAGM model to the mouse pluripotent stem cell data, by considering the uncertainty in the parameters and exploring how this uncertainty propogates to the uncertainty in protein localisation prediction. In <xref rid="fig4" ref-type="fig">figure 4</xref> we visualise the model as before using the first two principle components along with the first and fourth principle component as a representive example. For the TAGM model, we derive probability ellipses from the expected value of the posterior NIW distribution.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>(a) Probability ellipses given from using the MCMC method. The density is the expected value from the NIW distribution. (b) Probability ellipses visualised along the 1st and 4th principle component also from the MCMC method.</title></caption>
<graphic xlink:href="282269_fig4.tif"/>
</fig>
<p>We apply the statistical methodology detailed in <xref rid="s2" ref-type="sec">section 2</xref>. We perform posterior computation in the Bayesian setting using standard MCMC methods. We run 6 chains of our Gibbs sampler in parallel for 15, 000 iterations, throwing away the first 4, 000 iterations for burn-in and retain every 10<sup><italic>th</italic></sup> sample for thinning. Thus 1,100 sample are retained from each chain. We then visualise our trace plots of our chains; in particular, we monitor the number of proteins allocated to the known components (see <xref ref-type="sec" rid="s5d">appendix 5.4</xref>). We throw away 1 chain because we do not considered it to have converged. For the remaining 5 chains we further discard the first 500 samples by visual inspection. We then have 600 retained samples from 5 seperate chains. For further analysis, we compute the Gelman-Rubin convergence diagnostic (<xref ref-type="bibr" rid="c21">Gelman and Rubin, 1992</xref>; <xref ref-type="bibr" rid="c7">Brooks and Gelman, 1998</xref>), which is computed as <italic>R&#x2248;</italic>1.05. Values of <italic>R</italic> far from 1 indicate non-convergence and since our statistic is less than 1.1, we conclude our chains have converged. The remaining samples are then pooled to produce a single chain containing 3000 samples.</p>
<p>We produce point estimates of the posterior localisation probabilities by summarising samples by their monte-carlo average. These summmaries are then visualised on <xref rid="fig5" ref-type="fig">figure 5</xref>, where the pointer is scaled according to the localisation probabilities. Monte-Carlo based inference also provides us with additional information; in particular, we can interrogate individual proteins and their posterior probability distribution over subcellular locations.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>PCA plot of the protein quantitation data with colours representing the predicted class (5032 proteins). The pointer size of a protein is scaled to the probability that particular protein was assigned to that organelle, with proteins belonging to the outlier cluster shrunk. Markers are automatically assigned a probability of 1 and the size of the pointer reflects this.</title></caption>
<graphic xlink:href="282269_fig5.tif"/>
</fig>
<p><xref rid="fig6" ref-type="fig">Figure 6</xref> illustrates one example of the importance of capturing uncertainty. The E3 ubiquitin-protein ligase TRIP 12(G5E870) is an integral part of ubiquitin fusion degradation pathway and is a protein of great interest in cancer because it regulates DNA repair pathways. The SVM failed to assign this protein to any location, with assigment to the 60S Ribosome falling below a 5&#x0025; FDR and the MAP estimate assigned the protein to the nucleus non-chromatin with posterior probability <italic>&#x003C;</italic>0.95. The posterior distribution of localisation probabilities inferred from the TAGM model, shown in <xref rid="fig6" ref-type="fig">figure 6</xref>, demonstrates that this protein is most probably localised to the nucleus nonchromatin. However, there is some uncertainty about whether it localises to the 40S ribosome. This could suggest a dynamic role for this protein, which could be further explored with a more targeted experiment.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Violin plot revealing the posterior distribution of localisation probabilities of protein E3 ubiquitin-protein ligase (G5E870) to organelles and sub-cellular niches. The most probable localisation is nucleus non-chromatin, however there is uncertainty associated with this assignment.</title></caption>
<graphic xlink:href="282269_fig6.tif"/>
</fig>
</sec>
<sec id="s3a3">
<label>3.1.3</label>
<title>Enrichment analysis of outlier proteins</title>
<p>We have seen in the previous sections that we can assign proteins probabilitically to subcellular compartment and quantify the uncertainty in these assignments. Some proteins cannot be well described as belonging to any known component and we modelled this using an additional outlier component described mathematically as a T-distribution. It is biologically interesting to decipher what functional role proteins that are far away from known clusters play. We perform an over-representation analysis of gene ontology (GO) terms to asses the biological relevance of this component (<xref ref-type="bibr" rid="c3">Boyle <italic>et al.</italic>, 2004</xref>; <xref ref-type="bibr" rid="c51">Yu <italic>et al.</italic>, 2012</xref>). We take proteins that were allocated to known components with probability less than 0.95, a total of 1111 protein. Note that these 1111 proteins exclude proteins that are likely to belong to a known location but we are uncertain about which localisation. We then performed enrichment analysis against the set of all proteins quantified in the hyperLOPIT experiment. We search against the cellular compartment, biological process and molecular function ontologies.</p>
<p><xref rid="fig7" ref-type="fig">Figure 7</xref> shows this outlier component is enriched for cytoskeletal part (<italic>p &#x003C;</italic> 10<sup>&#x2212;7</sup>) and microtuble cytoskeleton (<italic>p &#x003C;</italic> 10-<sup>7</sup>). Cytoskeleton proteins are found throughout the cell and therefore we would expect them to be found in every fraction along the density gradient, this manifests as these proteins not forming a tight cluster. We also observe enrichment for highly dynamic subcellular processes such as cell division (<italic>p &#x003C;</italic> 10<sup>&#x2212;6</sup>) and cell cycle processes (<italic>p &#x003C;</italic> 10<sup>&#x2212;6</sup>), again these proteins are unlikely to have steady-state locations within a single component. We also see enrichment for molecular functions such as tranferase activity (<italic>p &#x003C;</italic> 0.005), another highly dynamic process. These observations justify including an additional outlier component in our mixture model.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Gene Ontology over representation analysis on outlier proteins that is proteins allocated with less than probability 0.95. We analyse the enrichment of terms in the cellular compartment, biological proccess, and molecular function ontologies. We display the top 10 significant results in the dotplots.</title></caption>
<graphic xlink:href="282269_fig7.tif"/>
</fig>
</sec>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Comparison with other classifiers</title>
<p>In this section we assess the generalisation performance of our methods on several datasets, by computing the performance metrics associated with each classifier as detailed in <xref rid="s2d" ref-type="sec">section 2.4</xref>. We compare the SVM and KNN classifiers alongside the MAP and MCMC approaches detailed in the methods section. The hyperparameter for the KNN algorithm, the number of nearest neighbours, is optimised via internal 5-fold cross-validation and the hyperparameters for the SVM, sigma and cost, are also optimised via internal 5-fold cross validation.We test our method on the following datasets <italic>Drosophila</italic> (<xref ref-type="bibr" rid="c48">Tan <italic>et al.</italic>, 2009</xref>), chicken (<xref ref-type="bibr" rid="c25">Hall <italic>et al.</italic>, 2009</xref>), mouse pluripotent stem cells (<xref ref-type="bibr" rid="c8">Christoforou <italic>et al.</italic>, 2016</xref>), a cancer cell line (<xref ref-type="bibr" rid="c49">Thul <italic>et al.</italic>, 2017</xref>) and the HeLa cell line (<xref ref-type="bibr" rid="c30">Itzhak <italic>et al.</italic>, 2016</xref>). A dataset specific marker list was used, which is curated specifically for the each cell line. We removed the &#x201D;high-curvature ER&#x201D; annotations from the HeLa dataset as there are too few proteins to correctly perform cross-validation. <xref rid="tbl1" ref-type="table">Table 1</xref> summarises these datasets, including information about number of quantified proteins, the workflow used and the number of fractions.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Summary of spatial proteomics datasets used for comparisons</p></caption>
<graphic xlink:href="282269_tbl1.tif"/>
</table-wrap>
<p><xref rid="fig8" ref-type="fig">Figure 8</xref> compares the Macro-F1 scores across the datasets for all classifiers and demonstrates that no classifier consistently outperforms any other across all datasets. We perform a pairwise unpaired T-test with multiple testing correction applied using the Benjamini-H&#x00F6;chberg procedure (<xref ref-type="bibr" rid="c2">Benjamini and Hochberg, 1995</xref>) to detect differences between classifier performance. In the <italic>Drosophila</italic> dataset only the KNN algorithm outpeforms the SVM at significance level of 0.01, whilst no other significance difference exist between the classifiers. In the chicken DT40 dataset only the MCMC method outperforms the KNN classifier at significance level of 0.01, no other significant conclusion can be drawn. In the mouse dataset the MAP based method outperforms the MCMC method at significant level of 0.01, no other significant conclusions can be drawn. In the HeLa dataset all classifiers are significantly different at a 0.01 level. These difference may exist because the dataset does not fit well with our modelling assumptions; in particular, this dataset set has been curated to have a class called &#x201D;Large Protein Complex&#x201D;, which likely describes several sub-cellular structures. These might include nuclear compartments and ribosomes, as well as any cytosolic complex and large protein complex which pellets during the centrifugation conditions used to capture this mixed subcellular fraction. Moreover, the cytosolic and nuclear fraction were processed separatly leading to possible imbalance with comparisions with other datasets. Thus, the large protein complex component might be better described as itself a mixture model or more detailed curation of these data may be required. We do not consider further modelling of this dataset in this manuscript. Finally, for the U2-OS all classifiers are significantly different at a significant level of 0.01 except for the SVM classifier and the MCMC method, with the MAP method performing the best. <xref rid="fig8" ref-type="fig">Figure 8</xref> shows that for this datset all classifiers are performing extremely well. The full results for the T-tests can be found in tables in <xref ref-type="sec" rid="s5e">appendix 5.5</xref>.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8:</label>
<caption><title>Box plots of the distributions of Macro F1 scores for 5 different spatial proteomics datasets</title></caption>
<graphic xlink:href="282269_fig8.tif"/>
</fig>
<p>However, the Macro-F1 scores do not take into account that whilst the TAGM model may misclassify, it may do so with low confidence. We use the probabilistic information that the classifiers output to compute the quadratic loss. The lower the quadratic loss the closer the probabilitic predicition is to the true value. We plot the distributions of quadratic losses for each classifier in <xref rid="fig9" ref-type="fig">figure 9</xref>. Again, we perform a pairwise unpaired T-test with multiple testing correction. We find that in every single dataset the MCMC methods achieves the lowest quadratic loss at a signifiance level <italic>&#x003C;</italic> 0.0001. We assert that if the TAGM model, using the MCMC methdology, makes an incorrect classification it does so with lower confidence than the SVM classifier, the KNN classifier and the MAP based classifier, whilst if it is correct in its assertion it does so with greater confidence. Additionally, a fully Bayesian methodology provides us with not only with point estimates of classification probabilities but uncertainty quantification in these allocations, and thus is is the most useful classifier.</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9:</label>
<caption><title>Box plots of the distributions of Quadratic losses for 5 different spatial proteomics datasets</title></caption>
<graphic xlink:href="282269_fig9.tif"/>
</fig>
<p>Computing distributions of F1 scores and quadratic losses, which can only be done on the marker proteins, can help us understand whether a classifier might have greater generalised performance accuracy. However, we are interested in whether there is a large disagreement between classifiers when prediction is performed on proteins for which we have no withheld localisation information. This informs us about a systematic bias for a particular classifier or whether a classifier ensemble could increase performance. To maintain a common set of proteins we set thresholds for each classifiers in turn and compare to the other classifier without thresholing. Firstly, we set a global threshold of 0.95 for the TAGM and then for these proteins plot a contingency table against the classification results from the SVM. Secondly, we set a 5&#x0025; FDR for the SVM and then for these proteins plot a contingency table against the classification results from the TAGM. We visualise the contingency tables in heat plots (<xref rid="fig10" ref-type="fig">figure 10</xref>).</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10:</label>
<caption><title>A heatmap representation of a contingency table, where we compare assignment results for proteins with unknown protein localisation using the TAGM and SVM. The scale ranges from 0 to 1 with values indicating the proportion of assigned proteins to that sub-cellular location. Values along the diagonal represent agreement between classifiers whilst other values represent disagreement. The coherence between the classifers is very high. (a) In this case we set a probability threshold of 0.95 for the TAGM assignments with no threshold for the SVM. (b) In this case we set a 5&#x0025; FDR threshold for the SVM and no threshold for the TAGM.</title></caption>
<graphic xlink:href="282269_fig10.tif"/>
</fig>
<p>In general, we see an extremely high level of coherence between the TAGM and the SVM, with almost all proteins predicted to concordant sub-cellular compartments. There is some disagreement between assigning proteins to the lysosome and plasma membrane, to the cytosol and proteasome, and between the ribosomal subunits (<xref rid="fig10" ref-type="fig">figure 10</xref>). However, we have not used the uncertainty in the probabilitic assignments to produce the contingency tables above. In the next sections, we explore examples of proteins with uncertainty in their posterior localisation probabilities. Selecting biologically relevant thresholds is important for any classifier and exploring uncertainty is of vital importance when drawing biological conclusions.</p>
</sec>
<sec id="s3c">
<label>3.3</label>
<title>Interpreting and exploring uncertainty</title>
<p>Protein sub-cellular localisation can be uncertain for a number of reasons. Technical variations and unknown biological novelty, such as yet uncharacterised functional compartments, can be some of the reasons why a protein might have an unknown or uncertain localisation. Furthermore many proteins are known to reside in multiple locations with possibly different functional duties in each location. With these considerations in mind, it is pertinant to quantify the uncertainty in our allocation of proteins to organelles. This section explores several situations where proteins display uncertain localisation and considers the biological factors that influence uncertainty. We later explore and visualise whole proteome uncertainty quantification.</p>
<p>Exportin 5 (Q924C1) forms part of the micro-RNA export machinery of the nucleus, transporting miRNA from the nucleus to the cytoplasm for further processing. It then translocates back through the nuclear pore complex to return to the nucleus. Exportin 5 can then continue to mediate further transport between nucleus and cytoplasm. The SVM was unable to assign a localisation of Exportin 5, with its assignment falling below a 5&#x0025; FDR to wrongly assign this protein to the proteasome. This incorrect assertion by the SVM was confounded by the similarity between the cytosol and proteasome profiles. <xref rid="fig11" ref-type="fig">Figure 11</xref> demonstrates, according to the TAGM model, that Exportin 5 most likely localises to the cytosol but there is some uncertainty with this assignment. This uncertainty is reflected in possible assignment of Exportin 5 to the nucleus non-chromatin and this uncertainty is a characterisation of the shuttling of this protein between nucleus and cytoplasm.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11:</label>
<caption><title>Exportin 5 (Q924C1) showing localisation to the cytosol with some uncertainty about association to the nucleus non-chromatin. (a) The violin plot shows uncertain localisation between these two sub-cellular localisations. (b) The quantitative profile of this protein shows mixed profile between the profiles of the organelle markers. (c) The density plot shows a complex distribution over localisations for this protein. (d) The protein Q924C1 has steady state distribution between the cytosol and nucleus non-chromatin.</title></caption>
<graphic xlink:href="282269_fig11.tif"/>
</fig>
<p>The Phenylalanine&#x2013;tRNA ligase beta subunit protein (Q9WUA2) has an uncertain localisation between the 40S ribosome and the nucleus nonchromatin (<xref rid="fig12" ref-type="fig">Figure 12</xref>). This protein was left unclassified by the SVM because its score fell below a 5&#x0025; FDR threshold to assign it to the 40S ribosome. Considering that this protein is involved in the acylation of transfer RNA (tRNA) with the amino acid phenylalanine to form tRNAPhe to be used in translation of proteins, it is therefore unsurprising that this protein&#x2019;s steady state location is ribosomal. Whilst the SVM is unable to make an assignment, TAGM is able to suggest an assignment and quantify our uncertainty.</p>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure 12:</label>
<caption><title>Phenylalanine-tRNA ligase beta subunit protein (Q9WUA2) showing localisation to the 40S Ribosome with some uncertainty about association to the nucleus non-chromatin. (a) The violin plot shows uncertain localisation between these two sub-cellular localisations. (b) The quantitative profile of this protein shows mixed profile between the profiles of the organelle markers. (c) The density plot shows a complex distribution over localisations for this protein. (d) The protein Q9WUA2 has steady state distribution skewed towards the 40S Ribosome and close to the nucleus nonchromatin.</title></caption>
<graphic xlink:href="282269_fig12.tif"/>
</fig>
<p>Relatively little is known about the Dedicator of cytokinesis (DOCK) protein 6 (Q8VDR9), a guanine nucleotide exchange factor for CDC42 and RAC1 small GTPases. The SVM could not assign localisation to the ER/Golgi, since its score fell below a 5&#x0025; FDR. Furthermore, the TAGM model assigned this DOCK 6 to the outlier component with probability <italic>&#x003E;</italic> 0.95. <xref rid="fig13" ref-type="fig">Figure 13</xref> shows possible localisation to several components along the secretory pathway. As an activator for CDC42 and RAC1 we may expect to see them with similar localisation. CDC42, a plasma membrane associated protein, regulates cell cycle and division and is found with many localisations. Furthermore RAC1, a small GTPase, also regulates many cellular processes and is found in many locations. Thus the steady-state distribution of DOCK6 is unlikely to be in a single location, since its interaction partners are found in many locations. This justifies including an outlier component in our model, else we may erroneously assign such proteins to a single locations.</p>
<fig id="fig13" position="float" fig-type="figure">
<label>Figure 13:</label>
<caption><title>Q8VDR9 showing localisation to the outlier component. (a) The violin plot shows uncertain localisation between several sub-cellular niches.(b) The quantitative profile of this protein shows mixed profile between the profiles of the organelle markers. (c) The density plot shows a similar localisation probabilities for both the ER/Golgi and Extracellular matrix. (d) The protein Q8VDR9 has steady state distribution in the centre of the plot skewed toward the secretory pathway; in particular, the ER/Golgi and Extracellular matrix components.</title></caption>
<graphic xlink:href="282269_fig13.tif"/>
</fig>
<sec id="s3c1">
<label>3.3.1</label>
<title>Visualising whole sub-cellular proteome uncertainty</title>
<p>The advantage of the TAGM is its ability to provide proteome wide uncertain quantification. Regions where organelle assignments overlap are areas were uncertainty is expected to be the greatest, as well as areas with no dominant component. We take an information theoretic approach to perform this analysis by computing the Shannon entropy (<xref ref-type="bibr" rid="c46">Shannon, 1948</xref>) for each Monte-Carlo sample <italic>t</italic> &#x003D; 1,&#x2026;, <italic>T</italic> of the posterior localisation probabilities of each protein
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="282269_eqn14.gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="282269_inline6.gif"/></alternatives></inline-formula> denotes the posterior localisation probabilty of protein <italic>i</italic> to component <italic>k</italic> at iteration <italic>t</italic>. We then summarise this as a Monte-Carlo averaged Shannon entropy. The greater the Shannon entropy the more uncertainty associated with the assignment of this protein. The lower the Shannon entropy the lower the uncertainty associated with the assignment of this protein. We visualise this in a PCA plot by scaling the pointers in accordance to this metric (<xref rid="fig14" ref-type="fig">figure 14</xref> panel(a)). We also note that while localisation probability (of a protein to its most probable location) and the Shannon entropy are correlated (<xref rid="fig14" ref-type="fig">figure 14</xref> panel(c)), it is not perfect. Thus it is important to use both the localisation probabilities and the uncertainty in these assignments to make conclusions.</p>
<fig id="fig14" position="float" fig-type="figure">
<label>Figure 14:</label>
<caption><title>PCA plots of the mouse pluripotent stem cell data, where each point represents a protein and is coloured to its (probabilistically-)assigned organelle. (a) In this plot, the pointer is scaled to the Shannon entropy of this protein, with larger pointers indicating greater uncertainty. (b) In this plot, the pointer is scaled to the probability of that protein belonging to its assigned organelle. (c) We plot the localisation probabilities against the Shannon entropy with each protein.</title></caption>
<graphic xlink:href="282269_fig14.tif"/>
</fig>
<p><xref rid="fig14" ref-type="fig">Figure 14</xref> demonstrates that the regions of highest uncertainty are those in regions where organelles assignments overlap. The conclusions from this plot are manifold. Firstly, many proteins are assigned unambiguously to sub-cellular localisations; that is, not only are some proteins assigned to organelles with high probability but also with low uncertainty. Secondly, there are well defined regions with high uncertainty, for example proteins in the secretary pathway or proteins on the boundary between cytosol and proteasome. Finally, some organelles, such as the mitochondria, are extremely well resolved. This observed uncertainty in the secretory pathway and cytosol could be attributed to the dynamic nature of these parts of the cell with numerous examples of proteins that traffic in and out of these sub-cellular compartments as part of their biological role. Moreover, the organelles of the secretary pathway share similar and overlapping physical properties making their separation from one another using biochemical fractionation more challenging. Furthermore, there is a region located in the centre of the plot where proteins simultaneously have low probability of belonging to any organelle and high uncertainty in their localisation probability. This suggests that these proteins are poorly described by any single location. These proteins could belong to multiple locations or belong to undescribed sub-cellular compartments. The information portrayed by these plots and the conclusion therein would be extremely challenging to obtain without the use of Bayesian methodology.</p>
</sec>
</sec>
</sec>
<sec id="s4">
<label>4.</label>
<title>Conclusions</title>
<p>We have seen that a Bayesian framework for spatial proteomics can provide whole sub-cellular proteome uncertainty quantification on the assignment of proteins to organelles and such information is invaluable. Furthermore Bayesian models are interpretable and our inferences are fully conditional on our data. In addition, we produce competitive classifier capabilities to the state-of-the-art classifiers, whilst also significantly outperforming the SVM and KNN classifiers with respect to the quadratic loss. We have demonstrated that the additional layer of information that our model provides is biologically intriguing and provides further avenues for additional exploration. We applied our method to a biologically significant dataset, which provides localisation information on thousands of proteins for the mouse pluripotent stem cell proteome. We have augmented this dataset by providing uncertainty quantification on the localisation of proteins to their sub-cellular niches, which had been previously unavailable.</p>
<p>We have also provided a set of visualisation methods which allow us to easily interrogate our data. High quality visualisation tools are essential for quality control and sound biological conclusions. Our methods have been developed in the R programming language and we will continue to contribute to the Bioconductor project by including other methods within the pRoloc package.</p>
<p>Currently, our model cannot integrate localisation information from different data sources nor can it explicity model proteins with multiple localisation. In addition, extensions to semi-supervised methods are under consideration to detect novel sub-cellular niches. This is the subject of further work.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgement</title>
<p>LG was supported by the BBSRC Strategic Longer and Larger grant (Award BB/L002817/1) and the Wellcome Trust Senior Investigator Award 110170/Z/15/Z awarded to KSL. PDWK was supported by the MRC (project reference MCUP0801/1). CMM was supported by a Wellcome Trust Technology Development Grant (Grant number 108467/Z/15/Z). OMC is a Wellcome Trust Mathematical Genomics and Medicine student supported financially by the School of Clinical Medicine, University of Cambridge.</p>
</ack>
<app-group>
<app id="app1">
<label>5.</label>
<title>Appendices</title>
<sec id="s5a">
<label>5.1</label>
<title>Appendix 1</title>
<p>This appendix give a formal derivation of the EM algorithm used for our model. Computations are standard but useful and similar technical summaries can be found (for example see <xref ref-type="bibr" rid="c15">Fraley and Raftery (2005)</xref>; <xref ref-type="bibr" rid="c41">Murphy (2007)</xref>) We let <italic>H</italic> &#x003D;<italic>&#x007B;</italic><bold><italic>&#x00B5;</italic></bold><sub>0</sub>, <italic>&#x03BB;</italic><sub>0</sub>, <italic>v</italic><sub>0</sub>, <italic>S</italic><sub>0</sub><italic>&#x007D;</italic> denote the parameters of the normalinverse-Wishart prior. More precisely:
<disp-formula id="eqn15">
<alternatives><graphic xlink:href="282269_eqn15.gif"/></alternatives>
</disp-formula>
Furthermore, let <bold><italic>&#x03B8;</italic></bold><sub><italic>k</italic></sub> &#x003D;<italic>&#x007B;</italic><bold><italic>&#x00B5;</italic></bold><sub><italic>k</italic></sub>, &#x03A3;<sub><italic>k</italic></sub>,<italic>&#x007D;</italic> and let &#x0398; &#x003D;<italic>&#x007B;&#x03BA;</italic>, <bold>M</bold>, <italic>V&#x007D;</italic> be the parameters of the global <italic>&#x1D4AF;</italic> distribution. We specify the following hierarchical Bayesian model.
<disp-formula id="eqn16">
<alternatives><graphic xlink:href="282269_eqn16.gif"/></alternatives>
</disp-formula>
Since <italic>p</italic>(<italic>&#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 1) &#x003D; 1<italic>-</italic>&#x03F5;, we can rewrite the last line of the model (16) as the following:
<disp-formula id="ueqn7">
<alternatives><graphic xlink:href="282269_ueqn7.gif"/></alternatives>
</disp-formula>
The total joint probability is
<disp-formula id="eqn17">
<alternatives><graphic xlink:href="282269_eqn17.gif"/></alternatives>
</disp-formula>
Before we formally derive an EM algorithm for this model, we derive a few useful quantities. Let <italic>f</italic> (<bold>x</bold><italic>&#x007C;</italic><bold><italic>&#x00B5;</italic></bold>, &#x03A3;) denote the density of the multivariate normal with mean vector <bold><italic>&#x00B5;</italic></bold> and covariance matrix &#x03A3; evaluated at <bold>x</bold> and further let <italic>g</italic>(<bold>x</bold><italic>&#x007C;&#x03BA;</italic>, <bold>M</bold>, <italic>V</italic>) denote the density of the multivariate T-distribution. We compute that
<disp-formula id="eqn18">
<alternatives><graphic xlink:href="282269_eqn18.gif"/></alternatives>
</disp-formula>
Likewise we see that,
<disp-formula id="eqn19">
<alternatives><graphic xlink:href="282269_eqn19.gif"/></alternatives>
</disp-formula>
Thus
<disp-formula id="eqn20">
<alternatives><graphic xlink:href="282269_eqn20.gif"/></alternatives>
</disp-formula>
and then substituting values leads to
<disp-formula id="eqn21">
<alternatives><graphic xlink:href="282269_eqn21.gif"/></alternatives>
</disp-formula>
We also see that
<disp-formula id="eqn22">
<alternatives><graphic xlink:href="282269_eqn22.gif"/></alternatives>
</disp-formula>
We can now formally derive the EM algorithm for this model. First, we compute the expected value of the log-posterior function with respect to the conditional distribution of the latent variable given the observations (under the current estimate of the parameters). For notational convenience we suppress the dependence on the parameters.
<disp-formula id="eqn23">
<alternatives><graphic xlink:href="282269_eqn23.gif"/></alternatives>
</disp-formula>
We note that the equation splits up into a likelihood term <italic>Q</italic><sup><italic>&#x2032;</italic></sup> plus the log prior <italic>D</italic>. The coefficient of the first term in the equation above has already been derived and the other term is given by:
<disp-formula id="eqn24">
<alternatives><graphic xlink:href="282269_eqn24.gif"/></alternatives>
</disp-formula>
where we used that <italic>&#x03C6;</italic><sub><italic>i</italic></sub> was a binary random variable. Thus we see that
<disp-formula id="eqn25">
<alternatives><graphic xlink:href="282269_eqn25.gif"/></alternatives>
</disp-formula>
Where
<disp-formula id="eqn26">
<alternatives><graphic xlink:href="282269_eqn26.gif"/></alternatives>
</disp-formula>
Then again using that <italic>&#x03C6;</italic><sub><italic>i</italic></sub> is binary we can make the following simplifications.
<disp-formula id="eqn27">
<alternatives><graphic xlink:href="282269_eqn27.gif"/></alternatives>
</disp-formula>
Terms can now be maximised by considering terms independently because of linearity. Note that the <xref ref-type="disp-formula" rid="eqn7">equations 7</xref> and 8 are computed with respect to the current estimated values of the parameters. For convenience set the following notation
<disp-formula id="eqn28">
<alternatives><graphic xlink:href="282269_eqn28.gif"/></alternatives>
</disp-formula>
The maximisation step requires finding <italic>&#x03B8;</italic> <inline-formula><alternatives><inline-graphic xlink:href="282269_inline7.gif"/></alternatives></inline-formula>, this can be found for parameter separately for each linear term. To find <inline-formula><alternatives><inline-graphic xlink:href="282269_inline8.gif"/></alternatives></inline-formula>, we need only consider computing the maximisation step from equation (B). First set <italic>&#x03F5;</italic><sub>1</sub>&#x003D; 1 <italic>-&#x03F5;</italic> and <italic>&#x03F5;</italic><sub>2</sub> &#x003D; <italic>&#x03F5;</italic> and add the log prior term to equation (B). Thus, the required Lagrangian is
<disp-formula id="eqn29">
<alternatives><graphic xlink:href="282269_eqn29.gif"/></alternatives>
</disp-formula>
Solving this system leads to
<disp-formula id="eqn30">
<alternatives><graphic xlink:href="282269_eqn30.gif"/></alternatives>
</disp-formula>
To find the MAP estimate for <bold><italic>&#x03C0;</italic></bold>, we examine equation (A) and add the log prior. Furthermore we must maximise <bold><italic>&#x03C0;</italic></bold> under the constraint that <inline-formula><alternatives><inline-graphic xlink:href="282269_inline9.gif"/></alternatives></inline-formula> 1. The Lagrangian for this constrained optimisation problem is the following,
<disp-formula id="eqn31">
<alternatives><graphic xlink:href="282269_eqn31.gif"/></alternatives>
</disp-formula>
The fixed point of this Lagrangian solves the required constrained optimisation problem and <italic>B</italic>(<italic>&#x03B2;</italic>) denotes the Beta function with parameter <italic>&#x03B2;</italic>.
<disp-formula id="eqn32">
<alternatives><graphic xlink:href="282269_eqn32.gif"/></alternatives>
</disp-formula>
Solving this pair of equations yields
<disp-formula id="eqn33">
<alternatives><graphic xlink:href="282269_eqn33.gif"/></alternatives>
</disp-formula>
To find the posterior mode of the remaining parameters requires some work. First we recall that the normal inverse-Wishart prior is proportional to:
<disp-formula id="eqn34">
<alternatives><graphic xlink:href="282269_eqn34.gif"/></alternatives>
</disp-formula>
The required equation we are interested in is (C).
<disp-formula id="eqn35">
<alternatives><graphic xlink:href="282269_eqn35.gif"/></alternatives>
</disp-formula>
Now to derive the M-step objective we remove the constant terms and add on the log prior. This leads to
<disp-formula id="eqn36">
<alternatives><graphic xlink:href="282269_eqn36.gif"/></alternatives>
</disp-formula>
This can be rewritten as
<disp-formula id="eqn37">
<alternatives><graphic xlink:href="282269_eqn37.gif"/></alternatives>
</disp-formula>
Now define <inline-formula><alternatives><inline-graphic xlink:href="282269_inline10.gif"/></alternatives></inline-formula> and note the following algebraic rearrangements.
<disp-formula id="eqn38">
<alternatives><graphic xlink:href="282269_eqn38.gif"/></alternatives>
</disp-formula>
This allows us to rewrite <xref ref-type="disp-formula" rid="eqn37">equation 37</xref> as
<disp-formula id="eqn39">
<alternatives><graphic xlink:href="282269_eqn39.gif"/></alternatives>
</disp-formula>
This can be written as:
<disp-formula id="eqn40">
<alternatives><graphic xlink:href="282269_eqn40.gif"/></alternatives>
</disp-formula>
where,
<disp-formula id="eqn41">
<alternatives><graphic xlink:href="282269_eqn41.gif"/></alternatives>
</disp-formula></p>
<p>Thus the parameters of the posterior mode are:
<disp-formula id="eqn42">
<alternatives><graphic xlink:href="282269_eqn42.gif"/></alternatives>
</disp-formula>
To summarise the EM algorithm, we iterate between the two steps:</p>
<p>E-Step: Given the current parameters compute the values given by equations (<xref ref-type="disp-formula" rid="eqn28">28</xref>), with formulas provided in equations (<xref ref-type="disp-formula" rid="eqn7">7</xref>) and (<xref ref-type="disp-formula" rid="eqn8">8</xref>).</p>
<p>M-Step: Compute
<disp-formula id="ueqn8">
<alternatives><graphic xlink:href="282269_ueqn8.gif"/></alternatives>
</disp-formula>
and
<disp-formula id="ueqn9">
<alternatives><graphic xlink:href="282269_ueqn9.gif"/></alternatives>
</disp-formula>
as well as
<disp-formula id="ueqn10">
<alternatives><graphic xlink:href="282269_ueqn10.gif"/></alternatives>
</disp-formula>
Compute the MAP estimates given by equations (<xref ref-type="disp-formula" rid="eqn42">42</xref>). These estimates are then used in the following iteration of the E-step. Iterate until <italic>&#x007C;Q</italic>(<bold><italic>&#x03B8;</italic></bold><italic>&#x007C;</italic><bold><italic>&#x03B8;</italic></bold><sub><italic>t</italic></sub>) <italic>-Q</italic>(<bold><italic>&#x03B8;</italic></bold><italic>&#x007C;</italic><bold><italic>&#x03B8;</italic><sub>t-</sub>1</bold>)<italic>&#x007C; &#x003C; &#x03B4;</italic> for some pre-specified <italic>&#x03B4; &#x003E;</italic> 0.</p>
</sec>
<sec id="s5b">
<label>5.2</label>
<title>Appendix 2</title>
<p>To derive the Gibbs sampler we write down all the conditional probabilities. Then, exploiting conjugacy, we can marginalise parameters in the model. Recall the total joint probability is the following:
<disp-formula id="eqn43">
<alternatives><graphic xlink:href="282269_eqn43.gif"/></alternatives>
</disp-formula>
Suppose we know the hidden latent component allocations <italic>z</italic><sub><italic>i</italic></sub> and outlier allocations <italic>&#x03C6;</italic><sub><italic>i</italic></sub>. Then we could sample from the a required normal distribution. The conditional probability of the parameters given the allocations is given by:
<disp-formula id="eqn44">
<alternatives><graphic xlink:href="282269_eqn44.gif"/></alternatives>
</disp-formula>
The prior is conjugate and so the posterior belongs to the same parametric family as the prior, a NIW distribution, and so the parameters can be updated as follows:
<disp-formula id="eqn45">
<alternatives><graphic xlink:href="282269_eqn45.gif"/></alternatives>
</disp-formula>
where <italic>n</italic><sub><italic>k</italic></sub> &#x003D;<italic>&#x007C;&#x007B;</italic><bold>x</bold><sub><italic>i</italic></sub><italic>&#x007C;z</italic><sub><italic>i</italic></sub> &#x003D; <italic>k, &#x03C6;<sub>i</sub></italic> &#x003D; 1<italic>&#x007D;&#x007C;</italic>. Now we write down the conditional of the component allocations
<disp-formula id="eqn46">
<alternatives><graphic xlink:href="282269_eqn46.gif"/></alternatives>
</disp-formula>
The first term in this equation is
<disp-formula id="eqn47">
<alternatives><graphic xlink:href="282269_eqn47.gif"/></alternatives>
</disp-formula>
To calculate the numerator we proceed by marginalising over <bold><italic>&#x03C0;</italic></bold> as follows
<disp-formula id="eqn48">
<alternatives><graphic xlink:href="282269_eqn48.gif"/></alternatives>
</disp-formula>
Hence, we arrive at the following probability:
<disp-formula id="eqn49">
<alternatives><graphic xlink:href="282269_eqn49.gif"/></alternatives>
</disp-formula>
The conditional for the second term of 46 is more tricky. First note the following conditional distributions
<disp-formula id="eqn50">
<alternatives><graphic xlink:href="282269_eqn50.gif"/></alternatives>
</disp-formula>
where we denote <italic>X</italic><sub><italic>k\i</italic></sub> as the observations associated with class <italic>k</italic>, besides <italic>x</italic><sub><italic>i</italic></sub>. Now, we first note that:
<disp-formula id="eqn51">
<alternatives><graphic xlink:href="282269_eqn51.gif"/></alternatives>
</disp-formula>
Thus, we find an equation for the numerator, using the fact that terms associated with <italic>&#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 0 do not depend on <italic>k</italic> and thus can be absorbed into the normalising constant.
<disp-formula id="eqn52">
<alternatives><graphic xlink:href="282269_eqn52.gif"/></alternatives>
</disp-formula>
This is the marginal likelihood of the data. Thus the ratio in 51 is the posterior predictive which is given by the non-centred T-distribution with formula given by:
<disp-formula id="ueqn11">
<alternatives><graphic xlink:href="282269_ueqn11.gif"/></alternatives>
</disp-formula>
Thus, we can compute the following:
<disp-formula id="eqn53">
<alternatives><graphic xlink:href="282269_eqn53.gif"/></alternatives>
</disp-formula>
It remains to compute the conditional for the <italic>&#x03C6;</italic><sub><italic>i</italic></sub>. By first recalling that <italic>&#x03C6;</italic><sub><italic>i</italic></sub> is binary we see that
<disp-formula id="eqn54">
<alternatives><graphic xlink:href="282269_eqn54.gif"/></alternatives>
</disp-formula>
can be written as
<disp-formula id="eqn55">
<alternatives><graphic xlink:href="282269_eqn55.gif"/></alternatives>
</disp-formula>
First we need to compute a formula for <italic>p</italic><sub>0</sub>(<italic>&#x03C6;</italic><sub><italic>i</italic></sub>&#x007C;&#x03C6;<sub>-i</sub>, <italic>u, v</italic>). First we see that
<disp-formula id="eqn56">
<alternatives><graphic xlink:href="282269_eqn56.gif"/></alternatives>
</disp-formula>
The numerator can be computed by marginalising over &#x03F5;:
<disp-formula id="eqn57">
<alternatives><graphic xlink:href="282269_eqn57.gif"/></alternatives>
</disp-formula>
We denote &#x03A3; 1 (&#x03D5;<sub><italic>i</italic></sub>&#x003D;1)&#x003D;&#x03C4;<sub>0</sub>&#x003D;1-&#x03C4;<sub>1</sub> Then it is easy to see that
<disp-formula id="eqn58">
<alternatives><graphic xlink:href="282269_eqn58.gif"/></alternatives>
</disp-formula>
Hence,
<disp-formula id="eqn59">
<alternatives><graphic xlink:href="282269_eqn59.gif"/></alternatives>
</disp-formula>
where <italic>n</italic> &#x003D; <italic>&#x03C4;</italic><sub>1</sub> &#x002B; <italic>&#x03C4;</italic><sub>2</sub>. In general,
<disp-formula id="eqn60">
<alternatives><graphic xlink:href="282269_eqn60.gif"/></alternatives>
</disp-formula>
Now we return to computing <italic>p</italic>(<bold>x</bold><sub><italic>i</italic></sub> <italic>&#x007C;</italic><bold>x</bold><sub><italic>-i</italic></sub>, <italic>Z, &#x03B8;, &#x03C6;</italic><sub><italic>i</italic></sub> &#x003D; 1, &#x03C6;, <italic>&#x03B2;, u, v, H</italic>). First we see that
<disp-formula id="eqn61">
<alternatives><graphic xlink:href="282269_eqn61.gif"/></alternatives>
</disp-formula>
Thus if we integrate over the parameters, we would have a ratio of marginal likelihoods giving the posterior predictive which is a non-centered T-distribution:
<disp-formula id="eqn62">
<alternatives><graphic xlink:href="282269_eqn62.gif"/></alternatives>
</disp-formula>
In the other case that <italic>&#x03C6;</italic> &#x003D; 0, we have that
<disp-formula id="eqn63">
<alternatives><graphic xlink:href="282269_eqn63.gif"/></alternatives>
</disp-formula>
Thus we can compute:
<disp-formula id="eqn64">
<alternatives><graphic xlink:href="282269_eqn64.gif"/></alternatives>
</disp-formula>
and sample from the required distribution. Thus, we can summarise the collapsed Gibbs sampler as follows:</p>
<list list-type="order">
<list-item><p>Update the priors with the labelled data</p></list-item>
<list-item><p>For the unlabelled observations, in turn, compute the probability of assigning to each component</p></list-item>
<list-item><p>Sample a label according to this probability</p></list-item>
<list-item><p>Compute the probability of belonging to this class or the outlier component</p></list-item>
<list-item><p>Sample an indicator to a class specific component or the outlier component</p></list-item>
<list-item><p>If we assign to the class specific component update the class specific posterior distribution with the statistics of this observation</p></list-item>
<list-item><p>Update other posteriors as appropriate.</p></list-item>
<list-item><p>Once all unlabelled observations have a been assigned, consider the observations sequentially, removing the statistics from the posteriors and then performing steps 2-7. We repeat this process for all unlabelled observations.</p></list-item>
<list-item><p>repeat 7-8 until convergence of the Markov-chain.</p></list-item>
</list>
<p>The computational bottleneck in the algorithm is computing the posterior updates for the parameters
<disp-formula id="eqn65">
<alternatives><graphic xlink:href="282269_eqn65.gif"/></alternatives>
</disp-formula>
We first note that
<disp-formula id="eqn66">
<alternatives><graphic xlink:href="282269_eqn66.gif"/></alternatives>
</disp-formula>
Let us denote <inline-formula><alternatives><inline-graphic xlink:href="282269_inline11.gif"/></alternatives></inline-formula> Thus we can derive a set of iterative updates to speed up computation when adding/removing statistics from clusters. More precisely, indicating updated posterior parameters by a prime, if we remove statistics of observation <italic>i</italic> from cluster <italic>k</italic>, we see that
<disp-formula id="eqn67">
<alternatives><graphic xlink:href="282269_eqn67.gif"/></alternatives>
</disp-formula>
Likewise if we add the statistics of observation <italic>i</italic> to cluster <italic>k</italic>, we see that
<disp-formula id="eqn68">
<alternatives><graphic xlink:href="282269_eqn68.gif"/></alternatives>
</disp-formula></p>
</sec>
<sec id="s5c">
<label>5.3</label>
<title>Appendix 3</title>
<fig id="fig15" position="float" fig-type="figure">
<label>Figure 15:</label>
<caption><title>Plot of the log-posterior at each iteration of the EM algorithm to demonstrate monotonicity and convergence</title></caption>
<graphic xlink:href="282269_fig15.tif"/>
</fig>
</sec>
<sec id="s5d">
<label>5.4</label>
<title>Appendix 4</title>
<fig id="fig16" position="float" fig-type="figure">
<label>Figure 16:</label>
<caption><title>Trace plots of the number of proteins allocated to the known components in each of 6 parallel MCMC runs. Chain 4 is discarded because of lack of convergence. 600 samples are retained from remaining chains and pooled.</title></caption>
<graphic xlink:href="282269_fig16.tif"/>
</fig>
</sec>
<sec id="s5e">
<label>5.5</label>
<title>Appendix 5</title>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Macro F-1 score classifier evaluation on the Drosophila dataset</p></caption>
<graphic xlink:href="282269_tbl2.tif"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Macro F-1 score classifier evaluation on the Chicken DT40 dataset</p></caption>
<graphic xlink:href="282269_tbl3.tif"/>
</table-wrap>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Macro F-1 score classifier evaluation on the mouse dataset</p></caption>
<graphic xlink:href="282269_tbl4.tif"/>
</table-wrap>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Macro F-1 score classifier evaluation on the HeLa dataset</p></caption>
<graphic xlink:href="282269_tbl5.tif"/>
</table-wrap>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Macro F-1 score classifier evaluation on the U2-OS dataset</p></caption>
<graphic xlink:href="282269_tbl6.tif"/>
</table-wrap>
</sec>
<sec id="s5f">
<label>5.6</label>
<title>Appendix 6</title>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Quadratic Loss classifier evaluation on the Drosphila dataset</p></caption>
<graphic xlink:href="282269_tbl7.tif"/>
</table-wrap>
<table-wrap id="tbl8" orientation="portrait" position="float">
<label>Table 8:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Quadratic Loss classifier evaluation on the Chicken DT40 dataset</p></caption>
<graphic xlink:href="282269_tbl8.tif"/>
</table-wrap>
<table-wrap id="tbl9" orientation="portrait" position="float">
<label>Table 9:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Quadratic Loss classifier evaluation on the mouse dataset</p></caption>
<graphic xlink:href="282269_tbl9.tif"/>
</table-wrap>
<table-wrap id="tbl10" orientation="portrait" position="float">
<label>Table 10:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Quadratic Loss classifier evaluation on the HeLa dataset</p></caption>
<graphic xlink:href="282269_tbl10.tif"/>
</table-wrap>
<table-wrap id="tbl11" orientation="portrait" position="float">
<label>Table 11:</label>
<caption><p>Adjusted P-values for pairwise T-tests for Quadratic Loss classifier evaluation on the U2-OS dataset</p></caption>
<graphic xlink:href="282269_tbl11.tif"/>
</table-wrap>
</sec>
</app>
</app-group>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="other"><string-name><surname>Banfield</surname>, <given-names>J. D.</given-names></string-name> and <string-name><surname>Raftery</surname>, <given-names>A. E.</given-names></string-name><year>1993</year>. <article-title>Model-based gaussian and non-gaussian clustering</article-title>. <source>Biometrics</source>, pages <fpage>803</fpage>&#x2013;<lpage>821</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Benjamini</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Hochberg</surname>, <given-names>Y.</given-names></string-name><year>1995</year>. <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>. <source>Journal of the royal statistical society. Series B (Methodological)</source>, pages <fpage>289</fpage>&#x2013;<lpage>300</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Boyle</surname>, <given-names>E. I.</given-names></string-name>, <string-name><surname>Weng</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gollub</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jin</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Botstein</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cherry</surname>, <given-names>J. M.</given-names></string-name>, and <string-name><surname>Sherlock</surname>, <given-names>G.</given-names></string-name><year>2004</year>. <article-title>Go:: Termfinder&#x2013;open source software for accessing gene ontology information and finding significantly enriched gene ontology terms associated with a list of genes</article-title>. <source>Bioinformatics</source>, <volume>20</volume>(<issue>18</issue>), <fpage>3710</fpage>&#x2013;<lpage>3715</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Christoforou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Groen</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name>, and <string-name><surname>Trotter</surname>, <given-names>M. W.</given-names></string-name><year>2013</year>. <article-title>The effect of organelle discovery upon sub-cellular protein localisation</article-title>. <source>Journal of proteomics</source>, <volume>88</volume>, <fpage>129</fpage>&#x2013;<lpage>140</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Mulvey</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name>, and <string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name> (<year>2016a</year>). <article-title>A bio-conductor workflow for processing and analysing spatial proteomics data</article-title>. <source>F1000Research</source>, <volume>5</volume>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Holden</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Wojnar</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Mulvey</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Christoforou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Groen</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Trotter</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Kohlbacher</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name>, and <string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name> (<year>2016b</year>). <article-title>Learning from heterogeneous data sources: an application in spatial proteomics</article-title>. <source>PLoS computational biology</source>, <volume>12</volume>(<issue>5</issue>), <fpage>e1004920</fpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Brooks</surname>, <given-names>S. P.</given-names></string-name> and <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name><year>1998</year>. <article-title>General methods for monitoring con-vergence of iterative simulations</article-title>. <source>Journal of computational and graphical statistics</source>, <volume>7</volume>(<issue>4</issue>), <fpage>434</fpage>&#x2013;<lpage>455</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Christoforou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mulvey</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Geladaki</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hurrell</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Hayward</surname>, <given-names>P. C.</given-names></string-name>, <string-name><surname>Naake</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Viner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Arias</surname>, <given-names>A. M.</given-names></string-name>, <etal>et al.</etal> (<year>2016</year>). <article-title>A draft map of the mouse pluripotent stem cell spatial proteome</article-title>. <source>Nature communications</source>, <volume>7</volume>, <fpage>9992</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Cooke</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Savage</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Kirk</surname>, <given-names>P. D.</given-names></string-name>, <string-name><surname>Darkins</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Wild</surname>, <given-names>D. L.</given-names></string-name><year>2011</year>. <article-title>Bayesian hierarchical clustering for microarray time series data with repli-cates and outlier measurements</article-title>. <source>BMC bioinformatics</source>, <volume>12</volume>(<issue>1</issue>), <fpage>399</fpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Coretto</surname>, <given-names>P.</given-names></string-name> and <string-name><surname>Hennig</surname>, <given-names>C.</given-names></string-name><year>2016</year>. <article-title>Robust improper maximum likeli-hood: tuning, computation, and a comparison with other methods for robust gaussian clustering</article-title>. <source>Journal of the American Statistical Association</source>, <volume>111</volume>(<issue>516</issue>), <fpage>1648</fpage>&#x2013;<lpage>1659</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>De Duve</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Beaufay</surname>, <given-names>H.</given-names></string-name><year>1981</year>. <article-title>A short history of tissue fractionation</article-title>. <source>The Journal of cell biology</source>, <volume>91</volume>(<issue>3</issue>), <fpage>293</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Dempster</surname>, <given-names>A. P.</given-names></string-name>, <string-name><surname>Laird</surname>, <given-names>N. M.</given-names></string-name>, and <string-name><surname>Rubin</surname>, <given-names>D. B.</given-names></string-name><year>1977</year>. <article-title>Maximum likelihood from incomplete data via the em algorithm</article-title>. <source>Journal of the royal statistical society. Series B (methodological)</source>, pages <fpage>1</fpage>&#x2013;<lpage>38</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Dunkley</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Watson</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Griffin</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Dupree</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name><year>2004</year>. <article-title>Localization of organelle proteins by isotope tagging (lopit</article-title>). <source>Molecular &#x0026; Cellular Proteomics</source>, <volume>3</volume>(<issue>11</issue>), <fpage>1128</fpage>&#x2013;<lpage>1134</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Dunkley</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Hester</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shadforth</surname>, <given-names>I. P.</given-names></string-name>, <string-name><surname>Runions</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Weimar</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Hanton</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Griffin</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Bessant</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Brandizzi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Hawes</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal> (<year>2006</year>). <article-title>Mapping the arabidopsis organelle proteome</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>103</volume>(<issue>17</issue>), <fpage>6518</fpage>&#x2013;<lpage>6523</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="other"><string-name><surname>Fraley</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Raftery</surname>, <given-names>A. E.</given-names></string-name><year>2005</year>. <article-title>Bayesian regularization for normal mixture estimation and model-based clustering</article-title>. <source>Technical report, Washington Univ Seattle Dept of Statistics</source>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Fraley</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Raftery</surname>, <given-names>A. E.</given-names></string-name><year>2007</year>. <article-title>Bayesian regularization for normal mixture estimation and model-based clustering</article-title>. <source>Journal of Classification</source>, <volume>24</volume>(<issue>2</issue>), <fpage>155</fpage>&#x2013;<lpage>181</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name> and <string-name><surname>Lilley</surname>, <given-names>K.</given-names></string-name><year>2012</year>. <article-title>Msnbase - an r/bioconductor package for isobaric tagged mass spectrometry data visualization, processing and quan-titation</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>288</fpage>&#x2013;<lpage>289</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Vizca&#x00ED;no</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Hermjakob</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Huber</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name><year>2010</year>. <article-title>Organelle proteomics experimental designs and analysis</article-title>. <source>Pro-teomics</source>, <volume>10</volume>(<issue>22</issue>), <fpage>3957</fpage>&#x2013;<lpage>3969</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="other"><string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Burger</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Nightingale</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Groen</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Campbell</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Mulvey</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Christoforou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ferro</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name> (<year>2014a</year>). <article-title>A foundation for reliable spatial proteomics data analysis</article-title>. <source>Molecular &#x0026; Cellular Proteomics</source>, pages <fpage>mcp</fpage>&#x2013;<lpage>M113</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="other"><string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Wieczorek</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Burger</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name> (<year>2014b</year>). <article-title>Mass-spectrometry based spatial proteomics data analysis using proloc and prolocdata</article-title>. <source>Bioinformatics</source>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="other"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name> and <string-name><surname>Rubin</surname>, <given-names>D. B.</given-names></string-name><year>1992</year>. <article-title>Inference from iterative simulation using multiple sequences</article-title>. <source>Statistical science</source>, pages <fpage>457</fpage>&#x2013;<lpage>472</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="book"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Carlin</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Stern</surname>, <given-names>H. S.</given-names></string-name>, and <string-name><surname>Rubin</surname>, <given-names>D. B.</given-names></string-name> (<year>1995</year>). <source>Bayesian Data Analysis</source>. <publisher-name>Chapman &#x0026; Hall, London</publisher-name>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Gibson</surname>, <given-names>T. J.</given-names></string-name><year>2009</year>. <article-title>Cell regulation: determined to signal discrete cooperation</article-title>. <source>Trends in biochemical sciences</source>, <volume>34</volume>(<issue>10</issue>), <fpage>471</fpage>&#x2013;<lpage>482</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Gneiting</surname>, <given-names>T.</given-names></string-name> and <string-name><surname>Raftery</surname>, <given-names>A. E.</given-names></string-name><year>2007</year>. <article-title>Strictly proper scoring rules, pre-diction, and estimation</article-title>. <source>Journal of the American Statistical Association</source>, <volume>102</volume>(<issue>477</issue>), <fpage>359</fpage>&#x2013;<lpage>378</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Hall</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Hester</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Griffin</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name>, and <string-name><surname>Jackson</surname>, <given-names>A. P.</given-names></string-name><year>2009</year>. <article-title>The organelle proteome of the dt40 lymphocyte cell line</article-title>. <source>Molecular &#x0026; Cellular Proteomics</source>, <volume>8</volume>(<issue>6</issue>), <fpage>1295</fpage>&#x2013;<lpage>1305</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="confproc"><string-name><surname>Hazimeh</surname>, <given-names>H.</given-names></string-name> and <string-name><surname>Zhai</surname>, <given-names>C.</given-names></string-name><year>2015</year>. <source>Axiomatic analysis of smoothing methods in language models for pseudo-relevance feedback</source>. <conf-name>Proceedings of the 2015 International Conference on The Theory of Information Retrieval</conf-name>, pages <fpage>141</fpage>&#x2013;<lpage>150</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>He</surname>, <given-names>H.</given-names></string-name> and <string-name><surname>Garcia</surname>, <given-names>E. A.</given-names></string-name><year>2009</year>. <article-title>Learning from imbalanced data</article-title>. <source>IEEE Transactions on knowledge and data engineering</source>, <volume>21</volume>(<issue>9</issue>), <fpage>1263</fpage>&#x2013;<lpage>1284</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Heard</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Sklen&#x00E1;&#x0159;</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Tome</surname>, <given-names>D. F.</given-names></string-name>, <string-name><surname>Robatzek</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Jones</surname>, <given-names>A. M.</given-names></string-name><year>2015</year>. <article-title>Identification of regulatory and cargo proteins of endosomal and secretory pathways in arabidopsis thaliana by proteomic dissection</article-title>. <source>Molecular &#x0026; Cellular Proteomics</source>, <volume>14</volume>(<issue>7</issue>), <fpage>1796</fpage>&#x2013;<lpage>1813</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="other"><string-name><surname>Hennig</surname>, <given-names>C.</given-names></string-name><year>2004</year>. <article-title>Breakdown points for maximum likelihood estimators of location-scale mixtures</article-title>. <source>Annals of Statistics</source>, pages <fpage>1313</fpage>&#x2013;<lpage>1340</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Itzhak</surname>, <given-names>D. N.</given-names></string-name>, <string-name><surname>Tyanova</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Cox</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Borner</surname>, <given-names>G. H.</given-names></string-name><year>2016</year>. <article-title>Global, quan-titative and dynamic mapping of protein subcellular localization</article-title>. <source>Elife</source>, <volume>5</volume>, <fpage>e16950</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kau</surname>, <given-names>T. R.</given-names></string-name>, <string-name><surname>Way</surname>, <given-names>J. C.</given-names></string-name>, and <string-name><surname>Silver</surname>, <given-names>P. A.</given-names></string-name><year>2004</year>. <article-title>Nuclear transport and cancer: from mechanism to intervention</article-title>. <source>Nature Reviews Cancer</source>, <volume>4</volume>(<issue>2</issue>), <fpage>106</fpage>&#x2013;<lpage>117</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kirk</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Babtie</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Stumpf</surname>, <given-names>M.</given-names></string-name> <year>2015</year>. <article-title>Systems biology (un) certainties</article-title>. <source>Science</source>, <volume>350</volume>(<issue>6259</issue>), <fpage>386</fpage>&#x2013;<lpage>388</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Kirk</surname>, <given-names>P. D.</given-names></string-name>, <string-name><surname>Huvet</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Melamed</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Maertens</surname>, <given-names>G. N.</given-names></string-name>, and <string-name><surname>Bangham</surname>, <given-names>C. R.</given-names></string-name><year>2016</year>. <article-title>Retroviruses integrate into a shared, non-palindromic dna motif</article-title>. <source>Nature microbiology</source>, <volume>2</volume>, <fpage>16212</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Laurila</surname>, <given-names>K.</given-names></string-name> and <string-name><surname>Vihinen</surname>, <given-names>M.</given-names></string-name><year>2009</year>. <article-title>Prediction of disease-related mutations affecting protein localization</article-title>. <source>BMC genomics</source>, <volume>10</volume>(<issue>1</issue>), <fpage>122</fpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Liley</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Todd</surname>, <given-names>J. A.</given-names></string-name>, and <string-name><surname>Wallace</surname>, <given-names>C.</given-names></string-name><year>2017</year>. <article-title>A method for identifying ge-netic heterogeneity within phenotypically defined disease subgroups</article-title>. <source>Na-ture genetics</source>, <volume>49</volume>(<issue>2</issue>), <fpage>310</fpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>L&#x00F6;nnberg</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Svensson</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>James</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Fernandez-Ruiz</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Sebina</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Montandon</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Soon</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Fogg</surname>, <given-names>L. G.</given-names></string-name>, <string-name><surname>Nair</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Liligeto</surname>, <given-names>U. N.</given-names></string-name>, <etal>et al.</etal> (<year>2017</year>). <article-title>Single-cell rna-seq and computational analysis using temporal mixture modeling resolves th1/tfh fate bifurcation in malaria</article-title>. <source>Science Immunology</source>, <volume>2</volume>(<issue>9</issue>).</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Luheshi</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Crowther</surname>, <given-names>D. C.</given-names></string-name>, and <string-name><surname>Dobson</surname>, <given-names>C. M.</given-names></string-name><year>2008</year>. <article-title>Protein mis-folding and disease: from the test tube to the organism</article-title>. <source>Current opinion in chemical biology</source>, <volume>12</volume>(<issue>1</issue>), <fpage>25</fpage>&#x2013;<lpage>31</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="book"><string-name><surname>Manning</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Raghavan</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Sch&#x00FC;tze</surname>, <given-names>H.</given-names></string-name> (<year>2008</year>). <source>Introduction to Information Retrieval</source>. <publisher-name>Cambridge University Press</publisher-name>, <publisher-loc>New York, NY, USA.</publisher-loc></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="other"><string-name><surname>Meyer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Dimitriadou</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hornik</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Weingessel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Leisch</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>C.-C.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>C.-C.</given-names></string-name>, and <string-name><surname>Meyer</surname>, <given-names>M. D.</given-names></string-name><year>2017</year>. <source>R-package e1071</source>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Mulvey</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Geladaki</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Britov&#x0161;ek</surname>, <given-names>N. K.</given-names></string-name>, <string-name><surname>Nightingale</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Christoforou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Elzek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Deery</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name> <year>2017</year>. <article-title>Using hyperLOPIT to perform high-resolution mapping of the spatial proteome</article-title>. <source>Nature Protocols</source>, <volume>12</volume>(<issue>6</issue>), <fpage>1110</fpage>&#x2013;<lpage>1135</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Murphy</surname>, <given-names>K. P.</given-names></string-name><year>2007</year>. <article-title>Conjugate bayesian analysis of the gaussian distribu-tion</article-title>. <source>Techincal Report</source>, <volume>1</volume>, <fpage>16</fpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="other"><string-name><surname>Murphy</surname>, <given-names>K. P.</given-names></string-name> (<year>2012</year>). <source>Machine learning: a probabilistic perspective</source>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Parsons</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Fern&#x00E1;ndez-Ni&#x00F1;o</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Heazlewood</surname>, <given-names>J.</given-names></string-name> <year>2014</year>. <article-title>Separation of the plant golgi apparatus and endoplasmic reticulum by free-flow elec-trophoresis</article-title>. <source>Methods in molecular biology (Clifton, NJ)</source>, <volume>1072</volume>, <fpage>527</fpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="other"><collab>R Core Team</collab> <year>2017</year>. <chapter-title>R: A Language and Environment for Statistical Computing</chapter-title>. <source>R Foundation for Statistical Computing</source>, Vienna, Austria.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Sadowski</surname>, <given-names>P. G.</given-names></string-name>, <string-name><surname>Dunkley</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Shadforth</surname>, <given-names>I. P.</given-names></string-name>, <string-name><surname>Dupree</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Bessant</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Griffin</surname>, <given-names>J. L.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name><year>2006</year>. <article-title>Quantitative proteomic approach to study subcellular localization of membrane proteins</article-title>. <source>Nature protocols</source>, <volume>1</volume>(<issue>4</issue>), <fpage>1778</fpage>&#x2013;<lpage>1789</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Shannon</surname>, <given-names>C. E.</given-names></string-name><year>1948</year>. <article-title>A mathematical theory of communication</article-title>. <source>The Bell System Technical Journal</source>, <volume>27</volume>(<issue>3</issue>), <fpage>379</fpage>&#x2013;<lpage>423</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="other"><string-name><surname>Siljee</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Bernard</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Ersoy</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Marley</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Von Zastrow</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Reiter</surname>, <given-names>J. F.</given-names></string-name>, and <string-name><surname>Vaisse</surname>, <given-names>C.</given-names></string-name><year>2018</year>. <article-title>Subcellular local-ization of mc4r with adcy3 at neuronal primary cilia underlies a common pathway for genetic predisposition to obesity</article-title>. <source>Nat Genet</source>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Tan</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Dvinge</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Christoforou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bertone</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Martinez Arias</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name><year>2009</year>. <article-title>Mapping organelle proteins and protein complexes in drosophila melanogaster</article-title>. <source>Journal of proteome research</source>, <volume>8</volume>(<issue>6</issue>), <fpage>2667</fpage>&#x2013;<lpage>2678</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="other"><string-name><surname>Thul</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>&#x00C5;kesson</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wiking</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mahdessian</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Geladaki</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ait Blal</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Alm</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Asplund</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bj&#x00F6;rk</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Breckels</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>B&#x00E4;ckstr&#x00F6;m</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Danielsson</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Fagerberg</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Fall</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gatto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gnann</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hober</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hjelmare</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Johansson</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lindskog</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Mulder</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Mulvey</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Nilsson</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Oksvold</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Rockberg</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Schutten</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Schwenk</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Sivertsson</surname>, <given-names>&#x00C5;A.</given-names></string-name>, <string-name><surname>Sj&#x00F6;stedt</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Skogs</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Stadler</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Sullivan</surname>, <given-names>D. P.</given-names></string-name>, <string-name><surname>Tegel</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Winsnes</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zwahlen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mardinoglu</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pont&#x00B4;en</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>von Feilitzen</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Lilley</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Uhl&#x00B4;en</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Lundberg</surname>, <given-names>E.</given-names></string-name><year>2017</year>. <article-title>A subcellular map of the human proteome</article-title>. <source>Science</source>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="confproc"><string-name><surname>Valcarce</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Parapar</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Barreiro</surname>, <given-names>A.</given-names></string-name><year>2016</year>. <source>Additive smoothing for relevance-based language modelling of recommender systems</source>. <conf-name>Proceedings of the 4th Spanish Conference on Information Retrieval</conf-name>, pages <fpage>1</fpage>&#x2013;<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Yu</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.-G.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>He</surname>, <given-names>Q.-Y.</given-names></string-name><year>2012</year>. <article-title>clusterprofiler: an r package for comparing biological themes among gene clusters</article-title>. <source>Omics: a journal of integrative biology</source>, <volume>16</volume>(<issue>5</issue>), <fpage>284</fpage>&#x2013;<lpage>287</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>