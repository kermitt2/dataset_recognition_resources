<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/056358</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Novel Algorithm for the Maximal Fit Problem in Boolean Networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Karlebach</surname><given-names>Guy</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>MIT-Broad Foundry, Broa d Institute of MIT and Harvard</institution>, Cambridge, Massachusetts, <country>USA</country></aff>
</contrib-group>
<author-notes>
<fn id="n1"><p>Email: <email>guykarle@broadinstitute.org</email></p></fn>
</author-notes>
<pub-date pub-type="epub"><year>2016</year></pub-date>
<elocation-id>056358</elocation-id>
<history>
<date date-type="received"><day>31</day><month>5</month><year>2016</year></date>
<date date-type="accepted"><day>31</day><month>5</month><year>2016</year></date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2016</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="056358.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract><title>Abstract</title>
<p>Gene regulatory networks (GRNs) are increasingly used for explaining biological processes with complex transcriptional regulation. A GRN links the expression levels of a set of genes via regulatory controls that gene products exert on one another. Boolean networks are a common modeling choice since they balance between detail and ease of analysis. However, even for Boolean networks the problem of fitting a given network model to an expression dataset is NP-Complete. Previous methods have addressed this issue heuristically or by focusing on acyclic networks and specific classes of regulation functions. In this paper we introduce a novel algorithm for this problem that makes use of sampling in order to handle large datasets. Our algorithm can handle time series data for any network type and steady state data for acyclic networks. Using in-silico time series data we demonstrate good performance on large datasets with a significant level of noise.</p>
</abstract>
<kwd-group kwd-group-type="author"><title>Keywords</title>
<kwd>Boolean network</kwd>
<kwd>Inference</kwd>
<kwd>Sampling</kwd>
</kwd-group>
<counts>
<page-count count="17"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><title>Introduction</title>
<p>Numerous biological phenomena arise through interactions between cellular components[<xref ref-type="bibr" rid="c1">1</xref>]. Gene regulatory networks (GRNs) are a paradigm that explains various processes such as embryonic development, circadian rhythms and disease progression as a product of interactions between genes that regulate each other&#x2019;s expression levels [<xref ref-type="bibr" rid="c2">2</xref>&#x2013;<xref ref-type="bibr" rid="c4">4</xref>], Various methodologies were suggested for modeling and analyzing these networks [<xref ref-type="bibr" rid="c5">5</xref>].</p>
<p>One of the simplest GRN models is the Boolean network[<xref ref-type="bibr" rid="c6">6</xref>]. Gene expression levels are marked as either expressed (Boolean 1) or not expressed (Boolean 0), and regulatory interactions such as those performed by transcription factors are described using Boolean functions. Although this formulation is simple, it can characterize a broad range of networks and dynamic behaviors [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>].</p>
<p>Researchers have successfully used Boolean networks for establishing various biological hypotheses. For example, Marr et al. [<xref ref-type="bibr" rid="c9">9</xref>] showed that the steady states of their Boolean network correspond to the differentiation states of lymphocytes. Similarly, Orlando et al. showed that a Boolean network model can predict cell cycle states, and explain the cyclic gene expression patterns that they observed in their dataset [<xref ref-type="bibr" rid="c10">10</xref>]. There exist examples from a diverse range of systems, including sporulation in <italic>B.subtillis</italic> [<xref ref-type="bibr" rid="c11">11</xref>], tryptophan biosynthesis in <italic>E.coli</italic> [<xref ref-type="bibr" rid="c12">12</xref>], floral organ determination in <italic>A.thaliana</italic> [<xref ref-type="bibr" rid="c13">13</xref>], and more. Usually the network&#x2019;s states are not derived directly from the data, but rather are determined using independent analysis or simulation and then compared to the data.</p>
<p>A different approach derives the Boolean states of the network directly from the data, such that each measurement is assigned an inferred network state. This allows for example comparison of the network behavior in cases and controls, or of the differences in trajectories of wild-type and mutant strains [<xref ref-type="bibr" rid="c14">14</xref>]. Karlebach and Shamir showed that the problem of finding the best dataset fit to a Boolean network is NP-Complete [<xref ref-type="bibr" rid="c15">15</xref>], and therefore a solution that can handle every instance of the problem efficiently is not likely to exist. Our goal in this work is not to prove the biological merit of this approach since this has been done elsewhere [<xref ref-type="bibr" rid="c14">14</xref>&#x2013;<xref ref-type="bibr" rid="c16">16</xref>], but to systematically investigate a proposed method for alleviating intractability in large datasets.</p>
<p>Several methods that apply to specific network types or greedily search for a solution have been developed. Karlebach and Shamir proposed an inference algorithm that gradually updates the belief in each Boolean value, and can be used with small datasets and uncertain network topologies [<xref ref-type="bibr" rid="c15">15</xref>]. Sharan and Karp used linear programming to solve the problem for acyclic networks in steady state, and showed that it performs well, in particular for a specific class of regulation functions, and that it reliably predicts the regulation functions of signaling networks [<xref ref-type="bibr" rid="c16">16</xref>]. Some methods exist for deriving Boolean states from the dataset alone, which can then be compared to a network model [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>]. In addition, there are various algorithms for computing the Boolean regulation functions [<xref ref-type="bibr" rid="c19">19</xref>&#x2013;<xref ref-type="bibr" rid="c21">21</xref>].</p>
<p>In this paper we take a different approach by making assumptions about the nature of the noise. If the noise is not correlated with a specific regulation function, then as datasets become large, inferring individual network states is more difficult than inferring the types of regulatory interactions, since regulatory interactions occur repeatedly in the data, whereas individual states may occur just once or a few times. Based on this argument, we present a novel algorithm that uses random sampling in order to infer individual states. The algorithm is suitable for time series data or for steady state data in acyclic networks, and we demonstrate its performance using the former. The main idea behind the algorithm is finding a trajectory that fits the largest number of Boolean data points in a sample. With enough data points for the fit, the sample is sufficient for overcoming the effect of incorrect measurements and detecting the correct trajectory. Since going over all possible initial states is infeasible for medium or larger networks, we devise a method that can perform the fit without need of doing so. Our experiments also establish a link between the level of error in the data and the running time required for finding an optimal solution.</p>
<p>The paper is organized as follows: the next section defines the problem, describes the inference algorithm and explains how it achieves good performance and accuracy. The Testing section demonstrates the performance and accuracy of the algorithm using a large simulated dataset. Finally, in the Conclusion section we summarize our findings and outline future work.</p></sec>
<sec id="s2"><title>Inference Algorithm</title>
<p>A Boolean network is a dynamic model that contains N nodes, which we will refer to as <italic><bold>genes</bold></italic>, and N Boolean functions, which we will refer to as <italic><bold>regulation functions</bold></italic>. The inputs of a regulation function are the Boolean values that are assigned to a subset of the genes (the genes in this subset are the <italic><bold>regulators</bold></italic>) at a time i, and the output of a function assigns a value to a single gene, called the <bold>target</bold>, at time i&#x002B;1. A <italic><bold>state</bold></italic> is an assignment of Boolean values to all the genes at a given time point. An initial state assigns a Boolean value to every gene. Then, the states at subsequent times can be derived by simultaneous application of the regulation functions. A set of time consecutive states is known as a <italic><bold>trajectory</bold></italic> of the network (<xref ref-type="fig" rid="fig1"><bold>Figure 1</bold></xref>). The graph that represents the relations between genes and their sets of regulators is called the <italic><bold>network topology</bold></italic>.
<fig id="fig1" position="float" fig-type="figure"><label><underline>Figure 1:</underline></label>
<caption><p>A Boolean network model and one trajectory. The leftmost table represents the trajectory, with the initial state (1,0,0). The middle diagram is the network topology. It shows the regulators of each gene, where there is a directed edge from every regulator to its target. In this case, A regulates B, B regulates C, and C regulates A. Since the trajectory is noiseless, by comparing it with the network topology it is easy to infer that the regulation functions that determine the values of B and C are identity functions, whereas the function that determines A is negation. The tables on the rightmost column specify the model&#x2019;s regulation functions.</p></caption>
<graphic xlink:href="056358_fig1.tif"/>
</fig></p>
<p>The state inference problem requires finding the correct trajectory of a given Boolean network model given a trajectory that contains errors, where errors are Boolean values that changed. In such a noisy trajectory, when the Boolean value of a data point is different than the output of its regulation function, we say that it constitutes a <italic><bold>discrepancy</bold></italic>. A Boolean value assigned to a specific gene at a specific time in the input trajectory will be referred to as a <italic><bold>data point</bold></italic>. Here we will assume that the changes are i.i.d random variables, in other probability of data point to correspond to an incorrect Boolean value is the same for every data point. The number of Boolean values in a trajectory of length T is N T. In terms of computational complexity, neither T nor N is assumed to be constant, and therefore there are 2<sup>NT</sup> different (noisy) trajectories for every network with N nodes and T time points.</p>
<p>The input for the maximal fit problem is a set of noisy trajectories and a network topology, and the output is a minimal set of changes that is necessary for eliminating all discrepancies. This objective is intended to reconstruct the original trajectories before noise was added. If the noise level is very high, e.g. every data point is flipped with probability 0.5, the problem is still defined, but the reconstruction will be meaningless.</p>
<p>Following is an outline for the suggested inference algorithm:
<list list-type="order">
<list-item><p>Infer the Boolean functions by selecting those functions that agree with the maximal number of states in the input trajectories.</p></list-item>
<list-item><p>For each input trajectory,</p>
<list list-type="alpha-lower">
<list-item><p>Find the initial state that fits the largest number of data points in a random sample from this trajectory (<xref ref-type="fig" rid="fig2"><bold>Figure 2</bold></xref>).</p></list-item>
<list-item><p>If there are several initial states that fit the largest number of Boolean values, select the one that generates a trajectory with minimal difference from the input trajectory.</p></list-item>
<list-item><p>Generate a trajectory starting from the selected initial state and return it as a solution for the corresponding input trajectory.</p></list-item>
</list>
</list-item></list>
<fig id="fig2" position="float" fig-type="figure"><label><underline>Figure 2:</underline></label>
<caption><p>Intersecting sets of states in order to find an initial state that is common to as many sampled data points as possible (2 in this example). Given a network topology, a memorization table that encodes sets of initial states that lead to each sampled data point value is generated. Then, the corresponding sets of initial states (represented in this figure both as tries, in which &#x2018;&#x003F;&#x2019;means &#x2018;0 or 1&#x2019;, and as strings) are intersected. The memorization table can also store sets that only <underline>contain</underline> the source states of each data point value, as long as the intersection of the sampled data point states will retrieve an initial state that solves the maximal fit problem. Note that some entries of the memorization table contain two sets, one corresponding to a Boolean 0 and one to a Boolean 1. This can occur during the recursive construction of the table.</p></caption>
<graphic xlink:href="056358_fig2.tif"/>
</fig></p>
<p>Step 1 can be performed using Branch &#x0026; Bound, as described in [<xref ref-type="bibr" rid="c15">15</xref>]. In short, for each row in the truth table of a Boolean function, each one of the two alternative outputs is assigned a score that is proportional to the number of its occurrence in the data. Then, for selecting the best combination of outputs that constitute the Boolean function, we branch at each Boolean output, bound when the greedy, highest scoring completion of the sub-solution scores below the best solution found, and reject illegal solutions. A combination of outputs is an illegal solution if the function that it defines does not depend on the value of one of its regulators.</p>
<p>Assuming that the number of initial states returned by step <bold>2a</bold> is constant, Steps <bold>2b</bold> and <bold>2c</bold> are computed trivially in O(N&#x00B7;T), and so next we focus on step <bold>2a</bold>.</p>
<p>Denote a data point as <italic>(g,t,b)</italic>, where <italic>g</italic> is some gene, <italic>t</italic> is some time and <italic>b</italic> is some Boolean value. An initial state <italic>S</italic> fits the data point (g,t,b) if the trajectory generated from <italic>S</italic> assigns the Boolean value <italic>b</italic> to geneg at time <italic>t</italic> (<xref ref-type="fig" rid="fig2"><bold>Figure 2</bold></xref>). For each data point, a recursive strategy is used for finding all the initial states that fit it:</p>
<p>For a gene <italic>g,</italic> time <italic>t</italic> and Boolean value <italic>b</italic>:
<list list-type="order">
<list-item><p>For each combination of regulator values that generates <italic>b</italic>:
<list list-type="alpha-lower">
<list-item><p>Assign this combination of values to the regulators of <italic>g</italic> at time <italic>t</italic>&#x2013;1</p></list-item>
<list-item><p>Solve the problem recursively for each regulator</p></list-item>
<list-item><p>Intersect the results returned from the recursive calls</p></list-item></list></p></list-item>
<list-item><p>Return a union of the results from step 1</p></list-item></list></p>
<p>The recursion returns a set that can contain an exponential number of states. However, its representation need not be exponential. A set of states can be represented succinctly by marking genes that can take either Boolean value with a special character&#x2019;?&#x2019;. For example, if we have 3 genes, the following annotation: (1,?,0) represents two Boolean states: (1,0,0) and (1,1,0). All union and intersection operations can make use of this symbolic representation. For example, a union between states (1,?,?) and (1,1,?) can be represented by (1,?,?), and an intersection between these states by (1,1,?). We implement these operations using tries.</p>
<p>The stopping condition of the recursion occurs at the initial state, where the solution is trivial - all the states that contain a given set of data point values. Since a memoization table can be built once and used for every possible trajectory, even if this takes time exponential in N, for large T it is still constant per trajectory. In cases where the memorization table needs to be built frequently, for example if there is uncertainty about the network topology, the sets of states can be computed inaccurately. To demonstrate this, we implemented a &#x201C;relaxed intersection&#x201D; operation as follows: to intersect sets A and B, sample a subset C of A such that the trie representing C has half of the leaves of A, and intersect B with A&#x002F;C. Then return as the result of the relaxed intersection: <italic>C &#x222A;(B &#x2229; (A&#x002F;C))</italic>. The result of the relaxed intersection contains the result of the accurate intersection <italic>A &#x2229; B</italic>, and therefore also the correct initial state. Hence, if enough such sets are obtained, the correct initial state can be retrieved from them. We applied the relaxed intersection instead of accurate intersection whenever the trie representation of A had more than 500 leaves.</p>
<p>Given a representation of all the states for each data point, we can select an initial state that fits the largest number of sampled data points using Branch &#x0026; Bound. We bound whenever the current sub-state is common to less data points than the value of the optimal solution found so far. An initial bound can be obtained as follows: Let <italic>&#x03C0;</italic> be the proportion of erroneous data points in the sampled data points. A good value for an initial bound would be (1&#x2212;&#x03C0;)&#x00B7;(# sampled data points), because that is exactly the proportion of correct data points. However, since <italic>&#x03C0;</italic> is not known, we will initialize <italic>&#x03C0;</italic> to p, the probability of error, and use the following loop:
<list list-type="order">
<list-item><p>Perform B&#x0026;B using (l-p)&#x00B7;(# sampled data points) as an initial bound</p></list-item>
<list-item><p>Increase p by 0.05</p></list-item>
</list></p>
<p>Until a solution is found.</p>
<p>When the sample size is large enough, the initial state that we will fit to will be the same one that fits the largest number of data points in the complete trajectory. If in practice there is more than one initial state that fits them, we select as the solution the one that is most similar to the input trajectory. We observed that as T increases, data points become less informative about the initial state, and so we adjusted the sampling probability to decrease with T.</p>
<p>Note that step <bold>2</bold> of the algorithm can be parallelized, although this functionality is currently not implemented in our code. The next section describes the tests that we performed in order to confirm efficiency and accuracy of the inference algorithm.</p></sec>
<sec id="s3"><title>Testing</title>
<p>Since the state inference problem is NP-Complete [<xref ref-type="bibr" rid="c15">15</xref>], an algorithm&#x2019;s ability to cope with large datasets is crucial for its general applicability. Our algorithm optimizes the same objective function as in [<xref ref-type="bibr" rid="c14">14</xref>&#x2013;<xref ref-type="bibr" rid="c16">16</xref>], and therefore its usefulness in analyzing biological datasets follows directly from the findings of these studies. In order to demonstrate that it is suitable for larger datasets and more complex network topologies, we construct the following Boolean network: The network has 25 genes, each of which has 2 regulators (<xref ref-type="fig" rid="fig3"><bold>Figure 3</bold></xref>). The regulators are chosen such that by iterating backwards from a gene to its regulator and to that regulator&#x2019;s regulator and so on, we can reach any other gene. This choice ensures that the network cannot be simplified into independent subnetworks, and that every pair of genes has the potential to influence one another in every trajectory. The regulation functions are XOR, as this choice produces complex dynamic behaviors.</p>
<fig id="fig3" position="float" fig-type="figure"><label><underline>Figure 3:</underline></label>
<caption><p>A diagram of the gene network that was used for testing the inference algorithm. The genes are drawn as circles, and there is a directed edge between every regulator and its target. The network has 25 genes, and each gene has two other genes as regulators, and is itself a regulator of another genes.</p></caption>
<graphic xlink:href="056358_fig3.tif"/>
</fig>
<p>The test dataset contains 100,000 data points, divided into 40 trajectories of length 100 each. A trajectory of length 100 of a cyclic network with 25 nodes has the same number of data points as a steady state acyclic network with 2,500 nodes. The following probabilities are used for generating errors in the input dataset: p<sub>1</sub>&#x003D;0.05, p<sub>2</sub>&#x003D;0.1, p<sub>3</sub>&#x003D;0.15 and p<sub>4</sub>&#x003D;0.2. For example, when using p<sub>4</sub> we change on average every fifth Boolean value in the input. The effects of these noise levels on the first 15 states of the first trajectory in the dataset are illustrated in <xref ref-type="fig" rid="fig4"><bold>Figure 4.</bold></xref></p>
<fig id="fig4" position="float" fig-type="figure"><label><underline>Figure 4:</underline></label>
<caption><p>Illustration of the effect of noise on the first 15 states in the test network&#x2019;s first trajectory. The original states (blue) and the states with addition of noise (red) are subjected to multidimensional scaling, where the distance function is the number of different Boolean values between a pair of states. The states are numbered according to their order in the trajectory. When the level of noise is 0.05 (top left frame), corresponding noisy and noiseless states are relatively close, or even identical in the case of states 2, 7 and 10. As noise level increases the distances between corresponding states grow.</p></caption>
<graphic xlink:href="056358_fig4.tif"/>
</fig>
<p>Then, for each probability pi we measure the running time of the algorithm and the number of incorrectly inferred Boolean values. <xref ref-type="fig" rid="fig5"><bold>Figure 5</bold></xref> summarizes the performance of the algorithm using these error levels. As can be seen in the figure, increasing the error level increases the running time and reduces the accuracy of prediction. This is to be expected since higher error levels mean that more flipped data points are sampled, and therefore finding an initial state that is shared between the maximal number of points is harder. For each sample size and noise level, we computed a new memorization table and included its construction time in the average running time per trajectory.</p>
<fig id="fig5" position="float" fig-type="figure"><label><underline>Figure 5:</underline></label>
<caption><p><bold>A:</bold> The percentage of incorrectly classified data points as a function of sample size, for the four different noise levels tested in the paper. For error levels p<sub>1</sub>&#x003D;0.05 (magenta) and P<sub>2</sub>=0.1 (blue), all sample sizes result in mistake-free reconstruction. The higher the noise level, the larger the sample size needed for eliminating errors. <bold>B:</bold> Running times of the algorithm for different sample sizes and noise levels. The y-axis is in log(seconds) scale for display purposes. Running times consistently increase with noise level for all sample sizes.</p></caption>
<graphic xlink:href="056358_fig5.tif"/>
</fig>
<p>So far we assumed that the probability of error of data points is the same. In order to test a different pattern of noise, we now define a probability of error p<sub>t</sub> as follows:
<disp-formula id="ueqn1"><alternatives><graphic xlink:href="056358_ueqn1.gif"/></alternatives></disp-formula>
where t corresponds to time. At even times the probability p<sub>t</sub> that a Boolean value be incorrect is 0.3, and at odd it is 0. Therefore, the overall number of errors for p<sub>t</sub> is the same as p<sub>3</sub>, but there is an association between time and error. <xref ref-type="fig" rid="fig6"><bold>Figure6A</bold></xref> illustrates the effect of this noise scheme on the first 15 states of the first trajectory in the dataset. <xref ref-type="fig" rid="fig6"><bold>Figure 6B</bold></xref> shows the number of mistakes the algorithm makes for different sample sizes, and <xref ref-type="fig" rid="fig6"><bold>Figure 6C</bold></xref> the running time as a function of sample size. As can be seen in the figure, the algorithm makes more mistakes at small sample sizes than it makes for noise level p<sub>3</sub>, which indicates that the association of noise with time makes data points with incorrect values share more initial states. Nevertheless, when the sample size is large enough the algorithm does not make any mistakes. The running times of the algorithm are shorter, most likely since this noise pattern creates a favorable search space for the branch and bound step of the algorithm.</p>
<fig id="fig6" position="float" fig-type="figure"><label><underline>Figure 6:</underline></label>
<caption><p><bold>A:</bold> Multidimensional scaling of the first <bold>15</bold> states in the first trajectory in the dataset, without noise (blue) and time-correlated noise (also see text). The distance function is the number of different Boolean values between a pair of states. The states are numbered according to their order in the trajectory. The first state and every odd state are noiseless, and therefore the blue and red odd numbers are completely overlapping. The other time points contain an error with probability 0.4 <bold>B:</bold> The percentage of incorrectly classified data points as a function of sample size, for the time-correlated error level p<sub>t</sub>. <bold>C:</bold> Running times of the algorithm for different sample sizes, measured in seconds.</p></caption>
<graphic xlink:href="056358_fig6.tif"/>
</fig>
<p>For executing our program we used a Macbook air with a 2.2 GHz Intel Core <italic>17</italic> processor with 8 GB of memory. For optimal performance, we implemented the algorithm in C. The binary, source code and input files that were used in this study can be obtained for free by contacting the author.</p></sec>
<sec id="s4"><title>Conclusion</title>
<p>Network models have been shown to agree well with observed patterns of gene expression. Currently, a gold-standard methodology for generating hypotheses about a network model given a dataset of gene expression does not exist. An important aspect in quantifying the usefulness of a given model is the analytical tools that are available when one adopts the model. Boolean networks are expressive, which means that they can describe a broad range of observations, and at the same time they are simple. Due to the latter property, inference algorithms can be developed and studied using existing theory [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c22">22</xref>&#x2013;<xref ref-type="bibr" rid="c24">24</xref>].</p>
<p>In this paper we showed that very large datasets can be used for accurate inference despite the computational complexity of the problem. Our algorithm offers researchers a powerful tool for exploring network hypotheses and provides an incentive for generating large datasets. In addition, it provides insight into the network inference problem that can be used for development of new analysis methods.</p>
<p>There are several research directions that we plan to pursue in future work. First, The minimal amount of data that is needed in order to reconstruct a trajectory is an important quantity both for inference and for designing biological experiments. This includes the minimal trajectory length T, and the minimal number of trajectories in the input. It may be possible to derive the information dynamically when constructing the state memorization table. In addition, we have observed that data points with larger time T are less useful for inferring the initial state, and it is of interest to quantify this property. Another interesting question is what is the maximal level of noise that can be corrected. This level may depend on the dataset and network topology, and so a related question is whether there are trajectories or network topologies that are more robust to noise. Given a dataset, it is also desirable to find bounds on the number of changes needed to remove all discrepancies. A lower bound clearly exists, since a single change in a data point value cannot solve more discrepancies than one plus the number of targets of a gene. We believe that answers to these questions will be important for the understanding of complex systems.</p></sec>
<sec><title>Competing Interests</title>
<p>The author declares that he has no competing interests</p></sec>
</body>
<back>
<ref-list><title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Ideker</surname>, <given-names>T.</given-names></string-name>, <string-name><given-names>T.</given-names> <surname>Galitski</surname></string-name>, and <string-name><given-names>L.</given-names> <surname>Hood</surname></string-name>, <article-title>A new approach to decoding life: systems biology</article-title>. <source>Annu Rev Genomics Hum Genet</source>, <year>2001</year>. <volume>2</volume>: p. <fpage>343</fpage>&#x2013;<lpage>72</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Layek</surname>, <given-names>R.</given-names></string-name>, <etal>et al.</etal>, <article-title>Cancertherapy design based on pathway logic</article-title>. <source>Bioinformatics</source>, <year>2011</year>. <volume>27</volume>(<issue>4</issue>): p. <fpage>548</fpage>&#x2013;<lpage>55</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="confproc"><string-name><surname>Li</surname>, <given-names>F.T.</given-names></string-name>, <etal>et al.</etal>, <article-title>The yeast cell-cycle network is robustly designed</article-title>. <conf-name>Proceedings of the National Academy of Sciences of the United States of America</conf-name>, <conf-date>2004</conf-date>. <volume>101</volume>(<issue>14</issue>): p. <fpage>4781</fpage>&#x2013;<lpage>4786</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Xu</surname>, <given-names>H.</given-names></string-name>, <etal>et al.</etal>, <article-title>Construction and validation of a regulatory network for pluripotency and self-renewal of mouse embryonic stem cells</article-title>. <source>PLoS Comput Biol</source>, <year>2014</year>. <volume>10</volume>(<issue>8</issue>): p. <fpage>e1003777</fpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Karlebach</surname>, <given-names>G.</given-names></string-name> and <string-name><given-names>R.</given-names> <surname>Shamir</surname></string-name>, <article-title>Modelling and analysis of gene regulatory networks</article-title>. <source>Nat Rev Mol Cell Biol</source>, <year>2008</year>. <volume>9</volume>(<issue>10</issue>): p. <fpage>770</fpage>&#x2013;<lpage>80</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Glass</surname>, <given-names>L.</given-names></string-name> and <string-name><given-names>S.A.</given-names> <surname>Kauffman</surname></string-name>, <article-title>The logical analysis of continuous, non-linear biochemical control networks</article-title>. <source>Journal of Theoretical Biology</source>, <year>1973</year>. <volume>39</volume>(<issue>1</issue>): p. <fpage>103</fpage>&#x2013;<lpage>129</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="confproc"><string-name><surname>Kauffman</surname>, <given-names>S.</given-names></string-name>, <etal>et al.</etal>, <article-title>Random Boolean network models and the yeast transcriptional network</article-title>. <conf-name>Proc Natl Acad Sci</conf-name> <conf-loc>USA</conf-loc>, <conf-date>2003</conf-date>. <volume>100</volume>(<issue>25</issue>): p. <fpage>14796</fpage>&#x2013;<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="confproc"><string-name><surname>Villani</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal>, <article-title>Coupled random boolean network forming an artificial tissue</article-title>. <conf-name>Cellular Automata, Proceedings</conf-name>, <conf-date>2006</conf-date>. <volume>4173</volume>: p. <fpage>548</fpage>&#x2013;<lpage>556</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Krumsiek</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal>, <article-title>Hierarchical differentiation of myeloid progenitors is encoded in the transcription factor network</article-title>. <source>PLoS One</source>, <year>2011</year>. <volume>6</volume>(<issue>8</issue>): p. <fpage>622</fpage>&#x2013;<lpage>649</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Orlando</surname>, <given-names>D.A.</given-names></string-name>, <etal>et al.</etal>, <article-title>Global control of cell-cycle transcription by coupled CDK and network oscillators</article-title>. <source>Nature</source>, <year>2008</year>. <volume>453</volume>(<issue>7197</issue>): p. <fpage>944</fpage>&#x2013;<lpage>7</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Steggles</surname>, <given-names>L.J.</given-names></string-name>, <etal>et al.</etal>, <article-title>Qualitatively modelling and analysing genetic regulatory networks: a Petri net approach</article-title>. <source>Bioinformatics</source>, <year>2007</year>. <volume>23</volume>(<issue>3</issue>): p. <fpage>336</fpage>&#x2013;<lpage>43</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Simao</surname>, <given-names>E.</given-names></string-name>, <etal>et al.</etal>, <article-title>Qualitative modelling of regulated metabolic pathways: application to the tryptophan biosynthesis in E.coli</article-title>. <source>Bioinformatics</source>, <year>2005</year>.<volume>21</volume> <issue>Suppl 2</issue>: p. <fpage>iiigo</fpage>&#x2013;<lpage>6</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Azpeitia</surname>, <given-names>E.</given-names></string-name>, <etal>et al.</etal>, <article-title>Gene regulatory network models for floral organ determination</article-title>. <source>Methods Mol Biol</source>, <year>2014</year>. <volume>1110</volume>: p. <fpage>441</fpage>&#x2013;<lpage>69</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Karlebach</surname>, <given-names>G.</given-names></string-name>, <article-title>Inferring Boolean network states from partial information</article-title>. <source>EURASIP J Bioinform Syst Biol</source>, <year>2013</year>. <volume>2013</volume>(<issue>1</issue>): p. <fpage>11</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Karlebach</surname>, <given-names>G.</given-names></string-name> and <string-name><given-names>R.</given-names> <surname>Shamir</surname></string-name>, <article-title>Constructing logical models of gene regulatory networks by integrating transcription factor-DNA interactions with expression data: an entropy-based approach</article-title>. <source>J Comput Biol</source>, <year>2012</year>. <volume>19</volume>(<issue>1</issue>): p. <fpage>30</fpage>&#x2013;<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Sharan</surname>, <given-names>R.</given-names></string-name> and <string-name><given-names>R.M.</given-names> <surname>Karp</surname></string-name>, <article-title>Reconstructing Boolean models of signaling</article-title>. <source>J Comput Biol</source>, <year>2013</year>. <volume>20</volume>(<issue>3</issue>): p. <fpage>249</fpage>&#x2013;<lpage>57</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Dimitrova</surname>, <given-names>E.S.</given-names></string-name>, <etal>et al.</etal>, <article-title>Discretization of Time Series Data</article-title>. <source>Journal of Computational Biology</source>, <year>2010</year>. <volume>17</volume>(<issue>6</issue>): p. <fpage>853</fpage>&#x2013;<lpage>868</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Shmulevich</surname>, <given-names>I.</given-names></string-name> and <string-name><given-names>W.</given-names> <surname>Zhang</surname></string-name>, <article-title>Binary analysis and optimization-based normalization of gene expression data</article-title>. <source>Bioinformatics</source>, <year>2002</year>. <volume>18</volume>(<issue>4</issue>): p. <fpage>555</fpage>&#x2013;<lpage>565</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Akutsu</surname>, <given-names>T.</given-names></string-name>, <string-name><given-names>S.</given-names> <surname>Miyano</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Kuhara</surname></string-name>, <article-title>Identification of genetic networks from a small number of gene expression patterns underthe Boolean network model</article-title>. <source>Pac Symp Biocomput</source>, <year>1999</year>: p. <fpage>17</fpage>&#x2013;<lpage>28</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Lahdesmaki</surname>, <given-names>H.</given-names></string-name>, <string-name><given-names>I.</given-names> <surname>Shmulevich</surname></string-name>, and <string-name><surname>O.</surname> <given-names>Yli-Harja</given-names></string-name>, <article-title>On learning gene regulatory networks underthe Boolean network model</article-title>. <source>Machine Learning</source>, <year>2003</year>. <volume>52</volume>(<issue>1&#x2013;2</issue>): p. <fpage>147</fpage>&#x2013;<lpage>167</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Segal</surname>, <given-names>E.</given-names></string-name>, <etal>et al.</etal>, <article-title>Module networks: identifying regulatory modules and their condition-specific regulators from gene expression data</article-title>. <source>Nat Genet</source>, <year>2003</year>. <volume>34</volume>(<issue>2</issue>): p. <fpage>166</fpage>&#x2013;<lpage>76</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Akutsu</surname>, <given-names>T.</given-names></string-name>, <etal>et al.</etal>, <article-title>Control of Boolean networks: hardness results and algorithms for tree structured networks</article-title>. <source>J Theor Biol</source>, <year>2007</year>. <volume>244</volume>(<issue>4</issue>): p. <fpage>670</fpage>&#x2013;<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Shmulevich</surname>, <given-names>I.</given-names></string-name>, <etal>et al.</etal>, <article-title>Probabilistic Boolean Networks: a rule-based uncertainty model for gene regulatory networks</article-title>. <source>Bioinformatics</source>, <year>2002</year>. <volume>18</volume>(<issue>2</issue>): p. <fpage>261</fpage>&#x2013;<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>S.Q.</given-names></string-name>, <etal>et al.</etal>, <article-title>Simulation study in Probabilistic Boolean Network models for genetic regulatory networks</article-title>. <source>Int J Data Min Bioinform</source>, <year>2007</year>. <volume>1</volume>(<issue>3</issue>): p. <fpage>217</fpage>&#x2013;<lpage>40</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>