<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/342501</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Animal Behavior and Cognition</subject>
</subj-group>
</article-categories>
<title-group><article-title>Low-Cost Solution for Rodent Home-Cage Behaviour Monitoring</article-title></title-group>
<contrib-group>
<contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4646-2089</contrib-id>
<name><surname>Singh</surname><given-names>Surjeet</given-names></name><xref ref-type="aff" rid="a1">1</xref></contrib>
<contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4937-1780</contrib-id>
<name><surname>Contreras</surname><given-names>Edgar Bermudez</given-names></name><xref ref-type="aff" rid="a1">1</xref></contrib>
<contrib contrib-type="author"><name><surname>Nazari</surname><given-names>Mojtaba</given-names></name><xref ref-type="aff" rid="a1">1</xref></contrib>
<contrib contrib-type="author" corresp="yes"><name><surname>Sutherland</surname><given-names>Robert J.</given-names></name><xref ref-type="aff" rid="a1">1</xref><xref ref-type="corresp" rid="cor1">&#x002A;</xref></contrib>
<contrib contrib-type="author" corresp="yes"><name><surname>Mohajerani</surname><given-names>Majid H.</given-names></name><xref ref-type="aff" rid="a1">1</xref><xref ref-type="corresp" rid="cor1">&#x002A;</xref></contrib>
<aff id="a1"><label>1</label><institution>Department of Neuroscience, Canadian Centre for Behavioural Neuroscience, University of Lethbridge</institution>, Lethbridge, AB, <country>Canada</country>, T1K 3M4</aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding authors: E-mail: <email>robert.sutherland@uleth.ca</email> (RJS) and <email>mohajerani@uleth.ca</email> (MHM)</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>342501</elocation-id>
<history>
<date date-type="received">
<day>08</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>08</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>08</day>
<month>6</month>
<year>2018</year>
</date>
</history><permissions><copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions>
<self-uri xlink:href="342501.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract><title>Abstract</title>
<p>In the current research on measuring complex behaviours/phenotyping in rodents, most of the experimental design requires animal-experimenter interaction in which the animal is removed from its home-cage environment and placed in an unfamiliar apparatus (novel environment). This may influence behaviour, general well-being, and metabolism of the animal, effecting the phenotypic outcome even if the data collection method is automated. Most of the commercially available solutions for home-cage monitoring are expensive and usually lack the flexibility to be incorporated with the existing home-cages. Here we present a low-cost solution for monitoring home-cage behaviour of rodents that can be easily incorporated practically with any available rodent home-cage. This system is based on a Raspberry Pi (RPi), which is a low-cost (35&#x0024;) credit-card sized single board computer. We developed a web interface that allows the user to view the animal activity in the home-cage in real-time and to change camera settings, start/stop recording, download saved videos/images and control peripherals attached to the general-purpose input/output (GPIO) pins of the Raspberry Pi. In addition, we provide custom written scripts for offline tracking, activity monitoring and synchronously acquire video from multiple cameras. To demonstrate the use of our system, we collected sleep-wake behavioural data of animals (n=5) for 200 min and simultaneously recording hippocampal local field potential (LFP) and electromyography (EMG) data. From the video data, the periods of continuous inactivity that were longer than 40 secs were identified as sleep periods. It was observed that these inactive periods are 91.6&#x0025; &#x00B1; 0.4 accurate with respect to LFP/EMG recordings, suggesting a prominent application of our system in sleep and circadian rhythm studies. In conclusion, this paper presents an innovative and flexible methodology for studying rodent behaviour with minimal experimenter interference. Our approach for automated acquisition of video-based behavioural data provides a tool that facilitates the analysis of behavior as a medium to study brain function.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Rodents</kwd>
<kwd>Behaviour</kwd>
<kwd>Monitoring</kwd>
<kwd>Home-Cage</kwd>
<kwd>Low-Cost</kwd>
<kwd>Raspberry Pi.</kwd>
</kwd-group>
<counts>
<page-count count="32"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1"><title>Introduction</title>
<p>Due to their smaller size, low housing costs and similar brain architecture as primates, rodents have been widely used for studying a variety of complex behaviours. Recent development of sophisticated tools for measuring and manipulating brain activity, including optogenetics, two photon imaging, widefield mesoscale imaging, fibre photometry, mini endoscopes [<xref ref-type="bibr" rid="c1">1</xref>-<xref ref-type="bibr" rid="c7">7</xref>], as well as the availability of diverse transgenic lines and disease models, further enhance their usefulness in mechanistic studies [<xref ref-type="bibr" rid="c8">8</xref>-<xref ref-type="bibr" rid="c11">11</xref>]. Though non-human primates have been traditionally used to understand the neural mechanisms underlying executive function and higher-order cognition (such as decision making, motor skill execution, and perceptual discrimination), high-throughput experiments on non-human primates are not feasible because of cost and regulation constrains [<xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>Automated behaviour monitoring systems are useful tools that allow scientists to characterise behavioural changes associated with ill health in rodents [<xref ref-type="bibr" rid="c13">13</xref>]. Since mice are crepuscular and nocturnal animals (they are active at dusk and dawn and throughout the night), assessing their signs of ill health, pain and distress is difficult [<xref ref-type="bibr" rid="c14">14</xref>]. In addition to the lack of observer bias in monitoring animal behaviour [<xref ref-type="bibr" rid="c15">15</xref>], one other big advantage of automated home-cage monitoring is continuous and accurate monitoring particularly during dark periods when mice are most active [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>]. Furthermore, remote monitoring of animals also greatly reduces the requirement for animal handling which may be stressful and/or confound studies [<xref ref-type="bibr" rid="c17">17</xref>-<xref ref-type="bibr" rid="c20">20</xref>].</p>
<p>There are multiple pre-existing methods currently used to evaluate animal activity in the home-cage. Some of these include: running wheels, RFID (radiofrequency identification) tags, and video. Each of these technologies have their own advantages and pitfalls. Though running wheels are widely used because of their low cost and ease of implementation for measuring the activity and/or changes in circadian rhythm, it has also been shown to greatly affect animal behaviour [<xref ref-type="bibr" rid="c21">21</xref>]. The use of RFID tags for monitoring location has a disadvantage of poor spatial resolution and the tag itself may provide discomfort to the animal. Further, automated video recording/analysis systems are expensive and usually lack the flexibility to be incorporated with the existing home-cages.</p>
<p>Here we present a low-cost rodent home-cage behaviour monitoring system built around the Raspberry Pi (RPi) using open-source software technologies that is suitable for high-throughput data acquisition with virtually no experimenter interventions. To demonstrate the capabilities of our system, we present a reliable sleep-wake classification based only on video data collected in the home-cage which has 91.6&#x0025; &#x00B1; 0.4 accuracy with respect to a classification made by using hippocampal local field potentials (LFP) and electromyogram (EMG) recordings. Using our approach, we demonstrate that it is possible to reliably and continuously monitor the animal activity (actogram) throughout day-night cycles, which is crucial for sleep studies [<xref ref-type="bibr" rid="c22">22</xref>]. Finally, following the methodology presented here, we found that animals were more active during the dark cycle than in light cycle which has been previously reported using conventional circadian analysis methods [<xref ref-type="bibr" rid="c22">22</xref>].</p>
<p>In summary, low-cost automated home-cage monitoring and analysis systems, like the one proposed here, represent a platform to build upon custom systems that will allow researchers to study complex, highly dimensional and dynamical behavior of rodents with minimal experimenter interference [<xref ref-type="bibr" rid="c23">23</xref>-<xref ref-type="bibr" rid="c26">26</xref>]. Using a similar behavioral monitoring approach could potentially expedite the understanding about the brain, as carefully thought high-throughput automated behavioural data might be key in the advancement of theoretical frameworks and experimental design to link behaviour and brain function [<xref ref-type="bibr" rid="c27">27</xref>].</p>
</sec>
<sec id="s2"><title>Material and Methods</title>
<sec id="s2a"><title>Animals</title>
<p>All experiments were carried out on adult (20-30 g, age 4 month) wild type C57BL/6 mice (n = 5). Mice were housed under standard conditions, in clear plastic cages under 12 h light, 12 h dark cycles. All the animals were either grouped or singly housed in Optimice<sup>&#x00AE;</sup> (Animal Care Systems) home-cages depending on the experimental protocol they were going through. Mice were given ad libitum access to water and standard laboratory mouse diet at all times. All protocols were approved by the Animal Welfare Committee of the University of Lethbridge and were in accordance with guidelines set forth by the Canadian Council for Animal Care.</p>
</sec>
<sec id="s2b"><title>System Architecture/Hardware</title>
<p>The lid of the home-cages was modified by making a hole at its centroid to fix a wide-angle lens with Pi Camera (the official Raspberry Pi Foundation Camera Module v2). The Pi Camera module is connected to the Mobile Industry Processor Interface (MIPI) Camera Serial Interface (CSI) port on the Raspberry Pi via a 15cm ribbon cable. The Raspberry Pi further connects to the computer network either via a LAN cable or a Wi-Fi connection (<xref ref-type="fig" rid="fig1">Fig 1 A-D</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure"><label>Fig 1.</label><caption><title>Animal home-cage monitoring system architecture and web interface.</title><p>(A) Basic rack with multiple home-cages. (B) Top view and, (C) side view of a single animal home-cage with a wide-angle camera mounted on top and connected to an RPi. This RPi is responsible for data acquisition and for controlling external peripherals. The Raspberry Pi further connects to a computer network either via an Ethernet cable or a Wi-Fi connection, (D) allowing the remote user to view the animal activity in the home-cage, via web browser (E) The home page of the web interface allows the user to view the animal activity in its home-cage in real-time and to start/stop recording videos and capturing images. In the Settings tab of the web interface the user can change the camera settings e.g. resolution of the video/image, framerate of video acquisition, brightness, contrast etc. (<xref ref-type="fig" rid="fig2">Fig 2</xref>). In the preview sections, the user can download videos/images and in the GPIO control section, the user can control external peripherals attached to the GPIO pins of the Raspberry Pi (<xref ref-type="fig" rid="fig3">Figs. 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>).</p></caption><graphic xlink:href="342501_fig1.tif"/></fig>
</sec>
<sec id="s2c"><title>System interface</title>
<p>The remote user can view the live feed of the animal activity in the home-cage via a customized web interface presented in this paper (<xref ref-type="fig" rid="fig1">Fig 1 E</xref>) or on a desktop computer using iSpy (<ext-link ext-link-type="uri" xlink:href="http://www.ispyconnect.com">www.ispyconnect.com</ext-link>) which is a software for remote video monitoring. The objective of this interface, besides to remotely monitor the animals&#x2019; activity, is also to acquire the video data to analyse its home-cage behaviour. The web interface was created using PHP, JavaScript and CSS, which runs on an Apache web server on the Raspberry Pi. Our code can be downloaded from (<ext-link ext-link-type="uri" xlink:href="https://github.com/surjeets/Animal_Home_Cage">https://github.com/surjeets/Animal_Home_Cage</ext-link>)</p>
<p>The web interface has Home, Settings, Preview and GPIO Control tabs; by default, the opening page is the Home page (<xref ref-type="fig" rid="fig1">Fig 1-E</xref>) where users can view the live camera feed, start/stop video recording, capture an image or stop the camera. Users can change the camera settings on the Settings page (<xref ref-type="fig" rid="fig2">Fig 2</xref>) where multiple options are available to change the video resolution, frame rate, brightness, contrast, sharpness, ISO, rotation, annotations, video splitting etc. Users can also preview/download/delete captured images and videos on the Preview page (<xref ref-type="fig" rid="fig3">Fig 3</xref>). The storage space available on the SD card for recording more videos/capturing images is also indicated on this page. Further, users can also manually control external peripherals attached to the system (e.g. LEDs, Buzzers, motors etc.) via GPIO Control interface (<xref ref-type="fig" rid="fig4">Fig 4</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure"><label>Fig 2.</label><caption><title>Web interface for camera settings.</title><p>This interface allows a user to change camera settings such as: video resolution, frame rate, brightness, contrast, sharpness, ISO, rotation, annotations, video splitting etc.</p></caption><graphic xlink:href="342501_fig2.tif"/></fig>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure"><label>Fig 3.</label><caption><title>Preview of recorded videos/captured images.</title><p>This interface allows a user to preview/download/delete captured images and videos. Further, storage space available on the SD card for recording more videos/capturing images is also indicated.</p></caption><graphic xlink:href="342501_fig3.tif"/></fig>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure"><label>Fig 4.</label><caption><title>GPIO control of external peripherals.</title><p>This interface allows a user to manually control external peripherals attached to the system (e.g. LEDs, Buzzers, motors etc.).</p></caption><graphic xlink:href="342501_fig4.tif"/></fig>
<p>The overall functionality of this interface centres on the <italic>RaspiMJPEG</italic> process which accesses the camera data. <italic>RaspiMJPEG</italic> is an OpenMAX-application developed by Silvan Melchior, which is based on the Multimedia Abstraction Layer (MMAL) library [<xref ref-type="bibr" rid="c28">28</xref>]. In the web interface of our system, the <italic>RaspiMJPEG</italic> makes a connection to the camera (MMAL) and generates a continuous stream of single frames (jpg) which are saved in the /dev/shm/mjpeg directory of the RPi (e.g. cam.tif<bold>)</bold>. This folder is a virtual memory shared location that speeds up the execution by avoiding having to do many read/write to disk operations. These frames are accessed via URLs on the Apache Web server. The script cam_pic.php returns the latest one and cam_pic_new.php merges the frames into an mjpeg stream. The stream of the frames (preview images) is maintained throughout even during capturing/recording video/image. The captured video/image data is stored in the media folder (/media) of the RPi, the image is stored in JPEG format while the video is initially stored in h264 format but can be automatically packaged into an mp4 file when the recording ends.</p>
<p>Alternatively, the video stream can also be assessed using the iSpy Connect software running on a windows machine by adding the following url: <ext-link ext-link-type="uri" xlink:href="http://&#x003C;your_pi_ip&#x003E;:&#x003C;port&#x003E;/html/cam.tif">http://&#x003C;your_pi_ip&#x003E;:&#x003C;port&#x003E;/html/cam.tif</ext-link> or <ext-link ext-link-type="uri" xlink:href="http://&#x003C;your_pi_ip&#x003E;:&#x003C;port&#x003E;/html/cam_pic_new.php?">http://&#x003C;your_pi_ip&#x003E;:&#x003C;port&#x003E;/html/cam_pic_new.php?</ext-link> in the JPEG URL or MJPEG URL tab within video source. This allows the user to simultaneously capture a video stream on a desktop computer and on the RPi. Even scheduled recording of behavioural activity across multiple cages can be easily implemented, although it is possible that the frame rate of acquisition would need to be lowered.</p>
</sec>
<sec id="s2d"><title>Offline Behaviour Analysis</title>
<p>Streaming live video over a network and simultaneous processing the video data is resource expensive and may stall the RPi. Thus, we implemented two offline algorithms for behavioural data analysis using OpenCV and Python, one for motion detection and another for animal tracking in the home-cage.</p>
</sec>
<sec id="s2e"><title>Motion detection</title>
<p>Two often used methods for motion detection are Gaussian Mixture Model-based [<xref ref-type="bibr" rid="c29">29</xref>-<xref ref-type="bibr" rid="c31">31</xref>] and Bayesian (probability) based [<xref ref-type="bibr" rid="c32">32</xref>] foreground and background segmentation. These methods model the background and monitor it for substantial changes. Furthermore, they can discern between actual motion and just shadowing/small lighting changes. However, while being very powerful and accurate, these methods are also computationally expensive. Since the objective of our system in this instance is to deploy motion detection/tracking algorithms on a Raspberry Pi system, it is best to follow simple algorithms. As the system utilises fixedmounted cameras in controlled lighting conditions, the background of the video stream is assumed to be largely static (it does not change over consecutive frames of a video), so that even simple algorithms can deliver reliable results.</p>
<p>For motion detection we implemented the algorithm shown in <xref ref-type="fig" rid="fig5">Fig 5</xref> (Algorithm 1). First, the background is estimated by calculating the weighted mean of previous frames along with the current frame. In this way our system can dynamically adjust to the background even with the small changes in the lighting conditions. After this, frame differencing is performed by subtracting the weighted mean from the current frame to get a delta frame
<disp-formula id="ueqn1"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="342501_ueqn1.gif"/></alternatives></disp-formula></p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure"><label>Fig 5.</label><caption><title>Off-line video analysis algorithms.</title><p>Algorithm 1 (top) quantifies animal activity and Algorithm 2 (bottom) calculates and draws the trajectory of the animal detected. Both algorithms are presented in pseudo-code (in our repository, they are implemented in Python using openCV).</p></caption><graphic xlink:href="342501_fig5.tif"/></fig>
<p>Further, the delta frame is thresholded to find regions in the image that contain substantial difference from the background model. These regions correspond to &#x201C;motion&#x201D; in the video stream. In the end, contour detection is applied on the thresholded delta frame and loop over each of these contours individually to see if the regions of motion are sufficiently large enough to be considered as motion. If they pass the criterion of being larger than a predefined minimum area (threshold), then the moving region is shown with a rectangle around it <xref ref-type="fig" rid="fig6">Fig 6-A</xref>.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure"><label>Fig 6.</label><caption><title>Animal motion detection and tracking.</title><p>(A) Results of activity detection algorithm showing day (left column) and night (right column) time activity of the animal in the home-cage. (B) Results for animal tracking algorithm with centroid marked (left) and track plot generated by connecting centroid of animal in each frame (right).</p></caption><graphic xlink:href="342501_fig6.tif"/></fig>
</sec>
<sec id="s2f"><title>Animal tracking</title>
<p>For animal tracking we implemented the algorithm shown in <xref ref-type="fig" rid="fig5">Fig 5</xref> (Algorithm 2). This algorithm assumes that there is a high contrast between the mouse and the home-cage background. First, a Gaussian filter (size = 21, sigma = 3.5) is used to reduce noise in each video frame, then intensity-based thresholding is applied to segment the filtered image. Subsequently, to find the animal location, the contour with the largest area is detected, which, in the home-cage, is usually the animal. Finally, to calculate the trajectory of an animal, the centroids of the detected largest contour in each frame are connected (<xref ref-type="fig" rid="fig6">Fig 6-B</xref>). These trajectories can be used to calculate the distance travelled by the animal or to visualize its spatial occupancy.</p>
</sec>
<sec id="s2g"><title>High Frame Rate Acquisition</title>
<p>In some of the behavioural tasks (e.g. reach and grasp, grooming behaviour) it is very important to acquire the data at high frame rates. Since the latest RPi camera board V 2.1 has an 8MP Sony IMX219 sensor, it is possible to record video @ 30 fps in full resolution (no shutter lag and simultaneous recording), and also @120 fps if using the 2 &#x00D7; 2 analogue binning mode.</p>
<p>In order to quantify the temporal precision of the frame acquisition of the RPi camera, we recorded the time stamps of each frame acquisition into a csv file using the <italic>picamera</italic> python library [<xref ref-type="bibr" rid="c33">33</xref>]. We evaluated the temporal precision of the frame acquisition of the RPi Camera by comparing the average missed frames and variation in interframe intervals (IFIV) in a video at different framerates (30, 60, 90 and 120 fps) and recording formats (h264 and raw YUV). We observed that there are dropped/delayed frames when we save the video in raw YUV format. This increases considerably with an increase in the frame rate to such an extent that at 90 fps we can only achieve a frame rate of 77.61 &#x00B1; 4.59 fps with a lag of 54.45 &#x00B1; 31.78 ms between consecutive frames (<xref ref-type="table" rid="tbl1">Table 1</xref>). Since the raw frames are larger in size than encoded frames, it takes a longer time for read/write cycles, which overlaps with acquisition, resulting in frames being dropped. In contrast, using the h264 encoding we were able to record @ 120 fps with no missed frames (120.54 &#x00B1; 0.00 fps) and almost no lag between consecutive frames (2.44 &#x00B1; 0.46 &#x00B5;s).</p>
<table-wrap id="tbl1" position="float" orientation="portrait"><label>Table 1.</label><caption><p>Comparison of frames per second (fps) and variance in Inter frame interval (IFIV) of the video data acquired over multiple trials: 15-minute video (320 &#x00D7; 240) was recorded in a raw (YUV) format and h264 encoding for 10 trials at a fixed frame rate (fps) on multiple RPis (n=5).&#x002A;results expressed as mean &#x00B1; standard deviation.</p></caption>
<graphic xlink:href="342501_tbl1.tif"/>
</table-wrap>
</sec>
<sec id="s2h"><title>Multiple camera synchronization</title>
<p>So far, we have presented our system using a single camera which can provide a top-down view or side-view perspective of the animal cage. However, using only one camera can present some problems: for example, insufficient mouse shape detail, reduced accuracy of tracking multiple mice, and detection of mice in images due to frequent changes in bedding position and appearance [<xref ref-type="bibr" rid="c34">34</xref>]. Thus, multiple PiCameras can be used to mitigate these issues. However, it is important that the video acquisition across multiple cameras is synchronized. To evaluate the time difference in simultaneous frame acquisition multiple Raspberry Pis were simultaneously triggered with an external TTL pulse. On another Raspberry Pi (besides the ones being triggered), we monitored the transition (high or low) of selected GPIO pins in real-time that corresponded to external trigger pulses that represent the start and stop times of video recording (<xref ref-type="fig" rid="fig7">Fig 7</xref>) using <italic>piscope</italic>, which is a digital waveform viewer for Raspberry Pi [<xref ref-type="bibr" rid="c35">35</xref>]. The timestamps of acquired frames on different RPis were later aligned offline to quantify any temporal jitter. <xref ref-type="table" rid="tbl1">Table 1</xref> shows that the jitter in the frame acquisition on different Raspberry Pis is in the order of few microseconds (approx. 2 &#x00B5;s).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure"><label>Fig 7.</label><caption><title>Simultaneous video acquisition on multiple Raspberry Pis.</title><p>Example of two Raspberry Pis triggered by an external TTL pulse (Trigger) to simultaneously start/stop video recording RPis (RPi 1 and RPi2). These timestamps were recorded on another Raspberry Pi using <italic>piscope</italic> and later aligned offline to evaluate synchronization performance.</p></caption><graphic xlink:href="342501_fig7.tif"/></fig>
</sec>
</sec>
<sec id="s3"><title>Results</title>
<sec id="s3a"><title>Sleep-wake state classification</title>
<p>Electroencephalogram (EEG) and electromyogram (EMG) signals have been used as a standard approach to classify sleep-wake states, but this involves the invasive implantation of cranial electrodes for recordings [<xref ref-type="bibr" rid="c36">36</xref>]. Not only is this approach time-consuming and invasive but also expensive to implement, particularly in high throughput experiments for assessing sleep-wake behaviour under varying pharmacological and environmental manipulations. In the past, several attempts have been made to developed alternative methods (other than EEG/EMG) to classify sleep-awake behaviour in rodents. In mice, subcutaneously implanted small magnets have been used to determine animal activity with respect to an array of magnetic field sensors under the home-cage [<xref ref-type="bibr" rid="c37">37</xref>]. Flores <italic>et al</italic>. developed a non-invasive approach for monitoring animal activity by using piezoelectric sensors positioned on the cage floor [<xref ref-type="bibr" rid="c38">38</xref>]. Another non-invasive system to quantify sleep-awake cycles in mice has been developed using passive infrared (PIR) motion sensors [<xref ref-type="bibr" rid="c39">39</xref>]. Video monitoring has been used to evaluate periods of sustained immobility as a surrogate of EEG/EMG-defined sleep [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c41">41</xref>]. All of these methods have been able to provide 90-95&#x0025; agreement with tethered EEG/EMG recordings, however these methods are sometimes difficult to implement because of their technical complexity or the expense of the required software/hardware. Here, we demonstrate that our home-cage monitoring system is capable of achieving reliable sleep-wake classification by collecting behavioural video of animals (n = 5) for 200 min. To calculate the sleep-wake classification, we applied the motion detection algorithm previously explained (see Methods and <xref ref-type="fig" rid="fig5">Fig 5</xref>), to identify the periods of continuous inactivity that were longer than 40 secs. To validate this classification, we simultaneously recorded hippocampal local field potentials (LFP) and EMG signals and compared them to our video-only based classification (<xref ref-type="fig" rid="fig8">Fig 8</xref>). Our sleep-wake classification was highly correlated to the LFP/EMG recordings (91.6&#x0025; &#x00B1; 0.4 accuracy).</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure"><label>Fig 8.</label><caption><title>Sleep-wake state classification.</title><p>(A) Example of hippocampal LFP and its spectrogram and rectified EMG activity recorded from a naturally sleeping animal (n = 5) during 200 min. (B) Comparison of hypnogram scoring the sleep and waking states calculated based on the EMG and video monitoring.</p></caption><graphic xlink:href="342501_fig8.tif"/></fig>
<p>This methodology of high-throughput monitoring of sleep-wake behaviour can be incorporated easily into any existing phenotyping test battery, e.g. circadian studies. As an example, <xref ref-type="fig" rid="fig9">Fig 9</xref> shows 24 hrs of activity of a mouse in the home-cage evaluated using the methodology described previously. The actogram (<xref ref-type="fig" rid="fig9">Fig 9</xref> A) represents the activity of an animal during the light and dark cycle (12 hrs each). Using one-way analysis of variance (ANOVA), Bonferroni post hoc analysis it was observed that animals (n=5) were more active during the dark cycle than in light cycle (<xref ref-type="fig" rid="fig9">Fig 9</xref> B) (F<sub>(1,9)</sub> = 12.03, p = 0.0085), a trend that is observed in commercial solutions that use running wheels for phenotyping circadian rhythms in mice [<xref ref-type="bibr" rid="c22">22</xref>]. Even though running wheels are widely used to study circadian rhythm in rodents [<xref ref-type="bibr" rid="c42">42</xref>], it has been shown that long-term access to a running wheel affect animal behaviour and disease pathology [<xref ref-type="bibr" rid="c21">21</xref>]. The home-cage video monitoring system does not introduce such confounding factors, rather it allows researchers to evaluate additional behavioural parameters such as the distance travelled, or the time spent in certain areas of the cage, which can provide additional data on anxiety or behavioural inhibition.</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure"><label>Fig 9.</label><caption><title>24 hrs activity monitoring.</title><p>(A) Example actogram generated using Algorithm 1, for a day-night sleep-wake state classification for one mouse. (B) Mean estimated awake duration expressed in terms of percentage activity for day and night cycle (12 hr each) for n = 5 animals (mean &#x00B1; standard deviation, &#x002A; p &#x003C; 0.01; one-way analysis of variance, Bonferroni post hoc).</p></caption><graphic xlink:href="342501_fig9.tif"/></fig>
</sec>
</sec>
<sec id="s4"><title>Discussion</title>
<p>When studying complex behaviour, experimental designs that requires animal-experimenter interaction and removing the animal from its home-cage environment and placing it in an unfamiliar apparatus (novel environment) are relatively disruptive, time- and labour-consuming and require additional laboratory space. This disruption may influence behaviour, general well-being, and metabolism of the animal, affecting the phenotypic outcome even if the data collection method is automated, possibly creating spurious findings. Therefore, monitoring the animals in their home-cage has several advantages. Though there are already open-source and commercial solutions available to monitor animal behaviour [<xref ref-type="bibr" rid="c43">43</xref>-<xref ref-type="bibr" rid="c50">50</xref>], they are usually difficult to construct, require a new infrastructure/space and are expensive. Here, we propose a system that can be integrated in many settings with minimal modifications for monitoring and analysing animal behaviour in the home-cage environment. This automated non-invasive home-cage behavioural data acquisition allows investigators to study the effects of experimental manipulations and a wide range of neurological diseases by accurate measurement of behavioural changes. In addition, our system could also be used for short-term welfare assessment (e.g. post-surgery monitoring) by enabling 24 hr monitoring, even in the dark phase where welfare assessment without disturbance to the cage is difficult and subjective. Further, video data collected with this system can be used to classify sleep-wake states of an animal in the home-cage with &#x007E;92&#x0025; accuracy when compared with tethered LFP/EMG recordings for sleep-wake state classification.</p>
<p>Our system has some limitations in its current state. One shortcoming of the system presented here is that it is unable to track multiple animals in the same home-cage, this is a major problem with video based animal identification systems because multiple animals have same fur colour and it is difficult to differentiate between them [<xref ref-type="bibr" rid="c46">46</xref>]. In order to overcome this, some algorithms extract characteristic fingerprints from each animal in a video and use these fingerprints to identify every individual [<xref ref-type="bibr" rid="c51">51</xref>]. However, such algorithms need to be highly calibrated and tested to provide reliable results. A potential candidate for this type or problem could be a hybrid video and RFID tracking system [<xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c52">52</xref>]. This approach provides an efficient data fusion of computer vision and RFID information for accurately monitoring the position and social interaction of multiple animals. Another possible limitation of our system is the processing power of the Raspberry Pi if extensive online video processing is required. For example, streaming live video over a network and simultaneously performing object detection on the RPi in real time might result in eventual frame dropping. Despite these limitations, the system has several advantages for large scale monitoring of rodents: it can be easily integrated with any available rodent cage-rack system. Further, a user can remotely monitor day/night activity of animals in multiple cages, virtually from anywhere via the web interface. Since the system is low cost and easily integrable in existing vivariums, it opens up the potential for the wider use of automated video monitoring in animal facilities.</p>
<p>A possible expansion of our system could be the addition of brain activity monitoring to our automated behaviour monitoring in freely behaving rodents. This would allow researchers to study the relationship between brain activity and behaviour in a less experimenter-biased and automated manner [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c53">53</xref>]. Another possible interesting avenue to explore with our system could be the study of social behaviour using multiple animals in the same cage [<xref ref-type="bibr" rid="c34">34</xref>].</p>
</sec>
<sec id="s5"><title>Conclusions</title>
<p>In this paper, we present a low-cost home-cage reliable behavioural monitoring system that can be easily adapted and extended to a large variety of conditions and pre-existing experimental setups. Due to its suitability for high-throughput data collection, minimization of experimenter bias and increasing availability, systems like the one presented here, will become an invaluable tool for behavioural and systems neuroscience research.</p>
</sec>
</body>
<back>
<ack><title>Acknowledgements</title>
<p>This work was supported by Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant #40352 and #RGPIN-2017-03857 (MHM), Campus Alberta for Innovation Program Chair, Alberta Alzheimer Research Program, Alzheimer Society of Canada (MHM), NSERC Discovery Grant and Alberta Neuroscience Program Grant (RJS).</p>
</ack>
<sec id="s6"><title>Author contributions</title>
<p>S.S., E.B.C., M.H.M. and R.J.S. conceived and designed the method, and prepared and reviewed the manuscript, S.S., E.B.C. and M.N. performed experimental work, S.S. and M.N. performed data analysis, S.S. and E.B.C wrote the manuscript, which all authors commented on and edited. M.H.M. and R.J.S. provided project leadership.</p>
</sec>
<sec id="s7" sec-type="COI-statement"><title>Competing financial interests</title>
<p>The authors declare no competing financial interests.</p></sec>
<ref-list><title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Dombeck</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Khabbaz</surname> <given-names>AN</given-names></string-name>, <string-name><surname>Collman</surname> <given-names>F</given-names></string-name>, <string-name><surname>Adelman</surname> <given-names>TL</given-names></string-name>, <string-name><surname>Tank</surname> <given-names>DW.</given-names></string-name> <article-title>Imaging large-scale neural activity with cellular resolution in awake, mobile mice</article-title>. <source>Neuron</source>. <year>2007</year>;<volume>56</volume>(<issue>1</issue>):<fpage>43</fpage>&#x2013;<lpage>57</lpage>. Epub 2007/10/09. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2007.08.003</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">17920014</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC2268027</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Ghosh</surname> <given-names>KK</given-names></string-name>, <string-name><surname>Burns</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Cocker</surname> <given-names>ED</given-names></string-name>, <string-name><surname>Nimmerjahn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ziv</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Gamal</surname> <given-names>AE</given-names></string-name>, <etal>et al.</etal> <article-title>Miniaturized integration of a fluorescence microscope</article-title>. <source>Nat Methods</source>. <year>2011</year>;<volume>8</volume>(<issue>10</issue>):<fpage>871</fpage>&#x2013;<lpage>8</lpage>. Epub 2011/09/13. doi: <pub-id pub-id-type="doi">10.1038/nmeth.1694</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">21909102</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC3810311</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Grinvald</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hildesheim</surname> <given-names>R.</given-names></string-name> <article-title>VSDI: a new era in functional imaging of cortical dynamics</article-title>. <source>Nat Rev Neurosci</source>. <year>2004</year>;<volume>5</volume>(<issue>11</issue>):<fpage>874</fpage>&#x2013;<lpage>85</lpage>. Epub 2004/10/22. doi: <pub-id pub-id-type="doi">10.1038/nrn1536</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">15496865</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Luo</surname> <given-names>L</given-names></string-name>, <string-name><surname>Callaway</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K.</given-names></string-name> <article-title>Genetic dissection of neural circuits</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>57</volume>(<issue>5</issue>):<fpage>634</fpage>&#x2013;<lpage>60</lpage>. Epub 2008/03/18. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2008.01.002</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">18341986</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC2628815</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Mohajerani</surname> <given-names>MH</given-names></string-name>, <string-name><surname>Chan</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Mohsenvand</surname> <given-names>M</given-names></string-name>, <string-name><surname>LeDue</surname> <given-names>J</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>R</given-names></string-name>, <string-name><surname>McVea</surname> <given-names>DA</given-names></string-name>, <etal>et al.</etal> <article-title>Spontaneous cortical activity alternates between motifs defined by regional axonal projections</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>(<issue>10</issue>):<fpage>1426</fpage>&#x2013;<lpage>35</lpage>. Epub 2013/08/27. doi: <pub-id pub-id-type="doi">10.1038/nn.3499</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">23974708</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC3928052</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>F</given-names></string-name>, <string-name><surname>Aravanis</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Adamantidis</surname> <given-names>A</given-names></string-name>, <string-name><surname>de Lecea</surname> <given-names>L</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K.</given-names></string-name> <article-title>Circuit-breakers: optical technologies for probing neural signals and systems</article-title>. <source>Nat Rev Neurosci</source>. <year>2007</year>;<volume>8</volume>(<issue>8</issue>):<fpage>577</fpage>&#x2013;<lpage>81</lpage>. Epub 2007/07/24. doi: <pub-id pub-id-type="doi">10.1038/nrn2192</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">17643087</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Bermudez-Contreras</surname> <given-names>E</given-names></string-name>, <string-name><surname>Chekhov</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sun</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tarnowsky</surname> <given-names>J</given-names></string-name>, <string-name><surname>McNaughton</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Mohajerani</surname> <given-names>MH</given-names></string-name>. <article-title>High-performance, inexpensive setup for simultaneous multisite recording of electrophysiological signals and mesoscale voltage imaging in the mouse cortex</article-title>. <source>Neurophotonics</source>. <year>2018</year>;<volume>5</volume>(<issue>2</issue>):<fpage>025005</fpage>. Epub 2018/04/14. doi: <pub-id pub-id-type="doi">10.1117/1.NPh.5.2.025005</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">29651448</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC5874445</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Saito</surname> <given-names>T</given-names></string-name>, <string-name><surname>Matsuba</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Mihira</surname> <given-names>N</given-names></string-name>, <string-name><surname>Takano</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nilsson</surname> <given-names>P</given-names></string-name>, <string-name><surname>Itohara</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal> <article-title>Single App knock-in mouse models of Alzheimer&#x2019;s disease</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>(<issue>5</issue>):<fpage>661</fpage>&#x2013;<lpage>3</lpage>. Epub 2014/04/15. doi: <pub-id pub-id-type="doi">10.1038/nn.3697</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">24728269</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Janus</surname> <given-names>C</given-names></string-name>, <string-name><surname>Westaway</surname> <given-names>D.</given-names></string-name> <article-title>Transgenic mouse models of Alzheimer&#x2019;s disease</article-title>. <source>Physiol Behav</source>. <year>2001</year>;<volume>73</volume>(<issue>5</issue>):<fpage>873</fpage>&#x2013;<lpage>86</lpage>. Epub 2001/09/22. PubMed PMID: <pub-id pub-id-type="pmid">11566220</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Elder</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Gama Sosa</surname> <given-names>MA</given-names></string-name>, <string-name><surname>De Gasperi</surname> <given-names>R.</given-names></string-name> <article-title>Transgenic mouse models of Alzheimer&#x2019;s disease</article-title>. <source>Mt Sinai J Med</source>. <year>2010</year>;<volume>77</volume>(<issue>1</issue>):<fpage>69</fpage>&#x2013;<lpage>81</lpage>. Epub 2010/01/27. doi: <pub-id pub-id-type="doi">10.1002/msj.20159</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">20101721</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC2925685</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Singh</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kaur</surname> <given-names>H</given-names></string-name>, <string-name><surname>Sandhir</surname> <given-names>R.</given-names></string-name> <article-title>Fractal dimensions: A new paradigm to assess spatial memory and learning using Morris water maze</article-title>. <source>Behav Brain Res</source>. <year>2016</year>;<volume>299</volume>:<fpage>141</fpage>&#x2013;<lpage>6</lpage>. Epub 2015/11/26. doi: <pub-id pub-id-type="doi">10.1016/j.bbr.2015.11.023</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">26592165</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Goodman</surname> <given-names>S</given-names></string-name>, <string-name><surname>Check</surname> <given-names>E.</given-names></string-name> <article-title>The great primate debate</article-title>. <source>Nature</source>. <year>2002</year>;<volume>417</volume>(<issue>6890</issue>):<fpage>684</fpage>&#x2013;<lpage>7</lpage>. Epub 2002/06/18. doi: <pub-id pub-id-type="doi">10.1038/417684a</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">12066153</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Littin</surname> <given-names>K</given-names></string-name>, <string-name><surname>Acevedo</surname> <given-names>A</given-names></string-name>, <string-name><surname>Browne</surname> <given-names>W</given-names></string-name>, <string-name><surname>Edgar</surname> <given-names>J</given-names></string-name>, <string-name><surname>Mendl</surname> <given-names>M</given-names></string-name>, <string-name><surname>Owen</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>Towards humane end points: behavioural changes precede clinical signs of disease in a Huntington&#x2019;s disease model</article-title>. <source>Proc Biol Sci</source>. <year>2008</year>;<volume>275</volume>(<issue>1645</issue>):<fpage>1865</fpage>&#x2013;<lpage>74</lpage>. Epub 2008/05/08. doi: <pub-id pub-id-type="doi">10.1098/rspb.2008.0388</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">18460434</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC2593928</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Hawkins</surname> <given-names>P.</given-names></string-name> <article-title>Recognizing and assessing pain, suffering and distress in laboratory animals: a survey of current practice in the UK with recommendations</article-title>. <source>Lab Anim</source>. <year>2002</year>;<volume>36</volume>(<issue>4</issue>):<fpage>378</fpage>&#x2013;<lpage>95</lpage>. Epub 2002/10/25. doi: <pub-id pub-id-type="doi">10.1258/002367702320389044</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">12396281</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Spruijt</surname> <given-names>BM</given-names></string-name>, <string-name><surname>DeVisser</surname> <given-names>L.</given-names></string-name> <article-title>Advanced behavioural screening: automated home cage ethology</article-title>. <source>Drug Discov Today Technol</source>. <year>2006</year>;<volume>3</volume>(<issue>2</issue>):<fpage>231</fpage>&#x2013;<lpage>7</lpage>. Epub 2006/07/01. doi: <pub-id pub-id-type="doi">10.1016/j.ddtec.2006.06.010</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">24980412</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Howerton</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Garner</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Mench</surname> <given-names>JA.</given-names></string-name> <article-title>A system utilizing radio frequency identification (RFID) technology to monitor individual rodent behavior in complex social settings</article-title>. <source>J Neurosci Methods</source>. <year>2012</year>;<volume>209</volume>(<issue>1</issue>):<fpage>74</fpage>&#x2013;<lpage>8</lpage>. Epub 2012/06/16. doi: <pub-id pub-id-type="doi">10.1016/j.jneumeth.2012.06.001</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">22698663</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Steele</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Jackson</surname> <given-names>WS</given-names></string-name>, <string-name><surname>King</surname> <given-names>OD</given-names></string-name>, <string-name><surname>Lindquist</surname> <given-names>S.</given-names></string-name> <article-title>The power of automated high-resolution behavior analysis revealed by its application to mouse models of Huntington&#x2019;s and prion diseases</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2007</year>;<volume>104</volume>(<issue>6</issue>):<fpage>1983</fpage>&#x2013;<lpage>8</lpage>. Epub 2007/01/31. doi: <pub-id pub-id-type="doi">10.1073/pnas.0610779104</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">17261803</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC1794260</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>de Visser</surname> <given-names>L</given-names></string-name>, <string-name><surname>van den Bos</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kuurman</surname> <given-names>WW</given-names></string-name>, <string-name><surname>Kas</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Spruijt</surname> <given-names>BM.</given-names></string-name> <article-title>Novel approach to the behavioural characterization of inbred mice: automated home cage observations</article-title>. <source>Genes Brain Behav</source>. <year>2006</year>;<volume>5</volume>(<issue>6</issue>):<fpage>458</fpage>&#x2013;<lpage>66</lpage>. Epub 2006/08/23. doi: <pub-id pub-id-type="doi">10.1111/j.1601-183X.2005.00181.x</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">16923150</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Tecott</surname> <given-names>LH</given-names></string-name>, <string-name><surname>Nestler</surname> <given-names>EJ.</given-names></string-name> <article-title>Neurobehavioral assessment in the information age</article-title>. <source>Nat Neurosci</source>. <year>2004</year>;<volume>7</volume>(<issue>5</issue>):<fpage>462</fpage>&#x2013;<lpage>6</lpage>. Epub 2004/04/29. doi: <pub-id pub-id-type="doi">10.1038/nn1225</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">15114359</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Winter</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Schaefers</surname> <given-names>AT.</given-names></string-name> <article-title>A sorting system with automated gates permits individual operant experiments with mice from a social home cage</article-title>. <source>J Neurosci Methods</source>. <year>2011</year>;<volume>196</volume>(<issue>2</issue>):<fpage>276</fpage>&#x2013;<lpage>80</lpage>. Epub 2011/01/25. doi: <pub-id pub-id-type="doi">10.1016/j.jneumeth.2011.01.017</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">21256865</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Richter</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ambree</surname> <given-names>O</given-names></string-name>, <string-name><surname>Lewejohann</surname> <given-names>L</given-names></string-name>, <string-name><surname>Herring</surname> <given-names>A</given-names></string-name>, <string-name><surname>Keyvani</surname> <given-names>K</given-names></string-name>, <string-name><surname>Paulus</surname> <given-names>W</given-names></string-name>, <etal>et al.</etal> <article-title>Wheel-running in a transgenic mouse model of Alzheimer&#x2019;s disease: protection or symptom?</article-title> <source>Behav Brain Res</source>. <year>2008</year>;<volume>190</volume>(<issue>1</issue>):<fpage>74</fpage>&#x2013;<lpage>84</lpage>. Epub 2008/03/18. doi: <pub-id pub-id-type="doi">10.1016/j.bbr.2008.02.005</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">18342378</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Eckel-Mahan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sassone-Corsi</surname> <given-names>P.</given-names></string-name> <article-title>Phenotyping Circadian Rhythms in Mice</article-title>. <source>Curr Protoc Mouse Biol</source>. <year>2015</year>;<volume>5</volume>(<issue>3</issue>):<fpage>271</fpage>&#x2013;<lpage>81</lpage>. Epub 2015/09/04. doi: <pub-id pub-id-type="doi">10.1002/9780470942390.mo140229</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">26331760</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC4732881</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Jafari</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Mehla</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kolb</surname> <given-names>BE</given-names></string-name>, <string-name><surname>Mohajerani</surname> <given-names>MH.</given-names></string-name> <article-title>Prenatal noise stress impairs HPA axis and cognitive performance in mice</article-title>. <source>Sci Rep</source>. <year>2017</year>;<volume>7</volume>(<issue>1</issue>):<fpage>10560</fpage>. Epub 2017/09/07. doi: <pub-id pub-id-type="doi">10.1038/s41598-017-09799-6</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">28874680</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC5585382</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Mehla</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lacoursiere</surname> <given-names>S</given-names></string-name>, <string-name><surname>Stuart</surname> <given-names>E</given-names></string-name>, <string-name><surname>McDonald</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Mohajerani</surname> <given-names>MH.</given-names></string-name> <article-title>Gradual Cerebral Hypoperfusion Impairs Fear Conditioning and Object Recognition Learning and Memory in Mice: Potential Roles of Neurodegeneration and Cholinergic Dysfunction</article-title>. <source>J Alzheimers Dis</source>. <year>2018</year>;<volume>61</volume>(<issue>1</issue>):<fpage>283</fpage>&#x2013;<lpage>93</lpage>. Epub 2017/11/21. doi: <pub-id pub-id-type="doi">10.3233/JAD-170635</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">29154281</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname> <given-names>JQ</given-names></string-name>, <string-name><surname>Sutherland</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>McDonald</surname> <given-names>RJ.</given-names></string-name> <article-title>Hippocampal damage causes retrograde but not anterograde memory loss for context fear discrimination in rats</article-title>. <source>Hippocampus</source>. <year>2017</year>;<volume>27</volume>(<issue>9</issue>):<fpage>951</fpage>&#x2013;<lpage>8</lpage>. Epub 2017/07/08. doi: <pub-id pub-id-type="doi">10.1002/hipo.22759</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">28686806</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Whishaw</surname> <given-names>IQ</given-names></string-name>, <string-name><surname>Faraji</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kuntz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Mirza Agha</surname> <given-names>B</given-names></string-name>, <string-name><surname>Patel</surname> <given-names>M</given-names></string-name>, <string-name><surname>Metz</surname> <given-names>GAS</given-names></string-name>, <etal>et al.</etal> <article-title>Organization of the reach and grasp in head-fixed vs freely-moving mice provides support for multiple motor channel theory of neocortical organization</article-title>. <source>Exp Brain Res</source>. <year>2017</year>;<volume>235</volume>(<issue>6</issue>):<fpage>1919</fpage>&#x2013;<lpage>32</lpage>. Epub 2017/03/21. doi: <pub-id pub-id-type="doi">10.1007/s00221-017-4925-4</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">28315945</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Gomez-Marin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Paton</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Kampff</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Costa</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Mainen</surname> <given-names>ZF.</given-names></string-name> <article-title>Big behavioral data: psychology, ethology and the foundations of neuroscience</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>(<issue>11</issue>):<fpage>1455</fpage>&#x2013;<lpage>62</lpage>. Epub 2014/10/29. doi: <pub-id pub-id-type="doi">10.1038/nn.3812</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">25349912</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="website"><string-name><surname>Melchior</surname> <given-names>S.</given-names></string-name> <source>RaspiCam Documentation</source> <year>2015</year> [updated 27 January 2015; cited 2017 6 January]. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/silvanmelchior/userland/tree/master/host_applications/linux/apps/raspicam">https://github.com/silvanmelchior/userland/tree/master/host_applications/linux/apps/raspicam</ext-link>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="book"><string-name><surname>KaewTraKulPong</surname> <given-names>P</given-names></string-name>, <string-name><surname>Bowden</surname> <given-names>R.</given-names></string-name> <chapter-title>An Improved Adaptive Background Mixture Model for Real-time Tracking with Shadow Detection</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Remagnino</surname> <given-names>P</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Paragios</surname> <given-names>N</given-names></string-name>, <string-name><surname>Regazzoni</surname> <given-names>CS</given-names></string-name></person-group>, editors. <source>Video-Based Surveillance Systems: Computer Vision and Distributed Processing</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Springer US</publisher-name>; <year>2002</year>. p. <fpage>135</fpage>&#x2013;<lpage>44</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Zivkovic</surname> <given-names>Z</given-names></string-name>, editor <article-title>Improved adaptive Gaussian mixture model for background subtraction</article-title>. <source>Proceedings of the 17th International Conference on Pattern Recognition</source>, <year>2004</year> ICPR 2004; 2004 23-26 Aug. 2004.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Zivkovic</surname> <given-names>Z</given-names></string-name>, <string-name><given-names>Heijden</given-names> <surname>Fvd</surname></string-name>. <article-title>Efficient adaptive density estimation per image pixel for the task of background subtraction</article-title>. <source>Pattern Recogn Lett</source>. <year>2006</year>;<volume>27</volume>(<issue>7</issue>):<fpage>773</fpage>&#x2013;<lpage>80</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.patrec.2005.11.005</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Godbehere</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Matsukawa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>K</given-names></string-name>, editors. <source>Visual tracking of human visitors under variable-lighting conditions for a responsive audio art installation</source>. <year>2012</year> American Control Conference (ACC); 2012 27-29 June 2012.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="website"><string-name><surname>Jones</surname> <given-names>D.</given-names></string-name> <source>picamera a pure Python interface to the Raspberry Pi camera module</source>. <year>2017</year> [updated 25 Feb 2017; cited 2017 8 January]. Available from: <ext-link ext-link-type="uri" xlink:href="https://picamera.readthedocs.io/en/release-1.13/">https://picamera.readthedocs.io/en/release-1.13/</ext-link>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Salem</surname> <given-names>GH</given-names></string-name>, <string-name><surname>Dennis</surname> <given-names>JU</given-names></string-name>, <string-name><surname>Krynitsky</surname> <given-names>J</given-names></string-name>, <string-name><surname>Garmendia-Cedillos</surname> <given-names>M</given-names></string-name>, <string-name><surname>Swaroop</surname> <given-names>K</given-names></string-name>, <string-name><surname>Malley</surname> <given-names>JD</given-names></string-name>, <etal>et al.</etal> <article-title>SCORHE: a novel and practical approach to video monitoring of laboratory mice housed in vivarium cage racks</article-title>. <source>Behav Res Methods</source>. <year>2015</year>;<volume>47</volume>(<issue>1</issue>):<fpage>235</fpage>&#x2013;<lpage>50</lpage>. Epub 2014/04/08. doi: <pub-id pub-id-type="doi">10.3758/s13428-014-0451-5</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">24706080</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC4570574</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="website"><string-name><surname>Joan</surname></string-name>. <source>Piscope is a digital waveform viewer for the Raspberry</source> <year>2017</year> [updated 20 March 2018; cited 2017 10 January]. Available from: <ext-link ext-link-type="uri" xlink:href="http://abyz.me.uk/rpi/pigpio/piscope.html">http://abyz.me.uk/rpi/pigpio/piscope.html</ext-link>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Chemelli</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Willie</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Sinton</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Elmquist</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Scammell</surname> <given-names>T</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>C</given-names></string-name>, <etal>et al.</etal> <article-title>Narcolepsy in orexin knockout mice: Molecular genetics of sleep regulation</article-title>. <source>Cell</source>. <year>1999</year>;<volume>98</volume>(<issue>4</issue>):<fpage>437</fpage>&#x2013;<lpage>51</lpage>. doi: <pub-id pub-id-type="doi">Doi 10.1016/S0092-8674(00)81973-X</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">WOS:000082174900005</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Storch</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hohne</surname> <given-names>A</given-names></string-name>, <string-name><surname>Holsboer</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ohl</surname> <given-names>F.</given-names></string-name> <article-title>Activity patterns as a correlate for sleep-wake behaviour in mice</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2004</year>;<volume>133</volume>(<issue>1-2</issue>):<fpage>173</fpage>&#x2013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.008</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">WOS:000188887700020</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Flores</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Flores</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Deshpande</surname> <given-names>H</given-names></string-name>, <string-name><surname>Picazo</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Xie</surname> <given-names>XMS</given-names></string-name>, <string-name><surname>Franken</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal> <article-title>Pattern recognition of sleep in rodents using piezoelectric signals generated by gross body movements</article-title>. <source>Ieee T Bio-Med Eng.</source> <year>2007</year>;<volume>54</volume>(<issue>2</issue>):<fpage>225</fpage>&#x2013;<lpage>33</lpage>. doi: <pub-id pub-id-type="doi">10.1109/Tbme.2006.886938</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">WOS:000243952100004</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Brown</surname> <given-names>L</given-names></string-name>, <string-name><surname>Hasan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>R</given-names></string-name>, <string-name><surname>Peirson</surname> <given-names>S.</given-names></string-name> <source>COMPASS: Continuous Open Mouse Phenotyping of Activity and Sleep Status</source> [version 1; referees: 3 approved, 1 approved with reservations] <year>2016</year>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Fisher</surname> <given-names>SP</given-names></string-name>, <string-name><surname>Godinho</surname> <given-names>SIH</given-names></string-name>, <string-name><surname>Pothecary</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Hankins</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>RG</given-names></string-name>, <string-name><surname>Peirson</surname> <given-names>SN.</given-names></string-name> <article-title>Rapid Assessment of Sleep-Wake Behavior in Mice</article-title>. <source>J Biol Rhythm</source>. <year>2012</year>;<volume>27</volume>(<issue>1</issue>):<fpage>48</fpage>&#x2013;<lpage>58</lpage>. doi: <pub-id pub-id-type="doi">10.1177/0748730411431550</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">WOS:000299848100005</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Pack</surname> <given-names>AI</given-names></string-name>, <string-name><surname>Galante</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Maislin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Cater</surname> <given-names>J</given-names></string-name>, <string-name><surname>Metaxas</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal> <article-title>Novel method for high-throughput phenotyping of sleep in mice</article-title>. <source>Physiol Genomics</source>. <year>2007</year>;<volume>28</volume>(<issue>2</issue>):<fpage>232</fpage>&#x2013;<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1152/physiogenomics.00139.2006</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">WOS:000244171700010</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Boggs</surname> <given-names>KN</given-names></string-name>, <string-name><surname>Kakalec</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Howell</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Flinn</surname> <given-names>JM.</given-names></string-name> <article-title>Circadian wheel running behavior is altered in an APP/E4 mouse model of late onset Alzheimer&#x2019;s disease</article-title>. <source>Physiology &#x0026; Behavior</source>. <year>2017</year>; <volume>182</volume>(<issue>Supplement C</issue>):<fpage>137</fpage>&#x2013;<lpage>42</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.physbeh.2017.09.021">https://doi.org/10.1016/j.physbeh.2017.09.021</ext-link>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Bains</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Wells</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sillito</surname> <given-names>RR</given-names></string-name>, <string-name><surname>Armstrong</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Cater</surname> <given-names>HL</given-names></string-name>, <string-name><surname>Banks</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal> <article-title>Assessing mouse behaviour throughout the light/dark cycle using automated in-cage analysis tools</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2017</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.physbeh.2017.09.021">https://doi.org/10.1016/j.jneumeth.2017.04.014</ext-link>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Jhuang</surname> <given-names>H</given-names></string-name>, <string-name><surname>Garrote</surname> <given-names>E</given-names></string-name>, <string-name><surname>Mutch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Khilnani</surname> <given-names>V</given-names></string-name>, <string-name><surname>Poggio</surname> <given-names>T</given-names></string-name>, <etal>et al.</etal> <article-title>Automated home-cage behavioural phenotyping of mice</article-title>. <source>Nat Commun</source>. <year>2010</year>;<volume>1</volume>:<fpage>68</fpage>. Epub 2010/09/16. doi: <pub-id pub-id-type="doi">10.1038/ncomms1064</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">20842193</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Weissbrod</surname> <given-names>A</given-names></string-name>, <string-name><surname>Shapiro</surname> <given-names>A</given-names></string-name>, <string-name><surname>Vasserman</surname> <given-names>G</given-names></string-name>, <string-name><surname>Edry</surname> <given-names>L</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Yitzhaky</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>Automated long-term tracking and social behavioural phenotyping of animal colonies within a semi-natural environment</article-title>. <source>Nat Commun</source>. <year>2013</year>;<volume>4</volume>:<fpage>2018</fpage>. Epub 2013/06/19. doi: <pub-id pub-id-type="doi">10.1038/ncomms3018</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">23771126</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Hong</surname> <given-names>W</given-names></string-name>, <string-name><surname>Kennedy</surname> <given-names>A</given-names></string-name>, <string-name><surname>Burgos-Artizzu</surname> <given-names>XP</given-names></string-name>, <string-name><surname>Zelikowsky</surname> <given-names>M</given-names></string-name>, <string-name><surname>Navonne</surname> <given-names>SG</given-names></string-name>, <string-name><surname>Perona</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal> <article-title>Automated measurement of mouse social behaviors using depth sensing, video tracking, and machine learning</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2015</year>;<volume>112</volume>(<issue>38</issue>):<fpage>E5351</fpage>&#x2013;<lpage>60</lpage>. Epub 2015/09/12. doi: <pub-id pub-id-type="doi">10.1073/pnas.1515982112</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">26354123</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC4586844</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Aoki</surname> <given-names>R</given-names></string-name>, <string-name><surname>Tsubota</surname> <given-names>T</given-names></string-name>, <string-name><surname>Goya</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Benucci</surname> <given-names>A.</given-names></string-name> <article-title>An automated platform for high-throughput mouse behavior and physiology with voluntary head-fixation</article-title>. <source>Nat Commun</source>. <year>2017</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1196</fpage>. Epub 2017/11/01. doi: <pub-id pub-id-type="doi">10.1038/s41467-017-01371-0</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">29084948</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC5662625</pub-id>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Poddar</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kawai</surname> <given-names>R</given-names></string-name>, <string-name><surname>Olveczky</surname> <given-names>BP.</given-names></string-name> <article-title>A fully automated high-throughput training system for rodents</article-title>. <source>PLoS One</source>. <year>2013</year>;<volume>8</volume>(<issue>12</issue>):<fpage>e83171</fpage>. Epub 2013/12/19. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0083171</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">24349451</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC3857823</pub-id>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Murphy</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Boyd</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Bolanos</surname> <given-names>F</given-names></string-name>, <string-name><surname>Vanni</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Silasi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Haupt</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>High-throughput automated home-cage mesoscopic functional imaging of mouse cortex</article-title>. <source>Nat Commun</source>. <year>2016</year>;<volume>7</volume>:<fpage>11611</fpage>. Epub 2016/06/14. doi: <pub-id pub-id-type="doi">10.1038/ncomms11611</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">27291514</pub-id>; PubMed Central PMCID: <pub-id pub-id-type="pmcid">PMCPMC4909937</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Bains</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Cater</surname> <given-names>HL</given-names></string-name>, <string-name><surname>Sillito</surname> <given-names>RR</given-names></string-name>, <string-name><surname>Chartsias</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sneddon</surname> <given-names>D</given-names></string-name>, <string-name><surname>Concas</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>Analysis of Individual Mouse Activity in Group Housed Animals of Different Inbred Strains using a Novel Automated Home Cage Analysis System</article-title>. <source>Frontiers in Behavioral Neuroscience</source>. <year>2016</year>;<volume>10</volume>(<issue>106</issue>). doi: <pub-id pub-id-type="doi">10.3389/fnbeh.2016.00106</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Perez-Escudero</surname> <given-names>A</given-names></string-name>, <string-name><surname>Vicente-Page</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hinz</surname> <given-names>RC</given-names></string-name>, <article-title>Arganda S, de Polavieja GG. idTracker: tracking individuals in a group by automatic identification of unmarked animals</article-title>. <source>Nat Methods</source>. <year>2014</year>;<volume>11</volume>(<issue>7</issue>):<fpage>743</fpage>&#x2013;<lpage>8</lpage>. Epub 2014/06/02. doi: <pub-id pub-id-type="doi">10.1038/nmeth.2994</pub-id>. PubMed PMID: <pub-id pub-id-type="pmid">24880877</pub-id>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Dandan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>X</given-names></string-name>, editors. <article-title>A Hybrid Video and RFID Tracking System for Multiple Mice in Lab Environment</article-title>. <source>2016 3rd International Conference on Information Science and Control Engineering (ICISCE)</source>; 2016 8-10 July <year>2016</year>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Saxena</surname> <given-names>R</given-names></string-name>, <string-name><surname>Barde</surname> <given-names>W</given-names></string-name>, <string-name><surname>Deshmukh</surname> <given-names>SS.</given-names></string-name> <article-title>Inexpensive, scalable camera system for tracking rats in large spaces</article-title>. <source>bioRxiv</source>. <year>2018</year>. doi: <pub-id pub-id-type="doi">10.1101/285460</pub-id>.</mixed-citation></ref>
</ref-list></back>
</article>
