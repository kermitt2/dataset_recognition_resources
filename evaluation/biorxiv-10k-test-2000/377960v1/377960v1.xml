<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BIORXIV</journal-id>
<journal-title-group>
<journal-title>bioRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/377960</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="author-type">
<subject>Regular Article</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>New Results</subject>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Animal Behavior and Cognition</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>An open source platform for analyzing and sharing worm behavior data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Javer</surname>
<given-names>Avelino</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Currie</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lee</surname>
<given-names>Chee Wai</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hokanson</surname>
<given-names>Jim</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Kezhi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Martineau</surname>
<given-names>C&#x00E9;line N</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yemini</surname>
<given-names>Eviatar</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Grundy</surname>
<given-names>Laura J</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Chris</given-names>
</name>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ch&#x2019;ng</surname>
<given-names>QueeLim</given-names>
</name>
<xref ref-type="aff" rid="a9">9</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schafer</surname>
<given-names>William R</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nollen</surname>
<given-names>Ellen AA</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kerr</surname>
<given-names>Rex</given-names>
</name>
<xref ref-type="aff" rid="a10">10</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Brown</surname>
<given-names>Andr&#x00E9; EX</given-names>
</name>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution>MRC London Institute of Medical Sciences</institution>, London, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>institute of Clinical Sciences</institution>, Imperial College London, London, <country>UK</country></aff>
<aff id="a3"><label>3</label><institution>OpenWorm Foundation</institution>, San Diego, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Department of Biomedical Engineering, Duke University</institution>, Durham, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution>European Research Institute for the Biology of Ageing, University of Groningen</institution>, Groningen, NL</aff>
<aff id="a6"><label>6</label><institution>Department of Biological Sciences, Columbia University</institution>, New York, <country>USA</country></aff>
<aff id="a7"><label>7</label><institution>MRC Laboratory of Molecular Biology</institution>, Cambridge, <country>UK</country></aff>
<aff id="a8"><label>8</label><institution>Department of Biology, City College of the City University of New York</institution>, New York, <country>USA</country></aff>
<aff id="a9"><label>9</label><institution>Centre for Developmental Neurobiology</institution>, King&#x2019;s College London, London, <country>UK</country></aff>
<aff id="a10"><label>10</label><institution>Calico Life Sciences LLC</institution>, South San Francisco, <country>USA</country></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="other"><label>&#x002A;</label><p><email>andre.brown@imperial.ac.uk</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2018</year>
</pub-date>
<elocation-id>377960</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="rev-recd">
<day>26</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>7</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2018</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="377960.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<p>Animal behavior is increasingly being recorded in systematic imaging studies that generate large data sets. To maximize the usefulness of these data there is a need for improved resources for analyzing and sharing behavior data that will encourage re-analysis and method development by computational scientists<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. However, unlike genomic or protein structural data, there are no widely used standards for behavior data. It is therefore desirable to make the data available in a relatively raw form so that different investigators can use their own representations and derive their own features. For computational ethology to approach the level of maturity of other areas of bioinformatics, we need to address at least three challenges: storing and accessing video files, defining flexible data formats to facilitate data sharing, and making software to read, write, browse, and analyze the data. We have developed an open resource to begin addressing these challenges using worm tracking as a model.</p>
</abstract>
<counts>
<page-count count="20"/>
</counts>
</article-meta>
</front>
<body>
<p>To store video files and the associated feature and metadata, we use a Zenodo.org community (an open-access repository for data) that provides durable storage, citability, and supports contributions from other groups. We have also developed a web interface that enables filtering based on feature histograms that can return, for example, fast and curved worms in addition to more standard searches for particular strains or genotypes (<xref ref-type="fig" rid="fig1">Fig. 1</xref> and <ext-link ext-link-type="uri" xlink:href="http://movement.openworm.org/">http://movement.openworm.org/</ext-link>). The database consists of 14,874 single-worm tracking experiments representing 386 genotypes (building on 9,203 experiments and 305 genotypes in a previous publication<sup><xref ref-type="bibr" rid="c2">2</xref></sup>) and includes data from several larval stages as well as ageing data consisting of over 2,700 videos of animals tracked daily from the L4 stage to death. Full resolution videos are available in HDF5 containers that include gzip-compressed video frames, timestamps, worm outline and midline, feature data, and experiment metadata. HDF5 files are compatible with multiple languages including MATLAB, R, Python, and C. We have also developed an HDF5 video reader that allows video playback with adjustable speed and zoom (important when reviewing high-resolution, multi-worm tracking data), as well as toggling of worm segmentation over the original video to verify segmentation accuracy during playback.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1:</label>
<caption><p>(<bold>a</bold>) To facilitate the sharing of tracking data, the OpenWorm Movement Database provides a web interface to search a database of worm videos by genotype, strain, and/or other discrete values. The interface includes interactive histograms, with sliders permitting users to filter results based on feature values, making it possible to find files with worms that are, for example, both fast and highly curved. The interface then connects to the video and feature data stored on Zenodo. Once downloaded, the video and feature data can be further analyzed or combined with data collected using other worm trackers through the Worm tracker Commons Object Notation (WCON), a human and machine readable JSON format for sharing tracking data. (<bold>b</bold>) Open-source repositories for tracking and analysis. Tierpsy Tracker segments and tracks worms, extracting the outline and skeleton of each animal then determining the head-tail orientation (Tierpsy is short for Tierpsychology, the German word for ethology). These data are saved in WCON. The Open Worm Analysis Toolbox is then used to extract the large set of behavioral features defined in Yemini <italic>et al</italic>.<sup><xref ref-type="bibr" rid="c2">2</xref></sup>. WCON includes a flexible notation for adding custom features to the WCON file if desired.</p></caption>
<graphic xlink:href="377960_fig1.tif"/>
</fig>
<p>Secondly, we have defined an interchange format named Worm tracker Commons Object Notation (WCON), to facilitate data sharing and software reuse among groups working on worm behavior. WCON uses the widely supported JSON format to store tracking data as text that is both human and machine readable. It is compatible with single and multi-worm<sup><xref ref-type="bibr" rid="c3">3</xref></sup> data, at any resolution: from a single point representing worm position over time<sup><xref ref-type="bibr" rid="c4">4</xref></sup>, to many points representing the high-resolution skeleton of a moving worm<sup><xref ref-type="bibr" rid="c2">2</xref></sup>. Importantly, it also supports custom feature additions so that individual labs can store their own specific data sets alongside the universal set of basic worm data. WCON readers are available for Python, MATLAB, Scala, and C. Detailed documentation for the file formats and software is available on the project page (<ext-link ext-link-type="uri" xlink:href="https://github.com/openworm/tracker-commons">https://github.com/openworm/tracker-commons</ext-link>).</p>
<p>Finally, we have complemented the database and file formats with open-source software written in Python for single and multi-worm tracking, feature extraction, review, and analysis (Supplementary Discussion).</p>
<p>The suite of tools we have reported makes quantitative behavior (re-)analysis more accessible for both experimentalists and computational scientists. It may also serve as a template for similar efforts in other model organism communities.</p>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by the MRC through grant MC-A658-5TY30 to AEXB. QC is supported by an ERC Starting Grant (NeuroAge 242666), Research Councils UK Fellowship, and the University of London Central Research Fund. Some strains were provided by the CGC, which is funded by the NIH Office of Research Infrastructure Programs (P40 OD010440).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Gomez-Marin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Paton</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Kampff</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Costa</surname>, <given-names>R. M.</given-names></string-name> &#x0026; <string-name><surname>Mainen</surname>, <given-names>Z. F.</given-names></string-name> <source>Nat. Neurosci.</source> <volume>17</volume>, <fpage>1455</fpage>&#x2013;<lpage>1462</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Yemini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Jucikas</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Grundy</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>A. E. X.</given-names></string-name> &#x0026; <string-name><surname>Schafer</surname>, <given-names>W. R.</given-names></string-name> <source>Nat. Methods</source> <volume>10</volume>, <fpage>877</fpage>&#x2013;<lpage>879</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Swierczek</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Giles</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Rankin</surname>, <given-names>C. H.</given-names></string-name> &#x0026; <string-name><surname>Kerr</surname>, <given-names>R. A.</given-names></string-name> <source>Nat. Methods</source> <volume>8</volume>, <fpage>592</fpage>&#x2013;<lpage>598</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Ramot</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>B. E.</given-names></string-name>, <string-name><surname>Berry</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Carnell</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Goodman</surname>, <given-names>M. B.</given-names></string-name> <source>PLoS ONE</source> <volume>3</volume>, <fpage>e2208</fpage> (<year>2008</year>).</mixed-citation></ref>
</ref-list>
<sec id="s1" sec-type="supplementary-material">
<title>Supplementary Discussion</title>
<sec id="s1a">
<title>Submitting Data to movement.openworm.org</title>
<p>The OpenWorm movement database is intended to be a growing resource to compile and compare behavior data contributed by the community. Despite the variety of behavioral experiments, the WCON format enables multiple labs to contribute data in a form that is easily validated and from which standard behavioral features can be derived. To make WCON easier to work with we have made a web browser-based viewer that checks that a WCON file has the correct format, renders the data as a video, and displays the metadata and units in a table (<xref ref-type="fig" rid="fig1">Fig. 1</xref>). Once data have been validated using either the viewer or one of the WCON readers on the Worm tracker Commons project page, they can be submitted through a web form on the movement database site. Submitted data will be reviewed manually to ensure they contain worm behavior data and analyzed to extract the same features used to search the movement database. Finally, the WCON and feature data will be uploaded to the OpenWorm Movement Database community on Zenodo.org for long term storage and citability.</p>
<fig id="fig1a" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1:</label>
<caption><title>WCON viewer.</title>
<p>Screenshot showing a validated WCON file being viewed in a web browser. The video can be played and paused, scrolled through using the slider, and zoomed. Below the video, the browser displays the metadata and units in a table.</p></caption>
<graphic xlink:href="377960_fig1a.tif"/>
</fig>
<p>To maximize comparability between submitted data and the existing data on <ext-link ext-link-type="uri" xlink:href="http://movement.openworm.org/">http://movement.openworm.org/</ext-link> we recommend the use of the same protocol that was used to collect the original data<sup><xref ref-type="bibr" rid="sc1">1</xref></sup>. However, we recognize that experiments with different goals may require different protocols and emphasize that we accept data collected using other protocols.</p>
</sec>
<sec id="s1b">
<title>Tierpsy Tracker Description</title>
<p>Tierpsy Tracker is a multi-worm tracker written primarily in Python that is capable of extracting postural information. Tierpsy Tracker was designed to occupy a niche that was not filled by existing worm trackers (see Comparison with other trackers below for details). It extracts the same high-dimensional feature set as WormTracker 2.0 so that its output can be directly compared to the growing worm behavior database described here. It is fully open source, including all dependencies, so no commercial software (such as MATLAB or Labview) is required to inspect it, run it, or modify it, while executable versions are provided for both Windows and Mac OSX for those who want to use the software without dealing with the source code. It has the following main features:
<list list-type="bullet">
<list-item><p>Following segmentation, it saves output videos in a compressed HDF5 format that preserves full pixel information around worms losslessly while zeroing background pixels (see <xref ref-type="fig" rid="fig1">Figure 1</xref> in main text). To monitor slowly changing background features such as food depletion, full resolution images can be saved with adjustable frequency. The HDF5 files can be read using many languages (including MATLAB and Python) and support precise frame indexing. They also include experiment and analysis metadata.</p></list-item>
<list-item><p>It supports a variety of video formats and experimental setups (see Sample Analysis below).</p></list-item>
<list-item><p>It provides graphical user interfaces to calibrate the parameters for a new experimental setup, review the segmentation results, and manually join trajectory fragments if desired.</p></list-item>
<list-item><p>It can analyze large data sets from screening projects consisting of thousands of videos by taking advantage of multicore processors to implement &#x2018;embarrassingly parallel&#x2019; processing of multiple videos. This can be done using a simple batch processing function in the graphical user interface or from the command line.</p></list-item>
<list-item><p>Its processing pipeline is modular so that analysis steps can be skipped or added depending on the analysis type and it records the provenance of output files (including software version and analysis parameters) to improve reproducibility.</p></list-item>
<list-item><p>It is able to copy files from and to temporary directories prior to and after the analysis in order to deal with unstable remote connections.</p></list-item>
</list></p>
</sec>
<sec id="s1c">
<title>Comparison with Worm Tracker 2.0</title>
<p>Tierpsy Tracker is at its core a multi-worm generalization of WormTracker 2.0<sup><xref ref-type="bibr" rid="sc1">1</xref></sup>, a single-worm tracker, although it should be emphasized that the underlying software has been ported to Python from MATLAB and completely re-designed. Tierpsy Tracker is fully compatible with videos produced by the WormTracker 2.0 hardware. The skeletonization, stage alignment, and feature calculation algorithms are Python ports of the original MATLAB algorithms. When WormTracker 2.0 files are analyzed in Tierpsy Tracker, the HDF5 output files include stage movement and experiment information along with the segmented video, reducing the risk of misplacing or losing this essential metadata.</p>
<p>Tierpsy Tracker uses a locally calculated threshold as opposed to the global threshold used in WormTracker 2.0, which makes it more robust to non-uniform lighting. However, on the high-contrast videos produced typically produced by WormTracker 2.0, the results are similar (see <xref ref-type="fig" rid="fig2">Fig. 2A</xref>). In cases where there are substantial differences between the two trackers, these are most-often caused by head-tail identification errors that are corrected by Tierpsy Tracker&#x2019;s more accurate head tail detection algorithm (see &#x201C;Head/tail identification&#x201D;). We measured the head/tail orientation accuracy by randomly selecting 100 videos from the database and manually assessing if the orientation was correct in each frame that was successfully skeletonized. In a random subset of 100 videos, containing 1.9 x 10<sup><xref ref-type="bibr" rid="sc6">6</xref></sup> frames that were successfully skeletonized in both Tierpsy and WT2.0, we confirmed by manual inspection that Tierpsy made a mistake in only 216 of the frames (0.01&#x0025;) while WormTracker2.0 made a mistake in 87,751 of the frames (4.49&#x0025;). To further test the accuracy, we measure the RMSE between skeletons produced by WormT racker 2.0 and Tierpsy T racker in 1.8 x 10<sup><xref ref-type="bibr" rid="sc8">8</xref></sup> frames across 9343 videos. We consider that two skeletons are in agreement if the RMSE between them is less than 1/48 the length of the Tierpsy Tracker skeleton which is equivalent to a single segment in the skeleton. We found that 96.19&#x0025; of the skeletons are in agreement, and that 8410/9343 of the videos have 90&#x0025; or more of their skeletons in agreement (<xref ref-type="fig" rid="fig2">Fig. 2</xref>). Head-tail errors will result in a large RMSE for otherwise well-skeletonized worms so we switched the orientation of the WormTracker 2.0 skeletons and re-calculated the RMSE. If we use the lower of the two RMSE values between switched or not switched, we find that 99.20&#x0025; of the skeletons are in agreement, and that 9208/9343 of the videos have 90&#x0025; or more of their skeletons in agreement.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig 2:</label>
<caption><title>Benchmark between Tierpsy Tracker and Worm Tracker 2.0.</title>
<p>A. Tracking results from video of a single L4 N2 analyzed with both Tierpsy Tracker (orange) and Worm Tracker 2.0 (green). Both trackers produce almost identical results except in a small segment where there was a head-tail identification error by Worm Tracker 2.0 (frames 5564 to 5678). The Tierpsy Tracker skeleton coordinates were rotated to align them with the Worm Tracker results prior plotting. This is because the coordinate system in Tierpsy matches the camera orientation, while in WT2.0, it matches the stage position. <italic>Left top</italic>, Root Square Mean Error (RMSE) between the skeletons output by each tracker. <italic>Left centre and bottom</italic>, y and x head coordinates over time. <italic>Right</italic>, midbody trajectory in space. <italic>Inset</italic>, example of the skeletonization results at frame 2500. B. <italic>Left</italic>, Cumulative distribution of the total fraction of skeletons with a given RMSE between the results of Worm Tracker 2.0 and Tierpsy Tracker. RMSE values are normalized by the worm length (L). The shaded blue region marks the threshold of 1/48 &#x2248; 0.021 and contains 99.2&#x0025; of all the frames in RMSE<sub>switch</sub>. The inset shows an example of WT2.0 (red) and Tierpsy (cyan) with a RMSE of 0.02, which is at the border of the shaded region. 99.2&#x0025; of skeleton agreements are as good or better than this. <italic>Right</italic>, videos sorted by the fraction of RMSE/L less than 1/48. See main text for more information.</p></caption>
<graphic xlink:href="377960_fig2.tif"/>
</fig>
</sec>
<sec id="s1d">
<title>Comparison with other trackers</title>
<p>Several worm trackers have been previously described<sup><xref ref-type="bibr" rid="sc1">1</xref>&#x2013;<xref ref-type="bibr" rid="sc19">19</xref></sup>. Most of the trackers either extract detailed postural information of one worm at a time or track multiple worms but extract only coarser-grained features such as centroid speed or orientation. Collecting postural information in addition to overall motion can be useful for phenotyping<sup><xref ref-type="bibr" rid="sc1">1</xref>,<xref ref-type="bibr" rid="sc13">13</xref>,<xref ref-type="bibr" rid="sc20">20</xref>&#x2013;<xref ref-type="bibr" rid="sc22">22</xref></sup>, while tracking multiple worms can increase throughput and make it possible to study worm-worm interactions. Tierpsy Tracker is one of a relatively smaller number of trackers that extracts postural information from frames containing multiple worms and is the only tracker that compresses videos by background subtraction while maintaining uncompressed pixel information around tracked objects. This is an important feature because it makes Tierpsy Tracker compatible with large scale screens while maintaining enough information to re-analyze datasets using algorithms that depend on pixel information (e.g. egg laying detection, texture-based analyses, idTracker<sup><xref ref-type="bibr" rid="sc23">23</xref></sup>, etc.).</p>
<p>There are two other published open source trackers that track multiple worms and extract detailed postural information: the Multi-Worm Tracker<sup><xref ref-type="bibr" rid="sc8">8</xref></sup> and CeLeST<sup><xref ref-type="bibr" rid="sc6">6</xref></sup>. The Multi-Worm Tracker can be used for high-throughput screens but compresses data by saving worm positions and outlines while discarding all pixel information. CeLeST extracts features from videos but does not compress videos. Furthermore, Tierpsy Tracker is fully open source, including its dependencies whereas the Multi-Worm Tracker and CeLEST use commercial software for at least part of their pipelines (the Multi-Worm Tracker requires a Labview runtime license for its user interface and CeLEST is written in MATLAB). Tierpsy Tracker occupies an intermediate niche between these two other trackers in terms of processing speed and ease of use. It is slower than the Multi-Worm Tracker but includes graphical user interfaces for parameter tuning and batch processing making it more accessible for users unfamiliar with running software from the command line (although Tierpsy Tracker can also be run from the command line). Compared to CeLeST, Tierpsy tracker extracts a wider range of features (provided sufficient video resolution, <xref ref-type="fig" rid="fig3">Fig. 3</xref>) and includes simple parallelization without user intervention, which is convenient for running on larger datasets. Tierpsy tracker is also faster on a per-file basis: on a MacBook Pro (2.7GHz Core Quad, 16GB) the Dataset S1 in Restif <italic>et al</italic>.<sup><xref ref-type="bibr" rid="sc6">6</xref></sup> was analyzed in 3 minutes using CeLEST (MATLAB 2014b) and 1.5 minutes using Tierpsy.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 3:</label>
<caption><title>Effect of resolution on tracking.</title>
<p>To simulate the effect of pixel size in the tracking analysis we reduced the size of a video of an N2 adult recorded using Worm Tracker 2.0. A. Example of a frame at the different image sizes tested, the skeletonization results are overlaid (red). We test image sizes of 680&#x00D7;480, 213&#x00D7;160, 91&#x00D7;68 and 45&#x00D7;34, this is the equivalent of 3.57, 10.73, 25.12 and 50.80 &#x03BC;m/pixel respectively. The skeletonization algorithm fails at 50.8 &#x03BC;m/pixel. B. Time series plots (<italic>left</italic>) and histograms (<italic>right</italic>) of a few selected features. Most of the features calculated produce similar results at different resolutions, except for features related with morphology (length, width, area) or to the head and the tail (foraging, angular speed) which show an increase in noise with reducing resolution.</p></caption>
<graphic xlink:href="377960_fig3.tif"/>
</fig>
</sec>
<sec id="s1e">
<title>Video compression in large fields of view</title>
<p>An uncompressed video stream from a four-megapixel camera recording at 25fps will fill a 2TB disk in less than 3hrs of recording. Some form of compression is therefore an important component of a high-resolution tracker intended for even moderate throughput experiments.</p>
<p>The most common approach is to use a video format that uses lossy compression to manage file sizes while maintaining visual features tuned to human vision (although not necessarily optimal for computer vision<sup><xref ref-type="bibr" rid="sc24">24</xref></sup>) but this introduces compression artefacts.</p>
<p>A more extreme approach is adopted by the Multi-Worm tracker<sup><xref ref-type="bibr" rid="sc8">8</xref></sup>, which saves a compact set of features including worm contour and position. This greatly reduces file size, but it comes at the expense of losing all the video textural information, precluding re-analysis with improved computer vision methods. Tierpsy Tracker uses an intermediate approach by only keeping the pixels around candidate worm regions and setting the rest of the image to zero (see Compression/object detection). These segmented images are highly compressible using standard lossless compression algorithms thus reducing file sizes while maintaining full resolution information around each worm so that tracking and analysis can be repeated as improved algorithms are developed. Tierpsy Tracker also uses pixel intensities in its improved head-tail detection algorithm (see &#x201C;Head/tail identification&#x201D; and <xref ref-type="fig" rid="fig4">Fig. 4</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig 4:</label>
<caption><title>Head tail correction using intensity.</title>
<p>A. Process of interpolation along the segments perpendicular to the worm skeletons to obtain the intensity along a straightened worm<sup><xref ref-type="bibr" rid="sc25">25</xref></sup>. B. Example of different intensity profiles along the worm skeletons for different frames. The blue line corresponds to the median values among all the intensity profiles (global intensity profile). C. Kymograph of the intensity profile along the skeleton. The position of each the intensity profile shown in panel B is marked with the corresponding colour line. D. L1-norm between the difference of each frame intensity profile and the global intensity profile (original, blue or inverted, orange). The region corresponding to a wrongly oriented skeleton block (pink shade) has a smaller value in the inverted than in the original L1-norms.</p></caption>
<graphic xlink:href="377960_fig4.tif"/>
</fig>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 5:</label>
<caption><title>Classification of wild isolates.</title>
<p>A. Left, original image. Right, results after the applying the compression mask. Each square corresponds to an identified worm. The worm in the red square is shown at a higher zoom in the inlets in each panel. B. Example of time series of two selected postural features. C. Confusion matrix of the classifier using 10-fold cross validation on features related with motion that could be extracted using low resolution multi-worm tracking (<italic>left</italic>) or using all the features we calculate using both motion and postural data (<italic>right</italic>).</p></caption>
<graphic xlink:href="377960_fig5.tif"/>
</fig>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 6:</label>
<caption><title>Swimming <italic>C. elegans</italic>.</title>
<p><italic>Top left</italic>, original image. <italic>Top right</italic>, results after applying the compression mask. Each square corresponds to an identified worm. <italic>Bottom left</italic>, example time series of two selected postural features. <italic>Bottom right</italic>, skeleton and contour of the worm inside the red square in the top right panel. The head is indicated with the red asterisk.</p></caption>
<graphic xlink:href="377960_fig6.tif"/>
</fig>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 7:</label>
<caption><title>Videos of maggots at different resolutions.</title>
<p>Data from ref<sup><xref ref-type="bibr" rid="sc27">27</xref></sup> (<italic>top row</italic>) and ref<sup><xref ref-type="bibr" rid="sc28">28</xref></sup> (<italic>centre and bottom row</italic>). The raw videos generously provided by Alex Gomez-Marin. Data from left to right: original image; results after applying the compression mask (each square corresponds to an identified maggot); skeleton and contour of a selected maggot; example time series of two selected postural features.</p></caption>
<graphic xlink:href="377960_fig7.tif"/>
</fig>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 8:</label>
<caption><title>Dataset S1 in Restif <italic>et al</italic>.<sup><xref ref-type="bibr" rid="sc6">6</xref></sup></title>
<p><italic>Top left</italic>, original image. <italic>Top right</italic>, results after the applying the compression mask. Each square corresponds to an identified worm. <italic>Bottom left</italic>, example time series of two selected postural features. <italic>Bottom right</italic>, skeleton and contour of the worm inside the red square in the top right panel. The head is indicated with the red asterisk.</p></caption>
<graphic xlink:href="377960_fig8.tif"/>
</fig>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 9:</label>
<caption><title>Example from pycelegans-1.0<sup><xref ref-type="bibr" rid="sc7">7</xref></sup>.</title>
<p>Data obtained from: <italic><ext-link ext-link-type="uri" xlink:href="https://github.com/david-biron/pycelegans-1.0/tree/master/example/input">https://github.com/david-biron/pycelegans-1.0/tree/master/example/input</ext-link></italic>. <italic>Top</italic>, original image. <italic>Middle</italic>, results after the applying the compression mask. Each square corresponds to an identified worm. <italic>Bottom left</italic>, example time series of two selected postural features. <italic>Bottom right</italic>, skeleton and contour of the worm inside the red square in the middle panel. The head is indicated with the red asterisk.</p></caption>
<graphic xlink:href="377960_fig9.tif"/>
</fig>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 10:</label>
<caption><title>Video S6 in Chagas <italic>et al</italic>.<sup><xref ref-type="bibr" rid="sc29">29</xref></sup></title>
<p><italic>Top left</italic>, original image. <italic>Top right</italic>, results after the applying the compression mask. Each square corresponds to an identified worm. <italic>Bottom left</italic>, example time series of two selected postural features. <italic>Bottom right</italic>, skeleton and contour of the worm inside the red square in the top right panel. The head is indicated with the red asterisk.</p></caption>
<graphic xlink:href="377960_fig10.tif"/>
</fig>
<p>Although segmentation followed by lossless compression is our currently favoured approach, Tierpsy Tracker can use video codecs supported by the FFmpeg library (<ext-link ext-link-type="uri" xlink:href="https://www.ffmpeg.org/">https://www.ffmpeg.org/</ext-link>) via OpenCV (<ext-link ext-link-type="uri" xlink:href="https://opencv.org/">https://opencv.org/</ext-link>), as well as setups where each frame is saved as an individual image. Tierpsy Tracker also makes it straightforward to save only worm contour, skeleton, and feature data because it creates a parallel directory structure for analysis results. If tracking results are acceptable, the original and/or compressed videos can simply be deleted to mimic the online behaviour of the Multi-Worm Tracker.</p>
</sec>
<sec id="s1f">
<title>Compression/object detection algorithm</title>
<p>The aim of the initial segmentation is to identify regions in the image that are likely to contain worms and to compress the data by only keeping the pixels around these candidate regions. The worms are assumed to be dark objects on a light background or light objects on a dark background. The detection algorithm uses an adaptive mean thresholding to account for local variations of the image intensity, filters the resulting blobs by their size, and uses morphological operations to clean the resulting mask and save the surrounding pixels. Each frame is then masked and saved into an HDF5 file using a compressed 3D array (frame &#x002A; image width &#x002A; image height). The HDF5 format is used due to its capacity to deal with arbitrarily large files, built-in compression filters, and its support of a large variety of software platforms.</p>
<p>Instead of calculating a new mask for each frame, we can save computation time by collecting a stack of frames and calculating the mask on the z-projection (minimum for a light background and maximum for a dark background). Using this approach together with the faster lz4 compression, a C&#x002B;&#x002B; implementation of the algorithm was implemented in our setup to run in real time (25 fps).</p>
</sec>
<sec id="s1g">
<title>Head/tail identification algorithm</title>
<p>The output of the skeletonization algorithm does not determine which end of the curve is the head and which one the tail. To orient the skeletons, we use the following algorithm which depends in part on having the high-resolution textural information in Tierpsy&#x2019;s HDF5 file format:
<list list-type="order">
<list-item><p>During the skeletonization step we attempt to keep the same orientation between consecutive skeletons by choosing the orientation that minimizes the L2-norm of the current and previous skeletons. For this step, the orientation does not have to be correct (head and tail could be misplaced), we are only interested in keeping a spatial coherence between consecutive frames. This approach will maintain the same</p></list-item>
<list-item><p>orientation even if the skeletonization fails for few frames, as long as the time gap between consecutive skeletons is small relatively to the worm displacement.</p></list-item>
<list-item><p>We divided the movie into blocks of skeletons with the same orientation. A skeleton is assigned to a given block if there is not a gap larger than 0.5s with the previous skeleton in the block. For each block, we estimate the motility of each extreme in the skeleton as the rolling standard deviation (window 5s) of the angles between each end-point and a point at &#x007E;1/10 of the worm length from it. The end corresponding to the head is assumed to have a larger motility than the end corresponding to the tail. This step typically orients most of the skeletons correctly, but it will fail if the tail moves more in that particular block, which occurs most often in small blocks.</p></list-item>
<list-item><p>To correct for mistakes in the previous step we make use of the pixel intensities along the worms. We interpolate along the segments perpendicular to the worm skeletons to obtain the profile intensity along a straightened worm<sup><xref ref-type="bibr" rid="sc25">25</xref></sup> (<xref ref-type="fig" rid="fig4">Fig 4A</xref>). If the trajectories are large enough most of the skeletons in the previous step should have been oriented correctly, therefore if we get the median value of all the intensities we can determine a global intensity profile for each worm with the correct orientation (<xref ref-type="fig" rid="fig4">Fig 4B</xref>). Blocks of skeletons with incorrect orientation will show a switched intensity profile (<xref ref-type="fig" rid="fig4">Fig 4C</xref>). We detect these blocks by calculating the L1-norm of the difference between each frame profile and the global profile in both the correct orientation and with a switched orientation. If the L1-norm of the switched profile is smaller than that of the correct orientation, it is likely that the corresponding skeleton needs to be corrected.</p></list-item>
<list-item><p>The previous step will typically orient all the skeletons with the same orientation, but this orientation could be wrong in rare cases where most of the head/tail blocks were assigned incorrectly in step 2). As a final refinement step, we recalculate the motility of each extreme in the skeleton similar to 2) but using the whole video as a single block. In cases where the worm is mostly immobile, <italic>i.e</italic>. the total head displacement range is less than half the worm length, we increase the rolling window from 5s to 250s in order to increase the sensitivity of the analysis.</p></list-item>
</list></p>
</sec>
<sec id="s1h">
<title>Sample analysis</title>
<p>To demonstrate the usefulness of postural features in a multi-worm tracker, we used Tierpsy Tracker to extract features from videos of twelve wild isolated strains of <italic>C. elegans</italic> (the CeNDR divergent set<sup><xref ref-type="bibr" rid="sc26">26</xref></sup>) and trained a classifier to distinguish them. We collected between 25 and 28 videos per strain. Each video contains 5-10 worms per plate. We pooled the time series and event data of all the worms in a given video and calculated the 726 morphological and behavioural features described in Yemini <italic>et al</italic>.<sup><xref ref-type="bibr" rid="sc20">20</xref></sup> We remove features where more than 5&#x0025; of the videos have NaN values leaving 681 features. We imputed any remaining NaN values with the global average (i.e. the average of that feature across all strains) and z-normalised each feature by subtracting the mean and dividing by its standard deviation.</p>
<p>To classify the strains, we implemented a multinomial logistic regression as a Softmax layer using PyTorch. We trained for 500 epochs using a mini-batch size of 50 and stochastic gradient descent with learning rate 0.001 and momentum 0.9. Using a 6-fold stratified cross validation we obtained an accuracy 87.8 &#x00B1; 4.0&#x0025; (mean &#x00B1; standard deviation) using all the 681 features selected as described above. To illustrate the importance of extracting high-resolution postural information, we trained a separate classifier on the same data using only features that could be extracted using a lower resolution multi-worm tracker without detailed postural data. These features are derivate from the midbody speed (linear and angular) and crawling (frequency and amplitude), motion events (<italic>e.g</italic>. turning rate, forward motion time, average displacement when moving backwards), and the path range and curvature. We selected in total 133 features and obtain a lower accuracy of 57.6 &#x00B1; 4.5&#x0025; (mean &#x00B1; standard deviation).</p>
<p>Sample preparation: The protocol for tracking is similar to that described in <xref ref-type="bibr" rid="c2">Yemini <italic>et al</italic>. (2013)</xref>. L4 larvae are picked onto a plate with OP50 and allowed to grow overnight to adulthood. Before imaging, 5 or 10 young adults are picked onto a 35 mm plate and allowed to habituate for 30 minutes before recording. Each recording lasts for 15 minutes. Imaging plates contain nematode growth medium (NGM) with low peptone that have been seeded the day before 75&#x03BC;L of OP50.</p>
</sec>
<sec id="s1i">
<title>Examples of Tierpsy Tracker analysis using different experimental setups</title>
<p>A useful characteristic of Tierpsy Tracker is that it can deal with data from a large variety of experimental setups. We provide the following examples using previously published data:
<list list-type="bullet">
<list-item><p><xref ref-type="fig" rid="fig6">Fig. 6</xref> Swimming <italic>C. elegans</italic>.</p></list-item>
<list-item><p><xref ref-type="fig" rid="fig7">Fig. 7</xref> <italic>Drosophila</italic> larvae<sup><xref ref-type="bibr" rid="sc27">27</xref>,<xref ref-type="bibr" rid="sc28">28</xref></sup>.</p></list-item>
<list-item><p><xref ref-type="fig" rid="fig8">Fig. 8</xref> Dataset S1 in Restif <italic>et al</italic>.<sup><xref ref-type="bibr" rid="sc6">6</xref></sup></p></list-item>
<list-item><p><xref ref-type="fig" rid="fig9">Fig. 9</xref> Example from pycelegans-1.0<sup><xref ref-type="bibr" rid="sc7">7</xref></sup>.</p></list-item>
<list-item><p><xref ref-type="fig" rid="fig10">Fig. 10</xref> Video S6 in Chagas <italic>et al</italic>.<sup><xref ref-type="bibr" rid="sc29">29</xref></sup></p></list-item>
</list></p>
</sec>
</sec>
<ref-list>
<title>Bibliography</title>
<ref id="sc1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Yemini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Jucikas</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Grundy</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>A. E.</given-names></string-name> &#x0026; <string-name><surname>Schafer</surname>, <given-names>W. R.</given-names></string-name> <article-title>A database of Caenorhabditis elegans behavioral phenotypes</article-title>. <source>Nat. Methods</source> <volume>10</volume>, <fpage>877</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="sc2"><label>2.</label><mixed-citation publication-type="book"><string-name><surname>Husson</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Costa</surname>, <given-names>W. S.</given-names></string-name>, <string-name><surname>Schmitt</surname>, <given-names>C.</given-names></string-name> &#x0026; <string-name><surname>Gottschalk</surname>, <given-names>A.</given-names></string-name> <chapter-title>Keeping track of worm trackers</chapter-title>. <collab>WormBook</collab>, ed. <publisher-name>The C. elegans Research Community</publisher-name>, doi<pub-id pub-id-type="doi">/10.1895/wormbook.1.156.1</pub-id> (<year>2005</year>).</mixed-citation></ref>
<ref id="sc3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Dusenbery</surname>, <given-names>D. B.</given-names></string-name> <article-title>Using a microcomputer and video camera to simultaneously track 25 animals</article-title>. <source>Comput. Biol. Med.</source> <volume>15</volume>, <fpage>169</fpage>&#x2013;<lpage>175</lpage> (<year>1985</year>).</mixed-citation></ref>
<ref id="sc4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>S. J.</given-names></string-name> &#x0026; <string-name><surname>Wang</surname>, <given-names>Z.-W.</given-names></string-name> <article-title>Track-a-worm, an open-source system for quantitative assessment of C. elegans locomotory and bending behavior</article-title>. <source>PloS One</source> <volume>8</volume>, <fpage>e69653</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="sc5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Ramot</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>B. E.</given-names></string-name>, <string-name><surname>Berry</surname> <suffix>Jr</suffix>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Carnell</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Goodman</surname>, <given-names>M. B.</given-names></string-name> <article-title>The Parallel Worm Tracker: a platform for measuring average speed and drug-induced paralysis in nematodes</article-title>. <source>PloS One</source> <volume>3</volume>, <fpage>e2208</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="sc6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Restif</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal> <article-title>CeleST: computer vision software for quantitative analysis of C. elegans swim behavior reveals novel features of locomotion</article-title>. <source>PLoS Comput. Biol.</source> <volume>10</volume>, <fpage>e1003702</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="sc7"><label>7.</label><mixed-citation publication-type="other"><string-name><surname>Nagy</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>A longitudinal study of Caenorhabditis elegans larvae reveals a novel locomotion switch, regulated by G&#x03B1;s signaling</article-title>. <source>Elife</source> <fpage>2</fpage>, (<year>2013</year>).</mixed-citation></ref>
<ref id="sc8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Swierczek</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Giles</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Rankin</surname>, <given-names>C. H.</given-names></string-name> &#x0026; <string-name><surname>Kerr</surname>, <given-names>R. A.</given-names></string-name> <article-title>High-throughput behavioral analysis in C. elegans</article-title>. <source>Nat. Methods</source> <volume>8</volume>, <fpage>592</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="sc9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Salvador</surname>, <given-names>L. C.</given-names></string-name>, <string-name><surname>Bartumeus</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Levin</surname>, <given-names>S. A.</given-names></string-name> &#x0026; <string-name><surname>Ryu</surname>, <given-names>W. S.</given-names></string-name> <article-title>Mechanistic analysis of the search behaviour of Caenorhabditis elegans</article-title>. <source>J. R. Soc. Interface</source> <volume>11</volume>, <fpage>20131092</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="sc10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Nagy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Goessling</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Amit</surname>, <given-names>Y.</given-names></string-name> &#x0026; <string-name><surname>Biron</surname>, <given-names>D.</given-names></string-name> <article-title>A generative statistical algorithm for automatic detection of complex postures</article-title>. <source>PLoS Comput. Biol.</source> <volume>11</volume>, <fpage>e1004517</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="sc11"><label>11.</label><mixed-citation publication-type="other"><string-name><surname>Broekmans</surname>, <given-names>O. D.</given-names></string-name>, <string-name><surname>Rodgers</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>W. S.</given-names></string-name> &#x0026; <string-name><surname>Stephens</surname>, <given-names>G. J.</given-names></string-name> <article-title>Resolving coiled shapes reveals new reorientation behaviors in C. elegans</article-title>. <source>eLife</source> <fpage>5</fpage>, (<year>2016</year>).</mixed-citation></ref>
<ref id="sc12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Pierce-Shimomura</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Morse</surname>, <given-names>T. M.</given-names></string-name> &#x0026; <string-name><surname>Lockery</surname>, <given-names>S. R.</given-names></string-name> <article-title>The fundamental role of pirouettes in Caenorhabditis elegans chemotaxis</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci.</source> <volume>19</volume>, <fpage>9557</fpage>&#x2013;<lpage>9569</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="sc13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Baek</surname>, <given-names>J.-H.</given-names></string-name>, <string-name><surname>Cosman</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Feng</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Silver</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Schafer</surname>, <given-names>W. R.</given-names></string-name> <article-title>Using machine vision to analyze and classify Caenorhabditis elegans behavioral phenotypes quantitatively</article-title>. <source>J. Neurosci. Methods</source> <volume>118</volume>, <fpage>9</fpage>&#x2013;<lpage>21</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="sc14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Geng</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Cosman</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Berry</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>Feng</surname>, <given-names>Z.</given-names></string-name> &#x0026; <string-name><surname>Schafer</surname>, <given-names>W. R.</given-names></string-name> <article-title>Automatic tracking, feature extraction and classification of C elegans phenotypes</article-title>. <source>IEEE Trans. Biomed. Eng.</source> <volume>51</volume>, <fpage>1811</fpage>&#x2013;<lpage>1820</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="sc15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Feng</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Cronin</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Wittig</surname>, <given-names>J. H.</given-names>, <suffix>Jr</suffix></string-name>, <string-name><surname>Sternberg</surname>, <given-names>P. W.</given-names></string-name> &#x0026; <string-name><surname>Schafer</surname>, <given-names>W. R.</given-names></string-name> <article-title>An imaging system for standardized quantitative analysis of C. elegans behavior</article-title>. <source>BMC Bioinformatics</source> <volume>5</volume>, <fpage>115</fpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="sc16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Stephens</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Johnson-Kerner</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Bialek</surname>, <given-names>W.</given-names></string-name> &#x0026; <string-name><surname>Ryu</surname>, <given-names>W. S.</given-names></string-name> <article-title>Dimensionality and Dynamics in the Behavior of C. elegans</article-title>. <source>PLoS Comput. Biol.</source> <volume>4</volume>, <fpage>e1000028</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="sc17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Tsibidis</surname>, <given-names>G. D.</given-names></string-name> &#x0026; <string-name><surname>Tavernarakis</surname>, <given-names>N.</given-names></string-name> <article-title>Nemo: a computational tool for analyzing nematode locomotion</article-title>. <source>BMC Neurosci.</source> <volume>8</volume>, <fpage>86</fpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="sc18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Itskovits</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Levine</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>E.</given-names></string-name> &#x0026; <string-name><surname>Zaslaver</surname>, <given-names>A.</given-names></string-name> <article-title>A multi-animal tracker for studying complex behaviors</article-title>. <source>BMC Biol.</source> <volume>15</volume>, <fpage>29</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="sc19"><label>19.</label><mixed-citation publication-type="other"><string-name><surname>Perni</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Massively parallel C. elegans tracking provides multi-dimensional fingerprints for phenotypic discovery</article-title>. <source>J. Neurosci. Methods</source> (<year>2018</year>). doi:<pub-id pub-id-type="doi">10.1016/j.jneumeth.2018.02.005</pub-id></mixed-citation></ref>
<ref id="sc20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Brown</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Yemini</surname>, <given-names>E. I.</given-names></string-name>, <string-name><surname>Grundy</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Jucikas</surname>, <given-names>T.</given-names></string-name> &#x0026; <string-name><surname>Schafer</surname>, <given-names>W. R.</given-names></string-name> <article-title>A dictionary of behavioral motifs reveals clusters of genes affecting Caenorhabditis elegans locomotion</article-title>. <source>Proc. Natl. Acad. Sci.</source> <volume>110</volume>, <fpage>791</fpage>&#x2013;<lpage>796</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="sc21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Yu</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal> <article-title>Systematic profiling of Caenorhabditis elegans locomotive behaviors reveals additional components in G-protein G q signaling</article-title>. <source>Proc. Natl. Acad. Sci.</source> <volume>110</volume>, <fpage>11940</fpage>&#x2013;<lpage>11945</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="sc22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Gomez-Marin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Stephens</surname>, <given-names>G. J.</given-names></string-name> &#x0026; <string-name><surname>Brown</surname>, <given-names>A. E.</given-names></string-name> <article-title>Hierarchical compression of Caenorhabditis elegans locomotion reveals phenotypic differences in the organization of behaviour</article-title>. <source>J. R. Soc. Interface</source> <volume>13</volume>, <fpage>20160466</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="sc23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>P&#x00E9;rez-Escudero</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Vicente-Page</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hinz</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Arganda</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>de Polavieja</surname>, <given-names>G. G.</given-names></string-name> <article-title>idTracker: tracking individuals in a group by automatic identification of unmarked animals</article-title>. <source>Nat. Methods</source> <volume>11</volume>, <fpage>743</fpage>&#x2013;<lpage>748</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="sc24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zuo</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Meng</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Zhang</surname>, <given-names>L.</given-names></string-name> <article-title>Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</article-title>. <source>IEEE Trans. Image Process.</source> <volume>26</volume>, <fpage>3142</fpage>&#x2013;<lpage>3155</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="sc25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Long</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>S. K.</given-names></string-name> &#x0026; <string-name><surname>Myers</surname>, <given-names>E.</given-names></string-name> <article-title>A 3D digital atlas of C. elegans and its application to single-cell analyses</article-title>. <source>Nat. Methods</source> <volume>6</volume>, <fpage>667</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="sc26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Cook</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Zdraljevic</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>J. P.</given-names></string-name> &#x0026; <string-name><surname>Andersen</surname>, <given-names>E. C.</given-names></string-name> <article-title>CeNDR, the Caenorhabditis elegans natural diversity resource</article-title>. <source>Nucleic Acids Res.</source> <volume>45</volume>, <fpage>D650</fpage>&#x2013;<lpage>D657</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="sc27"><label>27.</label><mixed-citation publication-type="other"><string-name><surname>Schulze</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>Dynamical feature extraction at the sensory periphery guides chemotaxis</article-title>. <source>Elife</source> <fpage>4</fpage>, (<year>2015</year>).</mixed-citation></ref>
<ref id="sc28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Gomez-Marin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Partoune</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Stephens</surname>, <given-names>G. J.</given-names></string-name> &#x0026; <string-name><surname>Louis</surname>, <given-names>M.</given-names></string-name> <article-title>Automated tracking of animal posture and movement during exploration and sensory orientation behaviors</article-title>. <source>PloS One</source> <volume>7</volume>, <fpage>e41642</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="sc29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Chagas</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Prieto-Godino</surname>, <given-names>L. L.</given-names></string-name>, <string-name><surname>Arrenberg</surname>, <given-names>A. B.</given-names></string-name> &#x0026; <string-name><surname>Baden</surname>, <given-names>T.</given-names></string-name> <article-title>The &#x20AC;100 lab: A 3D-printable open-source platform for fluorescence microscopy, optogenetics, and accurate temperature control during behaviour of zebrafish, Drosophila, and Caenorhabditis elegans</article-title>. <source>PLoS Biol.</source> <volume>15</volume>, <fpage>e2002702</fpage> (<year>2017</year>).</mixed-citation></ref>
</ref-list>
</back>
</article>