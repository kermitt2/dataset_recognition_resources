<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pixel-Level Deep Segmentation: Artificial Intelligence Quantifies Muscle on Computed Tomography for Body Morphometric Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-06-26">26 June 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hyunkwang</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<addrLine>25 New Chardon Street, Suite 400B</addrLine>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Troschel</surname></persName>
							<email>ftroschel@mgh.harvard.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<addrLine>25 New Chardon Street, Suite 400B</addrLine>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shahein</forename><surname>Tajmir</surname></persName>
							<email>stajmir@mgh.harvard.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<addrLine>25 New Chardon Street, Suite 400B</addrLine>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georg</forename><surname>Fuchs</surname></persName>
							<email>georg.fuchs@charite.de</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Charite -Universitaetsmedizin Berlin</orgName>
								<address>
									<addrLine>Chariteplatz 1</addrLine>
									<postCode>10117</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julia</forename><surname>Mario</surname></persName>
							<email>julia_mario@hms.harvard.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<addrLine>25 New Chardon Street, Suite 400B</addrLine>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><forename type="middle">J</forename><surname>Fintelmann</surname></persName>
							<email>fintelmann@mgh.harvard.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<addrLine>25 New Chardon Street, Suite 400B</addrLine>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Synho</forename><surname>Do</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<addrLine>25 New Chardon Street, Suite 400B</addrLine>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pixel-Level Deep Segmentation: Artificial Intelligence Quantifies Muscle on Computed Tomography for Body Morphometric Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-06-26">26 June 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">45963B6689D93B6C0AB644199182B09B</idno>
					<idno type="DOI">10.1007/s10278-017-9988-z</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2-SNAPSHOT" ident="GROBID" when="2022-05-18T11:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Muscle segmentation</term>
					<term>Convolutional neural networks</term>
					<term>Computer-aided diagnosis (CAD)</term>
					<term>Computed tomography</term>
					<term>Artificial intelligence</term>
					<term>Deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>Pretreatment risk stratification is key for personalized medicine.</s><s>While many physicians rely on an Beyeball testt o assess whether patients will tolerate major surgery or chemotherapy, Beyeballing^is inherently subjective and difficult to quantify.</s><s>The concept of morphometric age derived from cross-sectional imaging has been found to correlate well with outcomes such as length of stay, morbidity, and mortality.</s><s>However, the determination of the morphometric age is time intensive and requires highly trained experts.</s><s>In this study, we propose a fully automated deep learning system for the segmentation of skeletal muscle cross-sectional area (CSA) on an axial computed tomography image taken at the third lumbar vertebra.</s><s>We utilized a fully automated deep segmentation model derived from an extended implementation of a fully convolutional network with weight initialization of an ImageNet pre-trained model, followed by post processing to eliminate intramuscular fat for a more accurate analysis.</s><s>This experiment was conducted by varying window level (WL), window width (WW), and bit resolutions in order to better understand the effects of the parameters on the model performance.</s><s>Our best model, fine-tuned on 250 training images and ground truth labels, achieves 0.93 ± 0.02 Dice similarity coefficient (DSC) and 3.68 ± 2.29% difference between predicted and ground truth muscle CSA on 150 held-out test cases.</s><s>Ultimately, the fully automated segmentation system can be embedded into the clinical environment to accelerate the quantification of muscle and expanded to volume analysis of 3D datasets.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p><s>Image segmentation, also known as pixel-level classification, is the process of partitioning all pixels in an image into a finite number of semantically non-overlapping segments.</s><s>In medical imaging, image segmentation has been considered a fundamental process for various medical applications including disease diagnosis, prognosis, and treatments.</s><s>In particular, muscle segmentation on computed tomography (CT) for body composition analysis has emerged as a clinically useful risk stratification tool in oncology <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>, radiation oncology <ref type="bibr" target="#b3">[4]</ref>, intensive care <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, and surgery <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>.</s><s>Cadaver studies have established muscle cross-sectional area (CSA) at the level of the third lumbar (L3) vertebral body as a surrogate marker for lean body muscle mass <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>.</s><s>These studies applied semi-automated threshold-based segmentation with pre-defined Hounsfield unit (HU) ranges to separate lean muscle mass from fat.</s><s>However, segmentation errors require manual correction based on visual analysis by highly skilled radiologists <ref type="bibr" target="#b12">[13]</ref>.</s><s>As a result, semiautomated body composition analysis on large datasets is impractical due to the expense and time required.</s><s>Thus, there is a role for automated tissue segmentation in order to bring body composition analysis into clinical practice.</s></p><p><s>Adipose tissue segmentation on CT images is a relatively straightforward process as fat can be thresholded with a consistent HU range [−190 to −30] <ref type="bibr" target="#b13">[14]</ref>.</s><s>Muscle segmentation is less straightforward as muscle and neighboring organs have overlapping HU values [−29 to 150].</s><s>Few published strategies exist for automated muscle segmentation with various approaches.</s><s>A series of publications by Kamiya et al. <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref> focused on segmentation of a single muscle (psoas major) at L3. <ref type="bibr">Popuri et al.</ref> have studied the segmentation of all skeletal muscles visible at the L3 <ref type="bibr" target="#b17">[18]</ref> and T4 levels <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>.</s><s>Their approach involves a deformable shape model based on the ideal muscle appearance with fitting based on a statistical deformation model (SDM).</s><s>Another study <ref type="bibr" target="#b20">[21]</ref> attempted to segment a 3D body CT dataset with seven segmentation classes including fat and muscle by classifying each class using random forest classifiers when given 16 image features extracted from statistical information and filter responses.</s><s>All these attempts require sophisticated hand-crafted features to define knowledge-based parameters and select constraints for well-formed statistical shape and appearance models.</s><s>As a result, these approaches cannot be generalized.</s></p><p><s>Deep learning has demonstrated enormous success in improving diagnostic accuracy, speed of image interpretation, and clinical efficiency for a wide range of medical tasks, ranging from the interstitial pattern detection on chest CT <ref type="bibr" target="#b21">[22]</ref> to bone age classification on hand radiographs <ref type="bibr" target="#b22">[23]</ref>.</s><s>Particularly, a data-driven approach with deep neural networks has been actively utilized for several medical image segmentation applications, ranging from segmenting brain tumors on magnetic resonance images <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>, organs of interest on CT <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>, to segmenting the vascular network of the human eye on fundus photography <ref type="bibr" target="#b28">[29]</ref>.</s><s>This success is attributed to its capability to learn representative and hierarchical image features from data <ref type="bibr" target="#b29">[30]</ref>, rather than relying on manually engineered features based on knowledge from domain experts.</s></p><p><s>In this study, we propose a fully automated deep segmentation system for the segmentation of muscles on an axial CT slice taken at L3 using the improved fully convolutional network (FCN) <ref type="bibr" target="#b30">[31]</ref> and post processing.</s><s>This system enables realtime segmentation of muscle and possibly fat tissue, facilitating clinical application of body morphological analysis sets.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Acquisition and Characteristics</head><p><s>IRB approval was obtained for this retrospective study.</s><s>Four hundred patients with an abdominal CT and lung cancer treated with either surgery or systemic therapy between 2007 and 2015 were identified in an institutional database.</s><s>The surgical cohort (tumor stages I, II, and III) represented a cross section of all patients who underwent lung cancer resection at our institution, while the medical cohort were patients who received chemotherapy (tumor stage IV).</s><s>Only examinations with intravenous contrast were included to ensure consistency of HU values.</s><s>Four hundred examinations of 200 females and 200 male patients were included in the study, as detailed in Table <ref type="table" target="#tab_0">1</ref>.</s><s>A test subset of 150 cases was created for evaluating the algorithm performance by taking 25 cases from each BMI category per gender, as explained in BData Categorization.Î mages were acquired for routine clinical care as detailed in Table <ref type="table" target="#tab_1">2</ref>. Scanners were calibrated daily using manufacturersupplied phantoms to ensure consistency in attenuation</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Preparation</head><p><s>We reformatted the manually tuned muscle segmentation maps created by domain experts as described previously into acceptable input for convolutional neural networks (CNN).</s><s>As shown in Fig. <ref type="figure">1</ref>, the axial images and their corresponding color-coded images served as original input data and ground truth labels, respectively.</s><s>The main challenge for muscle segmentation is the accurate differentiation of muscle tissue from neighboring organs due to their overlapping HU ranges.</s><s>We manually drew a boundary between organs and muscle, setting the inside region as additional segmentation class (BInside^) in an effort to train the neural network to learn distinguishing features of muscle for a precise segmentation from adjacent organs.</s><s>The color-coded label images were assigned to pre-defined label indices, including 0 (black) for BBackground^, 1 (red) for BMuscle^, and 2 (green) for BInside^, before passing through CNNs for training as presented in Fig. <ref type="figure">1</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Categorization</head><p><s>We hypothesized that differences in body habitus could represent a confounding feature if the network was to be presented unbalanced examples, particularly because prior work has demonstrated that obese patients have higher image noise <ref type="bibr" target="#b31">[32]</ref>.</s><s>To minimize this possibility, the patients were categorized into eight groups based on gender and body mass index (BMI) (Fig. <ref type="figure">2</ref>).</s><s>We randomly selected 25 male and 25 female patients from the groups with normal weight, overweight, and obese in order to create a subset of 150 cases to be withheld for testing.</s><s>All underweight cases were included in the training dataset without being used for testing due to their small number.</s><s>The other 250 cases were used for training.</s><s>We chose the best model out of several trained models by selecting the last model after the loss became converged for a sufficiently long period of training time, approximately 500 epochs.</s><s>The best CNN was evaluated using the held-out test datasets to determine how much the predicted muscle regions overlap with the ground truth.</s><s>In order to make a fair comparison, we used the same seed value for the random selection from the test dataset for each experiment.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Architecture</head><p><s>Our proposed fully automated deep segmentation system for muscle segmentation includes grayscale image conversion using the best combination of window settings and bit depth per pixel with post processing to correct erroneous segmentation (Fig. <ref type="figure" target="#fig_2">3</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation AI: Fully Convolutional Network</head><p><s>Several state-of-the-art deep learning algorithms have been validated for natural image segmentation applications <ref type="bibr" target="#b30">[31]</ref>.</s><s>We chose to develop our muscle segmentation model based on a fully convolutional network (FCN) for three reasons: First, a set of convolutional structures enables learning highly representative and hierarchical abstractions from whole-image input without excessive use of trainable parameters thanks to the usage of shared weights.</s><s>Second, fine-tuning the trainable parameters of the FCN after weights that are initialized with a pre-trained model from a large-scale dataset allows the network to find the global optimum with a fast convergence of cost function when given a small training dataset.</s><s>Third, the FCN intentionally fuses different levels of layers by combining coarse semantic information and fine appearance information to maximize hierarchical features learned from earlier and later layers.</s><s>As shown in Fig. <ref type="figure" target="#fig_1">4</ref>, FCN-32s, FCN-16s, and FCN-8s fuse coarse-grained and fine-grained features and upsample them at strides 32, 16, and 8, for further precision.</s></p><p><s>Prior implementations of FCN describe further fusion of earlier layers beyond pool3; however, this was not pursued in their implementation due to only minor performance gains <ref type="bibr" target="#b30">[31]</ref>.</s><s>However, we decided to extend to FCN-4s and FCN-2s (highlighted in red in Fig. <ref type="figure" target="#fig_1">4</ref>) by fusing earlier layers further because muscle segmentation requires finer precision than stride 8.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image Conversion: HU to Grayscale</head><p><s>Medical images contain 12 to 16 bits per pixel, ranging from 4096 to 65,536 shades of gray per pixel.</s><s>A digital CT image has a dynamic range of 4096 gray levels per pixel (12 bits per pixel), far beyond the limits of human perception.</s><s>The human observer can distinguish many hundred shades of gray, and possibly as high as 700-900, but substantially less than the 4096 gray levels in a digital CT image <ref type="bibr" target="#b32">[33]</ref>.</s><s>Displays used for diagnostic CT interpretation support at most 8 bits per pixel, corresponding to 256 gray levels per pixel.</s><s>To compensate for these inherent physiologic and technical limitations, images displayed on computer monitors can be adjusted by changing the window level (WL) and window width (WW), followed by assigning values outside the window range to minimum (0) or maximum (2 BIT -1) value, as described in Fig. <ref type="figure" target="#fig_3">5a</ref>.</s><s>The Most prior investigations have converted CT images to grayscale with the commonly used HU range for the target tissue or organ without studying the effect of window settings on the performance of their algorithms.</s><s>While recent work has identified that image quality distortions limit the performance of neural networks <ref type="bibr" target="#b33">[34]</ref> in computer vision systems, the effect of window setting and bit resolution on image quality is often overlooked in medical imaging machine learning.</s><s>Therefore, we evaluated the effects of window and BIT settings on</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison Measures</head><p><s>The primary comparison measure utilizes the Dice similarity coefficient (DSC) to compare the degree of overlap between the ground truth segmentation mask and the FCN-derived mask, calculated as Eq. 1.</s></p><formula xml:id="formula_0">DSC ¼ 2 Â ground truth∩predict j j groiund truth j j þ predict j j<label>ð1Þ</label></formula><p><s>An additional comparison measure was the cross-sectional area (CSA) error, calculated as Eq. 2. This represents a standardized measure of the percentage difference in area between the ground truth segmentation mask and the FCN-derived mask.</s></p><formula xml:id="formula_1">CSA error % ð Þ ¼ ground truth−predict j j ground truth Â 100<label>ð2Þ</label></formula><p><s>Intramuscular Fat Post Processing Muscle tissue HUs do not overlap with adipose tissue HUs.</s><s>As a result, a binary image of fat regions extracted using HU thresholding can be utilized to remove intramuscular fat incorrectly segmented as muscle.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validation and Quality Control</head><p><s>Subsequent to post processing, the results of the test subset were visually analyzed by a research assistant together with a fellowship-trained board-certified radiologist (initials [FJF],</s></p><p><s>8 years of experience).</s><s>Common errors were identified and occurrence was noted for each image.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training</head><p><s>We trained the models by a stochastic gradient descent (SGD) with a momentum of 0.9 and with a minibatch size of 8 to achieve full GPU utilization.</s><s>As performed in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35]</ref>, we utilized a fixed, tiny learning rate and weight decay because training is highly sensitive to hyperparameters when unnormalized softmax loss is used.</s><s>We empirically found that a learning rate of 10 −10 and a weight decay of 10 −12 were optimal for our application to obtain stable training convergence at the cost of convergence speed.</s><s>Since training losses eventually converged if the models were trained for sufficient period of epochs, all models in this paper were trained for 500 epochs and the last model was selected without a validation phase to evaluate performance on our held-out test subset.</s><s>All experiments were run on a Devbox (NVIDIA Corp, Santa Clara, CA) containing four TITAN X GPUs with 12GB of memory per GPU <ref type="bibr" target="#b35">[36]</ref> and using Nvidia-Caffe (version 0.15.14) and Nvidia DIGITS (version 5.1).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analysis</head><p><s>Descriptive data were presented as percentages for categorical variables and as means with standard deviation (SD) for continuous variables.</s><s>We used two-tailed statistical tests with the alpha level set at 0.05.</s><s>We performed Student's t test for normally distributed values.</s><s>Dichotomous variables were compared using the Mann Whitney U test and ordinal variables were compared using the Kruskal Wallis test.</s><s>Inter-analyst agreement was quantified with intraclass correlation coefficients (ICC).</s><s>All statistical analyses were performed using</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fully Convolutional Network</head><p><s>To identify the best performing fully convolutional network, five models of increasing granularity-FCN-32s, FCN-16s, FCN-8s, FCN-4s, and FCN-2s-were trained and evaluated using the test dataset at 40,400 and 8 bits per pixel by measuring the DSC and CSA error between ground truth and predicted muscle segmentation.</s><s>These results were compared to the HU thresholding method, selecting HU ranging from −29 to 150 to represent lean muscle CSA.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FCN Segmentation Performance</head><p><s>The five different FCN models were compared to the previously described HU thresholding method.</s><s>Performance was evaluated using the DSC and muscle CSA error and detailed in Fig. <ref type="figure" target="#fig_5">6</ref>.</s><s>Even the most coarse-grained FCN model (FCN-32s) achieved 0.79 ± 0.06 of DSC and 18.27 ± 9.77% of CSA error, markedly better than the HU thresholding method without human tuning.</s><s>Performance increased as the number of features of different layers was fused.</s><s>The most fine-grained FCN model achieved DSC of 0.93 and CSA error of 3.68% on average, representing a 59% improvement in DSC and an 80% decrease in CSA error when compared to the most coarse-grained model.</s><s>The representative examples are detailed in Fig. <ref type="figure" target="#fig_6">7</ref> to visually show the performance of FCN-2s segmentation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Window and Bit Settings on Segmentation Performance</head><p><s>Results of the systematic experiment comparing seven different combinations of window settings for each bit depth per pixel are presented in Fig. <ref type="figure">8</ref>.</s><s>The DSC and CSA error were not meaningfully influenced by changes in window ranges as long as 256 gray levels per pixel (bit8) were available.</s><s>When 6-bit depth per pixel was used, performance was similar compared to the results of 8-bit cases.</s><s>However, model performance deteriorated when 8-bit pixels were compressed to 4-bit pixels.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deployment Time</head><p><s>Segmentation was performed using a single TITAN X GPU.</s><s>took 25 s on average for 150 test images, corresponding to only 0.17 s per image.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analysis of Model Segmentation Errors</head><p><s>In the majority of cases (n = 128), FCN CSA was smaller than ground truth CSA, while only few cases resulted in oversegmentation (n = 22; p &lt; 0.0001).</s><s>Review of incorrectly</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Obesity</head><p><s>To evaluate the influence of obesity on the performance of the segmentation algorithm, segmentation results of patients with BMI &gt;30 kg/m 2 were compared to those of patients with BMI &lt;30 kg/m 2 .</s><s>The average DSC was 0.93 in non-obese patients, but only 0.92 in obese patients, a statistically significant difference (p = 0.0008).</s><s>The incorrect inclusion of subcutaneous soft tissue edema into muscle CSA was more common in obese patients than in non-obese patients (p = 0.018).</s><s>However, inclusion of adjacent organs into muscle CSA (p = 0.553) and incomplete muscle segmentation (p = 0.115) were not significantly associated with obesity.</s><s>There was no statistically significant association between obesity and CSA error (p = 0.16).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Oral Contrast</head><p><s>Forty-eight percent of the cohort received oral contrast in addition to intravenous contrast.</s><s>The ratio was the same in the training and testing datasets.</s><s>There was no statistically significant association between the presence or absence of oral contrast and segmentation performance measured as DSC (p = 0.192) or CSA error (p = 0.484), probably because the network became invariant to its presence in the balanced cohorts.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p><s>We have developed an automated system for performing muscle segmentation at the L3 vertebral body level using a fully convolutional network with post processing at a markedly faster deployment time when compared to conventional semi-automated methods.</s></p><p><s>Our model was derived from a highly granular fully convolutional network and compared to the semi-automated HU thresholding method which requires tedious and time- consuming tuning of erroneous segmentation by highly trained human experts.</s><s>When compared to the HU thresholding method without human tuning, even coarsest FCN had markedly better performance.</s><s>It is not surprising as HU thresholding is so inaccurate, as it includes overlapping HU ranges between organs and muscle.</s><s>However, by combining hierarchical features and different layers of increasing granularity, our model was able to extract semantic information, overall muscle shape, fine-grained appearance, and muscle textural appearance.</s><s>These results persisted even when varying the WL and WW into ranges unsuitable for the human eye.</s><s>Changes in WW had greater effects on segmentation performance than WL, particularly when the number of gray shades was small (bit6 and bit4).</s><s>These results imply that this network's performance depends mostly on image contrast and possibly due to the number of HU values assigned to a single gray level, rather than inherent image brightness.</s><s>It also implies that preserving image information using the original 12bit resolution with 4096 shades of gray could provide considerable performance gains by allowing the network to learn other significant identifying features of muscle which are lost in the conversion to 8 bits.</s><s>These results are consistent with other published findings that CNNs are excellent at textural analysis <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deployment Time</head><p><s>Accurate segmentation of muscle tissue by the semiautomated HU thresholding method requires roughly 20-30 min per slice on average <ref type="bibr" target="#b17">[18]</ref>.</s><s>Algorithms proposed in most prior works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref> required between 1 and 3 min per slice.</s><s>More recent works have reported that their algorithms require only 3.4 s <ref type="bibr" target="#b20">[21]</ref> and 0.6 s per image on average.</s><s>To the best of our knowledge, our model is the fastest reported segmentation algorithm for muscle segmentation and needs only 0.17 s per slice on average.</s><s>Segmenting 150 test images can be performed in 25 s.</s><s>This ultra-fast deployment can allow realtime segmentation in clinical practice.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clinical Applications</head><p><s>Muscle CSA at L3 has been shown to correlate with a wide range of posttreatment outcomes.</s><s>However, integration of muscle CSA measurements in clinical practice has been limited by the time required to generate this data.</s><s>By dropping the calculation time from 1800 to 0.17 s, we can drastically speed up research into new applications for morphometric analysis.</s><s>CT is an essential tool in the modern healthcare arena with approximately 82 million CT examinations performed in the USA in 2016 <ref type="bibr">[39]</ref>.</s><s>In lung cancer in particular, the current clinical paradigm has been on lesion detection and disease staging with an eye toward treatment selection.</s><s>However, accumulating evidence suggests that CT body composition data could provide objective biological markers to help lay the foundation for the future of personalized medicine.</s><s>Aside from preoperative risk stratification for surgeons, recent work has used morphometric data to predict death in radiation oncology and medical oncology <ref type="bibr" target="#b3">[4]</ref>.</s><s>Our system has the great advantage of not requiring a special protocol (other than intravenous contrast) and could derive muscle CSA from routine CT examinations near-instantaneously.</s><s>This would enable body composition analysis of the vast majority of CT examinations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p><s>While the system has great potential for accelerating calculation of muscle CSA, there are important limitations.</s><s>The network statistically tends to underestimate muscle CSA.</s><s>This is probably due to a combination of overlapping HUs between muscle and adjacent organs and variable organ textural appearance.</s><s>On the other end of the spectrum, segmentation is also confused by the radiographic appearance of edema particularly in obese patients, which has a similar HU range to muscle, leading to higher CSA than expected.</s><s>Extensive edema tends to occur in critically ill patients, leading to potentially falsely elevated CSA in patients actually at higher risk for all interventions.</s></p><p><s>The average age of our cohort is 63 years.</s><s>While this is representative of the lung cancer population, it may limit the generalizability of our system for patients with different diseases and age groups.</s><s>Further training with data from a wider group of patients could enable the algorithms to account for these differences.</s><s>In addition, the network should be trained to segment CT examinations performed without intravenous contrast and ultra-low radiation dose.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p><s>The muscle segmentation AI can be enhanced further by using the original 12-bit image resolution with 4096 gray levels which could enable the network to learn other significant determinants which could be missed in the lower resolution.</s><s>In addition, an exciting target would be adipose tissue segmentation.</s><s>Adipose tissue segmentation is relatively straightforward since fat can be thresholded within a unique HU range <ref type="bibr">[−190 to −30]</ref>.</s><s>Prior studies proposed creating an outer muscle boundary to segment HU thresholded adipose tissue into visceral adipose tissue (VAT) and subcutaneous adipose tissue (SAT).</s><s>However, precise boundary generation is dependent on accurate muscle segmentation.</s><s>By combining our muscle segmentation network with a subsequent adipose tissue thresholding system, we could quickly and accurately provide VAT and SAT values in addition to muscle CSA.</s><s>Visceral adipose tissue has been implicated in cardiovascular outcomes and metabolic syndrome, and accurate fat segmentation would increase the utility of our system beyond cancer prognostication <ref type="bibr" target="#b40">[40]</ref>.</s><s>Ultimately, our system should be extended to wholebody volumetric analysis rather than axial CSA, providing rapid accurate characterization of body morphometric parameters.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p><s>We have created an automated, deep learning system to automatically detect and segment the muscle CSA of CT slices at the L3 vertebral body level.</s><s>This system achieves excellent overlap with hand-segmented images with an average of less than 3.68% error while rapidly accelerating segmentation time from 30 min to 0.17 s.</s><s>The fully automated segmentation system can be embedded into the clinical environment to accelerate the quantification of muscle to provide advanced morphometric data on existing CT volumes and possible expanded to volume analysis of 3D datasets.</s></p><p><s>Open Access This article is distributed under the terms of the Creative Comm ons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/),</s><s>which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 Fig. 1</head><label>21</label><figDesc><div><p><s>Fig.2Patients stratification based on gender and body mass index (BMI).</s><s>For each gender, 25 cases were randomly selected from normal, overweight, and obese weight categories for the testing cohort.</s><s>Underweight cases were excluded.</s><s>One hundred fifty total cases were withheld for algorithm testing.</s><s>The remaining cases were used to train the segmentation convolutional neural network</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4</head><label>4</label><figDesc><div><p><s>Fig.4Overview of the proposed fully convolutional network (FCN).</s><s>FCN-32s, FCN-16s, and FCN-8s appeared in the original FCN implementation<ref type="bibr" target="#b30">[31]</ref>.</s><s>The red-rimmed FCN-4s and FCN-2s are our extended version of FCN required for more detailed and precise muscle segmentation</s></p></div></figDesc><graphic coords="5,84.70,432.45,425.95,259.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc><div><p><s>Fig. 3 Overview of proposed fully automated deep segmentation system for muscle tissue segmentation.</s><s>HU Hounsfield units</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc><div><p><s>Fig. 5 (a) The relationship between gray level and Hounsfield units (HU) determined by window level (WL), window width (WW), and bit depth per pixel (BIT).</s><s>(b) The effect of different WL, WW, and BIT configurations on the same image</s></p></div></figDesc><graphic coords="6,84.70,53.86,425.95,196.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Image</head><label></label><figDesc><div><p><s>Conversion: HU to Grayscale Subsequently, we compared the performance of the best FCN model (FCN-2s) with seven different combinations of window settings for each bit depth per pixel-(40,400), (40, 240), (40,800), (40,1200), (−40,400), (100,400), and (160,400) expressed in WL and WW and 8, 6, and 4 bit resolutions per pixel.</s><s>The selected window ranges cover the HU range of lean tissue [−29 to 150] for a fair comparison to see if partial image information loss degrades model performance.</s><s>These window settings contain extreme window ranges as well as typical ones.</s><s>For example, the window setting (40,240) has a range of −80 to 160 HU values, which corresponds to almost the HU range of lean muscle, while the configuration (40,1200) converts all HU values between −560 and 1240 into shades of gray resulting in low image contrast.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6</head><label>6</label><figDesc><div><p><s>Fig. 6 Comparison of the HU thresholding method and five different FCNs.</s><s>(a) Dice similarity coefficient (DSC) and (b) cross-sectional area (CSA) error between ground truth manual and predicted muscle segmentation areas.</s><s>All numbers are reported as mean ± SD</s></p></div></figDesc><graphic coords="7,51.08,472.48,493.13,219.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7</head><label>7</label><figDesc><div><p><s>Fig. 7 Six examples of the better segmented CT images for six groups according to gender and BMI.</s><s>Dice similarity coefficient (DSC) is marked on each segmented image above.</s><s>Oversampled regions are</s></p></div></figDesc><graphic coords="8,84.70,53.86,425.95,288.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9</head><label>9</label><figDesc><div><p><s>Fig. 9 Segmentation errors most commonly presented as muscle partly excluded (a), organs partly included (b), and edema mischaracterized as muscle (c).</s><s>Oversampled regions are colored in blue, undersampled areas are colored in yellow, and correctly segmented areas are colored in red</s></p></div></figDesc><graphic coords="9,178.02,342.82,366.41,371.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc><div><p><s>Patient characteristics of the entire cohort (n = 400) and the test subset (n = 150)</s></p></div></figDesc><table><row><cell>Patient characteristics</cell><cell>n = 400 (entire</cell><cell>n = 150 (test</cell><cell>p values</cell></row><row><cell></cell><cell>cohort)</cell><cell>subset)</cell><cell></cell></row><row><cell cols="2">Age, mean (SD) (years) 63 (12)</cell><cell>62 (11)</cell><cell>0.31</cell></row><row><cell>Gender, no. (%)</cell><cell></cell><cell></cell><cell>1</cell></row><row><cell>Female</cell><cell>200 (50)</cell><cell>75 (50)</cell><cell></cell></row><row><cell>Male</cell><cell>200 (50)</cell><cell>75 (50)</cell><cell></cell></row><row><cell cols="2">Height, mean (SD) (cm) 168 (10)</cell><cell>168 (10)</cell><cell>0.70</cell></row><row><cell cols="2">Weight, mean (SD) (kg) 77 (18)</cell><cell>79 (19)</cell><cell>0.16</cell></row><row><cell>Lung cancer treatment,</cell><cell></cell><cell></cell><cell>0.78</cell></row><row><cell>no. (%)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Systemic therapy</cell><cell>227 (57)</cell><cell>86 (57)</cell><cell></cell></row><row><cell>Surgery</cell><cell>173 (43)</cell><cell>64 (43)</cell><cell></cell></row><row><cell>Lung cancer stage, no.</cell><cell></cell><cell></cell><cell>0.84</cell></row><row><cell>(%)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>I</cell><cell>102 (26)</cell><cell>38 (25)</cell><cell></cell></row><row><cell>II</cell><cell>33 (8)</cell><cell>10 (7)</cell><cell></cell></row><row><cell>III</cell><cell>38 (10)</cell><cell>16 (11)</cell><cell></cell></row><row><cell>IV</cell><cell>227 (57)</cell><cell>86 (57)</cell><cell></cell></row><row><cell cols="4">Note that there is no statistically significant difference between the entire</cell></row><row><cell>cohort and the test subset</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc><div><p><s>Image acquisition parameters</s></p></div></figDesc><table><row><cell>Imaging system</cell><cell cols="2">n = 400 (entire cohort) n = 150 (test subset)</cell></row><row><cell cols="2">Tube current, mA (SD) 360.78 (124.10)</cell><cell>363.41 (126.85)</cell></row><row><cell>kV, (SD)</cell><cell>120.85 (5.68)</cell><cell>120.67 (5.85)</cell></row><row><cell>Oral contrast, no. (%)</cell><cell>191 (48)</cell><cell>70 (47)</cell></row><row><cell>Manufacturer, no. (%)</cell><cell></cell><cell></cell></row><row><cell>Siemens</cell><cell>141 (35)</cell><cell>92 (35)</cell></row><row><cell>GE</cell><cell>241 (60)</cell><cell>52 (61)</cell></row><row><cell>Philips</cell><cell>17 (4)</cell><cell>6 (4)</cell></row><row><cell>Toshiba</cell><cell>1 (0)</cell><cell>0 (0)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">J Digit Imaging (2017) 30:487-498</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Prevalence and clinical implications of sarcopenic obesity in patients with solid tumours of the respiratory and gastrointestinal tracts: a population-based study</title>
		<author>
			<persName><forename type="first">Cmm</forename><surname>Prado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lieffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Mccargar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Sawyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Oncol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="629" to="635" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cancer cachexia in the age of obesity: skeletal muscle depletion is a powerful prognostic factor, independent of body mass index</title>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Birdsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Clandinin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Mccargar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Clin Oncol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1539" to="1547" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Loss of muscle mass during chemotherapy is predictive for poor survival of patients with metastatic colorectal cancer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Blauwhoff-Buskermolen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mae</forename><surname>De Van Der Schueren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Braver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berkhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jae</forename><surname>Langius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Clin Oncol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1339" to="1344" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CT measures of bone mineral density and muscle mass can be used to predict noncancer death in men with prostate cancer</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cardan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">282</biblScope>
			<biblScope unit="page" from="475" to="483" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Skeletal muscle predicts ventilator-free days, ICU-free days, and mortality in elderly ICU patients</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Moisey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mourtzakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Premji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Heyland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Crit Care</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">R206</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Low skeletal muscle area is a risk factor for mortality in mechanically ventilated critically ill patients</title>
		<author>
			<persName><forename type="first">Pjm</forename><surname>Weijs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wgpm</forename><surname>Looijaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Dekker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Stapel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Girbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Oudemans-Van Straaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Crit Care</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sarcopenia and mortality after liver transplantation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Englesbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Schaubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Am Coll Surg</title>
		<imprint>
			<biblScope unit="volume">211</biblScope>
			<biblScope unit="page" from="271" to="278" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Functional compromise reflected by sarcopenia, frailty, and nutritional depletion predicts adverse postoperative outcome after colorectal cancer surgery</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jla</forename><surname>Van Vugt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jjw</forename><surname>Tegels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Snijders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwe</forename><surname>Hulsewé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agm</forename><surname>Hoofwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Surg</title>
		<imprint>
			<biblScope unit="volume">261</biblScope>
			<biblScope unit="page" from="345" to="352" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pre-operative assessment of muscle mass to predict surgical complications and prognosis in patients with endometrial cancer</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Kuroki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mangano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Allsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Menias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Massad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Surg Oncol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="972" to="979" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effect of sarcopenia and visceral obesity on mortality and pancreatic fistula following pancreatic cancer surgery</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pecorelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carrara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Cobelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cristel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Damascelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br J Surg</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="434" to="442" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cadaver validation of skeletal muscle measurement by magnetic resonance imaging and computerized tomography</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mitsiopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Heymsfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Appl Physiol</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="115" to="122" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Total body skeletal muscle and adipose tissue volumes: estimation from a single abdominal cross-sectional image</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Punyanitya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-P</forename><surname>St-Onge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Albu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Appl Physiol</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2333" to="2338" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sarcopenia: current concepts and imaging implications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Boutin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Canter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lenchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJR Am J Roentgenol</title>
		<imprint>
			<biblScope unit="volume">205</biblScope>
			<biblScope unit="page" from="W255" to="W266" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated quantification of body fat distribution on volumetric computed tomography</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Colville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kalaigian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kijewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Assist Tomogr</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="777" to="783" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automated recognition of the psoas major muscles on X-ray CT images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yokoyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Engineering in Medicine and Biology Society</title>
		<imprint>
			<biblScope unit="page" from="3557" to="3560" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automated segmentation of psoas major muscle in X-ray CT images by use of a shape model: preliminary study</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yokoyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiol Phys Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="5" to="14" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automated segmentation of recuts abdominis muscle using shape model in X-ray CT images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yokoyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Engineering in Medicine and Biology Society</title>
		<imprint>
			<biblScope unit="page" from="7993" to="7996" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Automated segmentation of muscle and adipose tissue on CT images for human body composition analysis. SPIE Medical Imaging. International Society for Optics and Photonics 72610K-72610K-8</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cobzas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Birdsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lieffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Baracos</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.812412</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">FEMbased automatic segmentation of muscle and fat tissues from thoracic CT images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Popuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cobzas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jägersand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Esfandiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Baracos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Symposium on Biomedical Imaging</title>
				<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="149" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Body composition assessment in axial CT images using FEM-based automatic segmentation of skeletal muscle</title>
		<author>
			<persName><forename type="first">K</forename><surname>Popuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cobzas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Esfandiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Baracos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jägersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="512" to="520" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Tissue segmentation of computed tomography images using a random Forest algorithm: a feasibility study</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Polan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys Med Biol</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="6553" to="6569" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lung pattern classification for interstitial lung diseases using a deep convolutional neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Anthimopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christodoulidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Christe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mougiakakou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2016.2535865</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1207" to="1216" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fully automated deep learning system for bone age assessment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tajmir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Yeshiwas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Alkasab</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10278-017-9955-8</idno>
	</analytic>
	<monogr>
		<title level="j">J Digit Imaging</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Brain tumor segmentation using convolutional neural networks in MRI images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Silva</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2016.2538465</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1240" to="1251" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Brain tumor segmentation with deep neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Anal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="18" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic segmentation of MR brain images with a convolutional neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moeskops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mendrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mjnl</forename><surname>Benders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Isgum</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2016.2548501</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1252" to="1261" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Accurate segmentation of CT male pelvic organs via regression-based deformable models and multi-task random forests</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Segmenting retinal blood vessels with deep neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liskowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pawel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Krzysztof</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2016.2546227</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2369" to="2380" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Guest editorial deep learning in medical imaging: overview and future promise of an exciting new technique</title>
		<author>
			<persName><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1153" to="1159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image quality in obese patients undergoing 256-row computed tomography coronary angiography</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Segev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gaspar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Halon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Peled</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Domachevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Card Imaging</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="633" to="639" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Increasing the number of gray shades in medical display systems-how much is enough?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kimpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytschaever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Digit Imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="422" to="432" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Understanding how image quality affects deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Karam</surname></persName>
		</author>
		<idno type="DOI">10.1109/QoMEX.2016.7498955</idno>
		<idno>doi:10.1109/ QoMEX.2016.7498955</idno>
	</analytic>
	<monogr>
		<title level="m">Quality of Multimedia Experience (QoMEX)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Eighth International Conference on</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="640" to="651" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><surname>Nvidia® Digits™ Devbox</surname></persName>
		</author>
		<title level="m">NVIDIA Developer</title>
				<imprint/>
	</monogr>
	<note>Internet</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep filter banks for texture recognition and segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3828" to="3836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Using filter banks in convolutional neural networks for texture classification</title>
		<author>
			<persName><forename type="first">V</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Whelan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn Lett</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="63" to="69" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">CT Market Outlook Report</title>
		<editor>IMVInfo.com</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
	<note>Internet</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<ptr target="http://www.imvinfo.com/index.aspx?sec=ct&amp;sub=dis&amp;itemid=200081" />
		<title level="m">Available</title>
				<imprint>
			<date type="published" when="2017-03-14">14 Mar 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The clinical importance of visceral adiposity: a critical review of methods for visceral adipose tissue analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patlas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Pinthus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mourtzakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br J Radiol</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
