<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Decoding Toolbox (TDT): a versatile software package for multivariate analyses of functional imaging data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-01-06">06 January 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Martin</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
							<email>m.hebart@uke.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Systems Neuroscience</orgName>
								<orgName type="institution">University Medical Center Hamburg-Eppendorf</orgName>
								<address>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Bernstein Center for Computational Neuroscience</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Berlin Center for Advanced Neuroimaging</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Berlin School of Mind and Brain</orgName>
								<orgName type="institution">Humboldt-Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai</forename><surname>Görgen</surname></persName>
							<email>kai.goergen@bccn-berlin.de</email>
							<affiliation key="aff1">
								<orgName type="department">Bernstein Center for Computational Neuroscience</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Berlin Center for Advanced Neuroimaging</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Fachgebiet Neurotechnologie</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John-Dylan</forename><surname>Haynes</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Bernstein Center for Computational Neuroscience</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Berlin Center for Advanced Neuroimaging</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Berlin School of Mind and Brain</orgName>
								<orgName type="institution">Humboldt-Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julien</forename><surname>Dubois</surname></persName>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">VU University Amsterdam</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">Qiyong Gong</orgName>
								<orgName type="institution" key="instit2">West China Hospital of Sichuan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Department of Systems Neuroscience</orgName>
								<orgName type="institution">University Medical Center Hamburg-Eppendorf</orgName>
								<address>
									<addrLine>Martinistraße 52</addrLine>
									<postCode>W34, 20251</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Bernstein Center for Computational Neuroscience</orgName>
								<orgName type="institution">Charité Universitätsmedizin</orgName>
								<address>
									<addrLine>Haus 6, Philippstr. 13</addrLine>
									<postCode>10115</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Decoding Toolbox (TDT): a versatile software package for multivariate analyses of functional imaging data</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-01-06">06 January 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">8E37B502329C5A1D719BDD7E097B50C0</idno>
					<idno type="DOI">10.3389/fninf.2014.00088</idno>
					<note type="submission">Received: 01 July 2014; accepted: 10 December 2014; published online: 06 January 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2-SNAPSHOT" ident="GROBID" when="2022-05-18T11:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>multivariate pattern analysis</term>
					<term>decoding</term>
					<term>pattern classification</term>
					<term>fMRI</term>
					<term>representational similarity analysis</term>
					<term>searchlight</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>The multivariate analysis of brain signals has recently sparked a great amount of interest, yet accessible and versatile tools to carry out decoding analyses are scarce.</s><s>Here we introduce The Decoding Toolbox (TDT) which represents a user-friendly, powerful and flexible package for multivariate analysis of functional brain imaging data.</s><s>TDT is written in Matlab and equipped with an interface to the widely used brain data analysis package SPM.</s><s>The toolbox allows running fast whole-brain analyses, region-of-interest analyses and searchlight analyses, using machine learning classifiers, pattern correlation analysis, or representational similarity analysis.</s><s>It offers automatic creation and visualization of diverse cross-validation schemes, feature scaling, nested parameter selection, a variety of feature selection methods, multiclass capabilities, and pattern reconstruction from classifier weights.</s><s>While basic users can implement a generic analysis in one line of code, advanced users can extend the toolbox to their needs or exploit the structure to combine it with external high-performance classification toolboxes.</s><s>The toolbox comes with an example data set which can be used to try out the various analysis methods.</s><s>Taken together, TDT offers a promising option for researchers who want to employ multivariate analyses of brain activity patterns.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p><s>Human neuroscientists are interested in understanding the function of the human brain and nervous system.</s><s>For that purpose, they have developed numerous methods that directly or indirectly measure the activity of the nervous system at work.</s><s>One of these methods is functional magnetic resonance imaging (fMRI) which measures brain activity indirectly through the blood oxygen level dependent (BOLD) response <ref type="bibr" target="#b43">(Logothetis et al., 2001)</ref>.</s><s>Conventionally, the focus of fMRI has been to perform massunivariate analyses, i.e., to analyze the recorded data time courses of each fMRI brain voxel (for MEG/EEG each sensor/electrode) separately, for example with the general linear model (GLM, e.g., <ref type="bibr" target="#b16">Friston et al., 1994)</ref>.</s></p><p><s>More recently, these mass-univariate analysis methods have been complemented by multivariate pattern analysis (MVPA) which refers to a collection of multivariate methods of brain data analysis that incorporate multiple dependent variables at the same time <ref type="bibr" target="#b28">(Haynes and Rees, 2006;</ref><ref type="bibr" target="#b56">Norman et al., 2006;</ref><ref type="bibr" target="#b35">Kriegeskorte, 2011)</ref>.</s><s>One of the most popular multivariate methods of brain data analysis is generally referred to as multivariate decoding which describes the mapping of multiple dependent variables to one or multiple independent variables, and which contrasts with multivariate encoding describing the opposite mapping <ref type="bibr" target="#b51">(Naselaris et al., 2011)</ref>.</s><s>The popularity of multivariate methods of brain data analysis stems from three facts: First, multivariate methods offer increased sensitivity in detecting statistical dependence between cognitive variables and (patterns of) brain activity, because these methods can combine information across multiple voxels and exploit their covariance.</s><s>Put simply, multivariate methods make it easier to detect existing differences between brain signals.</s><s>Second, multivariate methods allow for greater specificity in finding a statistical dependence between measured brain data and multiple categorical responses.</s><s>Although a number of brain regions show overall changes in activity selective for specific stimulus categories (e.g., <ref type="bibr" target="#b34">Kanwisher et al., 1997)</ref>, stimuli can be encoded in a more distributed manner <ref type="bibr" target="#b1">(Averbeck et al., 2006)</ref>.</s><s>Multivariate methods can be used to target distributed representations of stimuli, cognitive variables, or other variables of interest.</s><s>This effectively enables researchers to ask more specific questions regarding neuronal representations, for example about the representation of individual face exemplars <ref type="bibr" target="#b36">(Kriegeskorte et al., 2007;</ref><ref type="bibr" target="#b52">Nestor et al., 2011)</ref>.</s><s>Third, multivariate decoding methods allow functional neuroimaging to be used for accurate prediction of cognitive and mental states in the form of a "neuronal marker."</s><s>For example, they might be used to support the diagnosis of neurological disorders beyond regions typically detected by radiologists <ref type="bibr" target="#b70">(Weygandt et al., 2011)</ref>, predict the conversion from mild cognitive impairment to Alzheimer's disease <ref type="bibr" target="#b10">(Cui et al., 2011)</ref>, interrogate cognitive states from people that cannot communicate <ref type="bibr" target="#b33">(Horikawa et al., 2013)</ref>, or support non-invasive brain-computer interfaces for motor control in paralyzed patients <ref type="bibr" target="#b3">(Blankertz et al., 2007)</ref>.</s></p><p><s>Although the number of publications using multivariate decoding methods has been rising continuously, it still seems to be common for researchers to program their own multivariate data analysis pipeline from scratch 1 .</s><s>This is not only very timeconsuming and redundant, it is also very error-prone.</s><s>Indeed, if the same piece of code is adapted for different decoding analyses, changes that were done for previous analyses might be overlooked in later analyses or might affect other analysis steps which can produce invalid results.</s><s>Just as problematic-and not uncommon even for experts-is the unintentional wrong use of decoding methods, for example circular analyses <ref type="bibr" target="#b39">(Kriegeskorte et al., 2009)</ref>.</s><s>In addition, researchers might hesitate to conduct decoding analyses, either because of their limited understanding of machine learning methods for functional neuroimaging (covered in detail by <ref type="bibr" target="#b15">Formisano et al., 2008;</ref><ref type="bibr" target="#b57">Pereira et al., 2009;</ref><ref type="bibr" target="#b41">Lemm et al., 2011)</ref> or because of the effort involved in learning to apply a new analysis method.</s><s>For that reason, researchers getting started with decoding would strongly benefit from an easy-to-use implementation of multivariate methods.</s><s>At the same time, they would ideally keep using the same software for simple analyses that they would later use for more sophisticated approaches once they have gained sufficient knowledge.</s></p><p><s>Here we present The Decoding Toolbox (TDT) that offers a flexible yet easy to use framework for decoding analyses in Matlab <ref type="bibr">(Mathworks, Natick, MA)</ref>.</s><s>TDT offers an interface with SPM (Statistical Parametric Mapping, http://www.fil.ion.ucl.ac.</s><s>uk/spm/), the most common fMRI data analysis software, but can also be extended to other fMRI data analysis packages.</s><s>TDT can be used by any researcher with basic knowledge in fMRI data analysis and minimal programming skills, while at the same time allowing a large amount of flexibility in the application of complex decoding approaches for more experienced researchers.</s><s>We briefly summarize the key features of the toolbox that should make its use attractive.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SIMPLICITY</head><p><s>Originally, we created TDT to simplify setting up decoding analyses and prevent the unintentional introduction of programming errors or unnoticed changes in settings that do not elicit error 1 To support this observation numerically, we conducted a Google Scholar search where we intended to limit our search to articles using multivariate decoding methods and which explicitly mention the software package they use for regular analyses.</s><s>These articles should also mention the MVPA toolbox used.</s><s>For the search, we used the combination "fMRI AND ('multivariate pattern analysis' OR 'multivoxel pattern analysis') AND (FSL OR AFNI OR Freesurfer OR SPM)."</s><s>This yielded 659 hits between 2010 and 2013.</s><s>Of these, only 103 (15.6 %) contained the strings "PRoNTo," "PyMVPA," "MVPA toolbox" or "3dsvm," which refer to previous MVPA-related software packages (see Comparison to Existing Packages of Multivariate Data Analysis).</s><s>132 (20.0 %) contained the terms "in-house," "custom-written," "custommade," "custom-built" or "custom Matlab."</s><s>Neither term was contained in 442 (67.0%) articles.</s></p><p><s>messages, but which may severely compromise results.</s><s>For that reason, we wanted to make TDT particularly easy to use, where all important settings are made at the beginning.</s><s>We believe that minimal programming ability is necessary, with the only requirement being that a user is able to modify existing Matlab scripts that define the settings for the decoding analysis.</s><s>This simplicity also allows users to see at a glance what decoding analysis they are performing.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MODULAR STRUCTURE AND TRANSPARENCY</head><p><s>The modular structure and use of encapsulation for different subroutines make the toolbox relatively easy to understand.</s><s>At the same time, this structure is less error prone and reduces programming effort from the side of developers.</s><s>For users, the existence of decoding design matrices (see below) and the possibility of extensive logging make the internal processes of the toolbox more transparent, which also reduces the probability of mistakes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPM INTERFACE</head><p><s>TDT has been developed from an SPM perspective and works with current SPM versions (downwards compatible to SPM2), but can also be used outside of SPM.</s><s>TDT can directly read all decoding-relevant information from SPM design matrices and in that way simplifies the process of setting up standard decoding analyses.</s><s>For example, a complete leave-one-run-out cross-validation decoding analysis can be executed using one line of code, by providing the path to the analysis and the names of the regressors that should be classified (see below).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MODULARITY, VERSATILITY, EXTENDIBILITY</head><p><s>TDT comes with a number of methods which allow for executing most commonly used analysis pipelines "out of the box" (Figure <ref type="figure" target="#fig_0">1</ref>).</s><s>These include feature scaling, feature transformation (e.g., principal component analysis), parameter selection, and feature selection as steps prior to decoding.</s><s>The decoding analysis itself has two-class and multiclass classification implemented, using a number of often-used classifiers including support vector classifiers, logistic regression, and correlation classifiers <ref type="bibr" target="#b26">(Haxby et al., 2001)</ref>.</s><s>Additionally, support vector regression is part of the toolbox.</s><s>The toolbox has been tested and runs under Windows, Linux, and Mac OS.</s></p><p><s>Due to the modular structure and the simplicity of the code, users can extend TDT with little effort to incorporate other methods as well: Other software packages can be used instead of SPM, new classifiers can be introduced, other means of feature selection can be applied, and even complete toolboxes-e.g., other Matlab decoding toolboxes-can be interfaced to run in the TDT framework.</s></p><p><s>We chose to implement our toolbox in Matlab because it is a very popular high-level programming language in the neuroimaging community and offers an excellent programming environment with a large and helpful community.</s><s>We are aware that part of the neuroimaging community is trying to move toward completely non-commercial software instead.</s><s>TDT does, however, not require any additional commercial Matlab toolboxes such as the Statistics or Bioinformatics Toolbox.</s><s>Many functions were written specifically for TDT, for example calculation All that is required are brain images (ideally preprocessed with SPM) and a configuration variable cfg that contains all decoding-relevant information.</s><s>TDT will then generate results, including.</s><s>mat-files with the results or if required brain maps displaying the decoded information in space.</s><s>(B) TDT view for intermediate users.</s><s>Decoding design creation, type of analysis, type of classifier and type of output can be modified.</s><s>All of these settings are necessary for any decoding analysis, which will be set to default settings if not specified by the user.</s><s>This level of description already covers most scenarios that the typical user would encounter.</s><s>(C) All TDT options.</s><s>For the optional functions including feature selection, feature transformation, scaling, and parameter selection, TDT offers a number of preconfigured settings which can be customized.</s><s>Expert users can extend the toolbox to include new methods (e.g., classifiers, feature selection methods) or can even create an interface to external machine learning packages.</s></p><p><s>of F-values, implementation of statistical distributions, and quick 1-D linear interpolation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPEED</head><p><s>TDT has been profiled extensively to identify and remove possible bottlenecks that would otherwise reduce the speed of decoding analyses.</s><s>For example, TDT can achieve a three-fold speed increase in cross-validation designs by computing a kernel <ref type="bibr" target="#b48">(Müller et al., 2001)</ref> only once and then passing the training and test part of that kernel to the classifier.</s><s>The resulting speed improvement becomes particularly apparent with large classification problems or searchlight analyses.</s><s>In addition, we rewrote many built-in Matlab functions, for example for creating correlation matrices or finding unique values, considerably speeding-up processing.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STRONG DEBUGGING AND ERROR CHECKING</head><p><s>We wanted to make sure that there are as few programming errors as possible in the code, a goal that is particularly difficult given the flexibility and diversity of possible decoding analyses.</s><s>Although in general it is never possible to guarantee that any software is free from bugs, we regularly run a number of basic analyses as benchmarks to check if these analyses still run and create the same output as in previous analyses.</s><s>TDT has been extensively tested by many beta users and, importantly, several published results used prior versions of the toolbox <ref type="bibr" target="#b32">(Hesselmann et al., 2011;</ref><ref type="bibr">Christophel et al., 2012, in press;</ref><ref type="bibr">Hebart et al., 2012, in press;</ref><ref type="bibr" target="#b58">Reverberi et al., 2012;</ref><ref type="bibr" target="#b6">Christophel and Haynes, 2014;</ref><ref type="bibr" target="#b59">Ritter et al., 2014;</ref><ref type="bibr">Van Kemenade et al., 2014a,b;</ref><ref type="bibr" target="#b44">Ludwig et al., 2015;</ref><ref type="bibr">Bilalić et al., in press;</ref><ref type="bibr">Guggenmos et al., in press)</ref>.</s></p><p><s>In addition, TDT contains many checks to prevent erroneous analyses.</s><s>In general, it is always possible that unwanted errors occur, and of course researchers always have to double-check if their analysis yields meaningful results.</s><s>The implemented checks facilitate the process of detecting and eliminating errors.</s><s>Among others, they ensure independence of training and test data, that all data has the same realignment parameters, and more generally whether the selected options are incomplete or would generate errors.</s><s>Other initial checks help in saving time and frustration of the user: Each decoding analysis creates a log-file which can be used to recover possible sources of errors.</s><s>These features have been implemented based on the experience of the authors as well as through user experience and will continuously be improved.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>READABILITY</head><p><s>TDT is open-source (see License Statement), with extensively commented code, comprehensive variable names, and an execution structure that follows along a main function with several auxiliary functions.</s><s>We did not want to provide a black-box where a user cannot follow the steps that are carried out in a decoding analysis.</s></p><p><s>In the following we will describe TDT in more detail.</s><s>We will use the style of a tutorial which is intended to ease readability of this section.</s><s>We will introduce TDT at three different levels of complexity, starting with a rough description of the toolbox to provide an initial overview of the basic structure of TDT.</s><s>This section should be sufficient for users just getting started with decoding, or those who would like to conduct a simple generic decoding analysis.</s><s>Second, we give a more detailed explanation of how to expand on this standard decoding analysis for users at an intermediate level who want to tailor the analysis to their needs.</s><s>Third, for advanced users we expand on more detailed optional settings of the toolbox, including parameter selection or feature selection.</s><s>After these three steps, we will briefly demonstrate how users who want to exploit the full capabilities of the toolbox can extend the toolbox to new classifiers, new feature selection methods, or even complete machine learning packages.</s></p><p><s>We may use terminology unfamiliar to some readers.</s><s>Rather than explaining all terms in the text, we summarize the most important ones in Table <ref type="table" target="#tab_0">1</ref> (for a detailed explanation of classification-related terms, please consult <ref type="bibr" target="#b57">Pereira et al., 2009)</ref>.</s><s>Although we provide examples written for users who want to carry out within-subject classification, most of these examples also hold for between-subject classification.</s><s>Curse of dimensionality Within machine learning the fact that classifier performance, i.e., the predictive power of a classifier drops when the number of features (e.g., voxels) becomes much larger than the number of samples (e.g., brain images)</s></p><p><s>Decoding step An iteration of a decoding analysis which is part of the cycle of evaluating the classifier.</s><s>When cross-validation is used, decoding step refers to a cross-validation fold</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature selection</head><p><s>Methods that reduce the number of features (e.g., voxels).</s><s>In our terminology, selecting regions of interest or running a searchlight analysis are not parts of feature selection.</s><s>In addition, we treat methods separately that reduce the dimensionality, but give up the voxel-to-voxel mapping (e.g., PCA).</s><s>Within TDT, we refer to methods that change the voxel-to-voxel mapping as feature transformation methods</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General linear model (GLM)</head><p><s>A statistical model that incorporates analysis of variance, linear regression, and related parametric tests into a common framework.</s><s>In brain imaging, the GLM is commonly used to explain each voxel's time series separately with multiple linear regressors each representing conditions of interest or nuisance variables <ref type="bibr" target="#b16">(Friston et al., 1994)</ref>.</s><s>The term mass-univariate refers to the fact that the GLM is calculated for each voxel individually Hyperplane A plane in more than 3D.</s><s>Typically, the term separating hyperplane is used which separates the space spanned by different features (e.g., voxels) in two subspaces and defines the decision boundary of the classifier.</s><s>Each part of the voxel space is in this way assigned to one of two classes L1/L2-norm A regularization method which influences the complexity of a classification model.</s><s>In most cases, an L2-norm is used which minimizes length of the weight vector.</s><s>The L1-norm can be used to minimize the sum of the absolute weights, typically resulting in a sparser model (i.e., less features will contribute to the classification)</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Margin</head><p><s>For support vector machines, the area of space between two classes, of which the center is typically the separating hyperplane.</s><s>SVMs have the goal of maximizing the margin between two classes Searchlight analysis One of the three most common types of decoding analysis conducted, the two other being whole brain decoding and region-of-interest decoding.</s><s>Searchlight decoding typically creates a map of classification accuracies that can be interpreted as the local information content around each voxel <ref type="bibr" target="#b37">(Kriegeskorte et al., 2006;</ref><ref type="bibr" target="#b29">Haynes et al., 2007)</ref> Support vector machine A type of classifier that maximizes the margin between two different classes <ref type="bibr" target="#b8">(Cortes and Vapnik, 1995)</ref> Weight vector Determines the contribution of each feature to the final classifier function.</s><s>For most classifiers, the weight vector cannot be directly interpreted as reflecting the classified variable, because it is a filter that extracts a class signal while at the same time it suppresses correlated noise.</s><s>Using the covariance of the data, the weight vector can be converted into an interpretable pattern vector <ref type="bibr" target="#b25">(Haufe et al., 2014)</ref> which in case of voxel features can be mapped back to a brain image</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A SIMPLE DECODING ANALYSIS</head><p><s>For a general decoding analysis, let us for the moment treat TDT as a black box (Figure <ref type="figure" target="#fig_0">1A</ref>).</s><s>The user feeds in a set of brain images that he wants to classify and receives a single classification accuracy or an information map as output.</s><s>What is needed in addition is the configuration variable cfg which carries all information necessary to conduct a specific decoding analysis.</s><s>Most parameters in cfg are defaults that are set automatically; parameters are only set manually when they should be changed.</s><s>In addition, the SPM-interface can automatically extract the decoding-relevant information from the SPM.mat file which is generated as part of a standard general linear model (GLM) in SPM.</s><s>This information is then automatically added to cfg.</s><s>This interface can be used if users classify not individual brain images, but use parameter estimates of single trials or runs generated by SPM (e.g., beta maps, see Table <ref type="table" target="#tab_0">1</ref>).</s><s>Assuming that a user created the SPM.mat file with unique names for all regressors (e.g., "left" and "right" for regressors related to button presses) and would like to carry out a "standard" leave-one-run-out cross validation scheme with two categories, a complete decoding analysis in TDT can be executed in only one line of code (we will explain the meaning of this below).</s><s>In short, the example call decoding_example('searchlight','left', 'right',beta_dir,output_dir,4)</s></p><p><s>will perform a cross-validated leave-one-run-out searchlight decoding analysis between the regressors "left" and "right," where beta_dir is the path where the SPM GLM results are stored, out-put_dir is the folder where the decoding results will be saved, and 4 is the radius of a spherical searchlight in voxels (see next paragraph for a detailed explanation).</s><s>This analysis will yield a map of accuracies that can be inspected with SPM or other thirdparty software and which should uncover brain regions involved in encoding the motor response.</s></p><p><s>To allow a first look inside the "black box," we will now explain the inner functions of this example call (Figure <ref type="figure" target="#fig_0">1</ref>).</s><s>Prior to running a decoding analysis, TDT assumes that data have been preprocessed appropriately (Figure <ref type="figure">2</ref> top).</s><s>Standard preprocessing includes spatial realignment, possibly slice timing correction and detrending, and in some cases also spatial normalization and smoothing (although these latter steps are less common for preprocessing of decoding analyses).</s><s>As mentioned above, rather than running a decoding analysis on individual images, it has become quite common to use single trial estimates of data <ref type="bibr" target="#b49">(Mumford et al., 2012)</ref> or even estimates that combine multiple trials within one run <ref type="bibr" target="#b29">(Haynes et al., 2007)</ref>.</s><s>This process can improve classifier performance <ref type="bibr" target="#b47">(Mourão-Miranda et al., 2006</ref><ref type="bibr" target="#b60">, 2007;</ref><ref type="bibr" target="#b49">Mumford et al., 2012)</ref>, and combining multiple trials can lead to higher classification accuracies <ref type="bibr" target="#b40">(Ku et al., 2008)</ref> and slightly improved power <ref type="bibr" target="#b0">(Allefeld and Haynes, 2014)</ref>.</s><s>These estimates would typically be generated in the common GLM framework and are stored as so called beta images.</s><s>For simplicity, in the following we will assume that one beta image per condition per run is generated (e.g., one for "left" for run 1, one for "right" for run 1, one for "left" for run 2, one for "right" for run 2, etc.).</s><s>In this case, the above example call simply gets the beta images from beta_dir representing the conditions "left" and "right" and will extract the run numbers.</s><s>The brain mask which SPM automatically creates during model estimation contained in beta_dir is automatically used to reduce the analysis to voxels inside the brain.</s><s>This information is sufficient to carry out a decoding analysis with a leave-one-run-out cross-validation scheme (see Table <ref type="table" target="#tab_0">1</ref> for terminology), and in this example, a so-called searchlight analysis is executed with a radius of 4 voxels, using a support vector machine (SVM, <ref type="bibr" target="#b8">Cortes and Vapnik, 1995)</ref> as a classifier.</s><s>On a Dell Precision M4600 Intel @ 2.30 GHz, 64 bit Windows 7 with Matlab (2011a), this analysis takes roughly 3 min for around 120,000 searchlights.</s></p><p><s>For a group analysis, this procedure is repeated for every participant, and the resulting accuracy maps can then be spatially normalized and submitted to standard statistical analysis procedures in SPM or any other preferred software package (Figure <ref type="figure">2</ref> bottom).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A CLOSER LOOK AT THE DECODING TOOLBOX-FOR INTERMEDIATE LEVEL USERS AND ABOVE</head><p><s>Although the most basic one-line-of-code use of the toolbox already allows running a multitude of analyses with practically no programming skills, users may want to adjust a number of settings.</s><s>In this section, we explain the major steps that are required in each decoding analysis (Figure <ref type="figure" target="#fig_0">1B</ref>), and in the next section optional steps are explained.</s><s>For each of these required steps there are default settings in TDT, but the user may wish to adjust them.</s><s>In general, each user creates a short script which contains (1) all the settings of the cfg variable and ( <ref type="formula">2</ref> This example automatically extracts regressor names from the SPM model, then accumulates all relevant information from the design related to the regressors of interest ("left" and "right"), creates a leave-one-run-out cross-validation design, and executes the decoding analysis using default settings.</s><s>Important basic settings that otherwise use these default settings are explained in the next four paragraphs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIGURE 2 | General analysis stream of a typical searchlight decoding analysis in</head><p><s>The Decoding Toolbox (TDT).</s><s>Top: Typical preprocessing of data is done prior to running TDT, for example with the common software SPM.</s><s>Rather than submitting individual images to decoding analyses, it has become quite common to use temporal compression or statistical estimates of trials (trial-wise decoding) or of multiple trials within one run (run-wise decoding) as data for classification.</s><s>Middle: The decoding stream of cross-validated searchlight decoding.</s><s>After selecting voxels from a searchlight and extracting data from the preprocessed images, a leave-one-run-out cross-validation is performed.</s><s>In this, data is partitioned, where in successive folds data from one run is used for testing and data from all other runs for training.</s><s>In each fold, a classifier is trained and its performance is validated on the left-out test set.</s><s>Finally, the performance of the whole cross-validation is evaluated, typically by calculating the mean accuracy across all cross-validation iterations.</s><s>The accuracy is then stored at the center of the current searchlight.</s><s>The whole procedure is repeated for all voxels in the brain, yielding a complete map of cross-validation accuracies.</s><s>Bottom: Usually, these searchlight maps are post-processed using standard random effects analyses, for example using SPM's second-level routine.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DESIGN CREATION</head><p><s>A powerful feature of TDT is the use of decoding design matrices (Figure <ref type="figure" target="#fig_2">3</ref>).</s><s>A decoding design matrix determines the exact structure of a cross-validation design, i.e., which data belongs to which class and which data is training and test data in each decoding step (also called cross-validation fold or iteration).</s><s>To determine which samples should remain together (e.g., because they are in one run and the analysis is a leave-one-run-out cross-validation), data can be assigned to chunks which serve as categorical numerical labels.</s><s>Although in many cases, the number of chunks determines the number of decoding steps, more complex designs (e.g., bootstrapping designs, Figure <ref type="figure" target="#fig_2">3C</ref>) can have more steps than chunks.</s><s>Finally, multiple decoding analyses can be carried out in one design, a feature which might be particularly useful if data needs to be analyzed separately and combined, or if crossclassification is applied to a number of different data sets saving repeated training on the same data.</s><s>A number of existing functions allow creating a multitude of different designs in advance, and additional design functions can be created by more advanced users (see Figure <ref type="figure" target="#fig_2">3</ref> for some example designs using different functions).</s><s>After creating the design, the design inspection can be used to visualize if the analysis is carried out in the correct manner.</s><s>Example call (design created and visualized prior to a decoding analysis as part of the script):</s></p><p><s>cfg.design = make_design_cv(cfg); % creates the design prior to decoding display_design(cfg)% visualizes the design prior to decoding</s></p><p><s>Alternative example call (design created and visualized while the decoding analysis is running):</s></p><p><s>cfg.design.function.name</s><s>= 'make_design_cv'; % creates a leave-one-chunk-out cross-validation design cfg.plot_design = 1; % plots the design when decoding starts</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANALYSIS TYPE</head><p><s>Most decoding analyses can be categorized as one of three different types of analysis, depending on the general voxel selection criterion: Whole-brain analyses, region-of-interest (ROI) analyses, and searchlight analyses.</s><s>All of these approaches are commonly used for decoding.</s><s>In the machine learning community, ROI and searchlight analyses might be considered feature selection approaches, but this is not typically how they are called in the brain imaging community.</s><s>All of these approaches have their respective advantages and disadvantages (discussed e.g., in <ref type="bibr" target="#b12">Etzel et al., 2009</ref><ref type="bibr" target="#b13">Etzel et al., , 2013))</ref>.</s><s>Among others, one advantage of whole-brain analyses is that all available information is fed into the classifier, while major disadvantages of this method are the difficulty to tell the origin of the information and the so-called "curse of dimensionality" (see Table <ref type="table" target="#tab_0">1</ref>).</s><s>These problems are less of an issue in ROI analyses, but ROIs need to be specified and can in that way be biased, variable ROI sizes make them difficult to compare, and information encoded across different ROIs gets lost.</s><s>Searchlight analyses can be seen as a succession of spherical ROIs, but require no prior selection of brain regions and are in that respect unbiased to prior assumptions about where to expect an effect <ref type="bibr" target="#b17">(Friston et al., 2006)</ref>; however, they suffer from the multiple comparisons problem, the necessity to specify the searchlight size as an additional parameter, and are-just like ROIs-insensitive to information encoded across distant brain regions.</s></p><p><s>Example call:</s></p><p><s>cfg.analysis = 'wholebrain'; % alternatives: 'ROI', 'searchlight'</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TRAIN AND TEST CLASSIFIER</head><p><s>The core of the toolbox is training and testing the classifier.</s><s>A classifier is typically first built from data where class membership is known ("train" classifier); then, the ability of the classifier to generalize to unseen data is evaluated ("test" or "validate" classifier).</s><s>This separation is important to limit the impact of overfitting the classifier to the data and to have an unbiased estimate of the classifier's generalization performance.</s><s>The training and test cycle is hardcoded to make sure that training and test data are truly kept separate in each cycle (unless users create their own extension to overcome this separation, if required).</s><s>TDT is equipped with a number of external classifiers which can be selected by setting the cfg variable.</s><s>These classifiers belong to the packages LIBSVM <ref type="bibr" target="#b4">(Chang and Lin, 2011)</ref> and LIBLINEAR <ref type="bibr" target="#b14">(Fan et al., 2008)</ref> and include L1-and L2-norm regularized support vector machines and logistic regression.</s><s>In addition, a correlation classifier <ref type="bibr" target="#b26">(Haxby et al., 2001)</ref> has been implemented as part of the toolbox.</s><s>Multiple classifiers have been compared across different data sets, with variable results <ref type="bibr" target="#b9">(Cox and Savoy, 2003;</ref><ref type="bibr" target="#b57">Pereira et al., 2009;</ref><ref type="bibr" target="#b45">Misaki et al., 2010)</ref>.</s><s>Typically, the L2-norm support vector machine (SVM) performs quite well, which is why it is the default classifier in TDT.</s><s>The options of the classifiers can be set using the cfg variable.</s><s>TDT can also be used for purposes other than classification, for example to conduct a simple correlation of two data sets.</s><s>Finally, at the stage of training and testing, advanced users can create an interface to completely external toolboxes that include other optimization methods (see How to Extend the Toolbox).</s><s>All input can be passed as part of the settings in the cfg and all output can be stored for later processing.</s></p><p><s>Example call:</s></p><p><s>cfg.decoding.software</s><s>= 'liblinear'; cfg.decoding.method</s><s>= 'classification'; cfg.decoding.train.classification.</s><s>model_parameters = '-s 0 -c 1 -q'; cfg.decoding.test.classification.</s><s>model_parameters = '-q';</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TRANSFORMATION OF RESULTS</head><p><s>Classifiers are essentially functions that describe a separation boundary (i.e., hyperplane, see Table <ref type="table" target="#tab_0">1</ref>) of multiple classes in voxel space.</s><s>Newly predicted samples are mapped relative to this function and typically receive an output larger or smaller than 0 that denotes the distance to the separating function, where positive values denote membership to one class and negative values membership to the other class.</s><s>For linear classifiers, so called decision values can be used to indicate the distance of a particular sample to the separating hyperplane.</s><s>Using the predicted labels, the actual labels and the decision values, a number of metrics can be calculated to evaluate the performance of a classifier.</s></p><p><s>The most typical output for a decoding analysis is the mean cross-validated accuracy value.</s><s>However, a number of other types of output are quite common and potentially useful.</s><s>For example, it can be of interest to look at the classification accuracy for each class separately to assess classifier bias.</s><s>A classification accuracy of 75% should be interpreted very differently when either class is decoded with 75% accuracy, or when one is decoded with 100% accuracy and the other with 50% (leading to 75% on average for a balanced number of samples in each class).</s><s>In case of differently sized classes, balanced accuracy or d-prime can give indices of performance that take into account the different size of the groups.</s><s>Additionally, the area under the receiveroperator-characteristic curve (AUC) which uses the distance of a classification output to the decision boundary can provide results about the information content using a graded rather than a binary response.</s></p><p><s>Other measures have received interest as well.</s><s>For instance, weight maps are useful to provide information about the contribution of each voxel to the classification and are often used in whole-brain classification settings.</s><s>Importantly, weight maps cannot be interpreted as reflecting the neural substrate relating to a task or another variable that is classified.</s><s>Researchers interested in interpreting weights beyond the classifier alone can convert the weight maps to patterns which then show the contribution of each voxel for the representation of the classes under study <ref type="bibr" target="#b25">(Haufe et al., 2014;</ref><ref type="bibr" target="#b59">Ritter et al., 2014)</ref>.</s><s>In addition, representational similarity analysis which exploits the correlation similarity structure of voxels and different distance metrics can be used to illustrate the representational distance of different conditions <ref type="bibr" target="#b38">(Kriegeskorte et al., 2008;</ref><ref type="bibr" target="#b54">Nili et al., 2014)</ref>.</s><s>All approaches described above have been implemented in TDT.</s></p><p><s>Example call:</s></p><p><s>cfg.results.output</s><s>= {'accuracy_minus_ chance', 'AUC_minus_chance', 'SVM_weights'}; cfg.decoding.method</s><s>= 'classification'; % weights cannot be extracted when precomputed kernels are used, i.e., we need to use the slower method of classification without kernels</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STATISTICAL ANALYSIS</head><p><s>For a neuroscientist, it is important to statistically evaluate the results generated by a classification analysis: Is the observed result statistically significantly different from chance?</s><s>Although at a first glance a decoding accuracy close to chance may seem disappointing, it is indeed quite commonly observed and not necessarily a problem.</s><s>In neuroscience, typically the goal is not to maximize classification performance, but to demonstrate that information is present in the brain signals used for classification.</s><s>This contrasts with the use in machine learning where the primary goal is to maximize classification performance and accuracies only slightly above chance would not be considered very useful.</s><s>For that reason, there is not much work investigating the combination of multivariate decoding with classical statistics.</s><s>Importantly, it can be shown that combining results based on cross-validation and classical statistics can lead to overly liberal results.</s><s>For example, cross-validated decoding accuracies are not binomially distributed, which is why binomial tests should not be used to statistically evaluate cross-validation results <ref type="bibr" target="#b62">(Schreiber and Krekelberg, 2013;</ref><ref type="bibr" target="#b55">Noirhomme et al., 2014)</ref>.</s><s>As an alternative, permutation testing can be used.</s><s>However, for searchlight analyses this can become very time consuming.</s><s>In addition, caution is warranted when using permutation approaches to make sure that these tests are not overly liberal <ref type="bibr" target="#b66">(Stelzer et al., 2013)</ref>, for example because they break up statistical dependencies at the wrong level (i.e., they violate the assumption of exchangeability, <ref type="bibr" target="#b53">Nichols and Holmes, 2002)</ref>.</s></p><p><s>These problems relate only to statistical analyses at the "decoding-level."</s><s>An alternative and common approach is to combine multiple decoding results and conduct a "second-level" statistical analysis.</s><s>This is the case when evaluating whether the mean accuracy across a group of subjects is different from chance.</s><s>For these purposes, classical parametric tests such as the Student's T-test can be used.</s></p><p><s>In TDT, at the decoding-level both binomial testing and permutation testing have been implemented.</s><s>However, binomial testing should only be used when training and test data are not reused, i.e., when no cross-validation and no bootstrapping is performed.</s><s>A permutation test is conducted in three steps: First, the same decoding design is set up using a permutation scheme where data from different chunks is kept separate.</s><s>Second, the permutations are conducted which can be run in parallel to speed-up processing.</s><s>Third, the permutation test is conducted.</s><s>Results can be reported in Matlab or written to brain images.</s><s>For the second-level, users are advised to use dedicated third-party software such as SPSS, R, or Matlab which is specialized for statistical analyses and allows testing for basic assumptions of the tests.</s><s>For users who do not want to export their results to other packages and are confident that the assumptions of their tests are met, TDT offers a set of basic functions that can conduct classical T-tests and F-tests.</s></p><p><s>Example call:</s></p><p><s>[results,cfg] = decoding(cfg); % run previously prepared decoding cfg.design = make_design_permutation (cfg,1000,1); % creates one design with 1000 permutations [reference,cfg] = decoding(cfg); % run permutations cfg.stats.test</s><s>= 'permutation'; % set test cfg.stats.tail</s><s>= 'right'; % set tail of statistical correction cfg.stats.output</s><s>= 'accuracy_minus_chance';</s></p><p><s>% choose from all original outputs p = decoding_statistics (cfg,results,reference);</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A DESCRIPTION OF OPTIONAL WORKFLOW STEPS-FOR ADVANCED LEVEL USERS</head><p><s>This section describes all remaining classification-related methods that can be carried out using a decoding analysis in TDT (Figure <ref type="figure" target="#fig_0">1C</ref>).</s><s>These include feature scaling, selection of model parameters in nested cross-validation, transformations of feature space, and feature selection.</s><s>None of these steps are strictly necessary for a decoding analysis, but they can in principle help improving the results of a decoding analysis.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SCALING</head><p><s>Scaling is the process of adjusting the range of data which enters the classifier.</s><s>This can be done to bring data to a range which improves the computational efficiency of the classifier (for example LIBSVM recommends scaling all data to be between 0 and 1).</s><s>It can, however, also be used to change the relative contribution of individual features or individual samples or to remove the influence of the mean spatial pattern <ref type="bibr" target="#b45">(Misaki et al., 2010</ref>; but see <ref type="bibr" target="#b18">Garrido et al., 2013)</ref> which might affect classification performance.</s><s>Scaling is also known as normalization, but we prefer the term scaling to distinguish it from another meaning of the term "normalization" which is commonly used in the MRI community to refer to spatial warping of images.</s></p><p><s>Typically, row scaling is used, i.e., scaling across samples within a given feature.</s><s>Although scaling can theoretically improve decoding performance, for some data sets it may not have any influence <ref type="bibr" target="#b45">(Misaki et al., 2010)</ref>.</s><s>Practically, scaling often has little or no influence on decoding performance when beta images or ztransformed data are passed, because this data already represents a scaled form of the raw images which is scaled relative to each run, rather than to all training data.</s><s>However, scaling may still speed-up classification.</s></p><p><s>TDT allows a number of different settings: Either all data are scaled in advance (in TDT: "all"), which is only valid when scaling carries no information about class membership that influences test data, or scaling is carried out on training data only and these estimated scaling parameters are then applied to the test data (in TDT: "across").</s><s>The typically used scaling methods which have also been implemented in TDT are min0-max1 scaling or z-transformation.</s><s>Min-max scaling scales all data to a range of 0 and 1, while z-transformation transforms data by removing the mean and dividing by the standard deviation.</s><s>In addition to scaling data to a specified range, cut-off values can be provided for outlier reduction <ref type="bibr" target="#b64">(Seymour et al., 2009)</ref>.</s><s>With this setting, all values larger than the upper cut-off are reduced to this limit, and all values smaller than the lower cut-off are set to this value.</s><s>In TDT, these approaches can be combined with outlier reduction.</s></p><p><s>Example call:</s></p><p><s>cfg.scale.method</s><s>= 'across'; % scaling estimated on training data and applied to test data cfg.scale.estimation</s><s>= 'z'; % z-transformation as scaling approach cfg.scale.cutoff</s><s>= [-3 3]; % all values &gt; 3 are set = 3 (here: 3 standard deviations, because data is z-transformed)</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PARAMETER SELECTION</head><p><s>Most multivariate classification and regression approaches use algorithms that contain parameters that need to be set by the user.</s><s>For example, linear support vector machines have the regularization parameter C that determines the degree to which data points can cross the so-called margin (Table <ref type="table" target="#tab_0">1</ref>) which can even lead to misclassification during training <ref type="bibr" target="#b8">(Cortes and Vapnik, 1995)</ref>.</s><s>Large values of C strongly penalize misclassification in training while small values of C allow for larger margins.</s><s>This variable influences the bias-variance tradeoff, i.e., the tradeoff between fitting a classifier too close to the training data (overfitting), or fitting it too little (underfitting, i.e., "ignoring" the structure of the training data too much), which directly affects the ability to generalize to the test data <ref type="bibr" target="#b48">(Müller et al., 2001)</ref>.</s><s>Another example is the parameter gamma that needs to be set for non-linear radial basis function (RBF) SVMs which determines the width of the RBF kernel <ref type="bibr" target="#b61">(Schölkopf et al., 1995)</ref>.</s><s>Since the optimal values for C and gamma are not known in advance, they are often estimated on the training data using nested cross-validation, a method where a cross-validation scheme is used only within training data to find good parameters.</s><s>Typically, all parameter combinations across a range of target values are tried, a process known as grid search.</s></p><p><s>The parameter combination that leads to best classification performance within training data is then applied to all training data and validated on the left-out test data.</s><s>This has the consequence that for each real cross-validation fold a different set of optimal parameters might be chosen.</s></p><p><s>To avoid nested cross-validation, many researchers simply choose to set C to a fixed value of 1.</s><s>In the typical scenario of an SVM where the number of features (e.g., voxels) is much larger than the number of samples (e.g., trials or beta images), in our experience only C-values much smaller than 1 have any influence on classification.</s><s>This is probably because all samples within training data can easily be linearly separated, and for larger values of C the classifier yields stable solutions.</s><s>Another problem is that with a small number of samples-even with nested cross-validation-the estimated parameters become quite variable, because they fit to the specifics of the training data and might not generalize well to test data.</s><s>In particular cases, this might improve decoding performance slightly.</s><s>Importantly, researchers should bear in mind that they must not escape the idea of cross-validation by trying out multiple parameter combinations and picking the one that yields the "best" results in the final cross-validated classification accuracy maps.</s><s>Rather, they should use nested cross-validation for picking the optimal parameter and testing whether this choice generalizes to independent test data in the outer cross-validation loop.</s><s>Alternatively, they could use parameters based on (previous) independent data sets or independent contrasts.</s><s>Finally, the disadvantage of parameter selection is that it is quite time consuming, in particular when multiple parameters are selected concurrently.</s><s>Parameter selection might make more sense in other circumstances or when other parameters are selected, for example the degree of a polynomial kernel.</s></p><p><s>In TDT, parameter selection is currently implemented as grid search, where all parameter combinations are combined.</s><s>Depending on the problem, there might be smarter optimization approaches, but in our experience grid search works well for optimizing few parameters, in particular when only few samples are available.</s><s>More advanced users can also create their own functions to tailor parameter selection to their specific problem.</s></p><p><s>Example call:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FEATURE TRANSFORMATION</head><p><s>The term feature transformation is not commonly used in the brain decoding community, but it is known in the machine learning community as a set of methods that change the meaning of each individual feature <ref type="bibr" target="#b42">(Liu and Motoda, 1998)</ref>.</s><s>We use this term to refer to a collection of methods that is used to change the space of data and possibly reduce the dimensionality of this changed space, as well.</s><s>Principal component analysis (PCA) is one example.</s><s>We prefer to treat such methods separately from feature selection (see below), because they lead to a change in the mapping of features.</s><s>Methods that we refer to as feature selection (below) select a subset of features (e.g., voxels) of the input.</s><s>In contrast, in feature transformation a data point refers to a non-linear transformation applied to the input, which essentially creates new features.</s><s>For example, the outcome of a principle component analysis (PCA) is no longer separate single voxel data, but a linear combination of the original voxel data.</s><s>This strict semantic separation helps to avoid confusion, makes the results of feature selection easier to interpret, facilitates the addition of new methods, and facilitates the use of multi-step feature selection (e.g., first running PCA and transforming voxels to principle component space, and then running feature selection on a subset of principal components).</s><s>Other examples of feature transformation would encompass independent component analysis (ICA), Fourier transformation, or pre-calculated mappings that can for example be used to align data spaces between subjects, known as hyperalignment <ref type="bibr" target="#b27">(Haxby et al., 2011)</ref>.</s><s>Currently, only PCA is implemented in TDT, but other methods can easily be added.</s><s>The transformation can be estimated on training data only and applied to test data in each cross-validation step ("across").</s><s>Alternatively, it can be estimated on both training and test data ("all") when it is ensured that this does not lead to nonindependence <ref type="bibr" target="#b39">(Kriegeskorte et al., 2009)</ref>.</s><s>This should not be the case as long as no label information is used for transformations (which is not done in PCA).</s><s>If feature transformation is also used for dimensionality reduction, the user can specify either the number of to be selected features or can specify a critical value in the score of the method that needs to be exceeded for a transformed feature to be of interest (e.g., for PCA the percent variance explained).</s></p><p><s>Example call:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FEATURE SELECTION</head><p><s>Books have been written about feature selection <ref type="bibr" target="#b22">(Guyon et al., 2006)</ref> which is a method in machine learning that refers to the reduction of the dimensionality of data, with the aim of finding the most relevant features and for improving classification performance.</s><s>Feature selection has been classified into three general categories: filters, wrappers, and embedded methods <ref type="bibr" target="#b21">(Guyon and Elisseeff, 2003)</ref>.</s><s>Filters are methods that use univariate or multivariate statistics based on the data to rank features and select them based on their rank.</s><s>Examples are the F-statistic, the weights of a classifier, or in brain imaging external masks that provide a ranking, such as external functional localizer images.</s><s>Wrappers are methods that iteratively include or exclude features, based on some optimization criterion specific to the feature selection method.</s><s>Examples are sequential forward selection or sequential backward elimination.</s><s>Finally, embedded methods are methods where the selection of features becomes part of the classification problem.</s><s>Examples are LASSO <ref type="bibr" target="#b67">(Tibshirani, 1996)</ref> or L1-regularized support vector machines <ref type="bibr" target="#b14">(Fan et al., 2008)</ref> where unimportant voxels receive a weight of zero, which eliminates their contribution.</s><s>Recursive feature elimination is another popular method (De <ref type="bibr">Martino et al., 2008)</ref> and is sometimes referred to as a wrapper method, although the final feature set and classification can depend on the previous steps.</s><s>For that reason-and to better distinguish it from other sequential methods-it can also be referred to as an embedded method.</s></p><p><s>In TDT, feature selection has been implemented with a number of filter methods and with the embedded method of recursive feature elimination.</s><s>Implemented filter methods are the F-statistic, the Mann-Whitney U-statistic, classifier weights, and external masks, with the additional option of supplying a separate mask for each cross-validation fold.</s><s>For determining the optimal feature set, nested cross-validation can be performed.</s><s>It should be noted, however, that similar to parameter selection the utility of feature selection is limited when the number of samples is very small.</s><s>In that case, nested cross-validation can optimize the number of features to the idiosyncrasies of the data, and it might be better not to perform feature selection at all.</s><s>In addition, feature selection can be computationally highly expensive and can thus dramatically slow down classification, in particular when recursive feature elimination is used with nested cross-validation and a large number of steps.</s><s>As has been mentioned for parameter selection, researchers should be cautious not to try out a number of different feature selection methods and choose one that produces the "best" final result.</s><s>Often researchers might be interested in implementing multiple feature selection steps.</s><s>In the current version of TDT, up to two feature selection steps are possible.</s><s>More sophisticated feature selection methods can be added to TDT, e.g., by including them directly into custom classification routines.</s></p><p><s>Example call:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HOW TO EXTEND THE TOOLBOX</head><p><s>TDT comes with a number of processing approaches, but of course not all methods have been implemented.</s><s>Researchers might want to use their preferred machine learning algorithm or feature selection method for their decoding analysis.</s><s>Other users might wish to use TDT only as a wrapper tool for their own machine learning package.</s><s>Data can also be passed to TDT, which in principle extends TDT to other modalities such as EEG or MEG decoding.</s><s>In this section, we will use three examples to illustrate how TDT can be extended.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXAMPLE 1: INTRODUCE A NEW CLASSIFIER</head><p><s>To add new classifiers, two functions need to be provided, one for training and one for testing the classifier.</s><s>If the new classifier should be called "newclassifier," the training method needs to be saved as newclassifier_train.m and is called by</s></p><formula xml:id="formula_0">model = newclassifier_train (labels_train,data_train,cfg)</formula><p><s>where model is any information that is needed to evaluate the classifier.</s><s>Within the function, the cfg is needed to distinguish whether a classification or regression should be performed, or whether a precomputed kernel is passed.</s><s>In addition, the parameters for classification can be passed in this variable.</s><s>In the following, we show pseudocode for the function to implement a new classifier.</s><s>% optional other output which we added just as an example (...) end</s></p><p><s>It is important that decoding_out returns a struct variable (i.e., structure array) with the subfields above (predicted_labels, true_labels, decisions_values, model, opt).</s><s>If some of these are not provided by a classifier, empty arrays can be passed.</s><s>These new classifier functions can then be called in any decoding analysis by setting cfg.decoding.software</s><s>= 'newclassifier';</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXAMPLE 2: INTRODUCE A NEW RESULT MEASURE</head><p><s>New, more sophisticated means of transforming results can also be introduced to TDT.</s><s>For example, consider a user who wants to weight classification accuracies by decision values before averaging.</s><s>The function would be written as follows: The function should be saved as transres_dvtimesacc.m and can then be used by setting cfg.results.output</s><s>= 'dvtimesacc';</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXAMPLE 3: EXTEND TOOLBOX TO EXTERNAL MACHINE LEARNING PACKAGE OR MORE COMPLEX PROCESSING STREAMS</head><p><s>The toolbox can be interfaced with complete external machine learning packages, for example, the powerful Shogun toolbox <ref type="bibr" target="#b65">(Sonnenburg et al., 2010)</ref>.</s><s>This might be useful for users who want to use the general workflow of TDT, e.g., the data handling, cross-validation facilities and searchlight routines, but do not wish to implement a large number of external algorithms for use in TDT.</s><s>The same general procedure can be applied to use highly sophisticated processing streams that do not directly fit into the TDT framework.</s><s>There are two approaches for creating an interface to an external toolbox.</s><s>The first takes place at the level of the classifier.</s><s>Essentially, an interface is created where all steps of the decoding analysis-if requested, even including cross-validation-are carried out outside of TDT.</s><s>The training function of a classifier acts as a placeholder to pass data to the testing function.</s><s>The function externalpackagewrapper would then contain the script which is normally executed using the external software package.</s><s>This can be made general purpose by passing parameters using the setting cfg.decoding.train.classification.model_parameters of TDT.</s></p><p><s>The second approach for creating an interface to external toolboxes takes place at the level of the transformation of outputs.</s><s>This might be useful if a user would like to complete the entire decoding analysis including the generation of output in an external toolbox.</s><s>In this case, the user creates a placeholder for the classifier which merely passes all data and classification parameters inside the model variable as the optional output decoding_out.opt</s><s>(e.g., using the toolbox function "passdata" as a classifier).</s><s>Then, the interface to the external package is created as follows: <ref type="bibr">(decoding_out,chancelevel,cfg,data) output = externalpackagewrapper (decoding_out.opt,data)</ref></s><s>where output contains all desired output of the external package.</s></p><formula xml:id="formula_1">function output = transres_packageinterface</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOOLBOX VALIDATION: SIMULATIONS AND APPLICATIONS TO fMRI DATA</head><p><s>To demonstrate that TDT works correctly, we validated the toolbox by running a number of analyses on simulated and real data.</s><s>These analyses are not supposed to provide an overview over all capabilities of the toolbox.</s><s>Rather, they are used to illustrate some of the functionalities of TDT.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SIMULATIONS: SEARCHLIGHT ANALYSIS, WHOLE-BRAIN ANALYSIS, REGION-OF-INTEREST ANALYSIS</head><p><s>Simulated data consisted of 48 ellipsoid volumes (31,016 voxels), centered in volumes of 64 × 64 × 16 voxels (Figure <ref type="figure" target="#fig_4">4</ref>).</s><s>Each voxel was assigned independent Gaussian random noise (mean = 0, standard deviation = 1).</s><s>Half of the volumes were assigned to the "noise" category and remained unchanged.</s><s>The other half was assigned to the "signal" category where a pattern was added to axial slice 8.</s><s>This pattern consisted of Gaussian random noise (mean = 0, standard deviation = 0.8).</s><s>The same pattern was added to all signal volumes.</s><s>Data was then split in 8 runs of 6 volumes each, providing three samples per category in each run.</s></p><p><s>Please note that noise is spatially and temporally independent, which is a strong simplification but is sufficient for the purpose of this simulation.</s><s>Additionally, univariate effects are present which is not necessary for classification to work.</s><s>The difference of the mean results is shown in Figure <ref type="figure" target="#fig_4">4A</ref> (left panel).</s></p><p><s>For Simulation 1, we ran a searchlight analysis with a leaveone-run-out cross-validation scheme.</s><s>The searchlight had a radius of 2 voxels, encompassing 27 voxels.</s><s>The classifier was a linear L2-norm SVM with C = 1, in the implementation of LIBSVM <ref type="bibr" target="#b4">(Chang and Lin, 2011)</ref>.</s><s>As output, the mean classification accuracy was returned.</s><s>The results are shown in Figure <ref type="figure" target="#fig_4">4A</ref> (right panel).</s><s>As expected, the accuracies around the signal regions are highly above chance while in other regions they fluctuate around chance-level.</s><s>In addition, Figure <ref type="figure" target="#fig_4">4A</ref> (right panel) illustrates the slight smoothing imposed by the searchlight, where the high SNR spreads the word "TDT" to the neighboring axial slices <ref type="bibr" target="#b13">(Etzel et al., 2013)</ref>.</s></p><p><s>Simulation 2 consisted of two whole-brain analyses that were run on the same simulated data set used for Simulation 1.</s><s>In Simulation 2A, we used all data to generate a weight map, i.e., we did not separate data in training and test sets.</s><s>A weight map indicates the contribution of each voxel to the classification which reflects a combination of signal enhancement and noise suppression.</s><s>As can be seen in Figure <ref type="figure" target="#fig_4">4B</ref> (left panel), the results are similar to the difference in means of the original data, because noise was spatially uncorrelated.</s><s>Simulation 2B used the same leave-one-run-out cross-validation scheme as in the searchlight analysis to achieve one classification accuracy for the entire brain.</s><s>The analysis consisted of an additional nested cross-validation where we conducted recursive feature elimination to identify the set of voxels that is optimally suited for carrying out the classification task.</s><s>Classification performance was at ceiling (100 % accuracy).</s><s>Figure <ref type="figure" target="#fig_4">4B</ref> (right panel) shows how often each voxel is chosen in any of the six cross-validation steps for recursive feature elimination, again clearly favoring signal voxels over noise voxels.</s></p><p><s>In Simulation 3, we ran a region-of-interest (ROI) analysis with two ROIs, where one ROI covered one third of the signal region while the other covered the remaining two thirds (Figure <ref type="figure" target="#fig_4">4C</ref>, left panel).</s><s>Again, we used a leave-one-run out crossvalidation scheme.</s><s>We then continuously varied the amount of signal that was added to the noise.</s><s>As can be seen in Figure <ref type="figure" target="#fig_4">4C</ref> (right panel), the decoding accuracy gradually decreased with decreasing SNR until it reached chance-level when no signal is present.</s><s>In addition, the accuracy in the smaller ROI was generally lower than that in the larger ROI, reflecting the reduced amount of signal present in that region.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VALIDATION ON EMPIRICAL DATA: THE Haxby 2001 DATASET</head><p><s>To validate the toolbox on real imaging data, we used data from a study by <ref type="bibr" target="#b26">Haxby et al. (2001)</ref> which is publicly available (http:// data.pymvpa.org/datasets/haxby2001/). Because of space limitations, we do not use the dataset provided with the toolbox for this article, because it would require more detailed explanation of the experimental paradigm.</s><s><ref type="bibr" target="#b26">Haxby et al. (2001)</ref> investigated processing of images belonging to 8 different object categories in ventral visual cortex.</s><s>Data from six subjects were made available.</s><s>For a complete description of the experimental paradigm and imaging parameters, see the original publication.</s></p><p><s>The experiment consisted of 12 runs where each category was shown once in each run in a 24 s block.</s><s>Data were motion corrected and detrended using SPM12 (http://www.fil.ion.ucl.ac.</s><s>uk/spm/software/spm12/).</s><s>We fitted each block with a canonical hemodynamic response function, yielding one beta image per condition per run and a total of 96 beta images per subject.</s></p><p><s>For the first empirical analysis, we ran a ROI decoding in ventral temporal cortex.</s><s>Our goal was to investigate the classification accuracy and the confusion of the different categories.</s><s>For that purpose, we used the masks provided with the Haxby data set to focus our analysis on ventral temporal cortex.</s><s>The beta images were then submitted to a leave-one-run-out cross-validation scheme, using a one-vs.-one</s><s>multiclass SVM classification approach 2 .</s><s>The output was specified to reveal a confusion matrix comparing the frequency of the predicted label with the true label.</s><s>This approach was repeated for all six subjects and the resulting confusion matrices were averaged.</s><s>The result is shown in Figure <ref type="figure" target="#fig_5">5A</ref>.</s><s>As can be seen, each class could be classified very well, with only little confusion between the classes.</s><s>The results indicate two clusters with larger confusion: Images of faces and cats were confused more often than other categories, and images of inanimate objects were confused more often.</s><s>This could indicate that in ventral visual cortex, faces and cats as well as different inanimate objects are processed more similarly to each other.</s></p><p><s>For the second empirical analysis, we ran a multiclass searchlight analysis on subject 1 from the data set, with a leave-one-run out cross-validation scheme and a searchlight radius of 4 voxels.</s></p><p><s>To assess statistical significance, we ran a permutation test, yielding a critical cut-off of 25 % accuracy (chance-level: 12.5 %) and a cluster size of k = 24 voxels (cluster-level corrected p &lt; 0.001).</s><s>The resulting accuracy maps were masked by the cut-off and are shown in Figure <ref type="figure" target="#fig_5">5B</ref>.</s><s>Large portions of the dorsal and ventral visual cortex carry information about the different categories, with decoding accuracies reaching 62.5 % ventral temporal cortex of subject 1.</s><s>Taken together, these results fit nicely with the known architecture of the visual cortex and reflect the feasibility of the toolbox to reveal information about the content of representations in the human brain.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p><s>We hope that the above illustration of TDT demonstrated the simplicity and general utility of this toolbox for multivariate analysis of functional MRI data.</s><s>In addition, the extensive error checking helps prevent many programming errors and should guide users in how to quickly resolve them.</s><s>We did not go into detail about an additional important feature of TDT that proved helpful to prevent errors: the visualization of the decoding design.</s><s>It shows users at a glance if the cross-validation design they intended to set-up is indeed the one that is computed and if the input data is indeed the data they wanted to use.</s><s>This further facilitates the prevention of unwanted or erroneous analyses.</s><s>To help in getting started, TDT comes with an example dataset an example analysis scripts.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FEATURES NOT CONTAINED IN TDT: PREPROCESSING AND RESULTS VISUALIZATION</head><p><s>When we developed TDT, we initially used it as a tool for conducting searchlight analyses on preprocessed data in order to create individual searchlight accuracy maps that could then be used as input to group-level analyses.</s><s>Later, the toolbox was extended to become more general purpose, adding whole-brain and ROI analyses and more and more machine-learning related utilities.</s><s>Our focus for TDT was on specifically creating a tool that provides users with the means to conduct multivariate decoding.</s><s>Most decoding analyses are carried out on preprocessed data (e.g., spatially realigned or temporally detrended data), but preprocessing is not a part of TDT, as numerous software packages exist that have been created for that purpose, each with their own benefits and drawbacks.</s><s>For example, detrending data or scaling time-series are important steps for single image decoding, but this can be done with popular software packages including SPM, FSL, or AFNI or directly in Matlab with specialized toolboxes.</s><s>The same applies to visualization of results: third-party software can be used for that purpose, for example MRIcron <ref type="bibr" target="#b60">(Rorden, 2007)</ref> to visualize searchlight accuracy maps or weight maps.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPARISON TO EXISTING PACKAGES OF MULTIVARIATE DATA ANALYSIS</head><p><s>A few other toolboxes have been created that can be used to carry out multivariate decoding analyses on fMRI data.</s><s>The key advantages of TDT have been listed in the introduction.</s><s>In general, it is difficult to tell to which degree other toolboxes offer similar advantages, for example where they might be comparably transparent, fast, easy to use, or versatile.</s><s>More objective measures that have been used for comparison purposes have partly underestimated the ability of other toolboxes <ref type="bibr" target="#b63">(Schrouff et al., 2013;</ref><ref type="bibr" target="#b19">Grotegerd et al., 2014)</ref> because the toolboxes might be more elaborate than described on the toolbox websites.</s><s>Rather than thoroughly describing the advantages and disadvantages of all existing toolboxes, we will mention the most widely used and in our view most promising alternative toolboxes and try to elucidate some degree of comparison to TDT.</s></p><p><s>The Princeton MVPA toolbox (http://code.google.com/p/</s><s>princeton-mvpa-toolbox/) is a rather versatile tool with a number of classifiers, basic feature selection capabilities and scaling and the possibility to run searchlight analyses, but it requires a more advanced level of programming skills and to our knowledge is not further developed.</s><s>Another advantage of this toolbox is an active user community.</s><s>TDT on the other hand offers more analysis methods, can be easily extended and due to the multilevel approach is probably easier for getting started.</s><s>The SPM interface of TDT is particularly well suited for users of SPM.</s></p><p><s>The developers of the Princeton MVPA toolbox seem to have shifted their focus to PyMVPA <ref type="bibr">(Hanke et al., 2009a,b)</ref>, a highly versatile programming environment that allows for a large variety of decoding analyses.</s><s>The key advantages of this toolbox are the high level of sophistication, the active user community and the fact that the toolbox does not require third-party software.</s><s>While TDT requires the third-party software Matlab and might not be as versatile in its core functions, PyMVPA also requires more advanced programming skills and for searchlight analyses is much slower than TDT.</s><s>In addition, Matlab is still widespread in the neuroimaging community, and running decoding analyses on SPM results from Python is not straightforward.</s><s>Finally, TDT can also be easily extended if users need additional functionality, which also requires only little programming skills (see Example 3: Extend Toolbox to External Machine Learning Package or More Complex Processing Streams).</s></p><p><s>A more recent development is PRoNTo (Pattern Recognition of Neuroimaging Toolbox, <ref type="bibr" target="#b63">Schrouff et al., 2013)</ref> which has the benefit of a graphical user interface and which also comes with an SPM interface.</s><s>However, the structure of the toolbox is not optimized for searchlight analyses, and parameter selection or feature selection have not been implemented.</s><s>Although TDT does not offer a graphical user interface, we are currently working on an interface through the SPM batch system which should become available with the next release of the toolbox and which obviates any command line programming knowledge.</s></p><p><s>We would also like to mention a toolbox specifically created for carrying out representational similarity analysis (RSA toolbox, <ref type="bibr" target="#b54">Nili et al., 2014)</ref> which can serve as a standard for this type of analysis.</s><s>The capabilities of TDT for representational similarity analysis at the current stage are still much more basic than those of the RSA toolbox.</s><s>However, TDT is in our experience faster than the RSA toolbox, both for searchlight analyses and for creating correlation matrices.</s><s>Users who would like to benefit from the speed of TDT, but use all functionalities of the RSA toolbox might consider using both toolboxes.</s><s>Alternatively, appropriate extensions can be made (see How to Extend the Toolbox) to include many functionalities of the RSA toolbox.</s><s>We are planning to include more representational similarity analysis methods in future versions of TDT.</s></p><p><s>A very recent development under Matlab is CosmoMVPA (http://cosmomvpa.org/) which is still in its very early stage.</s><s>The general structure of the toolbox is quite similar to TDT.</s><s>Rather than creating a cfg in the beginning as is the case for TDT, each option is passed along with the multiple subfunctions that are called.</s><s>The toolbox offers a range of classifiers, allows volumetric and surface-based searchlight analysis and has a basic interface to SPM and other brain analysis software packages.</s><s>The toolbox is easy to use with some intermediate level programming knowledge in Matlab.</s><s>However, CosmoMVPA currently does not offer decoding designs, potentially leading to overlooked mistakes in decoding analyses.</s><s>Due to its novelty, the error management of the toolbox and additional methods such as feature selection and parameter selection are still quite basic.</s><s>Passing parameters along the use of subfunctions also invites mistakes on the side of the user.</s><s>However, it is possible that these current limitations will be changed in future versions of the toolbox.</s></p><p><s>Finally, for completeness we would like to mention additional MVPA software packages for fMRI data: Searchmight (http://www.princeton.edu/∼fpereira/searchmight/)</s><s>which is a dedicated and fast software package for simple searchlight analyses with different classifiers 3 , 3dsvm (http://afni.nimh.</s><s>nih.gov/pub/dist/doc/program_help/3dsvm.html) which is part of the software package AFNI; PROBID (http://www.kcl.ac.</s><s>uk/iop/depts/neuroimaging/research/imaginganalysis/Software/ PROBID.aspx)</s><s>which is specialized for group comparisons, MANIA <ref type="bibr" target="#b19">(Grotegerd et al., 2014)</ref>, and the brain decoder toolbox (http://www.cns.atr.jp/dni/download/brain-decoder-toolbox/).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p><s>TDT offers a user-friendly, yet powerful and flexible framework for the multivariate analysis of brain imaging data.</s><s>The toolbox has many advantages in terms of structure, transparency, speed and error management.</s><s>It comes with an interface to the common brain data analysis software SPM which should make it particularly easy to apply to existing data.</s><s>Beginners can start using the toolbox with one single line of code, which increasingly can be extended to exploit the full functionality of TDT.</s><s>In addition, the toolbox can easily be extended for more general purpose use which allows adding new classifiers, feature selection methods, or even complete external software packages for multivariate data analysis.</s><s>We hope that TDT-through its simplicity and flexibility-will encourage a much broader application of machine learning methods in the analysis of functional imaging data.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LICENSE STATEMENT</head><p><s>TDT can be downloaded from http://www.bccn-berlin.de/tdt.</s><s>The toolbox code is open source, but is licensed as copyright software under the terms of the GNU General Public License (Free Software Foundation).</s><s>In addition, the toolbox comes with thirdparty software (LIBSVM, LIBLINEAR, Newton-SVM, http:// research.cs.wisc.edu/dmi/svm/nsvm/),</s><s>each with their respective copyright.</s><s>TDT has been tested under Windows, Linux, and OS X and works both on 32 and 64 bit systems.</s><s>The toolbox is compatible with Matlab versions R2006b or above and requires no additional Matlab toolboxes.</s><s>It works "out-of-the-box" with an installed version of SPM2, SPM5, SPM8, or SPM12b.</s><s>In addition, we provide an example data set that can be downloaded from the toolbox website.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc><div><p><s>FIGURE 1 | General structure of The Decoding Toolbox (TDT).</s><s>(A)TDT in the view of basic users.</s><s>All that is required are brain images (ideally preprocessed with SPM) and a configuration variable cfg that contains all decoding-relevant information.</s><s>TDT will then generate results, including.</s><s>mat-files with the results or if required brain maps displaying the decoded information in space.</s><s>(B) TDT view for intermediate users.</s><s>Decoding design creation, type of analysis, type of classifier and type of output can be modified.</s><s>All of these settings are necessary for any decoding analysis, which will be set to default settings if not specified by the user.</s><s>This level of description already covers most scenarios that the typical user would encounter.</s><s>(C) All TDT options.</s><s>For the optional functions including feature selection, feature transformation, scaling, and parameter selection, TDT offers a number of preconfigured settings which can be customized.</s><s>Expert users can extend the toolbox to include new methods (e.g., classifiers, feature selection methods) or can even create an interface to external machine learning packages.</s></p></div></figDesc><graphic coords="3,53.94,67.86,226.80,343.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc><div><p><s>) possibly the automatic extraction of data from an existing SPM model.Basic structure: cfg = decoding_defaults(); % optional: initializes cfg with default values ... % additional lines that modify cfg might go here results = decoding(cfg); % Performs decoding Concrete example call:</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 3 |</head><label>3</label><figDesc><div><p><s>FIGURE 3 | Decoding design matrices.</s><s>(A) General structure of a decoding design matrix.</s><s>The vertical dimension represents different samples that are used for decoding, typically brain images or data from regions of interest.</s><s>If multiple images are required to stay together within one cross-validation fold (e.g., runs), this is indicated as a chunk.</s><s>The horizontal axis depicts different cross-validation steps or iterations.</s><s>If groups of iterations should be treated separately, these can be denoted as different sets.</s><s>The color of a square indicates whether in a particular cross-validation step a particular brain image is used.</s><s>(B) Example design for the typical leave-one-run-out cross-validation (function make_design_cv).</s><s>(C) Example design for a leave-one-run-out cross-validation design where there is an imbalance of data in each run.</s><s>To preserve balance, bootstrap samples from each run are drawn (without replacement) to maintain balanced training data (function make_design_boot_cv). (D) Example design for a cross-classification design which does not maintain the leave-one-run-out structure (function make_design_xclass). (E) Example design for a cross-classification design, maintaining the leave-one-run-out structure (function make_design_xclass_cv). (F) Example design for two leave-one-run-out designs with two different sets, in the same decoding analysis.</s><s>The results are reported combined or separately for each set which can speed-up decoding.</s></p></div></figDesc><graphic coords="7,55.42,68.35,481.92,300.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc><div><p><s>(decision_values)); output = 100 * accuracy.</s><s>* dv_norm;</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 4 |</head><label>4</label><figDesc><div><p><s>FIGURE 4 | Results of simulations.</s><s>(A) On the left, the difference of the mean of images belonging to both classes is shown.</s><s>On the right, the results from Simulation 1 (searchlight analysis) are plotted.</s><s>(B) Results from Simulations 2A and 2B.</s><s>The left panel shows the weights of the SVM trained on data in (A).</s><s>On the right, the results from a recursive feature elimination are plotted.</s><s>(C) Results from Simulation 3. The left panel shows the ROIs that were selected.</s><s>The right panel shows decoding accuracies in the two ROIs depending on the SNR.</s></p></div></figDesc><graphic coords="13,311.89,67.99,226.80,348.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FIGURE 5 |</head><label>5</label><figDesc><div><p><s>FIGURE 5 | Results of analyses on Haxby 2001 data set.</s><s>(A) Confusion matrix reflecting the confusion of all eight classes in ventral temporal cortex, averaged across all 6 subjects.</s><s>(B) Searchlight multiclass classification results of subject 1 (permutation p &lt; 0.001, cluster-corrected).</s></p></div></figDesc><graphic coords="14,112.35,458.71,368.40,215.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc><div><p></p></div></figDesc><graphic coords="6,83.85,67.58,425.16,399.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 | Important terminology for multivariate decoding with The Decoding Toolbox. Term Description</head><label>1</label><figDesc><div><p><s>runs chunks, and on each decoding step (also called fold or iteration) one chunk is used as test data to evaluate a classifier trained on all other chunks.</s><s>Typically, the average performance of all decoding steps in terms of classification accuracy is then used to evaluate the classifier.</s><s>Nested cross-validation is cross-validation that is done only on training data to optimize the performance of the classifier (e.g., in feature or parameter selection)</s></p></div></figDesc><table><row><cell>Beta maps</cell><cell>After estimating the general linear model, each regressor in each voxel receives a parameter estimate beta which can be</cell></row><row><cell></cell><cell>used for classification and reflects the fit of the model to the data in form of a regression coefficient. Since each voxel is</cell></row><row><cell></cell><cell>analyzed separately, brain images of betas (i.e., beta maps) are created for each regressor</cell></row><row><cell>Chunk</cell><cell>A unit that determines which data should remain together within a decoding step (often: cross-validation fold). Typically,</cell></row><row><cell></cell><cell>chunks are used to assign run numbers to data, which in cross-validation should ensure that data is independent and not</cell></row><row><cell></cell><cell>biased by temporal autocorrelation. For a typical leave-one-run-out cross-validation, there are as many chunks as there are</cell></row><row><cell></cell><cell>decoding steps. For methods where data samples are drawn repeatedly, the number of decoding steps is often a lot larger</cell></row><row><cell></cell><cell>than the number of chunks</cell></row><row><cell>Cross-classification</cell><cell>Not to be confused with cross-validation. A method to test the stability of a classifier, which can be used (1) to demonstrate</cell></row><row><cell></cell><cell>the generality of a classifier, (2) for a representational association between two cognitive functions, or (3) simply to show</cell></row><row><cell></cell><cell>representational stability across time</cell></row><row><cell>Cross-validation</cell><cell>Method to estimate of how well a classifier generalizes to novel data. In leave-one-run-out cross-validation, data is</cell></row><row><cell></cell><cell>partitioned in n</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc><div><p><s>If the external function creates several outputs, these can be grouped within the variable model.</s><s>The structure for the second function parallels the first and looks as follows:</s></p></div></figDesc><table><row><cell>case 'classification_kernel'</cell></row><row><cell>...</cell></row><row><cell>case 'regression'</cell></row><row><cell>...</cell></row><row><cell>otherwise</cell></row><row><cell>error('...')</cell></row><row><cell>end</cell></row><row><cell>function decoding_out = newclassifier_test</cell></row><row><cell>(labels_test,data_test,cfg,model)</cell></row><row><cell>switch lower(cfg.decoding.method)</cell></row><row><cell>case 'classification'</cell></row><row><cell>[predicted_labels decision_values</cell></row><row><cell>other_output] = your_test_algorithm</cell></row><row><cell>(labels_test,data_test,model,</cell></row><row><cell>cfg.decoding.test.classification.</cell></row><row><cell>model_parameters);</cell></row><row><cell>decoding_out.predicted_labels =</cell></row><row><cell>predicted_labels;</cell></row><row><cell>decoding_out.true_labels = labels_test;</cell></row><row><cell>decoding_out.decision_values =</cell></row><row><cell>decision_values;</cell></row><row><cell>decoding_out.model = model;</cell></row><row><cell>decoding_out.opt = other_output;</cell></row><row><cell>function model = newclassifier_train</cell></row><row><cell>(labels_train,data_train,cfg)</cell></row><row><cell>switch lower(cfg.decoding.method)</cell></row><row><cell>case 'classification'</cell></row><row><cell>model = your_train_algorithm(labels_train,</cell></row><row><cell>data_train,cfg.decoding.train.</cell></row><row><cell>classification.model_parameters)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 4</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 6</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 7</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 8</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 9</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 11</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 12</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 13</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Please note that one-vs.-one multiclass SVM classification usually follows a "winner-takes-all" voting scheme. In case of ties, LIBSVM automatically assigns the first class to the tied output. To circumvent this bias, TDT resolves ties by choosing the class with the maximum decision value over all pairs of comparisons.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 14</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">It is difficult to compare the Searchmight and TDT in terms of speed. Since the major bottleneck in processing speed is the classifier, this will depend crucially on the implementation. For example, Searchmight comes with very fast and dedicated Gaussian Naïve Bayes searchlight capabilities, but at the same time does not pass kernel matrices to LIBSVM which can slow down processing.Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 15</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 16</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 17</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Neuroinformatics www.frontiersin.org January 2015 | Volume 8 | Article 88 | 18</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p><s>The authors declare no conflict of interest.</s><s>We thank Carsten Bogler, Thomas Christophel, Stephan Geuter, Elliott Wimmer and both reviewers for helpful comments on earlier versions of the manuscript.</s><s>We thank the members of the Haynes lab and many volunteers from around the world for trying prepublication releases of the toolbox.</s><s>This work was supported by the "Bernstein Award for Computational Neuroscience" by the German Ministry of Education and Research (BMBF Grant No. 01GQ1006) and by the German Research Foundation (DFG Grant GRK1589/1).</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest Statement:</head><p><s>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA</title>
		<author>
			<persName><forename type="first">C</forename><surname>Allefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.11.043</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="345" to="357" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural correlations, population coding and computation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Averbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn1888</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="358" to="366" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The faces in radiological images: fusiform face area supports radiological expertise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bilalić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grottenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nägele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lindig</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhu272</idno>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The non-invasive Berlin brain-computer interface: fast acquisition of effective performance in untrained subjects</title>
		<author>
			<persName><forename type="first">B</forename><surname>Blankertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dornhege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krauledat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Curio</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2007.01.051</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="539" to="550" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/1961189.1961199</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parietal and early visual cortices encode working memory content across mental transformations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Christophel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cichy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2014.11.018</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Decoding complex flowfield patterns in visual working memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Christophel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2014.01.025</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="43" to="51" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Decoding the contents of visual short-term memory from human visual and parietal cortex</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Christophel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0184-12.2012</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="12983" to="12989" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00994018</idno>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Functional magnetic resonance imaging (fMRI)&quot;brain reading&quot;: detecting and classifying distributed patterns of fMRI activity in human visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Savoy</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1053-8119(03)00049-1</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="261" to="270" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Identification of conversion from mild cognitive impairment to Alzheimer&apos;s disease using multivariate predictors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0021896</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">e21896</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining multivariate voxel selection and support vector machines for mapping and classification of fMRI spatial patterns</title>
		<author>
			<persName><forename type="first">De</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Staeren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Formisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2008.06.037</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="44" to="58" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An introduction to anatomical ROI-based fMRI classification analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Etzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gazzola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Keysers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.brainres.2009.05.090</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Res</title>
		<imprint>
			<biblScope unit="volume">1282</biblScope>
			<biblScope unit="page" from="114" to="125" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Searchlight analysis: promise, pitfalls, and potential</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Etzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Braver</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.03.041</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="261" to="269" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">LIBLINEAR: a library for large linear classification</title>
		<author>
			<persName><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1442794" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multivariate analysis of fMRI time series: classification and regression of brain responses using machine learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Formisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Valente</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.mri.2008.01.052</idno>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="921" to="934" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Statistical parametric maps in functional imaging: a general linear approach. Hum</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Worsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Poline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Frackowiak</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.460020402</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="189" to="210" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A critique of functional localisers</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rotshtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Henson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2005.08.012</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1077" to="1087" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The consequences of subtracting the mean pattern in fMRI multivariate correlation analyses</title>
		<author>
			<persName><forename type="first">L</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vaziri-Pashkam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilmer</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2013.00174</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">174</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MANIA-A pattern classification toolbox for neuroimaging data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grotegerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Redlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riemenschneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kugel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Arolt</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12021-014-9223-8</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="471" to="486" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Non-holistic coding of objects in lateral occipital complex with and without attention</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guggenmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cichy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Richardson-Klavehn</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2014.12.013</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An introduction to variable and feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=944968" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Feature Extraction: Foundations and Applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nikravesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zadeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">PyMVPA: a python toolbox for multivariate pattern analysis of fMRI data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">O</forename><surname>Halchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Sederberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pollmann</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12021-008-9041-y</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="37" to="53" />
			<date type="published" when="2009">2009a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PyMVPA: a unifying approach to the analysis of neuroscientific data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">O</forename><surname>Halchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Sederberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Olivetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fründ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Rieger</surname></persName>
		</author>
		<idno type="DOI">10.3389/neuro.11.003.2009</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Neuroinform</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2009">2009b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the interpretation of weight vectors of linear models in multivariate neuroimaging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haufe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Görgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dähne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Blankertz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.10.067</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="96" to="110" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distributed and overlapping representations of faces and objects in ventral temporal cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Gobbini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Furey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ishai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Schouten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pietrini</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1063736</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="2425" to="2430" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A common, high-dimensional model of the representational space in human ventral temporal cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Guntupalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Connolly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">O</forename><surname>Halchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Gobbini</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2011.08.026</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="404" to="416" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decoding mental states from brain activity in humans</title>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rees</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
		<idno type="DOI">10.1038/nrn1931</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="523" to="534" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reading hidden intentions in the human brain</title>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Passingham</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2006.11.072</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="323" to="328" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Human visual and parietal cortex encode visual choices independent of motor plans</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Donner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2012.08.027</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1393" to="1403" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The relationship between perceptual decision variables and confidence in the human brain</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Schriever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Donner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhu181</idno>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex bhu181</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Differential BOLD activity associated with subjective and objective reports during &quot;blindsight&quot; in normal observers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hesselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malach</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1556-11.2011</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="12936" to="12944" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Neural decoding of visual imagery during sleep</title>
		<author>
			<persName><forename type="first">T</forename><surname>Horikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyawaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamitani</surname></persName>
		</author>
		<idno type="DOI">10.1126/sci-ence.1234330</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">340</biblScope>
			<biblScope unit="page" from="639" to="642" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The fusiform face area: a module in human extrastriate cortex specialized for face perception</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Chun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="4302" to="4311" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pattern-information analysis: from stimulus decoding to computational-model testing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2011.01.061</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="411" to="421" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Individual faces elicit distinct response patterns in human anterior temporal cortex</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Formisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sorger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goebel</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0705654104</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="20600" to="20605" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Information-based functional brain mapping</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bandettini</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0600244103</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="3863" to="3868" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Representational similarity analysis-Connecting the branches of systems neuroscience</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bandettini</surname></persName>
		</author>
		<idno type="DOI">10.3389/neuro.06.004.2008</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Syst. Neurosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Circular analysis in systems neuroscience: the dangers of double dipping</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Bellgowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.2303</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="535" to="540" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Comparison of pattern recognition methods in classifying high-resolution BOLD signals obtained at high magnetic field in monkeys</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Macke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.mri.2008.02.016</idno>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1007" to="1014" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Introduction to machine learning for brain imaging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lemm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Blankertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dickhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2010.11.004</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="387" to="399" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Feature Extraction, Construction and Selection: A Data Mining Perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neurophysiological investigation of the basis of the fMRI signal</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pauls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Augath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Trinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oeltermann</surname></persName>
		</author>
		<idno type="DOI">10.1038/35084005</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">412</biblScope>
			<biblScope unit="page" from="150" to="157" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Investigating category-and shape-selective neural processing in ventral and dorsal visual stream under interocular suppression. Hum</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kathmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hesselmann</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.22618</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="137" to="149" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Comparison of multivariate classifiers and response normalizations for pattern-information fMRI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Misaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Bandettini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2010.05.051</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="103" to="118" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dynamic discrimination analysis: a spatial-temporal SVM</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mourão-Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brammer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2007.02.020</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="88" to="99" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The impact of temporal compression and space selection on SVM analysis of single-subject and multi-subject fMRI data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mourão-Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reynaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcglone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Calvert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brammer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2006.08.016</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1055" to="1065" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An introduction to kernel-based learning algorithms</title>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<idno type="DOI">10.1109/72.914517</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Netw. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="181" to="201" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</title>
		<idno type="DOI">10.1016/j.neuroimage.2011.08.076</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="2636" to="2643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Encoding and decoding in fMRI</title>
		<author>
			<persName><forename type="first">T</forename><surname>Naselaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nishimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Gallant</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2010.07.073</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="400" to="410" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unraveling the distributed neural code of facial identity through spatiotemporal pattern analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nestor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Plaut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Behrmann</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1102433108</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="9998" to="10003" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Nonparametric permutation tests for functional neuroimaging: a primer with examples. Hum</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Holmes</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.1058</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A toolbox for representational similarity analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wingfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Marslen-Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1003553</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">e1003553</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Biased binomial assessment of cross-validated estimation of classification accuracies illustrated in diagnosis predictions</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Noirhomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lesenfants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soddu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Garraux</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nicl.2014.04.004</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage Clin</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="687" to="694" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Beyond mind-reading: multi-voxel pattern analysis of fMRI data</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Polyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Detre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2006.07.005</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="424" to="430" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Machine learning classifiers and fMRI: a tutorial overview</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2008.11.007</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="S199" to="S209" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Distributed representations of rule identity and rule order in human frontal cortex and striatum</title>
		<author>
			<persName><forename type="first">C</forename><surname>Reverberi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Görgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2344-12.2012</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="17420" to="17430" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Representation of spatial information in key areas of the descending pain modulatory system</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolbers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Bingel</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.4342-13.2014</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="4634" to="4639" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Rorden</surname></persName>
		</author>
		<ptr target="http://www.mccauslandcenter.sc.edu/mricro/mricron/" />
		<title level="m">MRIcron. Available online at</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Extracting support data for a given task</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings, First International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>First International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>Menlo Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The Statistical Analysis of Multi-Voxel Patterns in Functional Imaging</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krekelberg</surname></persName>
		</author>
		<idno type="DOI">10.1371/jour-nal.pone.0069328</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">e69328</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">PRoNTo: pattern recognition for neuroimaging toolbox</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rondina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Marquand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12021-013-9178-1</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="319" to="337" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The coding of color, motion, and their conjunction in the human visual cortex</title>
		<author>
			<persName><forename type="first">K</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bartels</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2008.12.050</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="177" to="183" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The SHOGUN machine learning toolbox</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Widmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Behr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1859911" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1799" to="1802" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis (MVPA): random permutations and cluster size control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stelzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2012.09.063</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="69" to="82" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B Methodol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Decoding pattern motion information in V1</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Van Kemenade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Christophel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rothkirch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2014.04.014</idno>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="177" to="187" />
			<date type="published" when="2014">2014a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Tactile and visual motion direction processing in hMT+/V5</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Van Kemenade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Blankenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.09.004</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="420" to="427" />
			<date type="published" when="2014">2014b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">MRI pattern recognition in multiple sclerosis normal-appearing brain areas</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weygandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hackmack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pfüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bellmann-Strobl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zipp</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0021138</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">e21138</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
