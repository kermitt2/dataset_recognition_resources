<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-07-10">July 10, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Bach</surname></persName>
							<email>sebastian.bach@hhi.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Fraunhofer Heinrich Hertz Institute</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Binder</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">ISTD Pillar</orgName>
								<orgName type="institution">University of Technology and Design (SUTD)</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frederick</forename><surname>Klauschen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Charité University Hospital</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Brain and Cognitive Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
							<email>wojciech.samek@hhi.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Fraunhofer Heinrich Hertz Institute</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<settlement>Berlin, Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Universidad de Castilla-La Mancha</orgName>
								<address>
									<country key="ES">SPAIN</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-07-10">July 10, 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">D18810A5E7C19741A0938316D5FDA90C</idno>
					<idno type="DOI">10.1371/journal.pone.0130140</idno>
					<note type="submission">Received: May 19, 2014 Accepted: May 15, 2015</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2-SNAPSHOT" ident="GROBID" when="2022-05-18T11:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert.</s><s>Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision.</s><s>This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers.</s><s>We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks.</s><s>These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest.</s><s>We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p><s>Classification of images has become a key ingredient in many computer vision applications, e.g.</s><s>image search <ref type="bibr" target="#b0">[1]</ref>, robotics <ref type="bibr" target="#b2">[2]</ref>, medical imaging <ref type="bibr" target="#b3">[3]</ref>, object detection in radar images <ref type="bibr" target="#b4">[4]</ref> or face detection <ref type="bibr" target="#b5">[5]</ref>.</s><s>Two particularly popular approaches, neural networks <ref type="bibr" target="#b6">[6]</ref> and Bag of Words (BoW) models <ref type="bibr" target="#b7">[7]</ref>, are widely used for these tasks and were among the top submissions in competitions on image classification and ranking such as ImageNet <ref type="bibr" target="#b8">[8]</ref>, Pascal VOC <ref type="bibr" target="#b9">[9]</ref> and Image-CLEF <ref type="bibr" target="#b10">[10]</ref>.</s><s>However, like many methods in machine learning, these models often lack a straightforward interpretability of the classifier predictions.</s><s>In other words the classifier acts as a black box and does not provide detailed information about why it reaches a certain classification decision.</s></p><p><s>This lack of interpretability is due to the non-linearity of the various mappings that process the raw image pixels to its feature representation and from that to the final classifier function.</s><s>This is a considerable drawback in classification applications, as it hinders the human experts to carefully verify the classification decision.</s><s>A simple yes or no answer is sometimes of limited value in applications, where questions like where something occurs or how it is structured are more relevant than a binary or real-valued one-dimensional assessment of mere presence or absence of a certain structure.</s></p><p><s>In this work, we aim to close the gap between classification and interpretability both for multilayered neural networks and Bag of Words (BoW) models over non-linear kernels which are two classes of predictors which enjoy popularity in computer vision.</s><s>We will consider both types of predictors in a generic sense trying to avoid whenever possible a priori restrictions to specific algorithms or mappings.</s><s>For the first part, the Bag of Words models will be treated as an aggregation of non-linear mappings over local features in an image which includes a number of popular mapping methods such as Fisher vectors <ref type="bibr" target="#b11">[11]</ref>, regularized coding <ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref><ref type="bibr" target="#b14">[14]</ref> and soft coding <ref type="bibr" target="#b15">[15]</ref>, combined with differentiable non-linear kernels and a range of pooling functions including sum-and max-pooling.</s><s>For the second part, the neural networks (e.g.</s><s><ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b16">16]</ref>), we will consider general multilayered network structures with arbitrary continuous neurons and pooling functions based on generalized p-means.</s></p><p><s>The next Section Pixel-wise Decomposition as a General Concept will explain the basic approaches underlying the pixel-wise decomposition of classifiers.</s><s>In Section Bag of Words models revisited, we will give a short recapitulation about Bag of Words features and kernelbased classifiers and summarize related work.</s><s>Overview of the decomposition steps will discuss the decomposition of a kernel-based classifier into sums of scores over small regions of the image, and the projection down to single pixels.</s><s>Our method then is applied to a number of popular mappings and kernels in Section Examples for various mappings and kernels.</s><s>Pixelwise Decomposition for Multilayer Networks applies both the Taylor-based and layer-wise relevance propagation approaches explained in Pixel-wise Decomposition as a General Concept to neural network architectures.</s><s>The experimental evaluation of our framework will be done in Experiments and we conclude the paper with a discussion in Discussion.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pixel-wise Decomposition as a General Concept</head><p><s>The overall idea of pixel-wise decomposition is to understand the contribution of a single pixel of an image x to the prediction f(x) made by a classifier f in an image classification task.</s><s>We would like to find out, separately for each image x, which pixels contribute to what extent to a positive or negative classification result.</s><s>Furthermore we want to express this extent quantitatively by a measure.</s><s>We assume that the classifier has real-valued outputs which are thresholded at zero.</s><s>In such a setup it is a mapping f : R V !</s><s>R 1 such that f(x) &gt; 0 denotes presence of the learned structure.</s><s>Probabilistic outputs can be treated without loss of generality by subtracting 0.5.</s><s>We are interested to find out the contribution of each input pixel x (d) of an input image x to a particular prediction f(x).</s><s>The important constraint specific to classification consists in finding the differential contribution relative to the state of maximal uncertainty with respect to classification which is then represented by the set of root points f(x 0 ) = 0.</s><s>One possible way is to decompose the prediction f(x) as a sum of terms of the separate input dimensions 16BY1145).</s><s>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s><s>AB and KRM were partially funded by http://www.bmwi.de/EN/root.html</s><s>(grant no.</s><s>01MQ07018).</s><s>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s><s>KRM was partially funded by the BK21 program of the National Research Foundation of Korea in the Brain Korea 21 program (http://www.nrf.re.kr/nrf eng cms/, -no grant number available), and partially funded by the German Ministry for Education and Research as Berlin Big Data Center BBDC, funding mark 01IS14013A.</s><s>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s><s>GM is funded as an employee of the Machine Learning Group of the TU Berlin, http://www.ml.tu-berlin.de/</s><s>(research/teaching), http://www.tu-berlin.de/</s><s>(no grant number available).</s><s>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s><s>FK is funded by the Human Frontier Science Program (http://www.hfsp.org/,</s><s>grant no.</s><s>RGY0077/2011).</s><s>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s><s>WS was funded by the Federal Ministry of Education and Research (BMBF, http:// www.bmbf.de/)</s><s>under the project Adaptive BCI, grant no.</s><s>01GQ1115.</s><s>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s></p><p><s>Competing Interests: The authors of this manuscript have read the journal's policy and have the following competing interests: AB, FK, and KRM have a pending patent application: http://www.google.com/</s><s>patents/WO2013037983A1?cl = en and http://www.</s><s>google.com/patents/EP2570970A1?cl = en.</s><s>This patent deals with pixel-wise visualization of bag of words features.</s><s>This patent does not deal with artificial neural networks.</s><s>The authors submitted a second patent application, "RELEVANCE SCORE ASSIGNMENT FOR ARTIFICIAL NEURAL NETWORKS" with the provisional application number PCT/EP2015/056008.</s><s>The hereby confirm that this does not alter their adherence to PLOS ONE policies on sharing data and materials.</s><s>All other authors (SB, GM, WS) have declared that no competing interests exist on their behalf.</s></p><p><s>x d respectively pixels:</s></p><formula xml:id="formula_0">f ðxÞ % X V d¼1 R d<label>ð1Þ</label></formula><p><s>The qualitative interpretation is that R d &lt; 0 contributes evidence against the presence of a structure which is to be classified while R d &gt; 0 contributes evidence for its presence.</s><s>In terms of subsequent visualization, which however will not be the scope of this paper, the resulting relevances R d for each input pixel x (d) can be mapped to a color space and visualized in that way as a conventional heatmap.</s><s>One basic constraint will be in the following work that the signs of R d should follow above qualitative interpretation, i.e. positive values should denote positive contributions, negative values negative contributions.</s><s>Fig <ref type="figure" target="#fig_0">1</ref> depicts the main idea of our method.</s></p><p><s>In this paper we propose a novel concept we denote as layer-wise relevance propagation as a general concept for the purpose of achieving a pixel-wise decomposition as in Eq <ref type="bibr" target="#b0">(1)</ref>.</s><s>We also discuss an approach based on Taylor decomposition which yields an approximation of layerwise relevance propagation.</s><s>We will show that for a wide range of non-linear classification architectures, layer-wise relevance propagation can be done without the need to use an approximation by means of Taylor expansion.</s><s>The methods we propose in this paper do not involve segmentation.</s><s>They do not require pixel-wise training as learning setup or pixel-wise labeling for the training phase.</s><s>The setup used here is image-wise classification, in which during training one label is provided for an image as a whole, however, the contribution of this paper is not about classifier training.</s><s>The proposed methods are built on top of a pre-trained classifier.</s><s>They are even applicable to an already pre-trained image classifier as shown in Section Neural Network for 1000 ILSVRC classes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Layer-wise relevance propagation</head><p><s>We will introduce layer-wise relevance propagation as a concept defined by a set of constraints.</s><s>Any solution satisfying the constraints will be considered to follow the concept of layer-wise relevance propagation.</s><s>In later sections we will then derive solutions for two particular classifier architectures and evaluate these solutions experimentally for their meaningfulness.</s><s>Layer- Visualization of the pixel-wise decomposition process.</s><s>In the classification step the image is converted to a feature vector representation and a classifier is applied to assign the image to a given category, e.g., "cat" or "no cat".</s><s>Note that the computation of the feature vector usually involves the usage of several intermediate representations.</s><s>Our method decomposes the classification output f(x) into sums of feature and pixel relevance scores.</s><s>The final relevances visualize the contributions of single pixels to the prediction.</s><s>Cat image by pixabay user stinne24.</s><s>doi:10.1371/journal.pone.0130140.g001</s><s>wise relevance propagation in its general form assumes that the classifier can be decomposed into several layers of computation.</s><s>Such layers can be parts of the feature extraction from the image or parts of a classification algorithm run on the computed features.</s><s>As shown later, this is possible for Bag of Words features with non-linear SVMs as well as for neural networks.</s></p><p><s>The first layer are the inputs, the pixels of the image, the last layer is the real-valued prediction output of the classifier f.</s><s>The l-th layer is modeled as a vector z ¼ ðz ðlÞ d Þ VðlÞ d¼1 with dimensionality V(l).</s><s>Layer-wise relevance propagation assumes that we have a Relevance score R ðlþ1Þ d for each dimension z ðlþ1Þ d of the vector z at layer l + 1.</s><s>The idea is to find a Relevance score R ðlÞ d for each dimension z ðlÞ d of the vector z at the next layer l which is closer to the input layer such that the following equation holds.</s></p><formula xml:id="formula_1">f ðxÞ ¼ Á Á Á ¼ X d2lþ1 R ðlþ1Þ d ¼ X d2l R ðlÞ d ¼ Á Á Á ¼ X d R<label>ð1Þ</label></formula><formula xml:id="formula_2">d<label>ð2Þ</label></formula><p><s>Iterating Eq (2) from the last layer which is the classifier output f(x) down to the input layer x consisting of image pixels then yields the desired Eq <ref type="bibr" target="#b0">(1)</ref>.</s><s>The Relevance for the input layer will serve as the desired sum decomposition in Eq <ref type="bibr" target="#b0">(1)</ref>.</s><s>In the following we will derive further constraints beyond Eqs (1) and ( <ref type="formula" target="#formula_2">2</ref>) and motivate them by examples.</s><s>As we will show now, a decomposition satisfying Eq (2) per se is neither unique, nor it is guaranteed that it yields a meaningful interpretation of the classifier prediction.</s></p><p><s>We give here a simple counterexample.</s><s>Suppose we have one layer.</s><s>The inputs are x 2 R V .</s><s>We use a linear classifier with some arbitrary and dimension-specific feature space mapping ϕ d and a bias b</s></p><formula xml:id="formula_3">f ðxÞ ¼ b þ X d a d d ðx d Þ<label>ð3Þ</label></formula><p><s>Let us define the relevance for the second layer trivially as R ð2Þ 1 ¼ f ðxÞ.</s><s>Then, one possible layer-wise relevance propagation formula would be to define the relevance R (1) for the inputs x as</s></p><formula xml:id="formula_4">R ð1Þ d ¼ f ðxÞ ja d d ðx d Þj P d ja d d ðx d Þj if P d ja d d ðx d Þj 6 ¼ 0 b V if P d ja d d ðx d Þj ¼ 0<label>ð4Þ</label></formula><formula xml:id="formula_5">8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :</formula><p><s>This clearly satisfies Eqs (1) and ( <ref type="formula" target="#formula_2">2</ref>), however the Relevances R (1) (x d ) of all input dimensions have the same sign as the prediction f(x).</s><s>In terms of pixel-wise decomposition interpretation, all inputs point towards the presence of a structure if f(x) &gt; 0 and towards the absence of a structure if f(x) &lt; 0. This is for many classification problems not a realistic interpretation.</s></p><p><s>Let us discuss a more meaningful way of defining layer-wise relevance propagation.</s><s>For this example we define</s></p><formula xml:id="formula_6">R ð1Þ d ¼ b V þ a d d ðx d Þ<label>ð5Þ</label></formula><p><s>Then, the relevance of a feature dimension x d depends on the sign of the term in Eq <ref type="bibr" target="#b5">(5)</ref>.</s><s>This is for many classification problems a more plausible interpretation.</s><s>This second example shows that the layer-wise relevance propagation is able to deal with non-linearities such as the feature space mapping ϕ d to some extent and how an example of layer-wise relevance propagation satisfying Formula (2) may look like in practice.</s><s>Note that no regularity assumption on the feature space mapping ϕ d is required here at all, it could be even non-continuous, or non-measurable under the Lebesgue measure.</s><s>The underlying Formula (2) can be interpreted as a conservation law for the relevance R in between layers of the feature processing.</s></p><p><s>The above example gives furthermore an intuition about what relevance R is, namely, the local contribution to the prediction function f(x).</s><s>In that sense the relevance of the output layer is the prediction itself f(x).</s><s>This first example shows what one could expect as a decomposition for the linear case.</s><s>The linear case is not a novelty, however, it provides a first intuition.</s></p><p><s>We give a second, more graphic and non-linear, example.</s><s>The left panel of Fig <ref type="figure" target="#fig_1">2</ref> shows a neural network-shaped classifier with neurons and weights w ij on connections between neurons.</s><s>Each neuron i has an output a i from an activation function.</s></p><p><s>The top layer consists of one output neuron, indexed by 7.</s><s>For each neuron i we would like to compute a relevance R i .</s><s>We initialize the top layer relevance R ð3Þ 7 as the function value, thus R ð3Þ 7 ¼ f ðxÞ.</s><s>Layer-wise relevance propagation in Eq (2) requires now to hold</s></p><formula xml:id="formula_7">R ð3Þ 7 ¼ R ð2Þ 4 þ R ð2Þ 5 þ R<label>ð2Þ</label></formula><formula xml:id="formula_8">6 ð6Þ R<label>ð2Þ</label></formula><formula xml:id="formula_9">4 þ R ð2Þ 5 þ R ð2Þ 6 ¼ R ð1Þ 1 þ R ð1Þ 2 þ R ð1Þ 3<label>ð7Þ</label></formula><p><s>We will make two assumptions for this example.</s><s>Firstly, we express the layer-wise relevance in terms of messages R ðl;lþ1Þ i j between neurons i and j which can be sent along each connection.</s><s>The messages are, however, directed from a neuron towards its input neurons, in contrast to what happens at prediction time, as shown in the right panel of Fig 2 <ref type="figure">.</ref></s><s>Secondly, we define the relevance of any neuron except neuron 7 as the sum of incoming messages:</s></p><formula xml:id="formula_10">R ðlÞ i ¼ X k: i is input for neuron k R ðl;lþ1Þ i k<label>ð8Þ</label></formula><p><s>For example R ð1Þ 3 ¼ R ð1;2Þ 3 5 þ R ð1;2Þ 3 6 .</s><s>Note that neuron 7 has no incoming messages anyway.</s><s>Instead its relevance is defined as R ð3Þ 7 ¼ f ðxÞ.</s><s>In Eq <ref type="bibr" target="#b8">(8)</ref> and the following text the terms input and source have the meaning of being an input to another neuron in the direction as defined during classification time, not during the time of computation of layer-wise relevance i is the relevance of neuron i which is to be computed.</s><s>In order to facilitate the computation of R ðlÞ i we introduce messages R ðl;lþ1Þ i j .</s><s>R ðl;lþ1Þ i j are messages which need to be computed such that the layer-wise relevance in Eq (2) is conserved.</s><s>The messages are sent from a neuron i to its input neurons j via the connections used for classification, e.g. 2 is an input neuron for neurons 4, 5, 6. Neuron 3 is an input neuron for 5, 6. Neurons 4, 5, 6 are the input for neuron 7. doi:10.1371/journal.pone.0130140.g002</s></p><p><s>propagation.</s><s>For example in Fig 2 <ref type="figure">neurons</ref> 1 and 2 are inputs and source for neuron 4, while neuron 6 is the sink for neurons 2 and 3. Given the two assumptions encoded in Eq <ref type="bibr" target="#b8">(8)</ref>, the layer-wise relevance propagation by Eq (2) can be satisfied by the following sufficient condition:</s></p><formula xml:id="formula_11">R ð3Þ 7 ¼ R ð2;3Þ 4 7 þ R ð2;3Þ 5 7 þ R ð2;3Þ 6 7<label>ð9Þ</label></formula><formula xml:id="formula_12">R ð2Þ 4 ¼ R ð1;2Þ 1 4 þ R ð1;2Þ 2 4<label>ð10Þ</label></formula><formula xml:id="formula_13">R ð2Þ 5 ¼ R ð1;2Þ 1 5 þ R ð1;2Þ 2 5 þ R ð1;2Þ 3 5<label>ð11Þ</label></formula><formula xml:id="formula_14">R ð2Þ 6 ¼ R ð1;2Þ 2 6 þ R ð1;2Þ 3 6<label>ð12Þ</label></formula><p><s>In general, this condition can be expressed as:</s></p><formula xml:id="formula_15">R ðlþ1Þ k ¼ X i: i is input for neuron k R ðl;lþ1Þ i k<label>ð13Þ</label></formula><p><s>The difference between condition (13) and definition <ref type="bibr" target="#b8">(8)</ref> is that in the condition (13) the sum runs over the sources at layer l for a fixed neuron k at layer l+1, while in the definition (8) the sum runs over the sinks at layer l+1 for a fixed neuron i at a layer l.</s><s>When using Eq <ref type="bibr" target="#b8">(8)</ref> to define the relevance of a neuron from its messages, then condition ( <ref type="formula" target="#formula_15">13</ref>) is a sufficient condition in order to ensure that Eq (2) holds.</s><s>Summing over the left hand side in Eq <ref type="bibr" target="#b13">(13)</ref> yields</s></p><formula xml:id="formula_16">X k R ðlþ1Þ k ¼ X k X i: i is input for neuron k R ðl;lþ1Þ i k ¼ X i X k: i is input for neuron k R ðl;lþ1Þ i k ¼ eq:<label>ð8Þ</label></formula><formula xml:id="formula_17">X i R<label>ðlÞ</label></formula><p><s>i One can interpret condition <ref type="bibr" target="#b13">(13)</ref> by saying that the messages R ðl;lþ1Þ i k are used to distribute the relevance R ðlþ1Þ k of a neuron k onto its input neurons at layer l.</s><s>Our work in the following sections will be based on this notion and the more strict form of relevance conservation as given by definition <ref type="bibr" target="#b8">(8)</ref> and condition <ref type="bibr" target="#b13">(13)</ref>.</s><s>We set Eqs <ref type="bibr" target="#b8">(8)</ref> and <ref type="bibr" target="#b13">(13)</ref> as the main constraints defining layer-wise relevance propagation.</s><s>A solution following this concept is required to define the messages R ðl;lþ1Þ i k according to these equations.</s><s>Now we can derive an explicit formula for layer-wise relevance propagation for our example by defining the messages R ðl;lþ1Þ i k .</s><s>The layer-wise relevance propagation should reflect the messages passed during classification time.</s><s>We know that during classification time, a neuron i inputs a i w ik to neuron k, provided that i has a forward connection to k.</s><s>Thus, we can rewrite the left hand sides of Eqs ( <ref type="formula" target="#formula_11">9</ref>) and <ref type="bibr" target="#b10">(10)</ref> so that it matches the structure of the right hand sides of the same equations by the following</s></p><formula xml:id="formula_18">R ð3Þ 7 ¼ R<label>ð3Þ</label></formula><formula xml:id="formula_19">R ð2Þ 4 ¼ R<label>ð14Þ</label></formula><formula xml:id="formula_20">4 a 1 w 14 P i¼1;2 a i w i4 þ R<label>ð2Þ</label></formula><formula xml:id="formula_21">4 a 2 w 24 P i¼1;2 a i w i4<label>ð2Þ</label></formula><p><s>The match of the right hand sides of Eqs ( <ref type="formula" target="#formula_11">9</ref>) and ( <ref type="formula" target="#formula_12">10</ref>) against the right hand sides of ( <ref type="formula" target="#formula_19">14</ref>) and ( <ref type="formula" target="#formula_22">15</ref>) can be expressed in general as</s></p><formula xml:id="formula_23">R ðl;lþ1Þ i k ¼ R<label>ðlþ1Þ</label></formula><formula xml:id="formula_24">k a i w ik P h a h w hk<label>ð16Þ</label></formula><p><s>While this solution <ref type="bibr" target="#b16">(16)</ref> for message terms R ðl;lþ1Þ i k still needs to be adapted such that it is usable when the denominator becomes zero, the example given in Eq <ref type="bibr" target="#b16">(16)</ref> gives an idea what a message R ðl;lþ1Þ i k could be, namely the relevance of a sink neuron R ðlþ1Þ k which has been already computed, weighted proportionally by the input of the neuron i from the preceding layer l.</s><s>This notion holds in an analogous way when we use different classification architectures and replace the notion of a neuron by a dimension of a feature vector at a given layer.</s></p><p><s>The Formula ( <ref type="formula" target="#formula_24">16</ref>) has a second property: The sign of the relevance sent by message R ðl;lþ1Þ i k becomes inverted if the contribution of a neuron a i w ik has different sign then the sum of the contributions from all input neurons, i.e. if the neuron fires against the overall trend for the top neuron from which it inherits a portion of the relevance.</s><s>Same as for the example with the linear mapping in Eq <ref type="bibr" target="#b5">(5)</ref>, an input neuron can inherit positive or negative relevance depending on its input sign.</s><s>This is a difference to the Eq (4).</s><s>While this sign switching property can be defined analogously for a range of architectures, we do not add it as a constraint for layer-wise relevance propagation.</s><s>One further property is visible here as well.</s><s>The formula for distribution of relevance is applicable to non-linear and even non-differentiable or non-continuous neuron activations a k .</s><s>An algorithm would start with relevances R (l+1) of layer l+1 which have been computed already.</s><s>Then the messages R ðl;lþ1Þ i k would be computed for all elements k from layer l+1 and elements i from the preceding layer l-in a manner such that Eq (13) holds.</s><s>Then definition <ref type="bibr" target="#b8">(8)</ref> would be used to define the relevances R (l) for all elements of layer l.</s></p><p><s>The relevance conservation property can in principle be supplemented by other constraints that further reduce the set of admissible solutions.</s><s>For example, one could constrain relevance messages R ðl;lþ1Þ i k that result from the redistribution of relevance onto lower-level nodes in a way that is consistent with the contribution of lower-level nodes to the upper layer during the forward pass.</s><s>If a node i has a larger weighted activation z ik = a i w ik , then, in a qualitative sense, it should also receive a larger fraction of the relevance score R ðlþ1Þ k of the node k.</s><s>In particular, for all nodes k satisfying R k , ∑ i z ik &gt; 0, one can define the constraint 0 &lt; z ik &lt; z i 0 k ) R ðl;lþ1Þ i k R ðl;lþ1Þ i 0 k .</s><s>(The formulas provided in section Pixel-wise Decomposition for Multilayer Networks adhere to this ordering constraint.)</s><s>Nevertheless, nothing is said about the exact relevance values beyond their adherence to the constraint stated above.</s></p><p><s>To summarize, we have introduced layer-wise relevance propagation in a feed-forward network.</s><s>In our proposed definition, the total relevance is constrained to be preserved from one layer to another, and the total node relevance must be the equal to the sum of all relevance messages incoming to this node and also equal to the sum of all relevance messages that are outgoing to the same node.</s><s>It is important to note that the definition is not given as an algorithm or a solution of an objective with a distinct minimum.</s><s>Instead, it is given as a set of constraints that the solution should satisfy.</s><s>Thus, different algorithms with different resulting solutions may be admissible under these constraints.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taylor-type decomposition</head><p><s>One alternative approach for achieving a decomposition as in (1) for a general differentiable predictor f is first order Taylor approximation.</s></p><formula xml:id="formula_25">f ðxÞ % f ðx 0 Þ þ Df ðx 0 Þ½x À x 0 ¼ f ðx 0 Þ þ X V d¼1 @f @x ðdÞ ðx 0 Þðx ðdÞ À x 0ðdÞ Þ<label>ð17Þ</label></formula><p><s>The choice of a Taylor base point x 0 is a free parameter in this setup.</s><s>As said above, in case of classification we are interested to find out the contribution of each pixel relative to the state of maximal uncertainty of the prediction which is given by the set of points f(x 0 ) = 0, since f(x) &gt; 0 denotes presence and f(x) &lt; 0 absence of the learned structure.</s><s>Thus, x 0 should be chosen to be a root of the predictor f.</s><s>For the sake of precision of the Taylor approximation of the prediction, x 0 should be chosen to be close to x under the Euclidean norm in order to minimize the Taylor residuum according to higher order Taylor approximations.</s><s>In case of multiple existing roots x 0 with minimal norm, they can be averaged or integrated in order to get an average over all these solutions.</s><s>The above equation simplifies to</s></p><formula xml:id="formula_26">f ðxÞ % X V d¼1 @f @x ðdÞ ðx 0 Þðx ðdÞ À x 0ðdÞ Þ such that f ðx 0 Þ ¼ 0<label>ð18Þ</label></formula><p><s>The pixel-wise decomposition contains a non-linear dependence on the prediction point x beyond the Taylor series, as a close root point x 0 needs to be found.</s><s>Thus the whole pixel-wise decomposition is not a linear, but a locally linear algorithm, as the root point x 0 depends on the prediction point x.</s></p><p><s>Several works have been using sensitivity maps <ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b18">[18]</ref><ref type="bibr" target="#b19">[19]</ref> for visualization of classifier predictions which were based on using partial derivatives at the prediction point x.</s><s>There are two essential differences between sensitivity maps based on derivatives at the prediction point x and the pixel-wise decomposition approach.</s><s>Firstly, there is no direct relationship between the function value f(x) at the prediction point x and the differential Df(x) at the same point x.</s><s>Secondly, we are interested in explaining the classifier prediction relative to a certain state given by the set of roots of the prediction function f(x 0 ) = 0.</s><s>The differential Df(x) at the prediction point does not necessarily point to a root which is close under the Euclidean norm.</s><s>It points to the nearest local optimum which may still have the same sign as the prediction f(x) and thus be misleading for explaining the difference to the set of root points of the prediction function.</s><s>Therefore derivatives at the prediction point x are not useful for achieving our aim.</s><s>Fig <ref type="figure" target="#fig_2">3 illus</ref>trates the qualitative difference between local gradients (black arrows) and the dimension-wise decomposition of the prediction (red arrow).</s></p><p><s>One technical difficulty is to find a root point x 0 .</s><s>For continuous classifiers we may use unlabeled test data in a sampling approach and perform a line search between the prediction point x and a set of candidate points {x 0 } such that their prediction has opposite sign: f(x)f(x 0 ) &lt; 0. It is clear that the line l(a) = ax + (1 − a)x 0 must contain a root of f which can be found by interval intersection.</s><s>Thus each candidate point x 0 yields one root, and one may select a root point which minimizes the Taylor residuum or use an average over a subset of root points with low Taylor residues.</s><s>A second possible solution would be, for example, to find the root point x 0 that is the nearest to the data point x, or optimal in some measurable sense.</s><s>However, while we have presented two types of solutions to finding a root point, in the most general case, the Taylor-type decomposition is best described as a constraint-based approach.</s><s>In particular, the root point x 0 at which the Taylor decomposition is computed is constrained to satisfy f(x 0 ) = 0 and to lie not too far (e.g.</s><s>within a fixed radius) from the actual data point x.</s><s>Using this constraintbased definition, the most desirable properties of the Taylor decomposition are preserved, while the remaining specification is deferred to a later point in time.</s></p><p><s>Note that Taylor-type decomposition, when applied to one layer or a subset of layers, can be seen as an approximate way of relevance propagation when the function is highly non-linear.</s><s>This holds in particular when it is applied to the output function f as a function of the preceding layer f = f(z i − 1 ), as Eq <ref type="bibr" target="#b18">(18)</ref> satisfies approximately the propagation Eq (2) when the relevance of the output layer is initialized as the value of prediction function f(x).</s><s>Unlike the Taylor approximation, layer-wise relevance propagation does not require to use a second point besides the input point.</s><s>The formulas in Sections Pixel-wise Decomposition for Classifiers over Bag of Words Features and Pixel-wise Decomposition for Multilayer Networks will demonstrate that layer-wise relevance propagation can be implemented for a wide range of architectures without the need to approximate by means of Taylor expansion.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p><s>Several works have been dedicated to the topic of explaining neural networks, kernel-based classifiers in general and classifiers over Bag of Words features in particular.</s></p><p><s>As for neural networks, <ref type="bibr" target="#b20">[20]</ref> is dedicated towards analyzing classifier decisions at neurons which is applicable also to the pixel level.</s><s>It performs a layer-wise inversion down from output layers towards the input pixels for the architecture of convolutional networks <ref type="bibr" target="#b21">[21]</ref>.</s><s>This work is specific to the architecture of convolutional neural networks.</s><s>Compared to our approach it is based on a different principle.</s><s>See <ref type="bibr" target="#b22">[22]</ref> which establishes an interpretation of the work in <ref type="bibr" target="#b20">[20]</ref>  as an approximation to partial derivatives with respect to pixels in the input image.</s><s>In a highlevel sense, the work in <ref type="bibr" target="#b20">[20]</ref> uses the method from their own predecessor work in <ref type="bibr" target="#b23">[23]</ref> which solves optimization problems in order to reconstruct the image input, while our approach attempts to reconstruct the classifier decision.</s><s>In a more technical sense, the difference between <ref type="bibr" target="#b20">[20]</ref> and our approach can be seen by comparing how the responses are projected down towards the inputs.</s><s><ref type="bibr" target="#b20">[20]</ref> uses rectified linear units to project information from the unfolded maps towards the inputs with the aim to ensure the feature maps to be non-negative.</s><s>In our approach we use the signed activations of the neurons from the layer below for weighting the relevance quantity from the layer above with the aim of conserving the relevance quantity across layers.</s><s>The sign of the activations of neurons of the layer below, for which the relevance is to be computed, is used in our work for encoding assumptions about the structure of the neural network.</s><s>With respect to neural networks, our work is applicable to a wide range of architectures.</s><s>A different type of analysis for understanding neural networks deals with creating counter-intuitive examples, see for example the work in <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25]</ref>.</s><s>For a treatment on how to discriminate structures which influence predictions from correlations with hidden variables such that the hidden variables have an impact on the predictor, see <ref type="bibr" target="#b26">[26]</ref>.</s></p><p><s>Another approach which lies between partial derivatives at the input point x and a full Taylor series around a different point x 0 is presented in <ref type="bibr" target="#b22">[22]</ref>.</s><s>This work uses a different point x 0 than the input point x for computing the derivative and a remainder bias which both are not specified further but avoids for an unspecified reason to use the full linear weighting term x − x 0 of a Taylor series.</s><s>Besides deviating in the usage of a Taylor series, the work in <ref type="bibr" target="#b22">[22]</ref> does not make use of the layer-wise propagation strategy for neural networks presented in this paper, which unlike a Taylor series does not rely on a local approximation.</s><s>Explanation of neural network behavior on the level of single neurons is done in <ref type="bibr" target="#b27">[27]</ref> and <ref type="bibr" target="#b28">[28]</ref>.</s><s>These works try to find inputs which maximize the activation of neurons by means of optimization problems which can be solved by gradient ascent.</s><s>Our approach aims at explaining the decision for a given input rather than finding optimal stimuli for a particular neuron.</s><s>Note that the approach presented in our paper is different from plotting the activations of neurons during a forward-pass of the input image.</s><s>The latter is independent from the neural network properties in higher layers whereas in our approach we feed the classification score into the top neurons and use quantities computed by using properties of higher layers to obtain a representation at lower layers.</s><s>Quantifying the importance of input variables using a neural network model has also been studied in specific areas such as ecological modeling, where <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b30">30]</ref> surveyed a large ensemble of possible analyses, including, computing partial derivatives, perturbation analysis, weights analysis, and studying the effect of including and removing variables at training time.</s><s>A different avenue to understanding decisions in neural network is to fit a more interpretable model (e.g.</s><s>decision tree) to the function learned by the neural network <ref type="bibr" target="#b31">[31]</ref>, and extract the rules learned by this new model.</s></p><p><s>With respect to sensitivity of kernel-based classifiers to input dimensions, <ref type="bibr" target="#b32">[32]</ref> yields sensitivity maps, which are invariant to the sign of the predictions.</s><s><ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b18">[18]</ref><ref type="bibr" target="#b19">[19]</ref> consider explanation vectors based on local gradients which are sign-sensitive.</s><s>Both approaches use partial derivatives at the point which is to be predicted.</s><s>The first works to our knowledge to visualize BoW models are <ref type="bibr" target="#b33">[33]</ref> and <ref type="bibr" target="#b34">[34]</ref>.</s><s>The former work finds regions with a large influence for classification for the special case of max pooling, sparse coding and a linear classifier.</s><s>The latter work obtains an exact decomposition into local feature scores for the case of a histogram intersection kernel and zero-one coding of local features onto visual words.</s></p><p><s>We differ from the above works on kernel-based classifiers over Bag of Words features in the following sense: Our methodology is applicable to arbitrary Bag of Words models including various feature codings such as Fisher vectors and regularized codings and to a broader class of kernels, namely all differentiable or so-called sum decomposable kernels.</s><s>When relying on Taylor decomposition, our work relies on a Taylor series around a root close to the prediction point rather than partial derivatives at the prediction point itself.</s><s>The rationale for this choice was justified in the preceding Section Taylor-type decomposition.</s><s>Finally, in contrast to the preceding publications, our work introduces layer-wise relevance propagation for neural networks and Bag of Words features.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pixel-wise Decomposition for Classifiers over Bag of Words Features</head><p><s>Despite recent advances in neural networks, Bag of Words models are still popular for image classification tasks.</s><s>They have excelled in past competitions on visual concept recognition and ranking such as Pascal VOC <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b36">36]</ref> and ImageCLEF PhotoAnnotation <ref type="bibr" target="#b37">[37]</ref>.</s><s>In our experience Bag of Words Models perform well for tasks with small sample sizes, whereas neural networks are at risk to overfit due to their richer parameter structure.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag of Words models revisited</head><p><s>We will consider here Bag of Words features as an aggregation of non-linear mappings of local features.</s><s>All Bag of Words models, no matter whether based on hierarchical clustering <ref type="bibr" target="#b38">[38]</ref>, soft codebook mapping <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref><ref type="bibr" target="#b41">[41]</ref>, regularized local codings <ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref><ref type="bibr" target="#b14">[14]</ref>, or Fisher Vectors <ref type="bibr" target="#b11">[11]</ref>, share a multi-stage procedure in common.</s></p><p><s>In the first stage local features are computed across small regions in the image.</s><s>A local feature such as SIFT <ref type="bibr" target="#b42">[42,</ref><ref type="bibr">43]</ref> is in the abstract sense a vector computed from a region of the image, for example capturing information of interest such as shape characteristics or properties of color or texture on a local scale.</s><s>In a second stage which is performed once during training, representatives in the space of local features are computed, no matter whether they are cluster centroids obtained from k-means clustering, regions of the space as for clustering trees <ref type="bibr" target="#b38">[38]</ref>, or centers of distributions as for Fisher vectors <ref type="bibr" target="#b44">[44]</ref>.</s><s>The set of representatives, in the following referred to as visual words, serves as a vocabulary in the context of which images can be described as vectors.</s><s>In the third stage, statistics of the local features are computed relative to those visual words.</s><s>These statistics are aggregated from all local features l within an image in order to yield a BoW representation x, usually done by sum-or max-pooling.</s></p><p><s>The computation of statistics can be modeled by a mapping function accepting local feature vectors l as input, which are then projected into the Bag of Words feature space.</s><s>Let m be such a mapping function and let m (d) denote the mapping onto the d-th dimension of the BoW space.</s><s>We assume the very generic p-means mapping scheme for local features l as given in Eq <ref type="bibr" target="#b19">(19)</ref>.</s></p><formula xml:id="formula_27">x ðdÞ ¼ M À1 X M j¼1 ðm ðdÞ ðl j ÞÞ p ! 1 p<label>ð19Þ</label></formula><p><s>This contains sum-and max-pooling as the special cases p = 1 and the limit p = 1.</s></p><p><s>Finally, a classifier is applied on top of these features.</s><s>Our method supports the general class of classifiers based on kernel methods.</s><s>For brevity we use here an SVM prediction function which results in a prediction function over BoW features x i , training data labels y i , kernel functions k(Á, Á), and SVM model parameters b and α i .</s></p><formula xml:id="formula_28">f ðxÞ ¼ b þ X S i¼1 a i y i kðx i ; xÞ<label>ð20Þ</label></formula><p><s>This assumption can be extended without loss of generality to approaches using multiple kernel functions such as multiple kernel learning <ref type="bibr" target="#b45">[45]</ref><ref type="bibr" target="#b46">[46]</ref><ref type="bibr" target="#b47">[47]</ref><ref type="bibr" target="#b48">[48]</ref><ref type="bibr" target="#b49">[49]</ref>, structural prediction approaches with tensor product structure between features and labels as in taxonomy-based classifiers <ref type="bibr" target="#b50">[50]</ref><ref type="bibr" target="#b51">[51]</ref><ref type="bibr" target="#b52">[52]</ref> or boosting-like formulations as in <ref type="bibr" target="#b53">[53]</ref> f</s></p><formula xml:id="formula_29">ðxÞ ¼ b þ X S i¼1 X K u¼1 a i;u k u ðx iðuÞ ; x ðuÞ Þ:<label>ð21Þ</label></formula><p><s>An overview over notations used for the Bag of Words features is given in Table <ref type="table" target="#tab_1">1</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of the decomposition steps</head><p><s>The main contribution of this part is the formulation of a generic framework for retracing the origins of a decision made by the learned kernel-based classifier function for a BoW feature.</s><s>This is achieved, in a broad sense as visualized in Fig <ref type="figure" target="#fig_4">4</ref>, by following the construction of a BoW representation x of an image and the evaluation thereof by a classifier function in reverse direction.</s><s>In this section we will derive a decomposition of a kernel-based classifier prediction into contributions of individual local features and finally single pixels.</s><s>The proposed approach consists of three consecutive steps.</s></p><p><s>In the first step we will use, depending on the type of kernel, either the Taylor-type decomposition strategy or the layer-wise relevance propagation strategy.</s><s>In the first step relevance scores R ð3Þ d for the third layer of the BoW feature extraction process are obtained, describing the influence of all BoW feature dimensions d by deconstructing the classifier prediction function f (x) such that P d R ð3Þ d % f ðxÞ.</s><s>In other words, we gain a decomposition into contributions R ð3Þ d describing f(x) as a sum of individual predictions for all dimensions of x.</s></p><p><s>In the second step we will apply the layer-wise relevance propagation strategy in order to obtain relevance scores R ð2Þ l for the local features l from the relevance scores R ð3Þ d .</s><s>Layer-wise relevance propagation ensures that</s></p><formula xml:id="formula_30">P l R<label>ð2Þ</label></formula><formula xml:id="formula_31">l ¼ P d R<label>ð3Þ</label></formula><p><s>d % f ðxÞ holds.</s><s>The third step describes the computation of pixel-wise scores R ð1Þ q from local feature relevance scores R ð2Þ l , which are then visualized as heatmaps by color-coding.</s></p><p><s>Step one: relevance scores R ð3Þ d for the third layer of the BoW feature extraction process.</s><s>The third layer is the BoW feature itself.</s><s>In the first step we would like to achieve a decomposition of the classifier prediction f(x) into relevance scores R ð3Þ d for BoW feature dimension d.</s></p><formula xml:id="formula_32">f ðxÞ % X V d¼1 R ð3Þ d<label>ð22Þ</label></formula><p><s>The work of <ref type="bibr" target="#b34">[34]</ref> has performed this step for the special case of one single histogram intersection kernel.</s><s>Such a decomposition can be generalized naturally and performed without error for all kernel functions which are sum-decomposable along input dimensions.</s><s>We define a kernel function k to be sum-decomposable if there exists kernel functions k (d) acting on single input feature dimensions such that</s></p><formula xml:id="formula_33">kðx i ; x i 0 Þ ¼ X ðdÞ k ðdÞ ðx iðdÞ ; x i 0 ðdÞ Þ<label>ð23Þ</label></formula><p><s>In this case, as with the linear and histogram intersection kernel, we can achieve Eq <ref type="bibr" target="#b22">(22)</ref> with equality in the following definition by applying layer-wise relevance propagation which results in Eq <ref type="bibr" target="#b24">(24)</ref>.</s><s>Def. 1 Relevance scores for sum decomposable kernels</s></p><formula xml:id="formula_34">R ð3Þ d ¼ b V þ X S i¼1 a i y i k ðdÞ ðx iðdÞ ; x ðdÞ Þ<label>ð24Þ</label></formula><p><s>For the case of a general differentiable kernel we apply the Taylor-type decomposition strategy in order to linearly approximate the dimensional contributions R ð3Þ d .</s><s>The approximated dimensional contributions can be expressed as in Eq <ref type="bibr" target="#b25">(25)</ref>.</s></p><p><s>Def. 2 Relevance scores for differentiable kernels R</s></p><formula xml:id="formula_35">d := ðx À x 0 Þ ðdÞ X S i¼1 a i y i @kðx i ; ÁÞ @x ðdÞ ðx 0 Þ<label>ð3Þ</label></formula><p><s>Step two: relevance scores R ð2Þ l for the second layer of the BoW feature extraction process.</s><s>The second layer are the local features extracted from many regions of the image.</s><s>In the second step we would like to achieve a decomposition of the classifier prediction f(x) into relevance scores R ð2Þ l for the local features l based on the relevances R ð3Þ d from the third layer.</s><s>For the sake of clarity, we do for now start with the case of sum-pooled BoW aggregation, to later extend to a more general formulation for p-means pooling from this point on.</s></p><p><s>As introduced in context of Eq ( <ref type="formula" target="#formula_27">19</ref>) m (d) denotes the mapping projecting to dimension d of the BoW space.</s><s>We define the set of input dimensions Z(x) which are effectively not reached by the mappings of local features of an image.</s><s>Applying the layer-wise propagation allows to define the local feature relevance score R ð2Þ l as given in Eq <ref type="bibr" target="#b27">(27)</ref>.</s><s>Def. 3 Local feature scores for sum pooling</s></p><formula xml:id="formula_37">ZðxÞ ¼ d j X l m ðdÞ ðlÞ ¼ 0 ( )<label>ð26Þ</label></formula><formula xml:id="formula_38">R ð2Þ l := X d= 2ZðxÞ R<label>ð3Þ</label></formula><formula xml:id="formula_39">d m ðdÞ ðlÞ P l 0 m ðdÞ ðl 0 Þ þ X d2ZðxÞ R<label>ð3Þ</label></formula><formula xml:id="formula_40">d 1 jfl 0 gj<label>ð27Þ</label></formula><p><s>The coarse structure of definition ( <ref type="formula" target="#formula_40">27</ref>) can be explained as taking the relevances from the layer above and weighting them with the outputs from the layer below.</s><s>The summations over the mappings m (d) (l) over the local features {l} in Eq <ref type="bibr" target="#b27">(27)</ref> achieve a weighting of the relevance from the third layer proportional to the ratios of the mappings.</s><s>The second part describes an equal distribution of those relevance scores R ð3Þ d which correspond to dimensions of the Bag of Words feature x which have a value of zero and yet may contribute to the classifier prediction.</s><s>To see this consider computing the χ 2 -kernel value to a support vector which has a non-zero value in the same feature dimension.</s><s>This is necessary to ensure that the propagation Eq (2) holds.</s></p><p><s>Summing the local feature relevance scores R ð2Þ l from Eq (27) yields the Taylor approximation R ð3Þ d of the prediction score f(x) in Eqs <ref type="bibr" target="#b24">(24)</ref> or <ref type="bibr" target="#b25">(25)</ref>.</s><s>This property is the key to our approach.</s><s>We obtain exact summation to the prediction f(x) in the case of sum decomposable kernels and usage of Eq <ref type="bibr" target="#b24">(24)</ref> in this special case.</s></p><formula xml:id="formula_41">X l R ð2Þ l ¼ X V d¼1 R ð3Þ d % f ðxÞ<label>ð28Þ</label></formula><p><s>We would like to point out that this property holds also in the case when mappings m (d) can become negative as a consequence of the definition used in ( <ref type="formula" target="#formula_37">26</ref>) and ( <ref type="formula" target="#formula_40">27</ref>), as can be seen from the summation given in the appendix.</s><s>For that reason our approach is also applicable to Fisher vectors <ref type="bibr" target="#b11">[11]</ref> and regularized coding approaches <ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref><ref type="bibr" target="#b14">[14]</ref>.</s><s>Furthermore note that definition <ref type="bibr" target="#b27">(27)</ref> has no explicit dependence on the way how the local features are pooled in Eq <ref type="bibr" target="#b19">(19)</ref> and this might be inappropriate weighting for max-pooling or general p-means pooling.</s><s>We can extend this definition to reflect the usage of p-means pooling</s></p><formula xml:id="formula_42">M p ðx 1 ; . . . ; x n Þ ¼ 1 n X n i¼1 x p i ! 1=p<label>ð29Þ</label></formula><p><s>which may yield different results in prediction and local decomposition than sum pooling.</s><s>The extension is well-defined for non-negative mappings m (d) !</s><s>0 and any value of p and for arbitrary mappings when combined with a value of p from the natural numbers.</s></p><p><s>Def. <ref type="bibr" target="#b4">4</ref> Local feature scores for p-means pooling</s></p><formula xml:id="formula_43">Z ðpÞ ðxÞ ¼ d j X l m p ðdÞ ðlÞ ¼ 0 ( )<label>ð30Þ</label></formula><formula xml:id="formula_44">R ð2Þ l := X d= 2Z ðpÞ ðxÞ R<label>ð3Þ</label></formula><formula xml:id="formula_45">d m p ðdÞ ðlÞ P l 0 m p ðdÞ ðl 0 Þ þ X d2Z ðpÞ ðxÞ R<label>ð3Þ</label></formula><formula xml:id="formula_46">d 1 jfl 0 gj<label>ð31Þ</label></formula><p><s>The first quotient in Eq <ref type="bibr" target="#b31">(31)</ref> converges to an indicator function for the maximal mapping element in the limit p ! 1 which is consistent to max-pooling m p ðdÞ ðlÞ P l 0 m p ðdÞ ðl 0 Þ !</s><s>I fargmax l 0 m ðdÞ ðl 0 Þg ðlÞ ð 32Þ</s></p><p><s>Step three: relevance scores R ð1Þ q for the first layer of the BoW feature extraction process.</s><s>The first layer are the pixels of the image.</s><s>In order to calculate scores for each pixel we make use of information regarding local feature geometry and location known from the local feature extraction phase at the beginning of the image classification pipeline.</s><s>The pixel score R ð1Þ q of an image coordinate q is calculated as a sum of local feature scores of all local features l covering q, weighted by the number of pixels covered by each local feature l.</s><s>In terms of layerwise relevance propagation a local feature is a computation unit which has as much inputs as the number of pixels it is covering.</s><s>Without assumption of any further structure we distribute the relevance of the local feature equally to all its covered pixels.</s><s>Layer-wise propagation yields Eq <ref type="bibr" target="#b34">(34)</ref>.</s></p><formula xml:id="formula_47">LðqÞ ¼ fl j q 2 areaðlÞg<label>ð33Þ</label></formula><formula xml:id="formula_48">R ð1Þ q ¼ X l2LðqÞ R<label>ð2Þ</label></formula><formula xml:id="formula_49">l jareaðlÞj<label>ð34Þ</label></formula><p><s>The operator area(l) used Eqs <ref type="bibr" target="#b33">(33)</ref> and <ref type="bibr" target="#b34">(34)</ref> returns the set of pixel coordinates covered by a local feature l.</s><s>Projecting the obtained scores R ð1Þ q to their respective image coordinates yields the pixel-wise decomposition representation h of the evaluated image.</s></p><p><s>For visualization in the sense of color coding, the pixel-wise decomposition R (1) is then normalized as</s></p><formula xml:id="formula_50">R 0ð1Þ q ¼ R<label>ð1Þ</label></formula><p><s>q max q 0 ðjR ð1Þ q 0 jÞ ð35Þ ensuring that 8q : R 0ð1Þ q 2 ½À1; 1.</s><s>The normalized pixel-wise decomposition is then color coded by mapping the pixel scores to a color space of choice.</s><s>In the case of individually classified sub-regions originating from the same image, a global pixel-wise decomposition can be constructed by averaging local pixel-wise decompositions scores.</s><s>Note that by choosing above normalization scheme, the assumption is made that at least one class is represented within the image.</s><s>In case the assumption holds this might lead to prominent local predictions of even weakly projected features which we found suitable for the purpose of detecting class evidence.</s><s>If this assumption does not hold, then images may display score artifacts dominated by the set of pixels covered by a small subset of local features which would otherwise be considered input noise.</s><s>A solution for this problem is global normalization which uses a maximum over pixels over a set of images instead of one image.</s><s>We found that a global normalization scheme can be more appropriate for visualizing the actual decision process of the classifier, as it preserves the relative order of magnitude of local feature scores in between pixel-wise decomposition tiles.</s><s>Algorithm 1 gives an overview how to compute the pixel-wise decomposition for classifiers based on Bag of Words features and support vector machines.</s><s><ref type="formula" target="#formula_34">24</ref>) or (25) end for for all l 2 L do R ð2Þ l as in Eqs ( <ref type="formula" target="#formula_40">27</ref>) or (31) end for for all pixels q 2 I do R ð1Þ q as in Eq (34) end for Output: 8q : R ð1Þ q</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples for various mappings and kernels</head><p><s>In order to illustrate the generality of this framework we give some examples for various methods of mapping local features and kernels.</s></p><p><s>Example case: Soft codebook mapping.</s><s>A soft codebook mapping like in <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b40">40]</ref></s></p><p><s>Example case: Regularized coding.</s><s>Considering formulations as in <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b14">14]</ref> argmin B;C</s></p><formula xml:id="formula_52">X j k l j À Bc j k 2 þ Qðc j Þ<label>ð37Þ</label></formula><p><s>where B is the codebook and Q denotes a regularizer on the codebook coefficients such as the ℓ 1 -norm Q(c) = ∑ j jc(j)j, we arrive at</s></p><formula xml:id="formula_53">mðl j Þ :¼ c j<label>ð38Þ</label></formula><p><s>where the d-th dimension of the so defined mapping m (d) corresponds to the d-th basis element in B.</s></p><p><s>Example case: Fisher Vectors.</s><s>The Fisher vector <ref type="bibr" target="#b44">[44]</ref> can be replicated using the following mapping m (d) given below.</s><s>It is expected to be used with a linear kernel, thus we can use the exact formula from Eq <ref type="bibr" target="#b24">(24)</ref> for defining the BoW dimension relevance scores R ð3Þ d .</s><s>We stick to the formulation of Fisher vectors as given in <ref type="bibr" target="#b11">[11]</ref>.</s><s>The difference to other mappings is that a BoW feature dimension corresponds to a derivative of a Gaussian mixture center with respect to some parameter and not to a visual word.</s></p><p><s>Let g k (l) be the D-dimensional Gaussian mixture component with diagonal covariance σ k and mean μ k .</s><s>We define the softmax of the GMM mixture parameters α k as</s></p><formula xml:id="formula_54">w k ¼ exp ða k Þ P K j¼1 exp ða j Þ<label>ð39Þ</label></formula><p><s>Let the soft assignment of local feature l to Gaussian k be given as</s></p><formula xml:id="formula_55">g½lðkÞ ¼ w k u k ðlÞ P K j¼1 w j u j ðlÞ<label>ð40Þ</label></formula><p><s>Let k denote the index of a Gaussian mixture component, then the mapping contains three cases depending on whether we consider the derivative for the mixture parameter α k stored in dimension d = (2D + 1)(k − 1) + 1, derivatives for the Gaussian mean parameter μ k stored in dimensions d = (2D + 1)(k − 1) + 1 + r,r 2 [1,D], or finally, derivatives for the Gaussian variance parameter σ k stored in dimensions d = (2D + 1)(k − 1) + 1 + D + r,r 2 <ref type="bibr">[1,D]</ref> We assume one kernel without loss of generality, V 1 = (2D + 1)K where K is the number of Gaussian mixture components and D is the local feature dimension.</s></p><formula xml:id="formula_56">m ðdÞ ðlÞ ¼ 1 ffiffiffiffiffi w k p ðg½lðkÞ À w k Þ if d ¼ ð2D þ 1Þðk À 1Þ þ 1 1 ffiffiffiffiffi w k p g½lðkÞ l r À m k s k if d ¼ ð2D þ 1Þðk À 1Þ þ 1 þ r; r 2 ½1; D 1 ffiffiffiffiffi w k p g½lðkÞ 1 ffiffi ffi 2 p ðl r À m k Þ 2 s 2 k À 1 if d ¼ ð2D þ 1Þðk À 1Þ þ 1 þ D þ r; r 2 ½1; D<label>ð41Þ</label></formula><formula xml:id="formula_57">8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; :</formula><p><s>This definition can be extended in a straightforward manner to use power normalization and ℓ 2 normalization from <ref type="bibr" target="#b11">[11]</ref>.</s><s>The difference to the soft mapping case from Section Example case: Soft codebook mapping is that a the d-th dimension of the mapping m (d) corresponds not to a visual word but to a derivative with respect to a Gaussian mixture component.</s></p><p><s>Example case: Histogram intersection kernel.</s><s>The histogram intersection kernel applies to the exact decomposition formula in Eq <ref type="bibr" target="#b24">(24)</ref>.</s><s>It is defined as</s></p><formula xml:id="formula_58">k HI ðx i ; x i 0 Þ ¼ X d min ðx iðdÞ ; x i 0 ðdÞ Þ<label>ð42Þ</label></formula><p><s>Plugging the kernel into (24) yields</s></p><formula xml:id="formula_59">R ð3Þ d ¼ b V þ X S i¼1 a i y i min x iðdÞ ; x ðdÞ<label>ð43Þ</label></formula><p><s>Example case: χ 2 kernel The χ 2 kernel function has been applied with good performance in various image classification tasks <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b55">55]</ref>.</s><s>The χ 2 kernel is defined as</s></p><formula xml:id="formula_60">k w 2 ðx i ; x i 0 Þ ¼ exp Às X d ðx iðdÞ À x i 0 ðdÞ Þ 2 ðx iðdÞ þ x i 0 ðdÞ Þ !<label>ð44Þ</label></formula><p><s>To avoid divisions by zero in case of x i(d) = x i 0 (d) = 0 we adhere to the convention that 0 0 ¼ 0 for the kernel function itself, as well as its derivative</s></p><formula xml:id="formula_61">@k w 2 ðx i ; x i 0 Þ @x i 0 ðdÞ ¼ k w 2 ðx i ; x i 0 Þs 4ðx iðdÞ Þ 2 ðx iðdÞ þ x i 0 ðdÞ Þ 2 À 1 !<label>ð45Þ</label></formula><p><s>When plugged into Eq <ref type="bibr" target="#b25">(25)</ref>, the dimensional contributions of the χ 2 kernel are then obtained as</s></p><formula xml:id="formula_62">R ð3Þ d :¼ ðx À x 0 Þ ðdÞ Á X S i¼1 a i y i k w 2 ðx i ; x 0 Þs 4ðx iðdÞ Þ 2 ðx iðdÞ þ x 0ðdÞ Þ 2 À 1 !<label>ð46Þ</label></formula><p><s>Example case: Gaussian-RBF kernel.</s><s>The Gaussian-RBF kernel function is widely used in different communities and is one of the most prominent, if not the most prominent non-linear kernel function.</s><s>The kernel function is defined as</s></p><formula xml:id="formula_63">k Gauss ðx i ; x i 0 Þ ¼ exp À k x i À x i 0 k 2 2 s<label>ð47Þ</label></formula><p><s>Deriving the kernel function w.r.t x i 0 (d) and plugging it into Eq (25) yields</s></p><formula xml:id="formula_64">@k Gauss ðx i ; x i 0 Þ @x i 0 ðdÞ ¼ k Gauss ðx i ; x i 0 Þ 2x iðdÞ À 2x i 0 ðdÞ s<label>ð48Þ</label></formula><p><s>and consequently</s></p><formula xml:id="formula_65">R ð3Þ d :¼ ðx À x 0 Þ ðdÞ Á X S i¼1 a i y i k Gauss ðx i ; x 0 Þ 2x iðdÞ À 2x 0ðdÞ s<label>ð49Þ</label></formula><p><s>Pixel-wise Decomposition for Multilayer Networks</s></p><p><s>Multilayer networks are commonly built as a set of interconnected neurons organized in a layer-wise manner.</s><s>They define a mathematical function when combined to each other, that maps the first layer neurons (input) to the last layer neurons (output).</s><s>We denote each neuron by x i where i is an index for the neuron.</s><s>By convention, we associate different indices for each layer of the network.</s><s>We denote by "∑ i " the summation over all neurons of a given layer, and by "∑ j " the summation over all neurons of another layer.</s><s>We denote by x (d) the neurons corresponding to the pixel activations (i.e. with which we would like to obtain a decomposition of the classification decision).</s><s>A common mapping from one layer to the next one consists of a linear projection followed by a non-linear function:</s></p><formula xml:id="formula_66">z ij ¼ x i w ij ;<label>ð50Þ</label></formula><formula xml:id="formula_67">z j ¼ X i z ij þ b j ;<label>ð51Þ</label></formula><formula xml:id="formula_68">x j ¼ gðz j Þ;<label>ð52Þ</label></formula><p><s>where w ij is a weight connecting the neuron x i to neuron x j , b j is a bias term, and g is a non-linear activation function.</s><s>Multilayer networks stack several of these layers, each of them, composed of a large number of neurons.</s><s>Common non-linear functions are the hyperbolic tangent g(t) = tanh(t) or the rectification function g(t) = max(0,t).</s><s>This formulation of neural network is general enough to encompass a wide range of architectures such as the simple multilayer perceptron <ref type="bibr" target="#b56">[56]</ref> or convolutional neural networks <ref type="bibr" target="#b57">[57]</ref>, where convolution and sum-pooling are linear operations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taylor-type decomposition</head><p><s>Denoting by f:R M 7 !</s><s>R N the vector-valued multivariate function implementing the mapping between input and output of the network, a first possible explanation of the classification decision x 7 !</s><s>f(x) can be obtained by Taylor expansion at a near root point x 0 of the decision function f:</s></p><formula xml:id="formula_69">R ð1Þ d ¼ ðx À x 0 Þ ðdÞ Á @f @x ðdÞ ðx 0 Þ<label>ð53Þ</label></formula><p><s>The derivative @f(x)/@x (d) required for pixel-wise decomposition can be computed efficiently by reusing the network topology using the backpropagation algorithm <ref type="bibr" target="#b56">[56]</ref>.</s><s>In particular, having backpropagated the derivatives up to a certain layer j, we can compute the derivative of the previous layer i using the chain rule:</s></p><formula xml:id="formula_70">@f @x i ¼ X j @f @x j Á @x j @x i ¼ X j @f @x j Á w ij Á g 0 ðz j Þ:<label>ð54Þ</label></formula><p><s>A requirement of the Taylor-based decomposition is to find roots x 0 (i.e. points on the classification boundary) that support a local explanation of the classification decision for x.</s><s>These roots can be found by local search in the neighborhood of x.</s><s>However, as noted in <ref type="bibr" target="#b24">[24]</ref>, this can lead to points of the input space that are perceptually equivalent to the original sample x and whose choice as a root would produce non-informative pixel-wise decompositions.</s></p><p><s>Alternatively, root points can be found by line search on the segment defined by x and its closest neighbor of a different class.</s><s>This solution is problematic when the data manifold is sparsely populated, as it is the case for natural images.</s><s>In such case, it is likely that following a straight line between x and its nearest neighbor will strongly depart from the data manifold and produce roots x 0 with similarly poor pixel-wise decompositions.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Layer-wise relevance backpropagation</head><p><s>As an alternative to Taylor-type decomposition, it is possible to compute relevances at each layer in a backward pass, that is, express relevances R ðlÞ i as a function of upper-layer relevances R ðlþ1Þ j , and backpropagating relevances until we reach the input (pixels).</s><s>The method works as follows: Knowing the relevance of a certain neuron R ðlþ1Þ j for the classification decision f(x), one would like to obtain a decomposition of such relevance in terms of messages sent to neurons of the previous layers.</s><s>We call these messages R i j .</s><s>In particular, as expressed by Eqs ( <ref type="formula" target="#formula_10">8</ref>) and ( <ref type="formula" target="#formula_15">13</ref>), the conservation property</s></p><formula xml:id="formula_71">X i R ðl;lþ1Þ i j ¼ R ðlþ1Þ j<label>ð55Þ</label></formula><p><s>must hold.</s><s>In the case of a linear network f(x) = ∑ i z ij where the relevance R j = f(x), such decomposition is immediately given by R i j = z ij .</s><s>However, in the general case, the neuron activation x j is a non-linear function of z j .</s><s>Nevertheless, for the hyperbolic tangent and the rectifying function-two simple monotonically increasing functions satisfying g(0) = 0, -the pre-activations z ij still provide a sensible way to measure the relative contribution of each neuron x i to R j .</s><s>A first possible choice of relevance decomposition is based on the ratio of local and global preactivations and is given by: R ðl;lþ1Þ</s></p><formula xml:id="formula_72">i j ¼ z ij z j Á R ðlþ1Þ j<label>ð56Þ</label></formula><p><s>These relevances R i j are easily shown to approximate the conservation properties of Eq (2), in particular:</s></p><formula xml:id="formula_73">X i R ðl;lþ1Þ i j ¼ R ðlþ1Þ j Á 1 À b j z j !<label>ð57Þ</label></formula><p><s>where the multiplier accounts for the relevance that is absorbed (or injected) by the bias term.</s><s>If necessary, the residual bias relevance can be redistributed onto each neuron x i .</s><s>A drawback of the propagation rule of Eq <ref type="bibr" target="#b56">(56)</ref> is that for small values z j , relevances R i j can take unbounded values.</s><s>Unboundedness can be overcome by introducing a predefined stabilizer ε !</s><s>0:</s></p><formula xml:id="formula_74">R ðl;lþ1Þ i j ¼ z ij z j þε Á R ðlþ1Þ j z j ! 0 z ij z j Àε Á R ðlþ1Þ j z j &lt; 0 ð58Þ 8 &gt; &lt; &gt; :</formula><p><s>The conservation law then becomes</s></p><formula xml:id="formula_75">X i R ðl;lþ1Þ i j ¼ R ðlþ1Þ j Á 1 À b j þε z j þε z j ! 0 R ðlþ1Þ j Á 1 À b j Àε z j Àε z j &lt; 0<label>ð59Þ</label></formula><formula xml:id="formula_76">8 &gt; &gt; &lt; &gt; &gt; :</formula><p><s>where we can observe that some further relevance is absorbed by the stabilizer.</s><s>In particular, relevance is fully absorbed if the stabilizer ε becomes very large.</s><s>An alternative stabilizing method that does not leak relevance consists of treating negative and positive pre-activations separately.</s><s>Let z þ j ¼</s></p><formula xml:id="formula_77">P i z þ ij þ b þ j and z À j ¼ P i z À ij þ b À j</formula><p><s>where " − " and "+" denote the negative and positive part of z ij and b j .</s><s>Relevance propagation is now defined as</s></p><formula xml:id="formula_78">R ðl;lþ1Þ i j ¼ R ðlþ1Þ j Á a Á z þ ij z þ j þ b Á z À ij z À j !<label>ð60Þ</label></formula><p><s>where α + β = 1.</s><s>For example, for α,β = 1/2, the conservation law becomes:</s></p><formula xml:id="formula_79">X i R ðl;lþ1Þ i j ¼ R ðlþ1Þ j Á 1 À b þ j 2z þ j À b À j 2z À j !<label>ð61Þ</label></formula><p><s>which has similar form to Eq <ref type="bibr" target="#b57">(57)</ref>.</s><s>This alternate propagation method also allows to control manually the importance of positive and negative evidence, by choosing different factors α and β.</s><s>Once a rule for relevance propagation has been selected, the overall relevance of each neuron in the lower layer is determined by summing up the relevance coming from all upper-layer neurons in consistence with Eqs (8) and ( <ref type="formula" target="#formula_15">13</ref>):</s></p><formula xml:id="formula_80">R ðlÞ i ¼ X j R ðl;lþ1Þ i j<label>ð62Þ</label></formula><p><s>The relevance is backpropagated from one layer to another until it reaches the input pixels x (d) , and where relevances R ð1Þ d provide the desired pixel-wise decomposition of the decision f(x).</s><s>The complete layer-wise relevance propagation procedure for neural networks is summarized in Algorithm 2.  <ref type="formula">58</ref>) and ( <ref type="formula" target="#formula_78">60</ref>) are directly applicable to layers which satisfy a certain structure.</s><s>Suppose we have a neuron activation x j from one layer which is modeled as a function of inputs from activations x i from the preceding layer.</s><s>Then layer-wise relevance propagation is directly applicable if there exists a function g j and functions h ij such that</s></p><formula xml:id="formula_81">x j ¼ g j X i h ij ðx i Þ !<label>ð63Þ</label></formula><p><s>In such a general case, the weighting terms z ij = x i w ij from Eq <ref type="bibr" target="#b50">(50)</ref> have to be replaced accordingly by a function of h ij (x i ).</s><s>A key observation is that relevance propagation is invariant against the choice of function g j for computing relevances for the inputs x i conditioned on keeping the value of relevance R j for x j fixed.</s><s>This observation allows to deal with non-linear activation functions g j .</s><s>The function g j does however exert influence on computing the relevance R i by its influence on the relevance R j for x j .</s><s>This can be explained by the fact, that the choice of g j determines the value of x j and thus also relevance R j for x j which gets assigned by the weights in the layer above.</s></p><p><s>We remark again, that even max pooling fits into this structure as a limit of generalized means, see Eq <ref type="bibr" target="#b32">(32)</ref> for example.</s><s>For structures with a higher degree of non-linearity, such as local renormalization <ref type="bibr" target="#b58">[58,</ref><ref type="bibr" target="#b59">59]</ref>, Taylor approximation applied to neuron activation x j can be used again to achieve an approximation for the structure as given in Eq (63).</s></p><p><s>Finally, it can be seen from the formulas established in this section that layer-wise relevance propagation is different from a Taylor series or partial derivatives.</s><s>Unlike Taylor series, it does not require a second point other than the input image.</s><s>Layer-wise application of the Taylor series can be interpreted as a generic way to achieve an approximate version of layer-wise relevance propagation.</s><s>Similarly, in contrast to any methods relying on derivatives, differentiability or smoothness properties of neuron activations are not a necessary requirement for being able to define formulas which satisfy layer-wise relevance propagation.</s><s>In that sense it is a more general principle.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p><s>For Bag of Words features we show two experiments, one on an artificial but easily interpretable data set and one for on Pascal VOC images which have a high compositional complexity.</s><s>For the artificial data set we apply the Taylor-type strategy for the top layer, for Pascal VOC images we apply the strategy for sum-decomposable kernels for the top layer.</s><s>In both cases these strategies are combined with our definitions for arbitrary mappings for the lower layers.</s></p><p><s>For neural networks we show results also on two data sets, two sets of results on MNIST which are easy to interpret, and a second set of experiments in which we rely on a 15 layers already trained network provided as part of the Caffe open source package <ref type="bibr" target="#b60">[60]</ref>, which predicts the 1000 categories from the ILSVRC challenge.</s><s>On one side, by the experiments on MNIST digits, we intend to show that we can uncover details specific to the training phase.</s><s>On the other side, the results for the pre-trained network from the Caffe toolbox demonstrate, that the method works with a deep neural network out of the box and does not rely on possible tricks during the training phase.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag of Words features for polygons versus circles</head><p><s>An example of a pixel-wise decomposition for synthetic data is given in Fig 6 <ref type="figure">.</ref></s><s>The training images were image tiles of size 102 × 102 pixels.</s><s>An image was labeled positive if it contained at least one polygon independent of the presence of circles, and labeled negative if it contained no shape or circles only.</s><s>The BoW features have been computed over standard SIFT features on gray scale brightness values on a dense grid with scales 2.0 and 3.0 resulting in one BoW feature for each scale.</s><s>The SIFT feature masks have been rotated relatively to the main pixel gradient direction at their respective anchor locations.</s><s>One χ 2 -kernel as in Eq (44) was used for each BoW feature in conjunction with multiple kernel learning.</s><s>Therefore the Taylor-type decomposition was used for computing the third layer relevances R ð3Þ d by Eq <ref type="bibr" target="#b46">(46)</ref>.</s><s>The 128-dimensional BoW features are computed using a sum-pooled rank-mapping paradigm  This observation implies that local features over polygons are provided on average with positive second layer scores R ð2Þ l ) 0 and local features over circles receive on average weakly negative second layer scores R ð2Þ l &lt; 0. Furthermore regions which are far from shapes result in scores close to zero which are colored in green in the heatmap from pixel-wise decomposition of the predictions and in the overlay of the image and the decomposition.</s><s>We remark that the shapes have arbitrary positions in the image tiles of the training set and that position information was never used during training or BoW feature extractions.</s><s>Thus, the pixel-wise decomposition is able to detect structures on a smaller scale than the classifier was trained on although position information was never provided during training or used in the classification algorithm which maps an image tile to a real-valued classifier prediction.</s><s>The resolution of the smaller scale is limited by the scale of the SIFT features used here, the scale 3.0 results in a SIFT feature with side length of 4 Á 3 Á 3 = 36 pixels.</s><s>This explains also why pixel scores outside of a shape but nearby to a shape receive the color which corresponds to the label induced by the neighboring shape.</s></p><p><s>Finally we remark that the rank-mapping is a discontinuous weighting scheme for BoW feature dimensions, yet the layer-wise propagation yields reasonable explanations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag of Words features for the Pascal VOC2009 data set</head><p><s>We have calculated pixel-wise predictions for images from the evaluation set of the Pascal VOC 2009 image classification challenge.</s><s>The BoW representations of the training and test part of the data set have been computed over whole images based on local features extracted from a dense regular grid and fixed rotation.</s><s>Standard SIFT features and stacks of 9-dimensional quantile features measuring values from 0.1 to 0.9 of the data over color intensities as in <ref type="bibr" target="#b41">[41]</ref> have been used at local feature scale 3.0.</s><s>The quantile features are split into two regions describing halves of a circle, yielding one 9-dimensional quantile over color intensities each, which are then concatenated.</s><s>The SIFT feature descriptors have been computed once over a gray scale version of the image, stacked with feature descriptors computed over a combination if opposing color channels redþgreenÀ2Áblueþ2 4 , resulting in a 128+128 = 256 dimensional local feature vector.</s><s>For SIFT as well as the color intensity quantiles, the same procedure has been applied to the red, green and blue color channels of the images separately, resulting in 128Á3 = 384 and (2Á9)Á3 = 54 dimensions for the local features respectively.</s><s>SIFT and quantile features were mapped onto 1024 dimensional and 512 dimensional BoW spaces respectively, using the ranked mapping scheme in Formula (64) with p = 2.4 and n = 8.</s><s>Classifiers were trained for detecting the presence of the target object category regardless of the presence of other classes, using multiple kernel learning on three histogram intersection kernels, one for each computed local feature configuration.</s><s>Consequently, the layer-wise relevance propagation Formulas ( <ref type="formula" target="#formula_34">24</ref>) and ( <ref type="formula" target="#formula_40">27</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Networks for MNIST digits</head><p><s>We would like to investigate the capacity of relevance propagation to find evidence for classification of MNIST handwritten digits.</s><s>A particular advantage of this data set over many-class image data sets is that it is easy for humans to interpret both positive and negative evidence, because of the small number of classes.</s><s>For example, evidence for the handwritten digit "1" comes from the presence of a vertical bar on the pixel grid, but also from the absence of horizontal bar starting from the top of the vertical bar, which would make it a "7".</s><s>Also, the data set is relatively simple and the relation between the training algorithm and the resulting pixel-wise relevances can be analyzed.</s></p><p><s>We perform three experiments for MNIST data, as we would like to demonstrate that the method is able to uncover properties specific to the way of training.</s><s>One experiment is done with a smaller network which is trained without translations of digits for the sake of allowing a direct comparison of the pixel-wise decomposition results to class-densities for each pixel of digits and seeing the impact of artifacts in the training set.</s><s>Two further experiments are done on a larger network with has been trained without artifacts and with translated versions of digits and more training iterations for the sake of a better response to digits.</s><s>The latter two experiments intend to show the impact of non-digit pixels as positive and negative evidence for a class of digits.</s></p><p><s>MNIST experiments I.</s><s>The first set of experiments is done on a fully-connected neural network trained in the most common way: Input data is normalized so that the sum of pixels is on average zero, and the variance of pixel values is on average one.</s><s>This setting implies that only black pixels yield strong inputs whereas white pixels fire only due to mean subtraction.</s><s>The absence of translation invariance during training allows to uncover correlations of the pixel-wise decomposition to pixel-wise training densities and, as we will see in the experiments, allow to uncover artifacts in the data that may harm generalization.</s></p><p><s>Examples for pixel-wise decompositions for the first type of neural networks are given in Figs 11, 12 and 13.</s><s>Multilayer neural networks were trained on the MNIST <ref type="bibr" target="#b57">[57]</ref> data of handwritten digits and solve the posed ten-class problem with a prediction accuracy of 98.25% on the MNIST test set.</s><s>Our network consists of three linear sum-pooling layers with a bias-inputs, followed by an activation or normalization step each.</s><s>The first linear layer accepts the 28 × 28 pixel large images as a 784 dimensional input vector and produces a 400-dimensional tanhactivated output vector.</s><s>The second layer projects those 400 inputs to equally many tanh-activated outputs.</s><s>The last layer then transforms the 400-dimensional space to a 10-dimensional output space followed by a softmax layer for activation in order to produce output probabilities for each class.</s><s>The network was trained using a standard error back-propagation algorithm Pixel-wise decompositions for a multilayer neural network trained and tested on MNIST digits, using layer-wise relevance propagation as in Formula <ref type="bibr" target="#b56">(56)</ref>.</s><s>Each group shows the decomposition of the prediction for the classifier of a specific digit indicated in parentheses.</s><s>doi:10.1371/journal.pone.0130140.g012</s><s>using batches of 25 randomly drawn training samples with an added Gaussian noise layer per training iteration.</s><s>The above prediction accuracy was achieved after terminating the training procedure after 50 000 iterations.</s></p><p><s>Fig <ref type="figure" target="#fig_14">11</ref> shows pixel-wise relevances resulting from Taylor-type decomposition as defined in Eqs <ref type="bibr" target="#b18">(18)</ref> and <ref type="bibr" target="#b53">(53)</ref>.</s><s>The left column of the figure shows approximated pixel-wise relevances of the input digits, both times a 7, relative to a blank pixel tile.</s><s>Relevances are calculated for the classifier output producing the prediction score for the class of digits 7. Evidently the upper part of the digit and most prominently the horizontal bar at the top are important characteristics for the predictor speaking for the digit's class.</s><s>The middle column of Fig <ref type="figure" target="#fig_14">11</ref> shows pixelwise relevances for inputs from digit class 5 relative to a blank tile as interpreted by the classifier output reserved for the class of digit 3.</s><s>As for digit class 7, the gradient at the root point x 0 shows high positive prediction weights in areas corresponding to typical characteristics of the target class.</s><s>We observe strong positive responses in areas shared by both digit classes 5 and 3 (indicated by annotation a 2 ) and negative pixel-wise responses where the upper left vertical bar of the input digits is located, which is usually not present in a digit 3 (a 1 ).</s><s>The rightmost column of <ref type="bibr">Fig 11</ref> indicates distinguishing parts of the input digits from class 2 relative to their counter parts from digit class 6 chosen by minimal euclidean distance.</s><s>High pixel scores highlight characteristics of the prediction point indicating membership in class 2, most notable the upper arc and the tail of the input digits 2, as marked with the annotation a 2 .</s><s>Notably in the lower right image of the figure the absence of the leftmost vertical arc of the digit 6 (annotation a 1 ) in the prediction point causes positive local predictions for class 2.</s></p><p><s>Pixel-wise predictions obtained via the layer-wise relevance propagation Formula(56) were calculated based on the output of the last linear layer without taking the succeeding softmax normalization layer into account.</s><s>We can see pixel-wise decompositions for exemplary digits in Fig 12 <ref type="figure">.</ref></s><s>Notably, for the pixel-wise decomposition of the digit 2, we see highly positive responses in lower parts of the digits for the classifiers for digits 2 and 6, however for the classifier for digit 6, the prediction score is negative, because the high positive responses in the lower part are suppressed by high negative responses in the upper part where the digit 2 has an arc which is not present in the digit 6.</s></p><p><s>Correlating the pixel-wise decompositions for classifier for digit k with the relative density of the pixels of the digits k in the training set demonstrates the plausibility of the Each quadruple shows: on the leftmost the input digit; on the middle left the class specific pixel-wise density ratios d k (Eq (65)) for the digit class k for which the pixel-wise decomposition is computed; on the middle right the pixel-wise decomposition R (1) for that digit and the digit class k; on the rightmost the correlation between d k and the pixel-wise decomposition R (1) .</s><s>When considering a digit from class i and a pixel-wise decomposition from class k 6 ¼ i, it is observable that the pixel-wise decomposition shows frequently highly positive activations on pixels of the digit from class i which have high relative density d k for the digit class k 6 ¼ i. MNIST experiments I I.</s><s>In this set of experiments, we train larger neural networks on the MNIST data set augmented translated copies of the digits.</s><s>Neural networks are composed of three hidden layers of 1296 units each, where weight connections between layers are initialized at random.</s><s>Neural networks are trained by backpropagation using stochastic gradient descent with mini batches of size 25 and using a softmax objective <ref type="bibr" target="#b6">[6]</ref>.</s><s>In order to force the neural network to make decisions based on the shape of digits rather than their absolute position on the pixel grid, we augment the training data with pixel-wise translations of ±4 pixels (both vertical and horizontal) and add 10% salt-and-pepper noise to the inputs.</s><s>Also, in order to favor the construction of evidence on both black and white pixels, MNIST digits are re-scaled to take pixel values between −1 (white pixel) and 1 (black pixel).</s></p><p><s>We consider two types of non-linearities: (1) rectified linear units and (2) hyperbolic tangent sigmoids.</s><s>These non-linearities are some of the most commonly used in neural networks and are plotted in Fig 14 <ref type="figure">.</ref></s><s>Also, in order to study explanations on different level of detail, we consider (1) a network that has been trained for 1 000 000 iterations until it reaches 99.2% accuracy and (2) a network trained for only 10 000 iterations, at which point it reaches approximately 97.0% accuracy.</s></p><p><s>Figs 15 and 16 are two case studies of explanations produced by the neural networks we have trained.</s><s>The number in brackets on the top-left corner of the pixel-wise decomposition indicates the class with respect to which evidence is measured.</s><s>Similar explanations are produced by a network trained with rectified linear units.</s><s>It is interesting to note that layer-wise relevance propagation, which is not making use of the gradient information-and therefore agnostic to the type of neurons in the network, -still produces similar results across different types of neurons.</s><s>Explanations learned by the rectifying network are arguably more global, because the rectified linear units are prevented from saturating on both sides and therefore more linear.</s><s>Explanations produced by a rectifying network trained for a shorter time (rect ? ) are clearly more global, as evidenced by the positive and negative parts of the pixel-wise decompositions spreading over larger pixel areas.</s></p><p><s>In order to compute the pixel-wise decompositions, we used Eq <ref type="bibr" target="#b56">(56)</ref>, which does not use numerical stabilizers.</s><s>Use of numerical stabilizers causes relevance to leak from one layer to another, in particular, when the relevance of a particular handwritten digit is measured for Evidence for a handwritten digit being a "3" or a "8".</s><s>Classifying as "3" is supported by the middle horizontal stroke featured in this digit and the absence of vertical connections on the left of the image.</s><s>Evidence for being a "8" feature again the middle horizontal stroke, however, the absence of connections on the left side of the digit constitutes negative evidence.</s><s>Explanations are again stable for various models and samples.</s><s>Pixel flipping experiments using the rect-long model from Section MNIST experiments I I.</s><s>In this section we intend to make a semi-quantitative analysis of the pixel-wise decompositions.</s><s>The basic idea is to compute a decomposition of a digit for a digit class and then flip pixels with highly positive, highly negative scores or pixels with scores close to zero and then to evaluate the impact of these flips onto the prediction scores.</s><s>The advantage of demonstrating this on MNIST data is that a vast majority of pixels either has very high (black) or very low (white) values, with very few pixels having values in between.</s><s>For results on photographic scenes one may need to resort to building masks which are specific to each category, for example, a gray box may be good for masking a flower, but it will not mask effectively a gray road or fur of a Koala bear.</s></p><p><s>In general: If we flip a pixel, we do flipped = pixel Á(−1).</s><s>In further experiments we will consider the digits three and four as inputs.</s><s>The test set contains 983 fours and 1011 threes, over which the mean prediction is calculated.</s></p><p><s>One apparent result from the preceding section is that we can observe non-digit pixels with highly positive pixel scores.</s><s>In Fig <ref type="figure" target="#fig_22">18</ref> we evaluate the impact of flipping non-digit pixels with highly positive pixel scores on the resulting classifier prediction.</s><s>We observe in Fig <ref type="figure" target="#fig_22">18</ref> that the classifier prediction for the true digit class, namely three and four, decreases fast when the nondigit pixels with high pixel scores are flipped.</s><s>This shows, firstly, that having non-digit pixels with high positive pixel scores makes sense for a correct classification.</s><s>We see also, that flipping the highest scoring pixels for a digit three turns it into a digit eight, which is consistent to the decompositions seen in Fig <ref type="figure" target="#fig_10">16</ref>.</s></p><p><s>Secondly, it shows that measuring the quality of a pixel-wise decomposition by an object segmentation mask is not always a good idea.</s><s>When seeing the digit as an object, having nonobject pixels with high scores can make sense in the case of geometric constraints for objects which are to be recognized, as we have in our case.</s><s>For this reason we deliberately did not choose object segmentation masks for the digits as a basis for evaluation in the sense that digitpixels should have highly positive scores, and non-digit pixels should have zero or negative scores.</s></p><p><s>For the same reason, namely the possibility of the presence of geometric constraints, pixelwise decomposition is not always a good weak segmentation in contrast to the convincing results in the experiments of <ref type="bibr" target="#b22">[22]</ref> on images from the ILSVRC data set.</s><s>Another reason for a possible divergence between pixel-wise decomposition and segmentation is the possible influence of context in a scene.</s></p><p><s>Once we have established the reason why we do not use segmentation masks for evaluating the quality of pixel-wise prediction we can observe the effects of flipping the highest scoring pixels, independently of whether they are a digit or non-digit pixel.</s><s>We can see from Thus, the pixel-wise decomposition is not only intuitively appealing to a human but also makes sense for the representation used in classifier to make its decision.</s><s>Using digits for demonstrating such a statement has a mild bias towards our method because for a geometric-driven task like digits we can expect that firstly the problem can be learned well by a classifier so that  the resulting pixel-wise decompositions are very informative, and secondly what has been learned on digits might be more similar between humans and algorithms compared to complex natural scene recognition tasks.</s><s>See, however, the experiments in the Section Neural Network for 1000 ILSVRC classes on the categories from ILSVRC challenge for results on an object recognition tasks on photographic images which also yield results plausible to a human.</s><s>In general one can expect that a classifier with poor recognition ability will yield also pixel-wise decompositions with less informative scores.</s></p><p><s>Finally, we evaluate the influence of pixels with negative scores.</s><s>For this, we take a digit, compute the pixel-wise decomposition for a wrong class, then flip the pixels which are marked negatively when trying to predict the wrong class.</s><s>Results are shown in Fig <ref type="figure" target="#fig_26">21</ref>.</s><s>We observe for both example cases that the prediction for the true class declines sharply as we tweak the digits towards the wrong class.</s><s>For digit 9 as target and digits 4 as inputs this flipping results in a noisy blob on top of a stick, such that the result is not cleanly predictable as a nine.</s><s>However one can observe still a moderate rise of the prediction of the 4 as a 9.</s><s>For digit 8 as target and digits 3 as inputs we can see, that for some intermediate percentage of flips, the 3 will be identified as an 8.</s><s>In summary, negatively scored pixels are able to represent what is contradictory to classifying a digit to belong to a particular class.</s></p><p><s>The results in    On average over all digits, flipping the highest scoring pixels at first results in a fast decline of the prediction for the true class, and at some point another class is predicted.</s><s>Flipping the pixels at first with scores close to zero results in a much slower decline of the prediction for the true class.</s><s>This result demonstrates a quantifiable plausibility of the pixel-wise decomposition by layer-wise relevance prediction.</s><s>In order to visualize the process of pixel flipping, Figs <ref type="figure" target="#fig_28">23  and 24</ref> provide examples of a digit, its heatmap and the resulting images with increasing amounts of flipped pixels.</s><s>For each of the resulting images the softmax output y and the linear layer output yp are shown.</s><s>The first difference between Figs 23 and 24 is that in the former the pixels were flipped according to the heatmap for the highest scoring class, and in the latter the</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Network for 1000 ILSVRC classes</head><p><s>We use here the pre-trained neural network which is provided by the Caffe open source package <ref type="bibr" target="#b60">[60]</ref>.</s><s>Fig <ref type="figure" target="#fig_29">25</ref> shows pixel-wise decompositions for example images from categories of the ILSVRC data set.</s><s>Results are shown on images from Wikimedia Commons rather than the ILSVRC images in order to avoid license problems when showing images.</s><s>Unsurprisingly the evidence is not as sharp as for the MNIST data set because the underlying classification problem is much more diverse with a higher complexity of classes and images to be processed.</s><s>We can see for the rooster high scores at his cockscomb and parts of his feathers.</s><s>The black widow spider has high evidence in her head section which is surprising because it is not so prominent to humans but is consistent among other images of black widow spiders as well.</s><s>Further high evidence lies in parts of black widow legs, and, as expected, the characteristic red spots of a black widow.</s><s>For the tabby cat we see evidence in his fur but also in the road surface under the cat which has similar color and texture to a cat's fur.</s><s>The espresso cup has high responses on the cup's edges, the grip, some evidence in the espresso liquid, however only little response for the edges on the accompanying sweets which has the wrong color, gray, for an espresso.</s><s>Note that a good classifier for a concept does not necessarily imply that an object can be localized very well by its pixel-wise decomposition.</s><s>Since the classifier processes an image globally, it can perceive evidence away from the actual object, for example by taking into account typical background of objects, the context of an object or global statistics which are correlated to an object.</s><s>In that sense, for example, bottles can serve as evidence for a dining table or sky can be a clue for photos with airplanes on the ground or photos of outside views of churches.</s></p><p><s>Fig <ref type="figure" target="#fig_10">26</ref> shows examples where the pixel-wise decomposition does not yield discriminative results.</s><s>For the toilet paper, positive prediction scores were already low in both examples.</s><s>This corresponds to our expectation that a less discriminative classifier results also in less convincing pixel-wise decompositions.</s></p><p><s>Comparing the different shown methods in Figs 25 and 27, one can see that the method (58) with a small value of the stabilizer produces results with the finest granularity and also with the highest amount of negative evidence.</s><s>When increasing the values of the stabilizer , the method becomes less granular and shows less negative evidence.</s><s>This result was also observed when comparing other small and large values of the stabilizer .</s><s>The decrease of negative pixel-wise scores and of granularity can be both explained under some assumptions.</s><s>Firstly, note that compared to Eq <ref type="bibr" target="#b58">(58)</ref> with stabilizer equal to 0 the Eq (58) with stabilizer ε differs by a multiplicative factor of jz j j jz j jþ which goes to zero when jz j j goes to zero.</s><s>Thus dampening by this factor increases when the absolute value of inputs jz j j decreases.</s><s>Secondly note, that in Eq (58) the sign of the relevance R j of input neuron j will be flipped in the messages R ðl;lþ1Þ i j for either the positive or the negative inputs z ij (depending on the sign of z ij z j ).</s><s>When we assume that the neurons at layer l + 1 with small absolute value of inputs jz j j are responsible for generating a high proportion of all negative messages R ðl;lþ1Þ i j &lt; 0, then the reduction of negative pixel-wise scores by increasing stabilizer ε can be explained.</s><s>Such an assumption can be reasonable because a small absolute value of inputs can sometimes be explained by the sum of positive inputs being close to the sum negative inputs, and noting that either the positive or the negative  <ref type="bibr" target="#b60">[60]</ref>.</s><s>Second column shows decompositions computed by Formula (58) with stabilizers ε = 0.01, the third column with stabilizers ε = 100, the fourth column was computed by Formula (60) using α = +2, β = −1.</s><s>The artifacts at the edges of the images are caused by filling the image with locally constant values which comes from the requirement to input square sub-parts of images into the neural net.</s><s>Pictures in order of appearance from Wikimedia Commons by authors Jens Nietschmann, Shenrich91, Sandstein, Jörg Hempel.</s><s>doi:10.1371/journal.pone.0130140.g025</s><s>sets will produce negative messages R ðl;lþ1Þ i j &lt; 0. Therefore, in case of small inputs, sometimes a large fraction of the relevance R j can be turned into negative messages.</s><s>On the other side, one can expect that in a neural network which predicts a positive score f(x) &gt; 0, a majority of network inputs is positive, and a majority of neuron relevances R j is positive, since their sum within a layer equals f(x) &gt; 0. In particular one may expect from that, that the majority of neurons with large inputs z j have positive relevances R j &gt; 0, and the messages for neurons with large inputs z j are mostly positive.</s><s>In conclusion, positive scores are less affected by dampening when f(x) &gt; 0. Canceling out negative scores by a large value of in intermediate layers leads also to more positive scores observed in the final heatmaps, and thus also to less visual granularity.</s><s>We emphasize that this is a qualitative argument which we validated by checking a small number images rather than a universally holding claim.</s><s>As for properties of Eq (60), we note that a choice of β &lt; 0 such that α = 1 − β fixes the ratio of negative to positive messages to Àb 1Àb for each neuron.</s><s>In particular, the sum of the negative messages is upper bounded by the sum of the positive messages.</s><s>For rectified linear neurons this is a reasonable assumption because they fire only when their input is positive.</s><s>In conclusion, our choice β = −1, yielding a ratio of 1:2 towards positive messages explains why the heatmaps for the method <ref type="bibr" target="#b60">(60)</ref>  It is known from <ref type="bibr" target="#b21">[21]</ref> that lower layers of deep networks which are very similar to the one from <ref type="bibr" target="#b60">[60]</ref> used here may act like learned texture or gradient detectors.</s><s>Fig <ref type="figure" target="#fig_8">27</ref> shows that the pixel-wise decomposition is, however, not equivalent to simply assigning scores to dominant edges.</s><s>The original images from Fig 27 have many regions with strong gradients, however the pixel-wise decomposition assigns notable scores only to a small fraction of pixels with large gradients.</s><s>Note for example that the highly textured and visually prominent wallpaper in the middle example with the table lamp receives only small scores.</s><s>The same holds for the artifacts at the edges of the images which come from filling the image with locally constant values which is a compromise in order to make these images to be a square.</s></p><note type="other">in</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p><s>Nonlinear learning machines are ubiquitous in modern problem solving.</s><s>While highly successful in e.g.</s><s>hard classification, regression or ranking problems, their non-linearity so far has prevented these models to additionally explain and thus contribute to a better understanding about the nature of the solved problem.</s><s>Making, say, a nonlinear classification decision for one  particular novel data point transparent to the user is essentially orthogonal to the standard task of optimizing for an excellent and well generalizing classifier.</s><s>We have introduced a tool set for deconstructing a nonlinear decision and thus fostering transparency for the user.</s></p><p><s>In particular we have introduced the general concept of decomposition of a nonlinear image classification decision in terms of pixels.</s><s>In other words, for a well-classified image, a heatmap can be produced that highlights pixels that are responsible for the predicted class membership.</s><s>Note that this is possible without need of segmented training images.</s><s>We consider heatmapping as an important part of the interpretation of nonlinear learning machines and its applicability goes far beyond what has been exemplarily presented in this work: it ranges from the interpretation of bio-medical images to the practical validation of a trained models for image classification.</s></p><p><s>Practically, we have proposed two different approaches to pixel-wise decomposition: The first one, Taylor-type decomposition, seeks to linearly approximate the class scoring function locally by performing a Taylor decomposition of it near a neutral data point without class membership, where the contribution of each dimension (i.e.</s><s>pixel) can easily be identified.</s><s>The second one, coined layer-wise relevance propagation, applies a propagation rule that distributes class relevance found at a given layer onto the previous layer.</s><s>The layer-wise propagation rule was applied iteratively from the output back to the input, thus, forming another possible pixelwise decomposition.</s><s>This inherits the favorable scaling properties of backpropagation.</s></p><p><s>Notably, these two methods were not defined as a particular solution to the heatmapping problem, but instead as a set of constraints that the heatmapping procedure must fulfill in order to be admissible.</s><s>For instance, the exact choice of Taylor reference point was not specified beyond the constraints that it should be a root and that it should be located close to the actual data point.</s><s>Similarly, the layer-wise relevance propagation has been defined with the sole restriction that the propagation rule conserves class relevance on a layer and node basis.</s><s>Thus, the further specification of relevance propagation rule is deferred to the appreciation of the user, or as a future work, and may either be model-specific, problem-specific, or subject to a particular practical or computational requirement.</s></p><p><s>Specific instances of the pixel-wise decomposition procedure satisfying the constraints mentioned above have been proposed and analyzed.</s><s>In particular, our work has covered a set of non-linear learning algorithms for image classification, including kernel classifiers over Bag of Words pooled features, and feed-forward multilayer neural networks.</s><s>Both models are popular choices for image classification or analysis.</s></p><p><s>Our experiments show that applying Taylor-type decomposition, layer-wise relevance propagation or a combination of both on these non-linear models produces highly informed heatmaps that reflect in many aspects the sophistication of the learned classifier.</s><s>In particular, we have demonstrated that the same relevance propagation rule may, for different images, react to a variety of image features within the bounds modeling capacity.</s><s>For example, in the case of the ImageNet convolutional network, we have shown that the heatmapping procedure finds class-relevant features that can be large areas of a particular color, localized features, image gradients, or more structured visual features such as edges, corners, contours, or object parts.</s></p><p><s>An important aspect of the proposed heatmapping procedure lies in the fact that it does not require to modify the learning algorithm, or to learn an additional model for heatmapping.</s><s>Instead, it can be directly and transparently applied to any (pre-)trained Bag of Words model or neural network when applicable.</s><s>This desirable property is demonstrated in this paper by the heatmapping of images classified by the third-party GPU-trained ImageNet neural network.</s><s>In particular, our heatmapping procedure was applied to this network without any further training or retraining.</s><s>Thus, heatmaps for the ImageNet network could be quickly produced using a modest CPU.</s></p><p><s>While we have proposed in this paper several instances of pixel-wise decomposition and demonstrated their excellent performance in practice, the set of possible relevance propagation methods, and their mathematical properties, will certainly have to be further explored.</s><s>A first aspect that needs to be investigated is the greediness of the layer-wise relevance propagation procedure, in the sense that it is computed one layer at a time, and its potential impact on the quality of heatmaps: While computationally advantageous, some of the backpropagated relevance might encounter a dead-end in the lower layers and be distributed randomly.</s><s>Another open question relates to the heuristic nature of the proposed instances of relevance propagation, in particular, whether the distributed relevance messages being proportional to the weighted neuron activations can be analytically justified.</s></p><p><s>Finally, it is not clear how to evaluate the quality of a heatmap beyond simple visual assessment.</s><s>In this paper we have proposed as a starting point a pixel-flipping method that allows to discriminate between two heatmapping methods that may otherwise look of similar quality to the human.</s><s>Finding quantitative properties that are desirable for these heatmaps, or further constraints on the heatmapping procedure is therefore of nature to complement the human assessment.</s><s>Future work will need to explore the many domain-and data-specific degrees of freedom in the heatmapping process in order to ultimately propose a universal metric for quantification.</s><s>It is our firm belief, that heatmapping will be an important ingredient of future knowledge discovery and exploratory analysis and understanding of complex data in the sciences and industry, even beyond the presented field of image analysis.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig 1 .</head><label>1</label><figDesc><div><p><s>Fig 1.Visualization of the pixel-wise decomposition process.</s><s>In the classification step the image is converted to a feature vector representation and a classifier is applied to assign the image to a given category, e.g., "cat" or "no cat".</s><s>Note that the computation of the feature vector usually involves the usage of several intermediate representations.</s><s>Our method decomposes the classification output f(x) into sums of feature and pixel relevance scores.</s><s>The final relevances visualize the contributions of single pixels to the prediction.</s><s>Cat image by pixabay user stinne24.</s></p></div></figDesc><graphic coords="3,36.00,78.01,540.00,133.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig 2 .</head><label>2</label><figDesc><div><p><s>Fig 2. Left: A neural network-shaped classifier during prediction time.</s><s>w ij are connection weights.</s><s>a i is the activation of neuron i. Right: The neural network-shaped classifier during layer-wise relevance computation time.</s><s>R ðlÞi is the relevance of neuron i which is to be computed.</s><s>In order to facilitate the computation of R ðlÞ i we introduce messages R ðl;lþ1Þ i j .</s><s>R ðl;lþ1Þ</s></p></div></figDesc><graphic coords="5,200.01,78.01,308.35,100.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig 3 .</head><label>3</label><figDesc><div><p><s>Fig 3.</s><s>An exemplary real-valued prediction function for classification with the dashed black line being the decision boundary which separates the blue from the green dots.</s><s>The blue dots are labeled negatively, the green dots are labeled positively.</s><s>Left: Local gradient of the classification function at the prediction point.</s><s>Right: Taylor approximation relative to a root point on the decision boundary.</s><s>This figure depicts the intuition that a gradient at a prediction point x-here indicated by a square-does not necessarily point to a close point on the decision boundary.</s><s>Instead it may point to a local optimum or to a far away point on the decision boundary.</s><s>In this example the explanation vector from the local gradient at the prediction point x has a too large contribution in an irrelevant direction.</s><s>The closest neighbors of the other class can be found at a very different angle.</s><s>Thus, the local gradient at the prediction point x may not be a good explanation for the contributions of single dimensions to the function value f(x).</s><s>Local gradients at the prediction point in the left image and the Taylor root point in the right image are indicated by black arrows.</s><s>The nearest root point x 0 is shown as a triangle on the decision boundary.</s><s>The red arrow in the right image visualizes the approximation of f(x) by Taylor expansion around the nearest root point x 0 .</s><s>The approximation is given as a vector representing the dimension-wise product between Df(x 0 ) (the black arrow in the right panel) and x − x 0 (the dashed red line in the right panel) which is equivalent to the diagonal of the outer product between Df(x 0 ) and x − x 0 .</s><s>doi:10.1371/journal.pone.0130140.g003</s></p></div></figDesc><graphic coords="9,36.00,78.01,540.00,173.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc><div><p><s>f(Á) the classifier's prediction function x,y BoW representation and class label x 0 ,z root point of Taylor Expansion, root point candidates α,b learned model parameters k(x i ,x i 0 ) kernel function d,V counter and number of BoW-dimensions R ð3Þ d (approximate) contribution of BoW-dimension d R ð2Þ l local feature relevance R ð1Þ q pixel-wise decompositions per pixel q m(l) mapping function between local features l and BoW l,l 0 local feature descriptors Z(x) the set of unmapped dimensions of a BoW data point x area(l) the set of pixel coordinates covered by l doi:10.1371/journal.pone.0130140.t001</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig 4 .</head><label>4</label><figDesc><div><p><s>Fig 4. Local and global predictions for input images are obtained by following a series of steps through the classification-and pixel-wise decomposition pipelines.</s><s>Each step taken towards the final pixel-wise decomposition has a complementing analogue within the Bag of Words classification pipeline.</s><s>The calculations used during the pixel-wise decomposition process make use of information extracted by those corresponding analogues.</s><s>Airplane image in the graphic by Pixabay user tpsdave.</s><s>doi:10.1371/journal.pone.0130140.g004</s></p></div></figDesc><graphic coords="13,36.00,78.01,540.00,223.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1</head><label>1</label><figDesc><div><p><s>Pixel-wise decomposition for BoW features with SVM classifiers Inputs: Image I Local features L BoW representation x (and Taylor root point x 0 ) model and mapping parameters for d = 1 to V do R ð3Þ d as in Eqs (</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc><div><p><s>Fig 5 depicts a graphic example.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig 5 .</head><label>5</label><figDesc><div><p><s>Fig 5. Multilayer neural network annotated with the different variables and indices describing neurons and weight connections.</s><s>Left: forward pass.</s><s>Right: backward pass.</s><s>doi:10.1371/journal.pone.0130140.g005</s></p></div></figDesc><graphic coords="20,36.00,78.01,540.00,128.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 2</head><label>2</label><figDesc><div><p><s>Pixel-wise decomposition for neural networksInput: R (L) = f(x) for l 2 {L − 1, . .</s><s>.,1} do R ðl;lþ1Þ i j as in Eqs (58) or (60) R ðlÞ i ¼ P j R ðl;lþ1Þ i j end for Output: 8d : R ð1Þ d Above formulas (</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>m</head><label></label><figDesc><div><p><s>ðdÞ ðl j Þ m ðdÞ ðlÞ ¼ ( p Àrk d ðlÞ ; rk d ðlÞ n 0 ; else ð64Þ followed by an ℓ 1 -normalization of x.</s><s>Similar as in [41] we set p = 2 and n = 4.</s><s>The expression rk d (l) in Formula (64) describes the rank of the BoW prototype representing dimension d in the BoW feature space among ascendingly ordered Euclidean distances between l and all BoW prototypes.</s><s>Thus Formula (27) based on layer-wise relevance propagation was used to obtain predictions R ð2Þ l .</s><s>In order to compute the visualization in Fig 6, the test picture was divided into</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig 6 .</head><label>6</label><figDesc><div><p><s>Fig 6.</s><s>Pixel-wise decomposition for Bag of Words features over χ 2 -kernels using the Taylor-type decomposition for the third layer and the layerwise relevance propagation for the subsequent layers.</s><s>Left: The original image.</s><s>Middle: Pixel-wise prediction.</s><s>Right: Superposition of the original image and the pixel-wise prediction.</s><s>The decompositions were computed on tiles of size 102 × 102 and having a regular offset of 34 pixels.</s><s>The decompositions from the overlapping tiles were averaged.</s><s>In the heatmap, based on linearly mapping the interval [−1, +1] to the jet color map available in many visualization packages, green corresponds to scores close to zero, yellow and red to positive scores and blue color to negative scores.</s><s>See text for interpretation.</s><s>doi:10.1371/journal.pone.0130140.g006</s></p></div></figDesc><graphic coords="23,36.00,354.33,540.00,281.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc><div><p><s>) were used to compute local predictions for each evaluation image as a whole.</s><s>Pixel-wise predictions for the classes representing buses, persons, airplanes and cats are presented in Figs 7, 8, 9 and 10 respectively.</s><s>An interpretation which has been drawn from the depicted examples and other examples which are omitted here is given in the figure captions.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig 7 .Fig 8 .</head><label>78</label><figDesc><div><p><s>Fig 7. Pixel-wise decomposition for Bag of Words features over a histogram intersection kernel using the layer-wise relevance propagation for all subsequent layers and rank-mapping for mapping local features.</s><s>Each triplet of images shows-from left to right-the original image, the pixel-wise predictions superimposed with prominent edges from the input image and the original image superimposed with binarized pixel-wise predictions.</s><s>The decompositions were computed on the whole image.</s><s>Images twice by Pixabay users tpsdave, and by Pixabay users sirocumo and Pixeleye.</s><s>doi:10.1371/journal.pone.0130140.g007</s></p></div></figDesc><graphic coords="25,36.00,78.01,540.00,136.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig 9 .</head><label>9</label><figDesc><div><p><s>Fig 9.Pixel-wise decomposition for Bag of Words features over a histogram intersection kernel using the layer-wise relevance propagation for all subsequent layers and rank-mapping for mapping local features.</s><s>Each triplet of images shows-from left to right-the original image, the pixel-wise predictions superimposed with prominent edges from the input image and the original image superimposed with binarized pixel-wise predictions.</s><s>The decompositions were computed on the whole image.</s><s>Notably the tail of a plane receives negative scores consistently.</s><s>Blue sky context seems to contribute to classification which has been conjectured already in the PASCAL VOC workshops<ref type="bibr" target="#b35">[35]</ref> and which was observed also on other images not shown here, see the the second picture for comparison against the other three images which have more blueish sky.</s><s>Images from Pixabay users Holgi, nguyentuanhung, rhodes8043 and tpsdave.</s><s>doi:10.1371/journal.pone.0130140.g009</s></p></div></figDesc><graphic coords="26,36.00,78.01,540.00,130.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig 11 .</head><label>11</label><figDesc><div><p><s>Fig 11.</s><s>Taylor-approximated pixel-wise predictions for a multilayer neural network trained and tested on the MNIST data set.</s><s>Each group of four horizontally aligned panels shows-from left to right-the input digit, the Taylor root point x 0 , the gradient of the prediction function f at x 0 of a specific digit class indicated by the subscript next to f and the approximated pixel-wise contributions for x. doi:10.1371/journal.pone.0130140.g011</s></p></div></figDesc><graphic coords="27,36.00,78.01,540.00,107.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig 13 .</head><label>13</label><figDesc><div><p><s>Fig 13.</s><s>Each quadruple shows: on the leftmost the input digit; on the middle left the class specific pixel-wise density ratios d k (Eq (65)) for the digit class k for which the pixel-wise decomposition is computed; on the middle right the pixel-wise decomposition R(1) for that digit and the digit class k; on the rightmost the correlation between d k and the pixel-wise decomposition R(1) .</s><s>When considering a digit from class i and a pixel-wise decomposition from class k 6 ¼ i, it is observable that the pixel-wise decomposition shows frequently highly positive activations on pixels of the digit from class i which have high relative density d k for the digit class k 6 ¼ i.</s></p></div></figDesc><graphic coords="28,36.00,78.01,540.00,105.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc><div><p><s>doi:10.1371/journal.pone.0130140.g013</s><s>decomposition.</s><s>seen in Fig 13.</s><s>When considering the decomposition for a classifier for digit k and using a digit i 6 ¼ k from the wrong class as input, then we observe often that the decomposition shows high positive activations on those pixels of digit i which have high relative density d k (p) (Eq (65)) within the training set for digits of type k.</s><s>Even when we use the classifier for the wrong class, it uncovers evidence on those pixels which overlap regions with high density of positively labeled digits of its training set.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig 14 .</head><label>14</label><figDesc><div><p><s>Fig 14.</s><s>Example of non-linear activation functions g used in multilayer neural networks.</s><s>doi:10.1371/journal.pone.0130140.g014</s></p></div></figDesc><graphic coords="29,200.01,493.23,350.14,174.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig 15 .</head><label>15</label><figDesc><div><p><s>Fig 15.</s><s>Evidence for a handwritten digit being a "4" or a "9".</s><s>Strong positive evidence for "4" is allocated to the top part of the image for keeping it blank.</s><s>If trying to interpret these digits as "9", the open top-part of the image is perceived as negative evidence for this class, because a "9" would rather have a topdash closing the upper loop of the "4".</s><s>Explanations are consistent across a variety of neural networks and samples.</s><s>doi:10.1371/journal.pone.0130140.g015</s></p></div></figDesc><graphic coords="30,36.00,78.01,540.00,175.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>doi: 10 .</head><label>10</label><figDesc><div><p><s>1371/journal.pone.0130140.g016</s><s>another class.</s><s>Fig 17 shows examples of pixel-wise decompositions for 16 randomly drawn digits sorted according to the digit class.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc><div><p><s>Fig 19 that the prediction of the correct digit class decreases sharply in this case as well.</s><s>This decrease can be compared to the case when we flip those pixels whose absolute value of the decomposition score s is closest to zero by sorting the pixels according to 1 − jsj.</s><s>We see in Fig 20 that the classifier prediction for the true class decreases only very slowly, thus neutrally scored pixels are less relevant for the prediction.</s><s>The comparison between Figs 19 and 20 shows that the decomposition score is able to identify those pixels which play little role in the classification of a digit and those pixels which are important for identifying a digit.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig 17 .</head><label>17</label><figDesc><div><p><s>Fig 17.</s><s>Pixel-wise decompositions for all classes for 16 randomly drawn digits from the MNIST test set.</s><s>Results are obtained using the relevance propagation Formula (56) with the rectifying network trained for 1 000 000 iterations from Section MNIST experiments I I. doi:10.1371/journal.pone.0130140.g017</s></p></div></figDesc><graphic coords="32,36.00,78.01,407.51,580.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig 18 .</head><label>18</label><figDesc><div><p><s>Fig 18. Flipping of high-scoring non-digit pixels.</s><s>Pixels with highest positive scores are flipped first.</s><s>The pixel-wise decomposition was computed for the true digit class, three (left) and four (right).</s><s>doi:10.1371/journal.pone.0130140.g018</s></p></div></figDesc><graphic coords="33,36.00,78.01,534.44,257.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figs 18 ,</head><label>18</label><figDesc><div><p><s><ref type="bibr" target="#b19">19</ref> and 20 are shown for the true class against one or more particular wrong classes.</s><s>The results hold also when we show the behavior of the classifier predictions under flipping of the highest scoring and the most zero-like pixels when we compared for each digit against the maximum of predictions over all wrong classes.</s><s>Furthermore we compute the average over all 10 digits, not only digits 3 and 4 as true classes as shown inFigs 18, 19 and 20.</s><s>This result is shown inFig 22.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig 20 .</head><label>20</label><figDesc><div><p><s>Fig 20.</s><s>Flipping of pixels with pixel-wise decomposition score close to zero.</s><s>Pixels with absolute value closest to zero are flipped first.</s><s>Digit and nondigit pixels may be flipped.</s><s>Pixel-wise decomposition have been computed for the true digit classes three (left) and four (right).</s><s>doi:10.1371/journal.pone.0130140.g020</s></p></div></figDesc><graphic coords="34,36.00,78.01,534.44,257.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig 22 .</head><label>22</label><figDesc><div><p><s>Fig 22. Flipping of pixels for digit and non-digit pixels, compared for each modified digit for the true class against the maximal prediction of all wrong classes.</s><s>Left: Pixels with highest positive scores are flipped first.</s><s>Right: Flipping of neutrally predicted pixels, i.e. pixels with absolute value closest to zero are flipped first (solid lines), and flipping of randomly picked pixels (dashed lines).</s><s>Results are averaged over digits from all digit classes in contrast to using only digit classes 3 and 4 in the preceding figures.</s><s>doi:10.1371/journal.pone.0130140.g022</s></p></div></figDesc><graphic coords="35,36.00,393.05,533.25,256.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig 21 .</head><label>21</label><figDesc><div><p><s>Fig 21.</s><s>Flipping of pixels with negative responses, due to a pixel-wise decomposition for prediction targets 8 (for digits 3 on the left) and 9 (for digits 4 on the right).</s><s>Pixels with lowest negative scores are flipped first.</s><s>doi:10.1371/journal.pone.0130140.g021</s></p></div></figDesc><graphic coords="35,36.00,78.01,534.44,257.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig 23 .</head><label>23</label><figDesc><div><p><s>Fig 23.</s><s>Examples of images with an increasing amount of flipped pixels and the corresponding predictions of the classifier.</s><s>Here pixels are flipped away from the class label given in parentheses above the heatmap.</s><s>Pixels were flipped in steps of 1% of all pixels until the predicted class label changed.</s><s>The plots show the output of the softmax function y and the output score of the preceding linear layer yp.</s><s>The pixels were sorted before flipping in decreasing order of the pixel-wise score, i.e. highest scoring pixels were flipped first.</s><s>In this panel the heatmap was computed for the classifier which produced the highest score, i.e. for the predicted class label.</s><s>The originally predicted label is given on the leftmost image in parentheses, the predicted label after the switch of the prediction is given in the rightmost image.doi:10.1371/journal.pone.0130140.g023</s></p></div></figDesc><graphic coords="36,36.00,78.01,448.55,409.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig 24 .</head><label>24</label><figDesc><div><p><s>Fig 24.Examples of images with an increasing amount of flipped pixels and the corresponding predictions of the classifier.</s><s>Here pixels are flipped towards the class label given in parentheses above the heatmap.</s><s>Pixels were flipped in steps of 1% of all pixels until the predicted class label changed.</s><s>The plots show the output of the softmax function y and the output score of the preceding linear layer yp.</s><s>The pixels were sorted before flipping in increasing order of the pixel-wise score, i.e. lowest scoring pixels were flipped first.</s><s>In this panel the heatmap was computed for a classifier which did not produce the highest score, i.e. for a random false class label.</s><s>The originally predicted label is given on the leftmost image in parentheses, the predicted label after the switch of the prediction is given in the rightmost image.</s><s>doi:10.1371/journal.pone.0130140.g024</s></p></div></figDesc><graphic coords="37,36.00,275.93,467.49,341.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig 25 .</head><label>25</label><figDesc><div><p><s>Fig 25.</s><s>The pixel-wise decompositions for examples images of the neural net pre-trained on ILSVRC data set images and provided by the Caffe open source package<ref type="bibr" target="#b60">[60]</ref>.</s><s>Second column shows decompositions computed by Formula (58) with stabilizers ε = 0.01, the third column with stabilizers ε = 100, the fourth column was computed by Formula (60) using α = +2, β = −1.</s><s>The artifacts at the edges of the images are caused by filling the image with locally constant values which comes from the requirement to input square sub-parts of images into the neural net.</s><s>Pictures in order of appearance from Wikimedia Commons by authors Jens Nietschmann, Shenrich91, Sandstein, Jörg Hempel.</s></p></div></figDesc><graphic coords="39,36.00,78.01,540.00,542.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head></head><label></label><figDesc><div><p><s>Figs 25 and 27 are dominantly positive.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Fig 26 .Fig 27 .</head><label>2627</label><figDesc><div><p><s>Fig 26.</s><s>Failure examples for the pixel-wise decomposition.</s><s>Left and Right: Failures to recognize toilet paper.</s><s>The decompositions computed by Formula (58) with stabilizers ε = 0.01 The neural net is the pre-trained one on ILSVRC data from the Caffe package [60].</s><s>The computing methods for each column are the same as in Fig 25.</s><s>Pictures in order of appearance from Wikimedia Commons by authors Robinhood of the Burger World and Taro the Shiba Inu.</s><s>doi:10.1371/journal.pone.0130140.g026</s></p></div></figDesc><graphic coords="40,36.00,78.01,463.92,114.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head></head><label></label><figDesc><div><p><s>doi:10.1371/journal.pone.0130140.g027</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc><div><p><s>Notation Conventions Used in This Section.</s></p></div></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">PLOS ONE | DOI:10.1371/journal.pone.0130140 July 10, 2015</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Bayesian Hierarchical Model for Learning Natural Scene Categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2005</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="20" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<idno type="DOI">10.1109/CVPR.2005.16</idno>
		<ptr target="http://dx.doi.org/10.1109/CVPR.2005.16" />
		<imprint>
			<date type="published" when="2005-06">June 2005. 2005</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="524" to="531" />
			<pubPlace>San Diego, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Self-supervised Monocular Road Detection in Desert Terrain</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dahlkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stavens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Classification Of Cervical Cell Nuclei Using Morphological Segmentation And Textural Feature Extraction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jackway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lovell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Longstaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australian New Zealand Conference on Intelligent Information Systems</title>
				<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Object Recognition from Polarimetric SAR Images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hänsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hellwich</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-90-481-3751-0_5</idno>
		<ptr target="http://dx.doi.org/10.1007/978-90-481-3751-0_5" />
	</analytic>
	<monogr>
		<title level="m">of Remote Sensing and Digital Image Processing</title>
				<editor>
			<persName><forename type="first">U</forename><surname>Soergel</surname></persName>
		</editor>
		<meeting><address><addrLine>Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="109" to="131" />
		</imprint>
	</monogr>
	<note>Radar Remote Sensing of Urban Areas</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rapid Object Detection using a Boosted Cascade of Simple Features</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="511" to="518" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Neural Networks for Pattern Recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Oxford University Press, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual categorization with bags of keypoints</title>
		<author>
			<persName><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
		<ptr target="http://www.xrce.xerox.com/Research-Development/Publications/2004-0105/(language)/eng-GB" />
	</analytic>
	<monogr>
		<title level="j">In Workshop on Statistical Learning in Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2004">2004. 2015 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<ptr target="http://www.image-net.org/challenges/LSVRC/2012/" />
		<title level="m">The ImageNet Large Scale Visual Recognition Challenge 2012 (ILSVRC2012);. Accessed</title>
				<imprint>
			<date type="published" when="2015-04-01">2015 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results</title>
		<author>
			<persName><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cki</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">ImageCLEF: Experimental Evaluation in Visual Information Retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note>of The Information Retrieval Series</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving the Fisher Kernel for Large-Scale Image Classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>Daniilidis K, Maragos P, Paragios N</editor>
		<imprint>
			<biblScope unit="volume">6314</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Linear spatial pyramid matching using sparse coding for image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="1794" to="1801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Nonlinear Learning using Local Coordinate Coding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cki</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="page" from="2223" to="2231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Locality-constrained Linear Coding for image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="3360" to="3367" />
			<date type="published" when="2010">2010</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual Word Ambiguity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Geusebroek</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2009.132</idno>
		<idno type="PMID">20489229</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1271" to="1283" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<title level="m">Neural Networks: Tricks of the Trade, Reloaded</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7700</biblScope>
		</imprint>
	</monogr>
	<note>of Lecture Notes in Computer Science (LNCS). 2nd ed</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">How to Explain Individual Classification Decisions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Baehrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schroeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1803" to="1831" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visualization of Nonlinear Classification Models in Neuroimaging -Signed Sensitivity Maps</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schmah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yourganov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Strother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BIOSIGNALS</title>
		<editor>Huffel SV, Correia CMBA, Fred ALN, Gamboa H</editor>
		<imprint>
			<biblScope unit="page" from="254" to="263" />
			<date type="published" when="2012">2012</date>
			<publisher>SciTePress</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visual Interpretation of Kernel-Based Prediction Models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Baehrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schroeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<idno type="DOI">10.1002/minf.201100059</idno>
	</analytic>
	<monogr>
		<title level="j">Molecular Informatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="817" to="826" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visualizing and Understanding Convolutional Networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno>doi: abs/ 1311.2901</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<editor>Bartlett PL, Pereira FCN, Burges CJC, Bottou L, Weinberger KQ</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>doi: abs/1312.6034</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive deconvolutional networks for mid and high level feature learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="page" from="2018" to="2025" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno>doi: abs/1312.6199</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Explaining and Harnessing Adversarial Examples</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>abs/1412.6572</idno>
		<ptr target="http://arxiv.org/abs/1412.6572" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual Causal Feature Learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chalupka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Eberhardt</surname></persName>
		</author>
		<idno>abs/1412.2309</idno>
		<ptr target="http://arxiv.org/abs/1412.2309" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Visualizing Higher-Layer Features of a Deep Network. University of Montreal</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">1341</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Building high-level features using large scale unsupervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="8595" to="8598" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Review and comparison of methods to study the contribution of variables in artificial neural network models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gevrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dimopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lek</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0304-3800(02)00257-0</idno>
		<idno>doi: 10.1016/ S0304-3800(02)00257-0</idno>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="264" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Olden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Death</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ecolmodel.2004.03.013</idno>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="389" to="397" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Understanding Neural Networks via Rule Extraction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Setiono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<editor>IJCAI. Morgan Kaufmann</editor>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="480" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualization of nonlinear kernel models in neuroimaging by sensitivity maps</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2010.12.035</idno>
		<idno type="PMID">21168511</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1120" to="1131" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">What has my classifier learned? Visualizing the classification rules of bag-of-feature model by support region detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="3586" to="3593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Visual Extent of an Object-Suppose We Know the Object Locations</title>
		<author>
			<persName><forename type="first">Jrr</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rjh</forename><surname>Scha</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-011-0443-1</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="63" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The PASCAL Visual Object Classes Challenge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cki</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Part2-Classification Task</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The PASCAL Visual Object Classes Challenge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cki</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010. VOC2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The CLEF 2011 Photo Annotation and Concept-based Retrieval Tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liebetrau</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org" />
	</analytic>
	<monogr>
		<title level="m">CLEF 2011 Labs and Workshop, Notebook Papers</title>
				<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09-22">19-22 September 2011. 2011. 2015 Apr 01. CLEF2011wn-ImageCLEF-NowakEt2011.pdf</date>
			<biblScope unit="volume">1177</biblScope>
		</imprint>
	</monogr>
	<note>The Netherlands</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Randomized Clustering Forests for Image Classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Moosmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2007.70822</idno>
		<idno type="PMID">18617720</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1632" to="1646" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Kernel Codebooks for Scene Categorization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Geusebroek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="696" to="709" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">In defense of soft-assignment coding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<editor>Metaxas DN, Quan L, Sanfeliu A, Gool LJV</editor>
		<imprint>
			<biblScope unit="page" from="2486" to="2493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Enhanced representation and multi-task learning for image annotation. Computer Vision and Image Understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cviu.2012.09.006</idno>
		<idno>doi: 10.1016/j. cviu.2012.09.006</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="466" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="DOI">10.1023/B:VISI.0000029664.99615.94</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Evaluating Color Descriptors for Object and Scene Recognition</title>
		<author>
			<persName><forename type="first">Kea</forename><surname>De Sande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cgm</forename><surname>Snoek</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2009.154</idno>
		<idno type="PMID">20634554</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Image Classification with the Fisher Vector: Theory and Practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-013-0636-x</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="222" to="245" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning the Kernel Matrix with Semidefinite Programming</title>
		<author>
			<persName><forename type="first">Grg</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="27" to="72" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multiple kernel learning, conic duality, and the SMO algorithm</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grg</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Efficient and Accurate Lp-norm Multiple Kernel Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Brefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Laskov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="997" to="1005" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Brefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Norm Multiple Kernel Learning. Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="953" to="997" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Insights from Classifying Visual Concepts with Multiple Kernel Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Brefeld</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0038897</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Semantic Kernel Forests from Multiple Taxonomies</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="page" from="1727" to="1735" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On Taxonomies for Multi-class Image Categorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-010-0417-8</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="301" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Taxonomic Prediction with Tree-Structured Covariances</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="304" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Heterogeneous feature machines for visual recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="page" from="1095" to="1102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-006-9794-4</idno>
		<ptr target="http://dx.doi.org/10.1007/s11263-006-9794-4" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multiple kernels for object detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="page" from="606" to="613" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1038/323533a0</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986-10">1986 Oct</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The MNIST database of handwritten digits</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998">1998. 2015 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Why is Real-World Visual Object Recognition Hard?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.0040027</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">27</biblScope>
			<date>2008 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Convolutional networks and applications in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCAS</title>
		<imprint>
			<biblScope unit="page" from="253" to="256" />
			<date type="published" when="2010">2010</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Caffe: An Open Source Convolutional Architecture for Fast Feature Embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<ptr target="http://caffe.berkeleyvision.org/" />
		<imprint>
			<date type="published" when="2013">2013. 2015 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
